{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 2\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.sql.functions import input_file_name, regexp_extract, date_format, to_date\nfrom awsglue.dynamicframe import DynamicFrame\n## For getting dates from filenames\n\n\n    \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Current idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: G.1X\nSetting new worker type to: G.1X\nPrevious number of workers: 1\nSetting new number of workers to: 2\nTrying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 2\nSession ID: 9a33027e-59ad-4c2d-8d2b-1d5efadd4f10\nApplying the following default arguments:\n--glue_kernel_version 1.0.4\n--enable-glue-datacatalog true\nWaiting for session 9a33027e-59ad-4c2d-8d2b-1d5efadd4f10 to get into ready status...\nSession 9a33027e-59ad-4c2d-8d2b-1d5efadd4f10 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"tags": [],
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "input_dyf = glueContext.create_dynamic_frame.from_catalog(database='gpt-bucket-database', table_name='data', transformation_ctx='input_dyf')\ninput_dyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- job_key: string\n|-- location: string\n|-- keyword: array\n|    |-- element: string\n|-- from_age: int\n|-- page: int\n|-- position: int\n|-- salary_min: double\n|-- salary_max: double\n|-- salary_type: string\n|-- salary_estimated_flag: int\n|-- job_description: string\n|-- company: string\n|-- job_title: string\n|-- url: string\n|-- split_jd: string\n|-- id: string\n|-- object: string\n|-- created: int\n|-- model: string\n|-- choices: array\n|    |-- element: struct\n|    |    |-- index: int\n|    |    |-- message: struct\n|    |    |    |-- role: string\n|    |    |    |-- content: array\n|    |    |    |    |-- element: string\n|    |    |-- logprobs: null\n|    |    |-- finish_reason: string\n|-- usage: struct\n|    |-- prompt_tokens: int\n|    |-- completion_tokens: int\n|    |-- total_tokens: int\n|-- system_fingerprint: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Change dyf to df to add filenames more easily.",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "input_df = input_dyf.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "input_df_with_filename = input_df.withColumn(\"filename\", input_file_name())",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "input_df_with_filename.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------------+--------+--------------------+--------+----+--------+----------+----------+-----------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+----------+------------------+--------------------+--------------+------------------+--------------------+\n|         job_key|location|             keyword|from_age|page|position|salary_min|salary_max|salary_type|salary_estimated_flag|     job_description|             company|           job_title|                 url|            split_jd|                  id|         object|   created|             model|             choices|         usage|system_fingerprint|            filename|\n+----------------+--------+--------------------+--------+----+--------+----------+----------+-----------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+----------+------------------+--------------------+--------------+------------------+--------------------+\n|c40ac9eaa1278fdc|  remote|[data analyst, da...|       1|  13|      14|   72000.0|  109000.0|     YEARLY|                    0|The Senior Data A...|ohio shared infor...|    sr. data analyst|https://www.indee...|The Senior Data A...|chatcmpl-8yPnOyM8...|chat.completion|1709409530|gpt-3.5-turbo-0125|[{0, {assistant, ...|{879, 11, 890}|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|9da2149f4c0c676f|  remote|      [data analyst]|       1|  13|       2|  64539.29|  81721.12|     YEARLY|                    1|JOB PURPOSE:  The...|           endeavors|        data analyst|https://www.indee...| EXPERIENCE: 3-5 ...|chatcmpl-8yPnOgFj...|chat.completion|1709409530|gpt-3.5-turbo-0125|[{0, {assistant, ...|{468, 15, 483}|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|c7c487473ba0a838|  remote|      [data analyst]|       1|   7|       5|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOyb9...|chat.completion|1709409530|gpt-3.5-turbo-0125|[{0, {assistant, ...|{511, 22, 533}|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|62be243c0db32d5b|  remote|      [data analyst]|       1|  13|       3|   68821.2| 87142.984|     YEARLY|                    1|Overview: \\n  \\n ...|grow financial fe...|        data analyst|https://www.indee...| Performs advance...|chatcmpl-8yPnOOfs...|chat.completion|1709409530|gpt-3.5-turbo-0125|[{0, {assistant, ...| {703, 9, 712}|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|def7c0970b48a38e|  remote|      [data analyst]|       1|  11|      12|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOlbr...|chat.completion|1709409530|gpt-3.5-turbo-0125|[{0, {assistant, ...|{511, 22, 533}|     fp_2b778c6b35|s3://gpt-bucket-i...|\n+----------------+--------+--------------------+--------+----+--------+----------+----------+-----------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+----------+------------------+--------------------+--------------+------------------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Convert back to dyf for relationalization",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "dyf = DynamicFrame.fromDF(input_df_with_filename, glueContext, \"dyf\")\ndyf.printSchema()\n# dyf.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- job_key: string\n|-- location: string\n|-- keyword: array\n|    |-- element: string\n|-- from_age: int\n|-- page: int\n|-- position: int\n|-- salary_min: double\n|-- salary_max: double\n|-- salary_type: string\n|-- salary_estimated_flag: int\n|-- job_description: string\n|-- company: string\n|-- job_title: string\n|-- url: string\n|-- split_jd: string\n|-- id: string\n|-- object: string\n|-- created: int\n|-- model: string\n|-- choices: array\n|    |-- element: struct\n|    |    |-- index: int\n|    |    |-- message: struct\n|    |    |    |-- role: string\n|    |    |    |-- content: array\n|    |    |    |    |-- element: string\n|    |    |-- logprobs: null\n|    |    |-- finish_reason: string\n|-- usage: struct\n|    |-- prompt_tokens: int\n|    |-- completion_tokens: int\n|    |-- total_tokens: int\n|-- system_fingerprint: string\n|-- filename: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Relationalize (unnest) the dynamic frame and view the dyf pieces",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "unnested = dyf.relationalize('root', 's3://gpt-bucket-indeed/temp/')\nunnested.keys()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "dict_keys(['root', 'root_choices.val.message.content', 'root_keyword', 'root_choices'])\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "unnested.select('root_choices').toDF().show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+-----+-----------------+------------------------+---------------------------+-------------------------+\n| id|index|choices.val.index|choices.val.message.role|choices.val.message.content|choices.val.finish_reason|\n+---+-----+-----------------+------------------------+---------------------------+-------------------------+\n|  1|    0|                0|               assistant|                          1|                     stop|\n|  2|    0|                0|               assistant|                          2|                     stop|\n|  3|    0|                0|               assistant|                          3|                     stop|\n|  4|    0|                0|               assistant|                          4|                     stop|\n|  5|    0|                0|               assistant|                          5|                     stop|\n|  6|    0|                0|               assistant|                          6|                     stop|\n|  7|    0|                0|               assistant|                          7|                     stop|\n|  8|    0|                0|               assistant|                          8|                     stop|\n|  9|    0|                0|               assistant|                          9|                     stop|\n| 10|    0|                0|               assistant|                         10|                     stop|\n| 11|    0|                0|               assistant|                         11|                     stop|\n| 12|    0|                0|               assistant|                         12|                     stop|\n| 13|    0|                0|               assistant|                         13|                     stop|\n| 14|    0|                0|               assistant|                         14|                     stop|\n| 15|    0|                0|               assistant|                         15|                     stop|\n| 16|    0|                0|               assistant|                         16|                     stop|\n| 17|    0|                0|               assistant|                         17|                     stop|\n| 18|    0|                0|               assistant|                         18|                     stop|\n| 19|    0|                0|               assistant|                         19|                     stop|\n| 20|    0|                0|               assistant|                         20|                     stop|\n+---+-----+-----------------+------------------------+---------------------------+-------------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "unnested.select('root').toDF().show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------------+--------+-------+--------+----+--------+----------+----------+-----------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+----------+------------------+-------+-------------------+-----------------------+------------------+------------------+--------------------+\n|         job_key|location|keyword|from_age|page|position|salary_min|salary_max|salary_type|salary_estimated_flag|     job_description|             company|           job_title|                 url|            split_jd|                  id|         object|   created|             model|choices|usage.prompt_tokens|usage.completion_tokens|usage.total_tokens|system_fingerprint|            filename|\n+----------------+--------+-------+--------+----+--------+----------+----------+-----------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+----------+------------------+-------+-------------------+-----------------------+------------------+------------------+--------------------+\n|c40ac9eaa1278fdc|  remote|      1|       1|  13|      14|   72000.0|  109000.0|     YEARLY|                    0|The Senior Data A...|ohio shared infor...|    sr. data analyst|https://www.indee...|The Senior Data A...|chatcmpl-8yPnOyM8...|chat.completion|1709409530|gpt-3.5-turbo-0125|      1|                879|                     11|               890|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|9da2149f4c0c676f|  remote|      2|       1|  13|       2|  64539.29|  81721.12|     YEARLY|                    1|JOB PURPOSE:  The...|           endeavors|        data analyst|https://www.indee...| EXPERIENCE: 3-5 ...|chatcmpl-8yPnOgFj...|chat.completion|1709409530|gpt-3.5-turbo-0125|      2|                468|                     15|               483|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|c7c487473ba0a838|  remote|      3|       1|   7|       5|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOyb9...|chat.completion|1709409530|gpt-3.5-turbo-0125|      3|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|62be243c0db32d5b|  remote|      4|       1|  13|       3|   68821.2| 87142.984|     YEARLY|                    1|Overview: \\n  \\n ...|grow financial fe...|        data analyst|https://www.indee...| Performs advance...|chatcmpl-8yPnOOfs...|chat.completion|1709409530|gpt-3.5-turbo-0125|      4|                703|                      9|               712|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|def7c0970b48a38e|  remote|      5|       1|  11|      12|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOlbr...|chat.completion|1709409530|gpt-3.5-turbo-0125|      5|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|42f17753069fac80|  remote|      6|       1|   5|      14|   85000.0|  115000.0|     YEARLY|                    0|POSITION(S) I AM ...|          clark hill| data mining analyst|https://www.indee...| Clark Hill PLC i...|chatcmpl-8yPnOx6F...|chat.completion|1709409530|gpt-3.5-turbo-0125|      6|                512|                     13|               525|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|1a3f5dbeede1ac06|  remote|      7|       1|  11|       9|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOsSU...|chat.completion|1709409530|gpt-3.5-turbo-0125|      7|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|7039cf33dfe411f5|  remote|      8|       1|   5|       9|  91802.04|  140557.3|     YEARLY|                    0|Qualifications, S...|  vagus technologies|data analytics ma...|https://www.indee...|Qualifications, S...|chatcmpl-8yPnOj0c...|chat.completion|1709409530|gpt-3.5-turbo-0125|      8|                445|                     20|               465|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|1aa626e9262dabac|  remote|      9|       1|  13|       5|  69160.06|  87572.05|     YEARLY|                    1|Welcome to a team...|                hcsc|sr data analyst i...|https://www.indee...| 5-7 years of exp...|chatcmpl-8yPnO45u...|chat.completion|1709409530|gpt-3.5-turbo-0125|      9|                520|                     19|               539|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|34953636abf90c96|  remote|     10|       1|  11|      14|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOiLz...|chat.completion|1709409530|gpt-3.5-turbo-0125|     10|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|cec71eef2508e02c|  remote|     11|       1|  11|      11|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOVAV...|chat.completion|1709409530|gpt-3.5-turbo-0125|     11|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|94fff78eb0d787f1|  remote|     12|       1|   7|       2|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnOpaT...|chat.completion|1709409530|gpt-3.5-turbo-0125|     12|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|38a67ee8ff2879b9|  remote|     13|       1|   7|       7|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnPrSy...|chat.completion|1709409531|gpt-3.5-turbo-0125|     13|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|d83b8dddb68e93e7|  remote|     14|       1|   5|      13|  156000.0|  166400.0|     YEARLY|                    0|Overview:  \\n Tek...|      tekwissengroup|bioinformatics da...|https://www.indee...| Proven experienc...|chatcmpl-8yPnODYS...|chat.completion|1709409530|gpt-3.5-turbo-0125|     14|                452|                     30|               482|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|a0172147a15fcd08|  remote|     15|       1|  13|       1|  117900.0|  144000.0|     YEARLY|                    0|Who are we \\n  Ka...|     imperative care|     sr data analyst|https://www.indee...|  The opportunity...|chatcmpl-8yPnO3Qq...|chat.completion|1709409530|gpt-3.5-turbo-0125|     15|               1056|                     40|              1096|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|6b263edec2f76813|  remote|     16|       1|   5|       6| 119492.68| 151304.36|     YEARLY|                    1|With a focus on M...|              nissan|  sr. data scientist|https://www.indee...| Build and mainta...|chatcmpl-8yPnOiZq...|chat.completion|1709409530|gpt-3.5-turbo-0125|     16|                629|                     50|               679|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|a74590948ca152f3|  remote|     17|       1|   7|       4|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnPRve...|chat.completion|1709409531|gpt-3.5-turbo-0125|     17|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|5699d9f379d436b3|  remote|     18|       1|   7|       8|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnTcEW...|chat.completion|1709409535|gpt-3.5-turbo-0125|     18|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|cadcb00b7314b768|  remote|     19|       1|  11|       7|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnWmtB...|chat.completion|1709409538|gpt-3.5-turbo-0125|     19|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n|f3086c8c198cb970|  remote|     20|       1|   7|       0|      null|      null|       null|                    0|Accenture is a le...|           accenture|analytics senior ...|https://www.indee...| Here's what you'...|chatcmpl-8yPnaOKt...|chat.completion|1709409542|gpt-3.5-turbo-0125|     20|                511|                     22|               533|     fp_2b778c6b35|s3://gpt-bucket-i...|\n+----------------+--------+-------+--------+----+--------+----------+----------+-----------+---------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------+----------+------------------+-------+-------------------+-----------------------+------------------+------------------+--------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "unnested.select('root_keyword').toDF().show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+-----+--------------+\n| id|index|   keyword.val|\n+---+-----+--------------+\n|  1|    0|  data analyst|\n|  1|    1|data scientist|\n|  2|    0|  data analyst|\n|  3|    0|  data analyst|\n|  4|    0|  data analyst|\n|  5|    0|  data analyst|\n|  6|    0|data scientist|\n|  6|    1|  data analyst|\n|  7|    0|  data analyst|\n|  8|    0|data scientist|\n|  9|    0|  data analyst|\n|  9|    1|data scientist|\n| 10|    0|  data analyst|\n| 11|    0|  data analyst|\n| 12|    0|  data analyst|\n| 13|    0|  data analyst|\n| 14|    0| data engineer|\n| 15|    0|  data analyst|\n| 16|    0|data scientist|\n| 17|    0|  data analyst|\n+---+-----+--------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "unnested.select('root_choices.val.message.content').toDF().show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+-----+-------------------------------+\n| id|index|choices.val.message.content.val|\n+---+-----+-------------------------------+\n|  1|    0|             microsoft power bi|\n|  1|    1|             nextgen ehr system|\n|  2|    0|                            sql|\n|  2|    1|                       power bi|\n|  2|    2|                           domo|\n|  2|    3|                        tableau|\n|  2|    4|                         python|\n|  2|    5|                              r|\n|  3|    0|               google analytics|\n|  3|    1|             google tag manager|\n|  3|    2|                          excel|\n|  3|    3|                  google sheets|\n|  3|    4|             google data studio|\n|  3|    5|             sisense data cloud|\n|  4|    0|                              R|\n|  4|    1|                            SQL|\n|  4|    2|                         Python|\n|  4|    3|                        Tableau|\n|  5|    0|               google analytics|\n|  5|    1|             google tag manager|\n+---+-----+-------------------------------+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "## Join Create DFs from DYFcollection",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "dyf_root = unnested.select('root')\ndyf_root_keyword_full = unnested.select('root_keyword')\ndyf_root_content = unnested.select('root_choices.val.message.content')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Rename the content to techs\ndyf_root_tech = dyf_root_content.rename_field(\n    oldName=\"`choices.val.message.content.val`\", # Requires `` around the name as it contains .'s\n    newName='tech')\n# dyf_root_tech.toDF().show(5)\n\n# Rename the keywords to remove the period\ndyf_root_keyword = dyf_root_keyword_full.rename_field(\n    oldName='`keyword.val`',\n    newName='keyword_val')\n# dyf_root_keyword.toDF().show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 13,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Convert dyfs to dfs as we have a fixed schema with small memory usage so there aren't huge advantages to dyfs.\ndf_root = dyf_root.toDF()\ndf_root_keyword = dyf_root_keyword.toDF()\ndf_root_tech = dyf_root_tech.toDF()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 14,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_root.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- job_key: string (nullable = true)\n |-- location: string (nullable = true)\n |-- keyword: long (nullable = true)\n |-- from_age: integer (nullable = true)\n |-- page: integer (nullable = true)\n |-- position: integer (nullable = true)\n |-- salary_min: double (nullable = true)\n |-- salary_max: double (nullable = true)\n |-- salary_type: string (nullable = true)\n |-- salary_estimated_flag: integer (nullable = true)\n |-- job_description: string (nullable = true)\n |-- company: string (nullable = true)\n |-- job_title: string (nullable = true)\n |-- url: string (nullable = true)\n |-- split_jd: string (nullable = true)\n |-- id: string (nullable = true)\n |-- object: string (nullable = true)\n |-- created: integer (nullable = true)\n |-- model: string (nullable = true)\n |-- choices: long (nullable = true)\n |-- usage.prompt_tokens: integer (nullable = true)\n |-- usage.completion_tokens: integer (nullable = true)\n |-- usage.total_tokens: integer (nullable = true)\n |-- system_fingerprint: string (nullable = true)\n |-- filename: string (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_root_selected = df_root.select('job_key', 'keyword', 'choices', 'filename')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_root_selected.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------------+-------+-------+--------------------+\n|         job_key|keyword|choices|            filename|\n+----------------+-------+-------+--------------------+\n|c40ac9eaa1278fdc|      1|      1|s3://gpt-bucket-i...|\n|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|\n|c7c487473ba0a838|      3|      3|s3://gpt-bucket-i...|\n|62be243c0db32d5b|      4|      4|s3://gpt-bucket-i...|\n|def7c0970b48a38e|      5|      5|s3://gpt-bucket-i...|\n+----------------+-------+-------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_root_keyword.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+-----+--------------+\n| id|index|   keyword_val|\n+---+-----+--------------+\n|  1|    0|  data analyst|\n|  1|    1|data scientist|\n|  2|    0|  data analyst|\n|  3|    0|  data analyst|\n|  4|    0|  data analyst|\n+---+-----+--------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_root_keyword = df_root_selected.join(df_root_keyword, df_root['keyword'] == df_root_keyword['id'])",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_root_keyword = join_root_keyword \\\n                    .withColumnRenamed('index', 'keyword_index')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_root_keyword.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------------+-------+-------+--------------------+---+-------------+--------------+\n|         job_key|keyword|choices|            filename| id|keyword_index|   keyword_val|\n+----------------+-------+-------+--------------------+---+-------------+--------------+\n|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|  2|            0|  data analyst|\n|62be243c0db32d5b|      4|      4|s3://gpt-bucket-i...|  4|            0|  data analyst|\n|def7c0970b48a38e|      5|      5|s3://gpt-bucket-i...|  5|            0|  data analyst|\n|7039cf33dfe411f5|      8|      8|s3://gpt-bucket-i...|  8|            0|data scientist|\n|94fff78eb0d787f1|     12|     12|s3://gpt-bucket-i...| 12|            0|  data analyst|\n+----------------+-------+-------+--------------------+---+-------------+--------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_rk_techs = join_root_keyword.join(df_root_tech, on='id')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_rk_techs = join_rk_techs \\\n                    .withColumnRenamed('index', 'tech_index')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_rk_techs.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+----------------+-------+-------+--------------------+-------------+------------+----------+--------+\n| id|         job_key|keyword|choices|            filename|keyword_index| keyword_val|tech_index|    tech|\n+---+----------------+-------+-------+--------------------+-------------+------------+----------+--------+\n|  2|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|            0|data analyst|         5|       r|\n|  2|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|            0|data analyst|         4|  python|\n|  2|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|            0|data analyst|         3| tableau|\n|  2|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|            0|data analyst|         2|    domo|\n|  2|9da2149f4c0c676f|      2|      2|s3://gpt-bucket-i...|            0|data analyst|         1|power bi|\n+---+----------------+-------+-------+--------------------+-------------+------------+----------+--------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "cols_to_drop = ['keyword', 'choices']",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_dropped = join_rk_techs.drop(*cols_to_drop)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 26,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "join_dropped.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+----------------+--------------------+-------------+------------+----------+--------+\n| id|         job_key|            filename|keyword_index| keyword_val|tech_index|    tech|\n+---+----------------+--------------------+-------------+------------+----------+--------+\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         5|       r|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         4|  python|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         3| tableau|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         2|    domo|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         1|power bi|\n+---+----------------+--------------------+-------------+------------+----------+--------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# join_dropped.filter(join_dropped['job_key'] == '861f79f33ee60940').show(25)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "#### Get the day/month/year from filename, change datatype of date column",
			"metadata": {}
		},
		{
			"cell_type": "code",
			"source": "df = join_dropped.withColumn(\"date\", to_date(regexp_extract(join_dropped[\"filename\"], r\"\\d{2}_\\d{2}_\\d{4}\", 0), \"dd_MM_yyyy\"))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 52,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 53,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+----------------+--------------------+-------------+------------+----------+--------+----------+\n| id|         job_key|            filename|keyword_index| keyword_val|tech_index|    tech|      date|\n+---+----------------+--------------------+-------------+------------+----------+--------+----------+\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         5|       r|2024-03-02|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         4|  python|2024-03-02|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         3| tableau|2024-03-02|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         2|    domo|2024-03-02|\n|  2|9da2149f4c0c676f|s3://gpt-bucket-i...|            0|data analyst|         1|power bi|2024-03-02|\n+---+----------------+--------------------+-------------+------------+----------+--------+----------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Wasn't saving as a date type when in non- yyyy-MM-dd format.  Can look in to later, doesn't matter for now.\n# df = df.withColumn(\"date\", date_format(\"date\", \"dd-MM-yyyy\"))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 49,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# df = join_dropped.withColumn(\"day\", regexp_extract(join_dropped[\"filename\"], r\"\\d{2}(?=_\\d{2}_\\d{4})\", 0))\n# df = df.withColumn(\"month\", regexp_extract(df[\"filename\"], r\"(?<=_\\d{2}_)\\d{2}(?=_\\d{4})\", 0))\n# df = df.withColumn(\"year\", regexp_extract(df[\"filename\"], r\"\\d{4}(?=.json$)\", 0))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 105,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# df = df.withColumn(\"date\", concat_ws(\"-\", df[\"day\"], df[\"month\"], df[\"year\"]))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "final_df = df.drop('id', 'filename', 'keyword_index', 'tech_index')\nfinal_df.show(5)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 55,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------------+------------+--------+----------+\n|         job_key| keyword_val|    tech|      date|\n+----------------+------------+--------+----------+\n|9da2149f4c0c676f|data analyst|       r|2024-03-02|\n|9da2149f4c0c676f|data analyst|  python|2024-03-02|\n|9da2149f4c0c676f|data analyst| tableau|2024-03-02|\n|9da2149f4c0c676f|data analyst|    domo|2024-03-02|\n|9da2149f4c0c676f|data analyst|power bi|2024-03-02|\n+----------------+------------+--------+----------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "final_df.printSchema()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 56,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n |-- job_key: string (nullable = true)\n |-- keyword_val: string (nullable = true)\n |-- tech: string (nullable = true)\n |-- date: date (nullable = true)\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "### Can see above that join_rk_techs is properly formatted. The job key had 12 techs associated and 2 keyword vals, so 24 lines in total with the techs repeating for each keyword val.\nSo in:\ndf_root 'keyword' is the 'id' in df_root_keyword\ndf_root 'choices' is the 'id' in df_root_tech",
			"metadata": {
				"tags": []
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Write the data in the DynamicFrame to a location in Amazon S3 and a table for it in the AWS Glue Data Catalog\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "s3output = glueContext.getSink(\n  path=\"s3://glue-bucket-indeed/processed\",\n  connection_type=\"s3\",\n  updateBehavior=\"UPDATE_IN_DATABASE\",\n  partitionKeys=[\"date\"],\n  compression=\"snappy\",\n  enableUpdateCatalog=True,\n  transformation_ctx=\"s3output\",\n)\ns3output.setCatalogInfo(\n  catalogDatabase=\"gpt-bucket-database\", catalogTableName=\"results\"\n)\ns3output.setFormat(\"glueparquet\")\ns3output.writeFrame(DyF)",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		}
	]
}