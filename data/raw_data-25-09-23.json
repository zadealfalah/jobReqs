{"ea05a900e4b427b7": {"terms": ["data science"], "salary_min": 59520.652, "salary_max": 75366.41, "title": "Entry Level Data Scientist (Part-Time)", "company": "CORMAC", "desc": "HUB Zone residence is a requirement for this job. Please check if you qualify for this position at the link below.  HUBZone Map (sba.gov) to confirm residence and indicate this in your application. \n Must be a US citizen or hold permanent residency (green card) \n This is a remote based, part time, about 10 hours per week position, which allows for relatively flexible hours, but at least half of the work will be completed during business hours when some of the communications that are related to the work may need to occur. \n Essential Duties & Responsibilities \n Daily duties will vary according to project needs, with job responsibilities to include: \n \n Using Hadoop and/or SAS and related tools to manage the analysis of billions of data records. \n Leverage expertise in machine learning, data mining, statistical, and graph based algorithms in data analysis, solution development, analytic workflowprocesses, and complex data visualizations. \n Writing software to clean and investigate large amounts of numerical and textual data sets. \n Designing rich data visualizations to communicate complex ideas to customers or company leaders \n Investigating the impact of new technologies on the future of health informatics of tomorrow \n \n Preferred Skills & Experience \n \n Actively pursuing or graduated with an Associate's, Bachelor\u2019s or Master\u2019s degree in data science, computer science, machine learning or statistics  \n Experience using statistical tools. \n Experience with relational databases, SQL and distributed systems such as Hadoop \n Experience in applied statistics and exploratory analysis of large-scale datasets \n Experience in one or more of the following tools and languages is a plus. R, Java, C++, Python, SAS or other statistical tools. \n Exposure to Health care systems is a plus \n Ability to communicate effectively both orally and written \n \n \n CORMAC is an Equal Opportunity Employer \n Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, marital status, disability, veteran status, sexual orientation, or genetic information."}, "54d0f3ce0f5f3213": {"terms": ["data science", "data analyst"], "salary_min": null, "salary_max": null, "title": "Carenostics : Healthcare Data Analyst", "company": "M13", "desc": "At Carenostics, we're at the forefront of healthcare AI, forging a path to address chronic diseases with transformative solutions. Our work, starting in Chronic Kidney Disease at Hackensack Meridian Health (HMH), has garnered prestigious accolades like the Bio-IT World Innovative Practices Award, placing us in the league of industry giants. We have since rapidly deployed AI solutions for new health systems and diseases like asthma and heart disease.\n   \n \n \n  Our journey, underscored by a robust 2023, boasts of a recently oversubscribed Seed round, impactful partnerships, notably with AstraZeneca, and numerous accolades such as the Digital Health Hub Award. 2022 echoed this success, marking us as Bayer Pharmaceuticals' sole early-stage investment and winners of the coveted NSF SBIR & I-Corps Grants. As we gear up for an accelerated growth phase, we're excited about the immense potential that lies ahead.\n   \n \n \n  At the helm is our CEO, a trailblazer whose leadership has seen the successful launch of 20+ healthcare AI solutions, generating a staggering $5B in revenue and transforming the lives of millions globally. This unparalleled success is amplified by a world-class team with pedigrees from McKinsey, Siemens HealthCare, Amazon, and more. As we stand on the brink of rapid expansion, we invite you to be a part of this exhilarating journey, where each step forward is a leap toward reshaping the healthcare narrative.\n   \n \n \n  The Role:\n   \n \n    Carenostics is seeking an experienced (5+ years) data analyst with a passion for transforming healthcare to join our team (currently 10+ employees) as a Healthcare Data Analyst. This role will work directly with clinicians to develop and validate solutions that will help identify undiagnosed and undertreated patients, especially from traditionally vulnerable populations. The role will include analyzing underlying trends in patient diagnosis treatment and identifying and validating algorithms to help identify and target these individuals to receive the care they need.\n   \n \n    The ideal candidate will possess the ability to digest complex databases, have data analytic skill sets, and exhibit an adept ability for analyzing healthcare data from EMR and claims data. They will collaborate with internal stakeholders and external clinicians in providing quality, analytics, and business support for both internal stakeholders and our external clients.\n   \n \n \n \n \n \n  What you\u2019ll be doing  \n \n \n Researching and developing analytical approaches for identifying, analyzing, and interpreting trends or patterns in healthcare data. \n  Query, structure, and validating data using SQL \n  Assessing business needs, compiling necessary data, and developing dashboards/reports to provide strategic insights for stakeholders, both internal and external. \n  Extracting data directly from relational databases, data warehouses, or other data sources using SQL to solve business problems. \n  Identifying process improvement opportunities, developing and implementing optimized solutions, and educating stakeholders on new processes. \n  Communicating with clinical collaborators on analysis needs and presenting results. \n \n \n \n \n \n \n What you\u2019ll bring to Carenostics  \n \n \n BA / BS in Analytics, Statistics, Mathematics, or a related field. \n  5+ years of data analysis experience in healthcare data, including EMR and claims data \n  Strong SQL coding and database experience \n  Excellent critical thinking and problem-solving skills \n  Experience in analyzing and drawing valuable conclusions from data profiling results \n  A high level of organizational and time-management skills \n  Excellent analytical, verbal, and communication skills \n  Advanced proficiency with MS Excel \n  Experience working on real-world problems and passion for having a social impact \n \n \n  Additional desirable qualifications include: \n \n  Experience developing analytics dashboards (e.g., Looker, Tableau, Qlik, etc.) \n  Experience with managing & developing on cloud platforms (AWS, Azure, GCP) \n  Experience with healthcare data (e.g., EHR, claims, HL7) \n \n \n \n \n \n \n \n \n  Why you\u2019ll love working at Carenostics:  \n \n \n You'll earn a competitive salary, benefits, and options at a startup poised for hyper-growth \n  Be a key player in our mission-driven company that is tackling one of society\u2019s greatest challenges \n  You\u2019ll have access to and work with rich healthcare data from leading institutions for developing solutions with immediate real-world impact on tens of millions of patients \n  You\u2019ll work alongside a powerhouse team and be mentored by proven leaders in healthcare, databases, machine learning, and software engineering \n  You\u2019ll have opportunities to publish cutting-edge research on novel applications of AI to healthcare in leading journals and conferences (recent paper accepted in NeurIPS this year) \n  You can work remotely \n  As an early hire, you will have opportunities for rapid upward mobility and be empowered to lead as we scale the data team as Carenostics grows \n  You will work directly with clinicians on the interface/workflow and engage with leadership in conversations beyond data science (e.g., commercialization, growth strategy, leading new client deployments) \n \n \n \n \n \n \n \n \n    Learn more about us, our partnerships, and our journey this past year here here.\n   \n \n \n  If you want to be part of our mission to transform healthcare into a data-driven paradigm where decisions to improve lives are driven by insights learned from millions of EHRs and claims, please apply today!\n   \n \n    Research shows that while men apply to jobs when they meet an average of 60% of the criteria, women and other marginalized folks tend only to apply to jobs when they check every box. So if you have what it takes but don't necessarily meet every single point on the job description, please still get in touch. We'd love to chat and learn more about what you want to do next in your career.\n   \n \n \n  Carenostics provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws."}, "27ae7ba437caf3b1": {"terms": ["data science"], "salary_min": 106841.52, "salary_max": 135285.17, "title": "Analytics Engineer (L5) - Games", "company": "Netflix", "desc": "Remote, United States\n      \n \n \n \n \n \n \n         Data Science and Engineering\n        \n \n \n \n \n \n \n \n     Senior Analytics Engineer, Games\n    \n \n \n  Now is an amazing time to join Netflix as we seek to entertain the world. We have over 200 million paid members in over 190 countries, and we won\u2019t stop there. Games are our next big frontier and an incredible opportunity for us to deliver new experiences to delight and entertain our quickly growing membership. You will be jumping in at the early stages of this adventure and be in a position to help us redefine what a Netflix subscription means for our members around the world.\n    \n \n \n  Data Science and Engineering (\u2018DSE\u2019) at Netflix is aimed at using data, analytics, and sciences to improve various aspects of our business. We are looking for a Senior Analytics Engineer to join our Games DSE team, leading end-to-end analytics & data needs for the Games space. This role will be partnering closely with our Game stakeholders to define key metrics, build and maintain key dashboards and analytic tools and scale data access across our stakeholder set. As an early member of the team, you will also help shape our overall Games Data Strategy at Netflix.\n    \n \n \n  What You Will Do: \n \n  Partner directly with our Game stakeholders (e.g., Netflix Games Studio, Games Product, Game Strategy, Planning & Analysis team) on data, metrics & analytics initiatives \n  Lead end-to-end development of reports/dashboards/tools used by your direct stakeholders and a diverse set of teams across the company \n  Proactively perform data exploration and analytical deep dives to discover insights or future testing opportunities \n  Be a bridge between the business and tech, scaling access to insights that can empower better decision-making \n  Maintain and rethink existing data solutions to service a wider variety of use cases \n  Balance handling ad hoc requests while also driving larger projects forward \n \n \n \n  Who You Are: \n \n  You are an engineering-minded analyst with a strong bias towards action, delivering results quickly with iteration instead of waiting for perfection \n  You are comfortable taking vague requirements and crystallizing them into valuable tools, metrics, or analysis. \n  You have strong technical skills in manipulating large data sets with complex SQL and Python (or similar languages), big data technologies (e.g., Hadoop, Spark) and visualization tools (e.g., Tableau) \n  You are a self-starter that can work effectively in a fast-paced, ambiguous environment with changing priorities and minimally defined processes. \n  You are experienced in managing stakeholder asks, expectations, and relationships across a variety of stakeholders \n  Experience in Games industry a plus \n \n \n \n     At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location. The overall market range for this role is typically $150,000 - $750,000. This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.\n     \n \n \n \n \n We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service."}, "f2afc97954585a2b": {"terms": ["data science"], "salary_min": 29700.0, "salary_max": 70150.0, "title": "Data Scientist I", "company": "Gannett", "desc": "Gannett Co., Inc. (NYSE:  GCI) is a subscription-led and digitally-focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer Prize-winning content, consumer experiences and benefits, and advertiser products and services. \n \n  Our current portfolio of media assets includes The USA TODAY NETWORK, which includes USA TODAY, and local media organizations in 43 states in the United States, and Newsquest, a wholly-owned subsidiary operating in the United Kingdom. We also own digital marketing services companies under the brand LocaliQ, which provide a cloud-based platform of products to enable small and medium-sized businesses to accomplish their marketing goals. In addition, our portfolio includes one of the largest media-owned events businesses in the U.S., USA TODAY NETWORK Ventures. \n \n  Gannett open roles are featured on various external job boards. When applying to a position at Gannett, you should be completing an application on Gannett Careers via Dayforce. Job postings directing you to complete an application on other external sites may not be valid. \n \n  To connect with us, visit www.gannett.com \n \n  The new Data Scientist I in LOCALiQ\u2019s Automotive Division will join a dynamic team supporting a driven sales organization with information critical to the success of our dealer clients. We use data to uncover threats and opportunities to help grow their businesses in a competitive industry. Your work will help build one of the pillars of our go-to-market strategy, creating even more advanced and valuable tools and reporting. \n Responsibilities \n \n \n The job primarily includes these tasks: \n \n \n Querying data \n Updating performance reports and creating new ones \n Providing ad hoc analysis as needed \n Building new analytical and selling tools \n Partnering with colleagues across the country \n  Skills \n \n \n The right candidate has experience in the following: \n \n \n Data Mining \n Data Analysis \n Data Visualization \n  Knowledge of database architecture and administration is also helpful \n Fit \n \n \n The person we want is: \n \n \n Comfortable working remotely \n Detail and task-oriented \n Creative in finding solutions \n Able to manage changing priorities \n Clear and concise in communicating \n Professional and hard-working \n  Knowledge of the auto industry and small to medium business environment would help as well \n Education \n A bachelor\u2019s degree in one of the following (or a similar discipline) is required: \n \n \n Data Science \n Computer Science \n Management Information Systems \n Statistics \n Finance \n  Software \n \n \n Proficiency in the following is also needed: \n \n \n Excel \n SQL \n Tableau (preferred) \n Python (preferred) \n Looker Studio (preferred) \n  The annualized base salary for this role will range between $29,700 and $70,150. Base compensation is reflective of many factors, including, but not limited to, the market in which one lives/works, individual education level, skills, certifications, and experience. Note: variable compensation is not reflected in these figures and based on the role, may be applicable. \n \n  #LI-JM1 \n Gan.Sales \n #Sales \n #LocalIQ \n \n  Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee\u2019s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant\u2019s disability or religion, to complete this employment application and/or any other process in connection with an individuals\u2019 application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.\u2019s Recruitment Department at Recruit@gannett.com."}, "40837790ddbf0f1e": {"terms": ["data science"], "salary_min": 29700.0, "salary_max": 70150.0, "title": "Data Scientist I", "company": "LocalIQ", "desc": "Gannett Co., Inc. (NYSE:  GCI) is a subscription-led and digitally-focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer Prize-winning content, consumer experiences and benefits, and advertiser products and services. \n \n  Our current portfolio of media assets includes The USA TODAY NETWORK, which includes USA TODAY, and local media organizations in 43 states in the United States, and Newsquest, a wholly-owned subsidiary operating in the United Kingdom. We also own digital marketing services companies under the brand LocaliQ, which provide a cloud-based platform of products to enable small and medium-sized businesses to accomplish their marketing goals. In addition, our portfolio includes one of the largest media-owned events businesses in the U.S., USA TODAY NETWORK Ventures. \n \n  Gannett open roles are featured on various external job boards. When applying to a position at Gannett, you should be completing an application on Gannett Careers via Dayforce. Job postings directing you to complete an application on other external sites may not be valid. \n \n  To connect with us, visit www.gannett.com \n \n  The new Data Scientist I in LOCALiQ\u2019s Automotive Division will join a dynamic team supporting a driven sales organization with information critical to the success of our dealer clients. We use data to uncover threats and opportunities to help grow their businesses in a competitive industry. Your work will help build one of the pillars of our go-to-market strategy, creating even more advanced and valuable tools and reporting. \n Responsibilities \n \n \n The job primarily includes these tasks: \n \n \n Querying data \n Updating performance reports and creating new ones \n Providing ad hoc analysis as needed \n Building new analytical and selling tools \n Partnering with colleagues across the country \n  Skills \n \n \n The right candidate has experience in the following: \n \n \n Data Mining \n Data Analysis \n Data Visualization \n  Knowledge of database architecture and administration is also helpful \n Fit \n \n \n The person we want is: \n \n \n Comfortable working remotely \n Detail and task-oriented \n Creative in finding solutions \n Able to manage changing priorities \n Clear and concise in communicating \n Professional and hard-working \n  Knowledge of the auto industry and small to medium business environment would help as well \n Education \n A bachelor\u2019s degree in one of the following (or a similar discipline) is required: \n \n \n Data Science \n Computer Science \n Management Information Systems \n Statistics \n Finance \n  Software \n \n \n Proficiency in the following is also needed: \n \n \n Excel \n SQL \n Tableau (preferred) \n Python (preferred) \n Looker Studio (preferred) \n  The annualized base salary for this role will range between $29,700 and $70,150. Base compensation is reflective of many factors, including, but not limited to, the market in which one lives/works, individual education level, skills, certifications, and experience. Note: variable compensation is not reflected in these figures and based on the role, may be applicable. \n \n  #LI-JM1 \n Gan.Sales \n #Sales \n #LocalIQ \n \n  Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee\u2019s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant\u2019s disability or religion, to complete this employment application and/or any other process in connection with an individuals\u2019 application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.\u2019s Recruitment Department at Recruit@gannett.com."}, "bdb59498d36bfb92": {"terms": ["data science", "machine learning engineer"], "salary_min": 107414.56, "salary_max": 136010.77, "title": "Data Scientist", "company": "Protection Engineering Consultants", "desc": "Job Description \n  Protection Engineering Consultants (PEC) is a unique and diverse small-business engineering firm. PEC\u2019s services range from security consulting and risk mitigation support to the design, research, analysis and testing of protective structures subject to extreme loads, such as weapons effects, blast, vehicle impact, forced entry attack and natural hazards. We provide structural and mechanical engineering services; use machine learning (ML) and uncertainty quantification (UQ) techniques to deliver novel solutions to engineering problems; create specialized software for defense and anti-terrorism applications; perform advanced numerical modeling; develop, oversee and perform nonlinear and dynamic testing; develop criteria for protective applications; and, provide training. We work domestically and internationally. \n  PEC is looking for a creative computer scientist or coding-capable engineer to support the development of novel ML algorithms that address the unique engineering challenges of our military and civilian clients. Preferred areas of expertise include data engineering, machine learning, data visualization, and computer vision. Other areas of value include deep learning, experience with PyTorch, and knowledge of version control systems (e.g., git, etc.). Project work can be highly varied; the position demands flexibility, cleverness, and autodidactic learning. The successful candidate will be proficient with Python and be able to develop novel solutions from prototyping through software integration. \n  Your role initially will be to provide support for our ongoing efforts. We will provide opportunities for you to grow into project management, marketing, and business development, as your interests dictate; you can also stay in a technical role if that is your preferred career path. \n  This position offers both in-office and remote work options. Office locations include San Antonio and Austin, Texas. Remote work options are available within the contiguous United States. \n  Qualifications \n \n  BS or MS in Computer Science, Data Science, Physics, Engineering, or a similar field. \n  Professional experience not required, but 3-5 years of experience considered a plus. \n  Proficiency in Python and version control systems. \n  Ability to clearly communicate verbal and written technical information. \n  This position requires the ability to obtain a U.S. security clearance for which the U.S. Government requires U.S. citizenship. \n \n  Benefits \n  PEC offers a competitive compensation package for the successful candidate. Benefits include: \n \n  Competitive salary. \n  Flexible work schedule. \n  Relocation expenses. \n  Annual performance bonuses. \n  Opportunity for company ownership. \n  Professional development and training support. \n  Health, Dental, and Vision Insurance paid in full. \n  401(k) match plan. \n \n  Protection Engineering Consultants LLC (PEC) provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, PEC complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfers, leaves of absence, compensation and training. \n  Please send all applications and inquiries to careers@protection-consultants.com"}, "2aa6a819da0e9d3b": {"terms": ["data science"], "salary_min": 106835.34, "salary_max": 135277.34, "title": "Senior Data Scientist", "company": "Bamboo Insurance", "desc": "Job Summary: \n We are seeking a Senior Data Scientist to join our Product Team at high-growth personal homeowners insurance company. As a Senior Data Scientist, you will be responsible for leveraging your expertise in building models (e.g. Underwriting Models, Pricing Models, Conversion Models, Retention Models) to extract valuable insights from large datasets. Your work will be key for driving data-informed decisions across the corporation. \n Duties/Responsibilities: \n \n Collaborate with the actuarial team to identify data requirements and design analytical frameworks for assessing risk, pricing, and profitability of personal homeowners insurance policies. \n Develop and maintain predictive models to improve underwriting, claim prediction, and policy retention, for example \n Manage modeling projects through all phases, including data preparation, modeling, data visualization, presentation of results, and implementation \n Create and maintain data visualization tools and dashboards to present analytical findings to stakeholders in a clear and actionable manner. \n \n Required Skills/Abilities: \n \n Expertise in programming languages such as Python, R, or SAS. \n Deep understanding of advanced statistical and machine learning techniques. \n Strong communication skills, with the ability to explain technical concepts and analytical findings to both technical and non-technical stakeholders. \n Ability to independently oversee the entire data science project lifecycle, from problem definition to deployment. \n \n Required Education and Experience: \n \n Bachelor\u2019s degree in Data Science, Statistics, Mathematics, Actuarial Science, or a related field; advanced degree preferred. \n Minimum 3-5+ years\u2019 work experience applying advanced statistical modeling and machine learning techniques to solve complex business problems. \n \n Preferred Requirements: \n \n Experience with data visualization tools (e.g., Tableau, Power BI) to create informative and visually appealing dashboards. \n Insurance industry experience strongly preferred. \n \n Physical Requirements: \n \n Prolonged periods of sitting at a desk and working on a computer. \n \n Bamboo is committed to the principles of equal employment. We are committed to complying with all federal, state, and local laws providing equal employment opportunities, and all other employment laws and regulations. \n Job Type: Full-time \n Benefits: \n \n 401(k) matching \n Dental insurance \n Employee assistance program \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Do you have a bachelor's degree in Data Science, Statistics, Mathematics, Actuarial Science or a related field? \n \n Experience: \n \n applying advanced statistical modeling: 3 years (Required) \n \n Work Location: Remote"}, "8c83c915f3f3ccc5": {"terms": ["data science"], "salary_min": 101413.09, "salary_max": 128411.58, "title": "Data Scientist, Growth", "company": "Descript", "desc": "Our vision is to build the next generation platform to enable easy and fast creation of audio and video content powered by cutting-edge AI. Building a revolutionary way to record, transcribe, edit, and mix spoken audio and video comes with a series of unique challenges and requires solving hard and complex problems. \n  As a founding member on the data team and the owner of the growth space, you will play a critical role in shaping our growth strategy, up-leveling our experimentation culture, and scaling our business. \n  What You'll Do \n \n Conduct in-depth analysis to drive growth strategy, such as product-led growth motion and B2B expansion motion. \n Develop deep understanding of the growth ecosystem and identify opportunities to drive activation, engagement, monetization, and expansion through insightful analysis and actionable recommendations. \n Improve execution rigor of product teams by owning success metrics and opportunity sizing. Help team prioritize the highest lever work and stay on track towards goals. \n Brain buddy with product and engineering teams for day-to-day experiment design, deployment, and analysis. Provide creative solutions for tricky experimentation scenarios. \n Evolve experimentation culture and practices within the company. Foster the culture of experimentation within the company by hosting brownbags, training sessions, office hours, etc. \n \n What You Bring \n \n 4\u20137 years of experience in a Data Scientist or similar role. \n 3+ years working in a growth function. \n Strong product intuition to identify opportunities in the growth ecosystem. \n Strong knowledge of statistical analysis and A/B tests. \n Strong SQL skills and proficient in at least one programming language such as Python or R. \n Excellent communication and collaboration skills. \n Curiosity, savviness to navigate in a dynamic environment, and a growth mindset. \n Having worked at a fast-growing start-up is a plus. \n \n \n About Descript \n  Descript is building a simple, intuitive, fully-powered editing tool for video and audio \u2014 an editing tool built for the age of AI. We are a team of 125 \u2014 with a proven CEO and the backing of some of the world's greatest investors (OpenAI, Andreessen Horowitz, Redpoint Ventures, Spark Capital). \n  Descript is the special company that's in possession of both product market fit and the raw materials (passionate user community, great product, large market) for growth, but is still early enough that each new employee has a measurable influence on the direction of the company. \n  Benefits include a generous healthcare package, catered lunches, and flexible vacation time. We currently have offices in San Francisco and Montreal, and are open to folks working remotely between PT and ET time zones. Whether you love WFH or can't wait to get back to being in person, we're interested in offering an environment that works for you. \n  Descript is an equal opportunity workplace\u2014we are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. We believe in actively building a team rich in diverse backgrounds, experiences, and opinions to better allow our employees, products, and community to thrive."}, "3187de4a9028b871": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 210000.0, "salary_max": 230000.0, "title": "Senior Manager, Data Science", "company": "Veho", "desc": "About Veho \n \n \n \n  Veho is the post-purchase experience company that unlocks the potential of everyday consumers and brands to fully participate in e-commerce. Building an entirely new end-to-end logistics infrastructure, powered by the latest technology and designed for the modern era of shopping, Veho is reinventing shipping, and all parts of the post-purchase experience as we know it. By removing the pain from delivery and returns, Veho is creating powerful opportunities for brands to engage and build deep loyalty with their customers like never before.\n  \n \n \n  About The Role \n \n \n \n  As a Senior Data Science Manager, you\u2019ll be directly embedded in a team of talented data scientist, machine learning engineers, and software engineers to help define, build, and operate sophisticated models to answer hard questions centered around improving our logistics network and user experiences. You\u2019ll partner with product managers to understand high-value business problems, build systems that inform daily operations, and work with cutting-edge technology. You\u2019ll work closely with your team to operationalize the models you build in the production systems that drive Veho.\n  \n Responsibilities Include:  \n \n Understanding business context and gathering requirements \n  Proactively identify the most impactful opportunities to shape product roadmaps via collaboration with major business units \n  Coordinate the team to build reliable, efficient, and scalable models for our AI/ML capabilities \n  Creating robust data pipelines to feed analyses and models \n  Ensuring data quality and data integrity through best practices in data integration \n  Analyze and evaluate the impact and effectiveness of models in production systems \n \n  What You Bring: \n \n  Bachelor\u2019s Degree plus 8 years of experience in data science or data engineering, or Master\u2019s Degree plus 5 years in data science, Or Phd plus 3 years of experience in Data Science \n  3+ years of experience managing a team of data scientist and/or machine learning engineers \n  Experience scoping and leveraging statistical modeling and machine learning techniques to solve business problems \n  Experience leading end to end, real-time machine learning and data science projects. \n  Strong communication skills \n  At least 3 years of experience with open source languages and tooling used for large-scale data analytics like Python, numpy, and/or distributed data processing systems like spark \n  At least 3 years of experience with analytical relational databases like Redshift, BigQuery, or Snowflake \n  At least 3 years of experience working with cloud-based data engineering and data science tools. \n  Experience with MLOps and model deployment pipelines \n  Experience with logistics and or gig economy are nice to have, but not required \n  Experience with combinatorial optimization methods is nice to have but not required \n \n \n   The base salary range for this position is $210,000-$230,000 and will be dependent upon a number of factors, such as education, work experience, skills and location. Additionally, Veho offers a competitive equity package, comprehensive medical, dental and vision coverage as well as other benefits such as 401k and unlimited PTO.\n  \n \n  #LI-Remote \n \n \n \n  Veho is a growth company that looks for team members to grow with it. Veho offers a generous ownership package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Veho employee shares one galvanizing mission: to revolutionize the world of package delivery by creating exceptional experiences for customers and drivers. We are deeply value-driven (Ownership, Candor, Team Success, Human) and care tremendously about investing in people. We are committed to creating a diverse team and an environment that provides everyone with the opportunity to do the work of their lifetime. Veho is unable to provide sponsorship at this time.\n   \n \n \n \n \n  Veho is committed to nurturing, cultivating and preserving a diverse and inclusive work environment. Empathy and respect for each other is core to our values and a central part of working here every day. The diversity of our employees, drivers and applicants is welcomed and encouraged.\n  \n \n \n  By providing your phone number you consent to possibly be texted in relation to the job you are currently applying. You are free to opt-out at any time if texting communication occurs from Veho."}, "546b4fadce5c7fbd": {"terms": ["data science"], "salary_min": 129089.4, "salary_max": 163455.94, "title": "Data Architect", "company": "Juvare - External", "desc": "JUVARE is a technology company focused on developing innovative enterprise resilience solutions for government agencies, corporations, healthcare providers and higher education around the world. JUVARE solutions have supported over 500,000 emergency response incidents in all 50 states and 20 countries around the world. JUVARE helps our clients prepare, connect, and respond to protect people, property, and brands. \n  Thank you for your interest! \n \n  We are looking for a  Data Architect  to organize the way data is used within our products. You will be responsible for designing and building a modern data platform. You will work closely with the business leaders and Software Architects to deliver key element of data analytics platform such as data governance framework and data cleaning protocols. We offer a challenge of organizing a diverse set of data and promise a highly skilled team of individuals that will support you. \n  Reports to : VP of Engineering \n  Main Responsibilities: \n \n Define data managements principles (data governance framework, data cleaning protocols) within the company and support the implementation of them. \n Collaborate with enterprise architect and lead relevant technical teams to acquire, engineer, and govern enterprise data across a wide range of verticals and customers in emergency management domain. \n Support business leaders and our clients in extracting value from their data to move towards evidence-based decision making. \n Design and support the technical implementation of advanced analytics, reporting and AI solution architecture. \n Support the technical team on implementing business intelligence solutions that accommodate a diverse set of data sources. \n Develop plans for implementing an enterprise data catalog to identify data quality and data lineage. \n Act as a client or third-party facing point of contact for data related topics. \n \n Requirements: \n \n Significant experience with data architecture, data warehousing, data catalog and data governance for enterprise class solutions and large organizations. \n Significant experience with developing highly responsive data structures, metadata capture strategies, ontologies, and data dictionaries. \n Experience in designing data architecture as part of a team. \n Experience in working closely with business team to identify BI and analytics opportunities. \n Ability to lead data conversations and develop business concepts. \n Ability to translate business requirements into data requests, reports and dashboards. \n Stay up to date on relevant market changes. \n Knowledge in advanced data analysis techniques. \n Experience working with ETL and data warehouse solutions. \n \n Other Desirable Skills: \n \n Data science and programming: SQL, R, Python or similar. \n Data visualization and reporting: Power BI, Tableau, Qlik or similar. \n Data warehousing: Snowflake, PostgreSQL, SQL Server, AWS Redshift or similar. \n Data integration: Databricks, Talend, SSIS or similar. \n Familiarity with AI/ML modeling and related architectural requirements to build AI/ML based solutions. \n Message brokers. \n Experience with managing sensitive data. \n \n What We Offer: \n \n Unlimited PTO \n Health Insurance \n Dental and Vision Insurance - free for employees \n Employer paid life insurance \n Voluntary Life Insurance options \n 401K with Corporate Match \n Commuter Expense Reimbursement \n Tuition Reimbursement \n Expansive Self-Paced and Virtual Training Options \n Community Volunteer Opportunities \n Monthly Book Club \n \n ADDITIONAL INFORMATION \n \n No visa sponsorship is available for this position. Must be authorized to legally work in the US for this role. \n Must be able to obtain a Public Trust Security Clearance \n CCPA disclosure notice and Juvare privacy policy: https://www.juvare.com/privacy-policy/ \n Juvare is an Equal Opportunity, Affirmative Action employer. \n \n This position requires access to information that is subject to compliance with the Export Administration Regulations (\"EAR\"). In order to comply with the requirements of the EAR, applicants will be asked to provide specific documentation to verify U.S. person status under the EAR. A \"U.S. person\" according to their definition is a U.S. citizen, U.S. lawful permanent resident (green card holder), or protected individual such as a refugee, or asylee. This information will also be used in determining whether an exception to the EAR's licensing requirements can be exercised or a license required for deemed exports."}, "a067f61760c5dd69": {"terms": ["data science", "data analyst"], "salary_min": 77506.0, "salary_max": 87195.0, "title": "Senior Data Analyst - HEDIS", "company": "VIllageCare of New York", "desc": "SQL Senior Data Analyst - HEDIS \n  Remote \n  VillageCare is looking for a self-motivated Senior Data Analyst, with a strong knowledge of  SQL, Excel, Python, Tableau and MLTC  who will support our HEDIS Quality and Data Team. The Senior Data Analyst will provide analytic support to departments across the organization while working with clinical, demographic, financial and survey data to generate analyses, reports, and dashboards. Some responsibilities will include: \n \n \n  Compile, clean, analyze and interpret varied and complex data. \n  Run complex queries to build and maintain customized reports and dashboards for departments using various tools (SQL, MS Excel, Python, R, Tableau, other BI tools). \n  Design and build data visualizations that present data in a clear and concise format, helping customers easily extract insights from the data. \n  Work closely with the VillageCare IT department to automate data flows, facilitating the production of dashboards that automatically update and can be accessed directly by customers. \n  Work closely with all levels of business users to clearly define reporting requirements in support of strategic decision making. Develop a strong understanding of internal customers' business needs, and fosters the use of data and reporting to meet quality objectives. \n  Performs other duties and responsibilities as assigned. \n \n  We would like to speak to those who have a  Bachelor's Degree  or equal work experience ideally in a relevant field, such as Computer Science, Mathematics, Minimum Statistics and/or Engineering.  1-2 years' experience in business intelligence and analytics  performing increasingly complex data analysis and report/dashboard development,  within a healthcare setting, required. HEDIS data analysis experience required. \n  There are many benefits to working for VillageCare. If you are someone who likes being part of a team, enjoys a highly competitive benefits package from world leading carriers and competitive compensation, than we would love to speak with you!  \n \n PTO package \n  10 Paid Holidays \n  Personal and Sick time  \n Medical/Dental/Vision \n  HRA/FSA \n  Education Reimbursement  \n Retirement Savings 403(b) \n  Life & Disability \n  Commuter Benefits \n  Paid Family Leave \n  Additional Employee Discounts \n \n  VillageCare offers a wide range of at-home and community-based services, as well as managed long-term care options that seek to match each individual's needs to help them attain and maintain the greatest level of independent living possible. We are committed to superior outcomes in quality health care."}, "d8524da9f65a35a8": {"terms": ["data science"], "salary_min": 130000.0, "salary_max": 145000.0, "title": "Clinical Data Scientist III, Value Based Care Analytics", "company": "Teladoc Health", "desc": "Teladoc Health is a global, whole person care company made up of a diverse community of people dedicated to transforming the healthcare experience. As an employee, you\u2019re empowered to show up every day as your most authentic self and be a part of something bigger \u2013 thriving both personally and professionally. Together, let\u2019s empower people everywhere to live their healthiest lives.  \n \n Position Summary  \n Bring your analytics mastery and skills to the cutting-edge digital healthcare arena! In your role as Clinical Data Scientist III, you will develop, refine, and apply novel methodologies to understand product performance based on cost and clinical outcomes, and translate that information to support the successful delivery of value-based payment arrangements. You will conduct program evaluations for internal/external audiences, perform deep-dive analytics, and help us scale our analytical frameworks.  \n \n For ultimate success in this role, you\u2019ll demonstrate comfort in both the healthcare and data science realms as you collaborate with our internal teams and external clients. We\u2019re looking for someone with advanced knowledge of causal inference methodologies and experience building robust packages and pipelines at scale, with a perspective on how to deliver meaningful insights to our stakeholders. You\u2019ll be able to synthesize different perspectives and frameworks and turn varying inputs into actionable analytics. As a bonus, we\u2019re looking for someone seasoned in engineering best practices and who can process large data efficiently. Your core competencies include creative problem solving, collaboration, curiosity and the drive to learn new methods, as well as the ability to execute. If this sounds like you, we want to hear from you today!  \n \n \n Responsibilities  \n \n Work collaboratively with members of the Product, Clinical, Data Science and Engineering teams to optimize data ingestion pipelines Analyze medical claims, pharmacy claims, proprietary Teladoc Health data, and other sources to understand which programs work for which clients \u2013 and why  \n Serve as subject matter expert on causal inference and cost savings/ROI analyses that support value-based payment models  \n Create cost and utilization reporting and analytics, including analytics to provide early warning insights  \n Identify Teladoc Health members at risk for poor health outcomes or increased medical spending to drive improvement actions Engage with stakeholders to identify key analytic questions or develop hypothesis related to outcomes drivers  \n Design, perform, and communicate results of analysis projects  \n Provide consultative support for internal team leaders, helping to steer the company toward risk management and continuously improved outcomes  \n \n \n \n \n \n Qualifications  \n \n Tenacious curiosity to understand and share the story behind data  \n 5+ years\u2019 experience as a healthcare analyst or data scientist, with strong quantitative and report development capabilities  \n Data domain expertise in medical and pharmacy claims data, causal inference, and cost and utilization metrics  \n Experience in the healthcare industry working with managed care organizations, pharmaceutical benefit management organizations, government systems, hospital systems and integrated care systems  \n \n \n \n \n \n \n Strong data analysis skills, including using R, SQL, Python and/or other statistical software packages  \n A knack for conveying our data\u2019s stories in reports that spur data-driven decision-making  \n Excellent process, project management and problem-solving skills  \n The ability to manage multiple projects, exercising smart triage and good business judgment  \n Strong respect for confidentiality  \n Excellent verbal and written communication skills  \n The people skills to maintain productive goal-achieving relationships with colleagues and external collaborators (even if numbers are your first love)  \n A Bachelor\u2019s degree in Health Services Research, Epidemiology, Business Analytics, Data Science, or similar  \n \n \n Bonus Points:  \n \n Experience with data engineering/ETL  \n Experience developing and working in collaborative production coding environments to deliver analytic products or models Technical interest and experience with data visualization  \n Advanced degree in Health Services Research, Epidemiology, Business Analytics, or Data Science  \n \n \n The base salary range for this position is $130,000 - 145,000  .  In addition to a base salary, this position is eligible for performance bonus, RSU\u2019s, and benefits (subject to eligibility requirements) listed here: Teladoc Health Benefits 2023 . Total compensation is based on several factors including, but not limited to, type of position, location, education level, work experience, and certifications. This information is applicable for all full-time positions.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Why Join Teladoc Health?   \n   A New Category in Healthcare:  Teladoc Health is transforming the healthcare experience and empowering people everywhere to live healthier lives.      Our Work Truly Matters  : Recognized as the world leader in whole-person virtual care, Teladoc Health uses proprietary health signals and personalized interactions to drive better health outcomes across the full continuum of care, at every stage in a person\u2019s health journey.      Make an Impact:  In more than 175 countries and ranked Best in KLAS for Virtual Care Platforms in 2020, Teladoc Health leverages more than a decade of expertise and data-driven insights to meet the growing virtual care needs of consumers and healthcare professionals.      Focus on PEOPLE:  Teladoc Health has been recognized as a top employer by numerous media and professional organizations. Talented, passionate individuals make the difference, in this fast-moving, collaborative, and inspiring environment.      Diversity and Inclusion:  At Teladoc Health we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.      Growth and Innovation:  We\u2019ve already made healthcare yet remain on the threshold of very big things. Come grow with us and support our mission to make a tangible difference in the lives of our Members.   \n \n As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy.  \n \n Teladoc Health respects your privacy and is committed to maintaining the confidentiality and security of your personal information. In furtherance of your employment relationship with Teladoc Health, we collect personal information responsibly and in accordance with applicable data privacy laws, including but not limited to, the California Consumer Privacy Act (CCPA). Personal information is defined as: Any information or set of information relating to you, including (a) all information that identifies you or could reasonably be used to identify you, and (b) all information that any applicable law treats as personal information. Teladoc Health\u2019s Notice of Privacy Practices for U.S. Employees\u2019 Personal information is available at this link."}, "452f8ccc856d7530": {"terms": ["data science"], "salary_min": 106500.0, "salary_max": 198900.0, "title": "Data Scientist", "company": "Cisco Meraki", "desc": "The modern world runs on the Internet, and the Internet cannot exist without its underlying infrastructure. Meraki makes setting up, managing, and maintaining that infrastructure easier than it has ever been before. Meraki enables connectivity everywhere from neighborhood cafes to world-class universities to global hospitality groups operating thousands of sites. And Meraki's hardware organization is responsible for building the physical devices that get people online. \n  Meraki is looking for a Data Scientist to join Cisco Wireless & Meraki Hardware's Analytics and Data Science Team. As a Data Scientist you will be a key partner in Meraki's analytics ecosystem, responsible for conducting data-driven analyses that drive key decisions. You will work on both brand new and award-winning data sets, and you will help shape how teams leverage this data to achieve their goals. \n  As part of this role, you will develop relationships across teams including supply chain, hardware quality, software engineering, operations, and support. Ideal candidates will have strong communication skills, an analytical mindset, excellent organizational skills, and a bias to action. You don't wait for change - you embody the change you want to see in the world! \n  Meraki believes that the quality of our product is dependent on the quality of our employees. We place a high value on nurturing the growth and development of everyone on our team. We foster an open and supportive workplace where everybody is given the opportunity to succeed. \n  EXAMPLE PROJECTS OF A DATA SCIENTIST: \n \n Engineering teams want assurance that the firmware updates they deploy do not have unintended consequences for device health. Design and build the metrics and visualizations to monitor devices in the field for any issues. \n One of the team's core data pipelines is starting to fail its daily run more often as the size of the source data has grown. Review and optimize the pipeline for improved performance. \n Supply chain teams have noticed that when customers take longer to bring their new Meraki devices online, they tend to slow down their orders in the future (because they have hardware they haven't yet used). Conduct an analysis to test and quantify this hypothesis, and if true build a dashboard to help supply chain managers better predict customer demand. \n \n MINIMUM QUALIFICATIONS: \n \n 3+ years experience with SQL \n 3+ years experience working with core statistical concepts (e.g. correlation, modeling, regression analysis) in Python or R \n 3+ years experience with data visualization tools (e.g. Tableau) \n Ability to take initiative and work autonomously \n Strong analytical and critical thinking skills \n Strong written and oral presentation skills \n \n BONUS POINTS FOR: \n \n Master's degree in Statistics or a related field \n Experience data mining on large datasets \n Experience in the hardware development industry \n \n At Cisco Meraki, we're challenging the status quo with the power of diversity, inclusion, and collaboration. When we connect different perspectives, we can imagine new possibilities, inspire innovation, and release the full potential of our people. We're building an employee experience that includes appreciation, belonging, growth, and purpose for everyone. \n  Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis. Cisco will consider for employment, on a case by case basis, qualified applicants with arrest and conviction records. \n \n  Compensation Range:  \n \n   $106,500\u2014$198,900 USD\n   \n \n \n  Message to applicants applying to work in the U.S.:  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process. \n  U.S. employees have access to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program. \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid."}, "123a58dcff907fbf": {"terms": ["data science"], "salary_min": 29700.0, "salary_max": 70150.0, "title": "Data Scientist I", "company": "Gannett", "desc": "Gannett Co., Inc. (NYSE:  GCI) is a subscription-led and digitally-focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer Prize-winning content, consumer experiences and benefits, and advertiser products and services. \n \n  Our current portfolio of media assets includes The USA TODAY NETWORK, which includes USA TODAY, and local media organizations in 43 states in the United States, and Newsquest, a wholly-owned subsidiary operating in the United Kingdom. We also own digital marketing services companies under the brand LocaliQ, which provide a cloud-based platform of products to enable small and medium-sized businesses to accomplish their marketing goals. In addition, our portfolio includes one of the largest media-owned events businesses in the U.S., USA TODAY NETWORK Ventures. \n \n  Gannett open roles are featured on various external job boards. When applying to a position at Gannett, you should be completing an application on Gannett Careers via Dayforce. Job postings directing you to complete an application on other external sites may not be valid. \n \n  To connect with us, visit www.gannett.com \n \n  The new Data Scientist I in LOCALiQ\u2019s Automotive Division will join a dynamic team supporting a driven sales organization with information critical to the success of our dealer clients. We use data to uncover threats and opportunities to help grow their businesses in a competitive industry. Your work will help build one of the pillars of our go-to-market strategy, creating even more advanced and valuable tools and reporting. \n Responsibilities \n \n \n The job primarily includes these tasks: \n \n \n Querying data \n Updating performance reports and creating new ones \n Providing ad hoc analysis as needed \n Building new analytical and selling tools \n Partnering with colleagues across the country \n  Skills \n \n \n The right candidate has experience in the following: \n \n \n Data Mining \n Data Analysis \n Data Visualization \n  Knowledge of database architecture and administration is also helpful \n Fit \n \n \n The person we want is: \n \n \n Comfortable working remotely \n Detail and task-oriented \n Creative in finding solutions \n Able to manage changing priorities \n Clear and concise in communicating \n Professional and hard-working \n  Knowledge of the auto industry and small to medium business environment would help as well \n Education \n A bachelor\u2019s degree in one of the following (or a similar discipline) is required: \n \n \n Data Science \n Computer Science \n Management Information Systems \n Statistics \n Finance \n  Software \n \n \n Proficiency in the following is also needed: \n \n \n Excel \n SQL \n Tableau (preferred) \n Python (preferred) \n Looker Studio (preferred) \n  The annualized base salary for this role will range between $29,700 and $70,150. Base compensation is reflective of many factors, including, but not limited to, the market in which one lives/works, individual education level, skills, certifications, and experience. Note: variable compensation is not reflected in these figures and based on the role, may be applicable. \n \n  #LI-JM1 \n Gan.Sales \n #Sales \n #LocalIQ \n \n  Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee\u2019s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant\u2019s disability or religion, to complete this employment application and/or any other process in connection with an individuals\u2019 application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.\u2019s Recruitment Department at Recruit@gannett.com."}, "925f756a9ff4e7c7": {"terms": ["data science"], "salary_min": 98000.0, "salary_max": 130000.0, "title": "Data Profiler (Remote)", "company": "Sumitomo Mitsui Banking Corporation", "desc": "Join us on our mission to create a completely new, 100% digital bank that truly serves customers' best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch - and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience). \n \n  The anticipated salary range for this role is between $98,000.00 and $130,000.00. The specific salary offered to an applicant will be based on their individual qualifications, experiences, and an analysis of the current compensation paid in their geography and the market for similar roles at the time of hire. The role may also be eligible for an annual discretionary incentive award. In addition to cash compensation, SMBC offers a competitive portfolio of benefits to its employees. \n \n  We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the second largest bank in Japan and the 12th largest bank in the world with operations in over forty countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products. \n \n  It is the best of both worlds, and we are seeking proven marketing leaders to propel us towards a national launch. We have both the ambitious growth plans and the 'patient capital' necessary to execute a multi-year plan. Join us on the journey to deliver an exciting concept of evolved banking. \n \n \n \n  General Summary: \n \n \n  We are looking for a meticulous and analytical Data Profiler to join our dynamic team. As a Data Profiler, you will play a crucial role in ensuring the accuracy, quality, and integrity of our organization's data. Your keen eye for detail and proficiency in data analysis will be instrumental in driving data-driven decision-making and maintaining data compliance. \n \n \n \n \n  Principal Duties and Responsibilities: \n \n \n  Data Quality Assessment: \n \n  Analyze and evaluate various data sources to identify data quality issues, inconsistencies, and anomalies. \n  Develop data profiling methodologies and frameworks to assess data completeness, validity, and accuracy. \n  Collaborate with the Data Product team to understand data requirements and objectives for profiling activities. \n \n  Data Cleansing and Enrichment: \n \n  Recommend data cleansing and enrichment strategies to address data quality issues. \n  Work closely with Data Engineers to implement data transformations and standardizations. \n  Validate data improvements and monitor ongoing data quality to ensure compliance with standards. \n \n  Data Mapping and Documentation: \n \n  Create data mapping documents and data dictionaries to enhance data understanding and usability. \n  Document data profiling results and insights for communication to relevant stakeholders. \n  Maintain data profiling artifacts and ensure data lineage documentation for future reference. \n \n  Data Compliance and Governance: \n \n  Ensure compliance with data governance policies and regulations in all data profiling activities. \n  Collaborate with Data Stewards to establish data quality rules and guidelines. \n  Contribute to the development and implementation of data quality frameworks and best practices. \n \n  Continuous Improvement: \n \n  Continuously enhance data profiling processes and tools to streamline data assessment. \n  Monitor industry trends and emerging technologies to drive innovation in data profiling practices. \n  Participate in training and knowledge-sharing initiatives to expand expertise in data profiling.   \n \n \n \n \n \n  Position Specifications: \n \n \n \n  Bachelor\u2019s degree in computer science, Data Science, Statistics, or a related field. \n  Proven experience as a Data Profiler or similar role, with a strong background in data analysis. \n  Proficiency in data profiling tools and methodologies to assess data quality and completeness. \n  Strong knowledge of SQL and database query languages for data retrieval and manipulation. \n  Familiarity with data cleansing, transformation, and data enrichment techniques. \n  Solid understanding of data governance principles and data compliance requirements. \n  Excellent attention to detail and the ability to identify data patterns and trends. \n  Effective communication skills to collaborate with cross-functional teams and present findings. \n  Analytical mindset with the ability to draw actionable insights from complex datasets. \n  Self-motivated and results-oriented, with a passion for data accuracy and integrity. \n \n \n \n \n  EOE STATEMENT  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n \n  CCPA DISCLOSURE  Personal Information Collection Notice: This notice contains information under the California Consumer Privacy Act (CCPA) about the categories of personal information (PI) of California residents that Manufacturers Bank collects and the business or commercial purpose(s) for which the PI may be used. We do not sell PI. More information about our collection and use of PI may be found in our CCPA Privacy Policy at https://www.manufacturersbank.com/CCPA-Privacy. Persons with disabilities may contact our Customer Contact Center toll-free at (877) 560-9812 to request the information in this Notice in an alternative format."}, "aa94f7f419a25cab": {"terms": ["data science"], "salary_min": 106335.0, "salary_max": 134643.81, "title": "Data Scientist", "company": "Wiliot", "desc": "Wiliot was founded by the team that invented one of the technologies at the heart of 5G. Their next vision was to develop an IoT sticker, a computing element that can power itself by harvesting radio frequency energy, bringing connectivity and intelligence to everyday products and packaging, things previously disconnect from the IoT. This revolutionary mixture of cloud and semiconductor technology is being used by some of the world\u2019s largest consumer, retail, food and pharmaceutical companies to change the way we make, distribute, sell, use and recycle products. \n  Our investors include Softbank, Amazon, Alibaba, Verizon, NTT DoCoMo, Qualcomm and PepsiCo. \n  We are looking for a data scientist with proven hands-on skills to join the team and build high-performing, scalable applications that turn time-series telemetry into data products. You will collaborate with great people from multiple disciplines to create innovative digital products and integrate them within the Sensing-as-a-Service cloud platform. \n  Requirements:\n  \n \n \n \n BSc in Computer Science or Electrical Engineering or equivalent. Higher degree is an advantage. \n  At least 3 years of development experience \u2013 Python, Scala is an advantage \n  Experience with cloud data environments and big data ETL procedures, cloud architecture (AWS/GCP/Azure) \n  Experience with AI/ML/DL methods \n  Familiarity with some ML/data-processing frameworks and libraries (TensorFlow, Keras, PyTorch, MXNet, Spark, Scikit-learn, Pandas) \n  High self-learning and independent working abilities \n  Strong spoken and written English \n  Strong interpersonal and communication skills \n \n  #LI-Hybrid \n \n  Responsibilities:\n  \n \n \n \n \n Rapidly experiment and build models to clean signals and provide valuable insights to our customers. \n  Design algorithms and SW solutions, considering large scale, high availability, security, robustness, performance, and cloud aspects. \n  Work hands-on with the data using SQL, PySpark, and other tools to extract, analyze, and visualize data. \n  Understand and oversee all phases of the development life cycle, such as Automation, CI\\CD, TDD, Integrations, Builds, and Deployment. \n  Work with cross-functional stakeholders such as product management, marketing, and SW engineering. \n  Make strategic recommendations on data collection, integration, and retention requirements incorporating business best practices."}, "50d4e0658e6594a1": {"terms": ["data science"], "salary_min": 123100.0, "salary_max": 230900.0, "title": "Senior Data Scientist", "company": "Cisco Meraki", "desc": "The modern world runs on the Internet, and the Internet cannot exist without its underlying infrastructure. Meraki makes setting up, managing, and maintaining that infrastructure easier than it has ever been before. Meraki enables connectivity everywhere from neighborhood cafes to world-class universities to global hospitality groups operating thousands of sites. And Meraki's hardware organization is responsible for building the physical devices that get people online. \n  Meraki is looking for a Senior Data Scientist to join Cisco Wireless & Meraki Hardware's Analytics and Data Science Team. As a Data Scientist you will be a key partner in Meraki's analytics ecosystem, responsible for conducting data-driven analyses that drive key decisions. You will work on high impact and visibility initiatives using brand new data sets, and you will help shape how internal teams and external customers alike leverage this data to achieve their goals. \n  As part of this role, you will develop relationships across teams including software engineering, product management, hardware development, quality, support, and supply chain. Ideal candidates will have strong communication skills, an analytical mindset, excellent organizational skills, and a bias to action. You don't wait for change - you embody the change you want to see in the world! \n  Meraki believes that the quality of our product is dependent on the quality of our employees. We place a high value on nurturing the growth and development of everyone on our team. We foster an open and supportive workplace where everybody is given the opportunity to succeed. \n  EXAMPLE PROJECTS OF A DATA SCIENTIST: \n \n Build a model using hardware telemetry data (e.g. temperature, fan speed, utilization) to estimate device power consumption to support sustainability initiatives. \n Develop a methodology for scoring the health of a hardware device based on factors such as manufacture date, cumulative online time, and telemetry history. Work with teams to identify overlooked use cases for this device health score, and help bring them to bear. \n Supply Chain managers have realized that sometimes hardware is shipped by air that would have arrived in time if shipped by ocean (which is slower but cheaper). Build a data pipeline and visualization that shows when air shipping is necessary and when ocean shipping is possible. \n \n MINIMUM QUALIFICATIONS: \n \n 5+ years experience with SQL \n 5+ years experience working with core statistical concepts (e.g. correlation, modeling, regression analysis) in Python or R \n 4+ years experience with data visualization tools (e.g. Tableau) \n Experience data mining on large datasets \n Ability to take initiative and work autonomously \n Strong analytical and critical thinking skills \n Strong written and oral presentation skills. Able to communicate complex concepts to a variety of audiences \n \n BONUS POINTS FOR: \n \n Masters degree in Statistics or a related field \n Proficiency with unstructured data and related tools (e.g. MongoDB) \n Experience in the hardware development industry \n \n Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis. Cisco will consider for employment, on a case by case basis, qualified applicants with arrest and conviction records. \n  At Cisco Meraki, we don't just accept difference - it's one of our key values. Everybody In means we listen to each other's opinions. Everybody is accepted and valued here, and we are a team that works as one towards our goals. We recognize that diverse teams make the strongest teams, and we encourage people from all backgrounds to apply. \n \n  Compensation Range:  \n \n   $123,100\u2014$230,900 USD\n   \n \n \n  Message to applicants applying to work in the U.S.:  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process. \n  U.S. employees have access to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program. \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid."}, "382518713cf60da1": {"terms": ["data science"], "salary_min": 98036.984, "salary_max": 124136.67, "title": "Senior Fraud Decision Science Analyst", "company": "Radial, Inc.", "desc": "Senior Fraud Decision Science Analyst \n At Radial, our employees are the forefront of ecommerce, bringing beloved brands to consumers through our fulfillment, customer care and technology solutions. We are fueling the future of retail, which means you are, too. When you work for Radial, you join a global community of changemakers, where the work is critical, and the culture is fun. We depend on our workforce to overcome real-world challenges every day and encourage you to carve your own career path while shaping our future together. \n Radial, the leader in omnichannel commerce technologies and operations has an exciting opening for a Senior Fraud Decision Science Analyst. Radial\u2019s omnichannel solutions use cutting-edge technology and analytics to optimize the e-commerce end to end processes reducing costs for our customer while enhancing the consumer experience. \n Role Summary: \n The Senior Fraud Decision Science Analyst will be responsible for identifying new and unique ways of finding and capturing ecommerce fraud trends. This role is a terrific opportunity to work in the dynamic space of e-commerce fraud to solve complex problems using big data technologies. This role will work alongside a team of analysts and data scientists. \n Responsibilities: \n \n Work with a wide variety of systems, tools and algorithms to evaluate data, execute their investigation and develop an efficient analytical workflow including machine learning models, velocity detection and behavior analytics.   \n Analyze large volume of data using big data technologies to detect the fraud trends proactively.   \n Create the fraud business rules for deployment in case management engine to increase auto-decision rate and reduce manual review and chargeback rate.   \n Conduct portfolio analytics to generate client insights, market segmentation, and measure clients\u2019 risk profile.   \n \n \n Conduct robust analysis to help create rules and processes to proactively mitigate fraud and reduce customer impact.   \n Evaluate, resolve, and respond to fraud impacts to clients via analysis.   \n Work with 3rd party vendors to enhance analytics and improve data capabilities for analysis.   \n Support the Fraud Analytics, Order Review, and Chargeback teams, and work closely with other internal and external technology groups   \n \n Qualifications \n \n Strong programming skills in SQL, and Microsoft 365 Tools (Excel, Word, Power Point, Etc)   \n Experiences with Python and Tableau   \n Understanding Machine Learning and modeling is a plus   \n Strong analytical, organizational and communication skills   \n \n \n Bachelor\u2019s degree in Criminal Justice or a quantitative discipline. Master\u2019s degree is preferred.   \n 8+ years of working experience in fraud decisioning and fraud review   \n Candidate must have a proven track record of excellent relationship skills. Ability to understand business and technical requirements.   \n \n Travel: \n \n This position is remote.   \n \n \n Travel is not required.   \n \n \n Radial is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations, and ordinances. \n \n \n Radial is committed to ensuring that its online application process provides an equal employment opportunity to all job seekers, including individuals with disabilities. If you believe you need a reasonable accommodation in order to search for a job opening or to submit an application, please contact us by emailing hroperations@radial.com. We will work to assist disabled job seekers whose disability prevents them from being able to apply online."}, "9e6c4a5e8a2df5a0": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 170000.0, "salary_max": 190000.0, "title": "Sr Machine Learning Engineer", "company": "Vacasa", "desc": "Why Vacasa \n  We started with just one home and an idea: to bring homeowners and renters together with smart technology and caring local teams. Today, we're the largest full-service vacation rental company in North America thanks to the people who give us their best every day. You'll fit right in here if you're curious, entrepreneurial, and thrive in a rapid-growth environment. \n  What we're looking for \n  As a Senior Machine Learning Engineer at Vacasa, you will join a nimble, cross-functional team of bright machine learning engineers and data scientists. This team has a high impact on company revenue and cost reduction. \n  You will productionize ML models in the cloud using Python, and adapt feature engineering techniques to both batch and real-time pipelines. This includes writing robust, maintainable, and reliable systems with validation, monitoring, metrics, for both internal and external customers. \n  As a senior machine learning engineer, you will be expected to lead initiatives; define best practices for engineering, architecture and Data Science; be a leader for the team and mentor up-and-coming talent; set an example of conduct through cross-team collaboration; communicate to stakeholders; and balance engineering concerns with business needs. You will be accountable for selecting technologies, and defining patterns that will be used across machine learning projects. \n  Vacasa's machine learning and data science research is broad. We train dozens of models, from dynamic daily pricing for all units, to probability models that are used throughout the company. There's potential to explore and implement recommender systems, NLP techniques, and neural networks. Vacasa has hundreds of millions of records for model training. Help us discover value in our data and bring it to customers! \n  What you'll do \n \n Develop and productionize machine learning models using AWS, Python 3, CI/CD, and Terraform. \n Write maintainable, reliable, and robust pipelines complete with unit and integration tests. \n Contribute to all phases of development and delivery, including on-call rotation (currently at a bi-weekly basis). \n Develop dashboards to monitor pipeline health, and alert on key metrics. \n Collaborate with a cross-functional team of engineers, QA, data scientists, and Product. \n Continually update your engineering skills using modern tools and techniques. \n Deliver results to stakeholders on time and within budget. \n Conduct code reviews, peer design, and demonstrate respectful, effective communication. \n Debug difficult problems across multiple projects, and become an expert in MLOps. \n Lead large-scale initiatives, provide feedback, and mentor other team members. \n Define repeatable architectural patterns for large-scale, adaptive, secure, performant systems. \n Select technologies, guide technical solutions, and produce high quality documentation. \n \n Skills you'll need \n \n 6+ years of software engineering and data science, including 2+ years of machine learning engineering or equivalent experience. \n Familiarity with machine learning algorithms, including supervised and unsupervised. \n RDBMS and ETL experience, data warehouse experience. \n Ability to function in a \"big data\" environment such as Apache Spark. \n Familiarity with the AWS ecosystem and tools such as S3, Glue, or SageMaker. \n Strong Python experience. \n Experience writing infrastructure as code, Terraform is a plus. \n Ability to work under ambiguous environments \u2013 independently ask questions to derive ACs and requirements \n Other duties, as assigned. \n Reliable internet connection, must meet a minimum of 50 mbps \n \n Working conditions \n  Ability to work from home and resides in one of the followings states: AK, AL, AZ, CA, CO, DE, FL, GA, HI, ID, IL, IN, LA, MA, MD, ME, MI, MN, MO, MT, NC, NH, NJ, NM, NV, OH, OK, OR, PA, RI, SC, SD, TN, TX, UT, VA, VT, WA, WI, or WY \n  You'll be working in your home office setting. We hold virtual training sessions and weekly team meeting. Occasional offsite team meetings in your region or our HQ locations. Requires frequent, repetitive use of a computer, phone, and office equipment. Requires patient, professional communication with prospective clients, and the ability to build confidence with prospects. \n  Compensation \n \n $170000 - $190000 / year \n \n What you'll get \n \n Health/dental/vision insurance - employee & family coverage options \n Employer Sponsored & Voluntary Supplemental Benefits \n 401K retirement savings plan with immediate 100% company match on the first 6% you contribute \n Health & Dependent Care Flexible Spending Accounts \n Flexible vacation time \n Paid sick days and holidays \n Paid parental leave after one year of tenure \n Employee Assistance Program \n Career advancement opportunities \n Employee discounts and \n All the equipment you'll need to be successful \n Great colleagues and culture \n \n Please visit our careers page to review our full benefits offerings \n  Vacasa is an equal opportunity employer committed to fostering a diverse and inclusive workplace. We do not discriminate against applicants based upon race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), national origin, age, disability, genetic information, or other classes protected by applicable law. Veterans are encouraged. \n  Vacasa is committed to maintaining a safe and productive work environment. Possession, use, or being under the influence of alcohol or illegal drugs in the workplace is prohibited. \n  An offer of employment for this role will be contingent upon the successful completion of a background check. \n  #li-remote"}, "96f61dd924eb01b0": {"terms": ["data science", "data engineer", "machine learning engineer"], "salary_min": 120000.0, "salary_max": 155000.0, "title": "Senior Data Scientist / NLP Engineer - R11936", "company": "SIL International", "desc": "About the Role: \n Are you mad-skilled at building amazing technical solutions yet burned out because your efforts sell widgets you don\u2019t care about? Passionate about your Christian faith and want to put that to work making a difference for people around the world? Come join the IDX team as a senior data scientist / NLP Engineer! \n The SIL Innovation team (IDX) at SIL International is looking for a senior data scientist / NLP engineer to help advance AI technology expanding language possibilities designed to enable a quarter of the world\u2019s population to flourish using their mother language. This candidate will be part of a faith-based nonprofit organization committed to serving language communities worldwide as they build capacity for sustainable language development. The position is a paid salary position, offers exceptional real-world learning opportunities, and involves work on state-of-the-art (SOTA) NLP solutions and modern infrastructure. \n The senior data scientist / NLP engineer is seeking a full-time engineering position in which they will gain non-profit, business and technical experience. They enjoy supporting a team that solves complex problems to generate valuable insights. They communicate, create, organize, and advocate the impact of Bible Translation as a critical element of the Great Commission. \n The Senior Data Scientist / NLP Engineer works on real-world problems in natural language processing (NLP) for text and speech/voice. This includes extending and improving on NLP models and methods using pooled language/voice data from SIL and its partners (in 1,600+ languages). The output of this work will be applied by SIL, other NGOs, and commercial entities in technology/content creation for local language communities. \n What You'll Be Doing: \n Must be able to successfully fulfill the following tasks: -Participate in research in machine intelligence and machine learning applications -Develop solutions for real world natural language processing problems -Help curate and pre-process pooled data from SIL and its partners such that is can be utilized in NLP/ML/AI research and development -Advise and collaborate with SIL Data Scientist(s) -Lead and contribute to the design and implementation of NLP models and algorithms that can scale across diverse languages and dialects, taking into consideration the linguistic variations and complexities present in different language communities. -Collaborate with cross-functional teams, including linguists, on-the-ground Bible translation teams (consultants, mother tongue translators), software engineers, and domain experts, to identify language-specific challenges and develop innovative NLP solutions to address them. -Stay up-to-date with the latest advancements in NLP and machine learning research, and integrate cutting-edge techniques into the existing workflow to improve the efficiency and accuracy of language processing models. -Engage in regular knowledge-sharing sessions with team members, promoting a culture of continuous learning and professional development. -Contribute to the creation of technical documentation and research papers to disseminate findings and contribute to the academic community. -Collaborate with partner organizations and stakeholders to understand their specific NLP requirements and develop tailored solutions that cater to their needs. -Participate in technical discussions and brainstorming sessions to provide insights and recommendations for improving the overall AI technology strategy of SIL Innovation team. -Assist in exploring potential funding opportunities and grants that align with the organization's mission and research goals. \n What We're Looking For: \n -Available full time starting asap. -General availability during US business hours Monday \u2013 Friday, 8AM-5PM (central time); fairly flexible. -Bilingual and multicultural experience is preferred -Position can be remote or in person in the Dallas area (SIL International Headquarters). -Occasional face to face meetings: up to 25% travel, including international trips -Strong organizational, communication skills -Enjoy working with a team or independently with minimal supervision -Leadership skills and ambitious attitude -Passion for global missions -Experience with Google GSuite -Able to complete and pass all required screens for employment -U.S. Citizen or Permanent Resident (Deferred action and temporary / permanent resident do not qualify) -Able to pass a criminal background check \n Required experience/ education: -Python programming, including experience with data manipulation, algorithm development, and NLP libraries/frameworks. -Command line (e.g., bash) to navigate file systems, edit files, connect remotely to servers, etc. -Cloud infrastructure usage and management (e.g., AWS, GCP, or Digital Ocean), for deploying NLP solutions at scale. -Ability to work effectively in a collaborative team environment, utilizing office suites like Google Docs and shared drives such as Google Drive for efficient communication and documentation. -Degree in computer science or another quantitative discipline (physics, engineering, etc.) and/or 5 years of experience. -Previous projects demonstrating the ability to develop and deploy real world APIs or other software products. \n Preferred experience/ education: -Advanced degree (Master's or Ph.D.) in computer science, computational linguistics, or a related field, with a focus on natural language processing or machine learning. -Go programming experience. -Proven track record of research publications or contributions to the NLP/Machine Learning community, such as academic papers, conference presentations, or open-source projects. -Experience with deep learning frameworks like TensorFlow or PyTorch / HuggingFace, and the ability to fine-tune pre-trained language models for specific NLP tasks. -Strong understanding of linguistics, syntax, and semantics, enabling effective collaboration with linguistic experts within SIL International. -Familiarity with Agile development methodologies and project management tools for efficient project execution and delivery. -Knowledge of other programming languages commonly used in NLP, such as Java, C++, or JavaScript, to facilitate integration with existing systems or applications. -Prior experience working with multi-language or low-resource language datasets, addressing challenges in data scarcity and language diversity. -Demonstrated ability to conduct end-to-end model evaluation and performance optimization, considering real-world constraints and deployment scenarios. \n Extra credit experience: -Proven track record of public presentations on AI-related topics, including participation in podcasts, conferences, or speaking engagements. -Previous leadership and management experience, including leading NLP research teams or managing complex projects with interdisciplinary stakeholders. -Experience in collaborating with non-profit organizations or faith-based initiatives, demonstrating a passion for using AI technology to serve global language communities. -Involvement in community-driven AI initiatives or mentorship programs, promoting knowledge sharing and diversity in the AI field. \n Job Type: Full-time \n Pay: $120,000.00 - $155,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Retirement plan \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Education: \n \n Master's (Preferred) \n \n Experience: \n \n Python: 1 year (Preferred) \n SQL: 1 year (Preferred) \n \n Work Location: Remote"}, "50bbc854f0bb64c9": {"terms": ["data science", "machine learning engineer"], "salary_min": 99001.586, "salary_max": 125358.07, "title": "Software Developer", "company": "Protection Engineering Consultants", "desc": "Job Description \n  Protection Engineering Consultants (PEC) is a unique and diverse small-business engineering firm. PEC\u2019s services range from security consulting and risk mitigation support to the design, research, analysis and testing of protective structures subject to extreme loads, such as weapons effects, blast, vehicle impact, forced entry attack and natural hazards. We provide structural and mechanical engineering services; use machine learning (ML) and uncertainty quantification (UQ) techniques to deliver novel solutions to engineering problems; create specialized software for defense and anti-terrorism applications; perform advanced numerical modeling; develop, oversee and perform nonlinear and dynamic testing; develop criteria for protective applications; and, provide training. We work domestically and internationally. \n  As we continue to expand our services, PEC is looking for a creative software developer or coding-capable engineer to support the development of software that address the unique engineering challenges of our military and civilian clients. Preferred areas of expertise include C++ and Python programming, database management, cloud computing, and knowledge of version control systems (e.g., git, etc.). The ideal candidate would have a background in plugin development for Endgame Framework (or similar), cross-domain familiarity with structural or mechanical engineering, and experience with data science and machine learning. \n  Your role initially will be to provide support for our ongoing efforts. We will provide opportunities for you to grow into project management, marketing, and business development, as your interests dictate; you can also stay in a technical role if that is your preferred career path. \n  This position offers both in-office and remote work options. Office locations include San Antonio and Austin, Texas. Remote work options are available within the contiguous United States. \n  Qualifications \n \n  BS or MS in Computer Science, Data Science, Engineering, Information Systems, or a similar field. \n  No professional experience required (3-5 years of experience considered a plus). \n  Proficiency in C++, Python, and version control systems. \n  Ability to clearly communicate verbal and written technical information. \n  This position requires the ability to obtain a U.S. security clearance for which the U.S. Government requires U.S. citizenship. \n \n  Benefits \n  PEC offers a competitive compensation package for the successful candidate. Benefits include: \n \n  Competitive salary. \n  Flexible work schedule. \n  Relocation expenses. \n  Annual performance bonuses. \n  Opportunity for company ownership. \n  Professional development and training support. \n  Health, Dental, and Vision Insurance paid in full. \n  401(k) match plan. \n \n  Protection Engineering Consultants LLC (PEC) provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, PEC complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfers, leaves of absence, compensation and training. \n  Please send all applications and inquiries to careers@protection-consultants.com"}, "392056f262e64f83": {"terms": ["data science"], "salary_min": 145930.02, "salary_max": 184779.92, "title": "Senior Data Scientist (PHD Required)", "company": "Amperon", "desc": "The Company You'll Join \n  Amperon is the leading analytics and forecasting company for the energy transition. Our platform leverages advanced algorithms and machine learning techniques to accurately forecast energy demand on both the supply (power & utilities companies) and demand (large energy users) sides of the market. We incorporate real-time data feeds that help our clients reduce cost, monitor energy efficiency while increasing substantially. \n  We bring the brightest mind from energy, security and technology in order to combat climate changes and transition to clean energy solutions. We have offices in Texas but are a remote first company. \n  Our Mission \n  As the electricity grid faces challenges due to renewables, EVs, climate change, and more, there's a desperate need for an upgrade. Amperon's blend of energy expertise and AI technology offers analytics and forecasting software to improve grid reliability and accelerate decarbonization. We're building the next generation of market-leading energy analytics and forecasting products, and we want you to be part of our journey! \n  The team you'll work with \n  We use machine learning and data analytics to analyze large volumes of data, uncover patterns, and make predictions that can be invaluable in the energy sector. Our team managesdeep and valuable data around energy supply and demand that can lead to more efficient and sustainable energy systems. We are a small growing team with the opportunity to build high velocity machine learning from scratch. \n  The Impact \n  We have direct impact to help optimize energy distribution, predict demand fluctuations, and identify energy-saving opportunities. We build analytical tools that can process vast amounts of data collected from various sources within the energy grid. We work with cross functional teams around new product development including international expandsion. \n \n  The problems you'll solve \n \n Implement data validation and cleaning processes to identify and rectify errors or inconsistencies in the incoming data. \n Build advanced time series forecasting models at scale. \n Create relevant features that can improve forecasting accuracy, such as lag features, rolling statistics, and domain-specific variables. \n Continuously monitor the training process and evaluate model performance on the validation set. \n Deploying well-performing models into a production environment. \n Analyzing historical data and real-time information to determine changes in energy consumption. \n \n You may be a fit for this role if \n  You are a senior scientist with a PHD.You have expertise with building machine learning algorithms. You have extensive experience with data collection and data processing. Experience with techniques like data cleaning, normalization, and feature engineering to prepare the data for modeling. Experience with time series analysis and predictive modeling. Experience with Python and other modeling tools. \n  Perks \n  While we are serious about our company's culture, we aren't going to force \"culture\" to prove that we are cool and fun. It's a company filled with smart, genuinely nice individuals who are passionate about data science, energy and working together to build a product that can have a lasting impact on our planet. \n  Even though we are a remote company with employees spread across the globe, we still believe human interaction is a good thing. We will also have an all-company event at least once a year so people can get to know each other in a more fun and social way. \n \n Competitive salary \n Health insurance \n Monthly gym membership stipend \n Pre-tax commuter benefits \n 401k \n Stock options \n Flexible work hours \n Remote \n \n  If you are excited about contributing to a product that can have a lasting impact on our planet and you thrive in fast-paced, innovative environments, we would love to hear from you."}, "e4f1b2b43dad206b": {"terms": ["data science", "data engineer", "machine learning engineer", "mlops"], "salary_min": 145641.27, "salary_max": 184414.3, "title": "Principal Deep Learning Data Scientist/Engineer - Cloud Software Environ.", "company": "ELI , LLC", "desc": "MUST SEE FOR ANY DATA SCIENTIST THAT IS SUPER PASSIONATE ABOUT WORKING WITH LLMs AND CREATING A BETTER LIFE FOR OTHER'S CARE! \n ** REMOTE - AMAZING COMP PACKAGE (to include stocks & bonus) - WORK WITH INCREDIBLY SMART PEOPLE WHO ARE CHANGING HEALTHCARE** \n Our client is revolutionizing healthcare by delivering value-based care to their patients. Their total care model empowers doctors to prioritize the patient's well-being over fees preserving the autonomy of local physicians while establishing enduring partnerships. As a Principal Data Scientist , you will play a pivotal role in addressing complex healthcare challenges, ranging from enhancing medical diagnoses to identifying medication adherence risks. \n Key Responsibilities: \n \n Modeling Expertise : Develop, train, and deploy predictive models utilizing deep learning and large language models (LLMs)/generative architectures to address diverse healthcare use cases. \n Team Leadership : Lead project teams, provide mentorship to junior data scientists, and collaborate closely with clinical and operational stakeholders across the company to drive innovation. \n MLOps Implementation : Construct production-quality pipelines for model training and inference, utilizing the MLOps stack on AWS to ensure seamless integration. \n Data Utilization : Work with extensive clinical datasets sourced from company's data lake, spanning various data sources and formats. \n Research and Innovation : Stay abreast of the latest advancements in machine learning and other technologies relevant to value-based care. Identify strategic opportunities for publishing based on project achievements. \n Work Environment : What more can you ask for - REMOTE!! Your home office. \n \n Qualifications: \n \n Educational Background : Possess an advanced degree (PhD, MS) in a quantitative field, such as machine learning, statistics, economics, population health, epidemiology, or computer science. \n Deep Learning Experience : Demonstrate a minimum of 5 years of experience in training deep learning models, with a preference for hands-on experience with large language models (LLMs). \n Technical Proficiency : Exhibit expert proficiency in Python and SQL, essential for effective data analysis and queries. AWS and EC2 (Amazon Elastic Compute Cloud) experience. \n Production Experience : Have a minimum of 5 of experience working in a software production environment or a similar research background. Should be able to show documents or publications as to your research. \n \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Employee discount \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Referral program \n Retirement plan \n Tuition reimbursement \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Supplemental pay types: \n \n Bonus opportunities \n \n Experience: \n \n Python: 5 years (Required) \n SQL: 5 years (Required) \n completed Master's or PhD: 1 year (Required) \n AWS: 1 year (Preferred) \n team lead: 3 years (Required) \n full ML development lifecycle: 2 years (Required) \n current Amazon EC2: 1 year (Required) \n LLM: 5 years (Preferred) \n current software production: 3 years (Required) \n \n License/Certification: \n \n Live in US and area Green Card holder or Citizen (Required) \n \n Work Location: Remote"}, "8e4259990dbb3cfb": {"terms": ["data science"], "salary_min": 101200.0, "salary_max": 184000.0, "title": "Sr Manager Data Analytics - Remote", "company": "Optum", "desc": "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together. \n \n The Senior Manager, Digital Data Analytics is a seasoned professional with a proven track record, a driven self-starter, problem solver, and someone that is passionate about creating remarkable digital experiences driven by digital insights. The position requires extensive experience in digital analytics, relationship and consensus-building skills, and proven ability to think strategically in the complex and evolving healthcare environment. \n \n The role will use available tools and expertise to lead the digital analytics program focused on Optum across an ecosystem of digital channels. The program will provide insights that inform content decisions and fuel innovation and ideas that improve engagement and communication with Optum users. \n \n You\u2019ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges. \n \n Primary Responsibilities: \n \n Partner with stakeholders to develop measurement frameworks that align to organization key performance indicators \n Ensure that measurement solutions adhere to organizational priorities \n Act as a subject matter expert on best-in-class digital analytics and optimization, consulting with stakeholders to enable the best possible view to member behaviors \n Support product teams with ad hoc and recurring reporting, and deep dive analytics to answer key business questions \n Develop learning and optimization plans collaboratively with data science, web analytics, and business stakeholders \n Evangelize importance of analytics and optimization across organization while developing strong relationships with the business stakeholders \n Development of measurable stakeholder goals and measurement plans that tie to business impact and ROI \n Gain an in-depth knowledge of Optum website architecture, KPI\u2019s and customer goals \n Manage customer expectations appropriately and keep projects on schedule and within scope \n Lead face-to-face brainstorming session with key stakeholders on the marketing, technical and design sides of a client\u2019s business \n Manage multiple projects, with multiple remote teams, at one time \n Interact frequently with clients via phone, email, and in-person \n Provide regular status updates to the leadership and quickly escalate potential issues \n Monitor trends in web, social, digital, and mobile media and exploring new tools, trends and applications that could positively impact our business \n \n \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n  Required Qualifications: \n \n Undergraduate degree or equivalent work experience \n 5+ years of digital analytics experience working with large, distributed teams \n Demonstrated experience utilizing the Adobe suite of web analytics products, or Google Analytics \n Demonstrated experience in managing the analytics lifecycle, including testing methodologies \n Experience with MS Office tools (Excel, Word, PowerPoint) \n \n \n California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only:  The salary range for California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island or Washington residents is $101,200 to $184,000 per year. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives. \n \n \n All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy \n \n \n At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age, location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission. \n \n \n Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. \n \n UnitedHealth Group is a drug - free workplace. Candidates are required to pass a drug test before beginning employment."}, "2e6c3a1d292be332": {"terms": ["data science", "machine learning engineer"], "salary_min": 159675.44, "salary_max": 202184.69, "title": "Senior Machine Learning Engineer (Chat Agent)", "company": "Cresta", "desc": "Who are we? \n \n \n \n  Are you interested in defining how Generative AI will shape the future of work?\n   \n \n \n \n    We are a Silicon Valley Series C startup, spun out of the Stanford AI lab and are co-founded by Sebastian Thrun, co-founder and CEO of Google-X, Waymo, Udacity, Kitty Hawk, and more. Cresta launched in 2020. Since then, we\u2019ve grown revenue and our team by 300% and became officially a Unicorn. We\u2019ve assembled a world-class team of AI and ML experts, go-to-market leaders, top-tier investors, and advisors including Andreessen Horowitz, Greylock Partners, Sequoia Capital, Tiger Global, and former AT&T CEO John Donovan. Our valued customers include brands like Intuit, Porsche, Holiday Inn, and Dropbox and we have been recognized as a startup to watch by Business Insider, Forbes, and Gartner to name a few.\n   \n \n \n \n    We are growing our machine learning team in North America. Join us to develop great products in an exceptional strong team.\n   \n \n \n \n    Cresta is on a mission to make every knowledge worker 100x as effective, 10x faster, and 10x better. We apply AI to improve Call Center operations using our patented real-time coaching platform. We provide dynamic, live guidance to every agent based on the best practices of the top performers.\n   \n \n \n  As an ML software engineer, you will join the a team full of talented experts in frontend, backend, and ML/NLP. We have an in-house product for call analysis, building, evaluating, and deploying conversational AI models, and have labelers and analysts available. We work on a variety of ML problems, including but not limited to text generation, classification, summarization, etc. Our team leverages the latest in cutting edge LLM and GPT technologies to enable a truly market differentiated product suite.\n   \n \n \n  You will join a collaborative but highly autonomous working environment in which each member has a defined role with clear expectations, as well as the freedom to pursue individual projects.\n   \n \n \n \n \n \n  What you will do: \n \n \n  Collaborate with product managers, data scientists, and other cross-functional team members to understand, define, and detail product requirements, ensuring alignment with business objectives. \n  Design, prototype, and validate ML/NLP models to solve challenging cutting-edge problems, using state-of-the-art techniques (including LLM and ChatGPT!) and best practices. \n  Work with our production teams to build and deploy scalable, high-performing, and reliable ML/NLP pipelines and systems that operate 24x7. \n  Actively contribute to the continuous improvement of our ML productivity, by identifying and leveraging opportunities for automation, data improvements, code optimization, and process enhancements. \n  Help shape the direction of machine learning and artificial intelligence at Cresta. \n \n \n \n \n \n \n What we look for: \n \n \n  Master's degree or PhD in Computer Science or related technical fields. \n  Minimum of 5 years of experience in software development, with a strong focus on machine learning and natural language processing. \n  Proven hands-on experience in developing, deploying, and maintaining ML/NLP models and pipelines. \n  Expertise in programming languages such as Python, Go and ML/NLP libraries such as PyTorch, Tensorflow, Transformers. \n  Solid understanding of software development principles, data structures, algorithms, and design patterns. \n  Experience with LLMs. \n  Experience with model optimization. \n  Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and containerization technologies (e.g., Docker, Kubernetes) is a plus. \n  Strong problem-solving, communication, and collaboration skills. \n \n \n \n \n \n \n   If you want to make an impact with an amazing product, want to improve your tech skills by working with other exceptional engineers, and like to be part of an amazing international team, then you should join us. We pay an attractive salary and with the Cresta stock options, you can benefit from the company's growth."}, "a1600303cd1264fa": {"terms": ["data science", "data engineer"], "salary_min": 101000.0, "salary_max": 130000.0, "title": "Palantir Data Engineer (remote)", "company": "Cognizant Technology Solutions", "desc": "This remote position is   open to any qualified applicant in the United States. \n A qualified applicant must be willing to work PST hours. \n Practice - AIA - Artificial Intelligence and Analytics \n About AI & Analytics:  Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future\u2014a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies! \n By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models! Cognizant\u2019s AIA practice takes insights that are buried in data and provides businesses with a clear way to transform how they source, interpret, and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence. \n Job Duties and Responsibilities: \n \n Use Pyspark to build data pipes in AWS environments \n Write design documents and independently build the Data Pipes based on the defined source to target mappings \n Convert complex stored procedures, SQL triggers, etc. logic using PySpark in the Cloud platform \n Be open to learning new technologies and implementing solutions quickly in the cloud platform \n Communicate with program key stakeholders to keep the project aligned with their goals \n Effectively interact with QA and UAT team for code testing and migrate to different regions \n Spearheads data engineering initiatives targeting moderately to complex data and analytics challenges, delivering impactful outcomes through comprehensive analysis and problem-solving \n Pioneers the identification, conceptualization, and execution of internal process enhancements, encompassing scalable infrastructure redesign, optimized data distribution, and the automation of manual workflows \n Addresses extensive application programming and analysis quandaries within defined procedural guidelines, offering resolutions that span wide-ranging scopes \n Actively engages in agile/scrum methodologies, actively participating in ceremonies such as stand-ups, planning sessions, and retrospectives. \n Orchestrates the development and execution of automated and user acceptance tests, integral to the iterative development lifecycle. \n Fosters the maturation of broader data systems and architecture, assessing individual data pipelines and suggesting/implementing enhancements to align with project and enterprise maturity objective \n Envisions and constructs infrastructure that facilitates access and analysis of vast datasets while ensuring data quality and metadata accuracy through systematic cataloging \n \n Position Qualifications: \n \n Total 10+ years of experience with 3 plus years of experience in data engineering/ETL ecosystems with Palantir Foundry, Python, PySpark and Java. \n Required skills:  Palantir \n Nice to have skills:  Pyspark and Python \n Expert in writing shell scripts to execute various job scheduler \n Hands-on experience in Palantir & PySpark to build data pipes in AWS environments \n Good knowledge of Palantir components \n Good exposure to RDMS \n Basic understanding of Data Mappings and Workflows \n Any knowledge of the Palantir Foundry Platform will be a big plus \n Implemented a few projects in Energy and Utility space is a plus \n \n Salary and Other Compensation: \n The annual salary for this position is between $101,000 - $130,000 depending on experience and other qualifications of the successful candidate. \n This position is also eligible for Cognizant\u2019s discretionary annual incentive program and stock awards, based on performance and is subject to the terms of Cognizant\u2019s applicable plans. \n Benefits : Cognizant offers the following benefits for this position, subject to applicable eligibility requirements: \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n Disclaimer:  The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law. \n #LI-AY1 #CB #Ind123"}, "f70795a9f5510ed1": {"terms": ["data science", "data analyst"], "salary_min": 66448.49, "salary_max": 84138.6, "title": "Medical Economics Analyst", "company": "HealthComp", "desc": "Description \n \n  Exciting role to develop a highly versatile medical economic analytical skillset while helping to improve health analytics and healthcare affordability for members.\n  \n  Key Responsibilities \n \n \n  Support the development of new healthcare economic analytical tools and dashboards as the backbone for new product offerings and new efficiency improvements for operational teams \n Translating health care data into meaningful insights and actionable recommendations for clients and executive partners \n Identify industry and group specific medical trends and cost drivers \n Collaborate with sales and develop claims projections for new and existing groups \n Perform medical cost savings analysis on internal programs and external vendors \n Support consulting and strategic sales and pricing decisions through the development of medical economic analyses, with mentorship and collaboration from experienced data scientists, medical economic leaders and actuaries \n \n \n  Skills, Knowledge & Expertise \n \n \n  Microsoft Office Suite \n SQL , SAS, Python, Power BI \n BS / BS preferred in Math, Statistics, Data Science \n  Economics or similar analytical work experience \n \n \n  Benefits \n \n \n  Competitive pay with opportunity for career advancement \n Paid time off policy to support a healthy work-life environment \n Full offering of health and wellness benefits for you and your family \n Company paid life insurance and disability plan \n 401K plan with company matching \n Employee discounts and wellness program \n \n \n  About HealthComp \n \n   Operating since 1994, we\u2019re a third-party administrator (TPA) committed to providing employers with all the services needed to administer their benefits efficiently resulting in better health outcomes for their employees and higher cost savings for them. We partner with a variety of health providers and technology vendors to ensure a robust offering of medical, dental, vision, COBRA, HIPAA, flexible spending accounts and reference-based pricing, so members can make the most out of their benefits. It\u2019s comprehensive care without the confusion.\n   \n  HealthComp is an Equal Opportunity Employer.\n   \n  HealthComp recruiting correspondence will always come from a talent acquisition representative with an official @healthcomp e-mail address. In addition, our representatives will never ask for any form of payment from a new hire or candidate. Please report suspicious activity to hiringsecurity@Healthcomp.com."}, "367dba1b9d072440": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 130000.0, "title": "ServiceNow Solutions Engineer / Business Solution Analyst", "company": "Kanini Software Solutions", "desc": "About Kanini \n Kanini provides Agile Software Development, Cloud Computing, Data Science, and Location Intelligence services to public and private organizations. We have successfully served our clients in government, finance, transportation, utility, and software industries since 2003. \n Why you should join \n Working at Kanini is flexible and personal. We are a highly motivated, collaborative team experimenting with the latest technologies. We are committed to everyone having a healthy work/life balance, and we provide extensive mentorship and training resources to help you succeed. \n Kanini is looking for a  ServiceNow Solution Service Engineer /    Business Solutions Analyst  who has a deep experience in ServiceNow Solutions Engineering, User Stories. \n Key Responsibilities \n \n ServiceNow Solution Engineering: \n \n \n Design, configure, and customize ServiceNow applications to meet business requirements. \n \n \n Collaborate with stakeholders to gather and document functional and technical requirements. \n \n \n Develop and maintain ServiceNow workflows, scripts, and integrations. \n \n \n Perform system testing and ensure the quality of ServiceNow solutions. \n \n Business Systems Analysis \n \n Analyze existing business processes and systems to identify areas for improvement. \n \n \n Work closely with business stakeholders to understand their needs and translate them into technical solutions. \n \n \n Create detailed documentation, including user stories, process diagrams, and system specifications. \n \n Qualifications \n \n Bachelor\u2019s degree in computer science, Information Technology, or a related field. \n \n \n Proven experience as a ServiceNow Solution Engineer or Business Systems Analyst. \n \n \n ServiceNow certification (e.g., Certified System Administrator, Certified Implementation Specialist) is a plus. \n \n \n Strong analytical and problem-solving skills. \n \n \n Excellent communication and interpersonal skills. \n \n \n Project management experience is desirable. \n \n \n Knowledge of ITIL principles and practices is a plus. \n \n Kanini Software Solutions, Inc. does not discriminate in employment matters based on race, gender, religion, age, national origin, citizenship, veteran status, family status, disability status, or any other protected class. We support workplace diversity. If you have a disability, please let us know if there is anything we can do to improve the interview process for you; we\u2019re happy to accommodate. \n Kanini Software Solutions, Inc., 25 Century Blvd., Ste. 602, Nashville, TN 37214 \n Job Type: Full-time \n Pay: $120,000.00 - $130,000.00 per year \n Work Location: Remote"}, "a9389ded864c7af5": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "AWS Solutions Architect", "company": "COCOLEVIO", "desc": "Description: \n   Who we are... \n  Cocolevio is a modern technology solutions company, and our vision is to enable a future where all businesses have the modern technology they need to compete in their market. Our mission is to provide platform-agnostic solutions to our clients, so they can leverage modern technologies\u2014Cloud, AI, IoT, Big Data\u2014to grow, increase profitability, and improve operational efficiency. Visit our website at cocolevio.com to learn more about what we do. \n  Who we're looking for... \n  We are currently seeking a Cloud Architect that architects and validates reference architectures, workload driven demos and POCs focused on end to end solutions for enabling technology capabilities in Data, Cloud Native Technologies, HPC and AI and Analytics Technologies. The Cloud Architect serves as subject matter expert (SME) and drives product, solution and services development for the Cloud Native Technologies Practice. The ideal candidate is a Cloud Architect as a go-to person within the internal organization tasked with ensuring the company deliver an unparalleled customer experience around delivering cloud native practice capabilities. \n  What you'll do... \n \n  Build and validate scalable and distributed reference architectures that will help enable and power cloud native, AI, HPC, and data infrastructure workflows for AI, ML, and Analytics platforms. \n  Collaborate with multiple SSG practice teams to understand and define data and compute requirements for various workloads, use cases and verticals. \n  Be an internal champion for cloud native workflows and technologies among the client\u2019s technical community. \n  Collaborate with internal research and technical teams at client\u2019s solving complex problems. \n  Evangelize and test drive new developments in the cloud native technologies, deep learning and artificial intelligence, scouring arXiv, journals, and conferences for new algorithms, techniques, and capabilities. \n  Document what you know and teach others. This can vary from building targeted training for partners and other cloud architects, to writing whitepapers, blogs, and wiki articles, to simply working through hard problems with a customer on a whiteboard. \n  Collaborate on solving complex technical challenges in various areas supporting the four SSG practices including Data Technologies, Cloud Native Technologies, High Performance Computing Technologies and AI, ML and Analytics Technologies. \n  Requirements: \n   Required Skills and Qualifications: \n \n  At least 6 years of experience as an AWS Solutions Architect \n  Bachelor\u2019s degree in computer science, Computer/Electrical Engineering, Physics or a related field (or equivalent experience). \n  Solid technical foundation in distributed computing and storage, including significant experience with most of the following: server systems, storage, I/O, networking, and systems software. \n  Highly motivated with strong interpersonal skills, you have the ability to work successfully with multi-functional teams, principles and architects and coordinate effectively across organizational boundaries and geographies. \n  Experience with CI/CD, Agile development practices, Configuration Management systems. \n  Strong written and oral communication skills with the ability to effectively collaborate with management and engineering. \n  Strong time-management and organization skills for coordinating multiple initiatives, priorities and implementations of new technology and products into very complex projects. \n  Strong analytical and problem-solving skills. \n  Performance analysis and benchmarking experience. \n  Experience in generating design documentation in response to RFPs or similar requirements analysis. \n  Expertise with Microsoft Office Suite, specifically Excel and PowerPoint. \n  Working knowledge with at least one of C, C++, Java, Linux Shell Scripting, and Python. \n \n  Preferred Skills and Qualifications: \n \n  Advanced degrees and education; MS or PhD Engineering, Mathematics, Physics, Computer Science, or related fields or equivalent field work or research experience in distributed systems development and design. \n  Experience working with modern application deployment practices including but not limited to HPC Schedulers/Orchestration, Docker/Singularity Containers and Kubernetes. \n  Ability to create engaging proof-of-concepts communicating complex ideas in an intuitively. \n  Demonstrated track record of creative thinking and mentorship. \n  Exposure to Kubernetes technology and Rancher, OpenShift, or other Kubernetes platforms. \n  Exposure to architecting and deploying public and private cloud architectures. \n  Deep learning experience, have project experiences in one of the following: detection, recognition, tracking, translation, big data analysis, speech recognition, etc. \n  Parallel programming experience, OpenMP, MPI or other programming languages is a plus. \n  Have a go getter attitude to dive deeper and understand technical requirements with strong analytical and problem-solving skills. \n  In-depth software development, data science experience or HPC systems management. \n  Knowledge and experience working with software defined networking and cloud infrastructure, such as Cumulus Linux, Zero Touch Provisioning, \n \n  Benefits: Cocolevio provides the following benefits to eligible employees: \n \n  Medical Insurance, Dental Insurance, Vision Insurance \n  401(k) Retirement \n  Life Insurance and Disability Insurance \n  Paid Time off (PTO) \n  Holiday Pay \n  Bonus Plan \n \n  The diversity of Cocolevio employees is a tremendous asset. We are firmly committed to providing equal opportunity in all aspects of employment and will not tolerate any illegal discrimination or harassment based on age, race, gender, religion, national origin, disability, marital status, covered veteran status, sexual orientation, status with respect to public assistance, and other characteristics protected under state, federal, or local law and to prevent those who encourage, assist, or induce discrimination or force others to discriminate. \n  Accessibility: If you need an accommodation as part of the employment process please contact: HR@cocolevio.com \n  Disclaimer: The above description is meant to illustrate the general nature of work and level of effort being performed by individual\u2019s assigned to this position or job description. This is not restricted as a complete list of all skills, responsibilities, duties, and/or assignments required. Individuals may be required to perform duties outside of their position, job description or responsibilities as needed."}, "a5912a58a944d8e7": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Monitoring, Evaluation, and Learning Officer, Resettlement & Processing", "company": "International Rescue Committee", "desc": "Requisition ID:  req45617 \n  Job Title:  Monitoring, Evaluation, and Learning Officer, Resettlement & Processing \n  Sector:  Monitoring & Evaluation \n  Employment Category:  Fixed Term \n  Employment Type:  Full-Time \n  Compensation:  USD 65,000.00 - 79,000.00 Annually \n  Location:  New York, NY HQ USA \n  Work Arrangement:  Fully Remote     Job Description \n  Job Overview:   As part of IRC\u2019s Strategy 100, IRC\u2019s Resettlement, Asylum, and Integration Programs Department will continue and expand on its commitment to delivering impactful programs and services, focusing on raising program quality through giving clients greater influence over program design and delivery, better using research and other evidence, powering decisions with data, and more agile and impactful, outcomes-focused program design. The Monitoring, Evaluation, and Learning Officer will lead the monitoring and evaluation of the Resettlement & Processing (R&P) program, with a particular focus on the collection, analysis, and use of data on client outcomes via the IRC's resettlement assessment and monitoring and evaluation of the co-sponsorship program model. \n  Contingent upon notice of funding. \n \n  Major Responsibilities:   \n Responsibilities include but are not limited to: \n \n  Leading monitoring & evaluation of the R&P program. This includes:\n    \n  Leading the development of a high-quality MEL plan for the co-sponsorship program model that facilitates client-responsive, equitable, gender-sensitive service delivery, learning, and data-driven decision-making.\n      \n  Reviewing and updating the existing program Theory of Change and log frame in collaboration with program staff as needed to ensure project evaluability. \n  Ensuring a DEI-informed approach is applied to M&E planning and implementation. \n  Updating and managing existing data collection tools and systems in collaboration with program staff, RAL MEL colleagues and partners and building the capacity of program staff to use them. \n  Following up with program staff to ensure entry of data into IRIS/ETO systems. \n \n  Coordinating data collection of the Resettlement Assessment; monitoring the quality of data collected with other colleagues on the RAL MEL team. \n      \n Coordinating the use of translators, interpreters, and/or enumerators for data collection.  \n Managing gift card distribution and tracking project budget.  \n Conducting data analysis. \n  With program staff and partners, establishing data review routines and holding meetings to capture lessons learned. \n  Documenting and disseminating findings and lessons learned (through donor reporting as well as internal communications and knowledge management processes). \n \n \n  Contributing to thought leadership and capacity building related to monitoring and evaluation of the resettlement program.  \n Supporting other evaluations or research as opportunities arise. \n \n \n  Key Working Relationships:     \n This position is based in RAI\u2019s Research, Analysis and Learning Unit and reports to the Sr. Monitoring, Evaluation, and Learning Officer. The MEL Officer will work in close collaboration with other members of the RAL and R&P HQ program teams, and with program offices.   \n \n \n Job Requirements :   \n Education:  A University degree in a relevant discipline (preferably in Social Sciences, Data Science, or a related field) preferred.   \n \n \n Work Experience:  \n \n Experience developing and implementing M&E plans; coordinating and/or conducting project evaluations, conducting qualitative and both descriptive and inferential quantitative data analysis. Experience conducting evaluations of programs for refugee or displaced populations preferred. A minimum of 3 years of experience strongly preferred. \n \n \n  Demonstrated Skills and Competencies: \n \n  Demonstrated ability to promote an organizational culture that reflects IRC\u2019s core values of service, accountability, integrity, and equality. Ability to lead in a way that recognizes that IRC\u2019s work is best accomplished through the true collaboration of individuals from many cultures with a great variety of skills and perspectives. \n  Experience with writing and implementing M&E plans\u2014from inception to close-out. \n  A strong understanding of routines that promote data quality. \n  Experience with data management systems. For U.S staff, experience with Social Solutions\u2019 ETO platform is highly desired. \n  A strong understanding of client feedback systems and of how to apply a GEDI lens to monitoring, evaluation, and learning.  \n Experience developing both quantitative and qualitative data collection tools.  \n A strong understanding of principles and processes involved in collection of data from linguistically diverse, RIM populations. \n  Ability to effectively communicate results, including with data visualization. \n  Strong M&E technical knowledge, including knowledge of basic M&E concepts and tools, as well as experience with: design of evaluable projects, qualitative and quantitative methods, statistical analysis, sampling, and applied research.  \n Project management skills. \n  Advanced knowledge of Microsoft Office Word, PowerPoint and Excel.  \n Strong attention to detail (including in data management and written communication). \n  Ability to work flexibly both independently and as part of a team. \n  Excellent communication skills, both verbal and written. \n  Ability to handle multiple priorities and deadlines. \n  Strong critical thinking capabilities with an ability to rapidly assess situational needs, develop problem solving strategies, and implement sustainable solutions.   \n  Demonstrated experience with capacity building/training related to data collection tools and data quality.   \n  Proven experience with donor reporting.   \n  Experience managing project M&E across multiple locations, remotely preferred.   \n  Experience using mobile/ cloud-based digital technology for data collection and management, as well as analysis and reporting through the utilization of specific platforms such as Power BI preferred.   \n  Experience with R or similar data analysis software a plus. \n \n \n  Language Skills:  English language fluency. Fluency in additional languages (Dari, Pashtu, Arabic, Spanish, French, German) preferred. \n \n  Working Environment:   \n \n A combination of standard office environment and remote work depending on location \n  Occasional domestic (non-local) travel required; up to 10%. \n  May require occasional weekend and/or evening work. \n \n \n  Compensation:  Posted pay ranges apply to US-based candidates. Ranges are based on various factors including the labor market, job type, internal equity, and budget. Exact offers are calibrated by work location, individual candidate experience and skills relative to the defined job requirements. \n  Commitment to Diversity and Inclusivity:  IRC is committed to building a diverse organization and a climate of inclusivity. We strongly encourage applications from candidates who can demonstrate that they can contribute to this goal.     Gender Equality:  IRC is committed to narrowing the gender gap in leadership positions. We offer benefits that provide an enabling environment for women to participate in our workforce including parental leave, gender-sensitive security protocols and other supportive benefits and allowances. \n  Professional Standards:  The IRC and IRC staff must adhere to the values and principles outlined in IRC Way \u2013 Global Standards for Professional Conduct. These are Integrity, Service, Equality and Accountability. In accordance with these values, the IRC operates and enforces policies on Beneficiary Protection from Exploitation and Abuse, Child Safeguarding, Anti-Workplace Harassment, Fiscal Integrity, and Anti-Retaliation. \n  Equal Opportunity Employer:  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. \n  US Benefits:  We offer a comprehensive and highly competitive set of benefits. In the US, these include: 10 sick days, 10 US holidays, 20-25 paid time off days (depending on role and tenure), medical insurance starting at $145 per month, dental starting at $7 per month, and vision starting at $5 per month, FSA for healthcare, childcare, and commuter costs, a 403b retirement savings plans with up to 4.5% immediately vested matching contribution, plus a 3-7% base IRC contribution (3 year vesting), disability & life insurance, and an Employee Assistance Program which is available to our staff and their families to support counseling and care in times of crisis and mental health struggles. \n \n  #LI-JT1 \n  #LI-Remote"}, "d227b7a96b4dd3fc": {"terms": ["data science", "data engineer"], "salary_min": 102926.234, "salary_max": 130327.55, "title": "Data Engineer", "company": "ArchWell Health", "desc": "ArchWell Health is a new, innovative healthcare provider devoted to improving the lives of our senior members. We deliver best-in-class care at comfortable, accessible neighborhood clinics where seniors can feel at home and become part of a vibrant, wellness-focused community. Our members experience greater continuity of care, as well as the comfort of knowing they will be treated with respect by people who genuinely care about them, their families, and their communities. \n \n \n Duties/Responsibilities: \n \n \n Build data integrations from internal and external sources to centralize data into a Data Warehouse environment. \n Monitor data integration operations, data quality, troubleshoot, and resolve problems. \n Profile data sources and map to target table formats. \n Develop and monitor data quality processes and address problems. \n Develop, unit test and system test integration components. \n Create support documentation describing the functionality of the integrations. \n Participating in technical design & requirements gathering meetings. \n Participate in planning and implementing data integration and data migration activities. \n Perform QA tests to ensure data integrity and quality. \n Research data issues between source systems and the data warehouse. \n \n Required Skills/Experience: \n \n \n Bachelor\u2019s degree required; Master's degree (in data science, computer science or MIS, mathematics, engineering, or related field) preferred. \n 5+ years of prior experience in Data Management / ETL / ELT / Data Warehousing \n Experience in writing Data Quality routines for cleansing of data and capturing confidence score \n Experience with master data management \n Strong knowledge of Structured Query Language (SQL) and Transact-SQL (T-SQL) \n Experience using scripting languages such as JavaScript or Python \n Experience Healthcare data models, datasets, and source systems (e.g. EHR, claims, labs, etc.) \n Experience with healthcare reference data (ICD, CPT etc.) \n Experience with agile delivery methodologies \n Data Modeling experience preferred. \n Strong organizational, administrative, and analytical skills required. \n Experience managing and working in cloud environments such as Amazon Web Services or Azure \n Knowledge of HIPAA; ability to implement systems and processes in accordance with regulations \n Excellent interpersonal communication skills, both written and verbal \n  ArchWell Health is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to their race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other protected classification."}, "0d3da72661178a5c": {"terms": ["data science", "machine learning engineer"], "salary_min": 80269.375, "salary_max": 101638.92, "title": "Analytics Engineer", "company": "EquipmentShare", "desc": "EquipmentShare is Hiring an Analytics Engineer \n  EquipmentShare is searching for an Analytics Engineer to join our team. This position is fully remote. \n  What You'll Do as an Analytics Engineer \n  Despite having been fundamentally altered by earlier industrial revolutions, the construction industry has hardly budged with the computer revolution. In fact, since 1970, labor productivity in the US construction industry has actually declined, despite it more than doubling in the rest of the economy. This has contributed to housing shortages and the parlous state of infrastructure in some places, and is sanding the gears of carbon reduction efforts. \n  We think the industry is ripe for change, and we're pushing the leading edge of that change with our next generation T3 Platform, the OS for Construction. Through T3, we help contractors to coordinate humans and (increasingly smarter) machines to build more effectively. \n  As an Analytics Engineer in our small and quickly growing team, you will play a major role in this effort. In particular, you will: \n \n Establish sound pipelines and clear table structures for a wide variety of metrics used by both the business analytics and data science / ML engineering parts of the organization \n Work closely with the rest of the Data Science & Analytics Platform team to enable cutting edge algorithms, causal inference and analytics within a fast-moving environment, while adhering to industry best practices in terms of data access, security, traceability, etc \n \n About You as an Analytics Engineer \n  Our mission is to change an entire industry, so we only hire people inspired by the goal and up for the challenge. In turn, our employees have every opportunity to grow with us, achieve personal and professional success and enjoy making a tangible difference in a crucial industry for human welfare. \n  Minimum Qualifications for an Analytics Engineer \n \n Undergraduate degree, or equivalent practical experience, in computer science, machine learning, software engineering, statistics or related field \n 2+ years working on technology-powered products as either a data platform engineer, data engineer, ML engineer, analytics engineer or a closely related role \n Experience with data modeling: specifically the creation of dimensional models and fact tables (Data Vault experience not necessary but would be a plus) \n Demonstrated understanding of the techniques and methods of modern product development \n Demonstrated understanding of business analytics \n \n \n Strong cross-functional communication skills \n Must be qualified to work in the United States or the United Kingdom - we are not sponsoring any candidates at this time \n \n Why We're a Better Place to Work \n \n Competitive compensation packages \n 401 (k) and company match \n Health insurance and medical coverage benefits \n Unlimited paid time off \n Generous paid parental leave \n Volunteering and local charity initiatives that help you nurture and grow the communities you call home \n Opportunities for career and professional development with conferences, events, seminars, continued education \n State of the art onsite gym (Corporate HQ)/Gym stipend for remote employees \n \n Since our incorporation in 2015, we've had incredible growth \u2014 and we're not stopping anytime soon. Ready to invest in our mission, invest in yourself and discover a better place to work? Then, we'd love to meet you. \n  At EquipmentShare, it's more than just a job \u2014 it's a calling.  Apply today. \n  EquipmentShare is committed to a diverse and inclusive workplace. EquipmentShare is an equal opportunity   employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation,   protected veteran status, disability, age, or other legally protected status. \n  #LI-Remote"}, "2df2b3d73adead14": {"terms": ["data science"], "salary_min": 93419.23, "salary_max": 118289.555, "title": "Customer Experience Engineer", "company": "Amperon", "desc": "The Company You'll Join \n  Amperon is the leading analytics and forecasting company for the energy transition. Our platform leverages advanced algorithms and machine learning techniques to accurately forecast energy demand on both the supply (power & utilities companies) and demand (large energy users) sides of the market. We incorporate real-time data feeds that help our clients reduce cost, monitor energy efficiency while increasing substantially. \n  We bring the brightest mind from energy, security and technology in order to combat climate changes and transition to clean energy solutions. We have offices in Texas but are a remote first company. \n  Our Mission \n  As the electricity grid faces challenges due to renewables, EVs, climate change, and more, there's a desperate need for an upgrade. Amperon's blend of energy expertise and AI technology offers analytics and forecasting software to improve grid reliability and accelerate decarbonization. We're building the next generation of market-leading energy analytics and forecasting products, and we want you to be part of our journey! \n  The team you'll work with \n  The Customer Engineering (CEN) Team operates within the greater Amperon product framework to develop software and processes that center individual customers and their success. We execute customer-specific work such as deployments and custom reporting, we create monitoring tools and alerts that give product and engineering a pro-active understanding of how our product is serving our customers, and we build tools that simplify deployment so that we can scale more easily. We are a newly formed team so this individual will have the opportunity to drive tooling and infrastructure adaptation. \n  The impact \n  We have a direct impact on Amperon's ability to achieve its scale goals. Our success will be felt in the revenue side of the house as well as in product and engineering. As we continue to scale, our team will be on the forefront of new product development and customer enhancements. \n  The problems you'll solve \n \n Refactoring code that runs daily to deliver our product correctly. \n How to efficiently collaborate with Data Science in order to isolate and trace Data Science issues. \n Build verification, testing and monitoring into our product. \n Work on accommodating antiquated unrepeatable customer-specific systems while continuously focusing on scalability. \n Building dashboards, tooling and alerts to provide insights into customer usage. \n \n You may be a fit for this role if \n  Senior level experience in a technical customer-facing role. Experience in software engineering with a focus on customer analytics. Experience with Python and database management. Experience supporting various engineering teams with a focus on data science and data engineering. Understanding how technical decisions impact the users of what we are building. \n  Perks \n  While we are serious about our company's culture, we aren't going to force \"culture\" to prove that we are cool and fun. It's a company filled with smart, genuinely nice individuals who are passionate about data science, energy and working together to build a product that can have a lasting impact on our planet. \n  Even though we are a remote company with employees spread across the globe, we still believe human interaction is a good thing. We will also have an all-company event at least once a year so people can get to know each other in a more fun and social way. \n \n Competitive salary \n Health insurance \n Monthly gym membership stipend \n Pre-tax commuter benefits \n 401k \n Stock options \n Flexible work hours \n Remote \n \n  If you are excited about contributing to a product that can have a lasting impact on our planet and you thrive in fast-paced, innovative environments, we would love to hear from you."}, "f0d2749b9f5be743": {"terms": ["data science", "machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Job description: \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n j9SsS2R75b"}, "6814a6c2b2790ba4": {"terms": ["data science"], "salary_min": 175000.0, "salary_max": 240000.0, "title": "VP of Marketing", "company": "Appriss Retail", "desc": "VP of Marketing \n  Reports to: Chief Revenue Officer   \n Department: Marketing   \n Supervisory Duties: Yes   \n Travel Required: Yes, up to 10% \n  Location: Remote \n \n \n Company Overview \n  Leveraging more than 20 years of data science expertise, Appriss\u00ae Retail is the data science company transforming ecommerce and omnichannel consumer interactions by providing real-time, actionable recommendations that reduce fraud, drive efficiency, and maximize profitability. Our AI-driven, SaaS platform generates analytical insights and recommendations for a global base of leading retailers in more than 150,000 physical and online locations in 45 countries across six continents \n \n \n Overview \n \n The VP of Marketing reports directly to the Chief Revenue Officer and is responsible for managing the execution of the Marketing strategy for the company and will manage a team of marketing resources who support the effort associated with the strategy execution. They need to be able to develop both the high-level strategy and the detailed execution plans associated with Brand and Product Marketing. They need to be able to think outside the box and find creative and unique resolutions to challenges faced by Appriss Retail customers. They need to have a strong command of the Appriss Retail customer; the industry segments these customers reside in and how our products meet the needs of the customer. The leader also needs to have aptitude in all marketing disciplines to be able to drive the strategy and execution plans across the team. They need to be able to lead and mentor team members and provide ongoing feedback to the team. \n   \n Responsibilities \n \n The leader will need to be both strategic and tactical, driving the direction for the business and the team, but also being able to complete tactical tasks as necessary.  \n Responsible for setting strategy for the Appriss Retail brand, brand and product collateral, communications, events, social and digital presence, and demand generation.  \n Working with the team to support the development, maintenance, and execution of the Appriss Retail communication theme calendar, including developing overarching strategies for specific marketing vehicles \u2013 e.g., social/digital, web, blog, etc.  \n Working with the Revenue Generation and Product leaders to define the marketing plans for the year across all marketing disciplines.  \n Support team members in the coordination of external vendors and partners across the marketing disciplines.  \n Report on operational metrics of the marketing team on a regular basis.  \n Develop and implement OKRs that align with the organizational goals.  \n Provide both formal and informal reviews and feedback to team members. \n \n Qualifications \n \n 10+ years broad marketing experience, preferably in the Retail Industry, Bachelor's Degree preferred and 6+ years of team leadership/management.  \n Excellent writing, editing, and communication skills.  \n Superb relationship skills, with the ability to work within all levels of an organization.  \n Be comfortable in an ever-changing environment.  \n Proven experience managing and growing a team across marketing functions.  \n Track record of managing large, complex projects and/or programs.  \n Broad knowledge of all Appriss Retail products and services.  \n Exceptional listening skills with the ability to ascertain unspoken needs.  \n Critical thinking and problem-solving skills.  \n Hubspot experience required.  \n Work effectively remotely, but able to travel throughout the year. \n \n Preferred Qualifications \n \n  Salesforce CRM experience. \n \n  Physical Demands  - Sedentary  \n Benefits   \n Appriss Retail offers competitive benefits including medical, dental, and vision coverage. We offer an immediate vesting 401(k) plan with employer matching, unlimited paid time off for salaried employees, and well-being support including gym reimbursements, a subscription to Calm \u2013 Meditation and Sleep app, and paid leave for new parents and family care. As a hybrid global community, we also offer a remote work-first environment empowering our people to work wherever suits their lifestyle."}, "70189378044e8964": {"terms": ["data science"], "salary_min": 120675.25, "salary_max": 152801.75, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n xg8ZxPLYtq"}, "23e2dc1bb0bb3616": {"terms": ["data science", "machine learning engineer"], "salary_min": 93300.0, "salary_max": 212000.0, "title": "Generative AI Engineer, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         McLean,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0180741\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Generative AI Engineer, Senior\n           The Opportunity: \n  As an experienced engineer, you know that machine learning (ML) is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using ML techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support a variety of high-impact missions across sectors and domains. As an ML engineer, you\u2019ll build pipelines to train, test, deploy, and maintain models that learn from data. \n \n  In this role, you\u2019ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You\u2019ll be part of a large community of ML engineers across the firm and collaborate with data engineers, data scientists, software engineers, solutions architects, and product owners to deliver world class solutions to real world problems, processing data and information at a massive scale, developing pipelines that optimize the use of infrastructure, and integrating critical technologies into efficient user experiences. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. \n \n  Work with us to solve real-world challenges and define ML strategy for our firm and our clients. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with artificial intelligence, data science, ML engineering, data research, or data analytics \n  Experience with Generative AI, including transformers or LLM project work \n  Experience with Huggingface, LangChain, AutoGPT, or AgentGPT \n  Experience with software and artificial intelligence projects \n  Experience with a programming language, including Python, Scala, or Java \n  Experience with project work in deep learning, computer vision, NLP, or signal processing \n  Knowledge of modern software design patterns, including microservice design or edge computing \n  Ability to obtain a security clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with embedded systems programming in C, C++, or Rust \n  Experience with GPU programming, including CUDA or RAPIDs \n  Experience with modern Cloud computing technologies, including Docker and Kubernetes \n  Ability to gather requirements from customers and lead Agile teams \n  Master's degree in CS or Statistics \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law."}, "b22b62768c3294e5": {"terms": ["data science"], "salary_min": 107934.48, "salary_max": 136669.1, "title": "Associate Manager, Global Market Analytics & Insights", "company": "Olympus Corporation of the Americas", "desc": "Workplace Flexibility:  Field \n  Are you looking for a company that cares about people\u2019s lives and health, including yours? Let\u2019s inspire healthier lives, together. \n \n  Olympus, a leading medical technology company, has focused on making people\u2019s lives better for over 100 years. \n  Our Purpose is to make people\u2019s lives healthier, safer, and more fulfilling. \n \n  Our Core Values are reflected in all we do:   Integrity \u2013 Empathy \u2013 Agility \u2013 Unity \u2013 Long-Term View \n \n  We deliver on our purpose and our core values by staying  True to Life. \n \n \n \n  Job Description \n \n \n  The Associate Manager, Global Market Analytics & Insights will reside within the Global Market Analytics & Center of Excellence function, part of the overall Global Market Intelligence & Customer Insights & Analytics (GMCI&A) team. The candidate will collaborate with stakeholders both within GMCI&A and across Olympus businesses to define data and analytical needs, establish standardized process and plan, and provide analytics and actionable insights to support Therapeutic Solution Division (TSD), Endoscopic Solution Division (ESD), regional and Corporate functions. This position is highly visible to different levels of management. The candidate should possess strong expertise in data analysis including advanced level of analytical techniques, with the ability to not only synthesize complex data but also articulate critical analysis and actionable insights to help stakeholders to answer the most challenging business questions. It is expected that this role will develop strategic partnership with leaders within GMCI&A and across the entire enterprise including Business Units, Marketing, Business Development, Sales, Health Economics, Finance, and other areas. The candidate will also be a self-starter and comfortable with ambiguity in a fast-paced matrix working environment. \n \n \n \n \n  Job Duties \n \n \n \n  Engage with GMCI&A team leaders and global business stakeholders to identify strategic needs where data and analytics can drive business value and transform business problems into analytical solutions. \n  Lead the development and implementation of analytical projects to support both GMCI&A and cross functional strategic initiatives and business goals. \n  Develop global market models, conduct analysis on market drivers and mix, and carry out benchmarking, forecasting, and other business analysis. \n  Develop assessments and analytical insights on global market and competitive landscape, social and economic trends, provider trends, global and regional dynamics. \n  Support IR, business planning, business development, marketing and other strategic initiatives with market sizing development, opportunity identification, and market and competitive assessments. \n  Conduct analytics on customer segmentation, journey mapping, value proposition, persona to support product and marketing initiatives. \n  Carry out economic research and financial analysis on cost, revenue, margin, value and outcomes. \n  Translate data and analytics into actionable insights and effectively communicate key findings and strategic recommendations to different levels of stakeholders globally. \n  Partner with data analyst, Health Economics, Finance, IT and other resources to support integrated global data initiatives including needs identification, database development, standardization, governance, and management. \n  Collaborate with data analysts and other analytical resources on the team to standardize analytical models, KPIs, metrics, and foundational and strategic analytical reporting. \n  Oversee the development and implementation of dashboard, self-service reporting, and portal to support both GMCI&A and business stakeholders. \n  Lead the definition and implementation of standard processes and advanced analytical and visualization tools including automation and optimization. \n  Build strategic partnerships across global Olympus business units and functions with the Global Market, Competitive & Customer Intelligence (MCCI) team in GMCI&A to uncover synergies, drive efficiencies, and standardize best practices. \n  Performs all other duties as assigned. \n \n \n \n \n \n  Job Qualifications \n \n \n  Required: \n \n  Bachelor\u2019s degree in data science, analytics, mathematics, engineering, finance, economics, or related disciplines; Advanced degree a plus. \n  Minimum of 5 years of experience in business analysis, business intelligence, market/customer intelligence, consulting, strategy, or equivalent area; preferably in the healthcare, medical device, or life sciences \n  Minimum of 2 years of hands-on experience in advanced analytics including working knowledge on SQL, Python or R, statistical analysis, and data visualization tools such as Power BI or Tableau. \n  Minimum of 2 years project management experience in leading analytical projects across multiple teams \n  Advanced Excel and financial analysis skills \n  Primary market research experience preferred. \n  Travel <10% (domestic and international). \n \n \n  #LI-Remote \n \n \n \n  Why join Olympus? \n  Here, people matter\u2014our health, our happiness, and our lives. \n \n  Competitive salaries, annual bonus and 401(k)* with company match \n  Comprehensive Medical, Dental, Visions coverage effective on start date \n  24/7 Employee Assistance Program \n  Free virtual live and on-demand wellness classes \n  Work-life balance supportive culture with hybrid and remote roles \n  12 Paid Holidays \n  Educational Assistance \n  Parental Leave and Adoption Assistance \n  Volunteering and charitable donation match programs \n  Diversity & Inclusion Programs including Colleague Affinity Networks \n  On-Site Child Daycare, Caf\u00e9, Fitness Center** \n \n \n US Only \n \n  **Limited locations \n   \n We care about your health and financial well-being and offer the resources you need to feel vital, confident and ready for wherever life takes you. Learn more about our benefit offerings at https://www.olympusamerica.com/careers/benefits-perks. \n \n  About us: \n  Our Medical business uses innovative capabilities in medical technology, therapeutic intervention, and precision manufacturing to help healthcare professionals deliver diagnostic, therapeutic, and minimally invasive procedures to improve clinical outcomes, reduce costs, and enhance the quality of life for patients and their safety. \n \n  Headquartered in Tokyo, Japan, Olympus employs more than 31,000 employees worldwide in nearly 40 countries and regions. Olympus Corporation of the Americas, a wholly owned subsidiary of Olympus Corporation, is headquartered in Center Valley, Pennsylvania, USA, and employs more than 5,200 employees throughout locations in North and South America. For more information, visit www.olympusamerica.com. \n \n  Olympus is dedicated to building a diverse, inclusive and authentic workplace \n  We recognize diversity in people, views and lifestyle choices and emphasize the importance of inclusion and mutual respect. We strive to continue to foster empathy and unity in the workplace so that our employees can fully contribute and thrive. \n \n  Let\u2019s realize your potential, together. \n  It is the policy of Olympus to extend equal employment and advancement opportunity to all applicants and employees without regard to race, color, national origin (including language use restrictions), citizenship status, religious creed (including dress and grooming practices), age, sex (including pregnancy, childbirth, breastfeeding, medical conditions related to pregnancy, childbirth and/or breastfeeding), gender, gender identity and expression, sexual orientation, marital status, disability (physical or mental) and/or a medical condition, genetic information, ancestry, veteran status or service in the uniformed services, and any other characteristic protected by applicable federal, state or local law. \n \n  Posting Notes: || United States (US) || Massachusetts (US-MA) || Westborough ||"}, "08580a7a73bf60fb": {"terms": ["data science"], "salary_min": 87537.836, "salary_max": 110842.414, "title": "Sr. Statistician (Healthcare) (Remote, Full-time)", "company": "Integrity Management Services, Inc.", "desc": "Integrity Management Services, Inc. (IntegrityM) is a woman-owned small business specializing in assisting government healthcare organizations prevent and detect fraud and abuse in their programs. \n  At IntegrityM, we offer a culture of opportunity, recognition, and collaboration. We thrive off of these fundamental elements that make IntegrityM a great place to work. We offer the flexibility our employees need to challenge themselves and focus on advancing their professional development and careers. Large company perks. Small company feel. \n  http://www.integritym.com \n \n  We are now seeking a Sr. Statistician to join our team. This position will be responsible for supporting fraud, waste and abuse (FWA) study development and execution activities in a multi-payer environment. The team member will have advanced statistical skills and the ability to analyze healthcare claims across Medicare, Medicaid and private payers. The statistician will be responsible for creating, reviewing, and maintaining statistical analysis plans, providing data interpretation and generating reports. These duties will be performed in support of FWA studies using administrative healthcare data. \n \n \n Role and Responsibilities  \n \n Assist with study design and develop statistical plans for data analysis in support of proposed research questions \n Develop statistical tests for FWA modeling results and provide predictive analytic statistical support \n Prepare timelines for statistical project management and performs and interprets basic and complex analyses.  \n Utilizes knowledge of statistical methods and medical understanding to propose and perform additional analyses when appropriate \n Documents analyses, creates summaries and presents written and verbal results for FWA study reports \n Provides quality review on statistical analysis plan to ensure consistency with protocol and adequacy to meet objectives defined in protocol \n Effectively communicate statistical concepts to non-statisticians (managers, researchers in other fields, etc.). \n Serve as a statistical expert consultant for assigned research and FWA studies using healthcare claims data and other healthcare data sources \n Support programmers to identify potential data problems from analytic queries and to take appropriate action to guide the resolution process \n Exceptional problem-solving abilities, accuracy with work, strong organizational skills, attention to detail and the ability to multi-task while meeting deadlines \n Excellent communication skills, both written and verbal, and especially the ability to communicate data clearly to clients \n Ability to work in a fast-paced, team-oriented environment with minimal supervision \n \n Requirements \n \n Master\u2019s Degree in Statistics or related field \n Possesses a minimum of 3 years of data analysis experience within the healthcare industry.  \n Superior skills conducting statistical and mathematical modeling and analysis using SAS \n Advanced skills for modeling and data manipulation purposes \n Excellent problem solving, quantitative and analytical skills \n Advanced risk analytics and predictive modeling skills \n \n Desired Skills and Experience : \n \n Ability to make complex decisions and recommendations under limited direction and using high degree of initiative and independent judgment \n Experience with various outlier detection methods and clustering techniques \n Experience conducting health care related statistical analysis and intimately familiar with healthcare institutional claims (UB 04 claim form) \n Superior multi-tasking and organization skills. Must manage multiple simultaneous projects and prioritize assignments and tasks accordingly, remaining flexible to changing priorities and new initiatives \n \n \n Experience working with healthcare administrative data across Medicare, Medicaid, commercial as well as third party data assets"}, "b0bc7efaf93327d4": {"terms": ["data science"], "salary_min": 177578.75, "salary_max": 224854.25, "title": "Sr. Director, Marketing", "company": "Infor", "desc": "General information \n       \n \n \n \n \n \n \n        Country \n        \n United States  \n \n \n \n        State \n        \n New York  \n \n \n \n        City \n        \n Remote Location  \n \n \n \n        Department \n        \n Marketing  \n \n \n \n        Job ID \n        \n 36574  \n \n \n \n \n \n \n \n \n \n       Description & Requirements \n       \n \n \n \n \n \n \n To catapult Infor\u2019s growth ambition, we are seeking a strategy-to-execution oriented Solution Marketing expert to help position Infor\u2019s business applications, data & technology capabilities, and vast ecosystem of integrations to create breakthrough category disruption in the market. Reporting to the VP of Solution Marketing, this key role will partner closely with Product Management, Customer Success, Services, Sales and GTM teams to deliver on our vision. This is a unique opportunity for an experienced leader to own a domain and contribute directly to Infor\u2019s growth objectives, delivering measurable outcomes.   \n \n A Day in The Life Typically Includes: \n \n  Product Mastery and Storytelling: Own messaging, positioning, and narrative for specific verticals to elevate product features & capabilities to customer outcomes and business benefits, including suite/cross-portfolio level, business applications, integrations, data & technology/platform, industry benchmarking. \n  Become the competitive authority by gathering, analyzing and sharing competitive information to shape Infor\u2019s positioning in the market on why we win.  \n Value Creation: Develop clear, compelling industry and simplified value propositions, based on challenges and solutions that resonate with customers and prospects. \n  Product Influence: Collaborate closely with industry-specific product and engineering teams to provide direction in shaping product vision and roadmaps. Lead development of content and assets to support bi-annual product release launches (April, October). \n  Leveraging Partnerships: Develop joint value propositions for key technology partnerships, including AWS, and share impactful customer stories. \n  Sales Enablement: Own core solution marketing bill of materials for field and partner enablement, including aligned measures of success. \n  GTM Success: Partner with Product, Enablement, Sales and GTM teams to deliver sales plays and campaigns to drive pipeline. \n  Marketing Strategy and Execution: Partner across Marketing to develop thought leadership, improve Infor positioning in analyst relations evaluations, marquee customer references. Develop solution experience & content for events, hosted and 3rd party tradeshows. Own digital experience outcomes for product pages on Infor.com, with accountability for conversion rate optimization and lead generation. \n \n  Basic Qualifications: \n \n  Experience leading product marketing teams at B2B business application software. \n  Domain expereince in one of the following industries: Industrial Manufacturing, Distribution, Food & Beverage, Fashion, Automotive, Aerospace & Defense or Healthcare. \n  Cloud/SaaS product marketing domain experience. \n  Data-driven focused, experience leveraging qualitative and quantitative voice of the customer insights to inform solution marketing strategy.  \n Experience in category creation, portfolio positioning, product re-naming, packaging, pricing, sales play development. \n  Experience collaborating among Sales, Product, GTM, Presales, Customer Success, Industry Strategists, Enablement teams, etc.  \n Understanding of product release readiness and product development lifecycle with the ability to forge Marketing partnership with Product and GTM teams. \n \n \n  Preferred Qualifications: \n \n  Bachelor\u2019s degree \n  Experience in enterprise Cloud/SaaS preferred: industry applications, ERP, PLM, HCM, WFM, WMS, MES, etc. \n \n \n \n \n \n \n \n \n \n         About Infor\n         \n \n \n  Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.\n         \n \n          For more information visit www.infor.com\n         \n \n \n \n \n \n \n \n         Our Values\n         \n \n \n  At Infor, we strive for an environment that is founded on a business philosophy called Principle Based Management\u2122 (PBM\u2122) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization. Increasing diversity is important to reflect our markets, customers, partners, and communities we serve in now and in the future.\n         \n \n \n  We have a relentless commitment to a culture based on PBM. Informed by the principles that allow a free and open society to flourish, PBM\u2122 prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.\n         \n \n \n  Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law.\n          \n \n \n \n \n         At Infor we value your privacy that\u2019s why we created a policy that you can read here.\n         \n \n \n \n \n \n \n \n \n         This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf"}, "3daa48e5df7ec6d9": {"terms": ["data science"], "salary_min": 143298.78, "salary_max": 181448.19, "title": "Azure Gov. Platform Engineer - REMOTE - Government and Public Sector", "company": "EY", "desc": "EY focuses on high-ethical standards and integrity among its employees and expects all candidates to demonstrate these qualities. At EY, you\u2019ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we\u2019re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.\n  \n \n  From strategy to execution, the Government & Public Sector (GPS) practice of Ernst & Young LLP provides a full range of consulting and audit services to help our Federal, State, Local and Education clients implement new ideas to help achieve their mission outcomes. We deliver real change and measurable results through our diverse, high-performing teams, quality work at the highest professional standards, operational know-how from across our global organization, and creative and bold ideas that drive innovation. We enable our government clients to achieve their mission of protecting the nation and serving the people; increasing public safety; improving healthcare for our military, veterans and citizens; delivering essential public services; and helping those in need. EY is ready to help our government build a better working world. \n   \n Our GPS Technology Organization is a structure within the US GPS practice that implements and maintains a new operate and technology model designed specifically to support U.S. defense and Government engagements. \n \n  The opportunity \n \n  This is a remote opportunity that can be performed within Continental United States. \n \n  You will be responsible for leading delivery of solutions and infrastructure development efforts, establishing automated and frictionless consumption capabilities for cloud platforms supporting large and complex projects. You are expected to have strong design and hands-on development experience on Azure cloud automation and CI/CD for enterprise. You are expected to bridge organizations where core capabilities are developed and support evolution of cloud capabilities in Azure Gov without technical debt. You will be expected to fully understand business and user requirements, ensuring design specifications are meeting the business requirements. You will also support junior engineers and work in a collaborative environment, exercising your creativity and innovation. \n \n  Your key responsibilities \n \n \n \n  Architect, engineer and automate platform solutions to meet and exceed expectations of Product Managers \n  Proactively evolve and apply DevSecOps methodologies, standards and leading practices \n  Apply modern development standards/principles, global product-specific guidelines, security standards, usability design standards, as appropriate. \n  Ensure quality through use of manual and automated controls. \n  A desire to automate everything and the wisdom to know when not to. \n  Identify, communicate and mitigate Risks, Assumptions, Issues and Decisions throughout full lifecycle \n  Using critical thinking, consider the art of the possible, compare various options based on feasibility and impact, propose impactful plans and roadmaps that balance tactical and strategic needs \n  Experience of build and deploy (CI/CV), tools (Git VSC, Gradle, Jenkins, Azure DevOps Server, Ansible tower) and processes \n \n \n  Skills and attributes for success \n \n \n \n  Can document and design various processes; can update existing processes \n  Can improve practices for infrastructure development and application development \n  Follow all best practices and procedures as established by the company \n  Advanced knowledge of one or more of: Bash, Linux, PowerShell as well as scripting languages (I.e. Ansible) \n \n \n  To qualify for the role, you must have \n \n \n \n  Bachelor\u2019s degree in computer science, IT, or equivalent work experience \n  More than 5 years in an engineering or architecture role using service and hosting solutions such as private/public cloud IaaS, PaaS, and SaaS platforms. \n  Ability to obtain and maintain Top Secret security clearance level. \n  5+ years functional knowledge of programming scripting and data science languages such as Bash, PowerShell, Puppet, SQL, etc. \n  5+ years CI/CD delivery using code management, configuration management and automation tools such as GitHub AE, Terraform, Bicep, Azure DevOps Server, Ansible, DSC, Puppet, ARM Templates etc. \n  Experience in the following: Azure Stack, Azure AD \n  Experience with hardened OS images such as CIS STIG images. \n  Windows Server Administration: You need to be proficient in managing Windows servers to create, manage and deploy Group Policy Objects. \n  Knowledge/experience with Linux server administration \n  Significant relevant proven experience required, demonstrating solid understanding of relevant software infrastructure platforms (depending on specialism) and understanding of applicable standards. \n  Experience with any claims-based authentication (SAML/OAuth/OIDC) and RBAC. \n  Knowledge of cloud security controls including tenant isolation, encryption at rest, encryption in transit, key management, vulnerability assessments, application firewalls, SIEM, etc. \n  Delivery using modern methodologies especially SAFe Agile, Iterative, etc. \n  Experienced with Development frameworks such as Scrum and Kanban \n  Communicate fluently in English, both written and verbal \n  Excellent interpersonal communication and organizational skills to give as a leading member of global, distributed teams passionate about delivering quality solutions \n  Inspire DevSecOps teams by building consensus and mediating compromises when necessary \n  Demonstrate excellent engineering & automation skills in the context of cloud based global delivery using continuous integration (CI) and continuous deployment (CD) \n  Rapidly learn new and emerging technologies with ability to rapidly define engineering standards and produce automation code \n \n \n  Ideally, you\u2019ll also have \n \n  Experience and knowledge in: \n \n \n \n  Source control Management (git) \n  Azure cloud experience/knowledge \n  Scripting (PowerShell or Python) \n  Azure DevOps Pipelines \n  Agile methodology \n  Containers \n  Ansible(Tower)/Terraform/Bicep \n  AZ400 Certified Preferred \n  Azure Policy \n  Azure Multi-Tenant Knowledge \n \n \n  What we look for \n \n \n \n  A self-starter, independent-thinker, curious and creative person with ambition and passion \n  History of continuous learning and continuous progression \n \n \n \n \n  What we offer \n \n \n \n \n   We offer a comprehensive compensation and benefits package where you\u2019ll be rewarded based on your performance and recognized for the value you bring to the business. The salary range for this job in most geographic locations in the US is $83,000 to $150,700. The salary range for New York City Metro Area, Washington State and California (excluding Sacramento) is $99,600 to $171,200. Individual salaries within those ranges are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and geography. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Under our flexible vacation policy, you\u2019ll decide how much vacation time you need based on your own personal circumstances. You\u2019ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, financial, and emotional well-being.\n  \n \n \n \n  Continuous learning:  You\u2019ll develop the mindset and skills to navigate whatever comes next. \n  Success as defined by you:  We\u2019ll provide the tools and flexibility, so you can make a meaningful impact, your way. \n  Transformative leadership:  We\u2019ll give you the insights, coaching and confidence to be the leader the world needs. \n  Diverse and inclusive culture:  You\u2019ll be embraced for who you are and empowered to use your voice to help others find theirs. \n \n \n \n \n  If you can demonstrate that you meet the criteria above, please contact us as soon as possible. \n \n \n \n \n  The exceptional EY experience. It\u2019s yours to build. \n \n \n  EY | Building a better working world \n \n \n \n \n   EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.\n  \n \n \n \n   Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.\n  \n \n \n \n   Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.\n  \n \n \n \n   EY is an equal opportunity, affirmative action employer providing equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law.\n  \n \n \n \n   EY is committed to providing reasonable accommodation to individuals with disabilities. If you are a qualified individual with a disability and either need assistance applying online or need to request an accommodation during the interview process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY\u2019s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com."}, "4eea8f1f0c5242c4": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "AI Research Engineer Sr", "company": "Lockheed Martin", "desc": "Job ID:  643191BR \n  \n Date posted:  Jul. 18, 2023\n  \n \n Description: When it comes to using cutting-edge machine learning to tackle complex problems, Lockheed Martin is driven by a singular mission focus and desire to continuously innovate. Today's challenges to global security aren't just changing - they're accelerating faster than ever before. Through our dedication to our mission, our AI-enabled systems are changing the way militaries operate and protect their forces, the way first responders fight fires, and how researchers explore the far reaches of space and the ocean's depths.The Lockheed Martin Artificial Intelligence Center (LAIC) team is seeking a high energy individual with a strong working knowledge in software engineering, artificial intelligence and machine learning to support the AI Integration team and product portfolio, focusing on the Beacon program. The team is focused on creating portable microservices to enable JADC2.The selected candidate will focus on the development of technologies and products that leverage Artificial Intelligence to provide discriminating capability to our customers. This will require engagement in every phase of the system development lifecycle including requirements generation, system and software design, implementation, integration, and flight test. Activities will range from low TRL research, proof of concepts, development of prototypes, building demonstrators, and transition to production. The selected candidate can expect to lead the development leveraging current AI paradigms including computer vision, deep learning, and reinforcement learning, applying these techniques to solve complex problems and field innovative solutions. The candidate may also be expected assume technical lead responsibilities and mentor junior engineers.Must exhibit self-motivation, a strong work ethic, time management and interpersonal skills.The selected candidate can potentially work at any major Lockheed Martin facility or remotely.\n  \n \n \n 50% travel, can work from any LM site / remote \n \n  Basic Qualifications: \n \n \n Bachelor's Degree in Engineering, Computer from an accredited college in a related discipline, or equivalent experience, with 5 years of professional experience; or 3 years of professional experience with a related master's degree. \n Experience using AI/ML frameworks (Pytorch, Tensorflow, etc.) \n Experience with Python libraries (NumPy, OpenCV, Scikit, Pandas, etc.) \n Experience providing best practices and design principles in all program technologies and implementing them across product teams \n Experience with Python, Java, C++, GO, and other compiled languages \n Experience with DevOps tools: Docker, Git [GitLab, GitHub], Continuous Integration [CI], Continuous Deployment [CD] \n Experience with network/messaging (gRPC, ActiveMQ, RESTful API, etc.) \n Experience authoring schema specifications including at least protobuf and openapi \n Experience developing applications on Linux \n Experience writing Dockerfiles, Helm and Kubernetes deployment scripts and templates \n Active Secret security clearance with the ability to obtain and maintain TS/SCI \n \n  Desired Skills: \n \n \n Experience working with Agile methodologies \n Experience interfacing with databases (SQL, MongoDB, etc.) \n Experience with high-performance computing \n Experience with managing Kubernetes container orchestration platforms including Rancher, OpenShift, k3s, Kubeadm \n Familiarity with cloud platform management and provisioning including AWS GovCloud and Microsoft Azure \n Strong communicator and active participant in team communication channels such as Slack/Email \n \n  Security Clearance Statement:  This position requires a government security clearance, you must be a US Citizen for consideration.\n  \n Clearance Level:  TS/SCI\n  \n Other Important Information You Should Know \n \n Expression of Interest:  By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.\n  \n Ability to Work Remotely:  Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.\n  \n Work Schedules:  Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.\n  \n Schedule for this Position:  4x10 hour day, 3 days off per week\n  \n Pay Rate: \n  The annual base salary range for this position in Colorado or Washington is $100,900 - $193,300. Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.\n  \n \n Benefits offered:  Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.\n   (Washington state applicants only) Non-represented full time employees: accrue 10 hours per month of Paid Time Off (PTO); receive 40 hours of Granted PTO annually for incidental absences; receive at least 90 hours for holidays. Represented full time employees accrue 6.67 hours of PTO per month; accrue up to 52 hours of sick leave annually; receive at least 96 hours for holidays. PTO is prorated based on hours worked and start date during the calendar year.\n  \n  This position is incentive plan eligible.\n  \n Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. \n  At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work. \n  \n  With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.\n  \n  If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications.\n  \n Experience Level:  Experienced Professional\n  \n Business Unit:  ENTERPRISE BUSINESS SERVICES\n  \n Relocation Available:  Possible\n  \n Career Area:  Systems Architect\n  \n Type:  Full-Time\n  \n Shift:  First"}, "8bc10294f02c2fb8": {"terms": ["data analyst"], "salary_min": 33989.98, "salary_max": 43038.887, "title": "Data Entry Analyst", "company": "Carley Corporation", "desc": "JOB TITLE:   Courseware Data Specialist (Data Entry Analyst)  \n LOCATION:   Onsite and/or Remote  \n STATUS:   Full-time; Hourly, Non-exempt (Temporary; 3 month to 1 year project) \n   \n ABOUT CARLEY:  Headquartered in Orlando, Florida, Carley Corporation is an employee-owned small business specializing in analyzing, designing, developing, and implementing large-scale, complex blended training solutions where performance results are critical. We strive to deliver the highest quality and cost-effective solutions for all our customers. Carley provides products and services within the full spectrum of training system requirements. This includes training devices, SCORM-conformant web-based training, instructor-led training, advanced electronic classrooms, and PC-based simulations for technical skills and soft skills training. Carley Corporation is an ISO 9001:2015 certified business.  \n Carley is seeking to hire a dedicated Data Entry Clerk that would be responsible for coordinating with program management and the courseware development team in sequencing, editing, testing, and correcting errors in courseware content. \n   \n DAILY AND WEEKLY RESPONSIBILITIES INCLUDE:  \n \n Arrange and copy courseware data/content in specified sequence. \n Update courseware data files. \n Examine, audit, and test courseware for discrepancies throughout the courseware development life cycle. \n Notify programmers and graphic artists of errors and track errors until closed. \n Complete assigned tasks and ensure they are technically correct, thoroughly self-checked for quality control, meet the requirements of the contract, and are submitted according to the agreed-upon schedule. \n Communicate and coordinate with management, team leads, graphic artists, and courseware programmers. \n Complete other duties and tasks as assigned and needed. \n \n EDUCATION, EXPERIENCE, AND QUALIFICATIONS:   \n \n An AA/AS degree in Technical Communications, Education, Instructional Technology, Journalism, English, Industrial/Organizational (I/O) Psychology, or a related field. Additional relevant experience may be considered in lieu of degree if applicable and or allowed under assigned contract \u2013 PREFERRED. \n A high school diploma or equivalent - REQUIRED. \n Strong verbal and written communication skills - REQUIRED. \n Hands-on, detail-oriented skills to produce high-quality, accurate work \u2013 REQUIRED. \n Proficiency in Microsoft Word, Excel, and PowerPoint \u2013 REQUIRED. \n Able to work in a fast-paced, team-oriented environment - REQUIRED. \n Due to the nature of the work at Carley, this position requires U.S. citizenship -REQUIRED. \n Carley Corporation requires all employees to be fully vaccinated upon hire or be eligible for a legal accommodation under ADA or Title VII \u2013 REQUIRED. \n Must be a legal resident in a state in which Carley is registered to perform services (see list below) \u2013 REQUIRED . \n Employees living 50 miles or less of the Corporate Office will be deemed as local and must have the ability and means to support onsite hours \u2013 REQUIRED. \n Must be a legal resident of a state in which the Carley Corporation is registered to perform services (see list below)\u2013 REQUIRED. \n \n STATES WE ARE REGISTERED IN:  Alabama, Arkansas, Colorado, Connecticut, Delaware, Florida, Georgia, Iowa, Illinois, Kentucky, Maryland, Ohio, Pennsylvania, North Carolina, South Carolina, Tennessee, Texas, Virginia, and Washington. \n \n   \n \n \n SOME OF OUR EMPLOYEE BENEFITS INCLUDE:  \n \n \n Medical \n Dental \n Vision \n 401k Retirement Plans \n ESOP (Employee Stock Ownership) \n HSA (Health Savings Account) \n FSA (Flexible Spending Account) \n Life & Disability \n Accident Plans \n Critical Care Plans \n Cancer Insurance \n Legal & ID Theft Protection \n EAP (Employee Assistance Program) \n Tuition Reimbursement \n Employee Life Recognition Bonuses  \n Employee Referral Program \n \n   \n Have any questions about Carley, the job, or the benefits?  Contact our HR team at AskHR@carleycorp.com and we\u2019d be happy to assist you! Otherwise, head over to complete our application process and start your new career today! \n \n \n  To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed above represent some but not all the knowledge, skill, and ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n  Carley Corporation is an Equal Employment Opportunity (EEO) employer. The company\u2019s policy is to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information."}, "d95e348314a1d91c": {"terms": ["data analyst"], "salary_min": 51485.0, "salary_max": 64356.0, "title": "Data Analyst II", "company": "Computershare", "desc": "Location: US Colorado (Remote)  \n We\u2019re committed to your flexibility and wellbeing. As part of our global team, you\u2019ll be working with colleagues across different time zones and so your working pattern will be a collaboration between you and your manager. Find out more about our culture of flexible working.. Find out more about our culture of flexible working .   \n \n We Give You A World of Potential  \n Before we tell you more about the role, it\u2019s important for you to know a few things about the department that make this such a great place to work, as well as Computershare as a whole.  \n \n Loan Administration is the division with Computershare Loan Services responsible for loan boarding, special loans, mail room, customer support and escrow. The Data Analyst II manages the intake and review of loan transfer data and performs the tasks necessary to convert data from seller servicers onto SLS\u2019s platform.  \n We offer fantastic career development and put a lot of time into training and qualifications to ensure the continuous development of the team.  \n \n So, now that you know this is a tremendous department in a company that truly supports their employees, I\u2019m sure you\u2019ll want to find out more about the role and what you\u2019ll be involved in.   \n \n A role you will love  \n The Data Analyst II identifies potential gaps or errors in data and working with internal and external contacts to resolve identified concerns. You will also be responsible for providing mentorship and training to new analysts, drafting, and updating procedure documents, and providing feedback and support for improvement processes.  \n Some of your key responsibilities will include:  \n \n Interact with prior servicers and investors regarding SLS transfer requirements, data discrepancies, missing data, files/images, and timelines for servicing transfers. Communicate and coordinate with other business units to resolve these discrepancies and loan level reviews within deadlines. Follow-up on outstanding items through resolution.  \n Perform data analysis by using specific tools to identify discrepancies which need further review or explanation. Determine the best course of action to resolve the discrepancy dependent on the severity of the issue, loan product, lien position and loan status.  \n Analyse data so that it can be accurately mapped into a pre-boarding system utilizing proprietary programs, Microsoft Excel, and Microsoft Access. Upload data into the SLS servicing platform, by using specific tools.  \n Support company policies, procedures, decisions, and objectives. Work effectively in a team environment, and effectively communicate with team members and management.  Other duties or tasks as assigned by management. \n  \n \n What will you bring to the role?  \n As you\u2019ve probably gathered by now, we are looking for somebody that has the ability to bring people together to work collaboratively, define objectives, and influence leadership to get the best outcome. To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.  \n We are looking for people with these skills:  \n \n High school diploma or GED (Required)  \n Minimum of 4+ years of mortgage industry experience in loan boarding, underwriting or data analysis.  \n Subject matter expert on the data conversion business processes.  \n Excellent process improvement and project management skills.  \n Advanced Microsoft Excel and Access skills.  \n Detail-oriented and focused.  \n Strong proactive problem solving and analytical skills.  \n Ability to handle multiple priorities, meet fluctuating deadlines and demonstrate strong multi-tasking abilities.  \n Ability to work independently effectively.  \n Exceptional communication skills (verbal and written).  \n Exceptional organizational and time management skills.  \n Ability to work effectively in a high-volume environment.  Ability to perform training as needed. \n  \n \n Rewards designed for you   \n \n Parental Leave.  We offer paid parental leave, flexible working and a caring and inclusive culture.  \n Health and Wellbeing.  Our health and wellbeing rewards can be tailored to support you and your family, even your pets. These include medical, dental, vision and a wellness reimbursement.  \n Paid time away from work.  Our employees enjoy a competitive paid time off package, including a day each year to volunteer time for a good cause that is important to you.  \n Save for your future.  We will support you along your retirement savings journey with 401k matching and tax-advantaged flexible spending plans that include healthcare, dependent care and commuter.  \n Income protection.  To ease concerns when the unexpected occurs our package includes short and long-term disability benefits, life insurance, supplemental life insurance (single/spouse/family) and more.  \n Employee Share Plan.  Set aside salary to purchase shares in our company and you\u2019ll increase your investment when you receive a generous company contribution towards additional shares.  \n Extra Rewards.  From tuition reimbursement to cash bonus recruitment referral programs, our comprehensive benefits package offers a multitude of options.  \n Compensation.  The base pay range for this role is $51,485- $64,356. This base pay range is specific to Colorado and may not be applicable to other locations. \n \n \n \n \n A company to be proud of   \n \n \n \n  Computershare (ASX:CPU) is a world leader in financial administration with 14,000+ employees across 22 different countries delivering expertise to over 25,000+ clients. At Computershare, it\u2019s more than just a job, our open and inclusive culture means that we will help you to grow, to move forward and make the most of the world of opportunities we have available. With infinite possibilities, we could take you anywhere.\n   \n \n \n \n A diverse and inclusive place to work   \n \n \n \n  Computershare celebrates the diversity of our people, and we welcome applications from everyone. We believe that having a culture of inclusion is essential in delivering good results. Attracting, retaining, and developing a diverse workforce where employees feel valued, respected, and empowered allows people to reach their full potential. As a business this diversity helps us to better reflect and understand our customers\u2019 needs to allow us to drive better outcomes.\n   \n \n \n \n  We are happy to accommodate individual needs during your application journey. If you require disability accommodations or adjustments, please email us at TalentAcquisition@computershare.com detailing your requirements and contact information.\n   \n \n \n \n  Computershare is an equal opportunity employer. Qualified applicants will receive consideration for employment regardless of race, color, religion, sex, sexual orientation, gender identity or expression, national or ethnic origin, age, disability, protected veteran status, or other characteristics protected by applicable law."}, "d7a7bc35f886aa9f": {"terms": ["data analyst"], "salary_min": 33.65, "salary_max": 33.65, "title": "Business Analyst", "company": "EXL Services", "desc": "Company Overview and Culture \n \n EXL (NASDAQ:  EXLS) is a global analytics and digital solutions company that partners with clients to improve business outcomes and unlock growth. Bringing together deep domain expertise with robust data, powerful analytics, cloud, and AI, we create agile, scalable solutions and execute complex operations for the world\u2019s leading corporations in industries including insurance, healthcare, banking and financial services, media, and retail, among others. Focused on creating value from data for driving faster decision-making and transforming operating models, EXL was founded on the core values of innovation, collaboration, excellence, integrity and respect. Headquartered in New York, our team is over 40,000 strong, with more than 50 offices spanning six continents. For information, visit www.exlservice.com. \n \n  For the past 20 years, EXL has worked as a strategic partner and won awards in its approach to helping its clients solve business challenges such as digital transformation, improving customer experience, streamlining business operations, taking products to market faster, improving corporate finance, building models to become compliant more quickly with new regulations, turning volumes of data into business opportunities, creating new channels for growth and better adapting to change. The business operates within four business units: Insurance, Health, Analytics, and Emerging businesses. \n \n  Looking for Business Analyst. \n \n  EEO/Minorities/Females/Vets/Disabilities \n \n \n Base Salary Range Disclaimer:  The base salary range represents the low and high end of the EXL base salary range for this position. Actual salaries will vary depending on factors including but not limited to: location and experience. The base salary range listed is just one component of EXL's total compensation package for employees. Other rewards may include bonuses, as well as a Paid Time Off policy, and many region specific benefits. \n \n  Please also note that the data shared through the job application will be stored and processed by EXL in accordance with the EXL Privacy Policy. \n \n  Application & Interview Impersonation Warning \u2013 Purposely impersonating another individual when applying and / or participating in an interview in order to obtain employment with EXL Service Holdings, Inc. (the \u201cCompany\u201d) for yourself or for the other individual is a crime. We have implemented measures to deter and to uncover such unlawful conduct. If the Company identifies such fraudulent conduct, it will result in, as applicable, the application being rejected, an offer (if made) being rescinded, or termination of employment as well as possible legal action against the impersonator(s). \n \n  EXL may use artificial intelligence to create insights on how your candidate information matches the requirements of the job for which you applied. While AI may be used in the recruiting process, all final decisions in the recruiting and hiring process will be taken by the recruiting and hiring teams after considering a candidate\u2019s full profile. As a candidate, you can choose to opt out of this artificial intelligence screening process. Your decision to opt out will not negatively impact your opportunity for employment with EXL."}, "48d27e0a8786f42a": {"terms": ["data analyst"], "salary_min": 63000.0, "salary_max": 88000.0, "title": "Data Visualization Analyst", "company": "JJR Solutions, LLC", "desc": "Are you a strategic thinker skilled at solving complex challenges? Are you looked at as an expert in your field? Are you confident in your ability to advise and recommend solutions to leaders? \n  If this sounds like you, we've got the perfect job! \n  We are looking for candidates who like analyzing, thinking through, and solving complex challenges. You will be trusted to share your insights and recommendations with clients to inform their organizational, strategic, and programmatic initiatives. You will be surrounded by a team of other Rock Stars! \n  Why you should work with us. \n  First and foremost, we care deeply about every member of our JJR family and as a company, we are inspired by something greater than ourselves. Second you will play a vital role in building lasting partnerships with clients to advance their performance and create high-impact, meaningful value. Finally, culture is kind of our thing; we are committed to the well-being of each employee. \n  Need proof? It\u2019s in the pudding. Here are what people are saying! \n \n  \u201cJJR is one of the best companies I have worked with (for) in the past 20+ years.\u201d \u2013 Anonymous employee feedback from internal engagement surveys \n  \u201cI feel JJR does a very good job of hiring people who will work well in the group dynamic - people who share the same work ethic and values, which makes for working together to be much easier and more enjoyable.\u201d \u2013 Anonymous employee feedback from internal engagement surveys \n \n  We value feedback, but we think you should come see for yourself! \n  You in? Here are the details. \n  Title : Data Visualization Analyst \n  Location : Dayton, OH, Hybrid Work \n  Classification : Salary, Exempt \n  Travel : 10% \n  Security Requirement:  Must provide favorable background check and National Agency Check with Inquiries (NACI) \n  Position Expectations: \n \n  Perform all required responsibilities and duties in accordance with JJR\u2019s Handbook and job description. \n  Actively engage in your role, make informed decisions, be accountable for all outcomes, and be a positive influence for JJR. \n  Deliver exceptional service to internal and external clients, partners, teammates. \n \n  Duties: \n \n  Collects, studies, and analyzes data to inform and determine suggested courses of action. \n  Performs studies such as analysis of alternatives and return on investment. \n  Prepares documentation including reports, papers, and presentation for clients. \n  Maintains knowledge and applies advanced technical principles, theories, and concepts. \n  Design efficient databases and workbooks needed to support program-specific dashboards as needed. \n  Create data flow maps, process guides, and other support documents that describe collection, archiving, management, and retrieval processes for program evaluation data. \n  Create data visualization tools for data and metrics reporting using administrative medical records data, other VA administrative data, and curated data sets within the VA Suicide Prevention Program Office. \n  Develop a user-friendly and visually appealing reporting interface in Microsoft Power BI; work with other Power BI Developers to build and design a high-profile reporting dashboard for our VA clients. \n  Deploy and maintain dashboards and linkages to other dashboards and databases. \n  Provide ongoing support and management of the dashboard once completed. \n  Generate reports to communicate key Government owned data to internal and external audiences. \n  Create presentations and reports for VHA executive leadership. \n  Additional duties as assigned. \n \n  Required Education, Experience, & Skills: \n \n  Bachelor's Degree in Business, Computer Science, Healthcare Administration or related field. \n  2-4 years of experience. \n  Proficiency with MS Office. \n  Experience with SQL. \n  Experience with SAS. \n  Experience creating dashboard visuals to relay information. \n  Ability to provide exceptional client service, research and resolve issues, and demonstrated commitment to continuous learning. \n  Ability to work effectively in a team environment with all levels of client personnel in various industries. \n  JJR may choose to substitute education with relevant experience. \n \n  Preferred Education, Experience, & Skills: \n \n  Experience with modeling and cleansing data for use within Microsoft Power BI reporting and dashboards. \n  Experience with other Power Platform tools. \n  Healthcare data experience. \n  Experience in Veterans Affairs Hospitals or other Government entities. \n \n  TOTAL COMPENSATION PACKAGE \n  Salary:  In accordance with various state and federal pay transparency regulations, as well as best industry practices, our job descriptions include the salary range we reasonably expect to pay those joining our team, contingent upon little to no training being required. A final salary is subject to a number of factors, including but not limited to the following: years of experience, education, certification(s), training, specialized skills, responsibilities, etc. \n  The range of pay for this position is $63,000-$88,000. \n  Core Benefits:  Medical, Dental, Vision, 401K, Monthly $200 HSA Match, Complimentary $50k Basic Life and AD&D (eligible employees), STD, Complimentary LTD, AFLAC Coverage, etc. \n  PTO, Flexible Schedule, and Holidays:  Employees receive a robust amount of PTO along with flexible/hybrid working schedules and additional support for new parents. JJR also observes a total of 11 paid federal holidays annually, including: New Year's Day, President's Day, 4th of July, Veterans Day, Christmas, Martin Luther King Jr. Day, Memorial Day, Juneteenth, Labor Day, Thanksgiving, and Columbus Day. \n  Professional Development + Continued Education Support:  We believe employees at all levels benefit from continued growth and learning. As such, JJR is committed to paying the entirety of the cost for job-related certifications and/or training programs as well as contributing towards job-related higher-level education. \n  EEO Statement \n  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n  Disclaimer \n  This description in no way implies that the duties listed here are the only ones the employee can be required to perform. The employee is expected to perform other tasks as dictated by their supervisor or JJR leadership."}, "ee10d3c238f29e79": {"terms": ["data analyst"], "salary_min": 87465.0, "salary_max": 113190.0, "title": "Credit Card Underwriting Data Analyst", "company": "U.S. Bank National Association", "desc": "At U.S. Bank, we\u2019re on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at\u2014all from Day One. \n \n  Job Description \n  As a Credit Card Underwriting Data Analyst, you will play a crucial role in ensuring that our credit card underwriting processes are efficient, accurate, and in line with industry best practices. You will be responsible for analyzing data related to credit card limits, identifying trends, and producing reports that support the underwriting team. \n \n \n  Basic Qualifications \n \n \n Bachelor's degree in a related field, or equivalent work experience \n Four to five years of statistical and/or data analytics experience \n \n \n \n \n  Preferred Skills/Experience \n \n \n Experience in analytics, advanced analytics/statistics, predictive modeling \n Strong analytic skills with the ability to extract, collect, organize, analyze and interpret trends or patterns in complex data sets \n Demonstrated project management skills \n Effective interpersonal, verbal and written communication skills \n \n \n \n Three to four years' experience in data analysis using SaS and Tableau \n Attention to detail and the ability to work independently \n \n \n  This role is remote anywhere  within the U.S. Bank footprint. \n  #USBOps #TPSS \n \n  If there\u2019s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants. \n \n  Benefits: \n  Our approach to benefits and total rewards considers our team members\u2019 whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours): \n \n  Healthcare (medical, dental, vision) \n  Basic term and optional term life insurance \n  Short-term and long-term disability \n  Pregnancy disability and parental leave \n  401(k) and employer-funded retirement plan \n  Paid vacation (from two to five weeks depending on salary grade and tenure) \n  Up to 11 paid holiday opportunities \n  Adoption assistance \n  Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law \n \n \n  EEO is the Law \n  U.S. Bank is an equal opportunity employer committed to creating a diverse workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors. \n \n  E-Verify \n  U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services. \n  The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, US Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401k contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $87,465.00 - $102,900.00 - $113,190.00\n   U.S. Bank will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance."}, "aa11102475dc52c7": {"terms": ["data analyst"], "salary_min": 79644.875, "salary_max": 100848.16, "title": "Data Analyst", "company": "Summer", "desc": "Who We Are \n \n Summer is a Certified B Corp\u00ae with a mission to maximize savings for the 46 million Americans burdened by student debt. Summer combines policy expertise with innovative tech to help borrowers track their loans across multiple lenders and enroll them in the best loan assistance programs\u2013\u2013saving borrowers an average of $30,000. Watch our product demo and hear from borrowers on how Summer has put them on the path to becoming debt free. \n  Summer has raised $20 million to date from world-class investors, including QED Investors, General Catalyst, Greycroft, Foundation Capital, Story Ventures, NextView, Flourish Ventures, and the Financial Health Network. We've partnered with dozens of clients who pay for Summer to assist their employees and customers, including the city government of Alexandria, Virginia, the American Federation of Teachers, the American Diabetes Association, Asurion, Mattress Firm, Credit Karma, and more. \n \n Your Role \n  Summer is hiring a Data Analyst to power insights across the entire company. Data lies at the core of our loan algorithms as well as our business decisions, and this position will involve cross-team collaboration to transform data into actionable strategies. In this role, you will have the opportunity to: \n \n Architect and build frameworks and tools to enable data-driven decisions \n Segment student loan borrowers to understand motivations and use cases \n Support calculations for loan repayment scenario modeling \n Proactively identify patterns in user behavior that inform product opportunities \n Work closely with marketing team to optimize our acquisition funnel \n Collaborate with engineering team to maintain consistent data collection across web, app and API sources \n Champion an experimentation culture that rapidly tests, measures and iterates \n Build dashboards that enable data democratization and empower teammates to monitor key metrics \n Have a direct and profound effect on a data-driven organization that is breaking down barriers to higher education \n \n Recommended Experience \n  To be successful in this role, we are seeking a teammate with the following: \n \n Degree in a quantitative field and 3+ years of experience in data analytics \n Understanding of A/B testing methodologies \n Experience with statistical analyses and data visualization \n Strong SQL skills and knowledge of relational databases \n Experience in Python or other scripting languages \n Proficiency with business intelligence tools \n Startup and/or finance experience are a plus \n \n Finally, we are excited to work with teammates who are equally passionate about applying their talents to tackle a major social issue of our time. \n \n Values + Benefits \n  We're proud to be a mission-driven company with an inclusive culture. Our greatest asset is the set of values our team strives to embody every day: empathy, diversity, growth, determination, humility, and fun. Learn more about culture at Summer: www.meetsummer.org/post/summer-a-fintech-powered-by-people-built-for-impact \n  We also offer competitive salaries, significant equity allocations, healthcare coverage, 401(k) plans with an employer match, contribution toward student loan repayment, and flexible vacation/PTO. Summer supports a hybrid, flexible work environment and we welcome applicants from anywhere in the United States. \n  Sound interesting? We look forward to hearing from you. Join us to help fix the system! \n \n \n  -\n  \n \n Summer provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training."}, "9c4e280b943b42d0": {"terms": ["data analyst"], "salary_min": 69572.86, "salary_max": 88094.734, "title": "Business Intelligence Analyst", "company": "Montgomery County Community College", "desc": "Business Intelligence Analyst \n \n \n Position reports to Director of Analytics and Business Intelligence \n \n \n FLSA Status: Exempt \n \n \n This position is open until filled \n \n \n Application review beginning October 15, 2023 \n \n \n \n \n This position has been approved for a fully remote arrangement with occasional on-campus meetings. Employees are required to live in PA, NJ, \n or DE, as well as attend Opening Day and Commencement. The College will reimburse travel expenses not included in events for those residing more than 100 miles from campus location(s). This fully remote arrangement is in effect until August 31, 2024; however, the College will re-evaluate in February 2024 for the possibility of continuation for September 1, 2024 through August 31, 2025 as well as annually thereafter. \n \n \n Flexible work options can be ended  \n at any time \n  by the College, Cabinet, and/or supervisors based on employee performance and/or as institutional needs change. \n \n \n \n \n BASIC PURPOSE: \n \n \n   The Business Intelligence Analyst will assist in the development and maintenance of an integrated business intelligence platform that supports all College analytical and reporting requirements. This position is within the Information Technology department and will collaborate with other college departments in gathering requirements and delivering solutions related to business intelligence, data analytics, and operational reporting. In working across the College, the individual will promote data analysis and reporting that permits operational efficiencies or better-informed business decisions. The Business Intelligence Analyst will contribute to the development of dashboards and reports that support the strategic goals and mission of the College.\n   \n \n \n \n ESSENTIAL DUTIES AND RESPONSIBILITIES: \n \n \n Serve as a liaison between the Information Technology department and all other college departments in the gathering of business requirements related to Business Intelligence and Data Analytics projects. \n Develop dashboards and reports that measure KPIs and assist with decision-making within different departments across the College. \n Write complex SQL queries to pull data from various data sources for reporting. \n Support end users by conducting training and developing documentation on how to create and maintain their reports within the analytical and reporting systems. \n Identify opportunities through analytics and reporting that promote operational efficiencies and support the College\u2019s commitment to data-based decision making. \n Promote data governance across the institution through the use and maintenance of data catalogs, data dictionaries, and other administrative documentation. \n Work with external stakeholders to provide data and analytics, as needed.  \n Participate in resolving support tickets related to BI or reporting systems or output. \n Other duties as assigned. \n \n \n \n \n \n ESSENTIAL KNOWLEDGE AND SKILLS: \n \n \n Education/Training/Work Experience:  \n \n \n Bachelor's degree from an accredited four-year college or university required. Degree in mathematics, computer science, business, or related field preferred. \n \n \n \n \n \n Specialized Knowledge & Skills: \n \n \n Understanding of relational databases and experience with SQL, required. \n Experience with data analytic tools and data visualization software, including Power BI preferred. \n Experience in quantitative data analysis and interpretation preferred. \n Familiarity with predictive analytics and forecasting preferred. \n Experience within higher education or with the Ellucian Colleague Information System is preferred. \n Ability to effectively present information and respond to questions from groups of managers, customers, and external sources. \n Understanding of security issues involved in maintaining and safeguarding institutional data. \n Appreciation for serving the needs of a diverse population. \n Perform with a high degree of accuracy, attention to detail and problem solving, with minimal oversight. \n Proficient in the use of MS Excel, Word, Outlook, PowerPoint. \n Strong written and oral communication skills. \n Ability to work in a team-oriented, collaborative environment. \n \n \n \n \n   Montgomery County Community College (MCCC) has a strong institutional commitment to diversity and is dedicated to excellence through diversity in education and employment. MCCC, an EEO Employer, provides equal employment and educational opportunities to all who are qualified. In keeping with the College\u2019s diversity initiative, MCCC seeks and welcomes applications from diverse candidates, those who have had multicultural experience, and those who can demonstrate a commitment to diversity."}, "8e9b302cf467f2fc": {"terms": ["data analyst"], "salary_min": 5167.0, "salary_max": 8463.0, "title": "Senior Data Analyst", "company": "Health & Human Services Comm", "desc": "The Data Support Analyst (Data Analyst IV) is selected by and reports to the Director of Statistical Analytics and Data Visualization. The position performs complex (journey-level) data analysis and data research work in support of investigative and audit functions for the Office of the Inspector General (OIG). Work involves supporting in the design, development, implementation, and maintenance of the OIG Tableau dashboards. The Tableau dashboards are used to track and monitor performance, work products, workload metrics of the OIG organization, and potential fraud, waste, and abuse activities. The Data Support Analyst is also responsible for performing advanced-level programming to clean, prepare, and query large, complex datasets, to maintain algorithms that identify data trends, patterns, and anomalies, and to support the data and statistical analytics. This position prepares written methodology documents; communicates data analytics findings through data visualizations and presentations; and tests and evaluates new tools, methods, and techniques. Works under limited supervision, with moderate latitude for the use of initiative and independent judgment. \n      *** This position can telework 100% from locations within Texas consistent with HHS telework policies. ***\n     \n \n \n \n \n \n \n \n Essential Job Functions: \n  Responsible for supporting in the design, development, implementation, and maintenance of the OIG Tableau dashboards. Duties include, but not limited to, support and maintain software integration between Tableau and other in-house business application, regular review, cleanup, management and configuration of Tableau data, content, and dashboards, and troubleshoot and provide user support for Tableau dashboards. (40%) \n      Plans and conducts data and statistical analysis on large, complex datasets using SAS and SQL to identify data trends, patterns, and anomalies in response to requests from data operation, investigators, and auditors. Creates, maintains, and updates SAS coding in support of all OIG operational and analytical dashboards and provider analysis. (30%) \n     \n  Effectively communicates verbally and in writing statistical research analysis reports and findings to internal and external entities. Creates data visualization/graphics, statistical analysis, sample analysis and performs custom analyses on requests. Peer reviews the work products of the analysts assigned to the team (25%) \n     \n  Performs other duties necessary to achieve the mission of the Office of the Inspector General. Statewide travel of about 5% may be required. Keeps manager informed as required or as necessary. (5%)\n     \n \n \n \n \n \n \n \n \n Knowledge Skills Abilities: \n \n Knowledge of statistics and analyzing data sets; of running queries, report writing, and presenting findings; of data models, database design development, data mining, and segmentation techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data.  \n \n Knowledge of programming skill in SAS, SQL, Python or R, or other data science programming languages (SAS and SQL preferred).  \n \n Knowledge of Tableau.  \n \n Knowledge of Windows operation systems, as well as SQL Server, Power BI, PowerShell, and Office 365.  \n \n Skill in verbal and written communication skills essential to effectively interacting with OIG customers, leadership, and team members.  \n \n Skill in the use of a computer and applicable software, in analyzing problems and devising effective solutions, in conducting data searches, in evaluating and translating large amounts of data, and in critical thinking.  \n \n Skill in Excel and PowerPoint.  \n \n Skill in time management and task prioritization abilities  \n \n Ability to solve complex software and data issues.  \n \n Ability to pay attention to detail and strong in organizational skills  \n \n Ability to be flexible to changing project assignments, requirements, deadlines, and projects.  \n \n Ability to compile, review, and analyze data; to prepare reports; to maintain accuracy and attention to detail; and to communicate effectively.  \n \n \n \n \n \n \n Registration or Licensure Requirements: \n  Graduation from an accredited four-year college or university with major coursework in data science, business analytics, healthcare analytics, computer science, computer information systems, management information systems, accounting, finance, mathematics, statistics, economics, or a related field is required. At least 1 year of experience in SAS, SQL, Python or R for large scale data preparation and analysis required. Experience in SAS and Tableau is preferred. \n    \n \n \n \n \n \n \n Initial Selection Criteria: \n  Graduation from an accredited four-year college or university with major coursework in data science, business analytics, healthcare analytics, computer science, computer information systems, management information systems, accounting, finance, mathematics, statistics, economics, or a related field is required. At least 1 year of experience in SAS and/or SQL for large scale data preparation and analysis required. Experience in SAS programming and/or in designing and developing dashboards using Tableau is preferred.\n     \n \n \n \n \n \n \n \n \n Additional Information: \n  Additional Information: A copy of college transcript will be required. \n     \n  The OIG is responsible for preventing, detecting, auditing, inspecting, reviewing, and investigating fraud, waste, and abuse in the provision of HHS in Medicaid and other HHS programs. Potential employees of OIG are subject to criminal background checks in accordance with the HHS Human Resources policy. Selected applicants must complete a national fingerprint-based criminal background check through the Texas Department of Public Safety (TDPS) and Federal Bureau of Investigations (FBI) to determine if they have criminal history record information that constitutes a bar to employment. \n     \n  OIG will request that all applicants considered for an interview provide responses to essay questions. Failure to respond to the request could disqualify an applicant from the interview process. \n     \n  Any employment offer is contingent upon available budgeted funds. The offered salary will be determined in accordance with budgetary limits and the requirements of HHSC Human Resources Manual. \n     \n  HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work. ? \n     \n  In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888\u2014894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview. \n     \n  Note: For more information see the Texas State Auditor\u2019s Military Crosswalk at http://www.hr.sao.state.tx.us/Compensation/JobDescriptions.aspx.\n     \n \n \n \n \n \n \n MOS Code: \n  noon\n     \n \n \n \n \n \n Top 10 Tips for Success when Applying to Jobs at HHSC and DSHS \n \n \n \n \n \n \n HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work. \n \n \n In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview."}, "23dcbc6f47a7efc7": {"terms": ["data analyst"], "salary_min": 94031.83, "salary_max": 119065.25, "title": "Data Analyst 4723", "company": "MetroStar", "desc": "Data Analyst \n  Remote \n  As  Data Analyst , you'll play a pivotal role in extracting valuable insights from complex datasets to inform critical business strategies. Leveraging your five years of experience, you will collaborate with cross-functional teams to drive data-driven solutions, contribute to the development of analytical frameworks, and provide mentorship to junior analysts. Your ability to translate data into actionable recommendations will be crucial in enhancing our [specific department or project] and overall business performance. \n  We know that you can't have great technology services without amazing people. At MetroStar, we are  obsessed  with   our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers. \n  If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below! \n  What you'll do: \n \n Lead the end-to-end data analysis process, from data collection and cleansing to model development and insights generation. \n Collaborate with stakeholders to define clear business objectives and translate them into well-structured analytical plans. \n Develop and maintain advanced analytical models, algorithms, and dashboards to support various business functions. \n Perform exploratory data analysis to uncover trends, patterns, and insights that drive actionable recommendations. \n Design and execute A/B tests to evaluate the effectiveness of different strategies and initiatives. \n Provide mentorship and guidance to junior data analysts, fostering a culture of learning and growth within the team. \n Collaborate with cross-functional teams to integrate data insights into decision-making processes, influencing business strategies and outcomes. \n Present findings and insights to non-technical stakeholders in a clear and compelling manner. \n \n What you'll need to succeed: \n \n Bachelor's degree in a relevant field (e.g., Statistics, Mathematics, Computer Science, Economics). \n Minimum of five years of experience in a data analysis role, with a proven track record of driving actionable insights and impacting business outcomes. \n Proficiency in data manipulation, cleaning, and transformation using languages such as SQL, Python, or R. \n Strong experience with data visualization tools (e.g., Tableau, Power BI) to create meaningful dashboards and reports. \n Solid understanding of statistical analysis, hypothesis testing, and experimental design. \n Previous experience with machine learning techniques and predictive modeling is preferred. \n Excellent problem-solving skills with the ability to translate complex data into clear insights and recommendations. \n Effective communication skills, with the ability to present technical information to non-technical stakeholders. \n Proven experience in leading projects, collaborating with cross-functional teams, and providing mentorship. \n Attention to detail and a strong commitment to data accuracy and integrity. \n \n Like we said,  we are  big fans of our people. That's why  we offer  a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades. \n  Don't meet every single requirement?  \n Studies have shown that women, people of color and the LGBTQ+ community are less likely to apply to jobs unless they meet every single qualification. At MetroStar we are dedicated to building a diverse, inclusive, and authentic culture, so, if you're excited about this role, but your previous experience doesn't align perfectly with every qualification in the job description, we encourage you to go ahead and apply. We pride ourselves on making great matches, and you may be the perfect match for this role or another one we have. Best of luck! \u2013 The MetroStar People & Culture Team \n  What we want you to know: \n  In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. \n  MetroStar Systems is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of MetroStar Systems. \n  Not ready to apply now? \n  Sign up to join our newsletter here."}, "60804983e07807e4": {"terms": ["data analyst"], "salary_min": 55000.0, "salary_max": 60000.0, "title": "HMIS Data Analyst - YHDP", "company": "Institute for Community Alliances", "desc": "POSITION SUMMARY The Institute for Community Alliances (ICA) is a nonprofit organization and a national leader in the administration of Homeless Management Information Systems (HMIS). ICA has administered the Missouri Balance of State HMIS since 2014. The Balance of State Continuum of Care has been selected by HUD to participate in the Youth Homelessness Demonstration Program (YHDP) which is an initiative designed to reduce the number of youth and young adults experiencing homelessness. \n Under the direction of the Manager of Data Analysis & Reporting, the YHDP Data Analyst is responsible for creating and maintaining customized advanced report templates and conducting data review, interpretation, and analysis to support local and statewide planning, performance evaluation and management, and funding/policy decisions. \n The ideal candidate of the HMIS YHDP Data Analyst is grounded in research, evaluation, and data literacy principles. This candidate loves investigating and solving logical problems, thrives on helping others make meaning from data, and understands how data can serve efforts to end homelessness. This candidate can translate technical concepts to plan language and, conversely, listen to what someone wants to know about a dataset and apply technical concepts to build and display it for them. \n This position will be a remote position, but Missouri residency is required.  There will be travel within Missouri to meet with community stakeholders and occasional evening meetings with the Youth Action Board (YAB). \n Candidates MUST submit a Resume and Cover letter explaining how their skills fit the requirements for this position. \n ESSENTIAL JOB FUNCTIONS \n *Evaluation and Analysis \n \n Conduct data analysis to support local, statewide, or regional planning, and performance and program evaluation \n Provide project-specific, agency-level, and CoC-level reports to evaluate the impact of the YHDP initiatives on the CoC as a whole \n Pull custom data and provide on-going evaluation that will inform any needed adjustments to the YHDP Coordinated Community Plan \n Create, publish, and provide narrative interpretation for data visualizations \n \n *Product Development \n \n Create and maintain front-end development of advanced report templates and custom reports for use by ICA and HMIS stakeholders, including participating agencies, Continuums of Care, state and local funders, and other partners \n Respond to requests for advanced custom reporting \n Ensure compliance with federal and state data standards \n Provide project-specific, agency-level, and CoC-level reports to evaluate the impact of the YHDP initiatives on the CoC as a whole \n \n *Product Delivery \n \n Collaborate with project teams and external stakeholders on product design, build, and delivery \n Engage in all portions of product delivery, including quality assurance and user acceptance testing, develop statements of work, and project proposals, as applicable \n With guidance from project team lead, prioritize potential product flaws, feature enhancements, and custom requests in accordance with product delivery plan \n \n *Community Participation and Presentations \n \n Be an active member of the CoC\u2019s YHDP team, using data and programmatic expertise to help programmatic and data workflow decision-making \n Focus on data literacy by working with the Youth Action Board and community to understand the impact of data and how it can support the efforts to house youth and young adults \n \n *The Analyst will be responsible for creating and maintaining report templates and data visualization tools for use by ICA, HMIS Stakeholders, and the broader community. \n \n Facilitate stakeholder decision-making regarding product design \n Present HMIS data to internal and external groups \n \n *Maintain proficient working knowledge of HUD HMIS guidelines and regulations, with an emphasis on YHDP *Provide training to HMIS users related to reports and visualizations created *Provide support to ICA grant applications, as appropriate *Perform other duties as assigned \n MINIMUM QUALIFICATIONS AND REQUIREMENTS \n Experience and Education \n \n Bachelor\u2019s degree from an accredited four-year college or university or equivalent experience or training (Public Policy, Program Evaluation, Urban Planning, Statistics, Social Science) \n Minimum of five years paid experience in a position with a high degree of independence and responsibility \n \n Required Background/Knowledge \n \n Data visualization software and dashboard software (e.g., Tableau, Access) \n Relational and associative database structure \n Knowledge of basic office equipment and technology; excellent computer skills \n Microsoft Office Suite (Word, Excel, Outlook, PowerPoint, etc.) \n Project management principles \n Proficient use of inter- and intra-office communication tools such as email, video conferencing, teleconferencing, GoToMeeting, and similar tools \n \n Preferred Background/Knowledge \n \n SAP BusinessObjects Web Intelligence \n Experience in HMIS software, especially with Wellsky/ServicePoint \n Statistical Analysis software (SPSS, STATA, Matlab, R) \n GIS software \n Previous experience in the social services sector \n \n Demonstrated Skills \n \n Ability to quickly and accurately define problems, collect/review data and draw valid conclusions \n Excellent analytical, decision-making, problem-solving, organization, and time-management skills \n Ability and interest in learning new software reporting and visualization tools \n Ability to translate stakeholders needs into reports and data analysis, and successfully interpret the results of that analysis and reporting to the stakeholders \n Self-motivated with ability to work independently \n Extraordinary attention to detail and accuracy \n Understanding and use of abstract and concrete variables \n Interpreting professional journals, technical procedures, and/or government regulations \n Understanding the evolving role of data and its importance in efforts to address social problems \n Regular, ongoing collaboration in project teams, including with remote staff \n Cooperatively or independently author training and procedural manuals or guidelines \n Ability to work effectively and professionally with people from diverse backgrounds \n Ability to learn quickly, handle multiple tasks simultaneously, anticipate and meet established deadlines, and regularly produce high-quality work products in a deadline-driven environment \n Team player and collaborator with a positive attitude \n \n Physical Requirements \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to successfully perform the essential functions. \n \n Standing \u2013 Approximately less than 1/3 of on-the-job time \n Walking \u2013 Approximately less than 1/3 of on-the-job time \n Sitting \u2013 Approximately greater than 2/3 of on-the-job time \n Reaching with hands and arms \u2013 Approximately between 1/3 and 2/3 of on-the-job time \n Stooping, kneeling, crouching, or crawling \u2013 Approximately less than 1/3 of on-the-job time \n Talking or hearing \u2013 Approximately greater than 2/3 of on-the-job time \n Weight lifted/force exerted \u2013 An average of approximately up to 10 pounds, non-continuously \n Physical requirements listed are primarily applied to ability to lift and move paper supply, files, etc. \n Vision \u2013 Close vision (clear vision at 20 inches or less) \n Driving \u2013 Approximately less than 1/3 of on-the-job time \n \n Other Requirements \n \n A valid driver\u2019s license and proof of current automobile insurance \n \n Travel/Work Schedule \n \n Occasional out-of-state travel for professional conferences/training (generally less than one week for each occurrence) \n Occasional local or in-state travel for community meetings or onsite implementation support \n Schedule may fluctuate based on workload (there may be occasional evening meetings) \n \n Job Type: Full-time \n Pay: $55,000.00 - $60,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible spending account \n Health insurance \n Life insurance \n Paid time off \n Parental leave \n Vision insurance \n \n Compensation package: \n \n Yearly pay \n \n Experience level: \n \n 4 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: Remote"}, "5a109bb7bbcf000b": {"terms": ["data analyst"], "salary_min": 91677.336, "salary_max": 116083.93, "title": "Data Analytics Specialists", "company": "AccelPad", "desc": "We are currently looking for multiple outstanding data analytics specialists. Experience hands-on cloud engineering with Azure and/or AWS, with a major focus on enterprise-level cloud networking. Extensive, hands-on experience with network capacity planning and cost optimized network design, implementation, monitoring, and support at the enterprise level. Email your resume today to hr@accelpad.com with position ID in the subject."}, "4d8a84c74bc9a21c": {"terms": ["data analyst"], "salary_min": 88141.37, "salary_max": 111606.62, "title": "Data Analytics Specialists", "company": "AccelPad", "desc": "We are currently looking for multiple outstanding data analytics specialists. Data visualization, data engineering, and support integration and automation projects using Python/java/PowerBI and REST APIs. Email your resume today to hr@accelpad.com with position ID in the subject."}, "20910234a89ca0e4": {"terms": ["data analyst"], "salary_min": 72828.87, "salary_max": 92217.57, "title": "Claims Business Analyst", "company": "Berkshire Hathaway Direct Insurance Company", "desc": "biBERK, a Berkshire Hathaway company, has been experiencing substantial growth since its start just a few short years ago...and is anticipating even more growth to come! We are an internet-driven company that offers business insurance, such as workers' comp, liability, commercial auto and umbrella policies to small business owners across the country. We are looking for an enthusiastic Claims Business Analyst to join and grow with our team!\n  \n \n  The Claims Business Analyst will be responsible for helping to build and improve the processes that impact customers. You\u2019ll be part transforming the claims experience for internal users and external parties. This is a role for someone interested in growing with us to transform the way the business views itself. You\u2019ll be counted on gather requirements from stakeholders and ensure that they get what they need to move the business forward with attention to detail.\n  \n \n \n   Job Responsibilities\n  \n \n  Communicating and translating requirements for the claims system from management with development teams \n  Helping to identify issue root causes \n  Performing analysis for internal use \n  Training and creating documentation for system use \n  Working with members of the QA group to build test cases/scenarios \n  Helping roadmap project timelines \n \n \n \n   Preferred Knowledge\n  \n \n  Bachelor's degree or higher \n  1+ years experience relevant experience (such as System Analyst, Business Analyst) \n  Insurance claims experience/exposure helpful but not required \n  Strong analytical skills \n  Experience with Agile Processes \n \n \n \n   About biBERK\n  \n \n \n   biBERK is where commercial insurance buyers can obtain coverage for their businesses from insurers of the Berkshire Hathaway group of Insurance Companies, one of the best capitalized insurance groups in the world. Our ultimate parent, Berkshire Hathaway Inc. (berkshirehathaway.com) is a holding company with diversified interests in a host of industries, including insurance, energy, transportation and manufacturing. Most policies issued through \n   \n   biBERK.com\n    will be underwritten by Berkshire Hathaway Direct Insurance Company (\"BHDIC\"), which is an AM Best rated A++ insurer.\n  \n \n   BHDIC is domiciled in Omaha, Nebraska. BHDIC and the team at biBERK are focused on helping small business owners quickly and easily buy affordable insurance directly from a financially strong insurance company they can trust.\n  \n \n   Some Highlights of our Benefits are:\n  \n \n  Training is provided for this position \n  Defined career path for advancement \n  Generous amount of vacation and sick time \n  Closed on all major holidays \n  401K with company match \n  A competitive healthcare package \n  Tuition reimbursement after 6 months of employment \n  Be part of Berkshire Hathaway, one of world's most admired companies"}, "e5489fd2e23bfb72": {"terms": ["data analyst"], "salary_min": 0.0, "salary_max": 57.62, "title": "Sr. Business Analyst with CopperLeaf exp", "company": "App Dynamic Systems LLC", "desc": "Job Description: Client located in San Francisco or San Ramon, CA. Location: Remote 100% Duration: 12 Months Exp \u2013 10yr plus \n ***Gather a lot of data (70 diff data sources to pull from. BA takes what Copperleaf say they want, and investment planning people and figure where to get data and get into CL. Understand data and extractions, transformation, and physical network attributes (transformers, insulators). Job Description \u201cClient\u201d is looking for a Business Analyst focusing on the following: Requirements gathering, data analysis, documentation and supporting Project Manager Work on Migration/integration w/Bentley Electric Operation Asset Management projects Work Electric Load Calculation engineering support projects Documentation of routing/storage to support engineering team SAP work management experience is a MUST (as a user, not backend support) Must have experience with Foundry CopperLeaf Technologies tool exp is must have GIS exp is required (as a user, not backend support) Tools: o PPMC, SAP Work Management, MS Project, MS Excel 4+ years of experience as a Business Analyst required \n Job Type: Contract \n Salary: Up to $57.62 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n Day shift \n \n Work Location: Remote"}, "a355d1d0cda05b05": {"terms": ["data analyst"], "salary_min": 94580.88, "salary_max": 119760.48, "title": "Product Analyst", "company": "Dow Jones", "desc": "Job Description: \n Product Analyst \u2013 OPIS, a Dow Jones Company \n Rockville, MD (remote work available) \n Job Type \n Full Time  \n Your role \n Are you excited by the prospect shaping best-in-class data and analytics products to help solve critical business problems for clients? Do you enjoy being a product expert, understanding the ins and outs of a complex product platform to identify areas for improvement and new functionality to lead to a better experience? Do you thrive in a fast-paced environment, working hard and managing multiple priorities all while having fun?  \n We\u2019re looking for a Product Analyst for the OPIS Retail Fuels Division based in Rockville, MD with remote work flexibility. In this role, you will deliver value to our customers, our organization, and our team by: \n \n Becoming a product expert of the existing OPIS Retail software and analytics products and identifying and driving ways to improve existing and add new functionality to deliver more value to our clients. \n Creating and maintaining user guides, help materials, methodologies, and specifications for OPIS RetailSuite software and analytics products. \n Working with the sales and retail business development teams to translate customer needs and requests into business requirements for the product development teams. \n Working with the UI/UX design team to create mockups of customer development requests for our software and data products. \n Documenting internal processes to optimize workflow and efficiency. \n Periodically attending industry conferences and trade shows as well as client on-site visits in order to understand our clients\u2019 needs, identify trends and competitive offerings in the marketplace, and bring new ideas to drive new revenue streams. You may need to travel up to 10%.  \n \n Your team \n We\u2019re OPIS, a Dow Jones company. We are leaders in information gathering, analysis, and communication. We deliver data, software, analytics, and market intelligence and transparency to the entire downstream energy supply industry.  \n In this role, you will be joining the OPIS Retail team, a high-growth division that is dedicated specifically to providing solutions for the retail fuel marketing industry, with exciting high-profile products just recently launched to market. OPIS Retail team members work with fuel retailers and convenience store operators to provide data, software, and analytics that help them optimize their business operations and run more profitably and efficiently. You\u2019ll also work with other industries that utilize OPIS data, such as connected cars and mobile app/web clients who display OPIS real-time retail fuel prices to consumers when it\u2019s most critical to them \u2013 as they are looking to fill up their vehicles. And in a world where the reliance on fossil fuels is slowly diminishing as we look for cleaner and more sustainable energy options, OPIS is diversifying and future-proofing our business by expanding into clean energy, alternative fuels, and data and analytics for electric vehicles, while still providing world class data and products for the energy that moves us today.  \n Your expertise \n You have \n \n A bachelor\u2019s degree. Business, Marketing, or Product Management degrees are a strong fit for this role. \n Fluency in English, with other languages desirable based on our global customer base. \n Foundational understanding or the desire to learn about the Agile software development methodology, and the role a product owner plays as part of a highly successful development team. \n Data literacy, easily understanding how to interpret and analyze data to help our customers make the best-possible business decisions. \n Flexibility in your schedule, with the occasional early-morning or late-evening meeting with clients and/or colleagues across the globe. \n Excellent technical acuity. Experience with Google Workspace, Azure DevOps, Netsuite (or another CRM software), Adobe Creative Cloud, InVision, and LucidCharts products preferred.  \n \n You are \n \n A dynamic and engaging person, who enjoys building relationships, gaining expertise, and earning trust with our clients. \n Able to translate customer feedback into actionable user stories to better our products and drive value for our entire customer base. \n Excited about software and analytics tools, with a drive to improve the customer experience. \n A creative thinker, bringing outside-the-box ideas to innovate our software and data offerings. \n A self-starter with strong attention to detail. \n Someone who has a strong foundational knowledge of what makes data-driven analytics products invaluable to a customer. \n Extremely organized with solid problem-solving skills, including the ability to manage multiple tasks and deadlines simultaneously in a fast-paced environment \n Able to uncover and decipher complex problems and think outside the box to create solutions. \n Driven by the desire to help others succeed.  \n \n What we Offer \n \n A modern working environment, with flexible hours and your choice of office or remote work options (or a combination of both.) \n A comprehensive benefits package, including medical, dental, and vision coverage, 401K with company match, generous time off allowances, and so much more. \n Opportunity for career advancement in a high-growth company, driven by you, working with great team members.  \n \n Reasonable accommodation: Dow Jones, Making Careers Newsworthy - All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, or disability status. EEO/AA/M/F/Disabled/Vets. Dow Jones is committed to providing reasonable accommodation for qualified individuals with disabilities, in our job application and/or interview process. If you need assistance or accommodation in completing your application, due to a disability, email us at talentresourceteam@dowjones.com. Please put \"Reasonable Accommodation\" in the subject line and provide a brief description of the type of assistance you need. This inbox will not be monitored for application status updates. \n Business Area: OPIS \n Job Category: Quality Management \n Union Status: \n Non-Union role \n Since 1882, Dow Jones has been finding new ways to bring information to the world\u2019s top business entities. Beginning as a niche news agency in an obscure Wall Street basement, Dow Jones has grown to be a worldwide news and information powerhouse, with prestigious brands including The Wall Street Journal, Dow Jones Newswires, Factiva, Barron\u2019s, MarketWatch and Financial News. \n This longevity and success is due to a relentless pursuit of accuracy, depth and innovation, enhanced by the wisdom of past experience and a solid grasp on the future ahead. More than its individual brands, Dow Jones is a modern gateway to intelligence, with innovative technology, advanced data feeds, integrated solutions, expert research, award-winning journalism and customizable apps and delivery systems to bring the information that matters most to customers, when and where they need it, every day. \n If you are a current employee at Dow Jones, do not apply here. Please go to the Career section on your Workday homepage and view \"Find Jobs - Dow Jones.\" Thank you.  \n Req ID: 39153"}, "977821a90e8ba63d": {"terms": ["data analyst"], "salary_min": 82003.53, "salary_max": 103834.75, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "188958cc938429b1": {"terms": ["data analyst"], "salary_min": 83132.17, "salary_max": 105263.86, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "53512462e0fc90bf": {"terms": ["data analyst"], "salary_min": 82939.27, "salary_max": 105019.6, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "bd2a2373362fc3a3": {"terms": ["data analyst"], "salary_min": 85320.33, "salary_max": 108034.55, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "5cec3310db2bddb1": {"terms": ["data analyst"], "salary_min": 80618.516, "salary_max": 102081.0, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "423e29b618f119c5": {"terms": ["data analyst"], "salary_min": 81855.39, "salary_max": 103647.17, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "7d000ca56c0acf66": {"terms": ["data analyst"], "salary_min": 84081.75, "salary_max": 106466.234, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "44e3d172abc1d008": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 75000.0, "title": "Compensation Analyst, Data Operations", "company": "Salary.com", "desc": "Are you a driven individual looking to launch your career representing an innovative, fast growing company? Would you be excited to develop your skills and learn more about the compensation industry?  Salary.com  is looking to add an energetic, self-motivated  Compensation Analyst  to our amazing team!  \n We are the leading consumer and enterprise resource for compensation data, software, consulting, and education. For nearly 20 years, we\u2019ve not only helped people understand their worth \u2013 we\u2019ve also helped organizations attract and retain top talent by enabling smarter pay decisions. Today,  Salary.com  serves more than 8,000 customers and millions of consumers each year by connecting them with critical pay, benefits, and career data, technology, and resources. We are recognized by leading industry analysts as having the most innovative software platform in our space. \n -  \n About the Role\u2026 \n Salary.com  is competitively positioned as a leading enterprise resource for compensation data, software, consulting and education. As a  Salary.com   Compensation Analyst,  you will be responsible for supporting our customers by validating participant survey submissions and generating reports/analytics. In addition, this position creates, maps, and maintains job descriptive content including job levels and compensable factors. Our mission is to provide our customers with fast and accurate compensation data that they can use to make informed talent management decisions. \n \n REMOTE, Office located in Waltham, MA.  \n Monday-Friday  \n Career pathing & growth opportunities  \n Base Salary Range : $65,000 - $75,000 plus quarterly bonus potential \n \n \n A Day in the Life\u2026 \n \n Provide consultative solutions to our customers regarding our compensation analysis software and compensation data. \n Study market compensation surveys to understand the market ranges of pay for a job. \n Perform benchmark job matching across multiple survey sources. \n Build market-pricing composites for jobs in different industries, company sizes, and geographies. \n Formulate pay trends and scope differentials to make economic adjustments to the data. \n Prepare testing plans and assure data quality. \n Document business processes for data production. \n Help clients effectively use Salary.com software and data in order to manage their compensation programs. \n Audit customer survey participation files. \n Work with survey customers to resolve issues with their participation files. \n Write and edit benchmark job descriptions. \n Map supplementary content to jobs descriptions such as skills, certifications, and licenses. \n Contribute to compensation consulting projects. \n Contribute to new product development by working with Product Managers. \n Assist in the completion of other projects as needed. \n \n Requirements \n  About You\u2026. \n \n Bachelor\u2019s Degree (Human Resources, Math, Business Analytics focused preferred)  \n 0-1 years of experience in compensation and a desire for continuous learning  \n Able to thrive in a fast-paced, multi-task-oriented environment  \n Advanced Excel skills  \n Capacity to work independently, as well as collaborate with a team  \n Desire to become a Certified Compensation Professional  \n \n Benefits \n  Salary.com Perks\u2026 \n \n Company celebrations  \n 10 paid holidays and generous paid vacation time  \n Cell phone reimbursement  \n Robust benefit plan including Medical, Dental, Vision, Life, Disability coverage  \n 401K with 6% Company match \n \n \n \n Perfect your Pay. Inspire an Impact. Drive a Difference. \n  At Salary.com, we know your worth- Apply today to explore opportunities to join our team!"}, "366ee4c519082985": {"terms": ["data analyst"], "salary_min": 82824.36, "salary_max": 104874.09, "title": "Business Analyst", "company": "ECi Software Solutions", "desc": "For more than 30 years, ECI Software Solutions has been providing industry-specific, cloud-based business management software and services to small and medium-sized businesses. With divisions focused on manufacturing, wholesale/retail distribution, building and construction, and field service, ECI's solutions integrate into every aspect of a customers' business to help them level the playing field, run day-to-day operations more efficiently, and free them up to focus on what matters most. It\u2019s how business gets done. \n \n  Who is ECI? \n \n  At ECI, our mission is to enable the entrepreneurial spirit of small and medium-sized business owners. But ECI doesn\u2019t simply deliver amazing software solutions; we also have an award-winning company culture. \n \n \n \n We offer competitive benefits focused on employee well-being, including paid volunteer time off! \n We have been named by Achievers on its prestigious 50 Most Engaged Companies To Work For list for the last five years. \n We have received international recognition for our high levels of employee engagement through Certification as a Great Place to Work four years in a row. \n Our culture of creativity, innovation, and leadership has garnered over a dozen International Business Awards (Stevie\u00ae). \n  Come join a worldwide team with a strong culture of inclusion, professional development, and collaboration. \n \n  To apply for this position, please attach a detailed resume that demonstrates your qualifications and skill set pertaining to this position. Applications without a resume will not be considered. \n \n  ECI is seeking an energetic, passionate, experienced agile Business Analyst to join our software development team in our Manufacturing Division. This individual must be a problem-solver focused on understanding and translating operational business practices into working software solutions. Our team wants someone who will thrive in a collaborative environment. Our ideal candidate has relevant professional experience in a software development environment, specifically as a Business Analyst. \n \n  Roles and Responsibilities \n \n \n Lead complex multi-disciplinary projects with a proven track record of delivering quality solutions \n Analyzes and evaluates customer\u2019s needs to create product solutions that support overall business strategies \n Elicit and document business requirements from product owner and subject matter experts \n Apply critical thinking to gather requirements \n Focus on increasing business value for our customers by presenting ideas and collaborating with stakeholders \n Give input and drive alignment with the product road map \n Conduct product initiative story mapping sessions with stakeholders and subject matter experts to define scope \n Use story mapping techniques to define scope and objectives that assist in creation of backlog user stories that drive development and implementation \n Create and share user stories to multi-disciplinary teams and define the business-driven conditions of satisfaction \n Administer example mapping and facilitate refinement sessions with team to communicate functional behavior and to refine conditions of satisfaction \n Facilitate various agile events such as Story Mapping, Backlog Refinement, Sprint Planning, Sprint Reviews, Daily Stand-ups \n Serve as a liaison and actively collaborate with the agile team, Product Management, and stakeholder review of deliverables \n Work as an active member of an agile scrum team to deliver solutions for our customers \n Clarify questions from the development team with regards to intended usage of the software, definition of business logic \n Solid experience of deploying change management best practices and disciplines (e.g., SCRUM, Agile) \n Apply manufacturing industry best practices to develop a recommended set of functional specifications and any related documentation (wireframes, workflows, etc.) \n Provide subject matter proficiency in specific functional area(s) to the assigned scrum team \n Possess a wide degree of business and technical acumen, creativity, and a natural analytical way of thinking \n  Skills Required \n \n \n Ownership mentality to lead the team through peer collaboration and influence others to deliver product solutions \n Ability to visualize the solution and communicate the solution with stakeholders \n Excellent proficiency in verbal and non-verbal communication skills \n Expert in conceptual modeling; visualize possible solutions innovatively \n Proven experience using agile requirement techniques such as story mapping, user stories and example mapping. \n Ability to critically question to foresee future problems \n Analytical bend of mind towards developing solutions \n Problem-solving skills \n Highly organized with the ability to prioritize and track multiple tasks to successful completion \n Ability to organize, maintain, communicate, and archive requirements based on the project needs \n  Qualifications Required \n \n \n Bachelor\u2019s Degree in Computer Science, Engineering, Business, or related discipline. Education requirements may be satisfied with experience \n 4+ years of experience as a business analyst for a commercial software products company \n Proven ability to learn new business domains and apply knowledge to enterprise software products \n Prior experience with Manufacturing or other ERP software strongly desired \n  #LI-REMOTE \n \n  In addition to our competitive salary and award winning culture, we offer an excellent benefit package. We even offer our employees a day off to serve their community! Our company core values are our \u201cCODE\u201d: Crave Greatness, Own the Outcome, Deliver Awesome and Embrace Community."}, "69c1ef19f62bcc94": {"terms": ["data analyst"], "salary_min": 59118.0, "salary_max": 70942.0, "title": "Internal Audit Analyst (Remote Only)", "company": "Guilford County Government", "desc": "Salary \n \n \n \n \n     $59,118.00 - $70,942.00 Annually\n     \n \n \n \n \n \n Location  \n \n \n \n \n \n     100% Remote (Certain States), NC\n     \n \n \n \n \n \n \n \n Job Type \n \n \n \n \n     Full Time\n     \n \n \n \n \n \n Remote Employment \n \n \n \n \n     Remote Only\n     \n \n \n \n \n \n \n \n Job Number \n \n \n \n \n     03154\n     \n \n \n \n \n \n Department \n \n \n \n \n     Internal Audit\n     \n \n \n \n \n \n \n \n Opening Date \n \n \n \n \n     09/25/2023\n     \n \n \n \n \n \n Closing Date \n \n \n \n \n     10/16/2023 11:59 PM Eastern\n     \n \n \n \n \n \n \n \n \n Description \n \n \n \n GENERAL STATEMENT OF DUTIES \n  The primary purpose of the Internal Audit function is to assist county management in the efficient and effective discharge of their responsibilities by furnishing them with objective insights, analysis, appraisals, observations, and recommendations for improving controls, budget management, staff utilization, and processes within the county organization. \n  DISTINGUISHING FEATURES OF THE CLASS \n  Audit projects vary from process audits, to comprehensive audits of departments or outside agencies. Auditor trainees are assigned to a project, then must perform preliminary studies, conduct interviews and audit tests, then compile results and present findings in writing and verbally. The effect of audit work improves operational efficiency and effectiveness, internal controls, budget management, and staff utilization. Audit work provides crucial information for management decision-making, identifies non-compliance with laws and regulations that could lead to litigation, penalties, and adverse publicity for the county, and audit work monitors other organizations' contractual obligations. \n  This position is 100% remote; however, the successful candidate must live within three driving hours (approximately 175 miles of Greensboro, North Carolina). \n \n \n \n Examples of Duties \n \n \n \n Examples of Duties \n  DUTIES AND RESPONSIBILITIES   Essential Duties and Tasks \n \n  Audit county activities, functions, and programs. \n  Review organization, staffing, cost effectiveness, program effectiveness and efficiency; analyze and develop solutions to administrative and technical problems disclosed through internal or external review. \n  Make oral and written presentations to management during and at the conclusion of the audit discussing deficiencies, recommending corrective action, and suggesting improvements in operations and reductions in costs. \n  Prepare risk assessments. \n  Review and analyze accounts, records, internal controls, and fiscal procedures. \n  Perform tests of accounting records to verify accuracy, completeness and propriety. \n  Identify, gather, review and analyze physical or documentary data on management and business policies, practices, procedures, and organizational structure; make recommendations regarding industry best practices to improve performance efficiency and/or effectiveness. \n  Prepare formal reports on the adequacy and effectiveness of the system and the efficiency with which activities are carried out. \n  Appraise the adequacy of recommended corrective actions taken to improve deficient conditions. \n  Additional duties may include responsibilities relating to cross-divisional initiatives and compliance reviews. \n  Assist with completion of Single Audit assignments at the end of the fiscal year. \n \n  REQUIREMENT STANDARDS \n  This is an entry level position within the Department; the incumbent will be expected to satisfactorily complete both external and internal training. At the completion of training the employee should be able to demonstrate the following: \n   Skills and Abilities Required \n \n  Ability to analyze and recommend improvements \n  Ability to obtain and utilize sensitive information discreetly and objectively \n  Ability to analyze data, facts, or information and draw logical conclusions \n  Ability to communicate effectively with others, both verbally and in writing \n  Ability to establish and maintain effective relationships with County management, department management, professional personnel and others \n  Skilled in conducting research \n  Skilled in evaluating and testing internal controls and operational procedures \n  Skilled in prioritizing, organizing, and managing multiple simultaneous projects \n  Skilled in applying independent judgment, personal discretion, and resourcefulness in applying and interpreting guidelines \n \n  Knowledge \n \n  Knowledge of Audit Process \n  Knowledge of Methods and Practices and Governmental Accounting and Auditing \n  Knowledge of Information Systems (Munis/Tyler, Microsoft Office) \n  Knowledge of Organizational Structure \n  Knowledge of County Budget \n  Knowledge of Working Relationships \n  Knowledge of Federal, State & Local Laws and Regulations \n \n \n \n \n Typical Qualifications \n \n \n \n Minimum Qualifications  This is an entry level position within the Department; the incumbent will meet or exceed the following qualifications: \n \n  Graduation from an accredited college or university with a bachelor\u2019s degree in Accounting, Auditing, Finance or other field of study related to the nature of the work performed. \n  Must be certified or pass certification examination within 18 months of hiring; applicable certifications include: Certified Public Accountant (CPA), Certified Internal Auditor (CIA), Certified Government Auditing Professional (CGAP), Certified Management Auditor (CMA), and/or Certified Fraud Examiner (CFE). Other relevant certification may be considered. \n \n   Preferred Qualifications \n  Knowledge of data analytics. \n  Experience (internship or more) in internal auditing, local government accounting/finance or public accounting. \n  Experience (internship or more) in auditing governmental programs and services and/or financial records desired. \n  This position is 100% remote; however, the successful candidate must live within three driving hours (approximately 175 miles of Greensboro, North Carolina). \n \n \n \n Supplemental Information \n \n \n \n Physical Demands \n  Must be able to physically perform the basic life operational functions of climbing, balancing, stooping kneeling, crouching, crawling, reaching, standing, walking, pushing, pulling, lifting, fingering, grasping, talking, hearing and repetitive motions. Must be able to perform sedentary work exerting up to 10 pounds of force occasionally or and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. \n  Environmental Conditions \n  Work is performed in a normal office setting. \n  Working Conditions/Physical Demands \n \n  Interaction with various levels of supervisory staff \n  Normal Office Environment meeting ADA requirements \n \n  May Require Driving  This position may require driving for this position whether driving a County owned or personal vehicle to conduct county business such as but not limited to attending conferences, meetings, or any other county related functions. Motor Vehicle Reports may be verified for valid driver's license and that the driving record is compatible with the county's driving criteria. If a personal vehicle is operated for county business proper insurance is maintained as per Guilford County's vehicle use policy. \n  Special Note  This generic class description gives an overview of the job class, its job functions and recommended job requirements. However, for each individual position assigned to this class, there is available a completed job description with physical abilities checklist which can give further details about that one specific position. Those documents should be reviewed before initiating a selection process. They can provide additional detailed information on which to base various personnel actions and can assist management in making legal and defensible personnel decisions."}, "9008f3ffdc0ebb09": {"terms": ["data analyst"], "salary_min": 45.0, "salary_max": 50.0, "title": "Board Certified Behavior Analyst (BCBA) -1099", "company": "Spotlight Staffing LLC", "desc": "Board Certified Behavior Analyst - 1099 Contractor \n Salary $45-$50/hr CHOOSE YOUR OWN HOURS \n Board Certified Behavior Analyst (BCBA) : \n \u00b7 Function in a supervisory capacity and provide oversight to all areas of programming including the training of direct support professionals, person centered strategies consultants (if applicable) and DSP trainers. \n \u00b7 Assist in the development, facilitation, and follow-up training in Applied Behavior Analysis. \n \u00b7 Provide model teaching and other direct instructional supports including, but not limited to, practicum supervision/teaching, class instruction and in-service instruction to other support professionals. \n \u00b7 Assist in the development and implementation of assessment tools, to conduct functional assessments and analyses when appropriate, and to develop appropriate behavior strategies to teach appropriate behavior and reduce maladaptive behaviors. \n \u00b7 Provide ongoing support and training to direct support professionals, ABA implementers, and other individuals in support roles for families. \n \u00b7 Ongoing training and supervision of staff in implementation of ABA principles and methodology and behavior reduction strategies. \n \u00b7 Manage ongoing data collection system to establish baseline and programmatic efficacy for all consumers, and to analyze data on a frequent and ongoing basis to guide programming. \n \u00b7 Develop behavior plans/treatment plans and targets for all consumers with a focus on person-centered therapy and other antecedent strategies for reducing problematic behavior(s). \n \u00b7 Meet as needed with supervised staff to discuss ongoing consumer issues and to provide support when necessary. \n \u00b7 Review and sign off on behavior plan/treatment plan training for all field staff and provide field supervision when necessary. \n \u00b7 Enter session notes within 72 hours of each session. \n \u00b7 Provide consultation and collaboration services and to maintain ongoing communication with all constituents (other supports, parents, community, and community agencies). \n \u00b7 Keep current with the literature, new research findings and resources. In addition, continuing education courses to maintain BCBA certification are necessary (32 credits every 2 years). \n \u00b7 Maintain all data, paperwork, and communication between personal care staff and families, and to provide ongoing feedback to government related agencies that contract with such families. \n \u00b7 Perform other duties as assigned. \n \u00b7 Providing a hybrid of both direct (if based locally) and virtual treatment hours clients position can be 100% virtual \n \u00b7 Discharge and Transition Planning \n Required: \n \u00b7 Currently a Board Certified Behavior Analyst with the Behavior Analyst Certification Board (BACB) (open to out of state providers) \n Preferences: \n \u00b7 A passion for working with children and families diagnosed autism spectrum disorder and related conditions and their families. \n \u00b7 A willingness to professionally develop working with diverse and unserved communities. \n \u00b7 An eagerness to be a part of a caring and team-oriented company culture. \n \u00b7 A deep commitment to show up every day and be a leader for your team \n Job Types: Contract, Part-time, Full-time \n Pay: $45.00 - $50.00 per hour \n Schedule: \n \n Choose your own hours \n \n License/Certification: \n \n BCBA (Preferred) \n \n Work Location: Remote"}, "ad46cdd72893816f": {"terms": ["data analyst"], "salary_min": 87797.305, "salary_max": 111170.945, "title": "Business Analyst (Appian)", "company": "Silotech Group", "desc": "This position supports the Department of Labor and the Office of Labor-Management Standards to modernize the Electronic Labor Organizational Reporting Systems (e.LORS). The objective is to replace the existing legacy systems with a modernized system. Personnel will provide Appian code-based information technology (IT) solutions, services, and data management for custom application development, operations, and maintenance to modernize the e.LORS mission support system onto the DOL Appian Case Management Platform (CMP). \n Location \n Remote \n Clearance Requirements \n \n Must be willing and able to obtain and maintain Public Trust Clearance. \n Requires successful completion of National Agency Check with Inquiries (NACI) clearance. \n \n Essential Role and Responsibilities \n \n Work with the Contractor PM to lead the technical planning and requirements gathering phases of the project to include project estimates and deliverables. \n Provide subject matter expertise to the e.LORS 2.0 effort concerning functionality of the legacy e.LORS system as it relates to data integration and use of the existing applications and components. \n Assist the Contractor PM with plans, designs, development, and launch of a modernized e.LORS system in support of core organizational functions and business processes. \n Gather, document, and analyze requirements data in support of business cases, proposed enhancements, and systems requirements. \n Generate and compile reports based upon findings, complete with probable causes and possible solutions to systems issues. \n Apply proven communication, analytical, and problem-solving skills to help maximize the benefit of the project. \n Evaluate user requests for business process automation using Appian BPM and the DOL Software Development Lifecycle Model (SDLCM) system models to determine feasibility and technical requirements. \n Participate in team design meetings, daily scrum meetings, and other development meetings. \n \n Qualifications \n Education \n \n Bachelor's degree in Computer Science/Engineering or other relevant discipline. Acceptable substitute would be an advanced degree in the same field and 2 years of experience. \n \n Experience \n \n 7+ years using Agile development tools and methodologies proven experience in overseeing the design, development, and implementation of software and hardware solutions, systems, or products. \n 5+ years\u2019 proven experience in the operation and analysis of database, software implementation standards, and data retrieval methodologies. \n 3-5 years\u2019 experience developing requirements for Appian solutions, including integration capabilities and deployment options. \n Preferred any certification related to Appian, agile methodologies, and SCRUM. \n Experience with implementation and administration of Appian software in a FedRAMP-compliant cloud hosting environment. \n Excellent understanding of the organization\u2019s goals and objectives. \n Excellent analytical and creative problem-solving skills. \n Excellent written and oral communication skills. \n Ability to communicate ideas in both technical and user-friendly language. \n \n Certification \n Industry-recognized certifications such as: \n \n Preferred a current Project Management Professional certification (e.g., Project Management Professional (PMP) \n Agile Certified Practitioner (ACP) \n Certified Scrum Master (CSM), or comparable) \n \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) 4% Match \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid holidays \n Professional development assistance \n Unlimited paid time off \n Vision insurance \n \n Experience level: \n \n 5 years \n 6 years \n 7 years \n 8 years \n \n Schedule: \n \n 8 hour shift \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Agile: 7 years (Required) \n Appian solutions: 3 years (Required) \n \n Work Location: Remote"}, "5062d5bc635e6a42": {"terms": ["data analyst"], "salary_min": 72894.28, "salary_max": 92300.41, "title": "Business Intelligence Analyst", "company": "WebstaurantStore", "desc": "WebstaurantStore, the world\u2019s largest online restaurant supply company, is looking for a full-time Business Intelligence Analyst to drive data transparency, data empowerment, and data innovation throughout the organization. \n \n  Business Intelligence Analyst Job Responsibilities \n  Business Intelligence Analyst responsibilities include, but are not limited to: \n  Stakeholder Communications & Relationship Building: \n \n  Coordinate with business units to define reporting requirements, issues, needs, and deadlines \n  Communicate reporting needs to the BI Development team \n  Act as a liaison between business units, analysts, and developers \n  Maintain positive relationships \n \n \n  Reporting Assistance: \n \n  Assist business units with writing SQL queries and creating reports in Power BI \n  Handle reporting needs accurately and efficiently \n  Share best practices with business units and perform reporting audits \n \n \n  Maintain Team Documentation: \n \n  Collect and store reporting information related to requests from business units \n  Assist with the creation of training materials for business units \n  Maintain internal team standards for projects and reports \n \n \n  Project Management Experience: \n \n  Assists with planning and scoping projects \n  Tracks project benchmarks and milestones \n  Keeps relevant stakeholders up to date on project status (includes BI Analysts, BI Developers, business stakeholders) \n  Assists with making decisions to move project forward \n  Ensures project requirements are thorough, accurate, and up to date \n \n \n  Business Intelligence Analyst Job Requirements \n  Education & Experience: \n \n  Four-year degree in related field or equivalent work experience \n  At least 5 years of relevant job experience \n  Project management experience \n \n \n  Technical Skills & Experience: \n \n  Experience with BI software, preferably Power BI \n  Experience writing SQL \n \n \n  Professional Skills: \n \n  Ability to take leadership of multiple projects and accommodate frequent interruptions and changing priorities in a fast-paced environment \n  Strong attention to detail \n  Excellent written and verbal communication skills \n  Strong desire to collaborate with internal team members and other departments throughout the company \n \n \n  Preferred Experience (not required) \n  Professional Experience: \n \n  Cross-functional project coordination \n  Experience in working with enterprise Business Intelligence teams \n \n \n  Technical Skills: \n \n  Familiarity with statistical analysis and research methodologies \n  Advanced proficiency in Excel \n  Advanced proficiency with DAX \n  Advanced SQL \n  Familiarity with the following tools: Microsoft Power Platform (Power Automate, Power Apps, etc.), Azure DevOps, Microsoft SQL Server Management Studio \n \n \n  Data Experience: \n \n  Comfortability working with large amounts of e-commerce data \n  Data validation, data warehouse QA, and/or report auditing experience \n  Familiarity with Kimball methodology \n \n \n  Why WebstaurantStore? \n  Our Culture:  We uphold three core cultural values \u2013 \n \n  Entrepreneurial spirit:  We value employees who take ownership, approach problems with creativity, ask questions, and push through challenges. \n  Passion for excellence:  Our team members are committed to producing great results. They care about the details and strive for perfection. \n  Do the right thing:  We are committed to respect and honesty in our work environment. We work toward solutions that are best for the team and the organization. \n \n \n  Benefits & Offerings: \n \n  A competitive benefits package including paid time off, medical, dental coverage, and 401k match \n  A focus on work/life balance \n  Remote work \n  Competitive pay + bonuses \n \n \n  Submit your resume today and take the first step towards a fulfilling and dynamic career at WebstaurantStore! \n \n  Notes: \n \n  Accepting W2 candidates only. \n  No Relocation Provided. \n  No H1B\u2019s. \n  Not accepting candidates with anticipated sponsorship requirements. \n \n \n  Remote work qualifications \n \n  Access to a reliable and secure high-speed internet connection. Cable or fiber internet connections (at least 75mbps download/10mbps upload) are preferred, as satellite connections often cannot support the technologies used to perform day-to-day tasks. \n  Access to a home router and modem. \n  A dedicated home office space that is noise- and distraction-free. The space should have strong wireless connection or a wired Ethernet connection (wired connection is preferred, if possible). \n  A valid, physical address (apartment, suite, etc.). PO Boxes are not supported, as a physical address is required for you to receive your computer equipment. \n  The desire and ability to work and communicate with other team members via chat, webcam, etc. \n  Legal residents of one of the following states: (AK, AL, AR, AZ, DE, FL, GA, IA, ID, IN, KS, KY, MD, ME, MI, MN, MO, MS, NC, NH, NM, NV, OH, OK, PA, SC, SD, TN, TX, UT, VA, VT, WI, WV, and WY). H-1B Visa Sponsorship Not Available, W2 only."}, "2da5af34ac713c85": {"terms": ["data analyst"], "salary_min": 65.0, "salary_max": -1.0, "title": "Regulatory Tax Business Analyst", "company": "Tekshapers Software Solutions Pvt Ltd", "desc": "Regulatory Tax Business Analyst \n Scottsdale, AZ (Remote OK but candidate should be from PST Timezone or someone interested for Relocation) \n Interview Process: 3 Rounds of Interview \n With Strong SQL and strong background in regulatory TAX, experience in working with FACTA, Dodd Frank, Basel \n Job Description: \n \n Hands on in SQL is a must and over 9+ years of experience is required. \n \n \n Must have GCP knowledge & expertise \n \n \n Must write complex SQLs, generate reports and build visualizations \n \n \n Preferred/Basic understanding of Payments/Finance/Tax Industry Background will be a plus \n \n \n Having GCP certification or Cloud experience is a plus \n \n \n Having Hadoop knowledge/experience is a plus \n \n \n Strong skills in Microsoft Excel and Power Point \n \n \n Good in documenting the requirements \n \n \n Experience in working with both agile & waterfall methodologies \n \n \n Ability to analyze data and present outcomes in a way for management team to easily comprehend results \n \n \n Ability to gather, analyze, prioritize and present requirements \n \n \n Should be a fast learner and must be able to work with minimal supervision in a fast-paced environment \n \n \n Ability to build relationships and influence to create a positive outcome \n \n \n Must possess strong written & verbal communication skills \n \n \n Having scripting & coding experience is a plus \n \n Job Type: Full-time \n Pay: From $65.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n Business analysis: 10 years (Required) \n Data Analysis: 4 years (Required) \n Tax Regulatory: 3 years (Required) \n FACTA, Dodd Frank, Basel: 3 years (Required) \n Microsoft SQL Server: 4 years (Required) \n \n Work Location: Remote"}, "a2b39f82ede92247": {"terms": ["data analyst"], "salary_min": 65.0, "salary_max": -1.0, "title": "Treasury Business Analyst", "company": "Tekshapers Software Solutions Pvt Ltd", "desc": "Treasury Business Analyst \u2013 \n San Jose, CA(Remote OK but candidate should be from PST Timezone) \n Interview Process: 3 Rounds of Interview \n Required Skills: Quantum Treasury Management, SWIFT Messaging, Cash Management, experience in investment and debt management, equity management, power BI is good to have \n Job Description: \n \n Responsible for the delivery of the execution and oversight of effective Treasury system risk management activities within Finance with key responsibilities: \n \n \n Act as a subject matter expert for the Quantum Treasury management system,) and SWIFT. \n \n \n Collaborate with Treasury, IT and Finance teams to identify, analyze and implement process improvements related to cash management and SWIFT messaging. \n \n \n Partner with technology team and users to develop and maintain SLA\u2019s on various activities \n \n \n Support the Treasury team in the efficient system utilization of daily cash management activities, including bank reconciliation, cash forecasting and investment management, debt management ,identify and implement improvements as required. \n \n \n Work closely with IT to support Quantum upgrade and enhancements to improve automation and efficiency in Treasury operations. \n \n \n Provide training and support to Treasury team members on the use of Quantum and SWIFT. \n \n \n Stay current with new developments in Treasury management systems, SAP and SWIFT messaging, and recommend new technologies to improve operations. \n \n Knowledge, Skills, and Abilities: \n \n Bachelor's degree in Finance, Accounting or related field. \n \n \n Minimum of 7 years of experience in Treasury operations, including experience with Quantum Treasury management system and SWIFT messaging. \n \n \n Strong understanding of cash management, investment management processes and related Accounting rules. \n \n \n Excellent analytical and problem-solving skills, with the ability to think creatively and outside the box. \n \n \n Ability to work independently and effectively prioritize tasks in a fast-paced environment. \n \n \n Excellent written and verbal communication skills, with the ability to present complex information in a clear and concise manner. \n \n \n Strong project management skills, with the ability to lead cross-functional teams and drive projects to completion. \n \n Job Type: Full-time \n Pay: From $65.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n Cash management: 3 years (Required) \n Business analysis: 10 years (Required) \n Treasury management: 5 years (Required) \n SWIFT Messaging: 3 years (Required) \n \n Work Location: Remote"}, "9aa7131759a56c32": {"terms": ["data analyst"], "salary_min": 95607.97, "salary_max": 121061.0, "title": "Sr. Business Analyst", "company": "Greif", "desc": "Greif offers a great working environment and the opportunity to make an immediate impact at a company where your ideas are always welcome.\n  \n \n \n   Job Requisition #:\n   025488 Sr. Business Analyst (Open)\n  \n \n   Job Description:\n  \n \n   Greif Packaging, LLC seeks a Senior Business Analyst at its facility located at 366 Greif Parkway, Delaware, OH 43015.\n  \n \n \n   JOB DESCRIPTION:\n  \n \n \n   Perform business requirements analysis for software applications and liaison between the applications team and operational management. Responsible for translating business requirements into functional specifications; configure the standard functionality of the ERP system, work with developers for solution modeling and development; and perform testing of business process scenarios. Oversee the integrity of company core models; maintain detailed documentation of processes and work with business leaders to monitor continued applicability and effectiveness of business models. Comply with SOX and other established standards, processes, and procedures within the company and IT department. Provide training to key users and communicate complex technology and applications clearly to non-technical business users and translate business requirements into to functional/technical specifications to developers. Analyze complex user issues, evaluate alternatives, and devise efficient cost-effective, user-friendly solutions in core areas of manufacturing, sales, supply chain, and finance. Evaluate new tools and third-party applications and provide recommendations to management regarding their usefulness. Maintain positive inter-company and inter-department business relationships and ensure high levels of assigned project quality, timeliness, and stakeholder satisfaction. Collaborate with business owners, analysts, system end-users, developers, and support staff to ensure that technical and architectural designs form a cleanly integrated system that meets the business needs of the user community. Ensure timely completion of agreed objectives, while striving to exceed stakeholder expectations. Work with little direction from the management while producing high-quality work and oversee tasks to completion. Lead projects and take responsibility for delivery asked for, provide status updates to IT management, escalate issues in a timely manner, and gather to provide information supporting the metric reporting requirements of the organization. 25% of domestic travel required. Telecommuting permitted.\n  \n \n \n   REQUIREMENTS:\n  \n \n \n   This position requires a Master\u2019s degree, or foreign equivalent, in Computer Science, Mechanical Engineering, Computer Engineering, Industrial Engineering, Business Administration, or a related field, plus 5 years of experience as an Analyst or related occupation in Information Systems, Information Technology, Manufacturing Analytics, or related field. Additionally, the applicant must have professional experience with: 1) Utilizing INFOR ERP LN Manufacturing and Logistics applications to translate business requirements into functional specifications and configure the standard functionality of ERP systems; 2) Analyze business requirements to design and deploy IT solutions including ERP design, testing, and validation; 3) Developing functional designs that form a cleanly integrated system that meets the business needs of the user community by collaborating with business owners, analysts, system end-users, developers, and support staff; 4) Analyzing complex user issues, evaluating alternatives, and devising cost-effective and user-friendly solutions in core areas of manufacturing, sales, supply chain, and finance; and 5) Creating business modeling and process mapping to depict as-is and ERP enabled state of business to leadership team.\n  \n  40\n  \n \n   EEO Statement:\n  \n \n \n    htps://www.greif.com/uploads/media/default/0001/03/230497a078bec89c55df07d1d04e7f6db5ac6122.pdf\n   \n \n \n \n  We offer a competitive salary, excellent benefits and opportunity for growth. Greif, Inc. is an equal opportunity employer. We will not discriminate against any applicant or employee on the basis of sexual orientation, gender identity, race, gender, religion, age, national origin, color, disability, or veteran status.  \n EOE/Minority/Female/Disabled/Veteran. \n  For more information read Greif\u2019s Equal Opportunity Policy."}, "e4954f426d76fa09": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Senior IT Business Analyst (Epic Dorothy Rev Cycle) Remote Opportunity", "company": "University Hospitals", "desc": "Description \n \n  The position is visible to the hospital\u2019s business service lines and serves as a liaison between IT and those groups. This position also functions as a team member responsible for providing application(s) configuration support to enhance department\u2019s operational efficiencies/ workflow needs. Duties include: \n \n  Supports major enterprise applications and others as assigned. \n \n \n  Leads design of business workflow in conjunction with the business units and provides guidance to Application Analysts in designing improved efficiencies, solving complex workflow issues and incorporating quality initiatives. \n \n \n  Leads needs assessment, software design, implementation, support, and reporting. \n \n \n  Leads unit and integrated testing of the software to ensure that the design objectives are met. \n \n \n  Identifies complex testing scenarios, develops test scripts, and validates testing results. \n \n \n  Maintains high degree of understanding of departments\u2019 business processes. \n \n \n  Owns specific functionality and processes; responsible for all configuration, testing, and communication regarding this functionality/process. \n \n \n  Troubleshoots application issues, without assistance, to resolution. \n \n \n  Troubleshoots system hardware, as needed. \n \n \n  Partners with end users to understand workflow and business processes. \n \n \n  Oversees system security for assigned applications. \n \n \n  Manages Disaster Recovery and Back Up requirements for assigned systems and provides guidance to Applications Analysts in activities. \n \n \n  Acts as the team project lead in partnership with the Project Management Office on all phases of a project; from scoping and design through implementation and transition to Operations. \n \n \n  Mentors Application Analysts. \n \n \n  Produces and maintains custom reports; maintains knowledge and experience with industry standard report writers such as Crystal Reports. \n \n \n  Reviews and approves end-user training materials and participates in training efforts. \n \n \n  Guides other team members to ensure high documentation standards. \n \n \n  Leads escalation of issues with appropriate resources. \n \n \n  Develops policies and procedures in collaboration with the business unit, other team members, and IT management team. \n \n \n  Independently manages components of application upgrades, testing, troubleshooting, and support efforts. \n \n \n  Supports/troubleshoots inbound/outbound interfaces as appropriate. \n \n \n  Creates reports as needed and works problem tickets. \n \n \n  Evaluates and maintains appropriate system documentation. \n \n \n  Collaborates with other application and clinical analysts to ensure system integrations. \n \n \n  Serves as primary customer contact for on and off hours application support (rotating schedule). \n \n \n  Participates in change management activities to support successful system deployments and enhancements. \n \n \n  Utilizes and maintains appropriate change control procedures and standards. \n \n \n  Creates reports, dashboards, and other analytical tools to support customer base. \n \n \n  Prepares detailed flowcharts/diagrams to assist with design decisions and problem analysis. \n \n \n  Leads the design of business workflow in conjunction with the business departments; workflows will focus on improved efficiencies, as well as incorporating quality initiatives. \n \n \n  Assists with data collection from business subject matter experts, to facilitate design which will represent an improved business workflow. \n \n \n  Performs other duties as assigned. \n \n \n \n  Qualifications \n \n  Education \n  High School diploma or equivalent required. \n  Bachelor\u2019s degree preferred. \n  Experience & Knowledge \n  4+ years of experience supporting applications required. \n  Epic Dorothy Certification preferred.  \n Experience in a healthcare setting is highly desired. \n  Excellent written and verbal communication skills are required. \n  Ability to work in a team environment is required. \n  Ability to function independently in a fast-paced environment required. \n  Ability to work with all levels of the organization is required. \n  Knowledge of MS Office required. \n  Project management experience/skills preferred. \n  Business workflow redesign experience a desired. \n  Experience working with business applications such as: \n  Patient Scheduling systems \n  Hospital or Physician Revenue Cycle systems \n  Data Warehousing \n  SQL Server/SSIS \n  Enterprise Scanning and workflow management Applications \n  Bed Management Applications \n  Finance Applications \n  Special Skills & Equipment Knowledge \n  Knowledge and experience with SQL based applications required. \n  Knowledge of LAN, DNS, and networking required. \n  Ability to work with servers and apply software upgrades required. \n  Knowledge of disaster recovery and backup procedures required. \n  Knowledge and experience with HL7 Interfaces required. \n  Knowledge of ITIL standards desired."}, "98443e0b9cb7db1e": {"terms": ["data analyst"], "salary_min": 85190.54, "salary_max": 107870.21, "title": "Senior Business Analyst", "company": "Chainbridge Solutions Inc", "desc": "Chainbridge Solutions has a need for a Senior Business Analyst in a customer-centric role, supporting the productive and value driven relationship between Chainbridge Solutions and its customers. The BA\u2019s role is to elicit, analyze, specify, and validate the business needs of project sponsors and stakeholders. This includes interviewing stakeholders for gathering and compiling detailed user requirements and developing business process flows to convey to development teams throughout the project lifecycle. This position requires leadership, business and technical competencies and the ability to apply proven communication, analytical, and problem-solving skills to help support the development process. The BA will ensure project deliverables fully satisfy business needs.\n     \n \n \n \n Key Responsibilities  \n \n \n \n \n Serves as liaison between technology and business end-users. \n Elicits requirements from stakeholders. Translates, simplifies and analyzes the feasibility of requirements to promote business process and solution design efficiency. \n Translates conceptual user needs into functional business requirements in a clear manner to development teams. \n Formulates, defines and verifies business cases as well as business and solutions requirements based on both business and user needs. \n Works with Delivery teams to drive alignment of solutions with business strategies and business capability requirements. \n Consults with customers to develop process flows reflecting business process requirements. \n Manages requirements and issues, leveraging tools such as JIRA. \n Conducts reviews to ensure that requirement specifications are correctly interpreted. \n Communicates changes, enhancements, and modifications to project managers, sponsors and other stakeholders. \n Formulates, documents and verifies user stories, acceptance criteria, process flows, and mockups.  Supports the development of release notes, user guides, training materials, etc. \n     \n \n \n \n Skills, Knowledge and Expertise  \n \n \n \n \n Bachelor\u2019s degree required. \n 4-7 years of IT experience working in all major phases of software implementation projects. \n 3 years as a Business Analyst, including proven experience with business and technical requirements analysis, elicitation, modeling, verification and prioritization. \n 3+ years of experience in Agile Methodology. \n Experience with Jira preferred. \n Diversified experience across multiple business domains and functional areas is preferred. \n Strong communication and presentation skills. \n Demonstrated analytical and problem-solving abilities as well as attention to detail. \n Must possess strong interpersonal and information gathering skills and the ability to relate well to others at all levels throughout the organization. \n Strong organizational skills and ability to multi-task and successfully manage competing/changing priorities.  Advanced MS Office skill set to include Word, Excel, PowerPoint and Visio. \n     \n \n \n \n About Chainbridge Solutions  \n \n \n   Entrusted since 2010, Chainbridge Solutions is an award-winning SBA-certified 8(a) and woman-owned small business that specializes in building automated workflow solutions for our federal, state, local and private sector customers."}, "35dc39583c6251bb": {"terms": ["data engineer"], "salary_min": 112151.85, "salary_max": 142009.23, "title": "Data Engineer", "company": "AccelPad", "desc": "We are currently looking for an outstanding senior data engineer. Experience with different programming languages related to building data pipelines and analyzing data, such as SQL, Python or R. Proven experience building and managing cloud data pipelines and infrastructure in GCP or similar cloud environments. Experience with ETL tools, such as SSIS, Azure Data Factory or AWS Glue. Email your resume today to hr@accelpad.com with position ID in the subject."}, "3bca8b332336a22f": {"terms": ["data engineer"], "salary_min": 135000.0, "salary_max": 150000.0, "title": "Data Engineer - Backend", "company": "Chartbeat, Inc.", "desc": "Tubular and Lineup have partnered with Chartbeat to help you grow reach and revenue for your content. \n \n \n \n   Chartbeat\u2019s (www.chartbeat.com) mission is to help content creators around the world better connect with their audiences.\n   \n \n \n   In 2023, Chartbeat joined forces with Tubular, the leader in global social video intelligence and measurement, and Lineup Systems, the leading global provider of media sales technology. Together, we\u2019re expanding the ecosystem of insights we provide to enterprise content creators who are developing audiences and revenue streams across channels. We now serve more than 1,000 brands globally, including \n    The New York Times, the BBC, ESPN, Gannett, Vox, BuzzFeed, Paramount, WB, Mediahuis, Hearst, McClatchy,  and \n    GQ .\n   \n \n \n   You'll be joining a diverse group of focused, hard-working people who are passionate about doing work that's challenging and fun\u2014and who strive to maintain a healthy work/life balance.\n   \n \n \n The Role: \n \n   As a Data Engineer at Chartbeat, you will be designing, building, scaling, and maintaining our data pipelines, data stores, analysis engines, and APIs. You will primarily be contributing code within a cross-functional team, typically a few engineers, a designer, a data scientist, and a product manager. You will also participate in the engineering on call rotation to monitor and maintain the health of our production systems.\n   \n \n \n \n Responsibilities \n \n \n \n 3-5 years experience as a backend software engineer \n Experience writing software with Python \n Creation of maintainable software with documentation, tests and flexible design \n Knowledge of API styles like REST \n Build data pipeline that support multi tenant usage and ETL for large, high-scale applications (experience with Snowflake or PostgreSQL is a plus) \n Interest in working with and building distributed systems (e.g. technologies like Zookeeper, Kafka) \n Collaborate with Product, Frontend Engineers and Data Scientists \n Excellent verbal and written communication skills and a commitment to building an inclusive and collaborative working environment \n Available for occasional OnCall duties \n An interest in designing technical solutions to open-ended product problems \n Passion and enthusiasm about learning and teaching new technologies \n Applicants must be currently authorized to work in the United States \n \n \n \n \n Compensation and Benefits \n \n   We are proud to offer our team members a competitive compensation plan that includes stock options for all full-time employees and a 401K program with an immediately vesting match.\n   \n \n \n   401K (company match 100% of the first 3% and 50% of the next 2%).\n   \n \n   Health, Dental, Vision\n   \n \n   Parental Leave\n   \n \n   Pre-tax transit cards\n   \n \n   $30/month book stipend\n   \n \n   $250/year learning and development\n   \n \n   State-of-the-art technology\n   \n \n   Flexible hours\n   \n \n   Unlimited PTO\n   \n \n   Company-wide outings\n   \n \n   Employee-led classes\n   \n \n   Hackweeks\n   \n \n \n   The pay range for this position is $135-150K per year. Please note that the foregoing compensation information is a good-faith assessment associated with this position only and is provided pursuant to the applicable law.\n   \n \n \n \n Diversity, Equity, and Inclusion Statement \n \n \n   At Chartbeat we strive to create and continually grow as a company where all employees are able to be their authentic selves. We are committed to recruiting, hiring, and retaining employees from different backgrounds, viewpoints, and experiences. Our strength is our diversity and we are dedicated to continuously reflect upon, and evolve our efforts to maintain a diverse, equitable and inclusive ecosystem.\n   \n \n \n Equal Opportunity Employment Statement \n \n \n   Chartbeat is an Equal Opportunity Employer and does not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by applicable national, federal, state, or local law."}, "fae07e80376750d7": {"terms": ["data engineer"], "salary_min": 137864.25, "salary_max": 174566.84, "title": "Senior Software Engineer I, Data Infrastructure", "company": "HubSpot", "desc": "The Data Infrastructure teams at HubSpot are responsible for building and maintaining data storage technologies across the product. Teams work with a variety of open source technologies like MySQL, Vitess, Hadoop HBase, Kafka, Spark, and Elastic Search all running on AWS. A number of our teams are active contributors to the Open Source projects that they work on. \n  In this role you will: \n \n Build automation, tooling, and monitoring to provide developers with the knowledge necessary for understanding and optimizing datastore usage and minimizing the impact of any operational issues for clients \n Build datastore clients for more efficient monitoring and analysis of usage patterns in a multi-tenant environment \n Maintain operational responsibility over a huge volume of traffic to and from these data stores and stream data to and from applications \n Mentor less experienced engineers and assist them in growing their skills. Help verify the correctness of their work, educate them on any gaps in their knowledge of the HubSpot platform \n Assist other product engineers at HubSpot on their usage of our tooling for Kafka \n Educate others on the most effective way to store and interact with data \n Participate in the on-call rotation \n Write Java REST APIs as backend services to provide diagnostic data for troubleshooting as well as auditing of HubSpot cluster management \n Investigate advanced streaming issues on behalf of the HubSpot engineering organization to ensure all engineering teams meet company performance metrics and SLAs for Microservices accessing streaming data stores \n \n \n \n \n  We know the  confidence gap  and  imposter syndrome  can get in the way of meeting spectacular candidates, so please don't hesitate to apply \u2014 we'd love to hear from you. \n \n \n  If you need assistance or an accommodation due to a disability, please email us at  interviewaccommodation@hubspot.com .  This information will be treated as confidential and used only for the purpose of determining an appropriate accommodation for the interview process. \n \n \n  Germany Applicants:  (m/f/d) - link to HubSpot's Career Diversity page  here . \n \n \n \n About HubSpot \n  HubSpot (NYSE: HUBS) is a leading customer relationship management (CRM) platform that provides software and support to help businesses grow better. We build marketing, sales, service, and website management products that start free and scale to meet our customers' needs at any stage of growth. We're also building a company culture that empowers people to do their best work. If that sounds like something you'd like to be part of, we'd love to hear from you. \n  You can find out more about our company culture in the HubSpot Culture Code, which has more than 5M views, and learn about our commitment to creating a diverse and inclusive workplace, too. Thanks to the work of every employee globally, HubSpot was named the #2 Best Place to Work on Glassdoor in 2022, and has been recognized for award-winning culture by Great Place to Work, Comparably, Fortune, Entrepreneur, Inc., and more. \n  Headquartered in Cambridge, Massachusetts, HubSpot was founded in 2006. Today, thousands of employees work across the globe in HubSpot offices and remotely. Visit our careers website to learn more about culture and opportunities at HubSpot. \n \n By submitting your application, you agree that HubSpot may collect your personal data for recruiting, global organization planning, and related purposes. HubSpot's  Privacy Notice  explains what personal information we may process, where we may process your personal information, our purposes for processing your personal information, and the rights you can exercise over HubSpot's use of your personal information."}, "5a623598a9d99025": {"terms": ["data engineer"], "salary_min": 83267.37, "salary_max": 105435.04, "title": "Data Delivery Engineer", "company": "Clario", "desc": "Clario is looking for a Data Delivery Engineer to join our team. You will take responsibility for ensuring the flow of data is continuous and properly integrated with the systems by creating custom software components and writing complex queries to meet client specifications on reporting and visualization requirements.\n  \n \n \n   In this role, you will\n  \n \n  Work with Project Managers to design, develop, and create data reports, transfers, and data visualization tools as needed. \n  Recommend design approaches and reporting options to allow for successful clinical trials \n  Write simple/complex custom solutions that optimize the flow of data from various internal systems \n  Manage data integrations - design, develop and configure integrations with external systems \n  Understand and contribute towards the improvement of Project development delivery metric goals for productivity, cost, delivery and quality \n  Assist in continuous improvement initiatives, including workflow efficiencies and associated documentation. \n  Other related duties and projects as assigned. \n \n \n \n  The duties and responsibilities listed in this job description represent the major responsibilities of the  \n position. Other duties and responsibilities may be assigned, as required. This job description and  \n any attachments do not constitute or represent a contract. \n \n \n \n   What we seek -\n  \n \n  MSc/BA/BSc in a related field \n  1-3 years minimum technical experience \n  Ability to understand and develop optimized SQL / Oracle Stored Procedures, Tables, Views and Functions; MS SQL server experience preferred \n  Ability to read and develop in XML, XSLT, CSS and JavaScript \n  Experience with clinical trial industry data standards such as Oracle Clinical, CDISC ODM CDISC SDTM, etc. is a plus \n  Experience with other programming languages, such as C, C++ or Visual Basic is preferred \n  Must possess excellent verbal and written communication skills \n  Must be a team player \n  Able to prioritize multiple projects and work in a fast paced environment with short timelines \n  Clinical Trial experience is a plus \n  Ability to work from home every day \n \n \n \n  At Clario, we put people first, always. We are united and driven by patients, committed to making a difference, and we are always looking for the best talent to help us transform lives. \n \n \n \n  #LI-DNI \n  Courageously Curious\n  \n  Our appetite to blend the best of domain expertise, technology and human understanding knows no bounds. We\u2019re relentless in pursuing the information, insights and inspiration that means we can continuously improve clinical trial site support services and technology solutions.\n  \n  Behaviors:\n  \n \n \n We learn; embracing change, questioning how we work, finding a better way. And if it doesn't go to plan, we don't blame each other; instead, we own it and grow together \n We partner' with each other, with customers, patients and sites, working with them to understand their goals and then deliver the best solutions, Deliver Exceptional \n \n  We step forward because responsibility powers us; we don\u2019t leave others to do what we can do ourselves. We take charge of events, delivering exceptional work for our customers, patients and each other.\n  \n  Behaviors:\n  \n \n \n We prioritize; focusing on what matters, never compromising on quality. \n We commit; delivering what we say we will, working with energy and intent, sharing what we learn with each other., People first, always \n \n  We think of others before we think of ourselves. We have a deep understanding of our customers, and deep empathy for patients\u2014and each other. We\u2019re united by our purpose\u2014it\u2019s why we go above and beyond to support each other, emphatically.\n  \n  Behaviors:\n  \n \n \n We do the right thing; for our customers, patients, sites and each other. And We're passionate about it. \n We lift each other up; respectful of different views, we listen are inclusive, and support each other to succeed."}, "05aa6f37774a4b3b": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 136849.53, "salary_max": 173282.0, "title": "Senior Data Engineer - LATAM", "company": "Tesorio", "desc": "Tesorio empowers the Fortune 5,000,000 to run as if they had a Fortune 500 finance team. We plug into a company's cashflow data sources and leverage data science to surface the most impactful actions they can take to optimize their cash flow. Then, we let them implement those actions with the click of a button.\n    \n \n \n \n \n   We listen to our customers, and empower them to share their best practices and wishlist with us to make our product better every day. We are developing machine learning algorithms to understand business cash needs, predictive algorithms to forecast future cash flow, and a sleek UI/UX to make our products enjoyable to work with.\n    \n \n \n \n \n   We're looking for talented data engineers to take ownership over the data pipelines and workflows required to drive the data science, machine learning, and analytics that powers our platform. You'll be joining an early-stage company with a small, tight-knit team, backed by top-tier VCs (including First Round, Floodgate, Fuel and Y Combinator). You'll work closely with the entire engineering team, our Head of Product, and the co-founders. Learn more at tesorio.com.\n   \n \n \n \n \n \n  About you \n \n \n  You can independently own and drive data engineering projects from concept to completion  \n You're looking to have a large impact on the success of the business \n  You have strong opinions, but you hold them loosely. \n  You're always learning. \n  You love being a crucial part of a team that is building and shipping magical products that will help thousands of companies. \n \n \n \n \n \n \n What you\u2019ll do day-to-day \n \n \n  Take ownership over the current and future state of the data architecture \n  Collaborate with engineers, data scientists, and product managers to understand their data requirements and translate them into design \n  Build scalable data frameworks and data pipelines required to support data science, analytics, machine learning, and product use cases \n  Own the data quality, efficiency, automation, and observability of data pipelines and data transformations \n  Partner with different teams within the company to drive data driven projects and deliver data artifacts that integrate seamlessly into our product experience \n  Tackle a wide variety of technical problems and contribute daily to improve system health and code base. \n \n \n \n \n \n \n The ideal candidate \n \n \n  Bachelor's degree in Computer Science, Engineering, or related discipline \n  Has 5+ years of work experience (including 3+ years in data engineering) \n  Proficiency in SQL and one high-level programming language (preferably python). \n  Experience with one or more data orchestration, big data processing and transformation frameworks (for example: Airflow, DBT) \n  Experience with one or more SQL stores and data warehouse (for example: Postgres, Snowflake) is required \n  Experience with docker and kubernetes \n  Experience with other related technologies (for example: NoSQL data stores, Pandas) a plus \n  Is resourceful and agile, and remains positive in the face of problems. \n  Empathetic towards colleagues and users. \n  Excited about the challenge of working in a fast-paced environment with a small and talented team. \n \n \n \n \n \n \n Note: we currently cannot sponsor visas."}, "d918ebcf947a5d6f": {"terms": ["data engineer"], "salary_min": 97349.93, "salary_max": 123266.695, "title": "Data Platform Engineer", "company": "Lakeside Software", "desc": "Lakeside Software is how organizations with large, complex IT environments can finally get visibility across their entire digital estate and see how to do more with less. For far too long, IT teams have struggled to see what's going on in their dark estate \u2013 where costly inefficiencies, poor employee experiences, and unresolved problems hide. Only Lakeside lets you give everyone a better view, so they can see the hidden issues, see the smartest fixes, and see the biggest savings. That's why so many of the world's leading global brands rely on Lakeside. And it's how our customers see an average ROI of more than 250%. \n  Give everyone a better view.TM \n \n  The Role \n  As a Data Platform Engineer at Lakeside, you will leverage our unique set of clean and richly structured data to find new and creative ways to gain more insight into the data we collect by building actionable, use case driven content and solutions that will enhance our product and support IT professionals. This individual should be comfortable working in a global, fast-moving team where personal responsibility is counted upon. Experience with end-user computing, L3 support, and SQL is desired. \n  What You'll Do \n  The core functions of this role include: \n \n Designing solutions to aid customer IT departments from the L1 support desk all the way to the C-Suite \n Building dashboards using SQL to visualize data insights. Includes some CSS and basic UX/UI design \n Building automations to proactively solve customer IT problems. Creative solutions using PowerShell, C#, or similar \n Building sensors to directly monitor and detect issues on the end-point using SQL and our internal sensor syntax language \n Taking ownership of your projects from design all the way through build and continued support. \n Building effective relationships at all levels of the organization and always maintaining a high level of customer service \n \n What You'll Bring to Lakeside \n  The key requirements for this role include: \n \n Knowledge of end-user computing concepts, common IT problems, software, and hardware \n Experience providing high-level support or delivering solutions to large enterprises \n Knowledge of Windows OS environments (MacOS, Linux is a bonus) \n Advanced knowledge of SQL \n Understanding of virtualization technologies such as VMware, Citrix and Microsoft \n Some experience or familiarity with PowerShell, C#, Python is desired \n Excellent written/verbal communication, organization, presentation, and project management skills \n Ability to conduct meetings, document actions and follow up with all parties involved \n Ability to work on a global, remote team \n Willingness to learn and adapt in a fast-paced environment \n Ability to work individually and within a highly collaborative team setting \n BA/BS degree or higher in computer science, engineering, or related quantitative field \n \n Additional Details \n \n Location: Remote or Hybrid with preference for Ann Arbor. If fully remote, must be located in Eastern Standard Time \n \n #LI-Remote #LI-DF1 \n \n  Lakeside Software is committed to pursuing a diverse and talented team and offering an inclusive environment for all employees and candidates. As we expand our DE&I reach, we are particularly interested in receiving candidate applications from a broad spectrum of individuals, including women, historically marginalized groups, individuals with disabilities, members of the LGBTQIA+ community, veterans, and any other legally protected group. Lakeside is dedicated to providing equal access and opportunity, as well as reasonable accommodation, for individuals with disabilities in employment, its services, activities, and programs. Lakeside is an Equal Opportunity Employer and does not make hiring or employment decisions on any basis protected by applicable local, state, or federal laws or prohibited by Company policy. If reasonable accommodation is needed to participate in the job application or interview process, to perform required job functions, or to receive other benefits and privileges of employment, please contact accomodations@lakesidesoftware.com. \n  Read our Privacy Statement."}, "ed3be6c661ae75a5": {"terms": ["data engineer"], "salary_min": 60.0, "salary_max": 65.0, "title": "Data QA Engineer", "company": "NAVETA AG", "desc": "C2C \u2013 DATA QA ENGINEER \u2013 REMOTE \n Title : Data QA Engineer \n Location : Remote \n Duration : 6+ months \n C2C \n We are seeking a dedicated and technically skilled Data QA Engineer. The Engineer will work closely with development leads and data engineers to define analysis strategies and create test plans that ensure the highest quality of code delivery. The candidate will build, manage, and maintain a robust testing environment. \n What You'll Do: \n \n Collaborate with development leads and data engineers to define analysis strategy and test plans to ensure quality delivery. \n Define, build, automate, and execute testing for code in an agile practice in accordance with sprint planning. \n Build, manage, and maintain unit, integration, and regression tests using DBT, Vertex, and Colab. \n Troubleshoot issues found during the development and testing phases, proposing and implementing efficient solutions. \n Design, monitor, and maintain QA reports, KPIs, and quality trends to evaluate the effectiveness of QA processes. \n Communicate accurately the status and risks for ongoing work and timelines to stakeholders. \n \n What You Have: \n \n Expert-level proficiency in SQL and Python. \n Hands-on experience with DBT, Vertex, and Colab. \n Strong experience with agile development methodologies. \n Knowledge of software QA methodologies, tools, and processes. \n Familiarity with CI/CD tools and methods. \n Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience. \n \n The ideal Data QA Engineer for your environment should possess: \n 1. **Expertise in SQL**: Profound knowledge of SQL to craft intricate queries, especially in BigQuery, to validate data structures, relationships, and values. Their SQL expertise is foundational for comprehensive data validation and ensures that complex datasets are correctly interrogated. \n 2. **Python Mastery**: Proficient in Python scripting for developing automation tasks, custom validation scripts, and integrating with GCP services. Their Python expertise is pivotal for building custom QA tools and bridging various services in your tech stack. \n 3. **BigQuery Proficiency**: Ability to optimize for performance and deeply understand BigQuery's unique functions, using it as a primary tool for data validation. \n 4. **dbt Familiarity**: Experience with dbt for creating and validating data models, utilizing its testing functions, and automating these tests. \n 5. **Looker Understanding**: Capability to validate LookML models, ensuring that visualizations correctly represent the data underneath. \n 6. **GCP Automation Tools**: Skilled in GCP's tools, especially Cloud Composer, for orchestrating automated QA workflows. \n 7. **Version Control and CI/CD**: Knowledge of Git for versioning and familiarity with CI/CD processes, particularly in a dbt context. \n 8. **Data Quality Monitoring**: Proficiency with tools that monitor data quality, potentially leveraging Python for custom solutions. \n 9. **Containerization**: Knowledge of Docker and Kubernetes for deploying automation tasks within GCP. \n 10. **Integration and Performance Testing**: Ability to validate the entire data transformation pipeline from source to visualization and ensure optimal query and transformation performance. \n This individual's expertise in SQL and Python, combined with their experience in the mentioned tools and practices, will equip them to uphold and assure data quality in your specific environment. \n Thanks & Regards \n Pinki Kumari \n Technical Recruiter \n Desk No: +1- 4698071673 Email:  pinki@anveta.com   | URL: http://www.anveta.com Address: 1333 Corporate Drive, Suite #108 Irving, TX 75038, USA \n Job Type: Contract \n Salary: $60.00 - $65.00 per hour \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n SQL: 1 year (Preferred) \n Selenium: 1 year (Preferred) \n Test automation: 1 year (Preferred) \n \n Work Location: Remote"}, "ac7d6a873c091afd": {"terms": ["data engineer"], "salary_min": 108678.0, "salary_max": 163000.0, "title": "Senior Data Engineer", "company": "Bayer", "desc": "At Bayer we\u2019re visionaries, driven to solve the world\u2019s toughest challenges and striving for a world where 'Health for all Hunger for none\u2019 is no longer a dream, but a real possibility. We\u2019re doing it with energy, curiosity and sheer dedication, always learning from unique perspectives of those around us, expanding our thinking, growing our capabilities and redefining \u2018impossible\u2019. There are so many reasons to join us. If you\u2019re hungry to build a varied and meaningful career in a community of brilliant and diverse minds to make a real difference, there\u2019s only one choice. \n \n  Senior Data Engineer \n \n  OUR TASKS AND RESPONSIBILITIES \n \n  The primary responsibilities of this role, Senior Data Engineer, are to: \n \n \n \n  Develops strategies to identify, acquire and use appropriate data sets to develop practical solutions and support decision making; \n  Defines the strategy and engineering guidelines for major data platforms jointly with the data architect Governance; \n  Ensures to implement efficient data access control mechanisms to different raw data sources both on-premises and cloud environments; \n  Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability; \n  Creates and maintains optimal data pipeline architecture; \n  Builds an infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using various state of the art and big data technologies; \n  Architects, builds and manages a robust, scalable, data pipeline in a hybrid-cloud environment that provides data processing capabilities to meet functional / non-functional business requirements; \n  Responsible for establishing and continuously improving sustainable, efficient, scalable, adaptable data processes and data processing applications; \n  Supports the development of continuous integration processes and infrastructure; \n  Analyzes large and complex data sets and models to gain insights and build suitable data models; \n  Assembles large, complex data sets (e.g. text, time series, imagery) into a useful format for analysis using fit-for-purpose database technologies; \n  Builds services and tools to make data more accessible to all data consumers (tools such as searchable metadata, API gateway); \n  Ensures end-to-end pipeline orchestration; \n  Supports the further development of existing enterprise data analytics solutions and be available as a contact person for data support; \n  Responsible for participating in the data warehouse by continuously improving ELT and ETL processes for the data lakes and data warehouses; \n  Supports software architecture decisions by writing, maintaining, and reviewing software code and ensures the code quality by automated testing; \n  Builds semantic data layers and knowledge graphs using fit-for-purpose methodology and technologies e.g. linked data concept, RDF, triple stores, graph databases to make core data structures that have already been discovered findable, accessible and reusable in an efficient way to for data knowledge workers; \n  Works with the platform development team to design & use tools for data logging and repeatable data tasks to accelerate and automate data scientist duties; \n  Responsible for processing, cleaning, structuring, and improving data model and building processes to support company-wide analytics; \n  Participate and propose systems design, architecture and deployment strategy to automate the data aggregation and decisions capturing for the lab systems; \n  Collaborating with business and technical stakeholders and application end users through various stages of design and development. \n \n \n  Relocation as well as visa sponsorship is available. \n \n  WHO YOU ARE \n \n  Your success will be driven by your demonstration of our LIFE values. More specifically related to this position, Bayer seeks an incumbent who possesses the following: \n \n  Required Qualifications: \n \n \n \n  Bachelor\u2019s degree; \n  Experience in data architecture development, data asset management, data modelling, and linked data. \n \n \n  Preferred Qualifications: \n \n \n \n  Bachelor\u2019s degree in computer science, management information systems, or a related discipline. \n \n \n  Employees can expect to be paid a salary between $108,678.00 to $163,000.00. Additional compensation may include a bonus or commission (if relevant). Additional benefits include health care, vision, dental, retirement, PTO, sick leave, etc.. This salary range is merely an estimate and may vary based on an applicant\u2019s location, market data/ranges, an applicant\u2019s skills and prior relevant experience, certain degrees and certifications, and other relevant factors. \n \n \n \n \n \n \n \n \n \n \n  YOUR APPLICATION \n \n \n \n \n \n \n  Bayer offers a wide variety of competitive compensation and benefits programs. If you meet the requirements of this unique opportunity, and want to impact our mission Science for a better life, we encourage you to apply now. Be part of something bigger. Be you. Be Bayer.  To all recruitment agencies: Bayer does not accept unsolicited third party resumes.    Bayer is an Equal Opportunity Employer/Disabled/Veterans    Bayer is committed to providing access and reasonable accommodations in its application process for individuals with disabilities and encourages applicants with disabilities to request any needed accommodation(s) using the contact information below. \n \n \n \n \n \n \n \n \n \n \n \n     Bayer is an E-Verify Employer.\n    \n \n \n \n \n \n \n \n \n \n \n \n  Location: \n \n \n     United States : Missouri : Chesterfield || United States : Residence Based : Residence Based\n    \n \n \n \n \n \n  Division: \n \n \n     Crop Science\n    \n \n \n \n \n \n  Reference Code: \n \n \n     800274\n    \n \n \n \n \n \n \n \n \n \n \n \n \n  Contact Us \n \n \n \n \n \n \n \n \n \n \n \n  Email: \n \n \n     hrop_usa@bayer.com"}, "3d323d9a78671d61": {"terms": ["data engineer"], "salary_min": 104437.12, "salary_max": 132240.66, "title": "Data Engineer (contract)", "company": "MultiPlan Inc.", "desc": "JOB SUMMARY:\n  \n \n  This TEMPORARY role will be part of the team responsible for developing and deploying Engineering and Integration solutions. Primary responsibility will be to work closely with the Data Engineering team, Data Architects and Machine Learning Team to implement data solutions for the organization using Python, Java, Kafka and other big data solutions, creating technical specification documents and test plans. Also provide support for the data solutions across the enterprise.\n  \n \n \n  JOB ROLES AND RESPONSIBILITIES:\n    1.) Understand business processes and how they are modeled in various systems \n    2.) Work with business users, technology teams, and executives to understand their data needs to create innovative solutions to fulfil them\n    3.) Implement data structures, workflows, and integrations between enterprise platforms to ensure the accurate and timely execution of business processes.\n    4.) Maintain scalable data pipelines to support continuing increases in data volume and complexity.\n    5.) Adhere to established best practices on data integration/engineering, as well as the future of our data infrastructure\n    6.) Managing and improving the performance of our database, queries, tools, and solutions \n    7.) Creating and maintaining data warehouse, databases, tables, SQL queries, and ingestion pipelines to power reports(Tableau), dashboards, predictive models, and downstream analysis \n    8.) Writing complex and efficient queries to transform raw data sources into easily accessible models for our teams and reporting platforms\n    9.) Prepare data for predictive and prescriptive modeling\n    10.) Identify and analyze data patterns\n    11.) Identify ways to improve data reliability, efficiency and quality\n    12.) Work with analytics, data science, and wider engineering teams to help with automating data analysis and visualization needs, advise on transformation processes to populate data models, and explore ways to design and develop data infrastructure\n    13.) Collaborate, coordinate, and communicate across disciplines and departments.\n    14.) Ensure compliance with HIPAA regulations and requirements.\n    15.) Demonstrate Company's Core Competencies and values held within.\n    16.) Please note due to the exposure of PHI sensitive data - this role is considered to be a High Risk and priveleged Role.\n    17.) The position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary.\n  \n \n \n  JOB SCOPE:\n  \n \n  The incumbent works independently and relies on judgment and experience to complete job responsibilities. The incumbent possesses an extensive range of knowledge of practices and procedures within the field and acts a resource for less experienced team members. Work is varied and complex.\n  \n \n \n \n \n \n  JOB REQUIREMENTS (Education, Experience, and Training):\n  \n \n \n \n Minimum high school diploma and four (4) years' related experience, three (3) of which should be inclusive of experience with OOP, SQL, schema designing, data modeling, designing, building, and maintaining data processing systems. Bachelors' degree in computer science, information technology or a similarly relevant field is highly preferred. \n Required licensures, professional certifications, and/or Board certifications as applicable \n Experience with advanced analytics tools for Object-Oriented/object function scripting using languages such as R, Python, Java, others. \n Database development experience using SQL, SPARK, or BigQuery and experience with a variety of relational, NoSQL oriented databases like Hadoop, MongoDB, Cassandra  \n Experience in triaging data issues, analyzing end-to-end data pipelines and working with business users in resolving issues. \n Experience in working with data governance/data quality and data security teams and specifically data stewards and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification. \n Exposure to Big Data Development using Hive, Impala, Spark, and familiarity with Kafka (preferred) \n Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics \n Exposure to agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines.  \n Exposure to containerization using Docker, Kubernetes etc. \n Excellent communication skills (verbal, listening and written) \n Ability to build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata and workload management.  \n Ability to work with both IT and business in integrating analytics and data science output into business processes and workflows. \n An agile learner who brings strong problem-solving skills and enjoys working as part of a technical, cross functional team to solve complex data problems \n Able to prioritize and manage multiple projects and requests at any one time \n Strong attention to detail when identifying data relationships, trends, and anomalies. \n Thinking through long-term impacts of key design decisions and handling failure scenarios. \n Ability to effectively share technical information, communicate technical issues and solutions to all levels of business \n Ability to meet strict deadlines, work on multiple tasks and work well under pressure \n Individual in this position must be able to work in a standard office environment which requires sitting and viewing monitor(s) for extended periods of time, operating standard office equipment such as, but not limited to, a keyboard, copier and telephone \n \n \n \n  As an Equal Opportunity Employer, the Company will provide equal consideration to all employees and job candidates without regard to sex, age, race, marital status, sexual orientation, religion, national origin, citizenship status, physical or mental disability, political affiliation, service in the Armed Forces of the United States, or any other characteristic protected by federal, state, or local law."}, "dfdfebe2c9fd3354": {"terms": ["data engineer"], "salary_min": 103882.86, "salary_max": 131538.84, "title": "Data Engineer", "company": "helm", "desc": "Minimum Qualifications \n \u00b7 Security Clearance -  Must have a current Secret level security clearance  and therefore all candidates must be a U.S. Citizen with a willingness to go to TS/SCI and take the CI poly after starting the position. \n \u00b7 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n \u00b7 Experience with programming languages such as Python and Java. \n \u00b7 Proficiency with acquisition and understanding of network data and the associated metadata. \n \u00b7 Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n \u00b7 Experience with Kibana and Elasticsearch. \n \u00b7 Familiarity with various log formats such as JSON, XML, and others. \n \u00b7 Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). \n \u00b7 Ability to decompose technical problems and troubleshoot system and dataflow issues. \n \u00b7  Must have a Security+ or similar certification. \n \u00b7  Must be able to work on customer site in Columbia, MD at least 4 days a week. (Subject to change) \n Desired Skills (Optional) \n \u00b7 Experience with NOSQL databases such as Accumulo desired \n \u00b7 Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer. \n Job Type: Full-time \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Informatica: 1 year (Preferred) \n SQL: 1 year (Preferred) \n Data warehouse: 1 year (Preferred) \n \n Security clearance: \n \n Top Secret (Preferred) \n \n Work Location: Remote"}, "2dbb614132c7e30f": {"terms": ["data engineer"], "salary_min": 104957.18, "salary_max": 132899.17, "title": "Data Engineer", "company": "ArchWell Health", "desc": "ArchWell Health is a new, innovative healthcare provider devoted to improving the lives of our senior members. We deliver best-in-class care at comfortable, accessible neighborhood clinics where seniors can feel at home and become part of a vibrant, wellness-focused community. Our members experience greater continuity of care, as well as the comfort of knowing they will be treated with respect by people who genuinely care about them, their families, and their communities. \n \n \n Duties/Responsibilities: \n \n \n Build data integrations from internal and external sources to centralize data into a Data Warehouse environment. \n Monitor data integration operations, data quality, troubleshoot, and resolve problems. \n Profile data sources and map to target table formats. \n Develop and monitor data quality processes and address problems. \n Develop, unit test and system test integration components. \n Create support documentation describing the functionality of the integrations. \n Participating in technical design & requirements gathering meetings. \n Participate in planning and implementing data integration and data migration activities. \n Perform QA tests to ensure data integrity and quality. \n Research data issues between source systems and the data warehouse. \n \n Required Skills/Experience: \n \n \n Bachelor\u2019s degree required; Master's degree (in data science, computer science or MIS, mathematics, engineering, or related field) preferred. \n 5+ years of prior experience in Data Management / ETL / ELT / Data Warehousing \n Experience in writing Data Quality routines for cleansing of data and capturing confidence score \n Experience with master data management \n Strong knowledge of Structured Query Language (SQL) and Transact-SQL (T-SQL) \n Experience using scripting languages such as JavaScript or Python \n Experience Healthcare data models, datasets, and source systems (e.g. EHR, claims, labs, etc.) \n Experience with healthcare reference data (ICD, CPT etc.) \n Experience with agile delivery methodologies \n Data Modeling experience preferred. \n Strong organizational, administrative, and analytical skills required. \n Experience managing and working in cloud environments such as Amazon Web Services or Azure \n Knowledge of HIPAA; ability to implement systems and processes in accordance with regulations \n Excellent interpersonal communication skills, both written and verbal \n  ArchWell Health is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to their race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other protected classification."}, "6d7b80ba9d7b2b94": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 128998.086, "salary_max": 163340.33, "title": "Senior Big Data Engineer", "company": "Wikimedia Foundation", "desc": "Summary \n  The Wikimedia Foundation is looking for a Senior Data Engineer to join our Data Engineering team. As a Data Engineer, you will be responsible for building, maintaining, and expanding the shared data infrastructure that supports insights, research, and new data products, in the Foundation as well as the Wiki Movement. This includes everything from building scalable pipeline infrastructure, and working on the event streaming platform to providing scalable data-serving solutions. \n  We are a fully remote, internationally distributed team. We see each other in person 1-2 times a year during one of our off-sites (the last few have been in places like Berlin, Copenhagen, and New York) or Wikimania, the annual international conference for the Wiki community. \n  Open to candidates located in time zones UTC-8 to UTC+2. \n  You are responsible for: \n \n Building scalable data pipeline infrastructure, libraries and processes using Airflow, Spark, Flink, Kafka \n Implementing data quality monitoring that alerts the team of, possible data issues \n Implementing a data governance and lineage solution for all Wikimedia data \n Designing the shared data platform that supports use cases for critical aspects of the Wikimedia mission: product analytics, harassment prevention, image classification, bot detection, DDoS attacks flagging and many more \n Improve operational excellence of the data platform \n \n Skills and Experience: \n \n 5+ years of relevant industry experience \n Advanced working knowledge of SQL, relational databases, query authoring, ideally in a variety of flavors (in our team alone we deal with MariaDB, HiveQL, CassandraQL, Spark SQL and Presto) \n Experience with one or more programming languages such as Python, Scala, and Java \n Experience building data pipelines using tools such as Airflow, Spark, Gobblin, Yarn \n Familiarity with stream processing systems using Kafka, Spark streaming and/or Flink \n Excellent written and verbal communication skills \n Strong interpersonal and collaboration skills \n BS or MS degree, preferably in Computer Science, or equivalent work experience \n \n Qualities that are important to us: \n \n Commitment to the mission of the organization and our values \n Commitment to our guiding principles \n Commitment to diversity, equity, and inclusion \n Cross-cultural sensitivity and awareness \n Collaborative working experience \n \n Additionally, we'd love it if you have: \n \n Experience with Hadoop \n Understanding of related disciplines including Machine Learning, Statistics, Privacy and Algorithms \n Experience working with site reliability engineers \n \n About the Wikimedia Foundation \n  The Wikimedia Foundation is the nonprofit organization that operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. We host Wikipedia and the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. \n  The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive donations from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA. \n  As an equal opportunity employer, the Wikimedia Foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We encourage people with a diverse range of backgrounds to apply. We do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics. \n  The Wikimedia Foundation is a remote-first organization with staff members including contractors based in more than 50 countries. Salaries at the Wikimedia Foundation are set in a way that is competitive, equitable, and consistent with our values and culture. The anticipated annual pay range of this position for applicants based within the United States is US$ 105,309 to US$ 163,646 with multiple individualized factors, including cost of living in the location, being the determinants of the offered pay. For applicants located outside of the US, the pay range will be adjusted to the country of hire. We neither ask for nor take into consideration the salary history of applicants. The compensation for a successful applicant will be based on their skills, experience and location. \n  All applicants can reach out to their recruiter to understand more about the specific pay range for their location during the interview process. \n  If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or +1 (415) 839-6885. \n  More information \n  U.S. Benefits & Perks   Wikimedia Foundation   Applicant Privacy Policy   News from across the Wikimedia movement   Blog   Wikimedia 2030   Our Commitment to Equity   This is Wikimedia Foundation   Facts Matter   Our Projects   Our Tech Stack"}, "448523fdeb022e38": {"terms": ["data engineer"], "salary_min": 170000.0, "salary_max": 230000.0, "title": "Staff Data Engineer", "company": "Chartbeat, Inc.", "desc": "Tubular and Lineup have partnered with Chartbeat to help you grow reach and revenue for your content. \n \n \n \n   Chartbeat\u2019s (www.chartbeat.com) mission is to help content creators around the world better connect with their audiences.\n   \n \n \n   In 2023, Chartbeat joined forces with Tubular, the leader in global social video intelligence and measurement, and Lineup Systems, the leading global provider of media sales technology. Together, we\u2019re expanding the ecosystem of insights we provide to enterprise content creators who are developing audiences and revenue streams across channels. We now serve more than 1,000 brands globally, including \n    The New York Times, the BBC, ESPN, Gannett, Vox, BuzzFeed, Paramount, WB, Mediahuis, Hearst, McClatchy,  and \n    GQ .\n   \n \n \n   You'll be joining a diverse group of focused, hard-working people who are passionate about doing work that's challenging and fun\u2014and who strive to maintain a healthy work/life balance.\n   \n \n Are you a highly experienced software engineer passionate about building products involving large-scale, interactive computation? Are you interested in working with best in class technologies such as Spark, Kubernetes, ElasticSearch, Python and other languages? Do you want to make an impact with a close-knit team working on the core customer-facing intelligence products powering a successful and rapidly growing company? \n \n \n  In this job you will: \n \n Build mission-critical data processing pipelines underpinning our core suite of customer-facing social-media analytics products using Spark/PySpark, ElasticSearch and other petabyte-scale compute technologies \n Work collaboratively with a small product-focused, cross-functional team \n Own and develop a technical roadmap for mission critical technical components \n Lead the adoption of collaborative engineering best practices within your technical team \n Mentor other engineers within your team through pair/mob programming \n Lead and participate in technical design sessions \n Work closely with a small team of talented systems engineers working on petabyte-scale analytics systems supporting analytical workloads involving metadata for billions of videos \n \n \n \n  Your Responsibilities will include: \n \n Design, implement, and support large-scale data processing pipelines using Kubernetes, Spark, Kafka, ElasticSearch, and more \n Programming in Python, Scala, and Java \n Mentorship of engineers through collaborative development \n Participation in interviewing processes, as needed \n Participation in the Data services on-call rotation \n \n \n \n  Ideal candidates will have: \n \n 8+ years of experience as a senior member of the technical staff at a data-intensive engineering company \n Proven track record leading large-scale engineering projects \n Experience working on end-user products, ideally in enterprise SaaS is highly desirable \n \n Salary & Benefits (including Pay Transparency information) \n  Flexible paid time off \n  100% employer-paid Medical, Dental and Vision plans \n  401k plan \n  Life/AD&D & Disability Benefits \n  Hackathons \n  And more! \n \n \n  The pay range for this position is: $170,000 - $230,000 per year. Please note that the foregoing compensation information is a good-faith assessment associated with this position only and is provided pursuant to applicable law. \n \n \n Diversity, Equity, and Inclusion Statement \n \n \n   At Chartbeat we strive to create and continually grow as a company where all employees are able to be their authentic selves. We are committed to recruiting, hiring, and retaining employees from different backgrounds, viewpoints, and experiences. Our strength is our diversity and we are dedicated to continuously reflect upon, and evolve our efforts to maintain a diverse, equitable and inclusive ecosystem.\n   \n \n \n Equal Opportunity Employment Statement \n \n \n   Chartbeat is an Equal Opportunity Employer and does not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by applicable national, federal, state, or local law."}, "05de727107b9cd4c": {"terms": ["data engineer"], "salary_min": 85000.0, "salary_max": 115000.0, "title": "Data Engineer", "company": "TCA Consulting Group Inc.", "desc": "This is a direct hire position, Hybrid in West Palm Beach \n This role enables business and HR leaders through the provision of internal workforce and external market insights to take informed decisions and enact recommendations that drive workforce productivity and engagement, ensuring everyone has a suitably qualified and experienced workforce that delivers for its customers. Working as part of the wider HR team to support the attraction, retention and development of critical skills that enable business performance. Experience of working with cloud based Human Capital Management Systems e.g Ceridian Dayforce or Oracle would be an advantage plus data visualization via Power BI or SQL. \n Education \n \n A degree in mathematics, statistics, computer science, information management, or economics \n ADP and Ceridian Dayforce Reporting experience a plus \n \n Responsibilities: \n To be successful in this role you must be able to \n \n Analyze and synthetize data. You will demonstrate how to apply basic techniques for the analysis of research data and synthesis of findings. You have proven capability to effectively involve others in analysis and reporting, presenting clear findings that colleagues can understand and use. \n Communicate. You will have demonstrable communication skills to engage and inform technical and non-technical stakeholders. You will have the capability to host discussions within a multidisciplinary team, with capacity to bring people to a consensus. \n Lead Data management. You can explain the need for data governance and how it works in relation to other organizational governance structures. \n Data modelling, cleansing and enrichment. You will have demonstrable skills in producing data models and understand where to use different types of data models. You can explain the needs for different tools and can compare uses for different data models. You will be able to reverse-engineer a data model from a live system. You will be able to choose the right industry-recognized data-modelling patterns and standards for the task in hand. \n Data quality assurance, validation, and linkage. You can demonstrate appropriate ways to collect, collate and prepare data. You can provide levels of confidence to data to ensure it is accurate and fit for purpose. You can prepare and cleanse data with limited guidance. \n Data visualization. You can use the most appropriate medium to visualize data to tell compelling stories that are relevant to business goals and can be acted upon. You can present, communicate, and disseminate data appropriately and with influence. \n IT and mathematics. You can apply your knowledge and experience of IT and mathematical statistical skills, including tools and techniques. You can identify, adopt, and select those most appropriate for the task in hand. \n Statistical methods and data analysis. You have a proven understanding how and when to practically apply existing best practice solutions. \n Logical and creative thinking. You can respond to problems in databases, data processes, data products and services as they occur. You can initiate actions, monitor services, and identify trends to resolve problems. You can determine the appropriate remedy and assist with its implementation, and with preventative measures. \n Project management. You can apply your knowledge and experience of project management methodologies, including tools and techniques. \n \n Job Type: Full-time \n Pay: $85,000.00 - $115,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote"}, "a1389140dcb98358": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 128998.086, "salary_max": 163340.33, "title": "Senior Big Data Engineer", "company": "Wikimedia Foundation", "desc": "Summary \n  The Wikimedia Foundation is looking for a Senior Data Engineer to join our Data Engineering team. As a Data Engineer, you will be responsible for building, maintaining, and expanding the shared data infrastructure that supports insights, research, and new data products, in the Foundation as well as the Wiki Movement. This includes everything from building scalable pipeline infrastructure, and working on the event streaming platform to providing scalable data-serving solutions. \n  We are a fully remote, internationally distributed team. We see each other in person 1-2 times a year during one of our off-sites (the last few have been in places like Berlin, Copenhagen, and New York) or Wikimania, the annual international conference for the Wiki community. \n  Open to candidates located in time zones UTC-8 to UTC+2. \n  You are responsible for: \n \n Building scalable data pipeline infrastructure, libraries and processes using Airflow, Spark, Flink, Kafka \n Implementing data quality monitoring that alerts the team of, possible data issues \n Implementing a data governance and lineage solution for all Wikimedia data \n Designing the shared data platform that supports use cases for critical aspects of the Wikimedia mission: product analytics, harassment prevention, image classification, bot detection, DDoS attacks flagging and many more \n Improve operational excellence of the data platform \n \n Skills and Experience: \n \n 5+ years of relevant industry experience \n Advanced working knowledge of SQL, relational databases, query authoring, ideally in a variety of flavors (in our team alone we deal with MariaDB, HiveQL, CassandraQL, Spark SQL and Presto) \n Experience with one or more programming languages such as Python, Scala, and Java \n Experience building data pipelines using tools such as Airflow, Spark, Gobblin, Yarn \n Familiarity with stream processing systems using Kafka, Spark streaming and/or Flink \n Excellent written and verbal communication skills \n Strong interpersonal and collaboration skills \n BS or MS degree, preferably in Computer Science, or equivalent work experience \n \n Qualities that are important to us: \n \n Commitment to the mission of the organization and our values \n Commitment to our guiding principles \n Commitment to diversity, equity, and inclusion \n Cross-cultural sensitivity and awareness \n Collaborative working experience \n \n Additionally, we'd love it if you have: \n \n Experience with Hadoop \n Understanding of related disciplines including Machine Learning, Statistics, Privacy and Algorithms \n Experience working with site reliability engineers \n \n About the Wikimedia Foundation \n  The Wikimedia Foundation is the nonprofit organization that operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge freely. We host Wikipedia and the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. \n  The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive donations from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA. \n  As an equal opportunity employer, the Wikimedia Foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We encourage people with a diverse range of backgrounds to apply. We do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics. \n  The Wikimedia Foundation is a remote-first organization with staff members including contractors based in more than 50 countries. Salaries at the Wikimedia Foundation are set in a way that is competitive, equitable, and consistent with our values and culture. The anticipated annual pay range of this position for applicants based within the United States is US$ 105,309 to US$ 163,646 with multiple individualized factors, including cost of living in the location, being the determinants of the offered pay. For applicants located outside of the US, the pay range will be adjusted to the country of hire. We neither ask for nor take into consideration the salary history of applicants. The compensation for a successful applicant will be based on their skills, experience and location. \n  All applicants can reach out to their recruiter to understand more about the specific pay range for their location during the interview process. \n  If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or +1 (415) 839-6885. \n  More information \n  U.S. Benefits & Perks   Wikimedia Foundation   Applicant Privacy Policy   News from across the Wikimedia movement   Blog   Wikimedia 2030   Our Commitment to Equity   This is Wikimedia Foundation   Facts Matter   Our Projects   Our Tech Stack"}, "5ea2e890ce4fae77": {"terms": ["data engineer"], "salary_min": 60.0, "salary_max": 80.0, "title": "Snowflake Data Engineer \u2014 Sr", "company": "Intellibus", "desc": "Are you a Data Engineer working at a Large Financial Institution and being told by your leadership that you are too hands-on or detail-oriented or think and work like a start-up? \n Imagine working at  Intellibus  to engineer platforms that impact billions of lives around the world. With your passion and focus we will accomplish great things together! \n We are looking forward to you joining our Platform Engineering Team. \n Our Platform Engineering Team is working to solve the Multiplicity Problem. We are trusted by some of the most reputable and established FinTech Firms. Recently, our team has spearheaded the Conversion & Go Live of apps that support the backbone of the Financial Trading Industry. \n We are looking for Engineers who can \n \n Create Data modeling \n Work on Snowflake modeling \u2013 roles, databases, schemas, ETL toolswith cloud-driven skills \n Work on SQL performance measuring, query tuning, and database tuning \n Handle SQL language and cloud-based technologies \n Set up the RBAC model at the infra and data level. \n Work on Data Masking / Encryption / Tokenization, Data Wrangling / ECreLT / Data Pipeline orchestration (tasks). \n Setup AWS S3/EC2, Configure External stages and SQS/SNS \n Perform Data Integration e.g. MSK Kafka connect and other partners like Delta lake (data bricks) \n \n We work closely with \n \n Data Wrangling \n ETL \n Talend \n Jasper \n Java \n Python \n Unix \n AWS \n Data Warehousing \n Data Modeling \n Database Migration \n ECreLT \n RBAC model \n Data migration \n \n Our Process \n \n Schedule a 15 min Video Call with someone from our Team \n 4 Proctored GQ Tests (< 2 hours) \n 30-45 min Final Video Interview \n Receive Job Offer \n \n If you are interested in reaching out to us, please apply and our team will contact you within the hour. \n Job Type: Full-time \n Pay: $60.00 - $80.00 per hour \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n Data Wrangling: 7 years (Preferred) \n Snowflake: 7 years (Preferred) \n ETL: 7 years (Preferred) \n \n Work Location: Remote"}, "493f57436be75aa7": {"terms": ["data engineer"], "salary_min": 118000.0, "salary_max": 125000.0, "title": "Data Integration Engineer", "company": "Worldly", "desc": "Senior Data Integration Engineer \n  Location: Remote - US \n  About Worldly \n  Worldly is the world\u2019s most comprehensive impact intelligence platform \u2014 delivering real data to businesses on impacts within their supply chain. Worldly is trusted by 40,000 global brands, retailers, and manufacturers to provide the single source of ESG intelligence they need to accelerate business and industry transformation. \n  Through strategic and meaningful customer relationships, Worldly provides key insights around supplier performance, product impact, trends analysis, and compliance. When a company wants to change how business is done, we enable that systemic shift. \n  Backed by a dedicated global team of individuals aligned by values, Worldly proudly operates as a public benefit corporation with backing from mission-aligned investors. Want to learn more? Read our story. \n  About The Opportunity \n  We currently have an opening for a Data Integration Engineer to join our team. The hire will play a leading role in expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams and new product development. \n  The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Integration Engineer will work in conjunction with the Business Operations Team responsible for integrations and data and Engineering Team, and will support environmental and business data analysts on data initiatives and new product development, and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. \n  The right candidate will be excited by the prospect of optimizing and extending our company\u2019s data architecture to support our next generation of products and data initiatives. Passion for sustainability and/or experience with sustainability business data is a plus! \n  What You'll Do \n \n  Assemble large, complex data sets focused on measuring sustainability in product supply chains and supporting business optimization metrics \n  Create and maintain optimal data pipeline architecture for new and emerging products \n  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. \n  Help build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies. \n  Build analytics tools that utilize the data pipeline to provide actionable insights for users and for new product development \n  Work with stakeholders including the Customer Success, Product, Development, and Marketing teams to assist with data-related technical issues and support their data infrastructure needs. \n  Keep our data separated and secure across international boundaries through multiple data centers and AWS regions. \n  Create data tools for data analytics team members that assist them in building and optimizing our product into an innovative industry leader. \n  Work with data and analytics experts to strive for greater functionality in our data systems. \n \n  We'd Like to See \n  We are looking for a candidate with 3-5 years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have the following qualifications: \n \n  Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases (including AWS). \n  Extensive experience building and optimizing complex data pipelines, architectures, and data sets. \n  Strong analytic skills related to working with unstructured datasets. \n  Experience building processes supporting data transformation, data structures, metadata, dependency, and workload management. \n  A successful history of manipulating, processing, and extracting value from large disconnected datasets. \n  Experience supporting and working with cross-functional teams in a dynamic environment. \n  Experience with relational SQL databases, including Postgres. \n  Experience integrating with 3rd party services via API such as Zendesk, SFDC, Mailchimp, SendGrid, etc. \n  Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc is a plus. \n  Interest and familiarity with sustainable business data and practices is a plus. \n \n  What We Can Offer You \n \n  Medical, Dental and Vision Insurance offered through multiple PPO options. 90% employee premium and 60% spouse/dependent premium covered by Worldly. \n  Company sponsored 401k with up to 4% match. \n  Incentive Stock Options \n  100% Parental Paid Leave \n  Unlimited PTO \n  12 company holidays \n \n  Life at Worldly \n  Our team is motivated to transform the way products are made. By helping our customers succeed in a new era of sustainable production, we are able to build technology that makes a difference on a planetary level. \n  Our team represents over 15 countries and brings unique experiences from technology to farming to the table. Surround yourself with kind, enthusiastic, and dedicated people who put collaboration and growth at the center of our shared goals. \n  Benefits and Perks \n \n  Earn a competitive salary and performance-based bonuses. Get healthcare, retirement matching, and equity for US employees. \n  Use the office stipend to get the supplies you need. Combat zoom fatigue with no-meeting Fridays. \n  Flexible time off. Take the time you need to recharge. Our culture encourages team members to explore and rest to be their best selves. \n  We're remote, not lonely. Join the culture committee, coffee chats, or a variety of other interest groups. \n \n  Equity Statement \n  We believe it\u2019s essential to reflect the diversity of those we strive to serve. True innovation happens when everyone has room at the table, including the tools, resources, and opportunity to excel. We\u2019re dedicated to building a culturally and experientially diverse team that leads and works with empathy and respect. \n  Compensation Information:  $118,000 - $125,000 Annually \n   \n 2JId0fRHNJ"}, "a62cac15387d7f48": {"terms": ["data engineer"], "salary_min": null, "salary_max": null, "title": "Data QA Engineer", "company": "The Data Sherpas", "desc": "Who We Are: \n  The Data Sherpas are a team of highly skilled and motivated engineers that help our clients at every phase of their cloud journey. If it touches the cloud, involves data, or lives as an application, we have either worked on it or have the skills and expertise to accomplish it. \n  What We Are Looking For: \n  We are seeking a dedicated and technically skilled Data QA Engineer. The Engineer will work closely with development leads and data engineers to define analysis strategies and create test plans that ensure the highest quality of code delivery. The candidate will build, manage, and maintain a robust testing environment. \n  What You'll Do: \n \n Collaborate with development leads and data engineers to define analysis strategy and test plans to ensure quality delivery. \n Define, build, automate, and execute testing for code in an agile practice in accordance with sprint planning. \n Build, manage, and maintain unit, integration, and regression tests using DBT, Vertex, and Colab. \n Troubleshoot issues found during the development and testing phases, proposing and implementing efficient solutions. \n Design, monitor, and maintain QA reports, KPIs, and quality trends to evaluate the effectiveness of QA processes. \n Communicate accurately the status and risks for ongoing work and timelines to stakeholders. \n \n What You Have: \n \n Expert-level proficiency in SQL and Python. \n Hands-on experience with DBT, Vertex, and Colab. \n Strong experience with agile development methodologies. \n Knowledge of software QA methodologies, tools, and processes. \n Familiarity with CI/CD tools and methods. \n Bachelor's degree in Computer Science, Engineering, related field, or equivalent experience. \n \n \n \n  This is a contract to the end of the year with an expectation to extend into 2024 \n  We cannot work with third-party agencies at this time. Resumes submitted via unapproved agencies will be automatically rejected."}, "03f52a29aa662955": {"terms": ["data engineer"], "salary_min": 75000.0, "salary_max": 150000.0, "title": "Senior Software Engineer - Data (Remote)", "company": "Sumitomo Mitsui Banking Corporation", "desc": "Join us on our mission to create a completely new, 100% digital bank that truly serves customers' best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch - and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience). \n \n  The anticipated salary range for this role is between $75,000.00 and $150,000.00. The specific salary offered to an applicant will be based on their individual qualifications, experiences, and an analysis of the current compensation paid in their geography and the market for similar roles at the time of hire. The role may also be eligible for an annual discretionary incentive award. In addition to cash compensation, SMBC offers a competitive portfolio of benefits to its employees. \n \n  We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the second largest bank in Japan and the 12th largest bank in the world with operations in over forty countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products. \n \n  It is the best of both worlds, and we are seeking proven marketing leaders to propel us towards a national launch. We have both the ambitious growth plans and the 'patient capital' necessary to execute a multi-year plan. Join us on the journey to deliver an exciting concept of evolved banking. \n \n \n \n  Job Summary \n \n \n  Jenius Bank is looking for a hands-on Sr. Software Engineer - Data proficient in Java, Scala, and Python languages. You'll be part of the team that is responsible for building the Data and Analytics Platform for Jenius Bank. As a Sr. Software Engineer - Data, you will get an opportunity to perform proof of concept on new cloud technologies and build a highly scalable data platform to support critical business functions, create rest APIs to expose data services for internal and external consumers. \n \n \n \n \n  Principal Duties and Responsibilities \n \n \n \n  A solid experience and understanding of considerations for large-scale solutioning and operationalization of data warehouses, data lakes and analytics platforms within Cloud environments. \n  Monitors the Data Lake constantly and ensures that the appropriate support teams are engaged at the right times. \n  Design, build and test scalable data ingestion pipelines, perform end to end automation of ETL process for various datasets that are being ingested. \n  Determine the best way to extract application telemetry data, structure it, send to proper tool for reporting (Kafka, Splunk). \n  Work with business and cross-functional teams to gather and document requirements to meet business needs. \n  Provide support as required to ensure the availability and performance of ETL/ELT jobs. \n  Provide technical assistance and cross training to business and internal team members. \n  Collaborate with business partners for continuous improvement opportunities. \n \n \n \n \n \n  Position Specifications \n \n \n \n  Bachelor's degree in Computer Science, Computer Engineering, or Information Systems Technology \n  6+ years of experience in Data Engineering with an emphasis on Data Warehousing and Data Analytics. \n  4+ years of experience with one of the leading public clouds. \n  4+ years of experience in design and build of salable data pipelines that deal with extraction, transformation, and loading. \n  4+ years of experience with Java, Python or Scala. \n  Ability to work independently, solve problems, update the stake holders. \n  Analyze, design, develop and deploy solutions as per business requirements. \n  Strong understanding of relational and dimensional data modeling. \n  Experience in CI/CD related technologies. You will be responsible for creating CI/CD pipelines. \n  Excellent written, verbal communication skills, including experience in technical documentation and ability to communicate with senior business managers and executives. \n  Knowledge of GCP Cloud data implementation projects (Dataflow, DataProc, Cloud Composer, Big Query, Cloud Storage, GKE, Airflow, etc.) is preferred. \n \n \n \n \n  EOE STATEMENT  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n \n  CCPA DISCLOSURE  Personal Information Collection Notice: This notice contains information under the California Consumer Privacy Act (CCPA) about the categories of personal information (PI) of California residents that Manufacturers Bank collects and the business or commercial purpose(s) for which the PI may be used. We do not sell PI. More information about our collection and use of PI may be found in our CCPA Privacy Policy at https://www.manufacturersbank.com/CCPA-Privacy. Persons with disabilities may contact our Customer Contact Center toll-free at (877) 560-9812 to request the information in this Notice in an alternative format."}, "84fa80a648a2145c": {"terms": ["data engineer"], "salary_min": 100000.0, "salary_max": 180000.0, "title": "Staff Engineer - Data (Remote)", "company": "Sumitomo Mitsui Banking Corporation", "desc": "Join us on our mission to create a completely new, 100% digital bank that truly serves customers' best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch - and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience). \n \n  The anticipated salary range for this role is between $100,000.00 and $180,000.00. The specific salary offered to an applicant will be based on their individual qualifications, experiences, and an analysis of the current compensation paid in their geography and the market for similar roles at the time of hire. The role may also be eligible for an annual discretionary incentive award. In addition to cash compensation, SMBC offers a competitive portfolio of benefits to its employees. \n \n  We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the second largest bank in Japan and the 12th largest bank in the world with operations in over forty countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products. \n \n  It is the best of both worlds, and we are seeking proven marketing leaders to propel us towards a national launch. We have both the ambitious growth plans and the 'patient capital' necessary to execute a multi-year plan. Join us on the journey to deliver an exciting concept of evolved banking. \n \n \n \n  General Summary: \n \n \n  Join us in our mission to create a completely new, 100% digital bank that truly serves customers\u2019 best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch \u2013 and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience). \n  We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the 2nd largest bank in Japan and the 12th largest bank in the world with operations in over 40 countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products. \n \n \n \n \n  Principal Duties and Responsibilities: \n \n \n \n  Develop and maintain scalable data Platform, leveraging the GCP stack, including services such as BigQuery, GCE, Bigtable, Cloud Dataflow, dataproc, Airflow, Looker etc. \n  Collaborate with product engineering team to understand their requirements and help with building platform components, reusable frameworks and braining advanced tools & practices to enable faster feature development. \n  Collaborate with cross-functional teams including data scientists, analysts, and business stakeholders to understand their data needs and translate them into technical requirements. \n  Design, implement, and optimize end-to-end data pipelines, ensuring efficient and reliable data ingestion, transformation, and storage using common ETL methods & tools. \n  Optimize data storage and compute for efficiency and performance. \n  Monitor data systems and processes to identify issues and proactively implement improvements to prevent future problems. \n  Monitor and troubleshoot data pipelines, identifying and resolving performance bottlenecks and data-related issues. \n  Stay up to date with the latest developments in data engineering technologies and practices, and apply that knowledge to improve the company's data infrastructure. \n  Provide technical expertise in all aspects of data warehousing, Cloud computing and Big Data analysis pipelines. \n  Create an environment of innovation and entrepreneurship that enables a scalable data architecture to support all data across the organization \n \n \n \n \n \n  Position Specifications: \n \n \n \n  Bachelor\u2019s or master\u2019s degree in computer science, or a related field. Professional certifications in data engineering technologies are a plus.. \n  10+ years in data engineering or a related field. \n  Strong understanding of data architecture and data modeling principles, as well as proficiency in SQL and one or more programming languages like Python, Java, C#, or Scala. \n  Experience designing and implementing large-scale data systems and infrastructure. \n  In-depth knowledge of build/release systems and process \n  Proficiency in ETL/ELT processes and tools, as well as experience with data integration and data warehousing and lakehouse concepts. \n  Experience with cloud-based data technologies like GCP or Azure. \n  Familiarity designing and implementing data governance and quality principles and practices. \n  Strong problem-solving and troubleshooting skills, with the ability to identify and resolve data engineering issues and system failures. \n  Excellent communication skills, with the ability to communicate technical information to non-technical stakeholders and collaborate effectively with cross-functional teams. \n  Strong attention to detail and ability to work with complex data sets and systems. \n  Ability to stay up to date with the latest developments in data engineering technologies and practices and apply that knowledge to improve the company's data infrastructure. \n \n \n \n \n  EOE STATEMENT  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n \n  CCPA DISCLOSURE  Personal Information Collection Notice: This notice contains information under the California Consumer Privacy Act (CCPA) about the categories of personal information (PI) of California residents that Manufacturers Bank collects and the business or commercial purpose(s) for which the PI may be used. We do not sell PI. More information about our collection and use of PI may be found in our CCPA Privacy Policy at https://www.manufacturersbank.com/CCPA-Privacy. Persons with disabilities may contact our Customer Contact Center toll-free at (877) 560-9812 to request the information in this Notice in an alternative format."}, "40d11177cb70fb2d": {"terms": ["data engineer"], "salary_min": 106138.195, "salary_max": 134394.61, "title": "Data Integrity Engineer (PI Systems)", "company": "Meta", "desc": "We are delighted that you want to be part of our team! \n  We're consistently choosing to help customers overcome their IT challenges providing consulting expertise to support IT strategy, outsourced operations, staff augmentation, and digital transformation for companies such as ArcelorMittal, Air Liquide, Volvo Group, MLSE, and many more. \n  Take a look at our website, you can see some of the exciting work we are doing: https://www.metait.ca/ \n  About our customer \n  A world leader in gases, technologies, and services for Industry and Health, Air Liquide is present in 80 countries with approximately 66,000 employees and serves more than 3.6 million customers and patients. Air Liquide\u2019s ambition is to lead its industry, deliver long-term performance and contribute to sustainability thanks to a customer-centric transformation strategy relying on operational excellence, selective investments, open innovation and a network organization. Air Liquide has identified three major trends which represent growth opportunities and among them digitization. \n  Their Website: https://www.airliquide.com/ \n  How\u2019d the process work? \n  An interview with MetaIT\u2019s HR team, a chat with your future Manager here at Meta, and in case approved, a final interview directly with Air Liquide\u2019s team. \n  About the project \n  Air Liquide is deploying Aveva PI on a global scale as a foundation for smart manufacturing.Your job will be to create Aveva PI VIsion visual content for various operational facilities in the Americas. You will be an essential remote member of a Houston-centric PI data applications \n  team. \n  Responsibilities \n  Utilize style guide and content examples to create, maintain, and improve visual content in PI Vision. \n \n Modify pictures using the program Paint to create picture backgrounds. \n Utilize PI System Explorer to search for data tags and use the tags to create live content \n \n  in PI. \n \n Create functionally accurate PI Vision displays from P&IDs that summarize the \n \n  production assets for a particular facility. \n \n Develop dynamic template views using PI Vision. \n Maintain organization and records of PI Vision content in Google Drive. \n Maintain the organization of all PI Vision content folders. \n Ensure the accuracy of all PI Vision content. \n Develop content in PI Vision as a replacement for previous legacy historian content. \n \n  Requirements \n  Preferred 2 years of experience as a plant operator of a continuous process plant. \n \n Preferred 2 years of experience working with PI creating data visualization content. \n Ability to read P&IDs required. \n Basic understanding of High Performance HMIs. \n Highly motivated self-starter with strong ability and comfort working independently. \n Solution oriented, with strong analytical and problem solving skills. \n Must demonstrate an aptitude for creating high quality aesthetically pleasing visual \n \n  content. \n \n Must be fluent in English. \n Excellent written and verbal communication skills. \n Excellent organization skills and attention to detail. \n \n \n  Be willing to work from the office (near Memorial City Mall) 3 days per week. \n \n  Hiring Methods and overall information. \n \n  Air Liquide provides their own Laptop. \n  Average of 168 hours per month. \n  Hiring Method: As Contractor (1099 basis) \n  Remote role, but since the customer's branch is located in Houston, you may be invited to work in the office every once in a while."}, "ab46dacfb2e36c8e": {"terms": ["data engineer"], "salary_min": 133742.28, "salary_max": 169347.53, "title": "Data Engineer TS/SCI", "company": "Cyberjin", "desc": "Hybrid/Remote position \n  Looking for a talented Data Engineer to support the acquisition of mission critical and mission support data sets. The preferred candidate will have a background in supporting cyber and/or network related missions within the military spaces, as either a developer, analyst or engineer. Work is mostly on customer site in San Antonio, TX with some hybrid support. \n \n  Essential Job Responsibilities \n  The ideal candidate will have worked with big data systems, complex structured and unstructured data sets, and have supported government data acquisition, analysis, and/or sharing efforts in the past.  \n To excel in the position, the candidate shall have a strong attention to detail, be able to understand technical complexities, and have the willingness to learn and adapt to the situation.  \n The candidate will work both independently and as part of a large team to accomplish client objectives.  \n Minimum Qualifications \n  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata. \n  Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). \n  Ability to decompose technical problems and troubleshoot system and dataflow issues. \n  Must be able to work on customer site most of the time. \n  Preferred Requirements \n  Experience with NOSQL databases such as Accumulo desired \n  Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer. \n   \n 66FWNyaFlG"}, "2058570090966367": {"terms": ["data engineer"], "salary_min": 133742.28, "salary_max": 169347.53, "title": "Data Engineer TS/SCI", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Looking for a talented Data Engineer to support the acquisition of mission critical and mission support data sets. The preferred candidate will have a background in supporting cyber and/or network related missions within the military spaces, as either a developer, analyst or engineer. Work is mostly on customer site in San Antonio, TX with some hybrid support. \n \n  Essential Job Responsibilities \n  The ideal candidate will have worked with big data systems, complex structured and unstructured data sets, and have supported government data acquisition, analysis, and/or sharing efforts in the past.  \n To excel in the position, the candidate shall have a strong attention to detail, be able to understand technical complexities, and have the willingness to learn and adapt to the situation.  \n The candidate will work both independently and as part of a large team to accomplish client objectives.  \n Minimum Qualifications \n  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata. \n  Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). \n  Ability to decompose technical problems and troubleshoot system and dataflow issues. \n  Must be able to work on customer site most of the time. \n  Preferred Requirements \n  Experience with NOSQL databases such as Accumulo desired \n  Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer. \n   \n LRTQxi2ei9"}, "0bf5f24f8df3793b": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 70.0, "salary_max": 80.0, "title": "Data Engineer", "company": "Leadstack Inc", "desc": "Job Description \n LeadStack Inc. is an award winning, one of the nation\u2019s fastest growing, certified minority owned (MBE) staffing services provider of contingent workforce. As a recognized industry leader in contingent workforce solutions and Certified as a Great Place to Work, we\u2019re proud to partner with some of the most admired Fortune 500 brands in the world. \n Job Title: Data Engineer Location: Remote role  Duration: 6+ Months with possible extension  Job ID: 23-01741 \n Pay Range: $70/hr-80/hr. on W2 (DOE) \n Job Description: \n Minimum Position Qualifications: \n \n Extensive knowledge of data principles, patterns, processes, and practices \n Any experience defining evolutionary data solutions and underlying technologies \n Strong\u202fanalytical skills\u202fwith the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy \n Experience with SQL database design, data modeling \n Analyze and organize raw data \n Build data systems and pipelines \n Evaluate business needs and objectives \n Interpret trends and patterns \n Conduct complex data analysis and report on results \n Demonstrated written and oral communication skills \n Basic understanding of network and data security architecture \n Strong knowledge of industry trends \n Knowledge in a minimum of the following technical disciplines: data warehousing, data management, analytics development, data integration, cloud, servers and storage, and database management \n Experience building cost effective and performance driven solutions using elastic architectures in Azure Data lake services, Azure Data Factory, and Databricks Platforms. \n \n \u00b7  Experience with SQL and NoSQL applications on Big Data Platforms \n \n Experience with SSAS Tabular models, Power BI, Dataflows and DAX \n Experience with Azure Data Platform stack: Azure Data Lake, Azure Synapse, Data Factory and Databricks \n Experience with Python, Spark and SQL \n Any experience with streaming technologies like Kafka, IBM MQ and EventHub \n \n Desired Previous Experience/Education: \n \n Any experience with operational data science, machine learning or artificial intelligence solutions \n Any experience with data science solutions or platforms \n Degree in Computer Science, IT, or similar field; a Master\u2019s is a plus \n Data engineering certification (e.g IBM Certified Data Engineer) is a plus \n Any experience with data science solutions or platforms \n Any experience with a variety of SQL, NoSQL and Big Data Platforms \n Any experience building solutions using elastic architectures (preferably Microsoft Azure and Google Cloud Platform) \n \n Key Responsibilities: \n \n Drive digital innovation by leveraging innovative new technologies and approaches to renovate, extend, and transform the existing core data assets, including SQL-based, NoSQL-based, and Cloud-based data platforms \n Define high-level migration plans to address the gaps between the current and future state \n Present opportunities with cost/benefit analysis to leadership to shape sound architectural decisions \n Lead the analysis of the technology environment to detect critical deficiencies and recommend solutions for improvement \n Interpreting data, analyzing results using statistical techniques \n Developing and\u202fimplementing\u202fdata analyses, data collection systems and other strategies that optimize statistical efficiency and quality \n Acquiring\u202fdata from primary or secondary data sources and maintaining databases \n Promote the reuse of data assets, including the management of the data catalog for reference \n \n To know more about current opportunities at LeadStack, please visit us on https://leadstackinc.com/careers/ \n Should you have any questions, feel free to call me at 628.210.3003 or send an email on nikhil.saxena@leadstackinc.com \n Best, \n Nikhil Kumar Saxena \n Job Type: Contract \n Salary: $70.00 - $80.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Databricks: 5 years (Required) \n SQL: 10 years (Required) \n Python: 5 years (Required) \n \n License/Certification: \n \n Databricks Certified Data Engineer Professional (Required) \n \n Work Location: Remote"}, "5437e82025425efc": {"terms": ["machine learning engineer"], "salary_min": 150000.0, "salary_max": 200000.0, "title": "Senior Machine Learning Engineer", "company": "Chartbeat, Inc.", "desc": "Tubular and Lineup have partnered with Chartbeat to help you grow reach and revenue for your content. \n \n \n \n   Chartbeat\u2019s (www.chartbeat.com) mission is to help content creators around the world better connect with their audiences.\n   \n \n \n   In 2023, Chartbeat joined forces with Tubular, the leader in global social video intelligence and measurement, and Lineup Systems, the leading global provider of media sales technology. Together, we\u2019re expanding the ecosystem of insights we provide to enterprise content creators who are developing audiences and revenue streams across channels. We now serve more than 1,000 brands globally, including \n    The New York Times, the BBC, ESPN, Gannett, Vox, BuzzFeed, Paramount, WB, Mediahuis, Hearst, McClatchy,  and \n    GQ .\n   \n \n \n   You'll be joining a diverse group of focused, hard-working people who are passionate about doing work that's challenging and fun\u2014and who strive to maintain a healthy work/life balance.\n   \n \n Want to use your machine learning skills to understand and influence digital content strategies for many of the world\u2019s largest media companies? Love to dig into mountains of data on the latest trends in social video viewing behavior? A machine learning role at Chartbeat provides a unique opportunity to help media brands make sense of the data they capture about viewers of digital content on their owned and operated site, and combine that with insights gleaned from social audiences to drive informed decisions that grow their reach and revenue. \n  Summary of the Role \n  As a Senior Machine Learning Engineer at Chartbeat, you will play a lead role in the development of new machine learning-based product capabilities, working as part of a diverse team of other Machine Learning Engineers, Data Scientists, and Data Analysts and collaborating cross-functionally with Engineering and Product. You will also take responsibility for the ongoing operations of our machine learning tools and infrastructure, advocating for and supporting the tooling and infrastructure needs of the team. You will participate and/or lead discussions on machine learning approaches appropriate for solving Chartbeat\u2019s business problems, contribute and review code, and work with Chartbeat\u2019s most experienced engineers to architect and build large-scale ML systems that can support required training and serving workloads. \n  The Senior Machine Learning Engineer will join the Data Science team, managed by Bonnie Ray, VP Data. The Data Science team operates as part of the larger Data team, responsible for curating, enriching, and modeling Chartbeat\u2019s data to facilitate product discovery, ML-based product differentiation, and internal business decision making. \n  Key Duties & Responsibilities \n \n Lead development of new machine learning based product capabilities, such as metadata creation for news articles, conversion propensity modeling, or automated generation of business insights. \n Build and maintain tooling and infrastructure to allow data scientists to focus on experimentation while empowering self-service workflows to deploy and serve models reliably and consistently. \n Support life cycle management of deployed machine learning models (e.g., new releases, change management, model monitoring and troubleshooting). \n Effectively collaborate with other data scientists, engineers, and product managers to deliver new product capabilities with clear business impact \n Mentor more junior data scientists and machine learning engineers to aid development of clean, reproducible, and highly performant machine learning systems \n Build robust, scalable, high performance prediction, optimization and recommendation ML solutions based on massive structured and unstructured data from various sources \n Provide innovative thinking and technical expertise to expand Chartbeat\u2019s capabilities around natural language processing and generative AI \n \n \n \n  Minimum Qualifications \n \n 5+ years working as a practicing data scientist or machine learning engineer in industry, preferably for a B2B SaaS provider \n Experience developing, testing, and deploying Python-based machine learning algorithms in a production environment \n Experience implementing and working with commonly used platforms for managing ML workflows, such as MLflow, comet.ml, AWS Sagemaker, or similar \n Solid theoretical knowledge of statistical and machine learning algorithms, as evidenced by an undergraduate or graduate degree in a mathematics, computer science, or engineering-related discipline \n Proficiency with advanced SQL querying and knowledge of common data warehouse environments, such as Snowflake, Databricks, or similar \n Experience with Kubernetes, Docker or any other infrastructure or containerization management/automation platform. \n Excellent communication and collaboration skills, with the ability to effectively communicate technical concepts to both technical and non-technical stakeholders \n A passion for understanding behavioral data \n \n \n \n  Exceptional Candidates will have: \n \n Experience extracting insights from large text corpora using modern techniques \n Prior experience in the domain of media and content analytics \n Experience building and managing data pipelines \n Active presence in the DS/ML community, as evidenced by workshop or conference presentations, contributions to data science open source projects, involvement in pro bono data science initiatives, etc. \n \n Compensation and Benefits \n  We are proud to offer our team members a competitive compensation plan that includes: \n \n Comprehensive Health, Dental, and Vision Insurance \n 401K with company match (100% of the first 3% and 50% of the next 2%) \n Fully Paid Parental Leave - 18 weeks for birthing parents, 12 weeks for non-birthing parents \n $100/month phone and internet stipend \n $50/month book and wellness reimbursement \n $250/year lifelong learning and development reimbursement \n $100/month coworking space reimbursement \n $300 stipend for home office setup \n Flexible work hours \n Unlimited PTO \n 11 paid holidays and December holiday closure \n Company-wide outings \n Hackweeks    The pay range for this position is: $150,000 - $200,000 per year. Please note that the foregoing compensation information is a good-faith assessment associated with this position only and is provided pursuant to applicable law. \n \n \n \n Diversity, Equity, and Inclusion Statement \n \n \n   At Chartbeat we strive to create and continually grow as a company where all employees are able to be their authentic selves. We are committed to recruiting, hiring, and retaining employees from different backgrounds, viewpoints, and experiences. Our strength is our diversity and we are dedicated to continuously reflect upon, and evolve our efforts to maintain a diverse, equitable and inclusive ecosystem.\n   \n \n \n Equal Opportunity Employment Statement \n \n \n   Chartbeat is an Equal Opportunity Employer and does not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by applicable national, federal, state, or local law."}, "4e6a563a2be1f888": {"terms": ["machine learning engineer", "mlops"], "salary_min": 115555.516, "salary_max": 146319.03, "title": "Machine Learning Engineer II", "company": "Artera", "desc": "ABOUT ARTERA \n  Our Mission:  Make healthcare #1 in customer service. \n  What We Deliver:  Artera (formerly WELL Health\u00ae) is the patient communication platform that delivers happier staff, healthier patients, and more profitable organizations. We enable two-way conversations between patients and their healthcare teams through secure, multilingual messaging across multiple channels \u2013 including text, email, and telephone. By unifying disjointed touchpoints into a single, intuitive channel, Artera fuels connected patient experiences and empowers organizations to deliver the best customer service imaginable. \n  Our Impact:  Artera helps 500+ healthcare providers facilitate more than 1 billion messages for 40+ million patients annually. \n  Our award-winning culture:  In 2021, Artera was named #10 on the Forbes list of America's Best Startup Employers, as well as being named one of Deloitte's Fast 500 (#133). Artera was also recognized as one of the Best Midsize Companies to Work for in Los Angeles by Built In in 2022, and has been ranked on the Inc. 5000 list of fastest-growing private companies for three consecutive years. \n  SUMMARY \n  AI is central to Artera's ability to improve patient experiences, optimize workflows and empower health systems to deliver the best quality care possible. With the latest developments in AI, new and exciting opportunities emerged, further solidifying AI as a key strategic focus of Artera's product vision. \n  To make it happen, Artera's Data team is adding additional headcount to our Machine Learning function and we are looking for a talented Machine Learning Engineer. In this role, you will be primarily working with Product Managers, Software Engineers and Data Scientists to design and deliver customer-facing ML solutions. During this process, you will be developing ML workflows and end-to-end pipelines for data preparation, training, deployment, monitoring (ensure architectural quality) and model performance. \n  If you are a self-starter who enjoys applying ML expertise to make a difference in health care, this is the opportunity for you. \n  RESPONSIBILITIES \n \n Scope, design, build and ship end-to-end machine learning models \n Drive exploratory data analysis to test, define and iterate from idea to proof-of-concept \n Build feature pipeline with Analytics Engineers to automate feature extraction and monitoring \n Build and maintain Sagemaker pipelines to automate inference generation and work with product engineering for integration into product \n Own Sagemaker automated testing and deployment processes for machine learning models \n Develop and own AWS Sagemaker managed framework for performance monitoring, evaluation and automated retraining \n \n REQUIREMENTS \n \n MS or above in quantitative field \n 3+ years of full-time experience in building machine learning products \n End-to-end experience designing and shipping machine learning features \n Strong proficiency in Python, and experiences with machine learning framework e.g. TensorFlow, PyTorch or Keras \n Hands-on experience with MLOps in cloud infrastructure, ideally AWS \n Proven records in choosing the right solution for the right problem \n Great communication skills and business mindset \n \n BONUS \n \n Proficiency at NLP \n Experience with HL7 FHIR format, EHR data \n Knowledge with US health system \n Experience with dbt, Snowflake \n \n LOCATION \n  Artera is Santa Barbara, CA based and remote friendly. If you are located outside of the Santa Barbara area and located within the United States and are interested in working remotely, APPLY TODAY. #LI-Remote #BI-Remote \n  WORKING AT ARTERA \n \n Company benefits  - Full health benefits (medical, dental, and vision), flexible spending accounts, company paid life insurance, company paid short-term & long-term disability, flexible spending accounts, company equity, voluntary benefits, 401(k) and more! \n Career development  - Mentorship program, manager development cohorts, employee development funds. \n Generous time off  - Company holidays, wellness days, and flexible time off. \n Employee Resource Groups (ERGs)  - We believe that everyone should belong at their workplace. Our ERGs are available for identifying employees or allies to join. \n \n SALARY RANGE \n  Actual base salary will depend on experience, skills, education, geographic location, and/or internal equity. \n  $108,000 - $158,000 \n  Interested in learning more?  Please visit our LinkedIn page or our Life at Artera Instagram (@artera_io) to hear from our employees about working at Artera. \n  Committed to Diversity, Equity, and Inclusion \n  Artera is an Equal Opportunity Employer and is committed to fair and equitable hiring practices. All hiring decisions at Artera are based on strategic business needs, job requirements and individual qualifications. All candidates are considered without regard to race, color, religion, gender, sexuality, national origin, age, disability, genetics or any other protected status. \n  With that said, research shows that women and other underrepresented groups apply only if they meet 100% of the criteria. Artera is committed to leveling the playing field, and we encourage you to apply for positions even if you do not meet 100% of the criteria. We would love to connect with you and see if you would be a great fit for our role! \n  We're dedicated to creating an inclusive, equitable, and diverse workplace, where everyone feels safe to be themselves and diversity is a strength. Artera is committed to providing employees with a work environment free of discrimination and harassment; Artera will not tolerate discrimination or harassment of any kind. \n  DATA PRIVACY \n  Artera values your privacy. By submitting your application, you consent to the processing of your personal information provided in conjunction with your application. For more information please refer to our Privacy Policy."}, "1c824c9b77ee3d41": {"terms": ["machine learning engineer"], "salary_min": 90000.0, "salary_max": 120000.0, "title": "Senior Full Stack Software Engineer (Python, Django)", "company": "Cooperate Marketing", "desc": "Senior Full Stack Software Engineer (Python, Django)  \n ABOUT US Cooperate Marketing is an independent marketing agency that specializes in marketing technology and building customized channel marketing solutions for a variety of clientele. We have a strong and stable client roster across a number of industries. Our team is a close-knit group of marketing professionals who believe in the power of working together to achieve great things. We think being an independent agency is a fundamental advantage that allows us to create unexpected value\u2014both in our focus on people and our investment in our clients\u2019 business. Cooperate is an equal opportunity employer. \n ABOUT THE ROLE We are seeking a Senior Full Stack Software Engineer who is passionate about developing SaaS products and solutions. At this role, you will: \n \n Own our full tech stack that includes Backend, Frontend, Data and DevOps. \n Work in an agile environment with product team and client account directors to design and develop end-to-end solutions. \n Design, develop, and deploy software platforms that align with our clients\u2019 business needs and requirements. \n Work together with project leads to deliver solutions with successful client acceptance. \n Work closely with other team members and play an integral role in shaping the future of our platform, such as adding machine learning and artificial intelligence (ML/AI) capabilities. \n Be called upon to represent the agency in new business opportunities, either with your existing client or a new client, and will be expected to help lead and contribute to new business development. \n \n ABOUT YOU You are an experienced Python software developer. You have good grasp of databases and SQL. You are comfortable working with JavaScript and Frontend frameworks such as Vue.js. You can\u2019t wait to deploy your code through CI/CD instead of solely relying on DevOps. \n You are curious to find how things work and why things break by digging deep into our large code base and datasets. You are proud of your QA/QC skills and high quality of code you ship. You enjoy documenting and explaining what you did, and coaching junior developers. \n Deep inside, you have the insatiable desire to \u201cmake things work\u201d with technology and deliver products. You want to be seen as THE ONE who brings significant impact. You want to be the owner and key contributor of a software product. \n QUALIFICATIONS \n \n A Bachelor\u2019s degree and/or advanced degree(s), preferably in computer science, engineering or a related field with relevant certification \n ~5+ years of software development experience \n Experience building end-to-end SaaS software using Python and Django \n Experience with Postgre or other databases and SQL \n Knowledge with Frontend development such as RESTful API, Javascript, CSS, \n Vue.js, React.js or other frontend frameworks \n Experience with Docker, Kubernetes, Google Cloud or other cloud platforms \n Excellent communication and presentation skills: Demonstrated ability to explain technical content to both technical and non-technical audiences \n Strong interpersonal skills \n Strong self-driven motivation to learn and apply new technologies \n Ability to prioritize tasks from day-to-day needs through long-term project deliverables \n Comfortable multi-tasking and handling any number of requests as they come in \n Comfortable working in a dynamic, fast-paced environment \n Prior experience within the technology space (SaaS, enterprise solutions, etc.) \n Preferred experience working on channel, co-marketing, or other relevant initiatives \n \n Job Type: Full-time \n Pay: $90,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Health insurance \n Life insurance \n Paid time off \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Supplemental pay types: \n \n Bonus opportunities \n \n Experience: \n \n REST: 5 years (Preferred) \n \n Work Location: Remote"}, "87d66be98a25cc9d": {"terms": ["machine learning engineer"], "salary_min": 120000.0, "salary_max": 160000.0, "title": "Front-End Engineer", "company": "Spyglass Software", "desc": "Join our pioneering team as a Full-Stack Engineer in Brooklyn, New York, and play a key role in building the first-ever security platform for data teams!\n   \n \n \n Description \n \n \n \n Full-Stack Engineer  \n \n      Location: Brooklyn, New York City (in-office) \n     \n \n      Spyglass website | LinkedIn Page\n     \n \n  \ufe0f Why work with us \n \n      Spyglass is building the first security platform for data teams.\n     \n \n \n  We are looking for an entrepreneurial founding engineer. This is an amazing opportunity to work side by side as a founding member of a venture backed company and change how data teams manage security.\n     \n \n \n  We've raised $2.5M in pre-seed from Notation Capital, 8-Bit Capital, CoFound Partners and V1.VC with deep team expertise in enterprise software and security.\n     \n \n  \u200d What you\u2019ll work on \n \n      You will take a pivotal role in building a cloud based security platform alongside our CTO, CEO, and existing customers. We are working with data engineering teams iterating on the most advanced ways to deliver a purpose built security experience for their needs.\n     \n \n \n  You will have a hand in everything from prioritizing features, to defining the architecture, to selecting the tech stack. As we scale, you will have opportunities to explore various technical and managerial roles.\n     \n \n \n  In addition, you\u2019ll have the opportunity to work across our entire SaaS offering, from our frontend Svelte app to our backend Node.js server, our CI/CD integrations, and recommendations (machine learning) products.\n     \n \n  \u2705 Requirements \n \n \n  Strong knowledge of software development principles. \n \n  Strong problem-solving skills and ability to work independently in a fast-paced environment. \n \n  Demonstrated ability to quickly learn new technologies, and enthusiasm to contribute at all levels of the stack as needed. \n \n  Helpful but not required: Experience with Typescript, Postgres, GCP or Svelte. \n \n  Interest in security, machine learning, or developer tools is a plus! \n \n \n  What we look for \n \n \n  High-potential, raw talent. \n \n  Curiosity, mischief, and intensity. \n \n  History of building useful things. \n \n \n  Compensation \n \n      Our compensation packages are based on a wide array of factors including your unique skill set, years of experience, and preferred total compensation ratio between salary and equity.\n     \n \n \n  We\u2019re based in Brooklyn and prefer someone in New York who wants to work in person. We believe that face-to-face interactions foster more effective communication and help to build camaraderie, all things that are important to us as an early startup.\n     \n \n \n  We offer healthcare, a stipend for work equipment, and plan on implementing other perks as we achieve our milestones as a business.\n     \n \n \n  $120k - $160k salary range + significant equity.\n     \n \n  Interview process \n \n \n \n  30 minute call with Co-founder & CEO to discuss background, experience, career goals, and answer questions (remote) \n \n \n \n  1-2 hour take home technical assessment building a basic application \n \n \n \n  30 minutes with Co-founder & CTO (remote) \n \n \n \n  2-3 hour onsite technical interview in Brooklyn with Co-founder & CTO (onsite in New York, location TBD) \n \n \n \n  Reference checks \n \n \n \n  Offer extended \n \n \n \n  \ufe0f Who You\u2019ll Work With \n \n \n  I\u2019m Nick, co-founder and CEO of Spyglass. I\u2019ve spent the last decade building devops and developer tooling companies as the first GTM hire at both Edge Delta (observability) and Harness (CI/CD). I have a passion for working with engineering teams to solve complex and impactful problems at the enterprise scale. I enjoy road biking, playing with my dog and obsessing over my daily macronutrient ratios.\n     \n \n \n  I\u2019m Tyler, co-founder and CTO of Spyglass. I love building software infrastructure, security, and developer tools, and I\u2019m super excited about what we\u2019re building at Spyglass: security on autopilot for data teams. I have years of experience at startups (Fast) to big tech (Uber), but there\u2019s always more to learn. In my free time, I enjoy making electronic music, playing chess, cooking, and gaming.\n     \n \n   \n \n \n \n \n Salary \n $120,000 - $160,000 per year"}, "b8f986e1e332e875": {"terms": ["machine learning engineer"], "salary_min": 134045.84, "salary_max": 169731.9, "title": "Senior Software Engineer", "company": "Amperon", "desc": "The Company You'll Join \n  Amperon is the leading analytics and forecasting company for the energy transition. Our platform leverages advanced algorithms and machine learning techniques to accurately forecast energy demand on both the supply (power & utilities companies) and demand (large energy users) sides of the market. We incorporate real-time data feeds that help our clients reduce cost, monitor energy efficiency while increasing substantially. \n  We bring the brightest mind from energy, security and technology in order to combat climate changes and transition to clean energy solutions. We have offices in Texas but are a remote first company. \n  Our Mission \n  As the electricity grid faces challenges due to renewables, EVs, climate change, and more, there's a desperate need for an upgrade. Amperon's blend of energy expertise and AI technology offers analytics and forecasting software to improve grid reliability and accelerate decarbonization. We're building the next generation of market-leading energy analytics and forecasting products, and we want you to be part of our journey! \n  The team you'll work with \n  The mission of the platform team is to empower our customers by transforming complex energy data into simple yet highly interactive user-friendly apps. Technically we are on the forefront of energy forecasts continuously setting standards for user experience and performance while exceeding customer expectations. We are a small team so you'll have the opportunity to help with driving architectural decisions. \n  The Impact \n  We have a direct impact around our expansion into new markets such as Europe. We are the first point of contact with direct users which allows us to access millions of data points used for new enhancements. We have direct impact with climate volatility by creating custom weather scenarios for simulations where weather forecasts could change and demand would be affected based on those cases. \n  The problems you'll solve \n \n Displaying a lot of data in a performant way, both from a back-end/db perspective and a front-end/rendering one. \n Being able to master both front-end and back-end to take full ownership of certain features in a fast-paced environment with multiple technologies and languages. \n Preventing/minimizing the amount of bugs/alerts when working together with two other senior teams on the same codebase, orchestrating features together. \n \n You may be a fit for this role if \n  You have senior level experience building client facing applications. You are highly proficient on the frontend with React.JS. You have experience on the backend with Python specifically with data heavy applications. Experience building and deploying API's with a focus on scalability and security. \n  Our tech stack :React.js, Node.js, Sass, Python, Flask, Pandas, MySQL, Clickhouse, GCP. \n  Perks \n  While we are serious about our company's culture, we aren't going to force \"culture\" to prove that we are cool and fun. It's a company filled with smart, genuinely nice individuals who are passionate about data science, energy and working together to build a product that can have a lasting impact on our planet. \n  Even though we are a remote company with employees spread across the globe, we still believe human interaction is a good thing. We will also have an all-company event at least once a year so people can get to know each other in a more fun and social way. \n \n Competitive salary \n Health insurance \n Monthly gym membership stipend \n Pre-tax commuter benefits \n 401k \n Stock options \n Flexible work hours \n Remote \n \n  If you are excited about contributing to a product that can have a lasting impact on our planet and you thrive in fast-paced, innovative environments, we would love to hear from you."}, "45297ddc99dbaf6b": {"terms": ["machine learning engineer"], "salary_min": 104990.44, "salary_max": 132941.28, "title": "Integration Software Engineer", "company": "HALO Precision Diagnostics", "desc": "Saving Lives with Early Detection \n \n  Remote \n  Saving Lives with Precision Diagnostics \n  We're a dedicated team that moves fast, upholds design quality, values consistency and simplicity, and focuses on customers and their needs. We believe in inclusion both within our team and in the way we build products and make that clear in the way we hire, design, and execute. We value growth and encourage, not just respect, our differences. \n  We love what we do and build products that are reshaping the medical profession around the world. We embrace sophisticated application of machine learning as well as a deep discipline for software development in our domain. \n  Position Summary \n  HALO Precision Diagnostics is developing a comprehensive SaaS healthcare platform, initially focusing on the needs of independent radiology centers and genetics laboratories. As we expand our SaaS deployment, we are creating a new Integration team to work with our customers and onboard them to the HALO platform. The Integration Software Engineer will work with our platform developers, IT, and customer staff to ensure a smooth transition from the old system to the new platform. The engineer will participate in developing tools and processes for integration and migration to the new system, as well as solving unique problems that arise at each site. \n  Responsibilities \n  A successful Integration Software Engineer candidate will have 5+ years of experience in software development with proven track record of developing and deploying software in a complex multi-vendor environment. The candidate must be able to work independently and collaborate with technical and non-technical staff. \n  The integration software engineer will: \n \n develop software that will address customer's unique situation, \n develop tools that will improve the process of onboarding new customers, \n deploy onsite components, validate the installation, integrate with existing software, and migrate data from older systems, \n learn existing workflow and systems unique to each customer to aid the integration, \n problem solve any issues during integration, \n support non-technical internal customers to get up to speed on the new platform, \n work with overseas teams, \n document and report integration efforts, including lessons learned, issues and bugs, follow-ups, and so forth, and make recommendations for improvements and future needs. \n \n This is a full-time remote position with travel expected to sites in the US and occasional international travel. \n  Qualifications and Experience \n \n Bachelor's Degree in a technical field (CS, IT, EE, or similar) or equivalent. \n Experience working with Microsoft Windows and Linux. Experience with OSX, iOS, and Android a plus. \n Experience with troubleshooting software, hardware, SaaS platforms, and networking. \n Experience with writing tools in a scripting or programming language (Python, Perl, PHP, Java, shell scripting, etc.) \n Experience with data integration, transformation, and migration. \n Knowledgeable in IT and software development processes and terminologies ( :  GIT, REST API, firewall, subnet, etc.) \n Basic knowledge of SQL databases and queries. \n Experience with documenting process, procedures, and workflow. \n Demonstrate strong problem-solving skills. \n Knowledge of VMware stack and/or cloud service providers (AWS, GCP, Azure, etc.) a plus. \n Experience with containers (Docker, Kubernetes) a plus. \n Knowledge of computer security best practices a plus. \n Demonstrate technical aptitude and willingness to learn."}, "f61867077b7a59a9": {"terms": ["machine learning engineer"], "salary_min": 120000.0, "salary_max": 160000.0, "title": "Full-Stack Engineer", "company": "Spyglass Software", "desc": "Join our pioneering team as a Full-Stack Engineer in Brooklyn, New York, and play a key role in building the first-ever security platform for data teams!\n   \n \n \n Description \n \n \n \n Full-Stack Engineer  \n \n      Location: Brooklyn, New York City (in-office) \n     \n \n      Spyglass website | LinkedIn Page\n     \n \n  \ufe0f Why work with us \n \n      Spyglass is building the first security platform for data teams.\n     \n \n \n  We are looking for an entrepreneurial founding engineer. This is an amazing opportunity to work side by side as a founding member of a venture backed company and change how data teams manage security.\n     \n \n \n  We've raised $2.5M in pre-seed from Notation Capital, 8-Bit Capital, CoFound Partners and V1.VC with deep team expertise in enterprise software and security.\n     \n \n  \u200d What you\u2019ll work on \n \n      You will take a pivotal role in building a cloud based security platform alongside our CTO, CEO, and existing customers. We are working with data engineering teams iterating on the most advanced ways to deliver a purpose built security experience for their needs.\n     \n \n \n  You will have a hand in everything from prioritizing features, to defining the architecture, to selecting the tech stack. As we scale, you will have opportunities to explore various technical and managerial roles.\n     \n \n \n  In addition, you\u2019ll have the opportunity to work across our entire SaaS offering, from our frontend Svelte app to our backend Node.js server, our CI/CD integrations, and recommendations (machine learning) products.\n     \n \n  \u2705 Requirements \n \n \n  Strong knowledge of software development principles. \n \n  Strong problem-solving skills and ability to work independently in a fast-paced environment. \n \n  Demonstrated ability to quickly learn new technologies, and enthusiasm to contribute at all levels of the stack as needed. \n \n  Helpful but not required: Experience with Typescript, Postgres, GCP or Svelte. \n \n  Interest in security, machine learning, or developer tools is a plus! \n \n \n  What we look for \n \n \n  High-potential, raw talent. \n \n  Curiosity, mischief, and intensity. \n \n  History of building useful things. \n \n \n  Compensation \n \n      Our compensation packages are based on a wide array of factors including your unique skill set, years of experience, and preferred total compensation ratio between salary and equity.\n     \n \n \n  We\u2019re based in Brooklyn and prefer someone in New York who wants to work in person. We believe that face-to-face interactions foster more effective communication and help to build camaraderie, all things that are important to us as an early startup.\n     \n \n \n  We offer healthcare, a stipend for work equipment, and plan on implementing other perks as we achieve our milestones as a business.\n     \n \n \n  $120k - $160k salary range + significant equity.\n     \n \n  Interview process \n \n \n \n  30 minute call with Co-founder & CEO to discuss background, experience, career goals, and answer questions (remote) \n \n \n \n  1-2 hour take home technical assessment building a basic application \n \n \n \n  30 minutes with Co-founder & CTO (remote) \n \n \n \n  2-3 hour onsite technical interview in Brooklyn with Co-founder & CTO (onsite in New York, location TBD) \n \n \n \n  Reference checks \n \n \n \n  Offer extended \n \n \n \n  \ufe0f Who You\u2019ll Work With \n \n \n  I\u2019m Nick, co-founder and CEO of Spyglass. I\u2019ve spent the last decade building devops and developer tooling companies as the first GTM hire at both Edge Delta (observability) and Harness (CI/CD). I have a passion for working with engineering teams to solve complex and impactful problems at the enterprise scale. I enjoy road biking, playing with my dog and obsessing over my daily macronutrient ratios.\n     \n \n \n  I\u2019m Tyler, co-founder and CTO of Spyglass. I love building software infrastructure, security, and developer tools, and I\u2019m super excited about what we\u2019re building at Spyglass: security on autopilot for data teams. I have years of experience at startups (Fast) to big tech (Uber), but there\u2019s always more to learn. In my free time, I enjoy making electronic music, playing chess, cooking, and gaming.\n     \n \n   \n \n \n \n \n Salary \n $120,000 - $160,000 per year"}, "560d9a30319aa27e": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Technical Project Manager", "company": "Packsize, LLC", "desc": "What Product Experience Does \n We work in a Lean Software development environment as cross-functional teams. Together we develop new products, services, and features of the Packsize platform for our on-demand box making machines, integration with other systems, optimizing complex workflows, and more. We are highly collaborative with engineers, UX, senior management, stakeholders, and our customers. We are continuously looking at the health of our product engineering culture and how we can learn and improve. We also investigate new technologies and how we will leverage them to solve problems in new and better ways including IoT, cloud, and stream analytics. \n The Challenge \n We work in the unique space where software meets hardware. Preferred experience in managing and navigating the complexity of hardware, plc software, and application software will be an asset as we continue to make on-demand, right-sized packaging a reality for our customers. \n Our core software team is located at our headquarters in Salt Lake City, Utah. You will work with a cross-functional team of engineers and UX designers to identify what we build into our products. You will collect and synthesize data points to identify the problem to solve that will deliver the most value. \n The Technical Project Manager will be working with our product development teams to execute on strategic initiatives, leveraging talent both internal to Packsize, and external partners and vendors. Your excellent written and verbal communication skills will be critical in gaining alignment on your team, partners and across stakeholders. \n We focus on Lean Software development so you should feel comfortable navigating and organizing work items with kanban tools, analyzing and improving the overall process, identifying and communicating customer value, and continuous learning and improvement should be part of your daily life. \n As the Technical Project Manager, it is your responsibility to understand our domain, collaborate with internal stakeholders, define project scope and success criteria, and drive projects through to completion. You will be responsible for defining success criteria, managing external contracts and expectations, and delivering positive outcomes. \n Key Responsibilities \n \n Learn the complex domain of On-Demand Packaging and how it can be leveraged to streamline our customers\u2019 shipping processes. Develop a deep understanding of - and empathy for - our customers.   \n A focus on outcome-driven activities over a process. i.e., \u201cWhat impact do we want to achieve?\u201d   \n \n \n Utilize lean software development and optimize for value delivery.  \n Understand and manage cross-group collaboration, dependencies, and risks to deliver on schedule and with world-class quality. The ability to drive collaboration across teams is essential to your success. You play a critical role in creating alignment across the projects you are involved in.   \n Facilitate and guide consensus across multiple functional teams and groups.   \n \n \n You are an excellent communicator. You provide honest and candid feedback while also seeking feedback from others.   \n You define success and success metrics but are not afraid of missteps. You leverage your teams and stakeholders for knowledge and direction, and have no problem navigating any road bumps or blockages that arise, to keep the project on track.   \n You reflect the strategic priorities of Packsize. You fully understand - and have the ability to articulate - the problem, the solution, the vision, the ecosystem in which your projects will function, and how the product and ecosystem will interact and impact each other.  \n You are proactive about creating the conditions necessary for your team\u2019s success. When there is something needed for success you actively take steps to explore possible solutions.   \n You create transparency and visibility into the projects you manage, and actively report out to the organization.   \n \n Physical Demands and Working Conditions \n \n Travel to visit customers and vendors at their locations. Travel to Packsize HQ when needed (up to 25%)"}, "119730e2e7d18253": {"terms": ["machine learning engineer", "mlops"], "salary_min": 141000.0, "salary_max": 215025.0, "title": "Manager, Engineering \u2013 Medical Applications & Algorithms", "company": "HeartFlow, Inc", "desc": "HeartFlow, Inc. is a medical technology company transforming the diagnosis and management of coronary artery disease, the #1 cause of death worldwide, using cutting-edge technology. The flagship product\u2014an AI-based, non-invasive cardiac test called the HeartFlow Analysis\u2014provides a color-coded, 3D model of a patient's coronary arteries indicating the impact blockages have on blood flow to the heart. It offers physicians a completely novel way to diagnose and treat cardiac patients. Our pipeline of products is growing and so is our team; join us in helping to revolutionize precision heartcare.\n   \n \n \n   HeartFlow is a VC-backed, pre-IPO company that has received international recognition for exceptional strides in healthcare innovation, is supported by medical societies around the world, cleared for use in the US, UK, Europe, Japan and Canada, and has been used for more than 200,000 patients worldwide.\n   \n \n  HeartFlow is a VC-backed, pre-IPO, Software as a Service (SaaS) company that has received international recognition for exceptional strides in healthcare innovation. We combine clinical expertise with cutting-edge technology (deep learning, computational fluid dynamics, cloud-based computing) to revolutionize the diagnosis and treatment of coronary artery disease. \n  If you are passionate about advanced algorithmic applications and leading world-class teams of software engineers, come join our engineering team! You will work alongside Software Engineers, Research Scientists, and Process Engineers to deliver the future generations of our cloud-based algorithmic pipelines (image and geometry processing, machine learning). #LI-Remote; #LI-IB1. \n  This position can be held in any of our US offices (Mountain View CA or Austin, TX) and is also open to remote workers (USA or Canada). \n  Job Responsibilities \n \n Provide technical leadership on software components and tooling (cloud architecture, CI/CD pipelines, testing frameworks, ML infrastructure) \n Provide guidance to direct reports (career development of Software Engineers, 3-5 reports expected) \n Drive continuous improvement of our development methodology (Agile) and Engineering culture \n Collaborate cross-functionally with key partners in Research, Product management, Strategy, Operations and Regulatory to ensure high quality, high-impact delivery of innovative software projects \n Identify technology risks and dependencies early to establish mitigation plans \n Hands-on technical contributions as appropriate \n \n Qualifications required \n \n Minimum Bachelor's degree in Computer Science or related \n 5+ years of relevant industry experience in a software company \n 3+ years of management experience, preferably within growing organizations (hiring, forming new teams) \n Deep understanding of software development best practices: testing, CI/CD, Devops, agile methodologies \n Experience leading R&D projects for advanced scientific applications \n Experience with cloud-based infrastructure (Amazon Web Services or equivalent) \n Advanced programming proficiency: modern C++, Python \n Excellent communication and collaboration skills \n \n How you stand out \n \n Machine learning expertise: MLOps practices, ML infrastructure \n Algorithmic expertise: 3D image processing or 3D geometry \n Experience with medical applications or other regulated industries \n \n The pay range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to experience and training; skill sets; licensure and certifications; and other business and organizational needs. A reasonable estimate of the base salary compensation range is $141,000 to $215,025 (for all locations outside San Francisco Bay Area) and $159,000 to $242,475 (for San Francisco Bay Area).   We also offer a range of benefits and programs to meet employee needs based on eligibility. These benefits include comprehensive health care coverage, a health savings account, disability, and life insurance, a Critical Illness and accident plan, a flex spending account (medical and dependent care), a 401k plan with a company match, mental health support TaskHuman, EAP, financial coaching, Rocket Lawyer, and more. HeartFlow offers 12 paid holidays, 15 vacation days, and 80 hours of sick leave. \n \n \n  About HeartFlow, Inc. \n \n \n   HeartFlow, Inc. is a medical technology company redefining the way heart disease is diagnosed and treated. Our non-invasive HeartFlow FFRct Analysis leverages deep learning to create a personalized 3D model of the heart. By using this model, clinicians can better evaluate the impact a blockage has on blood flow and determine the best treatment for patients. Our technology is reflective of our Silicon Valley roots and incorporates decades of scientific evidence with the latest advances in artificial intelligence. The HeartFLow FFRct Analysis is commercially available in the United State, Canada, Europe and Japan. For more information, visit www.heartflow.com.\n   \n \n \n   HeartFlow, Inc. is an Equal Opportunity Employer. We are committed to a work environment that supports, inspires, and respects all individuals and do not discriminate against any employee or applicant because of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. This policy applies to every aspect of employment at HeartFlow, including recruitment, hiring, training, relocation, promotion, and termination.\n   \n \n \n   Positions posted for HeartFlow are not intended for or open to third party recruiters / agencies. Submission of any unsolicited resumes for these positions will be considered to be free referrals.\n   \n \n \n US Locations Only: All employees and contingent workers (contractor, consultant, interns or temporary personnel) are required to be vaccinated against SARS-CoV-2 as recommended by CDC, unless a reasonable accommodation is approved. All prospective hires will be expected to provide proof of vaccination on their first day of employment."}, "1176b84d3137125e": {"terms": ["machine learning engineer"], "salary_min": 180000.0, "salary_max": 210000.0, "title": "Technical Lead, Azure Cloud Based Content Management/Training System", "company": "JJR Solutions, LLC", "desc": "Are you an expert technologist who believes that comprehensive simulation technology can be used to revolutionize health care training? Do you have proven experience as a technical lead for the development and deployment of immersive training solutions, extended reality (XR) simulations, eLearning, and game-based learning products? Have you built SaaS solutions for the VA to elevate services, programs and support provided to Veterans? \n  If this sounds like you, we've got the perfect job! \n  We build partnerships with clients to elevate their organization's performance. Whether it's enhancing the technical capability of our nation's defense systems or advancing research and development for Veteran healthcare, our collaborations have a resounding impact on our communities and nation. \n  Customer Mission Success is JJR\u2019s world-class service delivery organization. Through laser focus on the client, we ensure flawless execution. We act as customer partner, trusted advisor, capability builder, innovation leader, and results driver. We\u2019re on the lookout for a visionary Technical Lead to not only safeguard the technical integrity of our cutting-edge Virtual reality (VR) Training Software but also to orchestrate a dynamic development team and conquer intricate technical hurdles. If you\u2019re excited by the idea of spearheading innovation in the realm of VR education, then your journey into the extraordinary starts here. Sound interesting? Keep reading! \n  Why you should work with us. \n  First and foremost, we care deeply about every member of our JJR family and as a company, we are inspired by something greater than ourselves. Second you will play a vital role in building lasting partnerships with clients to advance their performance and create high-impact, meaningful value. Finally, culture is kind of our thing; we are committed to the well-being of each employee. \n  Need proof? It\u2019s in the pudding. Here is what people are saying! \n \n  \u201cJJR is one of the best companies I have worked with (for) in the past 20+ years.\u201d \u2013 Anonymous employee feedback from internal engagement surveys \n  \u201cI feel JJR does a very good job of hiring people who will work well in the group dynamic - people who share the same work ethic and values, which makes for working together to be much easier and more enjoyable.\u201d \u2013 Anonymous employee feedback from internal engagement surveys \n \n  We value feedback, but we think you should come see for yourself! \n  You in? Here are the details. \n  Title : Technical Lead, Azure Cloud Based Content Management/Training System \n  Location : Remote, Orlando preferred \n  Classification : Salary, Exempt \n  Travel : Less than 10% \n  Security Requirement : Must provide favorable background check and National Agency Check with Inquiries (NACI) \n  Supervisory Role:  No \n  Position Description: \n  As the Technical Lead for our VR training software project, you will be the driving force behind the technical excellence required to deploy our partner\u2019s software to the client. You\u2019ll be at the helm of the cross functional development team comprised of JJR and subcontractor team members, working collaboratively to create a transformative educational experience for our users. From ensuring seamless technical implementation to conquering intricate challenges, you\u2019ll play a pivotal role in shaping the future of learning. \n  Position Expectations: \n \n  Exceed Service Excellence:  Go beyond the norm. Your mission? Deliver unparalleled service to both our internal and external partners, clients, and teammates. \n  Technical Stewardship:  Safeguard the technical integrity of our of our cutting-edge Virtual reality (VR) Training Software by providing expert guidance on architecture, design, and development. \n  Team Leadership:  Lead, inspire, and mentor a cross functional development team comprised of JJR and subcontractor team members, fostering a culture of innovation, collaboration, and continuous improvement. \n  Technical Innovation:  Stay on the cutting edge of relevant technologies and trends, integrating the latest advancements to enhance user experiences and learning outcomes. \n  Complex Problem Solving:  Tackle complex technical challenges head-on, developing ingenious solutions that ensure optimal performance and customer outcomes. \n  Collaborative Partner:  Collaborate closely with relevant partners such as program management, design, security specialists, and quality assurance program objectives are met. \n  Solution Security:  Support the team Security Engineers to obtain and ensure compliance with all required agency certifications such as FedRAMP Authorization and Agency ATO. \n  Performance Optimization:  Ensure that performance optimization strategies are implemented in order to deliver a smooth immersive VR experience. \n  Quality Assurance:  Ensure that comprehensive testing plans are developed to ensure the functionality, stability, and security of the VR Training Software. \n  Strategic Advising:  Provide technical insights and recommendations to project leaders, ensuring alignment between technical decisions and project goals. \n  Scalability and Future-Proofing:  Ensure that the solution is designed with scalability in mind, anticipating future demands and technological advancement. \n  Embrace Ownership:  Dive in wholeheartedly. Your role demands informed decisions, responsibility for outcomes, and a positive impact on JJR. \n  In Alignment with Excellence:  Walk the talk. All our responsibilities should harmonize with JJR\u2019s Handbook and job description. \n \n  Duties: \n \n  Lead, inspire, and mentor a cross functional development team comprised of JJR and subcontractor team members, fostering a culture of innovation, collaboration, and continuous improvement. \n  Safeguard the technical integrity of our safeguard the technical integrity of our cutting-edge Content Management and Training Software during development and sustainment by providing expert guidance on architecture, design, and development. \n  Ensure sound integration, data, security, and business architecture design throughout all stages within the platform or capability lifecycle. \n  Establish the technical roadmap for the platform or capability strategy and lifecycle that considers value-based outcomes, costs to maintain, supportability, and performance. \n  Create architecture, application and system integration designs and their documentation. \n  Communicate technical information to both technical and executive personnel. \n  Provide rapid delivery and development of technical solutions that align with business and/or platform outcomes. \n  Troubleshoot and resolve technical issues related to platform or capability systems, solutions, and services. \n  Develop and maintains deep technical knowledge and expertise related to domain area systems, solutions, services and applications. \n  Support company growth within established markets by identifying opportunities to expand our services and solve new challenges for existing clients. \n  Additional duties as assigned. \n \n  Required Education, Experience, & Skills: \n \n  Bachelor\u2019s Degree in Computer Science, Engineering or related field \n  10+ years as a Senior Software Engineer (or similar), including experience configuring SaaS solutions on Azure in the VA environment. \n  Strong expertise in Azure services, including Azure DevOps, Azure Functions, Azure App Service, and Azure Virtual Machines. \n  Experience with document store databases and distributed design. \n  Familiarity with message brokers. \n  Proficiency in test automation frameworks (e.g., Selenium, Appium) and scripting languages (e.g., Python, PowerShell, Shell Scripting). \n  Certifications related to Azure, Docker, or other relevant technologies. Experience with Agile/Scrum methodologies. \n  Knowledge of C#, TypeScript, Javascript. \n  Experience with relational and non-relational databases (e.g. GraphQL, MongoDB, MS SQL, etc) \n  Familiarity with modern CI/CD pipelines. \n  Demonstrated leadership skills with a track record of successfully leading and mentoring technical teams. \n  Excellent problem-solving abilities and a knack for finding innovative solutions to technical challenges. \n  Strong background in and understanding of Agile development methodologies and a results-driven approach to project management. \n  JJR may choose to substitute education with relevant experience. \n  Excellent analytical and communication (oral & written) skills. \n \n  Preferred Education, Experience, & Skills: \n \n  Strong expertise in SharePoint Integration \n  Hands-on experience with development/deployment in the VA Enterprise Cloud (VAEC) highly desired (or other federal cloud) using Azure \n  10+ years\u2019 hands-on experience designing and delivering commercial cloud-based, software-intensive solutions for Federal clients such as the VA \n  Knowledge of performance optimization techniques specific to Extended Reality environments. Proficiency in Extended Reality technologies, 3D graphics, and interactive user interfaces. \n  Industry recognized certifications for cloud technologies and enterprise architecture \n \n  TOTAL COMPENSATION PACKAGE \n  Salary:  In accordance with various state and federal pay transparency regulations, as well as best industry practices, our job descriptions include the salary range we reasonably expect to pay those joining our team, contingent upon little to no training being required. A final salary is subject to a number of factors, including but not limited to the following: years of experience, education, certification(s), training, specialized skills, responsibilities, etc. \n  The range of pay for this position is $180,000-$210,000. \n  Core Benefits:  Medical, Dental, Vision, 401K, Monthly $200 HSA Match, Complimentary $50k Basic Life and AD&D (eligible employees), STD, Complimentary LTD, AFLAC Coverage, etc. \n  PTO, Flexible Schedule, and Holidays:  Employees receive a robust amount of PTO along with flexible/hybrid working schedules and additional support for new parents. JJR also observes a total of 11 paid federal holidays annually, including: New Year's Day, President's Day, 4th of July, Veteran's Day, Christmas, Martin Luther King Jr. Day, Memorial Day, Juneteenth, Labor Day, Thanksgiving, and Columbus Day. \n  Professional Development + Continued Education Support:  We believe employees at all levels benefit from continued growth and learning. As such, JJR is committed to paying the entirety of the cost for job-related certifications and/or training programs as well as contributing towards job-related higher-level education. \n  EEO Statement \n  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n  Disclaimer \n  This description in no way implies that the duties listed here are the only ones the employee can be required to perform. The employee is expected to perform other tasks as dictated by their supervisor or JJR leadership."}, "769571fe9f4e06ef": {"terms": ["machine learning engineer"], "salary_min": 115648.56, "salary_max": 146436.84, "title": "Engineering Manager - Cloud Operations", "company": "CoreWeave", "desc": "CoreWeave is a specialized cloud provider, delivering a massive scale of GPU compute resources on top of the industry's fastest and most flexible infrastructure. CoreWeave builds cloud solutions for compute intensive use cases \u2014 VFX and rendering, machine learning and AI, batch processing, and Pixel Streaming \u2014 that are up to 35 times faster and 80% less expensive than the large, generalized public clouds. Learn more at www.coreweave.com. \n \n  About the role: \n  The Cloud Operations Team is the heart of CoreWeave's operational practice. This team is responsible for defining, socializing, and executing the processes and tooling that dictate operational and change management processes for all other engineering teams. With a round-the-clock presence, this team is the first in line to respond to issues in production, serving as generalist responders and incident commanders, and is empowered to drive reliability assessments and improvement across all CoreWeave products. \n  We are seeking an Engineering Manager for the Cloud Operations team who can help us build this new specialization. This individual will develop a strong pipeline of talent, manage onboarding and training, provide process and thought leadership across the team's domain, and champion reliability and customer satisfaction. As the manager of this team, you would have the opportunity to: \n \n Build and lead a 24/7 team of process-oriented, reliability and observability-focused engineers. \n Lead the development, socialization, and supporting tooling for change management, impact assessment, incident management, and post-incident review processes. \n Oversee investments in global observability, operational health measurement, runbook development and maintenance, and automated remediation. \n Provide a 24/7 engineering support function for high-criticality, time-sensitive or resource constrained programs. \n Develop a program of onboarding, documentation, enablement, and performance management to help your team members achieve new heights of personal growth and capability. \n Drive the culture and tone for how your team keeps score both in how they communicate with and support each other and how they enable the rest of CoreWeave. \n \n Wondering if you're a good fit?  We believe in investing in our people, and value candidates who can bring their own diversified experiences to our teams \u2013 even if you aren't a 100% skill or experience match.  Here are some qualities we've found compatible with our team. If a portion of this resonates with you, we'd love to talk. \n \n You have seven or more years of experience in a software or infrastructure engineering industry, of which at least two years were in a leadership capacity. \n You have a background that includes the knowledge and practice of SRE fundamentals, incident management, blameless culture, observability, and change management. \n You're comfortable with the idea of building and leading a 24/7 team of high-performing, diverse engineers. \n You believe in the value of automation and will champion practices that drive reliability and drive the adoption of cross-team processes and tooling. \n You love helping people on their journeys to become their best selves and are comfortable extending the range of your influence to partners, peers, and senior leadership. \n \n \n  Why CoreWeave? \n  At CoreWeave, we work hard, have fun, and move fast! We're in an exciting stage of hyper-growth that you will not want to miss out on. We're not afraid of a little chaos, and we're constantly learning. Our team cares deeply about how we build our product and how we work together, which is represented through our core values: \n \n Be Curious at your Core \n Act like an Owner \n Empower Employees \n Deliver Best In-Class Client Experience \n Achieve More Together \n \n We support and encourage an entrepreneurial outlook and independent thinking. We foster an environment that encourages collaboration and provides the opportunity to develop innovative solutions to complex problems. As we get set for take off, the growth opportunities within the organization are constantly expanding. You will be surrounded by some of the best talent in the industry, who will want to learn from you, too. Come join us! \n  Benefits \n  We offer a competitive salary and benefits, including: \n \n Medical, dental and vision insurance - 100% paid for the employee \n Life Insurance \n Short and long-term disability insurance \n Flexible Spending Account \n Flexible, full-service childcare support with Kinside \n 401(k) with a generous employer match \n Flexible PTO \n Catered lunch each day in our offices \n Weekly massages in NJ office \n A casual work environment \n Work culture focused on innovative disruption \n \n \n \n  California Consumer Privacy Act - California applicants only \n  CoreWeave is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age."}, "989ae87daa3587cc": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Formal Verification Engineer", "company": "INTEL", "desc": "Job Description \n  Oversees definition, design, verification, and documentation for SoC (System on a Chip) development. Determines architecture design, logic design, and system simulation. Defines module interfaces/formats for simulation. Performs Logic design for integration of cell libraries, functional units and subsystems into SoC full chip designs, Register Transfer Level coding, and simulation for SoCs. Contributes to the development of multidimensional designs involving the layout of complex integrated circuits. Performs all aspects of the SoC design flow from highlevel design to synthesis, place and route, timing and power to create a design database that is ready for manufacturing. Analyzes equipment to establish operation infrastructure, conducts experimental tests, and evaluates results. May also review vendor capability to support development.\n  \n  Qualifications \n  Minimum Qualifications: \n \n  Knowledge of digital electronics \n  Knowledge of hardware description languages (System Verilog/Verilog/VHDL) \n  Deep knowledge of System Verilog Assertions \n  Experience in using of System Verilog Assertions \n  Experience in formal verification methodology \n  Experience in using of the Cadence Jasper Tool \n  Experience in setting and using of sequence equivalence checks \n  Excellent written and verbal communication skills in English and Polish language \n \n  Preferred Qualifications: \n \n  Experience in using of the Jasper Gold SuperLint tool \n  Experience in using of the JasperGold's traces sharing mechanisms \n  Knowledge of signal, audio and image processing \n  Knowledge of neural networks and machine learning \n  Experience in algorithms prototyping \n \n  Inside this Business Group \n  In the Design Engineering Group (DEG), we take pride in developing the best-in-class SOCs, Cores, and IPs that power Intel\u2019s products. From development, to integration, validation, and manufacturing readiness, our mission is to deliver leadership products through the pursuit of Moore\u2019s Law and groundbreaking innovations. DEG is Intel\u2019s engineering group, supplying silicon to business units as well as other engineering teams. As a critical provider of all Intel products, DEG leadership has a responsibility to ensure the delivery of these products in a cost efficient and effective manner.\n  \n  Posting Statement \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n  \n  Benefits \n  We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html\n  \n  Working Model \n  This role is available as a fully home-based and generally would require you to attend Intel sites only occasionally based on business need. This role may also be available as our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. \n  In certain circumstances the work model may change to accommodate business needs. \n  JobType  \n Fully Remote"}, "803f25754fa33f7d": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Pre-Si Hardware Verification Engineer", "company": "INTEL", "desc": "Job Description \n  Oversees definition, design, verification, and documentation for SoC (System on a Chip) development. Determines architecture design, logic design, and system simulation. Defines module interfaces/formats for simulation. Performs Logic design for integration of cell libraries, functional units and subsystems into SoC full chip designs, Register Transfer Level coding, and simulation for SoCs. Contributes to the development of multidimensional designs involving the layout of complex integrated circuits. Performs all aspects of the SoC design flow from highlevel design to synthesis, place and route, timing and power to create a design database that is ready for manufacturing. Analyzes equipment to establish operation infrastructure, conducts experimental tests, and evaluates results. May also review vendor capability to support development.\n  \n  Qualifications \n  Minimum Qualifications:  \n \n Knowledge of digital electronics \n  Knowledge of hardware description languages (System Verilog/Verilog/VHDL) \n  Knowledge of System Verilog Assertions \n  Knowledge of UVM Methodology \n  Experience in writing SystemVerilog testbenches \n  Experience in extracting Design Features/Requirements and creating testplan documents \n  Experience in using of the Synopsys VCS/Verdi \n  Excellent written and verbal communication skills in English and Polish language \n  Preferred Qualifications: \n  Experience in regression triage and debugging \n  Knowledge of signal, audio and image processing \n  Knowledge of neural networks and machine learning \n  Experience in algorithms prototyping \n \n \n  Inside this Business Group \n  In the Design Engineering Group (DEG), we take pride in developing the best-in-class SOCs, Cores, and IPs that power Intel\u2019s products. From development, to integration, validation, and manufacturing readiness, our mission is to deliver leadership products through the pursuit of Moore\u2019s Law and groundbreaking innovations. DEG is Intel\u2019s engineering group, supplying silicon to business units as well as other engineering teams. As a critical provider of all Intel products, DEG leadership has a responsibility to ensure the delivery of these products in a cost efficient and effective manner.\n  \n  Posting Statement \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n  \n  Benefits \n  We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html\n  \n  Working Model \n  This role is available as a fully home-based and generally would require you to attend Intel sites only occasionally based on business need. This role may also be available as our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. \n  In certain circumstances the work model may change to accommodate business needs. \n  JobType  \n Fully Remote"}, "c369b191ee5b9e5c": {"terms": ["machine learning engineer"], "salary_min": 172994.0, "salary_max": 241000.0, "title": "Software Engineer, Infrastructure", "company": "Meta", "desc": "We are the teams who create all of Meta's products used by billions of people around the world. Want to build new features and improve existing products like Messenger, Video, Groups, News Feed, Search and more? Want to solve unique, large scale, highly complex technical problems? Meta is seeking experienced full-stack Software Engineers to join our product teams. You can help build products that help us connect the next billion people, create new features that have billions of interactions per day and be a part of a team that\u2019s working to help people connect with each other around the globe. Join us!\n  \n \n \n Software Engineer, Infrastructure Responsibilities:    \n \n Design core, backend software components \n  Code using primarily C/C++, Java, PHP and Hack \n  Interface with other teams to incorporate their innovations and vice versa \n  Conduct design and code reviews \n  Analyze and improve efficiency, scalability, and stability of various system resources \n  Set direction and goals for the team regarding project impact, product quality and engineering efficiency \n  Lead major initiatives, projects, teams, roll-outs and phased-releases \n  Helps onboard new team members, provides mentorship and enables successful ramp up on your team's code bases \n \n \n \n \n Minimum Qualifications:   \n \n  7+ years of programming experience in either C, C++, Java, C# or other relevant coding languages \n  7+ years relevant experience building large-scale infrastructure applications or similar experience \n  Experience building and shipping high quality work and achieving high reliability \n  Experience improving stability through thoughtful code reviews, appropriate testing, proper rollout, monitoring, and proactive changes \n  Experienced in utilizing data and analysis to explain technical problems and providing detailed feedback and solutions \n  Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n \n \n \n \n \n \n About Meta:    Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today\u2014beyond the constraints of screens, the limits of distance, and even the rules of physics.\n  \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com."}, "1f2aff225350da85": {"terms": ["machine learning engineer"], "salary_min": 205000.0, "salary_max": 240000.0, "title": "Applied Scientist III", "company": "Zappos.com", "desc": "Welcome! You made it to the job description page!\n  \n \n \n   At Zappos, we look for people who will show up as their whole self because we value diversity and inclusion, as well as people who enjoy fun and maybe even a little weirdness. So be sure to check on whether you\u2019re aligned with our company values and culture. If you think you can see yourself delivering WOW as a member of the Zappos family, then check out the job description below!\n  \n \n   Company Culture is at Our Core\n  \n \n \n   Our \n   \n   10 Core Values\n    are more than just words, they're a way of life. We know that companies with a strong culture & a higher purpose perform better in the long run.\n    Do our values speak to you?\n  \n \n   1. Deliver WOW Through Service\n    2. Embrace and Drive Change\n    3. Create Fun and A Little Weirdness\n    4. Be Adventurous, Creative, and Open-Minded\n    5. Pursue Growth and Learning\n    6. Build Open and Honest Relationships With Communication\n    7. Build a Positive Team and Family Spirit\n    8. Do More With Less\n    9. Be Passionate and Determined\n    10. Be Humble\n  \n \n \n   Company Perks: Quick Reference\n  \n \n \n \n     Zappos pays 100% of every employee\u2019s medical, dental, and vision benefits.\n    \n \n \n     Zappos pays 100% of 12 therapy, mental health, or coaching session annually.\n    \n \n \n     A multitude of benefits and incentives to stay mentally and physically healthy and fit.\n    \n \n \n     Meaningful assistance programs like professional development, mentoring, and 401k with employer contribution.\n    \n \n \n     Paid time off for life, vacations, staycations, and rest.\n    \n \n \n     A generous Zapponian discount program.\n    \n \n \n     Make an impact through volunteer adventures and other community programs.\n    \n \n \n     Want to have some fun, too? Yes, please! Enjoy team building, family spirit, and plenty of room to recharge!\n    \n \n \n   Zapponian [noun| employee of Zappos]. You are self-motivated. You think like an entrepreneur, constantly innovating and driving positive change, but more importantly, you consistently deliver mind-boggling results.\n  \n \n \n   Bold [adjective| not afraid of anything]. A role at Zappos is an opportunity to be a part of something different. To go bold. We\u2019re a company that isn\u2019t afraid to take risks and question the status quo. Oh yeah, we like to have fun too.\n  \n \n \n   Perks [noun| the good stuff you get for working hard]. Zappos pays 100% of your medical, dental and vision premiums. Primary care visits, dental exams, eye exams and generic prescriptions are all free. Plus matching 401k, life coaches, orthodontic benefits, and more. And don\u2019t forget, an unlimited 40% Zappos.com discount.\n  \n \n \n   1990s [noun| a decade we love, but no longer live in]. Old school cover letters are so 1990. Want to show us who you really are? Create a video cover letter. A flash mob, a comedic monologue\u2026 whatever showcases your passion for Zappos and the work you\u2019d be doing! Videos are not required, but if you create it, we\u2019ll watch it.\n  \n \n \n   Scout [noun| you're a recruiter, too]. As a Zapponian, we\u2019ll ask that you always keep your eye out for great talent to join our family. Consider yourself an extension of the recruiting team, scouting for the best people to grow our company.\n  \n \n \n   SUMMARY\n  \n \n   We are looking for experienced Applied Scientists in the Zappos Machine Learning team that work at the cross section of search and personalization to help understand customer shopping journey, personalize content, guide customer decisions and rank the most relevant products for our customers.\n  \n \n  Our team of scientists, engineers, and data analysts work as a multi-functional team in a primarily remote setting to build, improve, and maintain numerous machine learning models serving a variety of problems. We are a team passionate about building ML innovations in areas such as: Natural Language Processing, Deep Learning, Ranking, and Optimization to improve the customer experience as well as serve our internal partners to make key decisions.\n  \n \n \n   As an Applied Scientist, you will work closely with the team to build custom large-scale ML solutions in production to build meaningful and memorable experiences for our customers.\n  \n \n \n   WHAT YOU WILL BE DOING\n  \n \n \n \n     Find opportunities to improve our customers\u2019 website experience and propose a project plan backed up with data analysis.\n    \n \n \n     Scope projects with functional requirements and collaborate with internal & external teammates on Data, Modeling, ML Infrastructure, and path to production.\n    \n \n \n     Lead the design, implementation, and successful delivery of large, critical, or difficult scientific solutions.\n    \n \n \n     Research and implement novel ML models to improve the customer experience on the Zappos website.\n    \n \n \n     Invent, design, build and maintain innovative large-scale ML software systems that are stable and performant in production.\n    \n \n \n     Lead high code quality and engineering standards in the team, maintain and improve core ML pipeline.\n    \n \n \n     Sharing your knowledge base with others and mentoring more junior team members.\n    \n \n \n     Going beyond your existing toolkit to deliver a solution catering to multiple stakeholders and influence product roadmap using data backed analysis.\n    \n \n \n \n   WHAT YOU BRING TO THE TABLE\n  \n \n \n \n     PhD in Computer Science, ML or related field and at least five (5) years of related work experience or MS in Computer Science, ML or related field and at least ten (10) years of experience.\n    \n \n \n     At least four (4) years of experience in areas related to Search, Recommendation Systems, Personalization, and Applied ML.\n    \n \n \n     A previous track record of publications in one of the following fields: information retrieval, recommendation systems, and natural language processing.\n    \n \n \n     Proficiency in writing high quality production code, demonstrating strong software engineering and coding skills.\n    \n \n \n     Proficiency in neural frameworks such as Tensorflow and PyTorch.\n    \n \n \n     Experience with web-scale data preprocessing and ML workflow such as Apache Spark, Pipelines, etc.\n    \n \n \n     Experience working with cloud computing services, such as AWS.\n    \n \n \n     A product focus and passion for using machine learning to address real-world problems. Knowledge of various machine learning techniques and key parameters that affect their performance.\n    \n \n \n     Strong verbal and written communications skills and comfort working in a remote team.\n    \n \n \n     Self-motivated, flexible, and strong sense of ownership.\n    \n \n \n \n   WHAT REALLY EXCITES US\n  \n \n \n \n     Experience in the retail and/or e-commerce industries.\n    \n \n \n \n  The base pay range for this position is $205,000 to $240,000 per year; however, base pay offered may vary depending on job-related knowledge, skills, and experience. In addition, a full range of medical and other benefits is offered. \n \n \n \n   The Fine Print\n  \n \n  The Zappos Family of Companies is committed to Equal Employment Opportunity regardless of race, color, national origin, gender, sexual orientation, age, religion, veteran status, disability, history of disability or perceived disability. If you need assistance or an accommodation due to a disability, you may email us at recruiting@zappos.com or call us at 1.702.943.7777.\n  \n \n \n   To all recruitment agencies: We do not accept unsolicited agency resumes and are not responsible for any fees related to unsolicited resumes."}, "8ef7c9f752ad88a4": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Product Manager", "company": "Amperon", "desc": "The Company You'll Join \n  Amperon is the leading analytics and forecasting company for the energy transition. Our platform leverages advanced algorithms and machine learning techniques to accurately forecast energy demand on both the supply (power & utilities companies) and demand (large energy users) sides of the market. We incorporate real-time data feeds that help our clients reduce cost, monitor energy efficiency while increasing substantially. \n  We bring the brightest mind from energy, security and technology in order to combat climate changes and transition to clean energy solutions. We have offices in Texas but are a remote first company. \n  Our Mission \n  As the electricity grid faces challenges due to renewables, EVs, climate change, and more, there's a desperate need for an upgrade. Amperon's blend of energy expertise and AI technology offers analytics and forecasting software to improve grid reliability and accelerate decarbonization. We're building the next generation of market-leading energy analytics and forecasting products, and we want you to be part of our journey! \n  The team you'll work with \n  Our team is actively growing and we are looking for a Product Manager to work in tandem with the Head of Product to help lead the development and delivery of innovative and sustainable products that address electricity consumption. Our team works cross-functionally with engineering, marketing, sales, and our customers to roadmap and deliver best in class solutions; from ideation to launch. \n  The Impact \n  You will be playing a critical role in building out the foundation of our data stack. It is a force-multiplier development role that allows an engineer to have an impact broadly across engineering, data science and business. Engineers and data scientists will appreciate the ease of accessing the data while the business will appreciate the insights provided by the data in order to launch new products plus better serve our customers. \n \n  The problems you'll solve \n \n Drive the development and implementation of new products and features that align with our company's goals and customer demands. \n Conduct market research to identify emerging trends and opportunities, and translate insights into actionable product features and requirements. \n Collaborate with engineering, marketing, and sales teams to ensure products are technically feasible and commercially viable. \n Create and maintain detailed product roadmaps, timelines, and specifications, and communicate them effectively to internal and external stakeholders. \n \n You may be a fit for this role if \n  You have proven experience managing the product development process, from product design and prototyping to testing, launch, and post-launch evaluation. You have experience d defining and measuring product success metrics, and iterate on product features based on user feedback and market insights. \n  Perks \n  While we are serious about our company's culture, we aren't going to force \"culture\" to prove that we are cool and fun. It's a company filled with smart, genuinely nice individuals who are passionate about data science, energy and working together to build a product that can have a lasting impact on our planet. \n  Even though we are a remote company with employees spread across the globe, we still believe human interaction is a good thing. We will also have an all-company event at least once a year so people can get to know each other in a more fun and social way. \n \n Competitive salary \n Health insurance \n Monthly gym membership stipend \n Pre-tax commuter benefits \n 401k \n Stock options \n Flexible work hours \n Remote \n \n  If you are excited about contributing to a product that can have a lasting impact on our planet and you thrive in fast-paced, innovative environments, we would love to hear from you."}, "e86f191b00c8aca3": {"terms": ["machine learning engineer", "mlops"], "salary_min": 140000.0, "salary_max": 200000.0, "title": "DevOps Engineer", "company": "Spresso", "desc": "At Spresso, our mission is to use data to deliver better business outcomes to various industries around the world. We optimize decision-making with tools we\u2019ve built spanning a decade of first-hand experience in e-commerce. What started as an end-to-end platform for the e-commerce retailers is now a world-class suite of SaaS products powered by advanced analytics and machine learning. Spresso brings unique data and machine learning capabilities to retailers globally. \n Our Engineering team is a brilliant cultivator of technology powering our world class platform & SaaS modules spanning everything from Catalog, Orders & Fulfillment, and Personalization. Being part of Spresso\u2019s Engineering team means you\u2019ll work with wicked-smart individuals from all over the world who contribute as engineers, product managers, designers, and data scientists. Every day our Engineering team innovates in the e-commerce space with the latest technologies. We\u2019re excited to welcome engineers who are ready for a challenge and know how to think outside the box! \n The DevOps team values an always-learning approach to technology. We want people who already know they don\u2019t know it all, and who are willing to work closely and honestly with team members to collectively and objectively find the best solutions to problems. Technological humility - the desire to build what\u2019s correct over being the person who\u2019s correct - is a trait we value highly. \n As a  DevOps Engineer , you\u2019ll be helping to scale out and improve our large and growing GCP infrastructure and helping us manage our applications running in Docker and Kubernetes. Most of the software we run is Node.js, with a heavy reliance on MongoDB. Python, Go, and Java, which are also utilized for various services, as are several other data stores, including Redis, Postgres, Snowflake, and Elasticsearch. \n You Will: \n \n Work collaboratively with the team to build out and improve our large and growing GCP infrastructure \n Improve and optimize our cloud infrastructure with Terraform \n Help automate and streamline our operations \n Troubleshoot and resolve issues in our dev, staging and production environments \n Support Software Engineers with building, testing, and deploying their applications \n Be on an on-call rotation with the rest of the Engineering team \n Be a critical part of not just the technology team but to the company as an excellent problem solver. \n \n Requirements: \n \n Good programming skills \n Experience with Kubernetes \n Experience with GCP components & pitfalls (AWS or Azure also acceptable) \n Experience with an IaaC tool (Terraform) \n Experience with a CI/CD tool such as Jenkins \n Experience writing Dockerfiles for apps in multiple languages \n Experience writing scripts to automate repetitive tasks \n Disaster recovery experience, especially if self-inflicted \n Experience with MongoDB performance analysis, debugging, and/or data modeling \n Familiarity with cloud networking - Firewalls, NAT, VPN, network peering \n Experience running Node.js apps under load \n Ability to debug system problems like running out of memory, inodes, or ephemeral ports \n Knowledge of distributed systems (formal theory or learned firsthand) \n Experience using a Log Aggregation Platform. \n \n Job Type: Full-time \n Pay: $140,000.00 - $200,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Parental leave \n Vision insurance \n \n Work Location: Remote"}, "2810a2bd5c90ed85": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Numerical Analyst / Research Engineer", "company": "Protection Engineering Consultants", "desc": "Job Description \n  Protection Engineering Consultants (PEC) is a unique and diverse small-business engineering firm. PEC\u2019s services range from security consulting and risk mitigation support to the design, research, analysis and testing of protective structures subjected to extreme loads, such as weapons effects, blast, vehicle impact, forced entry attack and natural hazards. We provide structural and mechanical engineering services; use machine learning (ML) and uncertainty quantification (UQ) techniques to deliver novel solutions to engineering problems; create specialized software for defense and anti-terrorism applications; perform advanced numerical modeling; develop, oversee and perform nonlinear and dynamic testing; develop criteria for protective applications; and, provide training. We work domestically and internationally. \n  PEC is in search of a creative and motivated numerical analyst/research engineer who can support our advanced technology and applied research projects. The candidate must have experience (academic or work-related) in applying and/or developing state-of-the-art numerical modeling tools, for solid dynamics and fluid dynamics applications. Experience modeling extreme loads and highly nonlinear material response is preferred and course work in structural dynamics, numerical analysis, and computational modeling is expected. The ideal candidate will have capabilities in one or more of the following areas: nonlinear dynamic analysis using LS-DYNA, CTH, ABAQUS, ANSYS, DYSMAS, OpenFoam, or other first-principles high-fidelity, physics-based codes; laboratory testing; and programming in Python or other scientific languages. Familiarity with and application of data analytic techniques and open-source software is a plus. \n  Your role initially will be to provide support for our ongoing efforts. We will provide opportunities for you to grow technically as well as expand into project management, marketing, and business development responsibilities as your interests dictate. \n  This position offers both in-office and remote work options. Office locations include San Antonio and Austin, Texas. Remote work options are available within the contiguous United States. \n  Qualifications \n \n  BS or MS in Engineering, Physics, or Mathematics. \n  Recent graduates are welcomed, but work experience is a plus. \n  Course work or experience in structural dynamics, numerical analysis, and computational modeling. \n  Programming in Python or other scientific languages. \n  Ability to clearly communicate verbal and written technical information. \n  This position requires the ability to obtain a U.S. security clearance for which the U.S. Government requires U.S. citizenship. \n \n  Benefits \n  PEC offers a competitive compensation package for the successful candidate. Benefits include: \n \n  Competitive salary. \n  Flexible work schedule. \n  Relocation expenses. \n  Annual performance bonuses. \n  Opportunity for company ownership. \n  Professional development and training support. \n  Health, Dental, and Vision Insurance paid in full. \n  401(k) match plan. \n \n  Protection Engineering Consultants LLC (PEC) provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, PEC complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfers, leaves of absence, compensation and training. \n  Please send all applications and inquiries to careers@protection-consultants.com"}, "49a90d4bf72d7da7": {"terms": ["mlops"], "salary_min": 75034.56, "salary_max": 95010.47, "title": "Junior DevOps Engineer", "company": "Centennial Technologies", "desc": "Centennial Technologies is seeking a junior DevOps Engineer to work on a federal project. this position is fully remote. We can hire from DC, MD, VA, OH, NC, MN, IL, and MN, CO. \n The selected candidate will be responsible for the following tasks: \n \n Implementation of HashiCorp Sentinel embedded policy framework to enable policy enforcement: \n     \n Developing patterns of conditioned-based policies. \n Implementing enforcement levels of advisory, soft-mandatory, and hard mandatory. \n Outputting Sentinel activity (logs) via Splunk. Providing mechanisms for privileged consumers to access data in Splunk. \n \n Coordinating the implementation of Service Control Policies (SCP) via AWS Control Tower to existing Organizational Units. A prioritized list of SCPs will be provided that includes but is not limited to specific regions, permitted services, role/policy development, etc. \n \n Qualifications: \n \n Bachelor\u2019s degree in Computer Science, Engineering, or a related field. \n Experience with HashiCorp Sentinel and embedded policy frameworks. \n Proficiency in developing conditioned-based policies. \n Familiarity with advisory, soft-mandatory, and hard mandatory enforcement levels. \n Experience with Splunk for logging Sentinel activity and providing access to privileged consumers. \n Knowledge of AWS Control Tower and experience coordinating the implementation of Service Control Policies (SCP). \n Problem-solving and troubleshooting skills. \n Excellent communication and collaboration skills. \n \n Desired: \n In addition to the above requirements, the DevSecOps Engineer is good to have experience with the following technologies: \n \n SIEM/Log Aggregation \n Splunk \n     \n Metrics, Alerting, Dashboarding \n Predictive Analytics \n Integration with ServiceNow event management \n \n Monitoring/AIOps \n Cisco Application Dynamics \n     \n Automation of alerts, notifications \n Integration with ServiceNow Event Management \n \n ServiceNow \n     \n ServiceNow Event Management integrated into ServiceNow Incident Management \n \n Amazon X-Ray \n \n About the Company  Centennial Technologies Inc. (Centennial) is committed to a healthy work-life balance for our employees and we have worked hard to foster an environment that enables employees to effectively prioritize both their professional and personal responsibilities. We make every effort to accommodate employees by providing flexible paid time off, a casual work atmosphere, frequent collaborative interaction, and the opportunity to continuously develop career skills. \n \n   Centennial offers a competitive benefit package, which includes Medical, Dental, Short-Term Disability, Long-Term Disability, and Life Insurance, 401k, Mass Transit Benefits, Paid Time Off and Federal Holidays.\n    \n Our Culture is inclusive of: \n \n \n A supportive professional environment which promotes a healthy work-life balance \n Performance Management techniques which reward our top performers \n Employee surveys and discussions to inform Management\u2019s decisions \n Paid training on the latest technologies and business practices \n An employee-focused model \n Our team\u2019s shared vision of client success through cultivating long-term client relationships \n \n \n Equal Opportunity Employer \n Centennial is an equal opportunity employer and complies with all applicable federal, state, and local employment laws. \n \n \n \n \n \n Job Category:  Information Technology & Services IT \n     \n \n Job Type:  Full Time \n     \n \n Job Location:  remote"}, "81b543bd856ee22a": {"terms": ["mlops"], "salary_min": 162000.0, "salary_max": 172000.0, "title": "Senior Staff DevOps Engineer", "company": "Wolfe", "desc": "We are a fast-moving team looking for a  Senior Staff DevOps Engineer  with a passion to lead the transformation to DevOps and Continuous Delivery across the organization. Work directly with the Development, QA, and Support teams using agile methodologies to implement innovative, reliable, automated, and secure solutions in Cloud. To be a good fit, you'll need to have experience in leading multiple development projects, working across the organization, coaching and mentoring team members, supporting development and production environments and effective communication and collaboration skills. As an expert in the field, this role uses professional concepts in developing resolution to critical issues and broad design matters. The Senior Staff DevOps Engineer works on issues that directly impact current and future business success by creating formal networks with key decision makers and serves as external spokesperson for the organization. \n The Company: Wolfe LLC is an e-commerce company, located in Pittsburgh, PA, focused on next-generation gifting business models. We are well known for being the company that started the first coupon website in 1995 which sold to a public company in 2000, at the peak of the dot-com era, when we were delivering 20 million page views per month. We then built Direct Response Technologies; grew it to 70 employees; and sold it to Digital River in 2006. We spun off Jambo Media with our tech team and sold it to Undertone in 2012. We built and focused on GiftCards.com from 2006 to 2016 and sold it to Blackhawk Network. We had over 100 employees. Since 2016, our focus has been Gift Card Granny, PerfectGift, GiftYa, and Give InKind and Reaf Marketing. We have roughly 170 employees and contractors. We are experiencing triple-digit growth year over year for 4 years, thankfully. Our organization is committed to a positive work environment, and we prioritize our culture to continue to facilitate our high performance as a cohesive culturally enlightened team. We use OfficeVibe, Bonusly, and other leading tools to ensure our cultural initiatives are effective and productive. \n Company and Executive Team Recognitions: \n \n 2023 Inc. 5000 list of fastest-growing private companies (ranked no. 382) \n 2022 First place - Fast 50 Growing Companies Pittsburgh, Pittsburgh Business Times \n 2020 Best Places to Work by the Pittsburgh Business Times \n 2019 Carnegie Science Award Recipient, Entrepreneur Category \n 2017 Outstanding Entrepreneur Award Winner by the Pittsburgh Venture Capital Association \n 2015 Business Times Diamond Award Winner \n 2015 Business Ethics Award Winner \n 2015 Create Award Winner \n 2015 CEO of the Year Winner Pittsburgh Technology Council \n 2014 Entreprenuer.com Entrepreneur of the Year Finalist \n 2013 Governors Impact Award Winner \n 2011 Ernst & Young Entrepreneur of the Year Award Winner \n 2011 CFO of the Year Finalist \n 2011 CIO of the Year Finalist \n \n Responsibility: \n \n Partner with architects and application development teams to lead evaluation and building of new cloud services, features, & enhancements \n Design, implement and maintain AWS infrastructure including operation, security and compliance aspects \n Lead collaboration with other technology teams, stakeholders, and partners to gather requirements, define architecture, and provide technical expertise for projects. \n Partner with other stakeholders to develop and maintain the enterprise architecture vision, strategy, and roadmap, ensuring it aligns with the organization's business goals and objectives \n Create processes to perform continuous deployment, including full orchestration of deployment processes \n Write code, scripts, and templates to automate the provisioning and de-provisioning of cloud services using tools like Terraform and cloud provider APIs \n Create and provide best practices to the organization for DevOps, SecOps, CI/CD, and infrastructure \n Establish technical strategy and governance for cloud infrastructure and DevOps practices \n Exercise wide latitude in determining objectives and approaches to critical assignments. \n Analyze and evaluate the existing technology landscape, identifying areas for improvement and proposing strategic enhancements and optimizations \n Work closely with IT teams to guide the implementation of architectural principles and promote a culture of continuous improvement \n Participate in after-hours on-call rotation as needed to support production systems. \n Automation-first mindset \n Implement monitoring processes and design/deploy monitoring dashboards \n Build and support system automation, deployment, and continuous integration tools \n Help to maintain and monitor production environments \n Determine secure patterns & configurations for cloud services \n Use Site Reliability Engineering (SRE) principles to ensure the availability and resilience of Wolfe's public cloud hosted applications \n Provide technical consulting and expertise to application teams using public cloud services \n Manage Wolfe's cloud development tools including CI/CD orchestration platforms, source code repositories, artifact repositories, code quality tools, etc. \n Establish Incident Response playbooks and monitoring strategy; work closely with Engineering to promote accountability, escalations, and communication best practices. \n Troubleshoot and resolve production issues \n Partner with Security, CISO and IT to establish required security frameworks (e.g. PCI, SOC2, etc.) and best practices. Participate in audit activities as needed. \n Excellent verbal and written communication skills required \n Must be able to communicate effectively with other team members and leaders \n Positive, inspiring attitude to lead and champion change \n Mentor and lead technical staff \n \n Qualification: \n \n 8-10+ years of experience in AWS focused cloud engineering \n Strong Experience with AWS services like EC2, S3, RDS, ECS, API Gateway, Lambda, CloudFront, etc. \n Strong experience with Infrastructure-as-Code (IaC) automation with tools such as Terraform \n Proven experience with DevOps solution architecture, DevOps governance, DevOps technical guidance and mentoring \n Strong knowledge of Docker and Kubernetes, including deploying Kubernetes manifests, scaling pods, and managing stateful workloads \n Familiarity with MySQL databases and query optimization \n Experience with security best practices to support industry-specific \n Hands-on experience with ECS container orchestration \n Experience with CI/CD pipelines, tools, and best practices \n Experience with automation of CI/CD pipeline and infrastructure automation \n Strong Linux engineering skills \n Proven ability to steer and influence technical direction across the organization \n Willing to document key knowledge and share with team \n Problem-solving skills and ability to analyze complex issues and devise creative and practical solutions \n Communication and interpersonal skills to work effectively with cross-functional teams and stakeholders \n Track record of designing and implementing scalable, reliable, and secure software solutions \n Ability to align business and technology strategies and articulate complex technical concepts to non-technical stakeholders \n Comfortable conveying complex topics with executives and business leaders \n \n * Compensation & Benefits:* Wolfe is committed to providing its employees with a benefits package designed to give them the flexibility they need to ensure a healthy life/work balance. Wolfe offers its employees great benefits and perks, including, but not limited to: \n \n Restricted Stock Units (RSUs): This is an ownership and profit-sharing program. Our employees have earned over $18m through this program since 2000. \n \n \n Medical, Prescription, Vision, and Dental insurance for employees and dependents \n 15 days of PTO (vacation). 20 days after the 2-year anniversary. 25 days after the 5-year anniversary. \n 12 Paid Holidays plus 2 Floating Holidays \n 401(k) \n Tuition Reimbursement \n \n \n Employee recognition program \n Charitable Donation to a Charity of YOUR Choice yearly \n Employee Referral Bonus: Refer Friends, and if we hire them, you get awarded \n Family Picnic, Holiday Party, and other employee outings \n Brown bag sessions to keep you informed on the company/industry \n Internal Culture Club \n Competitive Compensation (Top quartile pay): The Top 75 percentile total pay range versus other local employers \n \n Wolfe is an Equal Opportunity Employer. \n Wolfe does not sponsor individuals for the purpose of obtaining H-1 Visas. \n Job Type: Full-time \n Pay: $162,000.00 - $172,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Health savings account \n Paid time off \n Referral program \n Tuition reimbursement \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n Performance bonus \n RSU \n \n Experience level: \n \n 8 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote"}, "fa1f99f0b82544a3": {"terms": ["mlops"], "salary_min": 60.0, "salary_max": 64.0, "title": "DevOps Architect", "company": "TekwissenGroup", "desc": "Overview: \n TekWissen Group is a workforce management provider throughout the USA and many other countries in the world. Our client is an American multinational information technology services and consulting company and is a leading provider of information technology, consulting, and business process outsourcing services, dedicated helping the world's leading companies build stronger businesses. \n Job Description: \n \n Data Engineering: \n Snowflake (CDW) \n AWS (Glue, DMS, S3) \n Informatica IICS \n Active Batch \n Denodo (Virtualization) \n \n DevOps: \n \n GitHub (SCM) \n GitHub Actions (CI,CD Orchestration & Integration) \n Schemachange (snowflake utility) \n Docker \n Develop and implement best practices for team members to consistently execute deployments and establish a \"rename and archive\" process for SQL changes in Snowflake. \n Implement a peer-review process for code and create basic tests to ensure code quality and prevent disruptions in the PROD environment. \n Establish a Sprint review or similar workflow where business approvals are collected for changes. \n Reduce deployment time by automating scripts through Github actions, enabling more deployments. \n Create an additive deployment process that renames and hides previous versions of data pipelines instead of removing and replacing them. \n Develop an automated rollback process to easily revert changes in case of issues post-deployment. \n Incorporate code review into the deployment process to ensure code sanity checks. \n Design automated tests to ensure deployment success and mitigate the risk of bugs in the PROD environment. \n Integrate ServiceNow signals to automatically document deployments in the change management platform. \n Demonstrate a safe way to update PROD systems while supporting more deployments and embracing Agile methodologies. \n Apply the same CI/CD principles and goals to other platforms, such as AWS, where possible. \n Define Release Management Strategy for Code Promotion handling parallel releases \n \n TekWissen\u00ae Group is an equal opportunity employer supporting workforce diversity. \n Job Types: Contract, Full-time \n Pay: $60.00 - $64.00 per hour \n Experience: \n \n Snowflake (CDW): 1 year (Preferred) \n AWS (Glue, DMS, S3): 1 year (Preferred) \n Informatica IICS: 1 year (Preferred) \n \n Work Location: Remote"}, "a3455a689db14b5e": {"terms": ["mlops"], "salary_min": 123782.4, "salary_max": 156736.1, "title": "DevOps Engineer", "company": "Cyberjin", "desc": "Hybrid Role \n  Looking for a DevOps Engineer with prior experience with Big Data Solutions, Cloud technology, and strong working knowledge of Linux. Passionate about the concept of infrastructure as code and leverages modern tools to define, build and manage virtual infrastructure in the cloud. Work is performed in a hybrid environment with a great team. \n \n  Essential Job Responsibilities \n  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications \n  Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills. \n  Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. \n  Prior experience or familiarity with Unified Platform (UP) Big Data Platform (formerly owned by DISA) is a plus. \n  Data parsing/transforming techniques to include JSON, XML, CSV formats. \n  Understanding of AGILE software development methodologies and use of standard software development tool suites. (e.g., JIRA, Confluence, Github Enterprise, etc.) \n  Willing to do on-call/pager duty is a big plus. Possible rotating shift in the future for this role as the current team is full. \n   \n tp62WnoObd"}, "bbb07e50379e9844": {"terms": ["mlops"], "salary_min": 120000.0, "salary_max": 145000.0, "title": "AZURE DEVOPS ENGINEER", "company": "Procentrix", "desc": "Position Description \n \n  The Azure DevOps Engineer will be part of an enterprise team working to plan, develop, integrate, deploy, and support multiple applications in a massive modernization effort that will integrate numerous systems in a complex multidisciplinary process. This individual will be a key part of the modernization effort; ensuring that a seamless process integration is achieved from foundational requirements to capability deployment across a complex environmental landscape to managed production code. As the program progresses, you will own environmental management and promotion across multiple dev teams, coordinating the complex deployment needs of an increasingly challenging topology, as one-at-a-time applications transition to sustainment and the operational continuity you\u2019ve assured through careful management enters a new stage. \n \n  The projected compensation range for this position is $120K to $145K (annualized USD). The final salary offered will generally fall within this range and is determined by various factors, including but not limited to the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as internal pay equity, location, contract-specific affordability and other organizational requirements. \n \n  Required Skills \n At least 6 years of experience working in an agile development environment implementing DevOps processes utilizing cloud technologies \n Experience implementing, configuring and optimizing Cloud environments to support specific business solutions based on overall Cloud architecture plan \n Ability to work closely with technical leads and team members to appropriately plan the full downstream lifecycle of delivery \n Experience documenting and communicating release definitions and inclusions to business stakeholders, including compliance and review bodies \n Intimate familiarity with Git source control mechanisms and management \n Significant experience implementing Microsoft Azure DevOps pipelines for CI/CD patterns through YAML configuration \n Comfortable with command-line and shell tools, especially PowerShell \n Familiar with containerized deployment (specifically, Docker) practices and procedures \n Strong focus on DevSecOps and responsible for software development, recognizing the security threats, and configuring the network infrastructure \n \n  Desirable Skills \n Active Public Trust Background Investigation \n Experience with integrating automated test cases in CI/CD pipelines (specifically, Selenium) \n Experience managing complex service topologies with Kubernetes (AKS, ideally) \n Experience with Microsoft Power Platform development and solution management approaches \n Familiarity with PowerApps Build Tools for Azure DevOps \n Relevant Microsoft certifications such as AZ-104, 204, 400 \n \n  Job ID"}, "b602f2ecfc7cabfa": {"terms": ["mlops"], "salary_min": 131222.1, "salary_max": 166156.4, "title": "DevOps Architect", "company": "Signant Health", "desc": "US (remote) \n \n  Are you ready for the Most Impactful Work of Your Life? \n Signant Health is a global evidence-generation company. We\u2019re helping our customers digitally enable their clinical trial programs, meeting patients where they are, driving change through technology and innovations and reimagining the path to proof. \n Working at Signant Health puts you in the very heart of the world\u2019s most exciting sector - a high-growth, dynamic company in an extraordinary industry. \n Where do you fit in? \n We are looking for a DevOps Architect to join our R&D Team who is a self-starter who thrives in a fast-paced, agile environment, which means wearing many hats, being able to change direction quickly, and showing an eagerness to learn and introduce new technologies as the need arises. \n \n \n As part of our team, your main responsibilities will be: \n \n \n Advise clients on leading cloud practices and\u202farchitectual approaches \n Architect cloud-native, hybrid, or multi-cloud solutions to meet business needs \n Lead the design and development of innovative cloud and\u202fDevOps solutions \n Build strong client relationships and foster the growth of other team\u202fmembers. \n Stay current with the latest cloud services, methods, and\u202ftrends. \n Provide\u202fguidance for\u202fcapacity\u202fplanning and\u202farchitecture of new services. \n Provision and configure infrastructure resources using code and\u202ftemplates. \n Architect and design logging, metrics and alerting tool chains \n Work with testing\u202fto conduct systems tests for performance and\u202favailability. \n Document cloud infrastructure, create runbooks and\u202fplaybooks. \n Work with customers and other teams to improve customer\u202fexperience. \n Guide the team to solve build & deployment automation issues. \n Design/Implement release orchestration solutions\u202ffor all size projects. \n Work with\u202facross teams including (application,\u202fsecurity & Devops teams) to provide guidance and leadership for new and existing solutions \n \n You\u2019ll need to bring: \n \n \n Minimum 8 years\u2019 experience working in complex enterprise\u202fIT\u202fenvironments using software engineering\u202ftechniques. \n Hands-on experience with Infrastructure as Code (Terraform or CloudFormation) \n Hands-on experience with automation tooling such as Chef, Puppet, or Ansible \n Experience working with the AWS public cloud or Microsoft Azure. \n Must have strong expertise in the following fundamental AWS Services (VPC, Subnet, Elastic Network interface, Internet Gateway, Route table, NAT Gateway, Network ACL, Direct Connect, VPC Peering, VPN, EC2). \n Experience in configuring connectivity between on \u2013Premise and AWS with\u202fappropriate security\u202fconfigurations. \n Trouble shoot and performance tuning of cloud\u202fservices. \n Understanding of\u202fDocker & containerization. \n Experience with scripting and orchestration including Terraform and/or\u202fCloudFormation. \n Experience building CI/CD pipelines. \n Experience using Git and Build Release Management Tools. \n Solid Linux\u202f& Windows\u202fexperience \n Hands-on experience in web\u202farchitecture around both Windows and Linux stacks \n Understanding of virtual machine environments and hypervisors \n Working knowledge of database technologies like MySQL, Oracle, AWS\u202fRDS, \n Ability to mentor other engineers in Lead\u2019s area of\u202fexpertise. \n Ability to collaborate and communicate within a cross functional\u202fteam. \n \n We will be thrilled if you also have: \n \n \n Bachelor\u2019s degree or equivalent years of experience \n MBA highly desirable \n  And finally, here are the ways of working that will help you succeed at Signant: \n \n \n You enjoy problem-solving and have a constructive can-do attitude. \n You're motivated by working in a fast-growing global company. \n You\u2019re self-driven, active, and want to learn new things continuously. \n  We know that everyone has different wants and needs, which is why along with a highly competitive base salary, we support our people and their loved ones with a variety of perks and benefits. \n As part of our team, some of the benefits you can expect to receive are: \n \n \n Our Long-Term Incentive Plan, which is unique to the industry \n The flexibility to work remotely \n Comprehensive health, dental, and vision insurance \n A competitive retirement savings plan \n Generous paid time off \n  Does this sound like something you\u2019d like to explore? Then we\u2019d love to hear from you! \n Please apply below. We review and respond to every application, keep an eye on your inbox for our reply. \n \n  Please note that Signant does not accept unsolicited resumes from Third Party vendors. \n #LI-CA1 \n #LI-REMOTE \n \n  At Signant Health, accepting difference isn\u2019t enough\u2014we celebrate it, we support it, and we nurture it for the benefit of our team members, our clients and our community. Signant Health is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or veteran status."}, "6acb5c5fa3bc6f0d": {"terms": ["mlops"], "salary_min": 126946.48, "salary_max": 160742.53, "title": "Senior DevOps Engineer (USA Remote)", "company": "Anomali", "desc": "Company Description: \n \n \n \n \n   Anomali delivers earlier detection and identification of adversaries in your organization\u2019s network by making it possible to correlate tens of millions of threat indicators against your real time network activity logs and up to a year or more of forensic log data. Anomali\u2019s approach enables detection at every point along the kill chain, making it possible to mitigate threats before any material damage to your organization has occurred.\n  \n \n \n \n  Job Description: \n \n \n \n  Senior DevOps Engineer \n \n \n \n  As a Senior DevOps Engineer, you will actively interface with software developers, product managers, test engineers, and administrators on projects to design and develop the build, release, and deploy toolchain for DevOps while providing on-call support. You should be able to support the identification, troubleshooting and resolution of issues quickly and effectively, sometimes under pressure. Responsibilities support capacity planning, high availability engineering, performance tuning, and automation/tools development. Excellent communication skills and teamwork are a must!\n  \n \n \n  Responsibilities: \n \n \n \n  Design and develop the build, release, and deploy toolchain for DevOps \n Setup, manage and maintain parity across development, staging, and production application environments in cloud infrastructure \n Provide release cadence across multiple environments \n Prototype and develop cloud-native architecture solutions for application needs \n Design and implement monitoring infrastructure development \n Provide support for production operations \n \n \n \n  Qualifications: \n \n \n   o Support our AWS production, staging and development environments.\n  \n \n   o Implement infrastructure as code for various cloud platforms, from planned architectures.\n  \n \n   o Implement monitoring and logging solutions for different technology stacks or container orchestration platforms.\n  \n \n   o Work with Engineering, IT and DevOps to troubleshoot and resolve issues in our AWS environments.\n  \n \n   o Apply security fixes and patches as required.\n  \n \n   o Ability to participate in an on-call rotation.\n  \n \n \n \n  Required Skills/Experience: \n \n \n   o Mid to senior level experience with Linux servers in virtualized environments.\n  \n \n   o Experience administering Amazon Web Services (AWS) environments (EC2, S3, RDS, etc.), security groups, VPCs, ingress/egress rules.\n  \n \n   o Experience with Terraform solutions. Experience with Ansible (preferred), Puppet or Chef.\n  \n \n   o Experience with Linux Containers and/or Docker.\n  \n \n   o Ability to use a wide variety of open source technologies.\n  \n \n   o Strong scripting using Bash, Python (preferred) & SQL.\n  \n \n   o Experience installing, configuring, and maintaining services such as RabbitMQ, Redis, PostgreSQL, nginx, HAProxy and iptables.\n  \n \n   o Experience with Splunk, Nagios, Syslog etc.\n  \n \n   o Mid level experience with builds, continuous integration.\n  \n \n \n \n Equal Opportunities Monitoring \n \n \n  It is our policy to ensure that all eligible persons have equal opportunity for employment and advancement on the basis of their ability, qualifications and aptitude. We select those suitable for appointment solely on the basis of merit without regard to an individual's disability, race, religion, sex, age or sexual orientation. Monitoring is carried out to ensure that our equal opportunity policy is effectively implemented. \n \n \n \n \n  If you are interested in applying for employment with Anomali and need special assistance or accommodation to apply for a posted position, contact our Recruiting team at  \n recruiting@anomali.com \n ."}, "4e789b369be8d5d4": {"terms": ["mlops"], "salary_min": 107961.11, "salary_max": 136702.81, "title": "DevOps Engineer IV", "company": "RevaComm", "desc": "Headquartered in Honolulu, Hawaii, with remote locations across the United States, RevaComm is a leader in Agile Software Development, User-Centered Design, and DevSecOps. As an enterprise digital transformation company, we transform organizational challenges into powerful digital capabilities through fresh experiences and great technology. Grounded by the company's core values, our approach brings together digital business strategists and architects, software engineers, user experience designers, and project managers to create sustainable solutions for customers while surprising and delighting their users. \n  Platform One provides cutting-edge DevSecOps services globally to the DoD and warfighters. We are mission-driven in enabling our armed forces and partners with secure, modern, cloud-based platforms that allow our users to deploy DoD-accredited software. This facilitates the securing and developing of data tools used by government personnel serving our nation. Our platform allows for shorter development cycles, less debugging, and more rapid feature development. Join us as we help modernize the secure environment in which our military and DoD personnel operate. \n  Minimum Qualifications \n \n  3+ years of CI/CD experience \n  3+ years of Linux experience \n  1+ years of Kubernetes and Docker experience \n  BS/MS in Computer Science or similar technical field of study \n  US Citizen (must be able to pass a background check) \n \n  Preferred Qualifications \n \n  Experience working with AWS \n  Experience with Terraform or other IaC \n  Effective communicator who is experienced in collaborating with customers, UX Designers, and non-technical partners \n  Strong Infrastructure and Configuration Management Experience \n  Passion for learning new technologies and applying design patterns \n  Demonstrated ability to drive and articulate technical challenges and solutions \n  Certifications: Security+, CKA / CKAD, CISSP \n \n  Join Our 'Ohana \n  'Ohana  in Hawaiian translates to  \"Family.\"  But we understand it to mean more than one's relatives. It also includes those people you choose to surround yourself with. The 'ohana-oriented mindset is one of the pillars upon which our company has been built. You can find additional information about RVCM here. \n  At RVCM, we are committed to offering a comprehensive and competitive slate of benefits that prioritize our employee's overall well-being. \n  Compensation and Benefits: \n  As a Full-time RVCM employee, you can also expect these additional benefits: \n \n  Fully remote work within the U.S. \n  Exemplary Medical, Dental, and Vision coverage \n  Health Care and Dependent Care Savings Accounts \n  Group Term Life Insurance auto-enrollment (for employees who participate in health insurance coverage with RVCM) \n  401(k) with company matching after 1 year of service. Accounts are 100% vested immediately \n  15 days of PTO for new hires. PTO increases by 1 day for every year of service up to a max of 25 days \n  11 Paid Holidays \n  Fully Paid Holiday Break (Last week of the calendar year) \n  A company-provided laptop plus a $1,000 Home Office Bonus upon hire; $500 per year thereafter to purchase additional equipment to improve productivity at home. \n  Paid parental leave for the care of a newborn or adopted child is compensated at 100% of the employee's regular, straight-time weekly pay. \n  Healthcare FSA (Flexible Spending Account) for eligible medical expenses \n  Dependent Care FSA (Flexible Spending Account) for eligible dependent care expenses \n  Continuous Education & Training, including financial support for acquiring certifications \n  Mentorship Programs \n \n  We believe in providing a safe space for all members of the RVCM 'ohana to grow and thrive. Our employees come from a broad spectrum of backgrounds, each with a unique story. Diversity, Equity, and Inclusion are at the heart of who we are, and everyone should feel valued and free to bring their most authentic self to work - without fear, without judgment. Creating this environment is important not only for our organization but also for our customers and our communities. \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran."}, "f73dd93faf9fc8d6": {"terms": ["mlops"], "salary_min": 152000.0, "salary_max": 266000.0, "title": "Senior Product Success Manager - DevOps", "company": "ServiceNow", "desc": "Company Description \n  At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \n With more than 7,700+ customers, we serve approximately 85% of the Fortune 500\u00ae, and we're proud to be one of FORTUNE 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u2122. \n Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. \n Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates. \n  Job Description \n  This is a unique opportunity to serve as a product expert in the definition and execution of product adoption and growth success motions within one of the largest product lines at one of the largest and fastest growing enterprise SaaS companies in the world. \n  As a member of the ITSM Product Success team, you will work directly with customers to enhance their overall experience with our products and make them successful, happy customers that want to share their story with others. You will drive customer programs, monitor customer health, and act as an expert for our Customer Success and Professional Services teams. \n  What you get to do in this role: \n \n  Act as an advocate, trusted advisor, and honest broker to accelerate the customer\u2019s adoption journey of ServiceNow DevOps products. \n  Work on early-stage products and drive adoption with a personal touch for early customers. Jointly define expected outcomes with our customers and ensure that they have realized value from the solution. \n  Act as a subject matter expert for DevOps practices and ServiceNow DevOps products. Must also advise on best practices and continue to expand that knowledge across each major release. \n  Work with Customer Success to understand and apply customer maturity model to drive with product adoption in a phased and operational manner, while reducing risk of unrealized value. \n  Maintain active customer conversations as required through (account executive team lead and or customer success team) AE / periodic, consistent engagement for top accounts or selected early adopter accounts. \n  Guide customer conversations, lead best practice workshops (as needed) and troubleshoot issues during critical product adoption escalations. \n  Work closely with ITSM Product Management, Product Engineering, and at-risk Customers on a regular cadence. \n  Act as the voice of our customers, conveying needs and issues internally across departments. \n  Prioritize input from customers, sales, customer outcomes, and partners to the BU to ensure customer feedback is fully represented in our Go To Market process and products investment planning. \n  20-30% of travel involved. \n \n \n  Qualifications \n  To be successful in this role, we need someone who has: \n \n  6+ years in a customer-facing role as a Solution Architect, Technical/Process Consultant or similar role \n  Prior experience of working in a DevOps environment or with DevOps tools preferred. \n  Strong technical skills and can roll up their sleeves to fix technical challenges if needed. \n  Expert problem-solving skills and enjoys untangling complex problems. \n  Strong desire to learn new products and features is a must. \n  Passion for customer success and is tenacious about advising, coaching, and mentoring customers on our technology to drive long-term value. \n  Highly data-driven with commitment to drive customer engagement towards business outcome and value realization. \n  Experience driving cross functional alignment and leading customers engagements. \n  Enjoys working in a fast-paced environment. \n \n  For positions in the Bay Area, we offer a base pay of $152,000 - $266,000, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. \n  Additional Information \n  ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. \n At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office. \n If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance. \n For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government. \n Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site. \n   \n From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license. \n Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow."}, "fa63f391d0f66659": {"terms": ["mlops"], "salary_min": 105000.0, "salary_max": 133500.0, "title": "AWS DevOps and Automation Engineer (Remote)", "company": "First American Financial Corporation", "desc": "Who We Are \n \n  Join a team that puts its People First! First American's Direct division provides comprehensive title insurance protection and professional settlement services for real estate purchases, refinances and equity loans. Since 1889, First American (NYSE: FAF) has held an unwavering belief in its people. They are passionate about what they do, and we are equally passionate about fostering an environment where all feel welcome, supported, and empowered to be innovative and reach their full potential. Our inclusive, people-first culture has earned our company numerous accolades, including being named to the Fortune 100 Best Companies to Work For\u00ae list for eight consecutive years. We have also earned awards as a best place to work for women, diversity and LGBTQ+ employees, and have been included on more than 50 regional best places to work lists. First American will always strive to be a great place to work, for all. For more information, please visit www.careers.firstam.com. \n \n  What We Do \n \n  First American is looking for an AWS Cloud DevOps and Automation Engineer to join our team. You will build secure automation capabilities that enable our application and data engineers to unveil their products to the world. Our goal is to create the platform to make a product smart, secure, and fast. If you are ready to bring your skills to work alongside our team of engineers, we promise you\u2019ll be working hands-on in the cloud with some of the newest technologies out there. \n  What You'll Do \n \n  Develop and Implement complex automation tasks and cloud architecture \n  Advocate DevOps culture, tooling, delivery methods, and cultural practices \n  Assist with estimating work efforts required for each phase of an agile project \n  Provide technical guidance and mentoring to peers and less experienced engineers \n  Identify and raise technical risks and issues \n  Research and stay current in AWS, technology, associated vendor products, and their interdependencies \n  Manage the Delivery of and reporting on the Requirements of all IT audit requests \n  Experience with managing Infrastructure patching that includes Microsoft or other third party tools, and communicate/follow-up with different teams on the vulnerabilities reported from various categories of scans \n  Govern and manage Infrastructure by keeping service accounts, certificates renewals up-to-date \n  Manage/Communicate the Release/Change related activities for the vulnerability and patching items \n  Assist with all infrastructure Configuration Management updates and Infrastructure changes ie. servers, DNS, certificates cleanup activities \n \n \n  What You'll Bring \n \n  5+ years of progressively responsible software engineering and DevOps experience building end-to-end CI/CD pipelines. \n  3+ years of AWS cloud experience is mandatory, Azure a plus (AWS experience must include Networking, Containers, Application integration (queuing), Database and Storage products.) \n  2+ years of experience in building YAML based pipelines and Azure DevOps. \n  2+ years of experience in Configuration Management using Chef, Puppet, Ansible, , etc. \n  2+ years of experience in Infrastructure-a-Code using Terraform and CloudFormation (plus). \n  Experience with Kubernetes Cluster in AWS is a huge plus. \n  Experience with securing the AWS workloads and security practices will be a huge plus. \n  Experienced on Site Reliability Engineering (preferred) and automating repetitive tasks using Python, PowerShell, etc. \n  Extensive experience with configuring and monitoring via tools such as DataDog, ELK, Splunk, AppDynamics, etc. \n  Experience collaborating across multiple functional and/or technical teams to deliver an Agile-based project. \n  Demonstrated growth mentality, enthusiasm about learning new technologies quickly and applying the gained knowledge to address practical business problems \n  Ability to communicate with team members and partners to work through technical solutions \n  Demonstrated knowledge of fundamental cloud security (e.g., Identity and Access Management, firewalls, etc...) \n \n \n  Pay Range: $105,000 \u2013 $133,500 annually \n \n  This hiring range is a reasonable estimate of the base pay range for this position at the time of posting. Pay is based on a number of factors which may include job-related knowledge, skills, experience, business requirements and geographic location. \n \n  #LI-NR1 \n  #LI-REMOTE \n \n  What We Offer \n \n  By choice, we don\u2019t simply accept individuality \u2013 we embrace it, we support it, and we thrive on it! Our People First Culture celebrates diversity, equity and inclusion not simply because it\u2019s the right thing to do, but also because it\u2019s the key to our success. We are proud to foster an authentic and inclusive workplace For All. You are free and encouraged to bring your entire, unique self to work. First American is an equal opportunity employer in every sense of the term. \n \n  Based on eligibility, First American offers a comprehensive benefits package including medical, dental, vision, 401k, PTO/paid sick leave and other great benefits like an employee stock purchase plan."}, "3d86da1e20a6950c": {"terms": ["mlops"], "salary_min": 128192.63, "salary_max": 162320.44, "title": "Senior DevOps Engineer", "company": "Luxoft", "desc": "Project  Description \n \n \n      We are seeking an experienced and highly skilled DevOps to join our Data Analytics development team. You will play a crucial role in building and maintaining our ETL pipelines. Your expertise AWS and CI/CD will help us build efficient deployment pipelines improving the quality and pace of our development with industry best practices.\n       \n  You will be a part of a global team working for an international investment management firm with over 3,000 employees in the United States, Europe, and Asia. Teams work collaboratively on building firm-wired centralized trading platforms\n       \n  Benefits and perks:\n       \n \n Competitive compensation package and benefits \n Opportunities for career and professional growth \n Global company \n Business-domain-specific courses \n Training programs for technical & functional skills \n Business trips to US/NYC \n Onboarding relocation package \n Sports and leisure activities \n Informal team events \n \n \n \n \n \n \n Responsibilities \n \n \n \n Develop deployment pipelines for AWS services with ETL processes on Python, SQL, Elasticsearch, and other technologies \n Enhance and optimize our ETL infrastructure by incorporating industry best practices. \n Collaborate with business users and technology stakeholders to understand requirements and ensure quality and integrity. \n Organize efficient operation of distributed queueing offerings like RabbitMQ, Kafka, SQS, or similar technologies for data processing and communication. \n Continuously improve and optimize data pipelines to ensure efficient and scalable data processing. \n Stay up-to-date with the latest industry trends and technologies related to data engineering and AWS services.  \n \n \n \n \n Skills \n \n Must have \n \n \n Minimum of 3 years of working experience as a DevOps \n Strong experience with AWS \n Strong experience in building deployment pipelines \n Familiarity with distributed queueing offerings like RabbitMQ, Kafka, SQS, or similar technologies. \n Bachelor's degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field.  \n \n \n Nice to have \n \n \n Experience with Elasticsearch, Kibana, and Logstash (ELK Stack). \n Knowledge of container technologies such as Kubernetes and Docker. \n Familiarity with AWS serverless offerings. \n Understanding of AWS Big Data offerings like EMR, Redshift, Athena. \n Broad understanding of equity, fixed income, derivatives, futures, FX, or other financial services instruments.  \n \n \n \n \n \n \n Languages \n \n English: B2 Upper Intermediate \n \n \n Seniority \n \n Senior \n \n \n Relocation package \n \n If needed, we can help you with relocation process. \n \n \n \n \n Vacancy Specialization  \n \n DevOps \n \n \n Ref Number \n \n VR-100222"}, "metadata": {"keywords": ["data science", "data analyst", "data engineer", "machine learning engineer", "mlops"], "locations": ["remote"], "time_ran": "18:43:17-25-09-23", "num_jobs": 129, "timings": {"start_drivers": 45.95454382896423, "find_job_ids": 416.4918432235718, "get_job_descs": 55.49537253379822}}}