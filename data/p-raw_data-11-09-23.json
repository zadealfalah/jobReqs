{"b376020741b70ef0": {"terms": ["data science"], "salary_min": 35.0, "salary_max": 39.7, "title": "Vendor Management Analyst", "company": "Russell Tobin", "desc": "Russell Tobin  is Hiring a  Supply Chain Analyst/Vendor Management Analyst for one of our clients based out in Palm Beach Gardens, FL. This is a  Remote   opportunity  and a contract  assignment for 6-months . \n Pay Range: $35-$39.70/hr. \n Must have requirements: \n \u00b7 Remote (Looking for candidates open to work in Eastern time) \n \u00b7 Need someone with Expert Level Excel (Dashboards, Macros) \n \u00b7 Will be responsible to pull reports and gather information for contract management, creating dashboard, processes, \n \u00b7 Will be working with Vendors they have around 35-40 agency, this person will be checking agreements, onboarding new vendors, managing vendors, keeping track of contracts. \n \u00b7 Mainly responsible to analyse data to gather information to support initiative, trends, vendors, contracts, analysis, cost saving. \n \u00b7 Knowledge of contract management. \n \u00b7 Comm skills \n \u00b7 Primary Roles - Dashboard creation, Audit, billing, payment of invoice, managing vendors. \n \u00b7 Power point presentation. \n \u00b7 Familiarity with Workday is required. \n \u00b7 Recruitment knowledge/experience is required to do better analysis. \n \u00b7 2 rounds of interviews, 1 more if required. \n Job Specific Requirements: Position Overview:  This multifaceted role requires a candidate with advanced Excel expertise, excellent communication skills, contract management and administration experience, adept data analysis abilities, and a comprehensive understanding of recruiting processes. \n Responsibilities: 1. Advanced Excel Analysis: \n \n Utilize advanced Excel functions and tools to analyze large datasets, generate insightful reports, and create data-driven visualizations. \n Develop and maintain complex spreadsheets to track operational metrics, financial data, and project progress. \n Collaborate with cross-functional teams to identify key performance indicators and provide actionable insights for strategic decision-making. \n \n 2. Contract Management & Administration: \n \n Manage contract lifecycle, reviewing, and negotiating agreements with vendors, clients, and partners. \n Ensure compliance with contract terms and conditions and maintain a centralized repository of contracts and related documentation. \n Monitor contract milestones, renewals, and amendments, and communicate with relevant stakeholders to ensure timely execution. \n \n 3. Data Analysis & Reporting: \n \n Conduct comprehensive data analysis to identify trends, opportunities, and areas for process improvement. \n Create regular and ad hoc reports using business intelligence tools, presenting findings to management, and making actionable recommendations. \n Work closely with various departments to gather data requirements and ensure data accuracy and consistency. \n \n 4. Communication & Collaboration: \n \n Foster open communication with internal teams, external partners, and candidates to ensure clear understanding of expectations and deliverables. \n Serve as a point of contact for inquiries related to contracts, data analysis, and recruitment, providing timely and accurate information. \n Collaborate with cross-functional teams to align operational processes and contribute to overall organizational objectives. \n \n Qualifications: \n \n Bachelor\u2019s degree in business administration, Human Resources, Data Science, or related field. Master's degree is a plus. \n Strong proficiency in Microsoft Excel, including complex formulas, pivot tables, data visualization, dashboards and macros. \n Proven experience in contract management, administration, and legal documentation. \n Adept in data analysis tools and techniques, with experience in extracting insights from diverse datasets. \n Excellent written and verbal communication skills, with the ability to convey complex information clearly and concisely. \n Minimum of 5 years of experience with recruiting and talent acquisition, with a deep understanding of recruitment processes and best practices. \n Detail-oriented with strong organizational and multitasking abilities to manage various projects concurrently. \n Ability to work independently and collaboratively in a fast-paced environment. \n Strong problem-solving skills and a proactive approach to identifying operational efficiencies. \n Experience in HRIS systems and Workday (ATS) is required \n \n #COE-EN-PN \n Job Types: Full-time, Contract \n Pay: $35.00 - $39.70 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Vendor management: 3 years (Required) \n Workday: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": " Bachelor\u2019s degree in business administration, Human Resources, Data Science, or related field. Master's degree is a plus. \n Strong proficiency in Microsoft Excel, including complex formulas, pivot tables, data visualization, dashboards and macros. \n Proven experience in contract management, administration, and legal documentation. \n Adept in data analysis tools and techniques, with experience in extracting insights from diverse datasets. \n Excellent written and verbal communication skills, with the ability to convey complex information clearly and concisely. \n Minimum of 5 years of experience with recruiting and talent acquisition, with a deep understanding of recruitment processes and best practices. \n Detail-oriented with strong organizational and multitasking abilities to manage various projects concurrently. \n Ability to work independently and collaboratively in a fast-paced environment. \n Strong problem-solving skills and a proactive approach to identifying operational efficiencies. \n Experience in HRIS systems and Workday (ATS) is required \n \n #COE-EN-PN \n Job Types: Full-time, Contract \n Pay: $35.00 - $39.70 per hour ", "techs": ["microsoft excel", "data visualization", "dashboards", "macros", "contract management", "legal documentation", "data analysis tools", "diverse datasets", "written communication skills", "verbal communication skills", "recruiting", "talent acquisition", "recruitment processes", "organizational abilities", "multitasking abilities", "problem-solving skills", "hris systems", "workday"]}, "517fa2e710075fd0": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "Center 1 (19052), United States of America, McLean, Virginia\n   Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Lead Generative AI Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services that enable real-time customer-facing applications. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience. \n  Enable our users to build new GenAI capabilities. \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $197,400 - $225,300 for Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $209,200 - $238,700 for Lead Machine Learning Engineer\n   Remote (Regardless of Location): $167,400 - $191,000 for Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 1 (19052), United States of America, McLean, Virginia\n   Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Lead Generative AI Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services that enable real-time customer-facing applications. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience. \n  Enable our users to build new GenAI capabilities.    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["python", "java", "scala", "apis", "sdks", "large-language models (llms)", "foundation models (fms)", "api products and services", "genai", "ai safety", "distributed computing", "cache optimization techniques", "deep neural networks", "nlp", "speech", "computer vision", "recommendation systems", "neural network models."]}, "f13f56c787cf47de": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Generative AI Systems (Remote-Eligible)", "company": "Capital One", "desc": "Locations: NY - New York, United States of America, New York, New York\n   Distinguished Engineer, Generative AI Systems (Remote-Eligible)\n  \n  Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "hpc", "ml", "ai", "python", "c/c++", "ml frameworks", "public cloud", "aws", "azure", "gcp", "gpu", "pytorch", "tensorflow", "lightning"]}, "dd3f560eb781d808": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Generative AI Systems (Remote-Eligible)", "company": "Capital One", "desc": "Locations: NY - New York, United States of America, New York, New York\n   Distinguished Engineer, Generative AI Systems (Remote-Eligible)\n  \n  Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["distributed computing hpc", "large-scale ml systems", "ml algorithms", "python", "c/c++", "ml development lifecycle", "ai", "ml frameworks", "public cloud", "modern ai techniques", "distributed platforms", "cloud environments", "aws", "azure", "gcp", "cloud systems", "security", "availability", "performance", "scalability", "cost", "mlops life cycle", "gpu clusters", "ml compilers", "distributed training frameworks", "pytorch", "tensorflow", "lightning", "prompt engineering", "vector databases/knowledge bases", "llm hosting", "fine-tuning", "neural networks", "sysml"]}, "486be783ee46c3de": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Scientist Data Curator \u2013 Remote", "company": "Rancho BioSciences LLC", "desc": "Rancho Biosciences is seeking an experienced data curator with clinical and/or clinical trial data expert knowledge for a full-time role with the company. This is a remote position, and you can work anywhere in the USA! Your primary focus will be on projects that include life sciences data curation. \n  We are a Data Curation company working with some of the most renowned pharmaceutical companies in the world. Our team of scientists, curators, computational biologists, biostatisticians, and computer scientists are located throughout the country; we support talented people living where they chose, working collaboratively together on projects that have a real impact on human health. \n  Requirements \n \n  MD or PhD in Biology or related field; or Master's degree with 3-5 years relevant experience \n  Clean, harmonize, curate clinical and/or clinical trial data/metadata according to various data standards (including diseases, medications, procedures, laboratory and/or biomarker tests). \n  Align data to ontologies/vocabularies. \n  Support the definition of new data standards, data models, terminologies, and ontologies. \n  Read, understand the scientific literature, and extract relevant information from publications and/or public online resources and data repositories creating reports and data manifests in a required format. \n  Communicate strategies, ideas, goals, and progress to the team and/or to the customers. \n  Review and monitor work and its quality. \n  Collaborate frequently with data scientists and data curators.  Provide presentations that are clearly articulated, engaging and convincing. \n  \n \n Desired Experience \n \n  Ability to adhere to timelines. \n  Detail-oriented and well organized, with an ability to work collaboratively/remotely.  \n Ability to communicate effectively at all levels. \n  Independently driven, hardworking, and committed. \n  Familiarity with the FAIR (Findable, Accessible, Interoperable, and Reusable) data guiding principles is a plus. \n  Ability to learn new software systems.", "cleaned_desc": "  MD or PhD in Biology or related field; or Master's degree with 3-5 years relevant experience \n  Clean, harmonize, curate clinical and/or clinical trial data/metadata according to various data standards (including diseases, medications, procedures, laboratory and/or biomarker tests). \n  Align data to ontologies/vocabularies. \n  Support the definition of new data standards, data models, terminologies, and ontologies.    Read, understand the scientific literature, and extract relevant information from publications and/or public online resources and data repositories creating reports and data manifests in a required format. \n  Communicate strategies, ideas, goals, and progress to the team and/or to the customers. \n  Review and monitor work and its quality. \n  Collaborate frequently with data scientists and data curators.  Provide presentations that are clearly articulated, engaging and convincing. ", "techs": ["md", "phd", "biology", "master's degree", "data standards", "diseases", "medications", "procedures", "laboratory", "biomarker tests", "ontologies", "vocabularies", "data models", "terminologies", "scientific literature", "publications", "data repositories", "reports", "data manifests", "format", "team", "customers", "work quality", "data scientists", "data curators", "presentations"]}, "4f48002e7ec5056b": {"terms": ["data science"], "salary_min": 86660.39, "salary_max": 109731.36, "title": "Data Scientist, Growth", "company": "Pagoda", "desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Pagoda Data Science team is looking for a Data Scientist to optimize developer growth and performance marketing. \n  What You'll Be Doing \n \n Define and assess metrics to inform key conclusions in growth optimization; \n Apply statistical models on large datasets to understand trends in developer behavior and influence growth and marketing strategy; \n Develop attribution models, and generate actionable insights into performance of marketing channels and other distribution channels; \n Collaborate closely with Pagoda's Marketing, Product and Developer Experience teams to help identify key drivers of developer growth and engagement; \n Partner with Engineering to optimize data quality; \n Cultivate data-informed decision making culture at the company and constantly research and adopt the most recent best practices in growth analytics. \n \n What We're Looking For \n \n Experience with data querying language (e.g. SQL), scripting languages (e.g. Python), data visualization (e.g. Tableau, Looker), dashboarding and data pipeline tools; \n Experience in growth optimization for B2B2C businesses and finding growth opportunities through data analytics; \n Experience with quantifying experience of developers or other technical audience; \n Strong data storytelling skills and ability to explain complex insights in a succinct way; \n Experience working with a distributed team, with strong written and verbal communication skills \n Bachelor's Degree in Computer Science, Applied Mathematics, Physics, Engineering, Statistics or related field is a must \n \n We'd Love If You Have \n \n Experience working with DataBricks and BigQuery technologies; \n Experience with custom events with Google Analytics; \n Familiarity with crypto or blockchain technologies; \n Familiarity with HTML and JS; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like \n \n Internal Recruiter Call (30 to 45 minutes) \n Meet with the Hiring Manager (30-45 minutes) \n Technical Interviews (3 x 60 minutes) \n Pagoda Values Interview (30 to 45 minutes) \n Meet & Greet with Chief Product Officer (30 minutes) \n \n Compensation  \n The base salary range for this role is $144,500 - $170,000, which represents the salary range applicable to US locations only. This does not include bonus, incentives, or benefits. \n  The actual base pay within the range is dependent upon many factors, including: leveling, relevant skills, and work location. If you are based outside of the US, we there are other geographic considerations that may impact your final compensation. Your recruiter can share more about the compensation and benefits applicable to your preferred location during the hiring process. \n \n \n  Benefits & Perks \n \n Flexible Annual Leave / PTO with an encouraged 20 day per year minimum \n Paid Holiday Week: the last week of the year \n Paid Wellness Week: the first week of July \n $2,000 Yearly Continued Education Reimbursement \n $2,000 Home Office Setup Reimbursement \n Co-working Space Reimbursement \n Company Retreats (2023 in Spain!) & Team Offsites \n Mental Health Support and access to licensed therapists through Spill, 100% paid by Pagoda \n \n Our Values at Pagoda \n  Our values express our company culture. Learn more on our careers page. \n  Pagoda is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, color, religion, national origin, age, disability, veteran status, genetic data, or other legally protected status.", "cleaned_desc": " Partner with Engineering to optimize data quality; \n Cultivate data-informed decision making culture at the company and constantly research and adopt the most recent best practices in growth analytics. \n \n What We're Looking For \n \n Experience with data querying language (e.g. SQL), scripting languages (e.g. Python), data visualization (e.g. Tableau, Looker), dashboarding and data pipeline tools; \n Experience in growth optimization for B2B2C businesses and finding growth opportunities through data analytics; \n Experience with quantifying experience of developers or other technical audience; \n Strong data storytelling skills and ability to explain complex insights in a succinct way; \n Experience working with a distributed team, with strong written and verbal communication skills \n Bachelor's Degree in Computer Science, Applied Mathematics, Physics, Engineering, Statistics or related field is a must ", "techs": ["sql", "python", "tableau", "looker"]}, "1fc7d3870da1ba09": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["tensorflow", "pytorch", "python", "scala", "java", "lightning", "mosaic ml"]}, "fa2e2981f552e982": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml"]}, "f60df5de35a1b95a": {"terms": ["data science"], "salary_min": 85000.0, "salary_max": 118000.0, "title": "Pricing Analyst (Federal/GovCon)", "company": "Sparksoft", "desc": "Financial Analyst - Pricing & Project Control \n Job Details \n Full-time \n Description \n Location \u2013 Remote / ** Hybrid if local to Columbia, MD** \n Sparksoft Corporation is seeking a self-driven, deadline oriented, and numbers focused individual to join our finance team! This position will become an integrated part of the finance organization and support critical functions within the organization. This is a great opportunity for the right candidate to gain exposure to/across many corporate and project financial activities including but not limited to: \n Pricing Development:  Develop price proposals for new opportunities by collaborating with internal stakeholders, external partners, and the Sparksoft leadership team. Support proposal development cradle-to-grave \n Project Financial Control:  Analyze and maintain the financial health of Sparksoft program(s) by collecting and monitoring financial data, assessing risk, and recommending action / mitigation plans to management. \n Responsibilities: \n \n Candidate should have interest in financial analysis, pricing, and/or financial data modeling \n Collaborate with Project Management Teams in the development, review, and updates of project and program budgets, forecasts, and estimate-at-completion (EAC) and associated reporting and analysis \n Responsible for monitoring and reviewing monthly project expenditures for accuracy and consistency. \n Support subcontractor/vendor cost management lifecycle, including setting up Purchase Requests, Purchase Orders, and tracking subcontractor/vendor invoicing, payments, and funding variances \n Perform Analyses and prepare client status reports, integrated program reviews, and/or ad-hoc financial requests from clients, internal management, and other stakeholders \n Ensure adequate funding availability by maintaining accurate records of expenditures, directing preparation of expenditure projections, and submitting timely requests for additional funding to the government when applicable \n Create price proposals with internal stakeholders while maintaining a competitive price to win target. \n Candidate should be comfortable with making iterative changes to the budget as the proposal develops \n Review Request for Proposal documentation and maintain compliance \n Candidate should be comfortable performing in a deadline driven environment \n Perform competitor analysis on similar products and services \n Assess, understand, and communicate business risk \n Create compliant business proposal submission documents \n \n Requirements \n Required Skills: \n \n Proficient in Excel and comfortable with all other Microsoft Office applications \n Attention to detail \n Strong communication and interpersonal skills \n Interest in financial analysis and numbers driven \n Self-motivated analytical thinker \n Customer Service experience / mentality \n Overtime hours required, on occasion/as needed \n \n Education: \n \n Qualified individuals will have 5+ years of experience working in Pricing/Project Control \n Experience working in a customer service and/or deadline driven environment is a plus \n Associates, Bachelors, OR equivalent work experience accepted \n \n Sparksoft is a certified Capability Maturity Model Integration (CMMI) SVC and DEV Level 3, ISO 9001:2015, ISO 27001:2013, Small Disadvantaged Business (SDB), Women-Owned Small Business (WOSB), and Small, Women-owned, Minority-owned (SWaM), and MBE/DBE/SBE consulting firm. With our focused mission \u201cto ignite innovation, inspire transformation, and implement digital solutions for a healthier nation\u201d, we specialize in 6 specific digital health services: Test Automation, Cloud Services, DevOps Delivery, Cyber Security, Data Science, and Human-Centered Design. Since 2004, our exceptionally skilled people, proven leadership, and optimized processes all work together relentlessly to continuously push for more efficient solutions. \n Sparksoft is an Affirmative Action/Equal Opportunity Employer and does not discriminate against any applicant for employment or employee because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or any other characteristic prohibited under Federal, State, or local laws. \n Job Type: Full-time \n Pay: $85,000.00 - $118,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee discount \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Tuition reimbursement \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n Overtime \n \n Application Question(s): \n \n List some examples of proposals you have done pricing for, including revenue/value and agency/customer: \n \n Experience: \n \n federal RFP/Proposal Pricing: 3 years (Preferred) \n Government contractor/Federal industry financial: 3 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "1bc1a2cedd34ae70": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["llms", "fms", "apis", "sdks", "python", "scala", "java", "nlp", "speech", "computer vision", "recommendation systems", "deep neural networks"]}, "b671c1125f7e73b2": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["python", "scala", "java"]}, "e1357d1260e17ba2": {"terms": ["data science"], "salary_min": 112143.984, "salary_max": 141999.28, "title": "Data Scientist, Growth", "company": "NEAR", "desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Pagoda Data Science team is looking for a Data Scientist to optimize developer growth and performance marketing. \n  What You'll Be Doing \n \n Define and assess metrics to inform key conclusions in growth optimization; \n Apply statistical models on large datasets to understand trends in developer behavior and influence growth and marketing strategy; \n Develop attribution models, and generate actionable insights into performance of marketing channels and other distribution channels; \n Collaborate closely with Pagoda's Marketing, Product and Developer Experience teams to help identify key drivers of developer growth and engagement; \n Partner with Engineering to optimize data quality; \n Cultivate data-informed decision making culture at the company and constantly research and adopt the most recent best practices in growth analytics. \n \n What We're Looking For \n \n Experience with data querying language (e.g. SQL), scripting languages (e.g. Python), data visualization (e.g. Tableau, Looker), dashboarding and data pipeline tools; \n Experience in growth optimization for B2B2C businesses and finding growth opportunities through data analytics; \n Experience with quantifying experience of developers or other technical audience; \n Strong data storytelling skills and ability to explain complex insights in a succinct way; \n Experience working with a distributed team, with strong written and verbal communication skills \n Bachelor's Degree in Computer Science, Applied Mathematics, Physics, Engineering, Statistics or related field is a must \n \n We'd Love If You Have \n \n Experience working with DataBricks and BigQuery technologies; \n Experience with custom events with Google Analytics; \n Familiarity with crypto or blockchain technologies; \n Familiarity with HTML and JS; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like \n \n Internal Recruiter Call (30 to 45 minutes) \n Meet with the Hiring Manager (30-45 minutes) \n Technical Interviews (3 x 60 minutes) \n Pagoda Values Interview (30 to 45 minutes) \n Meet & Greet with Chief Product Officer (30 minutes) \n \n Compensation  \n The base salary range for this role is $144,500 - $170,000, which represents the salary range applicable to US locations only. This does not include bonus, incentives, or benefits. \n  The actual base pay within the range is dependent upon many factors, including: leveling, relevant skills, and work location. If you are based outside of the US, we there are other geographic considerations that may impact your final compensation. Your recruiter can share more about the compensation and benefits applicable to your preferred location during the hiring process. \n \n \n  Benefits & Perks \n \n Flexible Annual Leave / PTO with an encouraged 20 day per year minimum \n Paid Holiday Week: the last week of the year \n Paid Wellness Week: the first week of July \n $2,000 Yearly Continued Education Reimbursement \n $2,000 Home Office Setup Reimbursement \n Co-working Space Reimbursement \n Company Retreats (2023 in Spain!) & Team Offsites \n Mental Health Support and access to licensed therapists through Spill, 100% paid by Pagoda \n \n Our Values at Pagoda \n  Our values express our company culture. Learn more on our careers page. \n  Pagoda is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, color, religion, national origin, age, disability, veteran status, genetic data, or other legally protected status.", "cleaned_desc": " Partner with Engineering to optimize data quality; \n Cultivate data-informed decision making culture at the company and constantly research and adopt the most recent best practices in growth analytics. \n \n What We're Looking For \n \n Experience with data querying language (e.g. SQL), scripting languages (e.g. Python), data visualization (e.g. Tableau, Looker), dashboarding and data pipeline tools; \n Experience in growth optimization for B2B2C businesses and finding growth opportunities through data analytics; \n Experience with quantifying experience of developers or other technical audience; \n Strong data storytelling skills and ability to explain complex insights in a succinct way; \n Experience working with a distributed team, with strong written and verbal communication skills \n Bachelor's Degree in Computer Science, Applied Mathematics, Physics, Engineering, Statistics or related field is a must ", "techs": ["sql", "python", "tableau", "looker"]}, "9043da2d0ed3e416": {"terms": ["data science"], "salary_min": 38567.0, "salary_max": 95993.0, "title": "Help Desk Analyst - Remote", "company": "ICF", "desc": "*We are open to supporting 100% remote work anywhere within the continental US.*\n   \n \n \n \n \n  ICF\u2019s Digital Modernization Division is a rapidly growing, entrepreneurial, technology driven department. We are seeking a motivated Help Desk Analyst to support a portfolio of Salesforce projects with our federal customer.\n   \n \n \n \n \n  The Work\n   \n \n \n \n    The Help Desk Analyst will work directly with customers to troubleshoot application issues, provide guidance on how to utilize the system, collaborate with ICF\u2019s technology team to resolve issues identified and document new requirements when needed.\n   \n \n \n \n \n \n  Responsibilities:\n    \n \n \n \n \n \n       Document, troubleshoot and resolve customer requests via phone, email, ticketing system\n      \n \n \n       Must be able to critically analyze, triage and resolve incidents, problems and requests\n      \n \n \n       Must be able to understand technical end user problems and provide clear and timely resolutions\n      \n \n \n       Build and utilize decision trees to evaluate and elevate issues to internal teams\n      \n \n \n \n \n \n \n \n \n       Update knowledge base to ensure procedures and known fixes are up-to-date\n      \n \n \n       Ensure SLA\u2019s are met\n      \n \n \n       Work with operations teams to prepare for releases and create scripts/documentation for customer support\n      \n \n \n       Gather and supply feedback from customers in a useable format to product teams\n      \n \n \n       Report incidents and problems to appropriate teams and communicate effectively through product management to the customer\n      \n \n \n \n \n \n \n \n \n       Assess system and product metrics on a routine basis and product reports for management\n      \n \n \n       Provide training and demos related to new processes or application features\n      \n \n \n \n \n \n  Basic Qualifications:\n    \n \n \n \n \n \n \n \n       1+ year experience working in a customer orientated service role as a service/help desk engineer\n      \n \n \n       US Citizenship is required (required by the federal government for this position)\n      \n \n \n       Must be able to obtain Public Trust clearance\n      \n \n \n       MUST RESIDE IN THE United States (U.S.) and the work MUST BE PERFORMED in the United States (U.S.), as this work is for a federal contract and laws do apply.\n      \n \n \n \n \n \n \n \n  Preferred qualifications:\n    \n \n \n \n \n \n       Bachelors or Associate degree, preferred in engineering or IT related field\n      \n \n \n       Experience building and managing dashboards, a plus\n      \n \n \n       Experience with Salesforce is a plus\n      \n \n \n       Must be able to manage work across multiple projects, concurrently\n      \n \n \n \n \n \n \n \n \n       Excellent communication skills\n      \n \n \n       Track record of working across multiple teams to resolve issues\n      \n \n \n       Able to prioritize work to meet deadlines\n      \n \n \n       Adaptable, dependable and independent\n      \n \n \n \n \n \n   Working at ICF\n  \n  ICF is a global advisory and technology services provider, but we\u2019re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.\n  \n \n   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our \n   \n   EEO & AA policy\n   .\n  \n \n \n   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email \n   \n   icfcareercenter@icf.com\n    and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: \n   \n   Know Your Rights\n    and \n   \n   Pay Transparency Statement.\n   \n \n \n \n  Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:\n   $38,567.00 - $95,993.00\n   Nationwide Remote Office (US99)", "cleaned_desc": "", "techs": ""}, "4977831790024af0": {"terms": ["data science", "machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n \n   \n   \n xjbwGgD0Dw", "cleaned_desc": "", "techs": ""}, "a8111c728cf15581": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml"]}, "3b85afeb05d59ed4": {"terms": ["data science", "data analyst", "machine learning engineer"], "salary_min": 102795.78, "salary_max": 130162.36, "title": "Senior Data Analyst", "company": "Digital Hands", "desc": "#GetThereFirst \n  Digital Hands is an innovative Managed Security Service Provider (MSSP) with a mission to protect customer data and make technology available, productive and secure with the strongest talent in the cyber industry. Members of the Digital Hands Team work with leading technologies and protect a dynamic set of enterprise-class customers including best-known brands in the hospitality, financial, manufacturing and communications industries. Digital Hands employees enjoy competitive compensation and benefits, training opportunities, personal skills development, and opportunities for professional advancement across the organization. \n  Digital Hands is comprised of innovators leading from the front, fueled by a desire to achieve, test new boundaries, and a determination to do whatever it takes to get there first every time. Ideal candidates believe in the mission and vision of the company and have a genuine love for what they do. At Digital Hands, we take ownership, obsess over our promises, anticipate our customers' needs. and get ahead of every threat so that our customers can focus on their business with the peace of mind that only comes from knowing their cyberworld is secure. \n \n \n Remote locations for this position include Florida, Texas, South Carolina, North Carolina, Tennessee, and Georgia. \n \n \n \n  POSITION SUMMARY: \n  Reporting directly to the CTO, you'll serve as our Senior Data Analyst, a key player in converting complex cybersecurity and business data into actionable insights. Utilizing advanced statistical and machine learning techniques, you'll design ETL workflows and collaborate with engineers and analysts to uphold data quality. You'll manage cloud-based SQL and NoSQL databases, ensuring optimal performance and reliability while managing our data lakes. \n  Your role is multifaceted, from refining data architecture aligned with business objectives to deploying cloud-based ML solutions. During security incidents, your real-time data analysis is mission-critical. You'll also spearhead the curation of real-time dashboards on our BI platform, making complex data understandable for both tech teams and C-suite executives. If you're a data expert with a strategic focus, your expertise could transform our organization. \n \n \n  DUTIES AND RESPONSIBILITIES: \n \n Leverage advanced statistical and machine learning techniques to turn complex cybersecurity and business data into actionable insights for threat detection, risk assessment, and strategic business initiatives. \n Design and implement robust ETL workflows to sanitize, transform, and enrich raw data, enabling seamless integration with automation platforms and reporting systems. \n Collaborate with software engineers and cybersecurity analysts to establish precise data requirements and uphold stringent data quality standards. \n Administer and optimize cloud-based SQL and NoSQL databases, guaranteeing fast query performance, high availability, and high reliability.  \n Interface internal and client-facing applications with our centralized data lake, safeguarding data flow integrity and seamless integration.  \n Partner with security analysts and DevOps to align data architecture strategies with overarching business and operational objectives.  \n Utilize cloud-based machine learning tools, with an emphasis on Large Language Models (LLMs), to develop and deploy production-grade use cases.  \n Swiftly address urgent, time-sensitive data analysis requests to provide crucial information during security incidents or for actionable business insights.  \n Lead the creation and upkeep of a scalable data architecture to optimize analytics capabilities and secure data integrations. \n Administer the SiSense BI platform and equip report designers through focused training.  \n Spearhead the creation of real-time dashboards and reports via SiSense to transparently communicate data-driven insights to both technical and executive audiences. \n \n \n \n  EDUCATION AND WORK EXPERIENCE: \n \n Bachelor's degree in a technical discipline (preferably computer science) and 5+ years of relevant professional experience. \n Experience building ETL data pipelines. \n Experience with data tools on Google Cloud and AWS. \n Hands on experience working with cloud-based data warehouse tools.  \n Proficiency in programming languages (Python, Javascript, SQL, etc) required.  \n Expertise using Python data analysis tools like Jupyter notebooks, Pandas, NumPy, etc. \n Experience administering SQL and NoSQL databases such as PostgreSQL, MongoDB, Elastic, etc.  \n Solid background in statistics and data modeling required.  \n Competency in gathering and documenting business requirements; collaborating with various departments across the organization. \n Excellent verbal and written communication skills and the ability to interact professionally with a diverse group, executives, managers, and subject matter experts. \n \n \n \n  Digital Hands is dedicated to a diverse and inclusive workplace and culture, and proud to be an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. \n  Digital Hands is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please contact us at  talentmanagement@digitalhands.com . \n  Digital Hands participates in the U.S. Government's E-Verify program to determine employment eligibility. In compliance with the federal government, all hired applicants will be required to verify identity and employment eligibility upon hire. To learn more about E-Verify, please visit  dhs.gov/e-verify . \n  By submitting your application, you agree that Digital Hands may collect, use, and process your information, which may include personal information and sensitive personal information, in connection with Digital Hands' recruitment activities. You may delete your application and/or unsubscribe from receiving notifications of career opportunities at Digital Hands at any time. For additional details on how Digital Hands uses and protects your personal information in the application process, including your rights under the California Privacy Rights Act (\"CPRA\"), click here to view our Privacy Notice.", "cleaned_desc": "  POSITION SUMMARY: \n  Reporting directly to the CTO, you'll serve as our Senior Data Analyst, a key player in converting complex cybersecurity and business data into actionable insights. Utilizing advanced statistical and machine learning techniques, you'll design ETL workflows and collaborate with engineers and analysts to uphold data quality. You'll manage cloud-based SQL and NoSQL databases, ensuring optimal performance and reliability while managing our data lakes. \n  Your role is multifaceted, from refining data architecture aligned with business objectives to deploying cloud-based ML solutions. During security incidents, your real-time data analysis is mission-critical. You'll also spearhead the curation of real-time dashboards on our BI platform, making complex data understandable for both tech teams and C-suite executives. If you're a data expert with a strategic focus, your expertise could transform our organization. \n \n \n  DUTIES AND RESPONSIBILITIES: \n \n Leverage advanced statistical and machine learning techniques to turn complex cybersecurity and business data into actionable insights for threat detection, risk assessment, and strategic business initiatives. \n Design and implement robust ETL workflows to sanitize, transform, and enrich raw data, enabling seamless integration with automation platforms and reporting systems.   Collaborate with software engineers and cybersecurity analysts to establish precise data requirements and uphold stringent data quality standards. \n Administer and optimize cloud-based SQL and NoSQL databases, guaranteeing fast query performance, high availability, and high reliability.  \n Interface internal and client-facing applications with our centralized data lake, safeguarding data flow integrity and seamless integration.  \n Partner with security analysts and DevOps to align data architecture strategies with overarching business and operational objectives.  \n Utilize cloud-based machine learning tools, with an emphasis on Large Language Models (LLMs), to develop and deploy production-grade use cases.  \n Swiftly address urgent, time-sensitive data analysis requests to provide crucial information during security incidents or for actionable business insights.  \n Lead the creation and upkeep of a scalable data architecture to optimize analytics capabilities and secure data integrations. \n Administer the SiSense BI platform and equip report designers through focused training.  \n Spearhead the creation of real-time dashboards and reports via SiSense to transparently communicate data-driven insights to both technical and executive audiences.   \n \n \n  EDUCATION AND WORK EXPERIENCE: \n \n Bachelor's degree in a technical discipline (preferably computer science) and 5+ years of relevant professional experience. \n Experience building ETL data pipelines. \n Experience with data tools on Google Cloud and AWS. \n Hands on experience working with cloud-based data warehouse tools.    Proficiency in programming languages (Python, Javascript, SQL, etc) required.  \n Expertise using Python data analysis tools like Jupyter notebooks, Pandas, NumPy, etc. \n Experience administering SQL and NoSQL databases such as PostgreSQL, MongoDB, Elastic, etc.  \n Solid background in statistics and data modeling required.  \n Competency in gathering and documenting business requirements; collaborating with various departments across the organization. \n Excellent verbal and written communication skills and the ability to interact professionally with a diverse group, executives, managers, and subject matter experts. \n \n \n ", "techs": ["senior data analyst", "advanced statistical techniques", "machine learning techniques", "etl workflows", "cloud-based sql", "nosql databases", "data lakes", "data architecture", "cloud-based ml solutions", "real-time dashboards", "bi platform", "threat detection", "risk assessment", "automation platforms", "reporting systems", "data flow integrity", "large language models (llms)", "sisense bi platform", "etl data pipelines", "google cloud", "aws", "cloud-based data warehouse tools", "programming languages (python", "javascript", "sql)", "python data analysis tools (jupyter notebooks", "pandas", "numpy)", "sql databases (postgresql)", "nosql databases (mongodb", "elastic)", "statistics", "data modeling", "gathering and documenting business requirements", "verbal and written communication skills."]}, "a6c931209f14b7de": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["apis", "sdks", "large-language models (llms)", "foundation models (fms)", "python", "scala", "java", "deep neural networks", "nlp", "speech", "computer vision", "recommendation systems", "neural network models", "api security", "observability", "cloud access control", "privacy best practices."]}, "f449f06edc03f810": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "deep neural networks", "nlp", "speech", "computer vision", "recommendation systems", "ai", "apis", "sdks", "distributed computing"]}, "2fd43a9919f25fae": {"terms": ["data science", "data analyst"], "salary_min": null, "salary_max": null, "title": "Senior Data Analyst", "company": "Naviguard", "desc": "Senior Data Analyst\n  \n \n  As a Senior Data Analyst you will be in a unique position to assist a growing business proactively plan, react to new developments, and implement improvements across multiple departments. Your work will involve constructing and examining large, complex data sets to identify key drivers impacting operations performance, business success, client satisfaction, and medical costs. You will lead data sourcing and compilation efforts and investigate business problems in several functional areas, resulting in final analyses ready for leadership teams to utilize and deploy. You will seek to always improve data integrity and reporting accuracy by identifying and resolving root-cause issues. You will lead research into ambiguous problems and potentially seek new/external data sources or construct data sets to help solve key business issues. You will analyze and interpret data from various sources, identify appropriate measurement methodologies, design reports, and work with technical, operational, and payment teams to drive performance. Your analyses will be used to create viable, real \u2013 world solutions in a complex and evolving health care landscape.\n  \n \n  Primary Responsibilities:\n  \n \n Conduct research and analyses aimed at improving overall performance and data integrity \n Collaborate on strategic initiatives to develop analytics that guide business actions \n Gather and document requirements from the client/business while focused on process improvement, workflow, benchmarking and/or evaluation of business processes \n QA/analysis of large data sets used for reporting and QA/analysis of subsequent deliverables for self and team \n Quickly develop subject matter expertise in new topics to ensure analytics output is accurate and complies with business rules/requirements/requests \n Predict emerging business needs and develop innovative data-driven solutions to evaluate and manage them \n Work with data warehouses, databases, database structures, data on a daily basis \n \n \n  Required Qualifications:\n  \n \n Bachelor\u2019s degree or equivalent work experience in Data Science, Computer Science, Engineering, Actuarial Science, Statistics, Business, Finance, Mathematics, Health Administration or related field \n Team-oriented, adaptable, accountable individual who can thrive in and contribute positively to a small, dynamic development team \n Proven problem-solving skills that generate demonstrable, meaningful, positive impacts; previous experience in analytics a plus \n Committed self-starter with proven ability to learn systems quickly and lead projects from concept to completion \n 3+ years of database/data warehouse or software development experience \n 3+ years Healthcare IT with strong understanding of industry \n Experienced in Agile/Scrum or similar system of prioritizing work on multiple complex assignments with iterative deliverables and contending deadlines \n Effective interpersonal, influence, collaboration and listening skills \n Demonstrated ability to communicate ideas clearly and concisely in writing and verbally to individuals and groups \n \n \n  Preferred Qualifications:\n  \n \n Master\u2019s degree in Math, Statistics, Data Science, Computer Science, Engineering, Actuarial Science, or a related field \n 7+ years working directly with healthcare claims data and/or claims adjudication systems/processes \n 7+ years of database/software development with superior command of SQL", "cleaned_desc": " Bachelor\u2019s degree or equivalent work experience in Data Science, Computer Science, Engineering, Actuarial Science, Statistics, Business, Finance, Mathematics, Health Administration or related field \n Team-oriented, adaptable, accountable individual who can thrive in and contribute positively to a small, dynamic development team \n Proven problem-solving skills that generate demonstrable, meaningful, positive impacts; previous experience in analytics a plus \n Committed self-starter with proven ability to learn systems quickly and lead projects from concept to completion \n 3+ years of database/data warehouse or software development experience \n 3+ years Healthcare IT with strong understanding of industry \n Experienced in Agile/Scrum or similar system of prioritizing work on multiple complex assignments with iterative deliverables and contending deadlines ", "techs": ["bachelor\u2019s degree", "data science", "computer science", "engineering", "actuarial science", "statistics", "business", "finance", "mathematics", "health administration", "team-oriented", "adaptable", "accountable", "individual", "small", "dynamic development team", "problem-solving skills", "analytics", "committed self-starter", "systems", "lead projects", "concept to completion", "database", "data warehouse", "software development", "healthcare it", "understanding of industry", "agile", "scrum", "prioritizing work", "multiple complex assignments", "iterative deliverables", "contending deadlines"]}, "1bd410b5b16ac1fd": {"terms": ["data science"], "salary_min": 109800.0, "salary_max": 170200.0, "title": "Data & BI Solutions Lead - Remote", "company": "The Infosoft Group", "desc": "Auto req ID:  22779    Title : Data & BI Solutions Lead - Remote    Job Function:  Digital    Location:  Remote   Company:  Harley-Davidson Financial Services    Full or Part-Time:  Full Time  \n \n Harley-Davidson Financial Services (HDFS), a wholly-owned subsidiary of Harley-Davidson, Inc., offers a wide range of financial products and services to motorcycle enthusiasts and Harley-Davidson dealerships. Products available to consumers include financing on motorcycles, MotorClothes, and parts and accessories; cycle insurance; and extended service plans for Harley-Davidson motorcycles. \n \n You'll play a pivotal role in helping us create the company we want to be. And for our employees and H-D community it's done through being fair, honest, positive and creative. This isn't just any company. And yours isn't just any career. It's part of your story. Ride with us and make it legendary. \n \n We maximize employee flexibility and well-being through a virtual mindset that supports our highly distributed, global workforce. We take an outcome-focused, people-centered approach to winning, including welcoming the best talent - wherever they may be. \n \n This remote role is not tightly linked to a physical location and provides flexibility in where, when and how you accomplish your work.Remote employees are expected to have a dedicated, quiet and distraction-free work space and an internet connection that's sufficient for completing their job remotely. \n \n \n \n     Job Summary\n    \n \n  The Lead Data Analyst supports the organization with consumer insight and analytics relative to global consumers and markets of Harley-Davidson products, services, and experience. The Lead Data Analyst will provide technical expertise to ensure the quality and accuracy of that data. They will then collect, design, and present it in ways that are helpful to the organization to make better decisions. This role is expected to lead larger ad hoc projects identified by company leadership. This role will also overe developers committed to delivery of the requirements of the business areas. The ideal candidate would have the following skill sets: \n \n \n A true team spirit who thrives on working as part of and leading enthusiastic and energetic teams, and inspiring others; demonstrating a collaborative approach \n Should be comfortable working on and leading multiple projects simultaneously \n Comfort working with ambiguity; strong communication and interpersonal skills \n A track record for achieving results, encouraging the inputs and ideas of others, and understanding the importance of active listening in the role. \n Global perspective and understanding, thinking across borders and cultures. \n Knowledge of data governance, data catalog and data quality profiling. \n \n \n \n \n \n    Job Responsibilities \n    \n \n \n \n Facilitate data consumption across business units by understanding the needs and publishing content to meet them.  \n Develop a deep understanding of a business area and the data required for decision and actions within that unit.  \n Translate from business data requirements into actionable data deliverables utilizing technical solutions. \n Lead the development of large-scale data science projects from the ground up, including: Frame data science problems; Identify clear lines of questioning; Extract, wrangle, and structure data from multiple source; Implement cutting edge classification, recommendation, simulation, sequence mining, and other models; Check your work against existing business knowledge; make decisions about project directions, conditions of success, and completion \n Create clear and concise presentations of project results including, high quality visualizations to present to leadership \n Proactively research industry trends, opportunities, and risks \n Partner and mentor other Data Analysts to produce clear, concise, and repeatable code that can be used by other members of the team without explanation. \n Provide quality assurance of imported data, working with quality assurance analysts if necessary. \n Commissioning and decommissioning of data sets. \n Processing confidential data and information according to guidelines. \n Managing and designing the reporting environment, including data sources, security, and metadata. \n Generating reports from single or multiple systems. \n Evaluating changes and updates to source production systems. \n Training end-users on new reports and dashboards. \n Providing technical expertise in data storage structures, data mining, and data cleansing. \n \n \n   Education Requirements \n \n \n A Bachelor's degree is preferred, preferably in Information Management, Computer Science, or a related field; An advanced degree in a related field is preferred. \n \n \n \n \n \n \n    Experience Requirements \n    \n \n \n \n Typically requires 8+ years of related experience \n Proven ability to integrate data from many sources, identifying yet unasked questions, and capitalizing on opportunities to advance business goals \n Expert level knowledge of .... Proven expertise in the use of either PowerBi (preferred) or Tableau. Knowledge of additional analytical software like Alteryx preferred but not required. Expertise with techniques and methodologies for analyzing large data sets \n Expert level knowledge of SQL and NoSql capabilities. Versed in interacting with relational and non-relational database solutions.  \n Demonstrated experience in handling large data sets. \n Understanding of addressing and metadata standards. \n High-level written and verbal communication skills. \n \n \n \n \n \n \n  Harley-Davidson is an equal opportunity employer that continues to build a culture of inclusion, belonging and equity through our commitment to attracting and retaining diverse talent from all backgrounds, without regard to race, color, religion, sex, sexual orientation, national origin, gender identity, age, disability, veteran status or any other characteristic protected by law. We believe in fairness and providing a level playing field for all. We foster a culture that thrives on diverse perspectives and contributions to ignite the creativity and innovation to fuel our business and enhance the employee and customer experience.   \n The pay range shown represents the national average pay range for this role. Your pay may be more or less than the stated range and is dependent on your geographic location and level of experience. \n \n We offer an inclusive compensation package for all full-time salaried employees including, but not limited to, annual bonus programs, health insurance benefits, a 401k program, onsite fitness centers and employee stores, employee discounts on products and accessories, and more. Learn more about Harley-Davidson . \n    Applicants must be currently authorized to work in the United States. \n   Direct Reports:Yes   Travel Required:0 - 10%   Pay Range:$109,800-170,200   Visa Sponsorship:This position is not eligible for visa sponsorship   Relocation:This position is not eligible for relocation assistance \n  #LI-REMOTE #LI-HDFS \n \n \n  Harley-Davidson is committed to recruiting and hiring qualified individuals in all job titles without regard to race, color, sex, age, national origin, religion, disability, genetic information, sexual orientation, gender identity, veteran status, or other classes protected by applicable law. Equal Opportunity Employer.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Harley-Davidson Motor Company \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full or Part Time\n   \n \n \n \n   Required Experience\n   \n \n   8+ years", "cleaned_desc": " \n \n \n \n    Job Responsibilities \n    \n \n \n \n Facilitate data consumption across business units by understanding the needs and publishing content to meet them.  \n Develop a deep understanding of a business area and the data required for decision and actions within that unit.  \n Translate from business data requirements into actionable data deliverables utilizing technical solutions. \n Lead the development of large-scale data science projects from the ground up, including: Frame data science problems; Identify clear lines of questioning; Extract, wrangle, and structure data from multiple source; Implement cutting edge classification, recommendation, simulation, sequence mining, and other models; Check your work against existing business knowledge; make decisions about project directions, conditions of success, and completion \n Create clear and concise presentations of project results including, high quality visualizations to present to leadership \n Proactively research industry trends, opportunities, and risks \n Partner and mentor other Data Analysts to produce clear, concise, and repeatable code that can be used by other members of the team without explanation. \n Provide quality assurance of imported data, working with quality assurance analysts if necessary. \n Commissioning and decommissioning of data sets. \n Processing confidential data and information according to guidelines. \n Managing and designing the reporting environment, including data sources, security, and metadata. \n Generating reports from single or multiple systems. \n Evaluating changes and updates to source production systems. \n Training end-users on new reports and dashboards. \n Providing technical expertise in data storage structures, data mining, and data cleansing. \n   \n   Education Requirements \n \n \n A Bachelor's degree is preferred, preferably in Information Management, Computer Science, or a related field; An advanced degree in a related field is preferred. \n \n \n \n \n \n \n    Experience Requirements \n    \n \n \n \n Typically requires 8+ years of related experience \n Proven ability to integrate data from many sources, identifying yet unasked questions, and capitalizing on opportunities to advance business goals \n Expert level knowledge of .... Proven expertise in the use of either PowerBi (preferred) or Tableau. Knowledge of additional analytical software like Alteryx preferred but not required. Expertise with techniques and methodologies for analyzing large data sets \n Expert level knowledge of SQL and NoSql capabilities. Versed in interacting with relational and non-relational database solutions.  \n Demonstrated experience in handling large data sets. \n Understanding of addressing and metadata standards. \n High-level written and verbal communication skills. \n \n ", "techs": ["powerbi", "tableau", "alteryx", "sql", "nosql"]}, "a00e5b2b58891033": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "nlp", "speech", "computer vision", "recommendation systems"]}, "389bc6c5f390259e": {"terms": ["data science"], "salary_min": 65000.0, "salary_max": 105000.0, "title": "Sr. Healthcare Analyst (MedInsight)", "company": "The Infosoft Group", "desc": "Description\n  \n  Company Overview: \n  Leading with our core values of Quality, Integrity, and Opportunity, MedInsight is one of the healthcare industry's most trusted solutions for healthcare intelligence. Our company purpose is to empower easy, data-driven decision-making on important healthcare questions. Through our products, education, and services, MedInsight is making an impact on healthcare by helping to drive better outcomes for patients while reducing waste. Over 300 leading healthcare organizations have come to rely on MedInsight analytic solutions for healthcare cost and care management. \n  MedInsight is a subsidiary of Milliman; a global, employee-owned consultancy providing actuarial consulting, retirement funding and healthcare financing, enterprise risk management and regulatory compliance, data analytics and business transformation as well as a range of other consulting and technology solutions. \n  Position Summary: \n  The MedInsight team develops an industry-leading data warehouse and analytics suite for major healthcare companies including insurers, providers, and public entities. We are a tech healthcare data company transforming how the industry understands and consumes healthcare data. We are accelerating and looking for a Sr. Healthcare Analyst to join our team. This position focuses on healthcare data profiling and analysis tasks that require quantitative reasoning skills, knowledge of tools and technologies used in data analysis, and an interest in the US healthcare industry. This person's primary duty will be to work with our consultants and healthcare analytics team by researching healthcare analytics inquiries, onboarding new data sources and supporting daily operations of the MedInsight business intelligence solution.  \n Primary Responsibilities: \n \n Work both independently and in a cross-functional team environment. \n Write complex SQL queries to support analytics needs. \n Develop, maintain, and support processes for data feasibility tests, data quality checks, data validations, and sense-checking of results. \n Support documentation of analysis results and methodologies. \n Develop technical specifications for analyses of healthcare data. \n Perform ad hoc analyses of healthcare data using SQL Server, Azure Databricks, and other tools. \n Work independently on assigned tasks, i.e., plan, organize, problem solve and meet established deadlines. \n Manage multiple priorities in a fast-paced environment. \n Prioritize work under time pressure. Follow-through and exceptional attention to detail on all project tasks are essential. \n Follows QRM Guidelines and MedInsight policies \n Acts in accordance with MedInsight core values \n \n Preferred Skills and Experience: \n  Candidates must be team players with excellent interpersonal skills. They must also have some experience/ familiarity with data analysis using large data sets. Experience with healthcare datasets is a significant plus.  \n Education/experience:  \n \n Bachelor's degree in data analytics or data science \n Education/ experience with quantitative analysis, statistics, and/or data science.  \n \n Skills:  \n \n Experience coding in SQL or similar language  \n Strong analytical ability  \n Healthcare data knowledge \n Microsoft Excel  \n Effective oral and written communication \n Punctual and reliable  \n Team player with positive and energetic attitude  \n \n Compensation and Location: \n \n The salary range is $65,000 to $105,000, depending on relevant factors, including but not limited to education, work experience, certifications, etc. This role can be located remotely within the U.S. \n \n What makes this a great opportunity? \n \n Join an innovative, high growth company with a solid industry track record \n Bring your expertise and ideas to directly impact and help build the next generation of MedInsight products and solutions \n Enjoy significant visibility in your work and be recognized for your wins \n Work for a company that values your wellbeing and professional growth, offering a flexible work environment, generous benefits package, and investment in the development of your career \n \n Benefits: \n \n Medical & Dental \n Vision \n Group Term Life Insurance \n Supplemental Life Insurance (Including Spouse/Domestic Partner & Dependent) \n AD&D \n Short & Long-Term Disability \n Paid Parental Leave \n FSA (Health Care Flexible Spending Account or Dependent Care Flexible Spending Account) \n Adoption Benefit \n Identity Theft Protection \n Retirement Program: 401(k) \n Paid Time Off (PTO) \n Access to free training through Milliman's Learning & Development department \n \n All qualified applicants will receive consideration for employment, without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.   \n \n \n \n \n Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities \n \n \n \n  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c) \n \n  Milliman is an equal opportunity employer\n  \n  Our company, with the full support of our Chief Executive Officer, is fully committed to the maximum utilization of all human resources and the goals of Equal Employment Opportunity and Affirmative Action. We recruit, hire, train, and promote, and consider qualified applicants for employment, in all job titles without regard to age, ancestry, citizenship status, color, creed, familial status, genetic information, marital status, national origin, political ideology, race, religion, sex, sexual orientation, gender identity, status as an individual with a disability, or veteran status, including qualified disabled veterans, Armed Forces service medal veterans, recently separated veterans, and active duty wartime or campaign badge veterans; and shall not discriminate against any individual, or any other characteristic protected by law.\n  \n  Reasonable Accommodation Notice\n  \n  Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Milliman, Inc \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   Open", "cleaned_desc": "Description\n  \n  Company Overview: \n  Leading with our core values of Quality, Integrity, and Opportunity, MedInsight is one of the healthcare industry's most trusted solutions for healthcare intelligence. Our company purpose is to empower easy, data-driven decision-making on important healthcare questions. Through our products, education, and services, MedInsight is making an impact on healthcare by helping to drive better outcomes for patients while reducing waste. Over 300 leading healthcare organizations have come to rely on MedInsight analytic solutions for healthcare cost and care management. \n  MedInsight is a subsidiary of Milliman; a global, employee-owned consultancy providing actuarial consulting, retirement funding and healthcare financing, enterprise risk management and regulatory compliance, data analytics and business transformation as well as a range of other consulting and technology solutions. \n  Position Summary: \n  The MedInsight team develops an industry-leading data warehouse and analytics suite for major healthcare companies including insurers, providers, and public entities. We are a tech healthcare data company transforming how the industry understands and consumes healthcare data. We are accelerating and looking for a Sr. Healthcare Analyst to join our team. This position focuses on healthcare data profiling and analysis tasks that require quantitative reasoning skills, knowledge of tools and technologies used in data analysis, and an interest in the US healthcare industry. This person's primary duty will be to work with our consultants and healthcare analytics team by researching healthcare analytics inquiries, onboarding new data sources and supporting daily operations of the MedInsight business intelligence solution.  \n Primary Responsibilities: \n \n Work both independently and in a cross-functional team environment. \n Write complex SQL queries to support analytics needs. \n Develop, maintain, and support processes for data feasibility tests, data quality checks, data validations, and sense-checking of results. \n Support documentation of analysis results and methodologies. \n Develop technical specifications for analyses of healthcare data. \n Perform ad hoc analyses of healthcare data using SQL Server, Azure Databricks, and other tools. \n Work independently on assigned tasks, i.e., plan, organize, problem solve and meet established deadlines. \n Manage multiple priorities in a fast-paced environment. \n Prioritize work under time pressure. Follow-through and exceptional attention to detail on all project tasks are essential. \n Follows QRM Guidelines and MedInsight policies \n Acts in accordance with MedInsight core values \n \n Preferred Skills and Experience: \n  Candidates must be team players with excellent interpersonal skills. They must also have some experience/ familiarity with data analysis using large data sets. Experience with healthcare datasets is a significant plus.  \n Education/experience:  \n ", "techs": ["sql server", "azure databricks"]}, "ced28472f52c7c87": {"terms": ["data science", "mlops"], "salary_min": 113755.664, "salary_max": 144040.02, "title": "Delivery Method DevOps Manager", "company": "Infor", "desc": "General information \n       \n \n \n \n \n \n \n        Country \n        \n United States  \n \n \n \n        City \n        \n Remote Location  \n \n \n \n        Department \n        \n Consulting Services  \n \n \n \n        Job ID \n        \n 36465  \n \n \n \n \n \n \n \n \n \n       Description & Requirements \n       \n \n \n \n \n \n \n In this role, your core responsibility is the design, configuration and maintenance of Azure DevOps (ADO) and Microsoft Project (MPP), as well as potentially additional software identified to manage customer implementation projects. You will have significant experience using Azure DevOps to manage and execute projects as a task management tool using Boards, Dashboards and Queries. Infor is currently not leveraging Pipelines, Releases and Repositories functionality, therefore experience with CI/CD Pipelines is not required. You will work closely with the VP, Delivery Method, as well as key members of the Delivery Method team, the Global Professional Services team, Global Project Management Office (PMO) and other key members of the \u201cTime to Value\u201d strategic initiative. Your focus will be on designing and evolving \u201cbest practice\u201d functionality within DevOps and related platforms to be used by our customer implementation project teams. \n \n  A Day in The Life Typically Includes: \n \n \n  Configuring Azure DevOps Process templates & Projects \n  Adjusting Azure DevOps Projects by using Queries, Wiki, Dashboards, custom fields, automated rules \n  Copying Azure DevOps Projects between the Organizations \n  Managing Azure DevOps and Microsoft Project Integration \n  Researching new techniques to apply updates in mass within a project as well as across projects and organizations \n  Ongoing updates to Infor\u2019s global industry project templates to implement continuous improvements \n  Enforcing global design standards across our DevOps projects \n  Research and guide the company on advanced functional capabilities offered by DevOps, Microsoft Project or other software in the marketplace, such as Microsoft Power Automate \n \n \n \n  Basic Qualifications:\n         \n \n  Azure DevOps - configuring process templates, projects, boards and dashboards; working with Queries; Creating Wiki Pages; Automation Rules; copying Azure DevOps projects between Organizations, Dashboards between Organizations and Process Templates between Organizations \n  Power Automate - Understanding Power Automate Concepts and Azure DevOps relevant application, Creating Power Automate Scripts \n  Power Shell - Installation & running Power Shell Scripts, Configuration and Editing of Power Shell Scripts \n  Microsoft Project - Understanding of Microsoft Project advanced features such as Custom Fields and Formulas, Understanding application of VBA scripting in Microsoft Projects, Knowledge of Integration between Microsoft Project and Azure DevOps, Configuration and adjustment of Microsoft Project integration files and components \n  ERP Project Management, Consulting in Services, Delivery Methodologies, such as Waterfall and Agile \n \n  Preferred Qualifications:\n         \n \n \n  Azure DevOps: Test Plans, Pipelines, Repos, Additional software that integrates with DevOps (e.g. 7pace Timetracker) \n  Leadership: Lead by example and demonstrate a positive mental attitude. Demonstrate standard leadership traits: strategic, forward thinking, problem solving, and implementation thought leadership. \n  Execution: Results oriented, and proactively leverages the organization in an efficient manner to overcome and resolve obstacles. \n  Thought Leader: Subject matter expert and thought leader in methodology. Keep up to date with new developments, best practices, industry trends and new innovations for all related methodology knowledge areas. \n  Analytical Skills: ability to understand, analyze and document requirements for enriching Infor Industry templates \n \n \n \n  Location: US Remote (St. Paul, MN, Alpharetta, GA, Dallas, TX,)\n         \n \n \n \n \n \n \n \n \n         About Infor\n         \n \n \n  Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.\n         \n \n          For more information visit www.infor.com\n         \n \n \n \n \n \n \n \n         Our Values\n         \n \n \n  At Infor, we strive for an environment that is founded on a business philosophy called Principle Based Management\u2122 (PBM\u2122) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization. Increasing diversity is important to reflect our markets, customers, partners, and communities we serve in now and in the future.\n         \n \n \n  We have a relentless commitment to a culture based on PBM. Informed by the principles that allow a free and open society to flourish, PBM\u2122 prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.\n         \n \n \n  Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law.\n          \n \n \n \n \n         At Infor we value your privacy that\u2019s why we created a policy that you can read here.\n         \n \n \n \n \n \n \n \n \n         This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf", "cleaned_desc": "  Managing Azure DevOps and Microsoft Project Integration \n  Researching new techniques to apply updates in mass within a project as well as across projects and organizations \n  Ongoing updates to Infor\u2019s global industry project templates to implement continuous improvements \n  Enforcing global design standards across our DevOps projects \n  Research and guide the company on advanced functional capabilities offered by DevOps, Microsoft Project or other software in the marketplace, such as Microsoft Power Automate \n \n \n \n  Basic Qualifications:\n         \n \n  Azure DevOps - configuring process templates, projects, boards and dashboards; working with Queries; Creating Wiki Pages; Automation Rules; copying Azure DevOps projects between Organizations, Dashboards between Organizations and Process Templates between Organizations \n  Power Automate - Understanding Power Automate Concepts and Azure DevOps relevant application, Creating Power Automate Scripts \n  Power Shell - Installation & running Power Shell Scripts, Configuration and Editing of Power Shell Scripts \n  Microsoft Project - Understanding of Microsoft Project advanced features such as Custom Fields and Formulas, Understanding application of VBA scripting in Microsoft Projects, Knowledge of Integration between Microsoft Project and Azure DevOps, Configuration and adjustment of Microsoft Project integration files and components \n  ERP Project Management, Consulting in Services, Delivery Methodologies, such as Waterfall and Agile \n \n  Preferred Qualifications:\n         \n \n \n  Azure DevOps: Test Plans, Pipelines, Repos, Additional software that integrates with DevOps (e.g. 7pace Timetracker) \n  Leadership: Lead by example and demonstrate a positive mental attitude. Demonstrate standard leadership traits: strategic, forward thinking, problem solving, and implementation thought leadership. \n  Execution: Results oriented, and proactively leverages the organization in an efficient manner to overcome and resolve obstacles. \n  Thought Leader: Subject matter expert and thought leader in methodology. Keep up to date with new developments, best practices, industry trends and new innovations for all related methodology knowledge areas. \n  Analytical Skills: ability to understand, analyze and document requirements for enriching Infor Industry templates \n ", "techs": ["azure devops", "microsoft project", "infor industry templates", "microsoft power automate", "power shell", "vba scripting", "erp project management", "waterfall", "agile", "test plans", "pipelines", "repos", "7pace timetracker", "leadership", "execution", "thought leader", "analytical skills"]}, "dea487aedc410f16": {"terms": ["data science", "data engineer", "machine learning engineer", "mlops"], "salary_min": 96824.2, "salary_max": 122601.016, "title": "Sr. Data Engineer - Remote", "company": "The Infosoft Group", "desc": "Chamberlain Group is a global leader in access solutions with top brands, such asLiftMasterand Chamberlain,found in millions of homes, businesses, and communities worldwide. \n \n  As a leader in the Smart Home industry, we boast one of the largest IoT install bases, with innovative products consisting of cameras, locks, card readers, garage door openers, gates and more, all powered by ourmyQdigital ecosystem. \n \n  This role is responsible for providing technical expertise and leadership to design and deliver end-to-end dataengineering solutions to support advanced analytics capabilities and drive innovation and decision-making  across Chamberlain. \n \n  Essential Duties and Responsibilities \n \n  Build and maintain real-time and batch data pipelines across the advanced analytics platform. \n  Design, develop and orchestrate highly robust and scalable ETL pipelines. \n  Design and implement Dimensional and NoSQL data modelling as per the business requirements. \n  Develop highly optimal codebase and perform Spark optimizations for Big Data use cases. \n  Design, develop and deploy optimal monitoring and testing strategy for the data products. \n  Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions. \n  Collaborate with data scientists to prepare data for model development and production. \n  Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports. \n  Collaborate with data architects on the enhancement of Chamberlain's enterprise data architecture and platforms. \n  Provide leadership to third-party contractors. \n  Comply with health and safety guidelines and rules. \n  Protect CGI's reputation by keeping information confidential. \n  Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies. \n \n \n  Minimum Qualifications \n  Education/Certifications: \n \n  Bachelor's degree in computer science or related quantitative field of study \n \n  Experience: \n \n  4+ years of professional experience \n \n  Knowledge, Skills, and Abilities: \n \n  Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic. \n  Proficient in Spark or Databricks, Cloud Data Engineering Services preferably Azure, Streaming frameworks like Event Hubs or Kafka. \n  Proficient in Microsoft Office. \n  Familiarity with modern Machine Learning Operationalization techniques. \n  Agile methodologies. \n  Familiarity with Data visualization tools, such as Qlik or Power BI. \n \n \n  Preferred Qualifications \n  Education/Certifications: \n \n  Master's degree in computer science or related quantitative field of study \n \n  Experience: \n \n  4+ years of professional experience \n  2+ years of professional experience delivering engineering for advanced analytics or data science solutions \n \n  Knowledge, Skills, and Abilities: \n \n  Agile methodologies \n  Experience with IoT Data Architecture. \n  Machine Learning Operationalization (MLOps) proficiency. \n  REST API design and development. \n  Proficiency with streaming design patterns. \n \n \n  The pay range for this position is $103,300.00 to $177.475.00; base pay offered may vary depending on a number of factors including, but not limited to, the position offered, location, education, training, and/or experience. In addition to base pay, also offered is a comprehensive benefits package and 401k contribution (all benefits are subject to eligibility requirements). \n \n  This position is eligible for participation in a short-term incentive plan subject to the terms of the applicable plans and policies. \n \n  #LI-Remote \n \n  Chamberlain Group wants all of its employees to succeed and encourages people of all backgrounds to apply. We're proud to be an Equal Opportunity Employer, and you'll be considered for this role regardless of race, color, religion, sex, national origin, age, sexual orientation, ancestry; marital, disabled or veteran status. We're committed to fostering an environment where people of all lived experiences feel welcome. \n \n  Persons with disabilities who anticipate needing accommodations for any part of the application process may contact, in confidence . \n  NOTE: Staffing agencies, headhunters, recruiters, and/or placement agencies, please do not contact our hiring managers directly. \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   The Chamberlain Group \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   4+ years", "cleaned_desc": "Chamberlain Group is a global leader in access solutions with top brands, such asLiftMasterand Chamberlain,found in millions of homes, businesses, and communities worldwide. \n \n  As a leader in the Smart Home industry, we boast one of the largest IoT install bases, with innovative products consisting of cameras, locks, card readers, garage door openers, gates and more, all powered by ourmyQdigital ecosystem. \n \n  This role is responsible for providing technical expertise and leadership to design and deliver end-to-end dataengineering solutions to support advanced analytics capabilities and drive innovation and decision-making  across Chamberlain. \n \n  Essential Duties and Responsibilities \n \n  Build and maintain real-time and batch data pipelines across the advanced analytics platform. \n  Design, develop and orchestrate highly robust and scalable ETL pipelines. \n  Design and implement Dimensional and NoSQL data modelling as per the business requirements. \n  Develop highly optimal codebase and perform Spark optimizations for Big Data use cases. \n  Design, develop and deploy optimal monitoring and testing strategy for the data products. \n  Collaborate with stakeholders and advanced analytics business partners to understand business needs and translate requirements into scalable data engineering solutions. \n  Collaborate with data scientists to prepare data for model development and production. \n  Collaborate with data visualization and reporting application developers to ensure the sustainability of production applications and reports. \n  Collaborate with data architects on the enhancement of Chamberlain's enterprise data architecture and platforms. \n  Provide leadership to third-party contractors. \n  Comply with health and safety guidelines and rules. \n  Protect CGI's reputation by keeping information confidential. \n  Maintain professional and technical knowledge by attending educational workshops, professional publications, establishing personal networks, and participating in professional societies. \n \n    Minimum Qualifications \n  Education/Certifications: \n \n  Bachelor's degree in computer science or related quantitative field of study \n \n  Experience: \n \n  4+ years of professional experience \n \n  Knowledge, Skills, and Abilities: \n \n  Natural sense of urgency, teamwork, and collaboration reflected in daily work ethic. \n  Proficient in Spark or Databricks, Cloud Data Engineering Services preferably Azure, Streaming frameworks like Event Hubs or Kafka. \n  Proficient in Microsoft Office. \n  Familiarity with modern Machine Learning Operationalization techniques. \n  Agile methodologies. \n  Familiarity with Data visualization tools, such as Qlik or Power BI. \n \n \n  Preferred Qualifications \n  Education/Certifications: \n \n  Master's degree in computer science or related quantitative field of study ", "techs": ["liftmaster", "chamberlain", "myq digital ecosystem", "spark", "databricks", "azure", "event hubs", "kafka", "microsoft office", "qlik", "power bi"]}, "28b87566f9cf1249": {"terms": ["data science", "data analyst"], "salary_min": null, "salary_max": null, "title": "QA Analyst/Senior Data Analyst", "company": "The Infosoft Group", "desc": "QA Analyst -(Senior Data Analyst)  \n \n  The Esntial eCommerce Analytics Team at Cox Automotive is looking for top talent who are excited to reimagine the way people buy and sell cars online and who want to advance the way it's done through the power of data and advanced analytics.\n  \n  The QA Analyst (Senior Data Analyst) is part of the Esntial eCommerce Analytics team, you will collaborate with key business stakeholders, SMEs across the organization such as Sales, Business Operations and Product Marketing to gather requirements, build, test and deliver Data needs for Advanced Analytics tools and self-service reporting to advance the goals of the eCommerce business.\n  \n  Part QA Analyst and part Developer, you will use your curiosity and collaboration expertise to define outcome-based requirements that enable quick insights and clear direction on optimization opportunities. You will use your estimation and time management skills to focus your stakeholders on what matters the most to be able to deliver iterative solutions in a fast-paced environment. All the while, your capabilities will be used across a growing client base and to drive eCommerce outcomes in a highly visible part of the organization.\n  \n \n Responsibilities:  \n \n \n Process Structured and Unstructured Data into Curated Metrics:   \n \n \n \n Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks.  \n Understands and enforces appropriate data master management techniques.  Leverages SQL expertise to curate key performance indicators and metrics to drive business decisioning. \n  \n \n \n Data Validation and Quality   \n \n \n \n Ensures data quality and implements tools and frameworks for automating the identification of data quality issues through proactive monitoring, anomaly detection and alerting.  \n Work with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings.  \n Execute test plans and perform QA to assure the functionality and integrity of the data models.  Partner with the Business Intelligence team to ensure all data requirements are met and data sources have been optimized for reporting and dashboard performance. \n  \n \n \n Product Development and Maintenance   \n \n \n \n Implements and optimizes data solutions in enterprise data warehouses and big data repositories.  \n Installs, maintains, monitors, and supports business intelligence, distributed computation, and big data analytics tools.  \n Provides ongoing support, monitoring, and maintenance of deployed products.  \n Actively works with less experienced data engineers providing technical guidance and oversight.  \n Actively participates in the engineering community, staying up to date on new data technologies and best practices and shares insights with others in the organization.  Participate in agile scrum routines and deliver in an agile scrum framework. \n  \n \n \n Candidates from the Eastern and Central Time Zones preferred.  \n \n \n Remote role  \n \n \n Up to 5% travel required.  \n \n \n Required Qualifications:   \n \n \n \n Bachelor's degree in a related discipline and 4 years experience in a related field. The right candidate could also have a different combination, such as a master's degree and 2 years experience; a Ph.D. and up to 1 year of experience; or 8 years experience in a related field.  \n Must have hands-on experience in building data pipelines and data warehouse ETL tools.  \n Must be comfortable navigating large, complex, and possibly disparate data sets and transforming and/or joining from those sets using SQL.  \n Must have expertise in creating business requirements documents and experienced in testing data processes and creating data validation documents.  \n Must have experience in building dashboards and monitoring reports in tools like Tableau using blended data sources.  \n Must have hands on experience at least one data warehouse software (Google Cloud Platform, AWS Redshift or Snowflake).  \n Experience in performing root cause analysis, unit testing, defect management and managing escalation communications.  \n Ability to quickly adapt to a changing environment and adjust to rapid changes in deadlines and priorities.  \n Experience working to deliver within an agile scrum framework.  \n Excellent written and verbal communication skills are a must.  Must be able to work Eastern Time Zone hours. \n  \n \n \n Preferred Qualifications:   \n \n \n \n An ideal candidate will have a combination of Analytics consultancy experience or worked in an Analytics and Business Intelligence consulting capacity within a large organization.  \n Experience with Python and ability to write programs for ETL purposes.  \n Hands on experience navigating large, complex, and possibly disparate data sets using SQL within a data warehouse is preferred.  \n Experience with AWS data engineering tools or Google Cloud Platform a plus.  \n Working experience using business intelligence tools (PowerBI, Tableau, Domo) is preferred.  \n Strong analytical mindset and ability to clearly communicate solution options and tradeoffs preferred.  \n Self-directed, driven, and enthusiastic. Has the ability to work in an ambiguous and fast paced start up environment.  \n Desired to have Automotive experience and understanding of Dealer and Consumer Metrics and Analytics.  Strong teambuilding skills with demonstrated problem-solving abilities. \n  \n \n \n About Cox Automotive \n \n  At Cox Automotive, people of every background are driven by their passion for mobility, innovation and community. We transform the way the world buys, sells, owns and uses cars, accelerating the industry with global powerhouse brands like Autotrader, Kelley Blue Book, Manheim and more. What's more, we do it all with an emphasis on employee growth and happiness. Drive your future forward and join Cox Automotive today!\n  \n \n About Cox \n \n  Cox empowers employees to build a better future and has been doing so for over 120 years. With exciting investments and innovations across transportation, communications, cleantech and healthcare, our family of businesses - which includes Cox Automotive and Cox Communications - is forging a better future for us all. Ready to make your mark? Join us today!\n  \n  Benefits of working at Cox may include health care insurance (medical, dental, vision), retirement planning (401(k)), and paid days off (sick leave, parental leave, flexible vacation/wellness days, and/or PTO). For more details on what benefits you may be offered, visit our benefits page .\n  \n  Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law. Cox provides reasonable accommodations when requested by a qualified applicant or employee with disability, unless such accommodations would cause an undue hardship.\n  \n  Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Cox \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   4+ years\n   \n \n \n \n   Security Clearance Note\n   \n \n   Data Intelligence & Science", "cleaned_desc": "QA Analyst -(Senior Data Analyst)  \n \n  The Esntial eCommerce Analytics Team at Cox Automotive is looking for top talent who are excited to reimagine the way people buy and sell cars online and who want to advance the way it's done through the power of data and advanced analytics.\n  \n  The QA Analyst (Senior Data Analyst) is part of the Esntial eCommerce Analytics team, you will collaborate with key business stakeholders, SMEs across the organization such as Sales, Business Operations and Product Marketing to gather requirements, build, test and deliver Data needs for Advanced Analytics tools and self-service reporting to advance the goals of the eCommerce business.\n  \n  Part QA Analyst and part Developer, you will use your curiosity and collaboration expertise to define outcome-based requirements that enable quick insights and clear direction on optimization opportunities. You will use your estimation and time management skills to focus your stakeholders on what matters the most to be able to deliver iterative solutions in a fast-paced environment. All the while, your capabilities will be used across a growing client base and to drive eCommerce outcomes in a highly visible part of the organization.\n  \n \n Responsibilities:  \n \n \n Process Structured and Unstructured Data into Curated Metrics:   \n \n \n \n Gathers and processes raw, structured, semi-structured, and unstructured data using batch and real-time data processing frameworks.  \n Understands and enforces appropriate data master management techniques.  Leverages SQL expertise to curate key performance indicators and metrics to drive business decisioning. \n  \n \n \n Data Validation and Quality   \n \n \n \n Ensures data quality and implements tools and frameworks for automating the identification of data quality issues through proactive monitoring, anomaly detection and alerting.  \n Work with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings.  \n Execute test plans and perform QA to assure the functionality and integrity of the data models.  Partner with the Business Intelligence team to ensure all data requirements are met and data sources have been optimized for reporting and dashboard performance. \n  \n   \n Product Development and Maintenance   \n \n \n \n Implements and optimizes data solutions in enterprise data warehouses and big data repositories.  \n Installs, maintains, monitors, and supports business intelligence, distributed computation, and big data analytics tools.  \n Provides ongoing support, monitoring, and maintenance of deployed products.  \n Actively works with less experienced data engineers providing technical guidance and oversight.  \n Actively participates in the engineering community, staying up to date on new data technologies and best practices and shares insights with others in the organization.  Participate in agile scrum routines and deliver in an agile scrum framework. \n  \n \n \n Candidates from the Eastern and Central Time Zones preferred.  \n \n \n Remote role  \n \n \n Up to 5% travel required.  \n \n \n Required Qualifications:   \n \n \n \n Bachelor's degree in a related discipline and 4 years experience in a related field. The right candidate could also have a different combination, such as a master's degree and 2 years experience; a Ph.D. and up to 1 year of experience; or 8 years experience in a related field.  \n Must have hands-on experience in building data pipelines and data warehouse ETL tools.  \n Must be comfortable navigating large, complex, and possibly disparate data sets and transforming and/or joining from those sets using SQL.  \n Must have expertise in creating business requirements documents and experienced in testing data processes and creating data validation documents.    Must have experience in building dashboards and monitoring reports in tools like Tableau using blended data sources.  \n Must have hands on experience at least one data warehouse software (Google Cloud Platform, AWS Redshift or Snowflake).  \n Experience in performing root cause analysis, unit testing, defect management and managing escalation communications.  \n Ability to quickly adapt to a changing environment and adjust to rapid changes in deadlines and priorities.  \n Experience working to deliver within an agile scrum framework.  \n Excellent written and verbal communication skills are a must.  Must be able to work Eastern Time Zone hours. \n  \n \n \n Preferred Qualifications:   \n \n \n \n An ideal candidate will have a combination of Analytics consultancy experience or worked in an Analytics and Business Intelligence consulting capacity within a large organization.  \n Experience with Python and ability to write programs for ETL purposes.  \n Hands on experience navigating large, complex, and possibly disparate data sets using SQL within a data warehouse is preferred.  \n Experience with AWS data engineering tools or Google Cloud Platform a plus.  \n Working experience using business intelligence tools (PowerBI, Tableau, Domo) is preferred.  \n Strong analytical mindset and ability to clearly communicate solution options and tradeoffs preferred.  \n Self-directed, driven, and enthusiastic. Has the ability to work in an ambiguous and fast paced start up environment.  \n Desired to have Automotive experience and understanding of Dealer and Consumer Metrics and Analytics.  Strong teambuilding skills with demonstrated problem-solving abilities. \n  \n \n \n About Cox Automotive \n \n  At Cox Automotive, people of every background are driven by their passion for mobility, innovation and community. We transform the way the world buys, sells, owns and uses cars, accelerating the industry with global powerhouse brands like Autotrader, Kelley Blue Book, Manheim and more. What's more, we do it all with an emphasis on employee growth and happiness. Drive your future forward and join Cox Automotive today!\n  \n \n About Cox ", "techs": ["qa analyst", "senior data analyst", "esntial ecommerce analytics team", "sales", "business operations", "product marketing", "sql", "batch processing", "real-time data processing", "data master management", "data validation", "data quality", "anomaly detection", "alerting", "test plans", "qa", "business intelligence team", "data models", "product development", "enterprise data warehouses", "big data repositories", "data engineers", "data technologies", "agile scrum", "eastern time zones", "central time zones", "remote role", "travel", "data pipelines", "data warehouse etl tools", "large complex data sets", "data transformation", "data blending", "tableau", "data warehouse software", "google cloud platform", "aws redshift", "snowflake", "root cause analysis", "unit testing", "defect management", "agile framework", "written communication skills", "verbal communication skills", "analytics consultancy experience", "analytics and business intelligence consulting", "python", "etl", "aws data engineering tools", "google cloud platform", "business intelligence tools", "powerbi", "domo", "analytical mindset", "automotive experience", "dealer metrics", "consumer metrics", "cox automotive"]}, "839e71d25e9566b8": {"terms": ["data science"], "salary_min": 110000.0, "salary_max": 120000.0, "title": "Data Architect", "company": "Alphident Technologies Inc", "desc": "Title : Data Architect \n Work location : Remote with occasional visit to Washington DC \n Term : Fulltime \n Job Responsibilities : \n 1  Provide Data Mapping and Integration, including but not limited to: \n a.  Identify source systems and data repositories for migration. \n b.  Develop a mapping strategy to migrate data from legacy systems to the new environment. \n c.  Collaborate with developers and database administrators to ensure seamless data integration. \n 2  Provide Conceptual and Logical Data Modeling, including but not limited to: \n a.  Design and develop conceptual and logical data models based on business requirements. \n b.  Define entities, attributes, relationships, and constraints to represent the data structure accurately. \n c.  Collaborate with stakeholders to validate and refine the data models. \n 3  Provide Physical Data Modeling, including but not limited to: \n a.  Develop an ontology for current and future states of enterprise data. \n b.  Translate the logical data models into physical data models suitable for implementation. \n c.  Define database schemas, tables, columns, indexes, and constraints. \n d.  Optimize data models for performance, scalability, and data integrity. \n 4  Provide Data Standardization and Normalization, including but not limited to: \n a.  Analyze existing data structures and propose data standardization and normalization techniques. \n b.  Identify redundant or inconsistent data elements and develop strategies for data cleansing and consolidation. \n c.  Ensure data models comply with industry best practices and data governance policies. \n d.  Define solution blueprints for implementing Master Data Management for applicable data domains based on high-level functional, technical, and non-functional requirements. \n 5  Provide Data Security and Privacy, including but not limited to: \n a.  Collaborate with agency and departmental security and compliance teams to define data security and privacy requirements. \n b.  Implement appropriate security measures, such as encryption, access controls, and data masking, including designing and maintaining data leak prevention appliances. \n c.  Incorporate Federal laws and privacy regulations, such as the Confidential Information Protection and Statistical Efficiency Act (CIPSEA) into the data models and processes. \n 6  Provide Data Quality Assurance, including but not limited to: \n a.  Develop data quality rules and measures to ensure accuracy, completeness, and consistency of data. \n b.  Implement data validation processes and conduct data profiling and cleansing activities. \n c.  Collaborate with data analysts and business users to validate data quality and resolve issues. \n d.  Develop Key Performance Indicators (KPIs) to regularly assess data quality processes. \n 7  Provide Data Governance and Documentation, including but not limited to: \n a.  Establish data governance frameworks and processes to ensure the uniformity, accuracy, stewardship, semantic consistency, and accountability for agency data assets. \n b.  Create and maintain data dictionaries, data flow diagrams, and metadata repositories. \n c.  Document data modeling standards, guidelines, and best practices for future reference. \n Requirements : \n \n Shall at a minimum have a Bachelor\u2019s degree in Computer Science, Computer Engineering, Data Science, Information Technology Management or Engineering, or other comparable Certifications or experience in the data domain. \n Shall have a minimum of five (5) years of experience in the data-related roles, including database administration, data engineering, data ETL (Extract, Transform and Load), or data analysis. \n Shall possess strong data modeling and database design experience (at least 3 years), including experience in architecting database designs for enterprise applications in the Cloud. \n Shall possess in-depth knowledge of various database management systems (DBMS), both relational databases (e.g., MSQL, PostgreSQL) and NoSQL databases (e.g., MongoDB, Cassandra). \n Shall possess expertise in large-scale, high-performance enterprise data-driven system development under complex heterogeneous environments such as AWS, Azure, or GCP. \n \n Job Type: Full-time \n Pay: $110,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Health insurance \n Paid time off \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n What is your expected annual salary? \n What is your work status: US Citizen, Permanent resident, H1B, OPT? \n Are you fine for Occasional Onsite visits to client's Place in Washington DC? \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Database administration: 5 years (Required) \n ETL: 5 years (Required) \n Data modeling: 3 years (Required) \n \n Work Location: Remote", "cleaned_desc": " b.  Translate the logical data models into physical data models suitable for implementation. \n c.  Define database schemas, tables, columns, indexes, and constraints. \n d.  Optimize data models for performance, scalability, and data integrity. \n 4  Provide Data Standardization and Normalization, including but not limited to: \n a.  Analyze existing data structures and propose data standardization and normalization techniques. \n b.  Identify redundant or inconsistent data elements and develop strategies for data cleansing and consolidation. \n c.  Ensure data models comply with industry best practices and data governance policies. \n d.  Define solution blueprints for implementing Master Data Management for applicable data domains based on high-level functional, technical, and non-functional requirements. \n 5  Provide Data Security and Privacy, including but not limited to: \n a.  Collaborate with agency and departmental security and compliance teams to define data security and privacy requirements. \n b.  Implement appropriate security measures, such as encryption, access controls, and data masking, including designing and maintaining data leak prevention appliances. \n c.  Incorporate Federal laws and privacy regulations, such as the Confidential Information Protection and Statistical Efficiency Act (CIPSEA) into the data models and processes. \n 6  Provide Data Quality Assurance, including but not limited to: \n a.  Develop data quality rules and measures to ensure accuracy, completeness, and consistency of data.   b.  Implement data validation processes and conduct data profiling and cleansing activities. \n c.  Collaborate with data analysts and business users to validate data quality and resolve issues. \n d.  Develop Key Performance Indicators (KPIs) to regularly assess data quality processes. \n 7  Provide Data Governance and Documentation, including but not limited to: \n a.  Establish data governance frameworks and processes to ensure the uniformity, accuracy, stewardship, semantic consistency, and accountability for agency data assets. \n b.  Create and maintain data dictionaries, data flow diagrams, and metadata repositories. \n c.  Document data modeling standards, guidelines, and best practices for future reference. \n Requirements : \n \n Shall at a minimum have a Bachelor\u2019s degree in Computer Science, Computer Engineering, Data Science, Information Technology Management or Engineering, or other comparable Certifications or experience in the data domain. \n Shall have a minimum of five (5) years of experience in the data-related roles, including database administration, data engineering, data ETL (Extract, Transform and Load), or data analysis. \n Shall possess strong data modeling and database design experience (at least 3 years), including experience in architecting database designs for enterprise applications in the Cloud. \n Shall possess in-depth knowledge of various database management systems (DBMS), both relational databases (e.g., MSQL, PostgreSQL) and NoSQL databases (e.g., MongoDB, Cassandra). \n Shall possess expertise in large-scale, high-performance enterprise data-driven system development under complex heterogeneous environments such as AWS, Azure, or GCP. ", "techs": ["translate the logical data models into physical data models suitable for implementation,define database schemas", "tables", "columns", "indexes", "and constraints,optimize data models for performance", "scalability", "and data integrity,provide data standardization and normalization,analyze existing data structures and propose data standardization and normalization techniques,identify redundant or inconsistent data elements and develop strategies for data cleansing and consolidation,ensure data models comply with industry best practices and data governance policies,define solution blueprints for implementing master data management for applicable data domains based on high-level functional", "technical", "and non-functional requirements,provide data security and privacy,collaborate with agency and departmental security and compliance teams to define data security and privacy requirements,implement appropriate security measures", "such as encryption", "access controls", "and data masking", "including designing and maintaining data leak prevention appliances,incorporate federal laws and privacy regulations", "such as the confidential information protection and statistical efficiency act (cipsea) into the data models and processes,provide data quality assurance,develop data quality rules and measures to ensure accuracy", "completeness", "and consistency of data,implement data validation processes and conduct data profiling and cleansing activities,collaborate with data analysts and business users to validate data quality and resolve issues,develop key performance indicators (kpis) to regularly assess data quality processes,provide data governance and documentation,establish data governance frameworks and processes to ensure the uniformity", "accuracy", "stewardship", "semantic consistency", "and accountability for agency data assets,create and maintain data dictionaries", "data flow diagrams", "and metadata repositories,document data modeling standards", "guidelines", "and best practices for future reference,bachelor\u2019s degree in computer science", "computer engineering", "data science", "information technology management or engineering", "or other comparable certifications or experience in the data domain,minimum of five (5) years of experience in data-related roles", "including database administration", "data engineering", "data etl (extract", "transform and load)", "or data analysis,strong data modeling and database design experience (at least 3 years)", "including experience in architecting database designs for enterprise applications in the cloud,in-depth knowledge of various database management systems (dbms)", "both relational databases (e.g.", "msql", "postgresql) and nosql databases (e.g.", "mongodb", "cassandra),expertise in large-scale", "high-performance enterprise data-driven system development under complex heterogeneous environments such as aws", "azure", "or gcp."]}, "8899d78b7b4a00ac": {"terms": ["data science", "machine learning engineer"], "salary_min": 49693.383, "salary_max": 62922.9, "title": "Senior Data Scientist (Remote) (Optimization Modeling & Process Mining)", "company": "Mercy", "desc": "We're a Little Different \n \n  Our mission is clear. We bring to life a healing ministry through our compassionate care and exceptional service. \n  \n  At Mercy, we believe in careers that match the unique gifts of unique individuals - careers that not only make the most of your skills and talents, but also your heart. Join us and discover why Modern Healthcare Magazine named us in its \"Top 100 Places to Work.\"\n  \n \n Overview: Senior Data Scientist (Optimization Modeling & Process Mining) \n \n \n Position can be Remote (work from home) \n \n \n \n Please note that as of the posting date of this job announcement, Mercy is unable to offer immigration sponsorship or visa assistance for this position. We encourage all eligible candidates, including U.S. citizens, permanent residents, and those with existing work authorization, to apply. \n \n  Highly Skilled and Advanced Data Science Team looking for a \n  Senior Data Scientist  with \n  process mining  and \n  modeling  experience for new projects aimed to reduce healthcare bottlenecks, improve patient movement and quality, reduce length of stay, and improve patient outcomes.\n  \n  Mercy is seeking a Senior Data Scientist to work within a team of other advanced professional data scientists, engineers, and application developers in the generation, extraction, and compilation of data to perform creative, high-quality, state-of-the-art analyses and evaluations that produce insights, support decision-making, and drive impact within a leading and transforming healthcare organization. This position will support Mercy's efforts to deliver on the vision of personalized, predictive, and proactive care. The candidate should demonstrate expertise with data extraction, management, analysis with data analytics tools, be able deliver outputs on a timeline, and lead others in the completion of related work. The candidate should be able to effectively document, develop, and communicate project plans and analytic findings with a variety of technical/non-technical stakeholders.\n  \n \n Qualifications: \n \n \n  Experience:  At least 4 years of experience in a similar role in academia or industry or PhD + 2 years in a similar role in academia or industry \n  Required Education:  Graduate degree in Public Health, Health Care Research, Epidemiology, Statistics, Data Science, Health Policy, Economic, Finance, Simulation/Simulation-Based Optimization, or related field. \n  Other:  \n Have a strong knowledge of electronic medical record data, clinical data, claims data, or financial data. \n  Experience with SQL \n  Intermediate/Advanced development skills with at least one scripting language (Python, R, etc.)  \n Ability to quickly learn new analytic tools and packages \n  Ability to develop and apply computational algorithms and statistical methods to healthcare data (including, but not limited to data from electronic medical record, financial management, human resource, quality and supply chain) \n  Ability to develop and deploy healthcare-relevant predictive and prescriptive models. \n  Experience with Cloud-based data and AI solutions, especially in implementation and operationalization of Machine Learning based solutions. \n  Hands-on experience with a broad range of deep learning tools (e.g., TensorFlow, Spark, Theano, PyTorch, Scikit-learn, Keras, Caffe, Nvidia Digits) and collaboration environments (e.g. Jupyter notebooks, PyCharm, gitlab, github) \n  Excellent problem-solving skills \n  Strong organizational skills, an orientation toward detail, and collaboration oriented. \n  Present complex data (qualitative and quantitative) in a clear, concise, and compelling manner to both technical and non-technical audiences to inspire action. \n \n \n  We Offer Great Benefits: \n \n  Day-one comprehensive health, vision and dental coverage, PTO, tuition reimbursement and employer-matched retirement funds are just a few of the great benefits offered to eligible co-workers, including those working 32 hours or more per pay period!\n  \n \n We're bringing to life a healing ministry through compassionate care. \n \n  At Mercy, our supportive community will be behind you every step of your day, especially the tough ones. You will have opportunities to pioneer new models of care and transform the health care experience through advanced technology and innovative procedures. We're expanding to help our communities grow. Join us and be a part of it all.\n  \n \n What Makes You a Good Match for Mercy?  \n \n  Compassion and professionalism go hand-in-hand with us. Having a positive outlook and a strong sense of advocacy is in perfect step with our mission and vision. We're also collaborative and unafraid to do a little extra to deliver excellent care - that's just part of our commitment. If that sounds like a good fit for you, we encourage you to apply.", "cleaned_desc": " \n \n \n Please note that as of the posting date of this job announcement, Mercy is unable to offer immigration sponsorship or visa assistance for this position. We encourage all eligible candidates, including U.S. citizens, permanent residents, and those with existing work authorization, to apply. \n \n  Highly Skilled and Advanced Data Science Team looking for a \n  Senior Data Scientist  with \n  process mining  and \n  modeling  experience for new projects aimed to reduce healthcare bottlenecks, improve patient movement and quality, reduce length of stay, and improve patient outcomes.\n  \n  Mercy is seeking a Senior Data Scientist to work within a team of other advanced professional data scientists, engineers, and application developers in the generation, extraction, and compilation of data to perform creative, high-quality, state-of-the-art analyses and evaluations that produce insights, support decision-making, and drive impact within a leading and transforming healthcare organization. This position will support Mercy's efforts to deliver on the vision of personalized, predictive, and proactive care. The candidate should demonstrate expertise with data extraction, management, analysis with data analytics tools, be able deliver outputs on a timeline, and lead others in the completion of related work. The candidate should be able to effectively document, develop, and communicate project plans and analytic findings with a variety of technical/non-technical stakeholders.   \n \n Qualifications: \n \n \n  Experience:  At least 4 years of experience in a similar role in academia or industry or PhD + 2 years in a similar role in academia or industry \n  Required Education:  Graduate degree in Public Health, Health Care Research, Epidemiology, Statistics, Data Science, Health Policy, Economic, Finance, Simulation/Simulation-Based Optimization, or related field. \n  Other:  \n Have a strong knowledge of electronic medical record data, clinical data, claims data, or financial data. \n  Experience with SQL \n  Intermediate/Advanced development skills with at least one scripting language (Python, R, etc.)    Ability to quickly learn new analytic tools and packages \n  Ability to develop and apply computational algorithms and statistical methods to healthcare data (including, but not limited to data from electronic medical record, financial management, human resource, quality and supply chain) \n  Ability to develop and deploy healthcare-relevant predictive and prescriptive models. \n  Experience with Cloud-based data and AI solutions, especially in implementation and operationalization of Machine Learning based solutions. \n  Hands-on experience with a broad range of deep learning tools (e.g., TensorFlow, Spark, Theano, PyTorch, Scikit-learn, Keras, Caffe, Nvidia Digits) and collaboration environments (e.g. Jupyter notebooks, PyCharm, gitlab, github) \n  Excellent problem-solving skills \n  Strong organizational skills, an orientation toward detail, and collaboration oriented. \n  Present complex data (qualitative and quantitative) in a clear, concise, and compelling manner to both technical and non-technical audiences to inspire action. \n \n \n  We Offer Great Benefits: ", "techs": ["process mining", "modeling", "data extraction", "data management", "data analytics tools", "sql", "python", "r", "computational algorithms", "statistical methods", "predictive models", "prescriptive models", "cloud-based data", "ai solutions", "machine learning", "tensorflow", "spark", "theano", "pytorch", "scikit-learn", "keras", "caffe", "nvidia digits", "jupyter notebooks", "pycharm", "gitlab", "github"]}, "5243dbc87ac5131a": {"terms": ["data science", "data engineer", "machine learning engineer"], "salary_min": 104000.0, "salary_max": 156000.0, "title": "Lead Data Engineer - Remote", "company": "The Infosoft Group", "desc": "Auto req ID : 22661    Title : Lead Data Engineer - Remote    Job Function : Digital    Location : Remote   Company:  Harley-Davidson Motor Company    Full or Part-Time:  Full Time     \n  At Harley-Davidson, we are building more than machines. It's our passion and commitment to continue the evolution of this storied brand, and heighten the desirability of the Harley-Davidson experience. To keep building our legend and leading our industry through innovation, evolution, and emotion we need the best and brightest talent. We stand for the timeless pursuit of adventure. Freedom for the soul. Are you ready to join us? \n \n We maximize employee flexibility and well-being through a virtual mindset that supports our highly distributed, global workforce. We take an outcome-focused, people-centered approach to winning, including welcoming the best talent - wherever they may be. \n \n This remote role is not tightly linked to a physical location and provides flexibility in where, when and how you accomplish your work.Remote employees are expected to have a dedicated, quiet and distraction-free work space and an internet connection that's sufficient for completing their job remotely. \n   Job Summary \n \n The Lead Data Engineer will work closely with various cross-functional teams and operations to develop and deliver tools or data structures that provide actionable recommendations to business partners. Successful candidates will exhibit technical acumen and business savvy, with a passion for making an impact by enabling both producers and consumers of data insight to work smarter. \n \n Job Responsibilities \n \n \n Implement data orchestration pipelines, data sourcing, cleansing, and augmentation and quality control processes \n Deploy machine learning models in production \n Work with a diverse set of clients across domains and industries \n Mentoring data engineers to further their personal and professional growth \n Leading other engineering staff on projects \n Developing team's talent by providing direction and facilitating technical architectural discussions \n Translating business needs into solutions \n Contribution to overall solution, integration, and enterprise architectures \n \n \n Job Requirements \n \n \n BS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience \n 8+ years of experience working on large scale, full lifecycle data implementation projects \n 2+ years professional development experience with some of the AWS/Azure/GCP stack: Databricks, EventHub, Docker, Azure Data Warehouse \n A deep knowledge of performant SQL and understanding of relational database technology \n Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures) \n Expertise in developing ETL/ELT workflows with one or more of the following; Pythone, Scala, Java \n Deployment of data pipelines in the Cloud in at least AWS, Azure, or GCP \n A deep understanding of relational and warehousing database technology, working with at least one of the major databases platforms (Oracle, SQLServer, Teradata, MySQL, Postgres) \n Experience working with Streaming data \n A solid foundation in data structures, algorithms, and OO Design with fundamentally strong programming skills \n Proven success working in and promoting a rapidly changing, collaborative, and iterative product development environment \n Strong interpersonal and analytical skills \n Intellectual curiosity and an ability to execute projects \n An understanding of \"big picture\" business requirements that drive architecture and design decisions \n DevOps and DataOps skills including \"infrastructure as code\" systems like CloudFormation or Terraform \n Data system performance tuning \n Implementation of predictive analytics and machine learning models (MLlib, scikit-learn, etc) \n \n \n Harley-Davidson is an equal opportunity employer that continues to build a culture of inclusion, belonging and equity through our commitment to attracting and retaining diverse talent from all backgrounds, without regard to race, color, religion, sex, sexual orientation, national origin, gender identity, age, disability, veteran status or any other characteristic protected by law. We believe in fairness and providing a level playing field for all. We foster a culture that thrives on diverse perspectives and contributions to ignite the creativity and innovation to fuel our business and enhance the employee and customer experience. \n \n The pay range shown represents the national average pay range for this role. Your pay may be more or less than the stated range and is dependent on your geographic location and level of experience. \n \n We offer an inclusive compensation package for all full-time salaried employees including, but not limited to, annual bonus programs, health insurance benefits, a 401k program, onsite fitness centers and employee stores, employee discounts on products and accessories, and more. Learn more about Harley-Davidson . \n  Applicants must be currently authorized to work in the United States. \n \n     Direct Reports:No   Travel Required:0 - 10%   Pay Range:$104,000- $156,000   Visa Sponsorship:This position is not eligible for visa sponsorship   Relocation:This position is not eligible for relocation assistance \n  #LI-REMOTE \n \n  Harley-Davidson is committed to recruiting and hiring qualified individuals in all job titles without regard to race, color, sex, age, national origin, religion, disability, genetic information, sexual orientation, gender identity, veteran status, or other classes protected by applicable law. Equal Opportunity Employer.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Harley-Davidson Motor Company \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full or Part Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   8+ years", "cleaned_desc": " Contribution to overall solution, integration, and enterprise architectures \n \n \n Job Requirements \n \n \n BS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience \n 8+ years of experience working on large scale, full lifecycle data implementation projects \n 2+ years professional development experience with some of the AWS/Azure/GCP stack: Databricks, EventHub, Docker, Azure Data Warehouse \n A deep knowledge of performant SQL and understanding of relational database technology \n Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures) \n Expertise in developing ETL/ELT workflows with one or more of the following; Pythone, Scala, Java \n Deployment of data pipelines in the Cloud in at least AWS, Azure, or GCP \n A deep understanding of relational and warehousing database technology, working with at least one of the major databases platforms (Oracle, SQLServer, Teradata, MySQL, Postgres) \n Experience working with Streaming data \n A solid foundation in data structures, algorithms, and OO Design with fundamentally strong programming skills \n Proven success working in and promoting a rapidly changing, collaborative, and iterative product development environment \n Strong interpersonal and analytical skills \n Intellectual curiosity and an ability to execute projects \n An understanding of \"big picture\" business requirements that drive architecture and design decisions ", "techs": ["contribution to overall solution", "integration", "enterprise architectures", "databricks", "eventhub", "docker", "azure data warehouse", "performant sql", "relational database technology", "rdbms experience", "etl/elt workflows", "python", "scala", "java", "data pipelines in aws", "azure", "or gcp", "relational and warehousing database technology (oracle", "sqlserver", "teradata", "mysql", "postgres)", "streaming data", "data structures", "algorithms", "oo design", "programming skills", "iterative product development environment", "interpersonal skills", "analytical skills", "intellectual curiosity", "big picture business requirements"]}, "c0242a5605676714": {"terms": ["data science"], "salary_min": 120675.25, "salary_max": 152801.75, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n 1hRtAZzz2v", "cleaned_desc": "", "techs": ""}, "ee2d4a40ca7517b3": {"terms": ["data science"], "salary_min": 43.05, "salary_max": 51.85, "title": "Salesforce CPQ - Products & Pricing Specialist", "company": "Numbers Only, Inc", "desc": "Responsibilities: - Analyze pricing data and trends to determine optimal pricing strategies - Develop and maintain pricing models and tools to support pricing decisions - Collaborate with cross-functional teams to gather data and insights for pricing analysis - Monitor market conditions and competitor pricing strategies - Identify opportunities for price optimization and revenue growth - Provide recommendations for pricing adjustments based on analysis findings - Present pricing analysis results to stakeholders and provide actionable insights \n Requirements: - Bachelor's degree in a quantitative field such as Mathematics, Statistics, or Economics - Strong analytical skills with experience in data analysis and modeling - Proficiency in using quantitative tools such as Excel, SQL, or Python - Knowledge of pricing strategies and concepts - Excellent communication skills to effectively present analysis findings - Attention to detail and ability to work with large datasets - Ability to work independently and collaborate with cross-functional teams \n Note: Experience in quantum engineering is a plus, but not required for this position. \n Job Type: Full-time \n Pay: $43.05 - $51.85 per hour \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Salesforce CPQ: 5 years (Required) \n Pricing and product: 3 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Responsibilities: - Analyze pricing data and trends to determine optimal pricing strategies - Develop and maintain pricing models and tools to support pricing decisions - Collaborate with cross-functional teams to gather data and insights for pricing analysis - Monitor market conditions and competitor pricing strategies - Identify opportunities for price optimization and revenue growth - Provide recommendations for pricing adjustments based on analysis findings - Present pricing analysis results to stakeholders and provide actionable insights \n Requirements: - Bachelor's degree in a quantitative field such as Mathematics, Statistics, or Economics - Strong analytical skills with experience in data analysis and modeling - Proficiency in using quantitative tools such as Excel, SQL, or Python - Knowledge of pricing strategies and concepts - Excellent communication skills to effectively present analysis findings - Attention to detail and ability to work with large datasets - Ability to work independently and collaborate with cross-functional teams ", "techs": ["excel", "sql", "python"]}, "7bd79a3b9d840979": {"terms": ["data science"], "salary_min": 72192.27, "salary_max": 91411.51, "title": "Program Officer - Indo Pacific", "company": "Organized Crime and Corruption Reporting Project (OCCRP)", "desc": "Location:  Sydney, Australia or remote \n Deadline:  October 2 2023, 11:59 P.M. \n About OCCRP \n The Organized Crime and Corruption Reporting Project (OCCRP) is a growing, global nonprofit media organization that is reinventing investigative journalism for the public good. By developing and equipping a global network of investigative journalists and publishing their stories, we expose crime and corruption so the public can hold power to account. We see a future where organized crime and corruption are drastically reduced and democracy is strengthened. Our global team includes editors, researchers, data engineers, security specialists, administrators, technologists, and strategists, each with areas of in-depth expertise. \n Position Overview \n OCCRP is seeking an experienced program officer to oversee the implementation, monitoring, and evaluation of its grant portfolio in the Indo Pacific region. The program officer will be OCCRP\u2019s lead for understanding all aspects of the grants\u2019 objectives, deliverables, timelines, and budgets in the regional portfolio. \n The program officer will be responsible for coordinating with OCCRP\u2019s management, relevant field staff, and finance staff to monitor and discuss the financial health and progress being made toward grant deliverables. The program officer will also be a main point of contact between OCCRP and the donors, keeping them updated about the progress of grants and any issues that may impact successful and timely execution. Finally, the program officer will work closely with field staff\u2013\u2013OCCRP\u2019s journalists and technologists\u2013\u2013to monitor and evaluate the effectiveness of the work being funded and will be responsible for compiling accurate, informative, and on time reports about the work to donors. \n This position will be a key link between multiple departments at OCCRP as well as between OCCRP and its funders. As such, the program officer must possess excellent communication skills, time management skills, and attention to detail. The incumbent should have experience managing U.S. government-funded projects at medium-to-large international NGOs. Working knowledge of investigative journalism is preferred but not required. \n Essential Duties and Responsibilities \n \n Maintain a thorough understanding of all objectives and deliverables as stipulated in grant agreements. \n Maintain a thorough understanding of grant budgets and ensure that all costs allocated to grants are in accordance with their budgets and are appropriate under the terms of the grant agreements. \n Liaise with relevant field staff to ensure they understand grant objectives, timelines, and key deliverables. \n Liaise with relevant field staff to receive regular updates about progress toward grant deliverables and any issues that may impact grants\u2019 progress. \n Liaise with donors to provide regular updates about the status of grants. \n Quickly identify any issues which may impact the grant program\u2019s timely and successful implementation and clearly communicate them to OCCRP\u2019s management, relevant field staff, and donors. \n Regularly meet with the finance team and field staff to monitor and manage grants\u2019 financial health. \n Work with the finance team and programs department management to determine which costs should be allocated to appropriate grants on a monthly basis. \n Work with OCCRP management to constantly improve the overall grant management and reporting process. \n Ensure OCCRP confidential information is well-protected and is responsible to preserve confidentiality at all times. \n Communicate and collaborate with colleagues and stakeholders in accordance with OCCRP\u2019s relevant Protocols and Policies. \n Additional responsibilities as determined by management. \n \n Performance \n Success in this role with hinge on the following: \n \n Sharp critical thinking skills and a strong desire to constantly improve anything the incumbent is working on. \n Timeliness, accuracy, thoroughness, and attention to detail in reports and all other communications dealing with the duties listed above. \n Top-notch communication and collaboration skills when working with colleagues from a diverse range of cultures and backgrounds. \n Strong narrative-writing skills. \n A basic understanding of nonprofit finance, especially with regards to U.S. government funding. \n A high degree of emotional intelligence. \n The incumbent\u2019s success will be measured during regular performance evaluations. \n \n Skills, Experience, and Education Requirements \n \n A Bachelor\u2019s degree or higher. \n Experience managing U.S. government grant-funded programs at a global NGO. \n An understanding of investigative journalism, data science, or international development preferred. \n Experience managing or mentoring junior program management staff preferred. \n Proficiency with Excel. \n Experience managing budgets and reading nonprofit financial statements. \n Excellent communication, collaboration, organizational, and leadership skills. \n Must be able to keep organization matters strictly confidential. \n \n To Apply \n To apply, please email your CV and a Cover Letter to jobs@occrp.org \n All applications must be submitted in English. Incomplete applications will not be considered. Whilst we have internal goals to reply to unsuccessful candidates, we regret that the high number of applicants greatly exceeds our capacity to respond to each person. We apologize that we will not be able to reply to any unsuccessful applicants. As an equal opportunity employer, OCCRP values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We do not discriminate against any person based upon race, religion, color, national origin, sex, medical conditions, family status, sexual orientation, gender identity, gender expression, age, disability, genetic information, or any other legally protected characteristics. If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process, please contact hr@occrp.org", "cleaned_desc": "", "techs": ""}, "4b80f1d576716e7c": {"terms": ["data science"], "salary_min": 83967.12, "salary_max": 106321.086, "title": "GPS Project Manager", "company": "Infor", "desc": "General information \n       \n \n \n \n \n \n \n        Country \n        \n United States  \n \n \n \n        City \n        \n Remote Location  \n \n \n \n        Department \n        \n IT Business Innovation  \n \n \n \n        Job ID \n        \n 36204  \n \n \n \n \n \n \n \n \n \n       Description & Requirements \n       \n \n \n \n \n \n \n As a Hospitality GPS (Global Professional Services) Project Manager, you will be responsible for implementing Cloud-based solutions used by Hotels, Casinos, and Resorts to manage their day-to-day operations for Hotel Management, Sales and catering, Restaurant Point of Sales and Revenue Management. Projects require industry-specific knowledge to effectively manage resource assignments for configuration, training, support, and technical installations. GPS Project Managers have responsibility for major accounts and multi-site product rollout. You\u2019ll be accountable for managing the client project, ensuring that all targets and requirements are met, on schedule and within budget, while operating with minimal supervision. You\u2019ll report to the Manager of Project Managers who will support you from project assignment to planning & execution, through to project billing and closure. These duties will be performed remotely with some travel to customer\u2019s site and with regular client facing video conferencing expected. Other duties may include supporting the sales teams in a pre-sales capacity and the support team for post-implementation queries as needed. \n     \n A Day in The Life Typically Includes: \n  Responsible for billable projects from initiation through delivery: \n \n Being accountable and ensuring that projects remain on schedule and within budget and confirm projects are completed according to agreed-upon plan. \n Keeping appropriate client and Infor resources informed of project progress, completing weekly Project Status Reports, dashboard reports, participating in weekly PM meetings and communicating appropriately with client project sponsors, client department leadership, and staff. \n Ensuring all project resources are identified, forecasted, and staffed. \n Completing timely and accurate client invoicing and monitors outstanding receivables. \n Provide team leadership including: building a team, motivating staff, aligning project requirements to resource competencies, delegating work assignments and monitoring performance. \n \n \n \n Managing the Infor Consulting business through accurate project accounting: \n \n Maintaining project financial and project profitability, to include resource scheduling, revenue forecasting per project, billing reconciliations, expense report and time approval for project work, etc. \n Providing timely and accurate updates to all internal reporting and tracking systems. \n Ensuring all project resources are identified, forecasted, and staffed. \n Responsible for medium to high value services work orders \n \n \n \n Basic Qualifications: \n \n Project lifecycle Project Management experience within the Hospitality Industry \n Ability to manage small, medium up to large implementation projects. \n Experience building relationships and client communication. \n Experienced with Project Management tools and MS Office products. \n Travel up to 25% \n \n \n \n \n Preferred Qualifications: \n \n PMP or other Project Management certification. \n Hotel software products use or experience. \n Demonstrated business acumen in the Hospitality Industry. \n Bachelor's Degree, or equivalent work experience. \n \n \n \n \n         Remote (Dallas, TX; St. Paul, MN; and Alpharetta, GA)\n         \n \n \n \n \n \n \n \n \n         About Infor\n         \n \n \n  Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.\n         \n \n          For more information visit www.infor.com\n         \n \n \n \n \n \n \n \n         Our Values\n         \n \n \n  At Infor, we strive for an environment that is founded on a business philosophy called Principle Based Management\u2122 (PBM\u2122) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization. Increasing diversity is important to reflect our markets, customers, partners, and communities we serve in now and in the future.\n         \n \n \n  We have a relentless commitment to a culture based on PBM. Informed by the principles that allow a free and open society to flourish, PBM\u2122 prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.\n         \n \n \n  Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law.\n          \n \n \n \n \n         At Infor we value your privacy that\u2019s why we created a policy that you can read here.\n         \n \n \n \n \n \n \n \n \n         This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf", "cleaned_desc": " \n \n \n Managing the Infor Consulting business through accurate project accounting: \n \n Maintaining project financial and project profitability, to include resource scheduling, revenue forecasting per project, billing reconciliations, expense report and time approval for project work, etc. \n Providing timely and accurate updates to all internal reporting and tracking systems. \n Ensuring all project resources are identified, forecasted, and staffed. \n Responsible for medium to high value services work orders \n \n \n \n Basic Qualifications: \n \n Project lifecycle Project Management experience within the Hospitality Industry \n Ability to manage small, medium up to large implementation projects. \n Experience building relationships and client communication. \n Experienced with Project Management tools and MS Office products. \n Travel up to 25% \n \n \n \n \n Preferred Qualifications: \n \n PMP or other Project Management certification. \n Hotel software products use or experience. \n Demonstrated business acumen in the Hospitality Industry. ", "techs": ["infor consulting", "project accounting", "resource scheduling", "revenue forecasting", "billing reconciliations", "expense report", "time approval", "internal reporting and tracking systems", "project resources", "services work orders", "project management", "hospitality industry", "relationships", "client communication", "project management tools", "ms office products", "pmp certification", "hotel software products", "business acumen"]}, "a6194be101d7553d": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["tensorflow", "pytorch"]}, "85aebe6ae1470cd0": {"terms": ["data science"], "salary_min": 117518.0, "salary_max": 152771.0, "title": "IT Specialist", "company": "The Infosoft Group", "desc": "Duties \n   This is not a bargaining unit position.       Please read this public notice in its entirety before submitting your application.       Vacancies may not presently exist but may become available at any point during the opening period of this vacancy announcement. We will not review applicant resumes until there is a request to fill a vacancy.    You are applying to a public notice to fill current and future vacancies. Please note, that there may or may not be actual/projected vacancies when you submit your application. Your resume and supporting documentation will be retained with other applicants and reviewed as vacancies occur. You will not receive a notice regarding your application's status other than the initial acknowledgment until a request is received to fill a position.    This announcement will remain open until  September 29, 2023 . The initial cut-off date is  January 20, 2023 ,  OR  the point at which the first 100 applications are received, whichever comes first. Applications submitted after  January 20, 2023  may not receive consideration. In addition, due to the potential of a high volume of applicants, not all applicants may receive consideration.    After the initial cut-off period, once additional requests to fill a vacancy are received, applications will be reviewed in increments of 100 applications  in date order.     Note:  Submitting multiple applications  will  change the order in which your application is reviewed.    We will refer qualified applicants to the selecting official for consideration. The organization's hiring needs will determine the referral of additional applicants. Applicants will be notified about their application's status if referred or if we fill all vacancies.    This position is primarily aligned to the following NICE Cybersecurity Workforce Framework work roles:  \n \n OPM Cyber Code 651 - Enterprise Architect \n OPM Cyber Code 804 - IT Investment/Portfolio Manager \n For more information about these work roles, where they fit within the larger Cyber Workforce, and how they can support your unique career journey, please visit the Cyber Career Pathways tool on the National Initiative for Cybersecurity Careers and Studies website:\n     \n \n \n Do you want an opportunity to improve the lives of millions of Veterans? Use your technical expertise to develop and deliver cutting-edge digital capabilities to Veterans and those who care for them! \n \n  We're looking for experts in data science, software engineering, product design, product management, and user experience (UX) who are passionate about using their skills to ensure Veterans and their families receive seamless care and services to join our team of technologists. Our technologists help develop cutting-edge technology, advocate for Veteran needs, and ensure the Department of Veterans Affairs can provide Veterans' home loans, G.I. Bill, healthcare, and other services.\n   \n  We are committed to building a team that reflects the communities we serve and strongly encourage people of color, LGBTQ+ individuals, women, minorities, people with disabilities, system-impacted people, Veterans, and people of all ages to apply.\n   \n \n About Our Technologist Teams \n \n  If selected, technologists will be appointed to serve in our Office of Chief Technology Officer (CTO) or Software Product Management (SPM).\n   \n  You can work from home anywhere in the United States, or at VA headquarters in Washington, D.C.\n   \n  At OIT, you will be working on a wide variety of projects that are relevant to your specific area of expertise. Possible projects could include: \n   \n Working on small, cross-functional teams with healthcare, education, and financial analysts to perform technical investigative research for projects that affect millions of Veterans. \n Analyzing computational models implemented by financial institutions that inform what benefits Veterans and their families are eligible for. Ex. Healthcare, home loan guarantees, and educational benefits \n Researching how electronic healthcare data can be utilized to deliver better care and services to Veterans. \n Anticipating risks and acting fast to support Veterans when IT systems fail. \n Serve as a technical expert and strategic advisor to further the Bureau's investigative and policymaking goals. \n \n \n Work Schedule : Monday - Friday, 8:00 am - 4:30 pm\n   \n Compressed/Flexible Schedule : May be available with supervisor approval\n   \n Duty Location Status : Will work remotely from home or at VA Headquarters in Washington, DC\n   \n Position Description/PD#:  IT Specialist/PD 18493A\n   \n Relocation/Recruitment Incentives : Recruitment Incentives Authorized\n   \n Financial Disclosure Report : Not Required\n   \n Physical Demands : The work is largely sedentary. The incumbent must possess the flexibility and versatility of mind necessary to defend and negotiate matters involving significant controversial issues. May be required to work under stressful conditions, such as long hours, to complete sensitive and urgent work assignments. \n  \n \n  Requirements Conditions of Employment \n   \n You must be a U.S. citizen to apply for this job. \n Selectees are subject to a background/suitability investigation. \n Designated and/or random drug testing may be required \n Selectees may be required to serve a probationary period. \n Selective Service Registration is required for males born after 12/31/1959. \n A complete application package, i.e., Resume, Transcripts, etc., as required by the job announcement. \n Selected applicants will be required to complete an online onboarding process. \n Participation in the Seasonal Influenza Prevention Program for VHA Health Care Personnel (HCP) is a requirement for all Department of Veterans Affairs HCP. \n All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA. \n Must be proficient in written and spoken English. \n Pre-employment physical evaluation may be required. \n \n \n   Qualifications \n    \n What We're Looking For \n \n  We want people excited about building technology and embracing the VA's mission.\n     \n  We are looking for skilled technologists with experience in any of the following areas: \n     \n Data Science & Strategy : Examine large datasets using scripting languages or modern statistical analyses and computational languages (e.g., Python, R, SQL, Azure Synapse, Power BI, Databricks, Azure ML, Kubernetes, Oracle, Enterprise Data Lake, Azure Data Factory and hosting solutions on cloud environments to include AWS and Azure) to provide seamless care and services to Veterans and their caregivers. Use artificial intelligence (AI) and machine learning technologies, logistic and linear regression models, or natural language processing (NLP) to detect, anticipate and prevent potential Veteran harm or inability to access VA benefits and services. \n Software Engineering : Design, create, and test systems to dig into how to best deliver IT products and services. Use front-end, back-end, and full-stack engineering to develop and support new technical strategies that could help effectively serve Veterans and VA employees. This could include API design and development, furthering open-source policies while prioritizing maintainability and software reusability in all product development. Programming languages, e.g., Python, SQL, R, Java, JS, Go, Scala, C, C++, Julia, or MatLab. \n Product Management:  Coordinate across stakeholders and use agile or lean approaches to align cross-functional teams around a common vision or strategy and user needs. Monitor Veteran and market trends and develop environmental analyses. Use expertise to advance the use of emerging technologies within government. \n Design & UX:  A user experience designer at Veteran's Affairs will have a direct impact on the VA's ability to provide its customers - Veterans of the US military and other members of the public that support those Veterans - with an exceptional customer experience, comparable with the experience they have with top tier commercial products and services. They may work on public-facing, clinical, or staff facing initiatives in various design practice areas. A user experience designer can advance through multiple levels in their design career at VA and have a significant impact on improving VA products, processes, and best practices. \n \n To qualify for this position, applicants must meet all requirements when a request is received to fill a vacancy. \n \n \n Experience  - Experience must be IT related; the experience may be demonstrated by paid or unpaid experience and/or completion of specific, intensive training (for example, IT certification), as appropriate.\n     \n  For all positions individuals must have IT-related experience demonstrating each of the four competencies listed below. The employing agency is responsible for identifying the specific level of proficiency required for each competency at each grade level based on the requirements of the position being filled. \n     \n \n Attention to Detail  - Is thorough when performing work and conscientious about attending to detail. \n \n \n Customer Service  - Works with clients and customers (that is, any individuals who use or receive the services or products that your work unit produces, including the general public, individuals who work in the agency, other agencies, or organizations outside the Government) to assess their needs, provide information or assistance, resolve their problems, or satisfy their expectations; knows about available products and services; is committed to providing quality products and services. \n \n \n Oral Communication  - Expresses information (for example, ideas or facts) to individuals or groups effectively, taking into account the audience and nature of the information (for example, technical, sensitive, controversial); makes clear and convincing oral presentations; listens to others, attends to nonverbal cues, and responds appropriately. \n \n \n Problem Solving  - Identifies problems; determines accuracy and relevance of information; uses sound judgment to generate and evaluate alternatives, and to make recommendations. \n \n \n AND \n \n \n Specialized Experience:  You must have one year of specialized experience equivalent to at least the next lower grade, \n     GS-14 , in the normal line of progression for the occupation in the organization. Specialized experience is defined as applying enterprise architecture principles to lead and deliver IT digital services program activities in the private and/or federal sectors; using modern technology development and management approaches to deliver digital products to production.\n     \n  Such experience is typically gained in the IT field or through the performance of work where the primary concern is IT.\n     \n  Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n     \n  , federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.\n     \n  To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.\n     \n \n Note : \n     A full year of work is considered to be 35-40 hours of work per week. Part-time experience will be credited on the basis of time actually spent in appropriate activities. Applicants wishing to receive credit for such experience must indicate clearly the nature of their duties and responsibilities in each position and the number of hours a week spent in such employment.  For more information on these qualification standards, please visit OPM's website at . \n    \n \n \n   Education \n    There is no education substitute for the GS-15 level.   \n \n \n   Additional information \n    \n \n * This is an announcement for a Term Appointment, initially not to exceed Two Years, which MAY be extended up to Four Years based on needs of the agency/management. *     Current Openings    New and emerging technologies are changing how preexisting products and services work or creating new ones. We need more technologists serving in the ranks of our technology teams. These positions are vital in helping us understand the constantly evolving needs of Veterans and their families.    Technologists will work alongside financial analysts, healthcare researchers, human resources experts, and more to provide quality IT products and services using various technical or design methods to inform how best to deliver care and benefits to Veterans. Technologists will support the cross-pollination of key ideas in emerging technology fields to ensure the federal government can keep pace with the private sector.    The  Interagency Career Transition Assistance Plan (ICTAP)  and  Career Transition Assistance Plan (CTAP)  provide eligible displaced VA competitive service employees with selection priority over other candidates for competitive service vacancies. To be well-qualified, applicants must possess experience that exceeds the minimum qualifications of the position including all selective factors if applicable, and must be proficient in most of the requirements of the job. Information about ICTAP and CTAP eligibility is on OPM's Career Transition Resources website which can be found at .     Receiving Service Credit for Earning Annual (Vacation) Leave:  Federal Employees earn annual leave at a rate (4, 6 or 8 hours per pay period) which is based on the number of years they have served as a Federal employee. VA may offer newly-appointed Federal employee's credit for their job-related non-federal experience or active duty uniformed military service. This credited service can be used in determining the rate at which they earn annual leave. Such credit must be requested and approved prior to the appointment date and is not guaranteed.     OPM General Schedule (GS) & Locality Pay Tables:  The salary range listed reflects the GS base rate (not including locality). Upon selection, the salary will be adjusted to include locality. Please see .     Superior Qualifications and Special Needs Pay-Setting:   Agencies may set the rate of basic pay of a newly-appointed employee at a rate above the minimum rate of the appropriate General Schedule (GS) grade because of- \n \n \n the superior qualifications of the candidate; or \n \n \n a special need of the agency for the candidate's services. \n \n \n An agency must approve each determination to use this authority  before the employee enters on duty - the determination cannot be made retroactively - and is not guaranteed.  .     Recruitment Incentives:  An agency may pay a recruitment incentive to a newly-appointed employee if the agency has determined that the position is likely to be difficult to fill in the absence of an incentive. . \n \n \n \n \n \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. .  \n \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n \n \n \n \n  Required Documents \n   \n Documents Accepted:   \n \n  DD-214/ Statement of Service \n  Disability Letter (VA) \n  Resume \n  Separation Notice (RIF) \n  SF-50/ Notification of Personnel Action \n \n  Documents Required:\n    \n \n Resume \n \n  Please review the above list(s) to ensure you have included all necessary documents required for your application.Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees).\n    You will not be contacted for additional information.  Applicants will be deemed ineligible if supporting documentation is not submitted.\n    \n \n Veterans' Preference:  Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.\n    \n \n Applications are accepted online.  Applying online will allow you to review and track the status of your application. \n   \n \n \n  How to Apply \n   \n All applicants are encouraged to apply online.     To apply for this position,  you must complete the occupational questionnaire and submit the documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (EST) on 09/29/2023 to receive consideration. To preview the questionnaire click .    1. To begin, click  Apply Online  to create a USAJOBS account or log in to your existing account. Follow the prompts to select your USAJOBS resume and/or other supporting documents and complete the occupational questionnaire.    2. Click  Submit My Answers  to submit your application package.     NOTE:  It is your responsibility to ensure your responses and appropriate documentation is submitted prior to the closing date. To verify your application is complete, log into your USAJOBS account, , select the  Application Status  link and then select the M ore Information  link for this position. The Details page will display the status of your application, the documentation received and processed, and any correspondence the agency has sent related to this application. Your uploaded documents may take several hours to clear the virus scan process.     To return to an incomplete application , log into your USAJOBS account and click  Update Application  in the vacancy announcement. You must re-select your resume and/or other documents from your USAJOBS account or your application will be incomplete. \n \n \n   Agency contact information VHA National Recruitment Center \n    \n \n     Phone \n      Email \n     \n \n \n     Address \n      \n \n DAS Information and Technology - 103 \n \n 810 Vermont Avenue NW \n \n Washington, DC 20420 \n \n US  \n \n \n \n Next steps \n   \n After the vacancy announcement closes, applicants are evaluated to ensure qualification and eligibility requirements are met. After the review is complete, a referral certificate(s) is issued and applicants will be notified of their status by email.  \n \n \n \n  Fair & Transparent \n   The Federal hiring process is set up to be fair and transparent. Please read the following guidance.   \n \n  The United States Government does not discriminate in employment on the \n   basis of race, color, religion, sex (including pregnancy and gender \n   identity), national origin, political affiliation, sexual orientation, \n   marital status, disability, genetic information, age, membership in an \n   employee organization, retaliation, parental status, military service, \n   or other non-merit factor.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Clement J. Zablocki VA Medical Center, Department of Veterans Affairs \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Work Hours (i.e. shift)\n   \n \n   Full-time -\n   \n \n \n \n   Salary and Benefits\n   \n \n   $117,518 - $152,771 per year\n   \n \n \n \n   Required Experience\n   \n \n   1+ years\n   \n \n \n \n   Required Security Clearance\n   \n \n   Other Clearance", "cleaned_desc": " Participation in the Seasonal Influenza Prevention Program for VHA Health Care Personnel (HCP) is a requirement for all Department of Veterans Affairs HCP. \n All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA. \n Must be proficient in written and spoken English. \n Pre-employment physical evaluation may be required. \n \n \n   Qualifications \n    \n What We're Looking For \n \n  We want people excited about building technology and embracing the VA's mission.\n     \n  We are looking for skilled technologists with experience in any of the following areas: \n     \n Data Science & Strategy : Examine large datasets using scripting languages or modern statistical analyses and computational languages (e.g., Python, R, SQL, Azure Synapse, Power BI, Databricks, Azure ML, Kubernetes, Oracle, Enterprise Data Lake, Azure Data Factory and hosting solutions on cloud environments to include AWS and Azure) to provide seamless care and services to Veterans and their caregivers. Use artificial intelligence (AI) and machine learning technologies, logistic and linear regression models, or natural language processing (NLP) to detect, anticipate and prevent potential Veteran harm or inability to access VA benefits and services. \n Software Engineering : Design, create, and test systems to dig into how to best deliver IT products and services. Use front-end, back-end, and full-stack engineering to develop and support new technical strategies that could help effectively serve Veterans and VA employees. This could include API design and development, furthering open-source policies while prioritizing maintainability and software reusability in all product development. Programming languages, e.g., Python, SQL, R, Java, JS, Go, Scala, C, C++, Julia, or MatLab. \n Product Management:  Coordinate across stakeholders and use agile or lean approaches to align cross-functional teams around a common vision or strategy and user needs. Monitor Veteran and market trends and develop environmental analyses. Use expertise to advance the use of emerging technologies within government. \n Design & UX:  A user experience designer at Veteran's Affairs will have a direct impact on the VA's ability to provide its customers - Veterans of the US military and other members of the public that support those Veterans - with an exceptional customer experience, comparable with the experience they have with top tier commercial products and services. They may work on public-facing, clinical, or staff facing initiatives in various design practice areas. A user experience designer can advance through multiple levels in their design career at VA and have a significant impact on improving VA products, processes, and best practices. \n \n To qualify for this position, applicants must meet all requirements when a request is received to fill a vacancy. \n \n \n Experience  - Experience must be IT related; the experience may be demonstrated by paid or unpaid experience and/or completion of specific, intensive training (for example, IT certification), as appropriate.\n     \n  For all positions individuals must have IT-related experience demonstrating each of the four competencies listed below. The employing agency is responsible for identifying the specific level of proficiency required for each competency at each grade level based on the requirements of the position being filled. \n     \n \n Attention to Detail  - Is thorough when performing work and conscientious about attending to detail. \n \n \n Customer Service  - Works with clients and customers (that is, any individuals who use or receive the services or products that your work unit produces, including the general public, individuals who work in the agency, other agencies, or organizations outside the Government) to assess their needs, provide information or assistance, resolve their problems, or satisfy their expectations; knows about available products and services; is committed to providing quality products and services. \n \n \n Oral Communication  - Expresses information (for example, ideas or facts) to individuals or groups effectively, taking into account the audience and nature of the information (for example, technical, sensitive, controversial); makes clear and convincing oral presentations; listens to others, attends to nonverbal cues, and responds appropriately. \n \n \n Problem Solving  - Identifies problems; determines accuracy and relevance of information; uses sound judgment to generate and evaluate alternatives, and to make recommendations. \n \n \n AND \n \n \n Specialized Experience:  You must have one year of specialized experience equivalent to at least the next lower grade, \n     GS-14 , in the normal line of progression for the occupation in the organization. Specialized experience is defined as applying enterprise architecture principles to lead and deliver IT digital services program activities in the private and/or federal sectors; using modern technology development and management approaches to deliver digital products to production.\n     \n  Such experience is typically gained in the IT field or through the performance of work where the primary concern is IT.\n     \n  Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n     \n  , federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.\n     \n  To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.\n     \n \n Note : ", "techs": ["python", "r", "sql", "azure synapse", "power bi", "databricks", "azure ml", "kubernetes", "oracle", "enterprise data lake", "azure data factory", "aws", "azure", "java", "js", "go", "scala", "c", "c++", "julia", "matlab"]}, "ba61c3be3365872a": {"terms": ["data science"], "salary_min": 120675.25, "salary_max": 152801.75, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n yRCKNPkWn2", "cleaned_desc": "", "techs": ""}, "6de1d41ca9824864": {"terms": ["data science"], "salary_min": 99908.0, "salary_max": 129878.0, "title": "IT Specialist", "company": "The Infosoft Group", "desc": "Duties \n   Do you want an opportunity to improve the lives of millions of Veterans? Use your technical expertise to develop and deliver cutting-edge digital capabilities to Veterans and those who care for them!    We're looking for experts in data science, software engineering, product design, product management, and user experience (UX) who are passionate about using their skills to ensure Veterans and their families receive seamless care and services to join our team of technologists. Our technologists help develop cutting-edge technology, advocate for Veteran needs, and ensure the Department of Veterans Affairs can provide Veterans' home loans, G.I. Bill, healthcare, and other services.    We are committed to building a team that reflects the communities we serve and strongly encourage people of color, LGBTQ+ individuals, women, minorities, people with disabilities, system-impacted people, Veterans, and people of all ages to apply.     About Our Technologist Teams    If selected, technologists will be appointed to serve in our Office of Chief Technology Officer (CTO).    You can work from home anywhere in the United States, or at VA headquarters in Washington, D.C.    At OIT, you will be working on a wide variety of projects that are relevant to your specific area of expertise. Possible projects could include:  \n \n Working on small, cross-functional teams with healthcare, education, and financial analysts to perform technical investigative research for projects that affect millions of Veterans. \n Analyzing computational models implemented by financial institutions that inform what benefits Veterans and their families are eligible for. Ex. Healthcare, home loan guarantees, and educational benefits \n Researching how electronic healthcare data can be utilized to deliver better care and services to Veterans. \n Anticipating risks and acting fast to support Veterans when IT systems fail. \n Serve as a technical expert and advisor to support VA mission. \n \n \n \n \n Work Schedule : Monday - Friday, 8:00 am - 4:30 pm\n   \n Compressed/Flexible Schedule : Available with supervisory approval\n   \n Duty Location Status : Will work remotely from home location\n   \n Position Description Title/PD# : IT Specialist/ PD18520A\n   \n Relocation/Recruitment Incentives : Not Authorized\n   \n Financial Disclosure Report : Not required\n   \n Physical Demands : The work is largely sedentary. The incumbent must possess the flexibility and versatility of mind necessary to defend and negotiate matters involving significant controversial issues. May be required to work under stressful conditions, such as long hours, to complete sensitive and urgent work assignments. \n   \n What We're Looking For \n \n  We want people excited about building technology and embracing the VA's mission.We are looking for skilled technologists with experience in any of the following areas: \n   \n Data Science & Strategy : Examine large datasets using scripting languages or modern statistical analyses and computational languages (e.g., Python, R, SQL, Azure Synapse, Power BI, Databricks, Azure ML, Kubernetes, Oracle, Enterprise Data Lake, Azure Data Factory and hosting solutions on cloud environments to include AWS and Azure) to provide seamless care and services to Veterans and their caregivers. Use artificial intelligence (AI) and machine learning technologies, logistic and linear regression models, or natural language processing (NLP) to detect, anticipate and prevent potential Veteran harm or inability to access VA benefits and services. \n Software Engineering : Design, create, and test systems to dig into how to best deliver IT products and services. Use front-end, back-end, and full-stack engineering to develop and support new technical strategies that could help effectively serve Veterans and VA employees. This could include API design and development, furthering open-source policies while prioritizing maintainability and software reusability in all product development. Programming languages, e.g., Python, SQL, R, Java, JS, Go, Scala, C, C++, Julia, or MatLab. \n Product Management:  Coordinate across stakeholders and use agile or lean approaches to align cross-functional teams around a common vision or strategy and user needs. Monitor Veteran and market trends and develop environmental analyses. Use expertise to advance the use of emerging technologies within government. \n Design & UX:  A user experience designer at Veteran's Affairs will have a direct impact on the VA's ability to provide its customers - Veterans of the US military and other members of the public that support those Veterans - with an exceptional customer experience, comparable with the experience they have with top tier commercial products and services. They may work on public-facing, clinical, or staff facing initiatives in various design practice areas. A user experience designer can advance through multiple levels in their design career at VA and have a significant impact on improving VA products, processes, and best practices. \n \n \n \n  Requirements Conditions of Employment \n   \n You must be a U.S. citizen to apply for this job. \n Selectees are subject to a background/suitability investigation. \n Designated and/or random drug testing may be required \n Selectees may be required to serve a probationary period. \n Selective Service Registration is required for males born after 12/31/1959. \n A complete application package, i.e., Resume, Transcripts, etc., as required by the job announcement. \n Selected applicants will be required to complete an online onboarding process. \n Participation in the Seasonal Influenza Prevention Program for VHA Health Care Personnel (HCP) is a requirement for all Department of Veterans Affairs HCP. \n All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA. \n Must be proficient in written and spoken English. \n Pre-employment physical evaluation may be required. \n \n \n   Qualifications \n    \n Please read this public notice in its entirety before submitting your application. Vacancies may not presently exist but may become available at any point during the opening period of this vacancy announcement. We will not review applicant resumes until there is a request to fill a vacancy. \n \n  You are applying to a public notice to fill current and future vacancies. Please note, that there may or may not be actual/projected vacancies when you submit your application. Your resume and supporting documentation will be retained with other applicants and reviewed as vacancies occur. You will not receive a notice regarding your application's status other than the initial acknowledgment until a request is received to fill a position.\n     \n  This announcement will remain open until the December 29, 2023. The cut-off date is January 20, 2023, OR the point at which the first 100 applications are received, whichever comes first. Due to the potential of a high volume of applicants, not all applicants may receive consideration.\n     \n  After the initial cut-off period, once additional requests to fill a vacancy are received, applications will be reviewed in increments of 100 applications\n      in date order. \n \n \n Note:  Submitting multiple applications will change the order in which your application is reviewed.\n     \n  We will refer qualified applicants to the selecting official for consideration. The organization's hiring needs will determine the referral of additional applicants. Applicants will be notified about their application's status if referred or if we fill all vacancies.\n     \n  This position is primarily aligned to the following NICE Cybersecurity Workforce Framework work roles: \n     \n OPM Cyber Code 801 - Program Manager \n For more information about these work roles, where they fit within the larger Cyber Workforce, and how they can support your unique career journey, please visit the Cyber Career Pathways tool on the National Initiative for Cybersecurity Careers and Studies website:\n     \n  You may qualify based on your experience as described below.\n     \n \n Experience  - Experience must be IT related; the experience may be demonstrated by paid or unpaid experience and/or completion of specific, intensive training (for example, IT certification), as appropriate.\n     \n  For all positions individuals must have IT-related experience demonstrating each of the four competencies listed below. The employing agency is responsible for identifying the specific level of proficiency required for each competency at each grade level based on the requirements of the position being filled. \n     \n \n Attention to Detail  - Is thorough when performing work and conscientious about attending to detail. \n \n \n Customer Service  - Works with clients and customers (that is, any individuals who use or receive the services or products that your work unit produces, including the general public, individuals who work in the agency, other agencies, or organizations outside the Government) to assess their needs, provide information or assistance, resolve their problems, or satisfy their expectations; knows about available products and services; is committed to providing quality products and services. \n \n \n Oral Communication  - Expresses information (for example, ideas or facts) to individuals or groups effectively, taking into account the audience and nature of the information (for example, technical, sensitive, controversial); makes clear and convincing oral presentations; listens to others, attends to nonverbal cues, and responds appropriately. \n \n \n Problem Solving  - Identifies problems; determines accuracy and relevance of information; uses sound judgment to generate and evaluate alternatives, and to make recommendations. \n \n \n AND \n \n \n Specialized Experience:  You must have one year of specialized experience equivalent to at least the next lower grade GS-13 in the normal line of progression for the occupation in the organization. Specialized experience is defined as experience with leading, coordinating, and ensuring the overall success of an IT program or products; ensuring alignment with agency priorities; and lifecycle management.\n     \n  Such experience is typically gained in the IT field or through the performance of work where the primary concern is IT.\n     \n  Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n     \n  , federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.\n     \n  To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.\n     \n \n Note : \n     A full year of work is considered to be 35-40 hours of work per week. Part-time experience will be credited on the basis of time actually spent in appropriate activities. Applicants wishing to receive credit for such experience must indicate clearly the nature of their duties and responsibilities in each position and the number of hours a week spent in such employment.  For more information on these qualification standards, please visit OPM's web site at . \n    \n \n \n   Education \n    There is no education substitute or requirement for the GS-14 level.   \n \n \n   Additional information \n    \n \n Current Openings    New and emerging technologies are changing how preexisting products and services work or creating new ones. We need more technologists serving in the ranks of our technology teams. These positions are vital in helping us understand the constantly evolving needs of Veterans and their families.    Technologists will work alongside financial analysts, healthcare researchers, human resources experts, and more to provide quality IT products and services using various technical or design methods to inform how best to deliver care and benefits to Veterans. Technologists will support the cross-pollination of key ideas in emerging technology fields to ensure the federal government can keep pace with the private sector.    The  Interagency Career Transition Assistance Plan (ICTAP)  and  Career Transition Assistance Plan (CTAP)  provide eligible displaced VA competitive service employees with selection priority over other candidates for competitive service vacancies. To be well-qualified, applicants must possess experience that exceeds the minimum qualifications of the position including all selective factors if applicable, and must be proficient in most of the requirements of the job. Information about ICTAP and CTAP eligibility is on OPM's Career Transition Resources website which can be found at .     Receiving Service Credit for Earning Annual (Vacation) Leave:  Federal Employees earn annual leave at a rate (4, 6 or 8 hours per pay period) which is based on the number of years they have served as a Federal employee. VA may offer newly-appointed Federal employee's credit for their job-related non-federal experience or active duty uniformed military service. This credited service can be used in determining the rate at which they earn annual leave. Such credit must be requested and approved prior to the appointment date and is not guaranteed.     OPM General Schedule (GS) & Locality Pay Tables:  The salary range listed reflects the GS base rate (not including locality). Upon selection, the salary will be adjusted to include locality. Please see .     Superior Qualifications and Special Needs Pay-Setting:  Agencies may set the rate of basic pay of a newly-appointed employee at a rate above the minimum rate of the appropriate General Schedule (GS) grade because of- \n \n \n the superior qualifications of the candidate; or \n \n \n a special need of the agency for the candidate's services. \n \n \n An agency must approve each determination to use this authority  before the employee enters on duty - the determination cannot be made retroactively - and is not guaranteed.  . This job opportunity announcement may be used to fill additional vacancies. \n  If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an . \n \n \n \n \n \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. .  \n \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n \n \n \n \n  Required Documents \n   \n Documents Accepted:   \n \n  DD-214/ Statement of Service \n  Disability Letter (VA) \n  Other (1) \n  Resume \n  Separation Notice (RIF) \n  SF-50/ Notification of Personnel Action \n \n  Documents Required:\n    \n \n Resume \n \n  Please review the above list(s) to ensure you have included all necessary documents required for your application.Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees).\n    You will not be contacted for additional information.  Applicants will be deemed ineligible if supporting documentation is not submitted.\n    \n \n Veterans' Preference:  Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.\n    \n \n Applications are accepted online.  Applying online will allow you to review and track the status of your application. \n    \n    If you are relying on your education to meet qualification requirements: \n     Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from .  \n Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.  \n \n \n \n \n  How to Apply \n   \n All applicants are encouraged to apply online.     To apply for this position,  you must complete the occupational questionnaire and submit the documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (EST) on 12/29/2023 to receive consideration. To preview the questionnaire click .    1. To begin, click  Apply Online  to create a USAJOBS account or log in to your existing account. Follow the prompts to select your USAJOBS resume and/or other supporting documents and complete the occupational questionnaire.    2. Click  Submit My Answers  to submit your application package.     NOTE:  It is your responsibility to ensure your responses and appropriate documentation is submitted prior to the closing date. To verify your application is complete, log into your USAJOBS account, , select the  Application Status  link and then select the M ore Information  link for this position. The Details page will display the status of your application, the documentation received and processed, and any correspondence the agency has sent related to this application. Your uploaded documents may take several hours to clear the virus scan process.     To return to an incomplete application , log into your USAJOBS account and click  Update Application  in the vacancy announcement. You must re-select your resume and/or other documents from your USAJOBS account or your application will be incomplete. \n \n \n   Agency contact information VHA National Recruitment Center \n    \n \n     Phone \n      Email \n     \n \n \n     Address \n      \n \n DAS Information and Technology - 103 \n \n 810 Vermont Avenue NW \n \n Washington, DC 20420 \n \n US  \n \n \n \n Next steps \n   \n After the vacancy announcement closes, applicants are evaluated to ensure qualification and eligibility requirements are met. After the review is complete, a referral certificate(s) is issued and applicants will be notified of their status by email.  \n \n \n \n  Fair & Transparent \n   The Federal hiring process is set up to be fair and transparent. Please read the following guidance.   \n \n  The United States Government does not discriminate in employment on the \n   basis of race, color, religion, sex (including pregnancy and gender \n   identity), national origin, political affiliation, sexual orientation, \n   marital status, disability, genetic information, age, membership in an \n   employee organization, retaliation, parental status, military service, \n   or other non-merit factor.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Clement J. Zablocki VA Medical Center, Department of Veterans Affairs \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Work Hours (i.e. shift)\n   \n \n   Full-time -\n   \n \n \n \n   Salary and Benefits\n   \n \n   $99,908 - $129,878 per year\n   \n \n \n \n   Required Experience\n   \n \n   1+ years\n   \n \n \n \n   Required Security Clearance\n   \n \n   Other Clearance", "cleaned_desc": "", "techs": ""}, "5440af24dca68223": {"terms": ["data science"], "salary_min": 46419.9, "salary_max": 58777.938, "title": "Part-Time Career Coach", "company": "General Assembly", "desc": "Since 2011, General Assembly (GA) has transformed tens of thousands of careers through pioneering, experiential education in today's most in-demand skills. As featured in The Economist, Wired, and The New York Times, GA offers training in web development, data, design, marketing, and more, both online and at campuses across multiple countries. Our global professional community boasts more than 95,000 full- and part-time alumni \u2014 and counting. \n  In addition to fostering career growth for individuals, GA helps employers cultivate top diverse tech talent and spur innovation by transforming their teams through strategic learning. More than 21,000 employees at elite companies worldwide have honed their digital fluency with our corporate training programs. GA has also been recognized as one of Deloitte's Technology Fast 500, and Fast Company has dubbed us leaders in World-Changing Ideas as well as the #1 Most Innovative Company in Education. \n \n  The Role \n  The goal of the Career Coach is to ensure students are supported as they start to think about their next professional steps and graduates are prepared and confident in their job search. A balance of ensuring that graduates are empowered to find jobs in a timely manner, as well as find roles that they are passionate about, is critical for this role.  This is part-time position (20-25hrs per week). \n  Responsibilities \n \n Coach & Counselor - Ensure all job-seeking students & graduates have a smooth transition from the classroom to job seeking and that they feel supported during this process. Reduce anxiety for students & graduates around their job search through clear communication. Help students identify their personal goals to best impact their job search & educational experience.   \n Content Delivery - Educate students & graduates of immersive programs on skills needed to perform an effective job search. Lead both recurring one-on-one and classroom based programming.   \n Content Creation - Work with teams at GA that are responsible for curriculum to highlight updates as needed and create new student-facing resources. Be a key thought partner in the curriculum and resource creation.   \n Internal Team Connector - Utilize and coordinate with GA community resources as needed to acquire additional educational opportunities (mock technical interviews, project feedback, etc.)   \n Risk Management - Track student progress and highlight to teammates and stakeholders when a student isn't doing well or falling out of communication. Also, ensure that we're putting quality, qualified grads into our community.   \n \n Skills & Qualifications \n \n Familiarity with the tech (web development, data science, UX) landscape; previous experience working in some facet of the tech industry. Awareness of tech job market and breadth of opportunities. \n Passionate about education & technology. \n Previous recruiting or counseling/coaching experience. Account management or sales experience is a plus. \n Comfortable presenting both one-on-one and delivering to a large group. \n Able to give constructive, positive feedback to people of diverse professional and life backgrounds. \n Previous personal job search experience, and an ability to be relatable. \n Resourceful; able to pull educational resources from the community and to tailor lesson plans/meetings based on graduate needs. \n Able to manage large volume of requests and organize systems to keep track of students in various stages. Highly organized & data conscious. \n High emotional intelligence; able to empathize with others and can handle other people's stress. \n \n Competencies \n \n Motivating Others:  Creates a climate in which people want to do their best; can motivate many kinds of direct reports and team or project members; can assess each person's hot button and use it to get the best out of him/her; pushes tasks and decisions down; empowers others; invites input from each person and shares ownership and visibility; makes each individual feel his/her work is important; is someone people like working for and with. \n Managing Vision & Purpose:  Communicates a compelling and inspired vision or sense of core purpose; talks beyond today; talks about possibilities; is optimistic; creates mileposts and symbols to rally support behind the vision; makes the vision sharable by everyone; can inspire and motivate entire units or organizations. \n Innovation Management:  Is good at bringing the creative ideas of others to market; has good judgment about which creative ideas and suggestions will work; has a sense about managing the creative process of others; can facilitate effective brainstorming; can project how potential ideas may play out in the marketplace. \n Managing and Measuring Work:  Clearly assigns responsibility for tasks and decisions; sets clear objectives and measures; monitors process, progress, and results; designs feedback loops into work. \n Organizing:  Can marshal resources (people, funding, material, support) to get things done; can orchestrate multiple activities at once to accomplish a goal; uses resources effectively and efficiently arranges information and files in a useful manner. \n Listening:  Practices attentive and active listening; has the patience to hear people out; can accurately restate the opinions of others even when he/she disagrees. \n Patience:  Is tolerant with people and processes; listens and checks before acting; tries to understand the people and the data before making judgments and acting; waits for others to catch up before acting; sensitive to due process and proper pacing; follows established process . \n Presentation Skills:  Is effective in a variety of formal presentation settings: one-on-one, small and large groups, with peers, direct reports, and bosses; is effective both inside and outside the organization, on both cool data and hot and controversial topics; commands attention and can manage group processes during the presentation; can change tactics midstream when something isn't working. \n \n The anticipated annualized salary range for this position in the US market is $26,000 and $41,600. Salary will be determined based on experience, education, geographic location, and other factors. If hired as a regular full-time employee, this position will include a variable compensation plan which could be a bonus or a commission. \n  US benefit offerings for full-time employment may include medical, dental, vision, term life insurance, short-term and long-term disability, additional voluntary benefits, commuter benefits, wellness plans & reimbursement and retirement programs. Available paid leave may include paid time off, parental leave and holiday pay. \n  The salary range published in this job posting is for US based locations only. Non-US based candidates interested in this position can email talent@generalassemb.ly for country-specific pay range details and benefits offered. \n \n  Unless otherwise noted, remote positions can be performed from the following approved General Assembly operating countries. \n  United States of America (states of operation may vary), Canada (provinces of operation may vary), United Kingdom, Australia, and Singapore.", "cleaned_desc": "", "techs": ""}, "0940da253ad3fe00": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n ET9sxrYjY1", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python expertise", "deep learning experience", "tensorflow"]}, "b9448de4c992cd87": {"terms": ["data science"], "salary_min": 70000.0, "salary_max": 85000.0, "title": "Sr. Supply Analyst - REMOTE", "company": "The Infosoft Group", "desc": "Description \n   \n Build your Career with an Industry Leader \n  Multi-Color Corporation and Fort Dearborn have merged and are now the world's largest prime label and packaging supplier. Join the new MCC and you will have the opportunity to become part of an organization that has been committed to excellence and industry leadership for over 110 years. \n  This position has ownership of all supply planning analytics activities and is responsible for ensuring the supply planning process delivers data integrity as a key input to the stakeholders such as supply planning, finance, and operations. He/she will focus on: \n \n  Assisting with content creation to support the monthly Supply Review as part of the S&OP/IBP process including the presentation of results based on data analytics and path for continuous improvement leveraging in data science expertise. \n  User data expert for Excel / Blue Yonder / JDA / BI / Power Query / VBA systems to deliver optimal modeling of the business and improve planner productivity by maximizing systems functionality. \n  Developing and fine tuning of supply plan using data driven insights  \n Developing and monitoring process metrics and reporting package to drive process performance, problem solving and improvement. \n  Identifying quantified risks within the demand plan and supply plan in order to develop appropriate counter measures for resolution. \n \n  Why work at MCC: \n \n  Compensation: $70K - $85K annually  \n Generous benefits package including medical, dental, vision, disability, life insurance and 401(k) \n  Paid Holidays: New Years, Memorial Day, Fourth of July, Labor Day, Thanksgiving, Day after Thanksgiving, Christmas Eve, Christmas Day, plus two floating Holidays \n \n  Responsibilities: \n \n  Generate supply plan across the planning horizon by utilizing customer prior shipments, POS data, knowledge of business unit trends, press speeds, capacity and upcoming promotions to guide decision making process by the Supply Planners. \n  Responsible for master data flows between ERP systems, data integrity management and process improvements. \n  Execute and maintain capacity data, press performance data, crewing models to optimize planning capabilities (Run Time/Make Ready Time/Down Time/Job Size, etc.) \n  Create and/or maintain statistical models for each item at each stocking location and for every customer within designated product lines to optimize supply plan. \n  Manage and review KPI performance and reporting through the Demand/Supply Planning Organization \n  Develop strategies for analysis. Build, collect, and transform data into information to draw conclusions, and to present and execute proposals supported by the analysis. \n  Problem solves the highest causes of error each month by researching errors, determining root cause, and driving for improvement. \n  Partner with IT to recommend, develop and enhance systems solutions aligned with business goals and company objectives within the Blue Yonder system. \n  Document business processes and standard work, assist to develop system solutions and validate system designs through rigorous testing of solutions. \n  Participates in special projects and performs other duties as assigned. \n \n  Qualifications: \n \n  Bachelor's Degree in Supply Chain Management, Engineering, Business Analytics, or related technical field \n  1-3 years of related experience in supply chain planning, management, and operations. \n  Proficiency in systems and analytics:  \n \n \n \n Advanced Excel (VLOOKUP, IF, SUMIFS, Pivot Tables, Graphing, etc.) \n \n  Power Query \n  VBA Macros \n  VBA User Forms \n \n  Microsoft Access \n  Blue Yonder/JDA \n  SQL or PostgreSQL (preferred, not required) \n \n \n \n  Strong Analytical/Problem Solving/Presentation Skills/ Statistical Modeling required \n  Ability to work in a high volume/fast paced environment \n  Must be able to process large amounts of data (90k+ SKU's), influence others and drive cross-functional alignment and be able to communicate at various levels within the Organization. \n  Good communication (written, verbal and presentation) and organizational skills. \n  Build strong, collaborative relationships with internal and external business partners. \n  Strong results orientation and work ethic; Able to work independently. \n  Ability to think and act strategically in the business while able to focus on day-to-day operational execution. \n  Proficiency with Excel, Access, PowerPoint, and other MS office tools is essential. \n  25% travel required to Plants, Customers and/or partner locations. \n  English proficiencyor working level required. \n \n  MCC welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. MCC is an equal opportunity employer. \n  #LI-REMOTE \n \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Multi-Color Corporation MCC \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   1 to 3 years", "cleaned_desc": "  Execute and maintain capacity data, press performance data, crewing models to optimize planning capabilities (Run Time/Make Ready Time/Down Time/Job Size, etc.) \n  Create and/or maintain statistical models for each item at each stocking location and for every customer within designated product lines to optimize supply plan. \n  Manage and review KPI performance and reporting through the Demand/Supply Planning Organization \n  Develop strategies for analysis. Build, collect, and transform data into information to draw conclusions, and to present and execute proposals supported by the analysis. \n  Problem solves the highest causes of error each month by researching errors, determining root cause, and driving for improvement. \n  Partner with IT to recommend, develop and enhance systems solutions aligned with business goals and company objectives within the Blue Yonder system. \n  Document business processes and standard work, assist to develop system solutions and validate system designs through rigorous testing of solutions. \n  Participates in special projects and performs other duties as assigned. \n \n  Qualifications: \n \n  Bachelor's Degree in Supply Chain Management, Engineering, Business Analytics, or related technical field \n  1-3 years of related experience in supply chain planning, management, and operations. \n  Proficiency in systems and analytics:  \n \n \n \n Advanced Excel (VLOOKUP, IF, SUMIFS, Pivot Tables, Graphing, etc.) \n \n  Power Query \n  VBA Macros \n  VBA User Forms   \n  Microsoft Access \n  Blue Yonder/JDA \n  SQL or PostgreSQL (preferred, not required) \n \n \n \n  Strong Analytical/Problem Solving/Presentation Skills/ Statistical Modeling required \n  Ability to work in a high volume/fast paced environment \n  Must be able to process large amounts of data (90k+ SKU's), influence others and drive cross-functional alignment and be able to communicate at various levels within the Organization. \n  Good communication (written, verbal and presentation) and organizational skills. \n  Build strong, collaborative relationships with internal and external business partners. \n  Strong results orientation and work ethic; Able to work independently. \n  Ability to think and act strategically in the business while able to focus on day-to-day operational execution. \n  Proficiency with Excel, Access, PowerPoint, and other MS office tools is essential. \n  25% travel required to Plants, Customers and/or partner locations. \n  English proficiencyor working level required. \n \n  MCC welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. MCC is an equal opportunity employer. \n  #LI-REMOTE \n \n ", "techs": ["blue yonder/jda", "sql", "postgresql", "advanced excel", "power query", "vba macros", "vba user forms", "microsoft access"]}, "dec079d73fe6f980": {"terms": ["data science"], "salary_min": 100000.0, "salary_max": 130000.0, "title": "Full-Stack Developer (FT)", "company": "Mesh Plus Plus", "desc": "Mesh++ designs solar- and battery-powered WiFi routers with a dedicated wireless backhaul for temporary or permanent outdoor installations. Our intention is to make last-mile infrastructure fully wireless, allowing for simple temporary installations and non-intrusive permanent ones. Mesh++ has completed installations over underserved communities all over the world with the goal of developing a platform that enables anyone to bring internet access to their community.\n  \n \n \n  We are looking for a Full-Stack Developer to help build our next-generation software and data management platform. This includes rapid ideation, prototyping, and maintaining a feedback loop with customers and stakeholders. As an early startup, tasks outside of the immediate job description may be required occasionally. Examples of projects include a sophisticated debug interface, an advanced network configuration interface to supplement our existing simple one, minor improvement of our mobile app and dashboard, and the fine-tuning of an existing billing and authorization system. We seek individuals who are enthusiastic to take on new responsibilities as we continue to grow.\n  \n \n \n  Examples of our existing applications are available on the App and Play stores under the name \u2018Mesh++\u2019 and online at meshplusplus.com, dashboard.meshplusplus.com, and design-tool.meshplusplus.com.\n  \n \n \n  This is a paid position for which we are open to either full-time or contract, with a salary of $100k-130k annual depending on experience, and equity available at a 40% discount. Full-time benefits include full Gold PPO health, vision, and dental insurance. This position is ideally in-person at our office in West Loop, Chicago but we will also consider remote applicants.\n  \n \n \n  Responsibilities: \n \n \n  Leading feature implementation \n  Rapid development and testing \n  Design verification with customers \n  Long-term improvements \n \n \n \n  Minimum Qualifications: \n \n \n  Experience designing simplified products for a non-technical audience \n  Experience developing both mobile and web applications \n  Ability to design intuitive user interfaces \n  Proficiency in Javascript \n  Proficiency in computer networking \n  Experience working with wireless networking products \n \n \n \n  Preferred Qualifications: \n \n \n  Experience maintaining and displaying large-scale datasets \n  Experience with basic data science \n  Experience with React Native \n  Familiarity with OpenWRT and RADIUS servers \n  Experience working with PostgreSQL \n \n \n  Please contact danny@meshplusplus.com with your resume or questions.", "cleaned_desc": " \n \n  Preferred Qualifications: \n \n \n  Experience maintaining and displaying large-scale datasets \n  Experience with basic data science \n  Experience with React Native \n  Familiarity with OpenWRT and RADIUS servers ", "techs": ["react native", "openwrt", "radius servers"]}, "1ca0a0ad8785e265": {"terms": ["data science", "mlops"], "salary_min": 99174.61, "salary_max": 125577.16, "title": "DevOps Engineer", "company": "The Infosoft Group", "desc": "Codeworks is an IT Services firm in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships.\n   \n \n \n  Who We're Looking For !...\n    \n A DevOps Engineer for a Direct Hire opportunity with our client. This is a 100% remote role! \n \n \n \n  Practice Overview \n  Our client is the largest and fastest growing on-site radiology practice in the US. They are an innovative practice focused on transforming how radiologists provide consistently exceptional services to hospitals, imaging centers, referring physicians and patients.?With their state-of-the art clinical technology, specialized expertise, access to capital, and retention of top physician talent, our client reliably exceeds the expectations of our clients, patients, and partners.?We serve our clients with an operational focus, and, above all, a commitment to quality patient care. Their mission is To Transform Radiology.\n    \n \n \n Position Summary \n  Our client utilizes custom high performant cloud-native applications to deliver AI results in the clinical workflow. We are deployment, operations and maintenance of cloud-native applications and infrastructure using modern tools and techniques.\n    \n \n \n Position Duties And Responsibilities  Manage a team of DevOps engineers ensuing that work is being completed timely, correctly, and with high quality. Utilize agile tools (JIRA) to accurately reflect status of assigned tasks. \n \n \n  Communicate task and project status to management and stakeholders \n  Actively promote the career growth of the engineers \n  Develop processes and standards that adhere to industry best practices and proper security controls \n  Work with senior engineers and data scientists to develop and maintain a robust DevOps pipeline \n  Work with engineering and product QA to develop automated deployments to development and test environments \n  Work with 3rd party vendors to install and configure their applications and products in the client's cloud environment \n  Participate in the agile development process consisting of task identification, backlogs, estimation, grooming, and daily standups \n  Participate in the security analysis for all internal and external systems in the various environments. Adhere to established security best practices. \n  Perform infrastructure operations and maintenance for the engineering and data science teams \n \n \n  Desired Professional Skills And Experience \n \n   \n \n \n 3+ years managing and leading a team \n  Experience with GCP \n \n \n  A strong passion for infrastructure as code and associated automation and provisioning tools \n  Experience delivering infrastructure and supporting services \n  Experience with developing and maintaining CI/CD environments \n  Strong systems engineering fundamentals (networking, storage, operating systems) \n  Very good knowledge of Docker and Kubernetes \n  Experience with relational and NoSQL databases \n  Experience with configuration file languages (YAML) \n  Extensive experience working in agile environment where constant collaboration is critical \n  Strong written and verbal communication skills \n \n \n  EXTRA CREDIT \n \n   \n \n \n Experience with Azure or AWS \n  Experience with large datasets and proper PHI handling \n  Familiarity with ML and DevOps \n \n \n  About CODEWORKS :\n     Headquartered in Milwaukee, WI with an office in Madison, WI-Codeworks has over 25+ years of experience serving Fortune 1000 companies in Wisconsin as well as our client's national locations. Our recruiting team is extremely good at evaluating, advising, and connecting IT professionals with new opportunities that will satisfy their expectations both in salary and opportunity for growth.\n   \n \n    For more information\n   \n \n \n  For priority career/job posting updates, please follow us on Twitter: @CodeworksIT \n \n \n \n  #LI-KH \n \n \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Codeworks, L.L.C. \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   3+ years", "cleaned_desc": "  Communicate task and project status to management and stakeholders \n  Actively promote the career growth of the engineers \n  Develop processes and standards that adhere to industry best practices and proper security controls \n  Work with senior engineers and data scientists to develop and maintain a robust DevOps pipeline \n  Work with engineering and product QA to develop automated deployments to development and test environments \n  Work with 3rd party vendors to install and configure their applications and products in the client's cloud environment \n  Participate in the agile development process consisting of task identification, backlogs, estimation, grooming, and daily standups \n  Participate in the security analysis for all internal and external systems in the various environments. Adhere to established security best practices. \n  Perform infrastructure operations and maintenance for the engineering and data science teams \n \n \n  Desired Professional Skills And Experience \n \n   \n \n \n 3+ years managing and leading a team \n  Experience with GCP \n \n \n  A strong passion for infrastructure as code and associated automation and provisioning tools \n  Experience delivering infrastructure and supporting services \n  Experience with developing and maintaining CI/CD environments    Strong systems engineering fundamentals (networking, storage, operating systems) \n  Very good knowledge of Docker and Kubernetes \n  Experience with relational and NoSQL databases \n  Experience with configuration file languages (YAML) \n  Extensive experience working in agile environment where constant collaboration is critical \n  Strong written and verbal communication skills \n \n \n  EXTRA CREDIT \n \n   \n \n \n Experience with Azure or AWS \n  Experience with large datasets and proper PHI handling \n  Familiarity with ML and DevOps \n \n \n  About CODEWORKS :\n     Headquartered in Milwaukee, WI with an office in Madison, WI-Codeworks has over 25+ years of experience serving Fortune 1000 companies in Wisconsin as well as our client's national locations. Our recruiting team is extremely good at evaluating, advising, and connecting IT professionals with new opportunities that will satisfy their expectations both in salary and opportunity for growth.\n   \n \n    For more information", "techs": ["gcp", "docker", "kubernetes", "yaml", "azure", "aws", "ml", "devops"]}, "2bd10fb1dd406f22": {"terms": ["data science", "machine learning engineer"], "salary_min": 124775.78, "salary_max": 157993.94, "title": "Sr AI Engineer", "company": "NetDocuments", "desc": "NetDocuments is the world\u2019s #1 trusted cloud-based content management and productivity platform that helps legal professionals do their best work. We strive to win together through passionate hard work, exploring new things and recognizing every interaction matters.\n  \n \n   NetDocuments provides rewarding career growth in an inclusive, diverse environment where employees are encouraged to openly contribute creative ideas and innovation, backed by supportive peers and leadership \n   working together  to achieve our goals as a unified team.\n  \n \n   At our core, we are dedicated to empowering our employees to drive successful business outcomes and better user experiences for our customers and partners. Our customer-centric approach and employee enablement has allowed us to enjoy many accolades, including being named among the 2022 list of \n   Inc. Magazine\u2019s 5000 Fastest-Growing Private Companies in America . Other recent awards include:\n  \n \n  2023 National Top Workplaces \n  Two-time winner (2021, 2022) Top Workplace in the US by the Salt Lake Tribune \n  Two-time winner (2021, 2022) Utah\u2019s Best Companies to Work for by Utah Business magazine \n  2022 Employee Appreciation and Employee Well Being by the Salt Lake Tribune \n  2022 Top Workplace in the US by the Salt Lake Tribune for the Technology Industry \n  2022 Top Workplace in the US by the Salt Lake Tribune for Compensation & Benefits \n  2022 Top Workplace in the US by the Salt Lake Tribune for Work-Life Flexibility \n  2021 Top Workplace in the US by the Salt Lake Tribune for Remote Work \n  2021 Top Workplace in the US by the Salt Lake Tribune for Top Managers \n  2021 Top Workplace in the US by the Salt Lake Tribune for Compensation \n  2021 Coolest Tech Companies to Work for by Dev Mountain \n \n \n \n  NetDocuments is a hybrid, remote-friendly workplace. Come join our team and \n   work inspired  each day!\n  \n \n  About the opportunity: \n \n \n   NetDocuments is seeking a Sr Artificial Intelligence/Machine Learning Engineer to create applications and services on existing LLMs, integrating capabilities with Azure Cognitive Services. The role will build scalable and efficient infrastructure and APIs to support AI integrations and facilitate the deployment and execution of machine learning models. The Sr AI/ML Engineer will report to the Manager of Engineering.\n  \n \n  What your contributions will be: \n \n \n  Develops new AI/ML integrated services using a combination of microservices, Azure Cognitive Services, generative AI, NLP, and other technologies as appropriate \n  Explores and experiments with emerging AI techniques, frameworks, and architectures to improve service performance and capabilities \n  Designs and develops software components and modules that enable seamless integration of machine learning models into existing applications and services \n  Implements data preprocessing and feature engineering pipelines to ensure the compatibility and quality of input data for machine learning models \n  Documents architectural designs through diagrams and logical flows \n  Strategizes with staff and principal engineers as well as product experts on where AI/ML services should evolve \n  Builds and tests new AI/ML service designs, formulations, materials, and systems for compliance with quality and/or performance standards \n  Interprets functional/non-functional requirements for AI/ML solutions \n  Collaborates across software engineering teams to integrate AI/ML solutions into existing products and deploy them at scale \n  Tests new applications and services in a variety of environments \n  Maintains and modifies existing applications and services without supervision \n  Estimates and plans out work through user stories and tasks \n  Determines operational feasibility by providing analysis, problem definition, requirements, solution development and proposed solutions \n  Participates in team exercises for collaboration \n  Guides and mentors team development efforts towards successful project delivery \n  Updates job knowledge by studying state-of-the-art development tools, programming techniques and computing equipment \n  Provides information by collecting, analyzing, and summarizing development and service issues \n  Accomplishes engineering and organization mission by completing related results as needed \n  Support and develop software engineers by providing advice, coaching and educational opportunities \n  Grows engineering teams by participating in interviewing, recruiting, and hiring \n  Stays on the leading edge of AI and ML technologies, communicating and guiding other engineers on these technologies \n  Displays passion about evolving AI and ML technologies \n  Understands business needs and know how to create the tools to manage them \n  This position will consist of 90% in the code and 10% mentoring other AI/ML engineers \n  Other duties as assigned \n \n \n \n  What you will bring to the team: \n \n \n  Strategic software development and design in the AI/ML space \n  Azure Cognitive Services experience \n  Research and analytical thinking skills \n  Collaboration within a team environment \n  Independent work with minimal oversight \n  Eagerness to learn new technologies \n  Business orientation and use case focus \n  Self-directed \n  High energy \n  Detail-orientation \n  Communication skills \n \n \n \n  What you will need for success: \n \n \n  Bachelor\u2019s degree or higher in Information Systems, Computer Science, or a related field or equivalent on-the-job experience \n  1-2 years in leading/mentoring a team of 5+ \n  Minimum 5 years of experience as a backend developer working with required technological stack listed below, in order of priority: \n \n \n  LLM AI skillsets and experience \n  Integration with AI/ML capabilities utilizing Azure Cognitive Services \n  Microservices \n  Backend/Platform team experience \n  Azure \n  Azure PaaS offerings \n  Object Oriented Programming \n \n \n \n  Priority consideration for applicants who have: \n \n \n  Model Hosting \n  Other AI integrations outside of Azure (Bard, OpenAI, etc) \n \n \n \n  Ideally you will have: \n \n \n  Experience in the Legal Industry \n \n \n \n  What you will receive: \n \n \n  90% healthcare premiums company covered \n  HSA company contribution \n  401K match at 4% with no vesting period \n  Twice a year merit increases \n  Flexible time off typically 3 to 4 weeks a year, not including the 9 paid holidays \n  Authenticity and accountability from leadership \n  Connection, access, and mentorship from exceptional leaders \n  Growing company with opportunities for advancement \n \n \n \n  NetDocuments is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. All employment decisions are based on business needs, job requirements, individual qualifications, without regard to race, color, religion, sex, (including pregnancy), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity and/or expression, military and veteran status, or any other status protected by laws or regulations in the locations where we operate. NetDocuments believes diversity and inclusion among our employees is critical to our success, and we are committed to providing a work environment free of discrimination and harassment.", "cleaned_desc": "   work inspired  each day!\n  \n \n  About the opportunity: \n \n \n   NetDocuments is seeking a Sr Artificial Intelligence/Machine Learning Engineer to create applications and services on existing LLMs, integrating capabilities with Azure Cognitive Services. The role will build scalable and efficient infrastructure and APIs to support AI integrations and facilitate the deployment and execution of machine learning models. The Sr AI/ML Engineer will report to the Manager of Engineering.\n  \n \n  What your contributions will be: \n \n \n  Develops new AI/ML integrated services using a combination of microservices, Azure Cognitive Services, generative AI, NLP, and other technologies as appropriate \n  Explores and experiments with emerging AI techniques, frameworks, and architectures to improve service performance and capabilities \n  Designs and develops software components and modules that enable seamless integration of machine learning models into existing applications and services \n  Implements data preprocessing and feature engineering pipelines to ensure the compatibility and quality of input data for machine learning models \n  Documents architectural designs through diagrams and logical flows \n  Strategizes with staff and principal engineers as well as product experts on where AI/ML services should evolve \n  Builds and tests new AI/ML service designs, formulations, materials, and systems for compliance with quality and/or performance standards \n  Interprets functional/non-functional requirements for AI/ML solutions \n  Collaborates across software engineering teams to integrate AI/ML solutions into existing products and deploy them at scale \n  Tests new applications and services in a variety of environments \n  Maintains and modifies existing applications and services without supervision \n  Estimates and plans out work through user stories and tasks \n  Determines operational feasibility by providing analysis, problem definition, requirements, solution development and proposed solutions \n  Participates in team exercises for collaboration    Detail-orientation \n  Communication skills \n \n \n \n  What you will need for success: \n \n \n  Bachelor\u2019s degree or higher in Information Systems, Computer Science, or a related field or equivalent on-the-job experience \n  1-2 years in leading/mentoring a team of 5+ \n  Minimum 5 years of experience as a backend developer working with required technological stack listed below, in order of priority: \n \n \n  LLM AI skillsets and experience \n  Integration with AI/ML capabilities utilizing Azure Cognitive Services \n  Microservices \n  Backend/Platform team experience \n  Azure \n  Azure PaaS offerings \n  Object Oriented Programming \n \n \n \n  Priority consideration for applicants who have: \n \n ", "techs": ["azure cognitive services", "generative ai", "nlp", "microservices", "llm ai skillsets", "azure paas offerings", "object oriented programming"]}, "947aea484d35ae20": {"terms": ["data science"], "salary_min": 117518.0, "salary_max": 152771.0, "title": "Supervisory IT Program Manager", "company": "The Infosoft Group", "desc": "Duties \n   This is not a bargaining unit position.       Please read this public notice in its entirety before submitting your application.       Vacancies may not presently exist but may become available at any point during the opening period of this vacancy announcement. We will not review applicant resumes until there is a request to fill a vacancy.    You are applying to a public notice to fill current and future vacancies. Please note, that there may or may not be actual/projected vacancies when you submit your application. Your resume and supporting documentation will be retained with other applicants and reviewed as vacancies occur. You will not receive a notice regarding your application's status other than the initial acknowledgment until a request is received to fill a position.     This announcement will remain open until September 29, 2023.  The cut-off date is  January 20, 2023 , OR the point at which the first 100 applications are received, whichever comes first. Applications submitted after  January 20, 2023  may not receive consideration. In addition, due to the potential of a high volume of applicants, not all applicants may receive consideration.    After the initial cut-off period, once additional requests to fill a vacancy are received, applications will be reviewed in increments of 100 applications  in date order .     Note : Submitting multiple applications  will  change the order in which your application is reviewed.    We will refer qualified applicants to the selecting official for consideration. The organization's hiring needs will determine the referral of additional applicants. Applicants will be notified about their application's status if referred or if we fill all vacancies.    This position is primarily aligned to the following NICE Cybersecurity Workforce Framework work roles:  \n \n OPM Cyber Code 804 - IT Investment/Portfolio Manager \n OPM Cyber Code 801- Program Manager \n For more information about these work roles, where they fit within the larger Cyber Workforce, and how they can support your unique career journey, please visit the Cyber Career Pathways tool on the National Initiative for Cybersecurity Careers and Studies website: \n   \n \n Do you want an opportunity to improve the lives of millions of Veterans? Use your technical expertise to develop and deliver cutting-edge digital capabilities to Veterans and those who care for them! \n \n  We're looking far experts in data science, software engineering, product design, product management, and user experience (UX) who are passionate about using their skills to ensure Veterans and their families receive seamless care and services to join our team of technologists. Our technologists help develop cutting-edge technology, advocate for Veteran needs, and ensure the Department of Veterans Affairs can provide Veterans home loans, G.I. Bill, healthcare, and other services.\n   \n  We are committed to building a team that reflects the communities we serve and strongly encourage\n    people of color, LGBTQ+ individuals, women, minorities, people with disabilities, system-impacted people, Veterans, and people of all ages to apply.\n   \n \n About Our Technologist Teams \n \n  If selected, technologists will provide service in our Office of Information Technology (OIT).\n   \n  You can work from home anywhere in the United States, or at VA headquarters in Washington, D.C.\n   \n  At OIT, you will be working on a wide variety of projects that are relevant to your specific area of expertise. Possible projects could include: \n   \n Working on small, cross-functional teams with healthcare, education, and financial analysts to perform technical investigative research for projects that affect millions of Veterans. \n Analyzing computational models implemented by financial institutions that inform what benefits Veterans and their families are eligible for. Ex. Healthcare, home loan guarantees, and educational benefits \n Researching how electronic healthcare data can be utilized to deliver better care and services to Veterans. \n Anticipating risks and acting fast to support Veterans when IT systems fail. \n Serve as a technical expert and strategic advisor to further the Bureau's investigative and policymaking goals. \n \n Work Schedule : Monday - Friday, 8:00 am - 4:30 pm\n   \n Compressed/Flexible Schedule : Available\n   \n Duty Location Status : Will work remotely from home\n   \n Position Description Title/PD# : Supervisory IT Program Manager/ PD18457A\n   \n Relocation/Recruitment Incentives : Not authorized\n   \n Financial Disclosure Report : Not required\n   \n Physical Demands : The work is sedentary and does not require any special physical effort. Some work may require walking and standing in conjunction with travel and attendance at meetings and conferences away from the work site. The work often requires long hours to meet project deadlines and to devise corrective action and solutions to unexpected technical and/or management crises resulting in sometimes highly stressful work situations. \n  \n \n  Requirements Conditions of Employment \n   \n You must be a U.S. citizen to apply for this job. \n Selectees are subject to a background/suitability investigation. \n Designated and/or random drug testing may be required \n Selectees may be required to serve a probationary period. \n Selective Service Registration is required for males born after 12/31/1959. \n A complete application package, i.e., Resume, Transcripts, etc., as required by the job announcement. \n Selected applicants will be required to complete an online onboarding process. \n Participation in the Seasonal Influenza Prevention Program for VHA Health Care Personnel (HCP) is a requirement for all Department of Veterans Affairs HCP. \n All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA. \n Must be proficient in written and spoken English. \n Pre-employment physical evaluation may be required. \n Applicants selected for this position may be required to serve a one-year supervisory probationary period. \n Failure to successfully complete the supervisory probationary period will result in the employee being reassigned to a position in the agency of no lower grade and pay than the one the employee left to accept the supervisory or managerial position. \n \n \n   Qualifications \n    \n What We're Looking For \n \n  We want people excited about building technology and embracing the VA's mission.\n     \n  We are looking for skilled technologists with experience in any of the following areas: \n     \n Data Science & Strategy : Examine large datasets using scripting languages or modern statistical analyses and computational languages (e.g., Python, R, SQL, Azure Synapse, Power BI, Databricks, Azure ML, Kubernetes, Oracle, Enterprise Data Lake, Azure Data Factory and hosting solutions on cloud environments to include AWS and Azure) to provide seamless care and services to Veterans and their caregivers. Use artificial intelligence (AI) and machine learning technologies, logistic and linear regression models, or natural language processing (NLP) to detect, anticipate and prevent potential Veteran harm or inability to access VA benefits and services. \n Software Engineering : Design, create, and test systems to dig into how to best deliver IT products and services. Use front-end, back-end, and full-stack engineering to develop and support new technical strategies that could help effectively serve Veterans and VA employees. This could include API design and development, furthering open-source policies while prioritizing maintainability and software reusability in all product development. Programming languages, e.g., Python, SQL, R, Java, JS, Go, Scala, C, C++, Julia, or MatLab. \n Product Management:  Coordinate across stakeholders and use agile or lean approaches to align cross-functional teams around a common vision or strategy and user needs. Monitor Veteran and market trends and develop environmental analyses. Use expertise to advance the use of emerging technologies within government. \n Design & UX:  A user experience designer at Veteran's Affairs will have a direct impact on the VA's ability to provide its customers - Veterans of the US military and other members of the public that support those Veterans - with an exceptional customer experience, comparable with the experience they have with top tier commercial products and services. They may work on public-facing, clinical, or staff facing initiatives in various design practice areas. A user experience designer can advance through multiple levels in their design career at VA and have a significant impact on improving VA products, processes, and best practices. \n \n To qualify for this position, applicants must meet all requirements when a request is received to fill a vacancy. \n \n \n Experience  - Experience must be IT related; the experience may be demonstrated by paid or unpaid experience and/or completion of specific, intensive training (for example, IT certification), as appropriate.\n     \n  For all positions individuals must have IT-related experience demonstrating each of the four competencies listed below. The employing agency is responsible for identifying the specific level of proficiency required for each competency at each grade level based on the requirements of the position being filled. \n     \n \n Attention to Detail  - Is thorough when performing work and conscientious about attending to detail. \n \n \n Customer Service  - Works with clients and customers (that is, any individuals who use or receive the services or products that your work unit produces, including the general public, individuals who work in the agency, other agencies, or organizations outside the Government) to assess their needs, provide information or assistance, resolve their problems, or satisfy their expectations; knows about available products and services; is committed to providing quality products and services. \n \n \n Oral Communication  - Expresses information (for example, ideas or facts) to individuals or groups effectively, taking into account the audience and nature of the information (for example, technical, sensitive, controversial); makes clear and convincing oral presentations; listens to others, attends to nonverbal cues, and responds appropriately. \n \n \n Problem Solving  - Identifies problems; determines accuracy and relevance of information; uses sound judgment to generate and evaluate alternatives, and to make recommendations. \n \n \n AND \n \n \n Specialized Experience:  You must have one year of specialized experience equivalent to at least the next lower grade GS-14 in the normal line of progression for the occupation in the organization. Specialized experience is defined as directing operational activities with assigned portfolio to ensure IT project goals are met; evaluating impact of changes in business needs on IT policy and projects; conducting feasibility studies; overmation papers.\n     \n  Such experience is typically gained in the IT field or through the performance of work where the primary concern is IT.\n     \n  Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n     \n  , federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.\n     \n  To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.\n     \n \n Note : \n     A full year of work is considered to be 35-40 hours of work per week. Part-time experience will be credited on the basis of time actually spent in appropriate activities. Applicants wishing to receive credit for such experience must indicate clearly the nature of their duties and responsibilities in each position and the number of hours a week spent in such employment.  For more information on these qualification standards, please visit OPM's web site at . \n    \n \n \n   Education \n    There is no education substitute for the GS-15 level.     Current openings    New and emerging technologies are changing how preexisting products and services work or creating new ones. We need more technologists serving in the ranks of our technology teams. These positions are vital in helping us understand the constantly evolving needs of Veterans and their families.    Technologists will work alongside financial analysts, healthcare researchers, human resources experts, and more to provide quality IT products and services using various technical or design methods to inform how best to deliver care and benefits to Veterans. Technologists will support the cross-pollination of key ideas in emerging technology fields to ensure the federal government can keep pace with the private sector.  \n \n \n   Additional information \n    \n \n Current openings    New and emerging technologies are changing how preexisting products and services work or creating new ones. We need more technologists serving in the ranks of our technology teams. These positions are vital in helping us understand the constantly evolving needs of Veterans and their families.    Technologists will work alongside financial analysts, healthcare researchers, human resources experts, and more to provide quality IT products and services using various technical or design methods to inform how best to deliver care and benefits to Veterans. Technologists will support the cross-pollination of key ideas in emerging technology fields to ensure the federal government can keep pace with the private sector.    The  Interagency Career Transition Assistance Plan (ICTAP)  and  Career Transition Assistance Plan (CTAP)  provide eligible displaced VA competitive service employees with selection priority over other candidates for competitive service vacancies. To be well-qualified, applicants must possess experience that exceeds the minimum qualifications of the position including all selective factors if applicable, and must be proficient in most of the requirements of the job. Information about ICTAP and CTAP eligibility is on OPM's Career Transition Resources website which can be found at .     Receiving Service Credit for Earning Annual (Vacation) Leave:  Federal Employees earn annual leave at a rate (4, 6 or 8 hours per pay period) which is based on the number of years they have served as a Federal employee. VA may offer newly-appointed Federal employee's credit for their job-related non-federal experience or active duty uniformed military service. This credited service can be used in determining the rate at which they earn annual leave. Such credit must be requested and approved prior to the appointment date and is not guaranteed. \n  OPM General Schedule (GS) & Locality Pay Tables:  The salary range listed reflects the GS base rate (not including locality). Upon selection, the salary will be adjusted to include locality. Please see .     Superior Qualifications and Special Needs Pay-Setting:  Agencies may set the rate of basic pay of a newly-appointed employee at a rate above the minimum rate of the appropriate General Schedule (GS) grade because of- \n \n \n the superior qualifications of the candidate; or \n \n \n a special need of the agency for the candidate's services. \n \n \n An agency must approve each determination to use this authority  before the employee enters on duty - the determination cannot be made retroactively - and is not guaranteed.  . \n  This job opportunity announcement may be used to fill additional vacancies. \n  If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an . \n \n \n \n \n \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. .  \n \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n \n \n \n \n  Required Documents \n   \n Documents Accepted:   \n \n  DD-214/ Statement of Service \n  Disability Letter (VA) \n  Resume \n  Separation Notice (RIF) \n  SF-50/ Notification of Personnel Action \n \n  Documents Required:\n    \n \n Resume \n \n  Please review the above list(s) to ensure you have included all necessary documents required for your application.Not every applicant will require the same documents, therefore it is the applicants responsibility to ensure that their application package includes all necessary documents to determine qualifications and eligibility for appointment, such as a copy of your SF-50, transcript, ICTAP/CTAP documentation (for displaced Federal employees).\n    You will not be contacted for additional information.  Applicants will be deemed ineligible if supporting documentation is not submitted.\n    \n \n Veterans' Preference:  Since the Direct-Hire Recruitment Authority is being used, traditional Veterans' Preference rules do not apply. Qualified veterans will, however, be given full consideration for this position.\n    \n \n Applications are accepted online.  Applying online will allow you to review and track the status of your application. \n   \n \n \n  How to Apply \n   \n All applicants are encouraged to apply online.     To apply for this position,  you must complete the occupational questionnaire and submit the documentation specified in the Required Documents section. The complete application package must be submitted by 11:59 PM (EST) on 09/29/2023 to receive consideration. To preview the questionnaire click .    1. To begin, click  Apply Online  to create a USAJOBS account or log in to your existing account. Follow the prompts to select your USAJOBS resume and/or other supporting documents and complete the occupational questionnaire.    2. Click  Submit My Answers  to submit your application package.     NOTE:  It is your responsibility to ensure your responses and appropriate documentation is submitted prior to the closing date. To verify your application is complete, log into your USAJOBS account, , select the  Application Status  link and then select the M ore Information  link for this position. The Details page will display the status of your application, the documentation received and processed, and any correspondence the agency has sent related to this application. Your uploaded documents may take several hours to clear the virus scan process.     To return to an incomplete application , log into your USAJOBS account and click  Update Application  in the vacancy announcement. You must re-select your resume and/or other documents from your USAJOBS account or your application will be incomplete. \n \n \n   Agency contact information VHA National Recruitment Center \n    \n \n     Phone \n      Email \n     \n \n \n     Address \n      \n \n DAS Information and Technology - 103 \n \n 810 Vermont Avenue NW \n \n Washington, DC 20420 \n \n US  \n \n \n \n Next steps \n   \n After the vacancy announcement closes, applicants are evaluated to ensure qualification and eligibility requirements are met. After the review is complete, a referral certificate(s) is issued and applicants will be notified of their status by email.  \n \n \n \n  Fair & Transparent \n   The Federal hiring process is set up to be fair and transparent. Please read the following guidance.   \n \n  The United States Government does not discriminate in employment on the \n   basis of race, color, religion, sex (including pregnancy and gender \n   identity), national origin, political affiliation, sexual orientation, \n   marital status, disability, genetic information, age, membership in an \n   employee organization, retaliation, parental status, military service, \n   or other non-merit factor.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Clement J. Zablocki VA Medical Center, Department of Veterans Affairs \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Work Hours (i.e. shift)\n   \n \n   Full-time -\n   \n \n \n \n   Salary and Benefits\n   \n \n   $117,518 - $152,771 per year\n   \n \n \n \n   Required Experience\n   \n \n   1+ years\n   \n \n \n \n   Required Security Clearance\n   \n \n   Other Clearance", "cleaned_desc": " All applicants tentatively selected for VA employment in a testing designated position are subject to urinalysis to screen for illegal drug use prior to appointment. Applicants who refuse to be tested will be denied employment with VA. \n Must be proficient in written and spoken English. \n Pre-employment physical evaluation may be required. \n Applicants selected for this position may be required to serve a one-year supervisory probationary period. \n Failure to successfully complete the supervisory probationary period will result in the employee being reassigned to a position in the agency of no lower grade and pay than the one the employee left to accept the supervisory or managerial position. \n \n \n   Qualifications \n    \n What We're Looking For \n \n  We want people excited about building technology and embracing the VA's mission.\n     \n  We are looking for skilled technologists with experience in any of the following areas: \n     \n Data Science & Strategy : Examine large datasets using scripting languages or modern statistical analyses and computational languages (e.g., Python, R, SQL, Azure Synapse, Power BI, Databricks, Azure ML, Kubernetes, Oracle, Enterprise Data Lake, Azure Data Factory and hosting solutions on cloud environments to include AWS and Azure) to provide seamless care and services to Veterans and their caregivers. Use artificial intelligence (AI) and machine learning technologies, logistic and linear regression models, or natural language processing (NLP) to detect, anticipate and prevent potential Veteran harm or inability to access VA benefits and services. \n Software Engineering : Design, create, and test systems to dig into how to best deliver IT products and services. Use front-end, back-end, and full-stack engineering to develop and support new technical strategies that could help effectively serve Veterans and VA employees. This could include API design and development, furthering open-source policies while prioritizing maintainability and software reusability in all product development. Programming languages, e.g., Python, SQL, R, Java, JS, Go, Scala, C, C++, Julia, or MatLab. \n Product Management:  Coordinate across stakeholders and use agile or lean approaches to align cross-functional teams around a common vision or strategy and user needs. Monitor Veteran and market trends and develop environmental analyses. Use expertise to advance the use of emerging technologies within government. \n Design & UX:  A user experience designer at Veteran's Affairs will have a direct impact on the VA's ability to provide its customers - Veterans of the US military and other members of the public that support those Veterans - with an exceptional customer experience, comparable with the experience they have with top tier commercial products and services. They may work on public-facing, clinical, or staff facing initiatives in various design practice areas. A user experience designer can advance through multiple levels in their design career at VA and have a significant impact on improving VA products, processes, and best practices. \n \n To qualify for this position, applicants must meet all requirements when a request is received to fill a vacancy. \n \n \n Experience  - Experience must be IT related; the experience may be demonstrated by paid or unpaid experience and/or completion of specific, intensive training (for example, IT certification), as appropriate.\n     \n  For all positions individuals must have IT-related experience demonstrating each of the four competencies listed below. The employing agency is responsible for identifying the specific level of proficiency required for each competency at each grade level based on the requirements of the position being filled. \n     \n \n Attention to Detail  - Is thorough when performing work and conscientious about attending to detail. \n \n \n Customer Service  - Works with clients and customers (that is, any individuals who use or receive the services or products that your work unit produces, including the general public, individuals who work in the agency, other agencies, or organizations outside the Government) to assess their needs, provide information or assistance, resolve their problems, or satisfy their expectations; knows about available products and services; is committed to providing quality products and services. \n \n \n Oral Communication  - Expresses information (for example, ideas or facts) to individuals or groups effectively, taking into account the audience and nature of the information (for example, technical, sensitive, controversial); makes clear and convincing oral presentations; listens to others, attends to nonverbal cues, and responds appropriately. \n \n \n Problem Solving  - Identifies problems; determines accuracy and relevance of information; uses sound judgment to generate and evaluate alternatives, and to make recommendations. \n \n \n AND \n \n \n Specialized Experience:  You must have one year of specialized experience equivalent to at least the next lower grade GS-14 in the normal line of progression for the occupation in the organization. Specialized experience is defined as directing operational activities with assigned portfolio to ensure IT project goals are met; evaluating impact of changes in business needs on IT policy and projects; conducting feasibility studies; overmation papers.\n     \n  Such experience is typically gained in the IT field or through the performance of work where the primary concern is IT.\n     \n  Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religions; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n     \n  , federal employees are assumed to have gained experience by performing duties and responsibilities appropriate for their official series and grade level as described in their position description. Experience that would not normally be part of the employee's position is creditable when documented by satisfactory evidence (e.g., a memorandum from the manager, human resources director, or official documentation such as SF-52, SF-50 documenting an official detail/assignments, or other comparable documentation). The documentation must indicate whether the employee performed the duties full time or, if part-time, the percentage of times the employee performed the additional duties.\n     \n  To receive credit for experience in your resume that is not within the official series and grade level of your position, you must provide official documentation of such experience as indicated above.\n     \n \n Note : ", "techs": ["python", "r", "sql", "azure synapse", "power bi", "databricks", "azure ml", "kubernetes", "oracle", "enterprise data lake", "azure data factory", "aws", "azure", "api design and development", "java", "js", "go", "scala", "c", "c++", "julia", "matlab"]}, "e4f70a950b524fc3": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml"]}, "5b8fb0d028590866": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": null, "salary_max": null, "title": "Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)\n  \n  Sr Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "python", "c/c++", "ai", "ml", "frameworks", "public cloud", "aws", "azure", "gcp", "security", "availability", "performance", "scalability", "cost", "gpu clusters", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting", "fine-tuning", "research publications", "neural networks", "distributed training", "sysml"]}, "9700324cab51712f": {"terms": ["data science", "machine learning engineer"], "salary_min": 124775.78, "salary_max": 157993.94, "title": "Sr AI Engineer", "company": "NetDocuments", "desc": "NetDocuments is the world\u2019s #1 trusted cloud-based content management and productivity platform that helps legal professionals do their best work. We strive to win together through passionate hard work, exploring new things and recognizing every interaction matters.\n  \n \n   NetDocuments provides rewarding career growth in an inclusive, diverse environment where employees are encouraged to openly contribute creative ideas and innovation, backed by supportive peers and leadership \n   working together  to achieve our goals as a unified team.\n  \n \n   At our core, we are dedicated to empowering our employees to drive successful business outcomes and better user experiences for our customers and partners. Our customer-centric approach and employee enablement has allowed us to enjoy many accolades, including being named among the 2022 list of \n   Inc. Magazine\u2019s 5000 Fastest-Growing Private Companies in America . Other recent awards include:\n  \n \n  2023 National Top Workplaces \n  Two-time winner (2021, 2022) Top Workplace in the US by the Salt Lake Tribune \n  Two-time winner (2021, 2022) Utah\u2019s Best Companies to Work for by Utah Business magazine \n  2022 Employee Appreciation and Employee Well Being by the Salt Lake Tribune \n  2022 Top Workplace in the US by the Salt Lake Tribune for the Technology Industry \n  2022 Top Workplace in the US by the Salt Lake Tribune for Compensation & Benefits \n  2022 Top Workplace in the US by the Salt Lake Tribune for Work-Life Flexibility \n  2021 Top Workplace in the US by the Salt Lake Tribune for Remote Work \n  2021 Top Workplace in the US by the Salt Lake Tribune for Top Managers \n  2021 Top Workplace in the US by the Salt Lake Tribune for Compensation \n  2021 Coolest Tech Companies to Work for by Dev Mountain \n \n \n \n  NetDocuments is a hybrid, remote-friendly workplace. Come join our team and \n   work inspired  each day!\n  \n \n  About the opportunity: \n \n \n   NetDocuments is seeking a Sr Artificial Intelligence/Machine Learning Engineer to create applications and services on existing LLMs, integrating capabilities with Azure Cognitive Services. The role will build scalable and efficient infrastructure and APIs to support AI integrations and facilitate the deployment and execution of machine learning models. The Sr AI/ML Engineer will report to the Manager of Engineering.\n  \n \n  What your contributions will be: \n \n \n  Develops new AI/ML integrated services using a combination of microservices, Azure Cognitive Services, generative AI, NLP, and other technologies as appropriate \n  Explores and experiments with emerging AI techniques, frameworks, and architectures to improve service performance and capabilities \n  Designs and develops software components and modules that enable seamless integration of machine learning models into existing applications and services \n  Implements data preprocessing and feature engineering pipelines to ensure the compatibility and quality of input data for machine learning models \n  Documents architectural designs through diagrams and logical flows \n  Strategizes with staff and principal engineers as well as product experts on where AI/ML services should evolve \n  Builds and tests new AI/ML service designs, formulations, materials, and systems for compliance with quality and/or performance standards \n  Interprets functional/non-functional requirements for AI/ML solutions \n  Collaborates across software engineering teams to integrate AI/ML solutions into existing products and deploy them at scale \n  Tests new applications and services in a variety of environments \n  Maintains and modifies existing applications and services without supervision \n  Estimates and plans out work through user stories and tasks \n  Determines operational feasibility by providing analysis, problem definition, requirements, solution development and proposed solutions \n  Participates in team exercises for collaboration \n  Guides and mentors team development efforts towards successful project delivery \n  Updates job knowledge by studying state-of-the-art development tools, programming techniques and computing equipment \n  Provides information by collecting, analyzing, and summarizing development and service issues \n  Accomplishes engineering and organization mission by completing related results as needed \n  Support and develop software engineers by providing advice, coaching and educational opportunities \n  Grows engineering teams by participating in interviewing, recruiting, and hiring \n  Stays on the leading edge of AI and ML technologies, communicating and guiding other engineers on these technologies \n  Displays passion about evolving AI and ML technologies \n  Understands business needs and know how to create the tools to manage them \n  This position will consist of 90% in the code and 10% mentoring other AI/ML engineers \n  Other duties as assigned \n \n \n \n  What you will bring to the team: \n \n \n  Strategic software development and design in the AI/ML space \n  Azure Cognitive Services experience \n  Research and analytical thinking skills \n  Collaboration within a team environment \n  Independent work with minimal oversight \n  Eagerness to learn new technologies \n  Business orientation and use case focus \n  Self-directed \n  High energy \n  Detail-orientation \n  Communication skills \n \n \n \n  What you will need for success: \n \n \n  Bachelor\u2019s degree or higher in Information Systems, Computer Science, or a related field or equivalent on-the-job experience \n  1-2 years in leading/mentoring a team of 5+ \n  Minimum 5 years of experience as a backend developer working with required technological stack listed below, in order of priority: \n \n \n  LLM AI skillsets and experience \n  Integration with AI/ML capabilities utilizing Azure Cognitive Services \n  Microservices \n  Backend/Platform team experience \n  Azure \n  Azure PaaS offerings \n  Object Oriented Programming \n \n \n \n  Priority consideration for applicants who have: \n \n \n  Model Hosting \n  Other AI integrations outside of Azure (Bard, OpenAI, etc) \n \n \n \n  Ideally you will have: \n \n \n  Experience in the Legal Industry \n \n \n \n  What you will receive: \n \n \n  90% healthcare premiums company covered \n  HSA company contribution \n  401K match at 4% with no vesting period \n  Twice a year merit increases \n  Flexible time off typically 3 to 4 weeks a year, not including the 9 paid holidays \n  Authenticity and accountability from leadership \n  Connection, access, and mentorship from exceptional leaders \n  Growing company with opportunities for advancement \n \n \n \n  NetDocuments is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind. All employment decisions are based on business needs, job requirements, individual qualifications, without regard to race, color, religion, sex, (including pregnancy), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity and/or expression, military and veteran status, or any other status protected by laws or regulations in the locations where we operate. NetDocuments believes diversity and inclusion among our employees is critical to our success, and we are committed to providing a work environment free of discrimination and harassment.", "cleaned_desc": "   work inspired  each day!\n  \n \n  About the opportunity: \n \n \n   NetDocuments is seeking a Sr Artificial Intelligence/Machine Learning Engineer to create applications and services on existing LLMs, integrating capabilities with Azure Cognitive Services. The role will build scalable and efficient infrastructure and APIs to support AI integrations and facilitate the deployment and execution of machine learning models. The Sr AI/ML Engineer will report to the Manager of Engineering.\n  \n \n  What your contributions will be: \n \n \n  Develops new AI/ML integrated services using a combination of microservices, Azure Cognitive Services, generative AI, NLP, and other technologies as appropriate \n  Explores and experiments with emerging AI techniques, frameworks, and architectures to improve service performance and capabilities \n  Designs and develops software components and modules that enable seamless integration of machine learning models into existing applications and services \n  Implements data preprocessing and feature engineering pipelines to ensure the compatibility and quality of input data for machine learning models \n  Documents architectural designs through diagrams and logical flows \n  Strategizes with staff and principal engineers as well as product experts on where AI/ML services should evolve \n  Builds and tests new AI/ML service designs, formulations, materials, and systems for compliance with quality and/or performance standards \n  Interprets functional/non-functional requirements for AI/ML solutions \n  Collaborates across software engineering teams to integrate AI/ML solutions into existing products and deploy them at scale \n  Tests new applications and services in a variety of environments \n  Maintains and modifies existing applications and services without supervision \n  Estimates and plans out work through user stories and tasks \n  Determines operational feasibility by providing analysis, problem definition, requirements, solution development and proposed solutions \n  Participates in team exercises for collaboration    Detail-orientation \n  Communication skills \n \n \n \n  What you will need for success: \n \n \n  Bachelor\u2019s degree or higher in Information Systems, Computer Science, or a related field or equivalent on-the-job experience \n  1-2 years in leading/mentoring a team of 5+ \n  Minimum 5 years of experience as a backend developer working with required technological stack listed below, in order of priority: \n \n \n  LLM AI skillsets and experience \n  Integration with AI/ML capabilities utilizing Azure Cognitive Services \n  Microservices \n  Backend/Platform team experience \n  Azure \n  Azure PaaS offerings \n  Object Oriented Programming \n \n \n \n  Priority consideration for applicants who have: \n \n ", "techs": ["llm ai skillsets and experience", "integration with ai/ml capabilities utilizing azure cognitive services", "microservices", "backend/platform team experience", "azure", "azure paas offerings", "object-oriented programming"]}, "25df306119d637ef": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 105000.0, "salary_max": 105000.0, "title": "Senior Software Engineer - AI/ML", "company": "Invisible Technologies", "desc": "Website:  https://www.invisible.co/ \n  Blog:  https://inv.tech/blog \n  Overview/Sales Deck:  https://docsend.com/salesdeck \n  Recorded Demo:  https://www.youtube.com/demo \n  Core Values:  https://www.notion.so/invisibletech/Invisible-Values \n \n \n \n \n Invisible Technologies is on a mission to redefine work through automation and human interaction, powered by our globally distributed team of Partners and Agents. We were a distributed team before it was a necessity, and we take pride in our transparent, effective communication to collaborate and take ownership as needed. \n  As a Senior Software Engineer, your job is to write excellent code and make careful system changes in coordination with your team to have a measurable impact on our business outcomes. In this role, you will partner directly with your team manager, product managers, and other stakeholders across the wider business to guide your team's work. You will cut through system complexity and help your peers find their way past obstacles with autonomy. Your position among the engineers on your team will provide you with mentorship and leadership opportunities. \n  As a member of our ML team, your work will be focused on improving our AI-powered process engine and other core parts of our client experience related to machine learning. \n \n \n  Culture \n  We believe in continuous learning and growth, and as a senior engineer, we expect you to foster this culture within the team. You will have the opportunity to mentor others and push the boundaries of what our platform can do. \n    Execution \n  Execution is key to our operations. We expect you to commit to delivery and effectively prioritize tasks to make sensible, expedient progress. As a senior member of your team, you will help remove obstacles to success for other engineers around you. \n  We are a remote team, so communication is crucial - announce what you will do, do it, then confirm when it's done. \n \n \n  The Technology \n  Our platform is Typescript and Python. \n  We're avid users of NextJS, React, Django, Postgres, Kubernetes, and GraphQL. \n  We're always eager to learn and try new technologies. Our ML team is continuously evaluating new AI models and integrating them into our platform. \n \n \n  Requirements \n \n You have significant experience developing applications in remote team environments. Our team spans the globe, and requires excellent communication and teamwork to succeed. \n You are able to partner with Product Managers. You enjoy developing technical specifications to meet business objectives with complex scope. As a senior member of your team, you will help other engineers understand requirements. \n You can analyze and author documentation. You will need to research and synthesize new technologies (model, frameworks, libraries, techniques), explain them to your team, and evangelize their usefulness in our platform on a regular basis. \n You have strong experience with Python and AI/ML libraries (Pandas, LangChain, PyTorch, Keras, scikit-learn, etc.). You should be comfortable enough to weigh the pros and cons of each model, framework, and third-party integration, then incorporate your insights into code. \n You understand the underlying theory and capabilities of widely-used machine learning models. \n You have proven expertise in implementing, deploying, and monitoring machine learning models to solve real world problems (We deploy on GCP with Kubernetes). We have a platform team, but you should know enough about DevOps/MLOps to be able to operate your models in production. \n \n \n \n  Location \n \n Currently, we're looking to hire in North/South America to ensure reasonable overlap with our existing teams and stakeholders. \n \n Working Schedule \n \n The candidate should be available between 10am to 3pm EDT from Monday to Friday. \n \n Compensation: \n \n \n 2023: $105,000 annual base + annual bonus potential + generous equity! \n Healthcare Benefits (or Stipend Option for Non - US Candidates) \n Unlimited PTO \n Work Remotely \n OWNERSHIP!!", "cleaned_desc": "", "techs": ""}, "0bac6b797eb8569d": {"terms": ["data science"], "salary_min": 117031.37, "salary_max": 148187.78, "title": "Senior Manager, Corporate Analytics", "company": "Calendly", "desc": "About the team & opportunity \n  What's so great about working on Calendly's Operations team? \n  We are the infrastructure of our business that allows us to scale to new heights. \n  Why do we need you? \n  We are seeking a Senior Manager of Corporate Analytics to be at the forefront of our data-driven culture by providing innovative insights and structured practices. In this role, you will oversee a team of analysts and collaborate with cross-functional stakeholders to unlock the full potential of our data. Your strategic mindset and ability to turn data into actionable recommendations will be pivotal in shaping the future of our company. \n  A day in the life of a Sr. Manager, Corporate Analytics at Calendly \n  As our Senior Manager of Corporate Analytics, your role will revolve around leveraging data to support decision making at Calendly. You will lead a team of analysts, conduct data analysis, collaborate with stakeholders and shape strategic decisions. This includes ensuring data accuracy, communicating insights and managing projects to align with Calendly's goals. \n  At Calendly, we believe good ideas can come from anywhere, and we will empower you to collaborate with others, form intelligent opinions, and drive decisions with leadership and the executive team. As such, top candidates are proactive, problem-solvers, and insightful. \n  On a typical day, you will be working on: \n \n Developing data analyses by reviewing and creating dashboards, reports and datasets to gain insights into user behavior, product performance and business metrics \n Work closely with cross-functional teams to understand their data needs. Leverage analysis tools, such as BigQuery and Tableau, to extract, analyze, and interpret data, translating it into useful insights to support business decision-making. \n Define and implement thought leadership of highly complex and enterprise-wide business intelligence programs outwards into the organization (both process and technology) \n Hire and train new employees, conduct performance reviews, and provide leadership and mentoring, as well as technical and personal development programs for team members \n \n What do we need from you? \n \n 8+ years of data analytics experience including a strong foundation at high-growth technology companies (SaaS and/or PLG) \n 4 + years experience as a people-manager for business intelligence and/or data analytics teams \n Proven expertise in leveraging advanced analytics tools such as BigQuery, Tableau or equivalent platforms \n Excellent communication and interpersonal skills with the ability to take complex information and present to all levels within the organization \n Bachelor's degree in finance, analytics or data science, Master's degree or MBA preferred \n Authorized to work lawfully in the United States of America as Calendly does not engage in immigration sponsorship at this time \n \n What's in it for you? \n  Ready to make a serious impact? Millions of people already rely on Calendly's products, and we're still in the midst of our growth curve \u2014 it's a phenomenal time to join us. Everything you'll work on here will accelerate your career to the next level. If you want to learn, grow, and do the best work of your life alongside the best people you've ever worked with, then we hope you'll consider allowing Calendly to be a part of your professional career. \n  Our Hiring Process: \n  Typically, individuals will participate in the following interview process. However, there may be slight nuances given the role and or department we are hiring for. Please keep in mind that individuals can be declined from the position at any stage of the process. \n \n Qualified individuals will be invited to schedule a phone interview with a member of our recruiting team. This is a great time to ask any initial questions you have about the company or the role. \n Next, we'll put you in direct contact with your potential manager. You'll get a chance to learn even more about life at Calendly, the responsibilities within your role, and the qualities needed to succeed here. \n Then, you will perform an interview exercise, where you can highlight your skills. \n Next, or in parallel, you'll meet with your potential team members. \n Finally, we connect with those you've worked with before, to learn more about the impact you can make, the value you bring, and the best way to set you up for success at Calendly. \n \n We aim to provide an inclusive and equitable experience to everyone who expresses interest in working at Calendly. The recruiter assigned to this role will keep you informed every step of the way. Have questions? Let your recruiter know! Want to share your experience? We are passionately committed to improving and building on our process, and we consider feedback a gift. \n  If you are an individual with a disability and would like to request a reasonable accommodation as part of the application or recruiting process, please contact us at  recruiting@calendly.com . \n  Calendly is registered as an employer in many, but not all, states. If you are located in Hawaii, you will not be eligible for employment. \n  Candidates residing in California may visit our Notice at Collection for California Candidates here:  Notice at Collection", "cleaned_desc": " \n What do we need from you? \n \n 8+ years of data analytics experience including a strong foundation at high-growth technology companies (SaaS and/or PLG) \n 4 + years experience as a people-manager for business intelligence and/or data analytics teams \n Proven expertise in leveraging advanced analytics tools such as BigQuery, Tableau or equivalent platforms \n Excellent communication and interpersonal skills with the ability to take complex information and present to all levels within the organization ", "techs": ["bigquery", "tableau"]}, "1f246353f0448cfe": {"terms": ["data science", "mlops"], "salary_min": null, "salary_max": null, "title": "Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)\n  \n  Sr Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "python", "c/c++", "ai", "ml", "ml frameworks", "public cloud", "engineering", "computer science", "distributed computing", "hpc", "large-scale ml systems", "ml algorithms", "ml development lifecycle", "cloud environments", "aws", "azure", "gcp", "cloud systems", "security", "availability", "performance", "scalability", "cost", "gpu clusters", "ml compilers", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting", "fine-tuning", "research publications", "neural networks", "sysml"]}, "6e58c332c89581a4": {"terms": ["data science"], "salary_min": 100000.0, "salary_max": 130000.0, "title": "Full-Stack Developer (C)", "company": "Mesh Plus Plus", "desc": "Mesh++ designs solar- and battery-powered WiFi routers with a dedicated wireless backhaul for temporary or permanent outdoor installations. Our intention is to make last-mile infrastructure fully wireless, allowing for simple temporary installations and non-intrusive permanent ones. Mesh++ has completed installations over underserved communities all over the world with the goal of developing a platform that enables anyone to bring internet access to their community.\n  \n \n \n  We are looking for a Full-Stack Developer to help build our next-generation software and data management platform. This includes rapid ideation, prototyping, and maintaining a feedback loop with customers and stakeholders. As an early startup, tasks outside of the immediate job description may be required occasionally. Examples of projects include a sophisticated debug interface, an advanced network configuration interface to supplement our existing simple one, minor improvement of our mobile app and dashboard, and the fine-tuning of an existing billing and authorization system. We seek individuals who are enthusiastic to take on new responsibilities as we continue to grow.\n  \n \n \n  Examples of our existing applications are available on the App and Play stores under the name \u2018Mesh++\u2019 and online at meshplusplus.com, dashboard.meshplusplus.com, and design-tool.meshplusplus.com.\n  \n \n \n  This is a paid position for which we are open to either full-time or contract, with a salary of $100k-130k annual depending on experience, equity available.\n  \n \n \n  Responsibilities: \n \n \n  Leading feature implementation \n  Rapid development and testing \n  Design verification with customers \n  Long-term improvements \n \n \n \n  Minimum Qualifications: \n \n \n  Experience designing simplified products for a non-technical audience \n  Experience developing both mobile and web applications \n  Ability to design intuitive user interfaces \n  Proficiency in Javascript \n  Proficiency in computer networking \n  Experience working with wireless networking products \n \n \n \n  Preferred Qualifications: \n \n \n  Experience maintaining and displaying large-scale datasets \n  Experience with basic data science \n  Experience with React Native \n  Familiarity with OpenWRT and RADIUS servers \n  Experience working with PostgreSQL \n \n \n  Please contact danny@meshplusplus.com with resume or questions.", "cleaned_desc": " \n \n  Preferred Qualifications: \n \n \n  Experience maintaining and displaying large-scale datasets \n  Experience with basic data science \n  Experience with React Native \n  Familiarity with OpenWRT and RADIUS servers ", "techs": ["react native", "openwrt", "radius servers"]}, "48e027138d8bd2f0": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 125000.0, "title": "Solutions/Cloud Architect", "company": "Alphident Technologies Inc", "desc": "Title : Solutions/Cloud Architect \n Work location : Remote with occasional visit to Washington DC \n Term : Fulltime \n Job Responsibilities : \n \n Act as an incubator for modernization of application, technical and security services through adoption of cloud-native solutions. \n Partner with Enterprise Architecture to implement a highly scalable, automated, and available cloud platform, aligned with the future state cloud-first strategy and architecture. \n Drive adoption and migrations from traditional technology platforms to public cloud services. \n Create and implement self-service DevOps, support, maintenance and governance practices and processes for the Cloud Platform. \n Recommend tools and methodologies to support Cloud Platform operations and implement SRE practices and team as part of the Digital transformation process \n Partner with Development teams, CyberSecurity, Support and Enterprise Architecture teams to deliver and maintain a cloud platform with associated DevOps practices. \n Break large complex systems into manageable subsystems and components, each of which can be managed by individuals or teams in a scalable manner. \n Create the capabilities required to utilize automation practices for initializing, provisioning and optimizing systems, and facilitate infrastructure orchestration \u2013 embracing self-service and autonomy. \n Convert the InfraOps practices into DevOps practices, building CI/CD pipelines and automation to deliver and deploy applications to production. \n Ensure systems and application have efficient and actionable monitoring with SLO aligned with business goals. \n \n Requirements : \n \n Shall at a minimum have a Bachelor\u2019s degree in Computer Science, Computer Engineering, Data Science, Information Technology Management or Engineering, or other comparable degree or experience. \n Shall have a minimum of seven (7) years of experience in the IT field focusing on Agile project development, DevSecOps solutions, technical and cloud-based architecture, solutions, and infrastructure specifically. \n Shall possess strong architecture & design experience, including at least three (3) years of experience building and deploying enterprise applications in cloud platforms, such as AWS, Azure, GCP. \n Shall possess expertise in large-scale, high-performance enterprise application architectural design, solution implementation, product development and deployment on cloud environments such as AWS, Azure, GCP. \n Shall possess in-depth understanding of Agile software development and DevSecOps concepts, practices, and tools. \n Shall be highly proficient with container technologies such as Docker and container orchestration platforms like Kubernetes. \n Shall possess skills to optimize cloud resources for cost efficiency, including choosing the right instance types, scaling resources, and utilizing reserved instances or spot instances. \n \n Job Type: Full-time \n Pay: $120,000.00 - $125,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Health insurance \n Paid time off \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n What is your expected annual salary? \n What is your work status: US Citizen, Permanent resident, H1B, OPT? \n How many years of experience in technical and cloud-based architecture, solutions, and infrastructure specifically? \n Are you fine for Occasional Onsite visits to client's Place in Washington DC? \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n DevSecOps: 7 years (Required) \n Kubernetes: 3 years (Required) \n Agile: 7 years (Required) \n \n Work Location: Remote", "cleaned_desc": " Break large complex systems into manageable subsystems and components, each of which can be managed by individuals or teams in a scalable manner. \n Create the capabilities required to utilize automation practices for initializing, provisioning and optimizing systems, and facilitate infrastructure orchestration \u2013 embracing self-service and autonomy. \n Convert the InfraOps practices into DevOps practices, building CI/CD pipelines and automation to deliver and deploy applications to production. \n Ensure systems and application have efficient and actionable monitoring with SLO aligned with business goals. \n \n Requirements : \n \n Shall at a minimum have a Bachelor\u2019s degree in Computer Science, Computer Engineering, Data Science, Information Technology Management or Engineering, or other comparable degree or experience. \n Shall have a minimum of seven (7) years of experience in the IT field focusing on Agile project development, DevSecOps solutions, technical and cloud-based architecture, solutions, and infrastructure specifically. \n Shall possess strong architecture & design experience, including at least three (3) years of experience building and deploying enterprise applications in cloud platforms, such as AWS, Azure, GCP. \n Shall possess expertise in large-scale, high-performance enterprise application architectural design, solution implementation, product development and deployment on cloud environments such as AWS, Azure, GCP. ", "techs": ["break large complex systems into manageable subsystems and components", "automation practices", "initializing", "provisioning", "optimizing systems", "infrastructure orchestration", "self-service", "autonomy", "convert infraops practices into devops practices", "ci/cd pipelines", "monitoring", "slo", "bachelor\u2019s degree in computer science", "computer engineering", "data science", "information technology management or engineering", "agile project development", "devsecops solutions", "technical architecture", "cloud-based architecture", "infrastructure", "aws", "azure", "gcp", "large-scale", "high-performance enterprise application architectural design", "solution implementation", "product development", "cloud environments"]}, "3551525a4cd5ddee": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml"]}, "a16379786f542a5a": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch"]}, "6eb878294a1dac65": {"terms": ["data science"], "salary_min": 117540.19, "salary_max": 148832.06, "title": "Senior Java NLP Developer", "company": "Baer Group", "desc": "**Federal Project - Applicant must be a United States Citizen, with the ability to obtain a Public Trust. ** \n \n \n Baer is looking for Senior Java NLP Developer for a 12 month Federal Remote Project. \n \n   \n \n Title:  Senior Java NLP Developer\n  \n Location:  Remote (Must be based in US)\n  \n Duration:  12 months\n  \n Rate:  All-Inclusive\n  \n Alignment:  W2 or C2C (Vendors Not Permitted)\n  \n \n Description: \n \n Design, build and configure applications to meet business process and application requirements using Java suite, cTAKES, MongoDB, PostgreSQL.  \n Responsible for developing and/or engineering the end-to-end features of a system, from user experience to backend code.  \n Use development skills to deliver innovative solutions that help our clients improve the services they provide.  \n Must be able to leverage machine learning and natural language processing to review client data and deploy optimal automated tasks to advance client\u2019s processes.  \n Leverage new technologies that can be applied to solve challenging business problems with a cloud first and agile mindset.  \n Identify and analyze user requirements to generate stories and tasks for team backlog  \n Prioritize and execute tasks in development cycle  \n \n \n Requirements: \n \n 5 years of experience with Java  \n 3 years of experience using Agile development methodologies and Natural Language Processing tools.  \n Master\u2019s degree in related field +10 years of experience; or PhD + 4 years   \n Experience with Machine Learning, Language Modeling and Python is a plus.  \n Java and Python, MongoDB, PostgreSQL, JavaScript, JQuery, Bootstrap  \n Knowledge working with AWS or cloud development environments  \n Experience with Java, Spring Boot, Spring Framework, and Spring Cloud  \n Experience with Restful Services, API's, and Microservices Architecture  \n Experience with Swagger or OpenAPI  \n Experience with SQL  \n Experience with AWS, Kubernetes, and Kafka  \n Experience with Git, Jira, and Confluence  \n Experience with integrating to COTS and SaaS applications  \n Knowledge about Agile development Methodologies.  \n Experience with Docker, AWS Lambda, and AWS ECS  \n Experience with Python  \n Preference to developer with experience working with healthcare data and Health IT  \n \n \n Public Trust Security Clearance  is the lowest level of additional background screening that the federal government requires for applicants of certain jobs, which includes completing a Standard Form 85 (SF85) form.\n  \n \n \n Company Overview: \n \n  Baer is an Enterprise Performance Partner providing job opportunities with several 1st Tier Global Systems Integrators and a wide array of Fortune 1000 clients. Baer consultants and employees enjoy access to the highest profile job opportunities across leading Enterprise Technology Solutions ranging from Digital Transformation programs utilizing the latest technologies from SAP and Oracle to a wide range of emerging Cloud based infrastructure, application and AI related solutions.\n  \n  At Baer we aim to provide a best-in-class engagement experience for our consultants. Our job requirements are carefully vetted and are typically associated with pivotal programs offering tremendous opportunities to expand your skills leveraging the latest solutions.\n  \n  Baer is an equal opportunity employer including disability/veteran.", "cleaned_desc": "  \n Rate:  All-Inclusive\n  \n Alignment:  W2 or C2C (Vendors Not Permitted)\n  \n \n Description: \n \n Design, build and configure applications to meet business process and application requirements using Java suite, cTAKES, MongoDB, PostgreSQL.  \n Responsible for developing and/or engineering the end-to-end features of a system, from user experience to backend code.  \n Use development skills to deliver innovative solutions that help our clients improve the services they provide.  \n Must be able to leverage machine learning and natural language processing to review client data and deploy optimal automated tasks to advance client\u2019s processes.    Leverage new technologies that can be applied to solve challenging business problems with a cloud first and agile mindset.  \n Identify and analyze user requirements to generate stories and tasks for team backlog  \n Prioritize and execute tasks in development cycle  \n \n \n Requirements: \n \n 5 years of experience with Java  \n 3 years of experience using Agile development methodologies and Natural Language Processing tools.  \n Master\u2019s degree in related field +10 years of experience; or PhD + 4 years   \n Experience with Machine Learning, Language Modeling and Python is a plus.  \n Java and Python, MongoDB, PostgreSQL, JavaScript, JQuery, Bootstrap    Knowledge working with AWS or cloud development environments  \n Experience with Java, Spring Boot, Spring Framework, and Spring Cloud  \n Experience with Restful Services, API's, and Microservices Architecture  \n Experience with Swagger or OpenAPI  \n Experience with SQL  \n Experience with AWS, Kubernetes, and Kafka  \n Experience with Git, Jira, and Confluence  \n Experience with integrating to COTS and SaaS applications  \n Knowledge about Agile development Methodologies.  \n Experience with Docker, AWS Lambda, and AWS ECS  \n Experience with Python  \n Preference to developer with experience working with healthcare data and Health IT  ", "techs": ["java suite", "ctakes", "mongodb", "postgresql", "machine learning", "natural language processing", "cloud first", "agile mindset", "java", "agile development methodologies", "natural language processing", "machine learning", "language modeling", "python", "java", "python", "mongodb", "postgresql", "javascript", "jquery", "bootstrap", "aws", "cloud development environments", "java", "spring boot", "spring framework", "spring cloud", "restful services", "api's", "microservices architecture", "swagger", "openapi", "sql", "aws", "kubernetes", "kafka", "git", "jira", "confluence", "cots", "saas applications", "agile development methodologies", "docker", "aws lambda", "aws ecs", "python", "healthcare data", "health it."]}, "955fb8edf4260ba6": {"terms": ["data science"], "salary_min": 80339.31, "salary_max": 101727.47, "title": "Senior Technical Sourcer, Machine Learning - US remote", "company": "Hugging Face", "desc": "Here at Hugging Face, we\u2019re on a journey to advance good Machine Learning and make it more accessible. Along the way, we contribute to the development of technology for the better. \n  We have built the fastest-growing, open-source, library of pre-trained models in the world. With more than 500K+ models and 250K+ stars on GitHub, over 15.000 companies are using HF technology in production, including leading AI organizations such as Google, Elastic, Salesforce, Algolia, and Grammarly. \n \n  About the role \n  As one of our first  Senior Technical Sourcer , you\u2019ll play a key role in structuring the recruitment for our technical teams, from identifying the needs to sourcing passive candidates and screening them until the offer stage. You\u2019ll work closely with the leadership team to develop our employer branding strategy, choose the must-go-to tech recruitment events, and create content to attract top talent. There is a lot of building to do and your scope can rapidly grow. \n  At Hugging Face, we deeply care about diversity, equity, and inclusion and you\u2019ll help us develop a more inclusive recruitment process and share best practices with our hiring team to have a more diverse team. \n  About you \n  You\u2019ll enjoy working here if you love to talk tech and especially about Machine Learning. If you know that Python is not just a snake, Transformers are not only Autobots or Decepticons, and Github/Twitter/Discord are in your favorite headhunting bookmarks, this role has been made for you.  \n You care about candidates\u2019 experiences and understand diversity is great but inclusion is key. You like to build things (almost) from scratch and you thrive in a fast-growing international environment, A solid startup or entrepreneurial experience in the Machine Learning world is also preferred.   \n \n \n More about Hugging Face \n  We are actively working to build a culture that values diversity, equity, and inclusivity . We are intentionally building a workplace where people feel respected and supported\u2014regardless of who you are or where you come from. We believe this is foundational to building a great company and community. Hugging Face is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. \n  We value development . You will work with some of the smartest people in our industry. We are an organization that has a bias for impact and is always challenging ourselves to grow continuously. We provide all employees with reimbursement for relevant conferences, training, and education. \n  We care about your well-being.  We offer flexible working hours and remote options. We offer health, dental, and vision benefits for employees and their dependents. We also offer parental leave and unlimited paid time off. \n  We support our employees wherever they are.  While we have office spaces in NYC and Paris, we're very distributed and all remote employees have the opportunity to visit our offices. If needed, we'll also outfit your workstation to ensure you succeed. \n  We want our teammates to be shareholders.  All employees have company equity as part of their compensation package. If we succeed in becoming a category-defining platform in machine learning and artificial intelligence, everyone enjoys the upside. \n  We support the community.  We believe major scientific advancements are the result of collaboration across the field. Join a community supporting the ML/AI community.", "cleaned_desc": "", "techs": ""}, "60e17890f686417f": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml", "gpu clusters"]}, "03e5f2fc8bc9f45f": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["python", "scala", "java"]}, "6241ef967ad41400": {"terms": ["data science"], "salary_min": 85000.0, "salary_max": 90000.0, "title": "UI/UX Lead", "company": "Alphident Technologies Inc", "desc": "Title : UI/UX Lead \n Work location : Remote with occasional visit to Washington DC \n Term : Fulltime \n Job Responsibilities : \n \n Conduct user research to understand user behaviors, preferences, and pain points to inform design decisions. UI/UX Design \n Design user interfaces that provide a seamless and cohesive experience across various features and modules \n Develop wireframes, mockups, and prototypes to effectively communicate design ideas and concepts. \n Identifying and solving product design problems \n Ensure designs are responsive and accessible across different devices and screen sizes, providing a consistent experience. \n Design user flows and interactions that guide users through complex processes and workflows with clarity and efficiency. \n Collaborate with developers to ensure smooth implementation of designs. \n Conduct usability testing to gather user feedback and insights, iteratively improving designs based on user input. \n \n Requirements : \n \n Shall at a minimum have a Bachelor\u2019s degree in Computer Science, Computer Engineering, Data Science, Information Technology Management or Engineering, or other comparable degree or experience. \n Shall have a minimum of seven (7) years of experience in the Information Technology field focusing on development projects and UX design specifically. \n Shall possess strong architecture & design experience (at least 3 years) providing UX design expertise for enterprise applications. \n Expertise in UXD best practices and methods, including prototyping \n \n Job Type: Full-time \n Pay: $85,000.00 - $90,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Health insurance \n Paid time off \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n What is your expected annual salary? \n What is your work status: US Citizen, Permanent resident, H1B, OPT? \n Are you fine for Occasional Onsite visits to client's Place in Washington DC? \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n UX: 7 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "3d805dac8e715eaf": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": null, "salary_max": null, "title": "Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)\n  \n  Sr Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms and fms", "mlops", "python", "c/c++", "ml development lifecycle", "aws", "azure", "gcp", "security", "availability", "performance", "scalability", "cost", "mlops life cycle", "gpu clusters", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting and fine-tuning", "neural networks", "distributed training", "sysml."]}, "657eed66ec34cbbc": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["llms", "fms", "apis", "sdks", "python", "scala", "java", "deep neural networks", "nlp", "speech", "computer vision", "recommendation systems", "neural network models"]}, "0eef55fd24e36a93": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["none"]}, "67a1555eed73a75f": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["tensorflow", "pytorch", "lightning", "mosaic ml"]}, "ce3e87c140650f3a": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml"]}, "d513949de612388c": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 3 (19075), United States of America, McLean, Virginia\n   Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["llms", "fms", "python", "scala", "java", "tensorflow", "pytorch", "lightning", "mosaic ml"]}, "3397c418f1240503": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["apis", "sdks", "large-language models (llms)", "foundation models (fms)", "python", "scala", "java", "deep neural networks", "nlp", "speech", "computer vision", "recommendation systems", "neural network models", "api security", "observability", "cloud access control"]}, "b6d15c3f9dbb9f65": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Generative AI Systems (Remote-Eligible)", "company": "Capital One", "desc": "Locations: NY - New York, United States of America, New York, New York\n   Distinguished Engineer, Generative AI Systems (Remote-Eligible)\n  \n  Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms and fms", "mlops for foundation models", "python", "c/c++", "ai and ml frameworks", "public cloud", "aws", "azure", "gcp", "gpu clusters", "ml compilers", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting and fine-tuning", "neural networks", "distributed training", "sysml"]}, "51ada1643e7b6728": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "nlp", "speech", "computer vision"]}, "3d2314926be583b2": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)", "company": "Capital One", "desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "11 West 19th Street (22008), United States of America, New York, New York\n   Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities, to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services of our capabilities and enable real-time customer-facing applications powered by these capabilities. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience.. \n  Enable our users to build new AI capabilities    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field. \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["python", "scala", "java", "apis", "sdks", "large-language models (llms)", "foundation models (fms)", "distributed computing", "cache optimization techniques", "deep neural networks", "nlp", "speech", "computer vision", "recommendation systems", "api security", "observability", "cloud access control", "privacy best practices"]}, "a98ec9f9bc6a5bae": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)", "company": "Capital One", "desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $230,100 - $262,700 for Sr. Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $243,800 - $278,200 for Sr. Lead Machine Learning Engineer\n   Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "201 Third Street (61049), United States of America, San Francisco, California\n   Sr. Lead Engineer - Generative AI Infrastructure (Remote-Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Lead Engineer, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n   \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 8 years of experience designing and building data-intensive solutions using distributed computing or 4+ years of experience with High-Performance Computing (HPC) systems. \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 3 years of experience building, scaling, and optimizing training and inferencing systems for deep neural networks \n \n \n  Preferred Qualifications:   \n  Master's or Doctoral degree in Computer science, Computer Engineering, Electrical engineering, Mathematics, or a similar field. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML etc. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n ", "techs": ["tensorflow", "pytorch", "python", "scala", "java", "lightning", "mosaic ml", "gpu clusters", "distributed computing", "high-performance computing (hpc) systems"]}, "91241b5069d4f343": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Lead Engineer - Generative AI Product Engineering (Remote- Eligible)", "company": "Capital One", "desc": "Center 1 (19052), United States of America, McLean, Virginia\n   Lead Engineer - Generative AI Product Engineering (Remote- Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Lead Generative AI Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services that enable real-time customer-facing applications. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience. \n  Enable our users to build new GenAI capabilities. \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $197,400 - $225,300 for Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $209,200 - $238,700 for Lead Machine Learning Engineer\n   Remote (Regardless of Location): $167,400 - $191,000 for Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 1 (19052), United States of America, McLean, Virginia\n   Lead Engineer - Generative AI Product Engineering (Remote- Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Lead Generative AI Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services that enable real-time customer-facing applications. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience. \n  Enable our users to build new GenAI capabilities.    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["llms", "fms", "apis", "sdks", "python", "scala", "java", "nlp", "speech", "computer vision", "recommendation systems"]}, "8fc8f0152786f8d4": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 160000.0, "title": "Senior Statistical Programmer", "company": "Warman O'Brien", "desc": "Join a Global Leader in Clinical Research Excellence \n Senior/Principal Statistical Programmer | Small CRO | Remote/Hybrid \n Our client, a prominent force in the clinical research landscape, is seeking talented Principal Statistical Programmer. With the option to work on-site in Toronto/Markham, Ontario, Canada, or remotely from anywhere in Canada/United States, this position offers the chance to contribute to cutting-edge projects that shape the future of healthcare. \n The Company \n Our client stands as a pioneer in the CRO realm. They boast an impeccable reputation for delivering high-quality solutions, unmatched customer service, and the flexibility to meet diverse client needs. From their headquarters in the dynamic Greater Toronto Area to their strategic sites across North America and Asia, this visionary organization has been thriving since 2004. \n Why Choose This Role? \n As a Principal Statistical Programmer, you'll play a pivotal role in leading projects of utmost complexity, charting paths to resolve intricate programming challenges. Your expertise will shine as you manage projects with finesse, ensuring on-time delivery of superior-quality outcomes that foster client trust and repeat business. You'll be a driving force behind regulatory submissions, mentorship, innovation, and excellence. \n Key Responsibilities: \n \n Spearhead projects with heightened complexity, addressing intricate statistical programming hurdles with finesse. \n Utilize your project management and statistical programming prowess to guide projects to successful outcomes. \n Represent the organization in client interactions, showcasing your expertise in programming oversight, project estimates, bid defenses, and more. \n Collaborate with regulatory agencies under supervision, demonstrating our commitment to responsible projects. \n Mentor and guide less-experienced Statistical Programmers, fostering their growth and development. \n Create SDTM and ADaM dataset specifications, championing adherence to SOPs and project requirements. \n Program, validate, and perform quality checks on critical datasets, ensuring adherence to industry standards. \n Lead programming teams and contribute to regulatory submissions, showcasing your expertise in a crucial role. \n Innovate by developing new macros and utilities, staying at the forefront of programming tools. \n Implement rigorous data integrity checks, ensuring data quality and scientific accuracy. \n Embrace training and uphold company policies, SOPs, and guidelines. \n \n Qualifications: \n Hold a Master\u2019s or Ph.D. degree in Statistics, Biostatistics, Epidemiology, or Computer Sciences. \n Possess a minimum of 8 years of clinical trial statistical programming experience with an advanced degree, or 10 years with a Bachelor\u2019s degree. \n Join a trailblazing organization that values innovation, quality, and the pursuit of excellence. Shape the future of clinical research as a Principal Statistical Programmer and be part of a team that drives transformation in healthcare. \n Apply now with your resume to avoid missing out on this opportunity! \n Job Types: Full-time, Permanent \n Salary: $120,000.00 - $160,000.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Lead programming teams and contribute to regulatory submissions, showcasing your expertise in a crucial role. \n Innovate by developing new macros and utilities, staying at the forefront of programming tools. \n Implement rigorous data integrity checks, ensuring data quality and scientific accuracy. \n Embrace training and uphold company policies, SOPs, and guidelines. \n \n Qualifications: \n Hold a Master\u2019s or Ph.D. degree in Statistics, Biostatistics, Epidemiology, or Computer Sciences. \n Possess a minimum of 8 years of clinical trial statistical programming experience with an advanced degree, or 10 years with a Bachelor\u2019s degree. ", "techs": ["macros", "utilities", "programming tools", "data integrity checks", "statistics", "biostatistics", "epidemiology", "computer sciences", "clinical trial statistical programming"]}, "46285bca20f2f77b": {"terms": ["data science"], "salary_min": 180687.0, "salary_max": 180687.0, "title": "Remote- Statistical Project Leader", "company": "Sanofi", "desc": "Job Summary \n \n  As a Statistical Project Leader, you will provide statistical leadership and guidance for clinical studies in one or more indications and will be accountable for methodological and statistical aspects of clinical development or medical affairs plans and subsequent deliverables. Utilizing strong study management, interpersonal and communication skills, you will be expected to ensure productive collaborations with other functions, as well as with other statistical project leaders and in communicating with senior leadership. You will promote teamwork, quality, operational efficiency, and innovation, as also represent Biostatistics (or provide leadership) in scientific or technology working groups or cross functional initiatives. \n \n  Major Duties and Responsibilities \n \n  With minimal direction from the group head, direct statistical support and provide scientific leadership for one moderate project, one or several indications or a highly complex large study in Neurology late phase. \n  Be accountable for statistical aspects of late clinical development, studies and submissions activities (when applicable), including relevance to external stakeholders (e.g. regulatory authorities, medical journals) and scientific validity, according to internal standards and regulatory guidelines, and in compliance with SOPs. \n  Plan and track project activities, timelines, and resource use. Seek to optimize resource utilization through efficient and well-managed resource allocation and across projects or areas. \n  Provide justifications for planned resource needs, allowing for the capacity to respond to unscheduled increase in project workload as needed. Effectively utilize external groups, e.g. CROs or data monitoring committees (DMCs), as applicable. \n  Represent Statistics in regulatory meetings. \n  Act as statistical consultant within company, and provide technical guidance and mentoring to people working on the projects. \n  Contribute to process optimization and provide input to statistical standards. \n \n \n  Required Education/Experience \n \n  PhD/MS in statistics or related discipline with at least 6 years of pharmaceutical experience. \n  Broad experience in clinical development or post-marketing activities such as submissions, interactions with regulatory agencies or other external stakeholders. \n  Broad knowledge and good understanding of advanced statistical concepts and techniques. \n  Experience in Neurology therapeutic areas preferred. \n \n \n  Sanofi Inc. and its U.S. affiliates are Equal Opportunity and Affirmative Action employers committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race; color; creed; religion; national origin; age; ancestry; nationality; marital, domestic partnership or civil union status; sex, gender, gender identity or expression; affectional or sexual orientation; disability; veteran or military status or liability for military status; domestic violence victim status; atypical cellular or blood trait; genetic information (including the refusal to submit to genetic testing) or any other characteristic protected by law. \n \n  The salary median compensation for this position is $180,687. All compensation will be determined commensurate with demonstrated experience. Employees may be eligible to participate in Company employee benefit programs. Additional benefits information can be found through the link,  www.benefits.sanofiusallwell.com \n \n  #GD-SA  #LI-SA \n \n  At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.", "cleaned_desc": "  Required Education/Experience \n \n  PhD/MS in statistics or related discipline with at least 6 years of pharmaceutical experience. \n  Broad experience in clinical development or post-marketing activities such as submissions, interactions with regulatory agencies or other external stakeholders. \n  Broad knowledge and good understanding of advanced statistical concepts and techniques. ", "techs": ["phd/ms in statistics", "clinical development", "post-marketing activities", "submissions", "interactions with regulatory agencies", "advanced statistical concepts", "advanced statistical techniques."]}, "bf7b3992f512e7c5": {"terms": ["data analyst"], "salary_min": 19.25, "salary_max": 24.05, "title": "Data Specialist", "company": "New Roots Institute", "desc": "ABOUT NEW ROOTS INSTITUTE   Who We Are, What We Do, And How We Do It \n  New Roots Institute is a nonprofit organization empowering the next generation with knowledge and training to end factory farming. \n  Through interactive, high school and college lessons, we inspire critical thinking and dynamic discussions about the connections between industrial animal agriculture and current key issues impacting us all\u2014like animal welfare, climate change and environmental sustainability, human rights, and personal and public health. \n  Through our Leadership Program, we offer fellowships for students motivated to dig deeper into the impacts, and solutions, of factory farming\u2014while being trained in effective communication, advocacy, and leadership skills. Upon completing the fellowship, alumni go on\u2014with our continued support\u2014to develop and empower other leaders to create change in their communities toward our shared goal of ending factory farming. \n  Our Vision  A just and sustainable food system for all. \n \n  Our Mission  To empower the next generation with knowledge and training to end factory farming. \n  Our Values  Our team is united around our shared mission and our shared values\u2014what we call our DNA. \n  These values guide our culture and our approach to empowering the next generation with knowledge and training to end factory farming. \n  Fierce Competence  We focus on achieving the greatest impact by effectively empowering the largest number of People. \n \n  Humble Self-Awareness  We recognize that we don\u2019t have all the answers and will listen to others, including those we believe we disagree with, to grow as individuals and as an organization. \n \n  Ready Adaptation  We understand that social and informational contexts evolve, and seek new knowledge to update our perspectives and optimize our approach. \n \n  Inclusive Collaboration  We strive to see beyond our egos to meet others where they\u2019re at and collectively strengthen our impact. \n \n  Caring Accountability  We show our commitment to one another and our cause by holding ourselves to a standard no lower than excellence, openly addressing issues with honesty and directness. \n \n  Last but not least, we genuinely enjoy our co-workers and have fun despite the tragic nature of what we\u2019re up against. Check out our  Rotten Truth  series on YouTube to see how we use humor to grapple with the grim reality of factory farming. \n  If all of this appeals to you, we encourage you to apply! \n  ABOUT THE POSITION   Overview  As the data specialist at New Roots Institute, you\u2019ll be integral in tracking and communicating our impact to a wide range of audiences. As a member of the advancement team, you will ensure the effectiveness of our marketing, communications, and fundraising systems. In collaboration with our technical manager and communications coordinator, you\u2019ll build workflows and maintain vital data in Hubspot and Airtable. You may also help maintain content for the New Roots Institute website, and will work closely with the programming team to facilitate a timely and lucid information flow between teams. \n \n  Details  This remote job will be full time/40 hours per week. \n \n  Skills Required \n \n \n Have a keen eye for detail, and the ability to understand how details fit into the big picture of the work the organization is doing \n Strong technical skills, and experience or interest in workplace technology such as Hubspot, Google Workspace, Asana, and Airtable \n Have experience managing data across a variety of formats and platforms \n Have a strong grasp of English grammar and punctuation \n Have experience working across teams to communicate complex information \n Be able and willing to work remotely/independently \n \n Other Requirements \n \n \n Be conversant in workplace technologies such as Google Suite (Google Docs, Google Sheets, Google Calendar), Asana, and Airtable \n Have a desire for honest and direct critique and interest in growing from it \n Be able to consistently and happily see beyond your ego to make the best decisions for the organization \n Have impeccable time management and prioritization abilities \n Be excellent at not missing details or deadlines \n Love working hard for a mission you deeply care about\u2014while understanding how to differentiate between working really hard (good) and unsustainable self-sacrifice (not so good) \n Have a strong grasp of English grammar and punctuation, as well as written and verbal communication that you imbue with emotional intelligence \n Be able and willing to work remotely/independently \n Share vegan values \n \n Compensation and Benefits \n \n \n $19.25-$24.05 per hour (i.e. $40,000-$50,000 annually) depending on experience \n In addition to a collaborative and innovative work environment, full-time hires will be able to take part in our benefits package, including:\n    \n Health insurance \n Generous paid time off, including vacation and sick leave \n Eleven paid federal holidays \n 401k to which employees may contribute \n Budget for professional development and workspace enhancements \n Phone & internet and personal computer reimbursement \n   \n \n Application Details  We consider traditional and nontraditional qualifications and carefully review each resume and cover letter. We are committed to hiring and retaining a diverse, culturally competent staff at all levels of the organization. We envision a team that not only reflects the demographics of our country, but also continues to deepen their skills and competencies to serve the full range of our audiences. We strongly encourage people of the global majority, especially Black and Indigenous folks, LGBTQIA+ individuals, persons living with disabilities, women, non-binary individuals, and people of various socioeconomic backgrounds to apply for this position. \n \n  To Apply  Please follow the \u201cApply for this position\u201d link. In your cover letter, we encourage you to state how you would add to our culture; what we would gain from having you on our team; and how you align with our organizational vision, mission, and values. You can direct questions to Carrie Moran, the Hiring Manager, at carrie@newrootsinstitute.org. \n \n  By submitting your information, you are acknowledging that you have read our  Privacy Policy   and agree to its terms.", "cleaned_desc": " \n \n Have a keen eye for detail, and the ability to understand how details fit into the big picture of the work the organization is doing \n Strong technical skills, and experience or interest in workplace technology such as Hubspot, Google Workspace, Asana, and Airtable \n Have experience managing data across a variety of formats and platforms \n Have a strong grasp of English grammar and punctuation \n Have experience working across teams to communicate complex information \n Be able and willing to work remotely/independently \n \n Other Requirements \n \n \n Be conversant in workplace technologies such as Google Suite (Google Docs, Google Sheets, Google Calendar), Asana, and Airtable ", "techs": ["hubspot", "google workspace", "asana", "airtable", "google suite", "google docs", "google sheets", "google calendar"]}, "1d869b2761cc2ede": {"terms": ["data analyst"], "salary_min": 60954.668, "salary_max": 77182.195, "title": "Data Analyst", "company": "Silent Falcon UAS Technologies", "desc": "Job Description \n  The role of a Data Analyst is the last phase of the process of data within Silent Falcon. Due to being the last step before being presented to the client, it is heavily interlocked with various departments and requires flexible skillsets and creative problem-solving. \n  About the Job \n \n  We\u2019re looking for a Data Analyst! Our software and data pipelines have been built from the ground up, so if you are excited about collaborating in a high-performance team and implementing the latest advancements in Aviation to impact the future of geospatial analytics, then this opportunity could be an excellent fit for you. \n  Typical Duties and Responsibilities \n \n Relabeling of data, for use by the client - both internal and externally \n GIS or esri experience \n Ensuring layers are represented and displayed correctly according to the collected data \n Collaborating between the various teams internally, the client, and stakeholders for visibility \n Attend weekly pavement training to enhance your skills and knowledge \n \n Education and Experiences \n \n  Intermediate computer experience, at minimum \n \n  Skills and Qualifications \n \n Eye for fine detail \n Ability to follow through on deadlines \n Clear communication \n Adept at learning \n Ability to work remotely \n \n The Location \n  Silent Falcon is located in Front Royal, VA and Albuquerque, NM. While both locations are great places to live, you can work remotely within the continental United States. Candidates must be U.S. Citizens.", "cleaned_desc": "", "techs": ""}, "dcedb2e4e9bc5153": {"terms": ["data analyst"], "salary_min": 85000.0, "salary_max": 105000.0, "title": "Technical Business Analyst", "company": "Kunz, Leigh & Associates", "desc": "Who We Are: \n KL&A is an IT consulting firm that knocks the socks off our clients. We work closely with organizations across the United States to develop creative business solutions through project & program management and custom software applications so they can focus on what\u2019s most important\u2026their mission. \n We are honored to be named a Top Workplace by the Detroit Free Press for five consecutive years! Here at KL&A, we love what we do and believe that our employees are our greatest asset which is why we search for the best and brightest (and perhaps the most caffeinated) of the bunch. This is why our employees have the opportunity to work in an environment of their choosing: whether in the dynamic office environment, in your PJ bottoms at home, or a combination of the two. \n Who You Are \n You approach projects with the perfect balance of analytical skills and curiosity. You are a logical thinker who enjoys analysis, writing, and planning, and your attention to detail is so good it\u2019s scary. You enjoy collaborating with those around you, but can also accomplish tasks as a solo artist. Your creative and open mindset allows you to develop unique solutions that help clients solve their business problems. You are a client-advocate who thinks about how to make business processes and training documentation easy for the user. Continuous learning is important to you, which makes you excited to learn new and challenging business domains. You\u2019re personable, self-motivated, and love lending a hand to your colleagues. You are skilled at finding the perfect meme for any situation and may also enjoy joking around with your peers while you enjoy a lunch delivered to your door, on KL&A. \n About the Role \n As a Technical Business Analyst, you\u2019ll work closely with clients, project managers, and software engineers to create, enhance and support custom web applications. Your first few months will be spent developing a deep understanding of your client\u2019s business processes and needs to be able to help your team design, refine, enhance and support the application, when necessary. You\u2019ll work closely with stakeholders and the development team, to ensure all documentation is well-written, meets standards, and, most importantly, is easily understood by the client. With Agile as the underlying foundation to our approach, you'll contribute to everything from process re-engineering to addressing change requests and bugs, all the while focusing on data organization and user experience. As the intermediary between clients and the development team, you will lead meetings to distill and refine business needs, effectively communicating information between technical and non-technical audiences. You\u2019ll provide support to the development team by answering questions, participating in peer reviews, and validating that the system performs to the required specifications. \n Superpowers We\u2019re Seeking \n \n A Bachelor\u2019s Degree or higher \n Must be legally authorized to work in the US without a current or future need for visa sponsorship \n A minimum of 5 years of experience as a Business Analyst, Technical Analyst, or Systems Analyst building web applications for external clients \n \n Systems and Process Analysis: \n \n Previous experience internalizing clients\u2019 business operations to ensure proper data validation, business rules & exceptions, and accurate workflows throughout the SDLC \n Understanding of business analysis process concepts, and how business needs drive the implementation approach to solutions \n Experience preparing for and conducting effective JAD sessions to elicit desired functionalities from clients about documented business and functional requirements \n \n Documentation and Writing: \n \n Experience analyzing and developing user stories, acceptance criteria, and test scenarios \n Must have excellent writing skills, including the ability to write user guides and technical/functional documentation for complex processes that is concise, yet thorough \n Experience producing project artifacts, including meeting notes, mockups, wireframes, process maps, and data flow diagrams to convey functionality to stakeholders and development teams. \n \n Communication and Client Management: \n \n Demonstrated experience creating and implementing strategies for effective communication and collaboration between the development team and non-technical client stakeholders. \n Experience collaborating with the development team(s) to design and develop functional solutions \n Experience building relationships with internal and external stakeholders by acting as a trusted advisor and liaison \n Must be self-motivated, resourceful, and adaptable to work efficiently and independently in a remote-first environment \n \n Technical Knowledge : \n \n Strong understanding of how data is structured and its influence on the overall solution, as well as experience analyzing data \n Experience writing SQL queries \n \n Gadgets and Gizmos : \n \n Experience using tools (such as Jira, Confluence, or TFS) to document and trace requirements through the software development life cycle \n Proficient in MS Excel, MS Word, MS PowerPoint, and MS Visio \n \n Bonus Superpowers \n \n Experience with Third Party Liability and coordination of benefits in the context of Medicaid, or equivalent experience within the commercial health insurance domain \n Knowledge of Microsoft Excel advanced features such as macros and/or relational database software \n Experience with testing \n Previous software development experience \n Experience ensuring the backlog is properly managed to maintain appropriate development velocity \n Previous experience triaging bugs \n \n Compensation & Perks: \n \n Competitive salaries with bonus potential \n Three (3) weeks of paid vacation (prorated for first year) \n 40 days of paid sick time (prorated for first year) \n Paid parental leave \n Family building assistance (adoption reimbursement, IVF counseling, etc.) \n 401(k) with immediate employer match \n Workspace customization bonus \n Ongoing education and training reimbursement \n Employee recruiting bonuses \n Monthly communication reimbursement \n Premium healthcare insurance, including medical, dental, and vision for individuals, families, and domestic partners \n Flexible Spending Accounts for dependent care and medical care \n Employer-paid group long-term disability and group life insurance \n Voluntary insurance options, such as pet, critical illness, AD&D, and life. \n Awesome co-workers! \n \n Work Environment \n Since the COVID-19 pandemic forced most of us to work remotely, KL&A has embraced the new flexible scheduling that was one of the microscopic lights at the end of the isolated tunnel. As a result, we are conducting all interviews virtually (get your Zoom background ready.) New employees have the option of being onboarded into a virtual, in-person, or hybrid work schedule and are provided the tools they need to begin employment successfully, regardless of location. \n Equal Employment Opportunities \n Kunz, Leigh & Associates provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Kunz, Leigh & Associates complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. \n Kunz, Leigh & Associates expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Kunz, Leigh & Associates\u2019 employees to perform their job duties may result in discipline up to and including discharge. \n Job Type: Full-time \n Pay: $85,000.00 - $105,000.00 per year \n Benefits: \n \n 401(k) 4% Match \n AD&D insurance \n Adoption assistance \n Continuing education credits \n Dental insurance \n Dependent health insurance coverage \n Disability insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid holidays \n Paid sick time \n Paid time off \n Parental leave \n Partner benefits \n Professional development assistance \n Tuition reimbursement \n Vision insurance \n Work from home \n \n Compensation package: \n \n Yearly bonus \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Must have excellent writing skills, including the ability to write user guides and technical/functional documentation for complex processes that is concise, yet thorough \n Experience producing project artifacts, including meeting notes, mockups, wireframes, process maps, and data flow diagrams to convey functionality to stakeholders and development teams. \n \n Communication and Client Management: \n \n Demonstrated experience creating and implementing strategies for effective communication and collaboration between the development team and non-technical client stakeholders. \n Experience collaborating with the development team(s) to design and develop functional solutions \n Experience building relationships with internal and external stakeholders by acting as a trusted advisor and liaison \n Must be self-motivated, resourceful, and adaptable to work efficiently and independently in a remote-first environment \n \n Technical Knowledge : \n \n Strong understanding of how data is structured and its influence on the overall solution, as well as experience analyzing data \n Experience writing SQL queries \n \n Gadgets and Gizmos : \n \n Experience using tools (such as Jira, Confluence, or TFS) to document and trace requirements through the software development life cycle \n Proficient in MS Excel, MS Word, MS PowerPoint, and MS Visio \n \n Bonus Superpowers \n ", "techs": ["jira", "confluence", "tfs", "ms excel", "ms word", "ms powerpoint", "ms visio"]}, "eb810c852c7b6513": {"terms": ["data analyst"], "salary_min": 43000.0, "salary_max": 79000.0, "title": "Data Analyst Quality Advisor", "company": "Premier Inc.", "desc": "Data Analyst Quality Advisor\n  \n \n  What will you be doing:\n  \n \n  This purpose of this position is to process member data from data receipt to entrance into the QualityAdvisor data warehouse error-free and effectively support members once the data is in the system. The analyst will be expected to communicate with members on a regular basis via email and phone calls answering basic member questions regarding data, processing or reporting issues. Provide written communication regarding deadlines, decisions, explanations of issues, etc. \n \n \n \n  This level will start out supporting 1-2 members the first few months and then grow workload to minimum of 10 members in 6 months. \n \n \n \n  This position works in collaboration with customers; QualityAdvisor Operations including the clinical staff, mentors, Supervisors, and the Solution Center to respond to client issues and questions; and Data Warehouse Services, Data Quality and Development teams to resolve data integrity or application issues; and other Premier stakeholders to ensure issues are resolved and required deliverables are met. \n \n \n \n   This position may require travel to hospitals to assist with installations, kickoffs or training classes for clients\n  \n \n \n  Data Processing \n  Customer Service \n  Data Acquisition tools \n \n \n  What we're looking for:\n  \n \n  Required Qualifications\n  \n \n   Work Experience:\n   Years of Applicable Experience - 2 or more years\n  \n   Skills & Experience:\n   Customer Service, Data Acquisition, Data Processing\n  \n   Education:\n   Bachelors\n  \n \n  Preferred Qualifications\n  \n \n   Relevant Experience to include:\n  \n \n  Practical hospital or healthcare related experience \n \n \n   Education:\n  \n \n \n   #LI-DNI\n  \n \n  Premier\u2019s compensation philosophy is to ensure that compensation is reasonable, equitable, and competitive in order to attract and retain talented and highly skilled employees. Premier\u2019s internal salary range for this role is $43,000 - $79,000. Final salary is dependent upon several market factors including, but not limited to, departmental budgets, internal equity, education, unique skills/experience, and geographic location. Premier utilizes a wide-range salary structure to allow base salary flexibility within our ranges.\n  \n  Employees also receive access to the following benefits:\n  \n \n  Health, dental, vision, life and disability insurance \n  401k retirement program \n  Paid time off \n  Participation in Premier\u2019s employee incentive plans \n  Tuition reimbursement and professional development opportunities \n \n \n \n   Premier at a glance:\n  \n \n  Ranked #1 on Charlotte\u2019s Healthiest Employers list for 2019, 2020 and 2022, and 49th Healthiest Employer in America (2022) \n  Named one of the World\u2019s Most Ethical Companies\u00ae by Ethisphere\u00ae Institute for the 13th year in a row \n  The only company to be recognized by KLAS twice for Overall Healthcare Management Consulting \n \n \n  Employees receive:\n  \n \n  Perks and discounts \n  Access to on-site and online exercise classes \n  Paid time off to volunteer in their communities \n \n \n   Premier is looking for smart, agile individuals like you to help us transform the healthcare industry. Here you will find critical thinkers who have the freedom to make an impact. Colleagues who share your thirst to learn more and do things better. Teammates committed to improving the health of a nation. See why incredible challenges require incredible people.\n  \n \n \n  Qualified applicants will receive consideration for employment without regard to unlawful discrimination because of their age, race, color, religion, national origin, ancestry, citizenship status, gender, sexual orientation, gender identity, gender expression, marital status, familial status, pregnancy status, genetic information, status as a victim of domestic violence, covered military or protected veteran status, disability, or any other applicable federal, state or local protected class, trait or status or that of persons with whom an applicant associates. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. In addition, as a federal contractor, Premier complies with government regulations, including affirmative action responsibilities, where they apply.\n  \n \n \n  Premier also provides reasonable accommodations to qualified individuals with a disability or those who have a sincerely held religious belief. If you need assistance in the application process, please reply to \n   \n   diversity_and_accommodations@premierinc.com\n    or contact Premier Recruiting at 704.816.5200.\n   \n  Information collected and processed as part of any job application you choose to submit to Premier is subject to Premier\u2019s \n   \n   Privacy Policy\n   .", "cleaned_desc": "", "techs": ""}, "a326c9f1bc036958": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Healthcare Data Analyst", "company": "Ozarks Community Hospital", "desc": "HEALTHY COMMUNITIES. COMPASSIONATE CARE. \n Ozarks Community Hospital in Gravette, AR has an immediate opening for a full-time,  Healthcare Data Analyst . Remote work opportunity available. \n Position Summary:  Responsible for developing and sustaining databases and software applications to achieve business requirements. Maintains, stores, maps, and develops data in compliance with policies and procedures. Prepares and validates routine and special information and reports. Assists in the design, research, and writing of technical specifications. Acts as a resource person to administrative team, department managers, the medical staff, nursing, and other ancillary departments. \n \n Creates workflow diagrams, explores alternative solutions, and writes programs. \n Responsible for finding and condensing raw data from multiple data sources and converting it into useable data for the analytics team. \n Responsible for effectively collecting, aggregating, and analyzing data required for CMS, other regulatory bodies and performance improvement projects. \n Coverts data into usable information and communicates information to others in a way that is easily understood. \n Performs other duties as assigned. \n \n About our health system:  Ozarks Community Hospital is a safety-net healthcare provider headquartered in Gravette, Arkansas, serving both urban and rural communities throughout the Ozarks. Our facilities include a hospital located in Gravette, Arkansas and a number of satellite clinics located in Southwest Missouri and Northwest Arkansas. \n Our Mission:  Ozarks Community Hospital and clinics are dedicated to providing exceptional healthcare and preventive services to all patients in an atmosphere of compassion, respect, and dignity, with a commitment to care for the underserved and to improve access to care. \n Benefits include: \n \n Eligibility for health, dental, and vision coverage; 401(k) plan; life insurance; short-term disability; flexible spending accounts; and many other elective benefits subject to plan terms. \n Paid time off (PTO) earned on an accrual basis, up to 3.5 weeks per year based on a 40 hour work week. \n Employee discounts. \n Company-paid holidays. \n \n Requirements: \n \n Bachelors or master\u2019s degree in data Analytics or related field. \n Experience in relevant clinical or technical area of expertise related to EMR preferred. \n Minimum of one (1) years\u2019 experience in SQL. \n \n OCH is an Equal Opportunity Employer \n Job Type: Full-time \n Benefits: \n \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Work Location: Hybrid remote in Gravette, AR 72736", "cleaned_desc": "HEALTHY COMMUNITIES. COMPASSIONATE CARE. \n Ozarks Community Hospital in Gravette, AR has an immediate opening for a full-time,  Healthcare Data Analyst . Remote work opportunity available. \n Position Summary:  Responsible for developing and sustaining databases and software applications to achieve business requirements. Maintains, stores, maps, and develops data in compliance with policies and procedures. Prepares and validates routine and special information and reports. Assists in the design, research, and writing of technical specifications. Acts as a resource person to administrative team, department managers, the medical staff, nursing, and other ancillary departments. \n \n Creates workflow diagrams, explores alternative solutions, and writes programs. \n Responsible for finding and condensing raw data from multiple data sources and converting it into useable data for the analytics team. \n Responsible for effectively collecting, aggregating, and analyzing data required for CMS, other regulatory bodies and performance improvement projects. \n Coverts data into usable information and communicates information to others in a way that is easily understood. ", "techs": ["healthcare data analyst", "databases", "software applications", "data compliance", "routine reports", "technical specifications", "workflow diagrams", "programs", "raw data", "analytics", "data analysis", "cms", "regulatory bodies", "performance improvement projects", "data communication"]}, "730444d210021f89": {"terms": ["data analyst"], "salary_min": 81424.266, "salary_max": 103101.266, "title": "Business Analyst III, Data Visualization", "company": "Pathward, N.A.", "desc": "We are a hybrid, remote-office company dedicated to growing our talent anywhere! \n  We have onsite locations in: Sioux Falls, SD, Scottsdale, AZ, Troy, MI, Franklin, TN, Dallas, TX \n  At Pathward, we take tremendous pride in our purpose to create financial inclusion for all\u2122. We are a financial empowerment company that works with innovators to increase financial availability, choice, and opportunity for all. We strive to remove barriers that traditional institutions put in the way of financial access, and promote economic mobility by providing responsible, secure, high quality financial products. \n  We are a team of problem solvers and innovators who celebrate our differences and know that our unique perspectives make us stronger and well-positioned for success. We celebrate, and embrace, our team members through our  *HUMBLE*HUNGRY*SMART  approach, and we believe that we are strongest when we embrace the voices of our employees, customers, partners, and the communities we serve. \n \n  About the Role: \n  Develop the visual aspect of data analysis. Help design reporting to communicate data in an engaging, consumable, and concise way. Create and maintain reporting packages for committee and leadership presentations. \n  What You Will Do: \n \n Develop dashboards, presentations, and internal communications by creating and utilizing templates with a consistent, cohesive theme. Update templates as needed. \n Develop data aesthetic and tone by creating presentations and communications that are consumable, visually appealing, and easily understood by the intended audience. \n Provide data visual packages for various internal customers including Leadership and the Board of Directors. \n Maintain various dashboards and reporting packages through regular updates. Assess effectiveness of output and update accordingly to highlight focus areas. \n Work closely with analysts to interpret data sets and determine relevant information to be included in data visualization output and the overall story to be communicated. Provide recommendations on effective output options based on the data. \n Participate in project teams and give presentations as needed. \n Develop and maintain presentations for Monthly Business Review meetings. \n Other duties as assigned. \n \n What You Will Need: \n \n Bachelor's degree or equivalent education and work experience. \n Typically, 3+ years with bachelor's or equivalent. \n Understanding of data and analytics required. \n Knowledge and experience in visual design, including senior management level presentations. \n Proficient in MS Office suite and BI tools. \n Communication (verbal & written) \n Ability to manage competing priorities \n Collaborative \n \n The responsibilities listed above are not all inclusive and may be changed at any time. \n  #LI-Remote \n \n  Don't have everything listed under qualifications? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single condition. At Pathward, we are dedicated to building a diverse and inclusive culture of belonging, so if you're excited about this role but your experiences don't match exactly to everything in the posting we encourage you to apply anyway. You may be just the right candidate for this or other Pathward roles. \n  Who we are: \n  Our commitment to inclusion is woven into our DNA. We believe that we are strongest when we embrace the voices of our employees, customers, partners, and the communities we serve. \n  We are committed to providing equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender (including pregnancy), sexual orientation, gender identity, national origin, age, disability, genetic information, marital status, amnesty, status as a covered veteran, or any other class protected by federal, state and local laws. \n  Please click here to learn more about our benefits and review information about our Privacy Policy, Affirmative Action Plan and other notices. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and certain state or local laws. For assistance completing an application, please contact a Pathward People & Culture Representative by emailing \u2013 careers@pathward.com \n  Please click here to view Pathward's Applicant Privacy Notice.", "cleaned_desc": " Typically, 3+ years with bachelor's or equivalent. \n Understanding of data and analytics required. \n Knowledge and experience in visual design, including senior management level presentations. \n Proficient in MS Office suite and BI tools. \n Communication (verbal & written) \n Ability to manage competing priorities \n Collaborative ", "techs": ["ms office suite", "bi tools"]}, "ad4f3c4f9e2964ba": {"terms": ["data analyst"], "salary_min": 132368.0, "salary_max": 172075.0, "title": "Management & Program Analyst (Data Analytics)", "company": "US Patent and Trademark Office", "desc": "Duties \n \n This role is the ideal next career step for you if: \n \n You can independently initiate, plan, and lead team projects and studies, with the collaboration of other professionals and contractors, to solve complex and far-reaching data management issues and problems for a wide range of systems, applications, and customers. \n You have strong analytical skills to develop, coordinate and promote cooperative efforts in the management, utilization, and operation of data processing and data communication resources. \n You're enthusiastic about maintaining, operating, and improving existing data products to address the needs of the business unit. \n You can conduct complex data analyses using extracted data and compiles results to brief executives and stakeholders on findings and recommendations. \n \n The physical worksite for this position is located in Alexandria, Virginia \n \n This position is eligible for fully remote work anywhere within the 50 United States, District of Columbia, and Puerto Rico. There is no reporting requirement. \n The duty station is the authorized telework location (typically your home address) and locality pay is adjusted appropriately. \n If selected for an interview, applicants are encouraged to discuss telework options and eligibility specific to the position in which they applied with the hiring manager. \n \n \n \n \n Requirements \n Conditions of Employment \n \n Applications will only be accepted from United States Citizens and Nationals. \n Your resume and question responses must demonstrate the job-related competencies. \n You must meet the definition of specialized experience. \n Required to pass a background investigation and fingerprint check. \n Must be registered for Selective Service, if applicable (www.sss.gov). \n If selected, you may be required to complete a one year probationary period. \n You must meet all qualification requirements upon the closing date of this announcement. \n Suitable for Federal Employment \n \n \n Qualifications \n \n    You must meet the United States Office of Personnel Management's (OPM) qualification requirements (including specialized experience and/or educational requirements) for the advertised position. You must meet all eligibility and qualifications requirements by the closing date of the job announcement. OPM Qualifications Standards are available at Group Qualifications Standard for Administration and Management positions.\n     \n  Specialized Experienceis experience that has equipped applicants with the particular knowledge, skills and abilities to successfully perform the duties of the position, and that is typically in or related to the position to be filled. To be creditable, specialized experience must have been equivalent to at least the next lower grade level in the federal service.\n     \n  For this position, the next lower grade level is a GS-13. \n     Specialized experience for this position includes: \n \n Experience leading complex data management projects, interpreting data and analyzing results using various statistical techniques and developing data visualization products and graphics; and  \n Experience with data programming languages or analytic tools in order to advise on the development, maintenance, support of data ingestion, analysis, interpretation and visualization tools such as SQL, R, Databricks, Alteryx, Tableau or Kibana. \n Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience. \n    \n \n \n Education \n Education may not be substituted for specialized experience at the GS-14 grade level.   \n \n \n Additional information \n \n If you are a male applicant born after December 31, 1959, you must certify that you have registered with the Selective Service System. If you are exempt from registration under Selective Service Law, you must provide appropriate proof of exemption. Please visit the Selective Service System website for more information.    This is a Bargaining Unit position and represented by The National Treasury Employees Union, Chapter 243 (NTEU 243).    This is a Public Trust position and has a risk level designation of \" MODERATE \".    Background Investigation - If selected for this position, you may be required to complete a Declaration for Federal Employment (OF-306), which includes a fingerprint and credit check, to determine your suitability for Federal employment and to authorize a background investigation.    The USPTO participates in E-Verify. For more information on E-Verify, please visit the Department of Homeland Security Website.    All Federal employees are required to have Federal salary payments made by direct deposit to a financial institution of their choice.    Relocation Expenses are not authorized and will not be paid.    CTAP and ICTAP candidates will be eligible for selection priority if it is determined that they have exceeded the minimum qualifications for the position by attaining at least a \"well qualified\" rating of 85 out of 100. Information about CTAP and ICTAP eligibility is on the Office of Personnel Management's Career Transition Resources website at: OPM CTAP/ICTAP.    CTAP/ICTAP documentation requirements are listed in the 'Required Documents' section of this announcement.     More than one selection may be made from this announcement  if additional identical vacancies in the same title, series, grade, and unit occur within 90 days from the date the certificate was issued.    All application materials become the property of the United States Patent and Trademark Office.    USPTO Job Applicants requiring reasonable accommodation for any part of the application and hiring process should request accommodation(s) from the USPTO at http://www.uspto.gov/accommodation.     The United States Patent and Trademark Office is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factors. If you believe that you have been discriminated against and would like to file an EEO complaint, you must do so within 45 days of the date of the alleged discriminatory act. Claims of employment discrimination must be submitted to the attention of the USPTO's Office of Equal Employment Opportunity & Diversity via email ( oeeod@uspto.gov ) or phone (571-272-8292). \n \n \n \n \n \n Benefits \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.  \n \n Review our benefits  \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n \n \n \n \n How You Will Be Evaluated \n \n You will be evaluated for this job based on how well you meet the qualifications above. \n Your resume, optional cover letter and supporting documentation will be reviewed to determine if you meet the minimum qualifications for the position. If you meet the minimum qualifications stated in the job opportunity announcement, we will compare your resume, optional cover letter and supporting documentation to your responses on the self-assessment questions (True/False, Yes/ No, Multiple Choice questions) and place you in one of three pre-defined categories. These categories are \" gold, \" \" silver ,\" and \" bronze .\" Your resume and/or optional cover letter must support your responses to the scored occupational questionnaire, or your score may be lowered.     Candidates placed in the \"GOLD\" category will be identified for referral to the hiring manager and may be invited for an interview.    How you will be evaluated for Veteran's Preference eligibility:     Preference eligibles with a service-connected disability of 10% or more will be listed at the top of the highest quality category (gold).      Your resume will be evaluated based on evidence of your ability to demonstrate possession of any specialized experience and how well your background and experience relates to the self-assessment questions in the job announcement.  Responses to job questions that are not fully supported by the information in your resume may result in adjustments to your rating. Any experience claimed in a cover letter should be substantiated by information contained in your resume. An HR Representative will validate the qualifications of those candidates eligible to be referred to the hiring official.     The scored occupational questionnaire will evaluate you on the following competencies; Please do not provide a separate written response.   \n \n Data Management \n  DataOps \n  Qualitative and Quantitative Analysis \n  System Analysis \n \n \n  For more information on category rating, please go to: DOC Bulletins\n    \n \n Please click the link below to preview the Assessment Questionnaire: \n  https://apply.usastaffing.gov/ViewQuestionnaire/12121778\n    \n  Please note that a complete application is required for consideration. (Please review the \"Required Documents\" section of this job announcement to see what must be included in a complete application). \n   \n \n \n \n \n Benefits \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.  \n \n Review our benefits  \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n Required Documents \n \n As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies. \n A complete application consists of:     1. A resume or any other written format you choose to describe your job-related qualifications; optional cover letter:  Your resume should indicate your citizenship and should list your educational and work experience including titles, salary, employment dates, duties, experience and how it relates to the specialized experience in the job announcement.     Supporting Documents:     PLEASE NOTE:  Applicants claiming veterans' preference entitlement or CTAP/ICTAP eligibility who fail to submit supplemental documentation within 5 business days of receiving the request will not lose consideration for this position, however they will not be entitled to special or priority consideration.     1. Veterans' Preference Documentation:  If you are a veteran with preference eligibility, you will be asked to submit a copy of your DD-214 containing your discharge disposition, dates of service, and rank. If you are a preference eligible claiming a service connected disability of 10 percent or more, you will be asked to submit documentation (i.e. a letter dated 1991 or later from the Department of Veterans Affairs or from a branch of the Armed Forces) certifying to the veteran's present receipt of compensation. Veterans must include dates of military service within the automated application process, and submit a copy of each Certificate of Release or Discharge from Active Duty, DD-214. For more information, please visit Feds Hire Vets.     2. Career Transition Assistance Program (CTAP) or Interagency Career Transition Assistance Program (ICTAP) documents  -     CTAP applicants MUST submit the following documents:  1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area; a Certificate of Expected Separation (CES); or certification that you are in a surplus organization or occupation (this could be a position abolishment letter. a notice of eligibility for discontinued service retirement. or similar notice); 2. A copy of your SF-50. Notification of Personnel Action\", noting current position, grade/band level, and duty location; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your bureau/operating unit that shows your current promotion potential.     ICTAP applicants MUST submit the following documents:  1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area, notice of disability annuity termination, certification from your former agency that it cannot place you after your recovery from a work-related compensable injury; or certification from the National Guard Bureau or Military Department that you are eligible for disability retirement. 2. A copy of your SF-50 \"Notification of Personnel Action\", documenting your RIF separation, noting your position, grade/band level, and duty location, and/or Agency certification of inability to place you through RPL, etc.; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your agency that shows your current promotion potential.    You can upload your documents when you register or update your information on the Dept. of Commerce site which you access through the USAJobs site.     Your application and all required documents must be received by 11:59 pm ET on the closing date of this job announcement.  NOTE: The preceding documents requirement are based on job requirements and individual applicant eligibility. Not all documents are applicable to all applicants; if you are unsure which documents apply to you, contact the HR Specialist listed on this announcement.  \n \n How to Apply \n \n \n You  MUST  apply online. If you experience difficulties with the application process or do not have access to a computer, please contact the HR Specialist listed as the point of contact before the closing date of this job announcement.    If you are a new user to the USAJobs Site and have never registered for an account; you will first need to create an account profile with your basic contact information and a resume to begin applying. You must be a registered USAJobs user AND you must be signed-in to your account in order to apply for this position. For help setting up an account or for general help using USAJobs, go to USAJobs Help Page. Once you have gathered all of the required information and are ready to begin the application process, click the \"APPLY\" button at the right side of the page. You will then be directed away from USAJobs to the Department of Commerce application site for USPTO. You must click \"Submit\" at the end of the application process to send your application for consideration.    To return to your saved application, log in to your USAJOBS account at http://www.usajobs.gov/ and click on \"Applications.\" Click on the position title, then select \"Update Application.\"    If you experience any difficulties with the application site, help is available! OPM has a Help feature on each page. Use this option when you need assistance.    All required supporting documents will be collected electronically via the USAJobs \"Saved Documents\" feature.     Personally Identifiable Information (PII)  Personally Identifiable Information (PII) is defined as information that can be traced back to a specific individual and potentially compromise their security or privacy. Examples of PII include: date of birth, Social Security Number, and place of birth.    Please ensure that you have removed all Personally Identifiable Information from all documents prior to submitting or uploading your applications material. \n \n \n Agency contact information \n Alicia Matute  \n \n \n Phone \n 571-270-0483  \n Email \n alicia.matute@uspto.gov  \n \n \n Address \n \n \n TMCO-Office of the Deputy Comm for Trademark Admin \n \n Office of Human Resources \n \n Mail Stop 171  \n \n P.O. Box 1450  \n \n Alexandria, VA 22313-1450 \n \n US  \n \n \n \n \n Next steps \n \n You will receive a notice generated by the USAJobs System when you have successfully submitted your application.    You will be notified of your application status through USAJOBS at four points during the hiring process, as applicable. You can check the status of your application by accessing the USAJOBS website at http://usajobs.gov/ and clicking on \"Track Your Online Application.\" The four points of notification are:    1. Application Received or Application Incomplete;  2. Minimum Qualification Requirement Met or Minimum Qualification Requirement Not Met;  3. Eligible (Application Referred to the Selecting Official) or Eligible (Application Not Referred to the Selecting Official); and  4. Selected or Not Selected    After all application packages have been received, we will review your application and transcript(s) (if you are qualifying based on education) to ensure you meet the basic qualification requirements. We will evaluate each applicant who meets the basic qualifications on the information provided and you may be contacted for follow-up supplemental documentation. It is the applicant's responsibility to provide any supplemental documents or information requested by the Office of Human Resources within the allocated timeframes.    You will be required to submit official documentation prior to appointment. The agency will then verify the information provided on your application (i.e., degree, veterans' preference, disability, etc.).You can check the status of your application by logging into USAJOBS. You may also sign up to receive automatic emails anytime the status of your application has changed by logging into your USAJobs Account, editing your profile and changing the \"Notification Settings\" to indicate that you want to be notified by email when the status changes. Information regarding the status of your application should be updated in the system within 2 weeks after the closing date of this job announcement.  \n \n \n Fair and Transparent \n \n The Federal hiring process is set up to be fair and transparent. Please read the following guidance.  \n \n Equal Employment Opportunity (EEO) Policy  \n Reasonable accommodation policy  \n Financial suitability  \n Selective Service  \n New employee probationary period  \n Signature and false statements  \n Privacy Act  \n Social security number request  \n \n \n \n \n \n Required Documents \n \n A complete application consists of:     1. A resume or any other written format you choose to describe your job-related qualifications; optional cover letter:  Your resume should indicate your citizenship and should list your educational and work experience including titles, salary, employment dates, duties, experience and how it relates to the specialized experience in the job announcement.     Supporting Documents:     PLEASE NOTE:  Applicants claiming veterans' preference entitlement or CTAP/ICTAP eligibility who fail to submit supplemental documentation within 5 business days of receiving the request will not lose consideration for this position, however they will not be entitled to special or priority consideration.     1. Veterans' Preference Documentation:  If you are a veteran with preference eligibility, you will be asked to submit a copy of your DD-214 containing your discharge disposition, dates of service, and rank. If you are a preference eligible claiming a service connected disability of 10 percent or more, you will be asked to submit documentation (i.e. a letter dated 1991 or later from the Department of Veterans Affairs or from a branch of the Armed Forces) certifying to the veteran's present receipt of compensation. Veterans must include dates of military service within the automated application process, and submit a copy of each Certificate of Release or Discharge from Active Duty, DD-214. For more information, please visit Feds Hire Vets.     2. Career Transition Assistance Program (CTAP) or Interagency Career Transition Assistance Program (ICTAP) documents  -     CTAP applicants MUST submit the following documents:  1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area; a Certificate of Expected Separation (CES); or certification that you are in a surplus organization or occupation (this could be a position abolishment letter. a notice of eligibility for discontinued service retirement. or similar notice); 2. A copy of your SF-50. Notification of Personnel Action\", noting current position, grade/band level, and duty location; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your bureau/operating unit that shows your current promotion potential.     ICTAP applicants MUST submit the following documents:  1. A copy of your RIF separation notice, notice of proposed removal for declining a directed geographic relocation outside of the local commuting area, notice of disability annuity termination, certification from your former agency that it cannot place you after your recovery from a work-related compensable injury; or certification from the National Guard Bureau or Military Department that you are eligible for disability retirement. 2. A copy of your SF-50 \"Notification of Personnel Action\", documenting your RIF separation, noting your position, grade/band level, and duty location, and/or Agency certification of inability to place you through RPL, etc.; 3. A copy of your latest performance appraisal including your rating; and 4. Any documentation from your agency that shows your current promotion potential.    You can upload your documents when you register or update your information on the Dept. of Commerce site which you access through the USAJobs site.     Your application and all required documents must be received by 11:59 pm ET on the closing date of this job announcement.  NOTE: The preceding documents requirement are based on job requirements and individual applicant eligibility. Not all documents are applicable to all applicants; if you are unsure which documents apply to you, contact the HR Specialist listed on this announcement. \n \n \n \n \n \n Help \n  This job is open to \n \n \n \n \n Career transition (CTAP, ICTAP, RPL) \n Federal employees who meet the definition of a \"surplus\" or \"displaced\" employee. \n \n \n \n \n The public \n U.S. Citizens, Nationals or those who owe allegiance to the U.S. \n \n \n \n Clarification from the agency \n Applications will be accepted from all U.S. Citizens or Nationals.", "cleaned_desc": "", "techs": ""}, "06b546b9db7c18a5": {"terms": ["data analyst"], "salary_min": 50.0, "salary_max": 55.0, "title": "Business Analysts", "company": "Conglomerate IT", "desc": "7+ years of experience. \n Role : Business Analysts( Retirement Business Knowledge) \n looking folks with experience on OPF (Open Payment Framework) wire, ACH. \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour \n Experience level: \n \n 7 years \n \n Schedule: \n \n Day shift \n \n Experience: \n \n Retirement Business Knowledge: 4 years (Required) \n Open Payment Framework: 4 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "82cf35fb0767a359": {"terms": ["data analyst"], "salary_min": 55.0, "salary_max": 60.0, "title": "Enrollment Business Analyst", "company": "Merican Inc", "desc": "Merican Inc. is a staffing firm that offers recruitment solutions to large clients across the United States. \n Job Role: Enrollment BA \n Location: Remote \n Type: Contract \n Job Requirement: \n Take the tech lead in capturing business requirements! \n Enrolment BA \n Enrolment EAM project \n Facets: Medicare Processes \n Job Type: Contract \n Salary: $55.00 - $60.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Enrollment: 3 years (Required) \n Enrollment Administration Manager: 1 year (Required) \n Facets: 4 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "9eb193307dd4c84c": {"terms": ["data analyst"], "salary_min": 53105.0, "salary_max": 84441.0, "title": "Program Analyst", "company": "US Geological Survey", "desc": "Duties \n \n As a Program Analyst within the Office of Budget, Planning and Integration (OBPI), some of your specific duties will include: \n \n Uses qualitative and quantitative analysis methods to analyze program-related data and identify and analyze program or policy issues using quantitative data. \n In a developmental capacity, participates in several annual USGS wide data-calls that includes revising annual guidance, SOPs, aggregating large data-sets in order to submit final results to OBPI leadership. \n Works with and assists senior-level analysts to evaluate existing internal processes and procedures, drafting proposed findings and recommendations for the improvement of administrative systems, legislation, and regulations in order to promote efficiency and to achieve mission-oriented programs and organizational objectives. \n Assists with drafting, reviewing, editing, and/or providing input to written materials, including program guidance, informational/decision memoranda, pre-meeting background briefings, talking points for senior-level manager meetings (from informal to international), speeches, testimony, and decision proposals/justifications. \n Ability to collaborate and interact on project teams with multiple stakeholders, including peers, management, and external stakeholders. \n Provides operational technical and administrative support to critical projects, programs, and policies within the organization \n \n \n \n \n Requirements \n Conditions of Employment \n Key Requirements :   \n \n \n Applicants must be U.S. Citizens. \n \n \n Suitable for Federal employment, as determined by background investigation. \n \n \n Selectee may be subject to serving a one-year probationary period. \n \n \n More requirements are listed under Qualifications and Other Information. \n \n \n Are There Any Special Requirements For This Position? \n \n If selected you may be asked to provide information regarding your COVID-19 vaccination status for the purposes of implementing workplace safety protocols, such as those related to masking, physical distancing, testing, travel, and quarantine. \n Because this position requires travel for official business, the selectee will be required to apply for a charge card within 30 calendar days of appointment. Individuals who have delinquent account balances from a previous Government charge card will be required to satisfy their existing obligation before a new card can be issued. \n \n \n A background investigation will be required for this position. Continued employment will be subject to the applicant's successful completion of a background security investigation and favorable adjudication. Failure to successfully meet these requirements will be grounds for termination. \n Throughout the recruitment and hiring process we will be communicating with you via email; therefore, it is imperative that the email address you provide when applying for this vacancy remains active. Should your email address change, please notify the point of contact identified in the vacancy announcement as soon as possible so that we can update our system. \n \n \n \n Qualifications \n \n For GS-07: \n Applicants must meet one of the following to qualify for the GS-07 level: \n Possess one year of specialized experience in or directly related to this position that equipped the applicant with the knowledge, skills, and abilities to perform successfully the duties of this position. To be creditable, the required specialized experience must have been equivalent to at least the GS-5 level in the Federal service. Examples of GS-5 level work include: analyzing problems to identify significant factors, gathering pertinent data, and recognizing solutions regarding programs and functions; planning and organizing work; and communicating effectively orally and in writing. \n **OR applicants may substitute successful completion of one full year of graduate level education which provided the applicant with the knowledge, skills, and abilities necessary to do the work of a Management Analyst. \n **OR a combination of successfully completed graduate level education and experience that meets the total qualification requirement for the GS-07 level. \n **OR Superior Academic Achievement. \n \n   For GS-09: \n Applicants must meet one of the following to qualify for the GS-9 level: One year of specialized experience in or directly related to this position that equipped the applicant with the knowledge, skills, and abilities to perform successfully the duties of this position. To be creditable, the required specialized experience must have been equivalent to at least the GS-7 level in the Federal service. Examples of GS-7 level work include assisting in: 1) Research and investigations of new and improved business and management practices; 2) development of management and program evaluation plans, procedures, and methodology; 3) management surveys to determine compliance with regulations, procedures, sound management practices and effective utilization of staff. This level of work typically involved following established methods and procedures or detailed instructions; using some judgment in applying analytical techniques; solving minor problems and making routine decisions. \n **OR applicants may substitute successful completion of 2 years of progressively higher-level graduate education or master's or equivalent graduate degree (such as an LL.B or J.D if related). (36 semester hours, 54 quarter hours, or the equivalent). \n **OR a combination of appropriate specialized experience (as described above) and graduate education (as described above) that is beyond the first year of progressive graduate study to meet the qualification requirements. \n  You must meet all qualification and eligibility requirements for the position by the closing date of the announcement. \n \n \n \n \n Education \n \n \n Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g. Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community; student; social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience. \n Education completed in colleges or universities outside the United States may be used to meet the above requirements. You must provide acceptable documentation that the foreign education is comparable to that received in an accredited educational institution in the United States. For more information on how foreign education is evaluated, visit: https://www.usgs.gov/about/organization/science-support/human-capital/how-foreign-education-evaluated-federal-jobs . \n \n \n \n \n Additional information \n \n Other Information :   \n \n Applicants who include vulgar, offensive, or inappropriate language or information in their application package will be ineligible for further consideration for this position. \n Identification of promotion potential in this announcement does not constitute a commitment or an obligation on the part of management to promote the employee selected at some future date. Promotion will depend upon administrative approval and the continuing need for and performance of higher-level duties. \n Under Executive Order 11935, only United States citizens and nationals (residents of American Samoa and Swains Island) may compete for civil service jobs. Agencies are permitted to hire non-citizens only in very limited circumstances where there are no qualified citizens available for the position. \n USGS employees are subject to Title 43, USC Section 31(a) and may not: (a) have any personal, private, direct or indirect interest in lands or mineral wealth of lands under survey; (b) have any substantial personal, private, direct or indirect interests in any private mining or mineral enterprise doing business with the United States; or (c) execute surveys or examinations for private parties or corporations. \n The application contains information subject to the Privacy Act (P.L. 93-579, 5 USC 552a). The information is used to determine qualifications for employment, and is authorized under Title 5, USC, Section 3302 and 3361. \n DOI uses E-Verify to confirm the employment eligibility of all newly hired employees. To learn more about E-Verify, including your rights and responsibilities, please visit www.dhs.gov/E-Verify. \n The Department of the Interior (DOI) places a high value on diversity of experience and cultural perspectives and encourages applications from all interested eligible candidates. Diversity, equity, inclusion, and accessibility (DEIA) are fundamental principles that guide the Department and allow us to successfully achieve our mission. \n THE FEDERAL GOVERNMENT IS AN EQUAL OPPORTUNITY EMPLOYER. \n \n Agency Benefits \n : \n \n USGS has determined that the duties of this position are suitable for telework and the selectee may be allowed to telework in accordance with the DOI Telework policy and with supervisor approval. The official worksite for the selectee is the duty station identified in this vacancy announcement. The selectee will typically report to this duty location on a regular and recurring weekly basis. \n For additional information on our internal telework policy, please reference the Department of the Interior Telework Handbook at: https://www.doi.gov/telework/policies. \n Working for the U.S. Geological Survey offers a comprehensive benefits package that includes paid vacation, sick leave, and holidays; health, life, dental, vision, and long term care insurance, flexible spending accounts, and participation in the Federal Employees Retirement System. \n \n \n \n \n \n \n \n Benefits \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.  \n \n Review our benefits  \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n \n \n \n \n How You Will Be Evaluated \n \n You will be evaluated for this job based on how well you meet the qualifications above. \n \n -Vacancy Related Questions:  As part of the online application process, you will need to respond to a series of questions designed to assess your possession of the following knowledge skills, abilities and/or competencies: \n     Compile/Analyze Data, Information Management, Written Communication, Administration Regulations/Procedures, Teamwork, Pressure/Deadlines. \n \n -Basis of Rating:  Category rating will be used in the ranking and selection process for this position. The quality categories are Best Qualified and Qualified. Your qualifications will be evaluated based on your application materials (e.g., resume, supporting documents), the responses you provide on the application questionnaire, and the result of the additional assessment required for this position. Your responses must be substantiated by your resume. If you do not respond to the application questions you may be rated ineligible. Veterans' preference rules for category rating will be applied.\n     \n \n - Additional Assessment Required:  If you meet the eligibility and basic qualification requirements for this position a subject-matter-expert will perform a structured review of your resume to evaluate your knowledge, skills, abilities, and competences as they directly relate to the duties of this position. \n \n \n -NOTE:  If it is determined that you have rated yourself higher than is supported in your description of experience and/or education as described in your resume/application, or that your resume or application is incomplete, you may be rated ineligible, not qualified, or your score may be lowered.\n     \n  To preview the announcement questionnaire, click here: https://apply.usastaffing.gov/ViewQuestionnaire/12116910 \n    \n \n \n \n \n Benefits \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.  \n \n Review our benefits  \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n Required Documents \n \n As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies. \n \n      Required documents may be: (1) uploaded directly from your desktop; or (2) uploaded directly from your USAJOBS stored attachments.\n       \n \n Resume \n \n \n -You are highly encouraged to use USAJOBS Resume Builder to ensure all required information is included in your Resume. If you use your own resume, curriculum vitae, or other written form, then you must describe your job-related qualifications, including: beginning and ending dates for paid and non-paid work experience; hours worked per week; month and year of employment for each job title listed; annual salary; and description of job duties. Include name and address of employer; supervisor name and telephone number. Additional information on what to include can be found here. \n \n \n Supporting documents \n \n \n -Upload any supporting documents identified in the Key Requirements section or included below as it applies to your eligibility. Supporting documents may be: (1) uploaded directly from your desktop; or (2) uploaded directly from your USAJOBS stored attachments \n \n \n Transcripts \n \n \n -If this position requires specific educational course work to qualify, or you are qualifying based in whole or part on education, you are required to provide all unofficial transcripts (undergraduate, graduate, etc.) or list of course work, which includes semester hours earned and grade received, by the closing date of this announcement or you will be disqualified from further consideration. Please ensure that all documentation is legible. \n \n \n Veterans' Preference Eligibles \n \n \n -If you are claiming veterans' preference you must provide a legible copy of your DD-214, Certificate of Release or Discharge from Active Duty, member 4 copy or any official documentation or statement from the Armed Forces that confirms your dates of service and that your separation, discharge, or release from active duty was under honorable conditions (i.e., Honorable or General Discharge). Note: If you have more than one DD-214 for multiple periods of active duty, submit a copy for each period of service. \n \n \n \n -If you are currently on active military duty, you must provide documentation (e.g., campaign document, award citation, etc.), that verifies entitlement to veterans' preference and that your character of military service is honorable. \n \n \n \n -If you are claiming 10-point veterans' preference, in addition to the documents specified above, you must also submit documentation that supports your claim, e.g., an official statement from the Department of Veterans Affairs (dated 1991 or later) or from a branch of the Armed Forces certifying the existence of a service-connected disability, or the award of the Purple Heart, etc. The overall rating must be identified on your certification letter or separation orders. Documentation must be received by the closing date shown in this vacancy announcement. If you fail to submit any of the required documentation, you will not be granted veterans' preference. \n \n  Additional information on veterans' preference can be found in the VetGuide.\n       \n \n Career Transition Assistance Plan (CTAP) & Inter-agency Career Transition Assistance Plan (ICTAP) Eligibles \n \n \n -If you are claiming CTAP/ICTAP eligibility, the Servicing Human Resources Office must receive proof by the closing date of this announcement that you meet the requirements of 5 CFR 330 Subpart F for CTAP and 5 CFR 330 Subpart G for ICTAP or you will not receive priority consideration. This includes:  \n \n \n \n copy of the agency notice; \n your most recent Performance Rating; and \n your most recent SF-50 noting current position, grade level, and duty location. \n If you are a CTAP or ICTAP eligible, you will be considered well qualified if you earn a minimum score of 85 (prior to the assignment of veteran's preference points). For more information on CTAP/ICTAP please click here. \n      \n \n If you are relying on your education to meet qualification requirements:  \n Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.  \n Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.  \n \n \n How to Apply   \n \n \n \n -Applications (resume and application questions) for this vacancy must be received on-line via USAJOBS BEFORE midnight Eastern Time (Washington, D.C. time) on the closing date of this announcement. If you fail to submit a complete online resume, you will not be considered for this position. Requests for extensions will not be granted. Most libraries, employment offices, and all USGS personnel offices can provide access to the Internet. If applying online poses a hardship for you, you must speak to someone in the Servicing Human Resources Office listed on this announcement PRIOR TO THE CLOSING DATE for assistance. \n \n \n \n -Instructions for Applying Online for this Vacancy Announcement: 1)Click the blue \"Apply Online\" button. 2)If you are not a registered USAJOBS user, please create a new account and follow the instructions to complete your application process. If you are a registered user, login to access your existing USAJOBS profile. 3)As a registered user, select a stored resume and select one or more of your stored documents to attach to your application. 4)Check the \"Certification\" box and click the \"Apply for this position now!\" button located at the bottom of the screen. 5)Address the eligibility questions as well as the questionnaire containing questions and/or task statements that address the knowledge, skills, abilities and/or competencies for this vacancy. 6)Submit required documents. 7) If you experience technical difficulties during the online application process, please contact the USAJOBS helpdesk. \n \n \n \n \n Agency contact information \n Kathy Falino  \n \n \n Phone \n 703-648-7408  \n Email \n kfalino@usgs.gov  \n \n \n Address \n \n \n OFFC OF BUDGET, PLAN AND INTEGR \n \n 12201 Sunrise Valley Drive \n \n Mail Stop 600  \n \n Reston, VA 20192 \n \n US  \n \n \n \n \n Next steps \n \n \n -If you are rated as one of the most highly qualified candidates, you will be referred to the hiring manager for further consideration and possible interview. We expect to make a selection within 30-45 days of the closing date of this announcement. You will be notified via email of the outcome. You can also go to \"My Account\" within USAJOBS to review your Application Status.  \n \n \n \n Fair and Transparent \n \n The Federal hiring process is set up to be fair and transparent. Please read the following guidance.  \n \n Equal Employment Opportunity (EEO) Policy  \n Reasonable accommodation policy  \n Financial suitability  \n Selective Service  \n New employee probationary period  \n Signature and false statements  \n Privacy Act  \n Social security number request  \n \n \n \n \n \n Required Documents \n \n \n    Required documents may be: (1) uploaded directly from your desktop; or (2) uploaded directly from your USAJOBS stored attachments.\n     \n \n Resume \n \n \n -You are highly encouraged to use USAJOBS Resume Builder to ensure all required information is included in your Resume. If you use your own resume, curriculum vitae, or other written form, then you must describe your job-related qualifications, including: beginning and ending dates for paid and non-paid work experience; hours worked per week; month and year of employment for each job title listed; annual salary; and description of job duties. Include name and address of employer; supervisor name and telephone number. Additional information on what to include can be found here. \n \n \n Supporting documents \n \n \n -Upload any supporting documents identified in the Key Requirements section or included below as it applies to your eligibility. Supporting documents may be: (1) uploaded directly from your desktop; or (2) uploaded directly from your USAJOBS stored attachments \n \n \n Transcripts \n \n \n -If this position requires specific educational course work to qualify, or you are qualifying based in whole or part on education, you are required to provide all unofficial transcripts (undergraduate, graduate, etc.) or list of course work, which includes semester hours earned and grade received, by the closing date of this announcement or you will be disqualified from further consideration. Please ensure that all documentation is legible. \n \n \n Veterans' Preference Eligibles \n \n \n -If you are claiming veterans' preference you must provide a legible copy of your DD-214, Certificate of Release or Discharge from Active Duty, member 4 copy or any official documentation or statement from the Armed Forces that confirms your dates of service and that your separation, discharge, or release from active duty was under honorable conditions (i.e., Honorable or General Discharge). Note: If you have more than one DD-214 for multiple periods of active duty, submit a copy for each period of service. \n \n \n \n -If you are currently on active military duty, you must provide documentation (e.g., campaign document, award citation, etc.), that verifies entitlement to veterans' preference and that your character of military service is honorable. \n \n \n \n -If you are claiming 10-point veterans' preference, in addition to the documents specified above, you must also submit documentation that supports your claim, e.g., an official statement from the Department of Veterans Affairs (dated 1991 or later) or from a branch of the Armed Forces certifying the existence of a service-connected disability, or the award of the Purple Heart, etc. The overall rating must be identified on your certification letter or separation orders. Documentation must be received by the closing date shown in this vacancy announcement. If you fail to submit any of the required documentation, you will not be granted veterans' preference. \n \n  Additional information on veterans' preference can be found in the VetGuide.\n     \n \n Career Transition Assistance Plan (CTAP) & Inter-agency Career Transition Assistance Plan (ICTAP) Eligibles \n \n \n -If you are claiming CTAP/ICTAP eligibility, the Servicing Human Resources Office must receive proof by the closing date of this announcement that you meet the requirements of 5 CFR 330 Subpart F for CTAP and 5 CFR 330 Subpart G for ICTAP or you will not receive priority consideration. This includes:  \n \n \n \n copy of the agency notice; \n your most recent Performance Rating; and \n your most recent SF-50 noting current position, grade level, and duty location. \n If you are a CTAP or ICTAP eligible, you will be considered well qualified if you earn a minimum score of 85 (prior to the assignment of veteran's preference points). For more information on CTAP/ICTAP please click here. \n    \n \n If you are relying on your education to meet qualification requirements:  \n Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.  \n Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating. \n \n \n \n \n \n \n Help \n  This job is open to \n \n \n \n \n Career transition (CTAP, ICTAP, RPL) \n Federal employees who meet the definition of a \"surplus\" or \"displaced\" employee. \n \n \n \n \n The public \n U.S. Citizens, Nationals or those who owe allegiance to the U.S. \n \n \n \n Clarification from the agency \n Open to all qualified U.S. citizens.", "cleaned_desc": "", "techs": ""}, "b29fd5b13a0dc0aa": {"terms": ["data analyst"], "salary_min": 79272.49, "salary_max": 100376.63, "title": "Remote Business Data Analyst - Business Intelligence (BI)", "company": "The Infosoft Group", "desc": "Pay Transparency Statement:    The compensation philosophy reflects the Company's reasonable expectation at the time of posting. We consider a number of factors when making individual compensation decisions including, but not limited to, skill sets, experience and training, and other business needs. This role may also be eligible to participate in a discretionary incentive program, subject to the rule governing the program.  \n \n Position Summary:  This Business Analyst position will work within a Business Intelligence Scrum Team and bridge the gap between our business partners and technology solution providers (e.g., vendors, infrastructure team, development team, etc.) by translating their business needs into BI solutions. This position will also involve identification/development of and execution of test plans to ensure that technical solutions meet the needs of the business.     Position Responsibilities may include, but not limited to: \n \n Deliver design documents as part of SDLC (requirement gathering and analysis, design, testing, deployment and plan support maintenance). \n Build relationships with business clients along with the Product Owner and acts as a liaison between the business community and technical team. \n Assist Product Owner in determining value and priority of competing projects across multiple business functions to better create roadmaps and timelines. \n Analyze change requests to determine feasibility in relation to existing business requirements and processes. \n Interface with developers and vendors to understand whether we can meet business and technical requirements. \n Anticipate the needs of the business and align solutions to strategic initiatives. \n Identify missing requirements based on experience and business goals. \n Ensure transition and documentation for ongoing system support. \n Work with business partners to develop acceptance criteria / test cases in order to develop comprehensive test plan and perform needed application testing. \n Maintain all documentation, including business and technical application requirements, report requirements, and support documentation. \n Document data requirements, source systems involved, and perform data profiling to assist in determining project feasibility. \n Other projects or duties as assigned. \n \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Reyes Beer Division \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   Open", "cleaned_desc": "", "techs": ""}, "1604b5d8eaefa226": {"terms": ["data analyst"], "salary_min": 100000.0, "salary_max": 135000.0, "title": "Senior Data Analyst", "company": "The Infosoft Group", "desc": "Description\n   As a Senior Data Analyst, you will work with business users to define new data requirements, build/maintain data models, map data from transaction systems to the data warehouse, maintain data catalogs, and help maintain data quality by working with customer service and operations to address business process issues that impact the quality of data. \n \n  The ability to communicate across a broad set of stakeholders, solicit requirements, define solutions, document and implement new data governance processes, and measure outcomes will be key to the success of this role. \n \n  Responsibilities: \n \n  Work with stakeholders throughout the organization to identify opportunities for leveraging data & analytics to drive business outcomes. \n  Communicate across a wide range of audiences with specialized subject matter expertise including Marketing, Sales, Finance, Product, Brand Leaders, and Technology. \n  Define and maintain data models to represent core objects of the business and their relationships. Help resolve inconsistencies across business units and drive standardization where possible. \n  Maintain Data Catalog to ensure common understanding of data assets and map source data to data warehouse tables. \n  Query, manipulate, and validate data across multiple database technologies and querying languages. \n  Work with Project Managers to help manage stories / use cases in Jira backlog. \n \n \n  Core Skills: \n \n  5-10 years of experience \n  Data Requirements Analysis \n  Data Modeling and Table Design \n  Data Governance processes including working with Data Catalogs \n  Accessing data in AWS Redshift using general SQL queries \n  Managing and prioritizing multiple concurrent requests  \n \n \n Additional Skills/Knowledge that might help: \n \n  Understanding of Agile methodology and principles \n  Experience with Talend ETL tool \n  Experience with building Tableau reports \n  Experience with Subscription Businesses \n  Bachelor's Degree \n \n \n  This position is exempt under the Fair Labor Standards Act and is not eligible for overtime pay.    Pay Transparency Disclosure:    The estimated base salary range for this position is $100,000 to $135,000.    The final salary offering will take into account a wide range of factors, including experience, accomplishments and location. The salary range provided should not be considered as a salary limit or cap. In addition to base salary, Crain also offers competitive benefits including retirement plan savings contributions and bonus opportunities based on individual and company performance. \n \n  #LI-Remote \n  #LI-KL1 \n  #mid \n  #data \n  #full-time \n \n  Visit us at www.Crain.com \n \n  Environmental Demands \n  Where you work matters. The job posting will provide specific information on where and when your amazing work would be performed. Employee work location is determined by the needs of the specific team and may include on-site, hybrid or remote.  \n \n An \"in-office\" role would require the employee to come into the office most days with occasional flexibility to work remotely if tasks can be performed elsewhere and if the manager approves.  A \"remote\" role would allow an employee to work from a home office that is in one of the states Crain does business in. \n   k from home employee unless they reside in one of these states. \n  A \"hybrid\" role would be a mix of in-office and remote work. There may be a specified schedule for coming into the office or it could be at the discretion of the employee with the manager's approval. \n \n \n  Many positions will also include work done in \"the field.\" Depending on the role, this may include conducting in-person interviews, attending work-related events, meeting with sources or clients. Specifics will be noted in the job posting. Employees may be exposed to adverse environmental conditions, specifically during field work. Other typical job functions are performed under conditions such as those found in general office work. \n \n  Travel to cover news stories/events, meetings with clients, and to our geographically separated offices may be required. It is the nature of many positions to experience non-standard working hours and be on-call when needed for responding to email, meeting with clients, attending work-related events, story development or breaking news. Most employees perform work Monday through Friday, although early-morning, evening or weekend shifts may be required.  \n \n Phys ical Demands  The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of many Crain jobs. \n  Physical activities will include frequent in-person or virtual interactions. For most positions, it is essential to be able to remain at a desk/computer workstation for prolonged periods, perform computer-related tasks, and create/maintain documents within filing systems. Must have close visual acuity to perform an activity, such as preparing and analyzing reports and information, transcribing, viewing a computer terminal, or extensive reading. The typical physical requirements are light work-exerting up to 25lbs of force occasionally and/or up to 10lbs of force frequently and may include climbing, pushing, standing, hearing, walking, reaching, grasping, kneeling, stooping, and repetitive motion. Some positions will have additional physical requirements, including exerting up to 50lbs of force to move and/or carry equipment, supplies, files, or other materials as the role requires. \n \n  Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions and meet the environmental and physical demands of the role. \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c) \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Crain Communications \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   5 to 10 years", "cleaned_desc": "Description\n   As a Senior Data Analyst, you will work with business users to define new data requirements, build/maintain data models, map data from transaction systems to the data warehouse, maintain data catalogs, and help maintain data quality by working with customer service and operations to address business process issues that impact the quality of data. \n \n  The ability to communicate across a broad set of stakeholders, solicit requirements, define solutions, document and implement new data governance processes, and measure outcomes will be key to the success of this role. \n \n  Responsibilities: \n \n  Work with stakeholders throughout the organization to identify opportunities for leveraging data & analytics to drive business outcomes. \n  Communicate across a wide range of audiences with specialized subject matter expertise including Marketing, Sales, Finance, Product, Brand Leaders, and Technology. \n  Define and maintain data models to represent core objects of the business and their relationships. Help resolve inconsistencies across business units and drive standardization where possible. \n  Maintain Data Catalog to ensure common understanding of data assets and map source data to data warehouse tables. \n  Query, manipulate, and validate data across multiple database technologies and querying languages. \n  Work with Project Managers to help manage stories / use cases in Jira backlog. \n \n \n  Core Skills: \n \n  5-10 years of experience \n  Data Requirements Analysis \n  Data Modeling and Table Design \n  Data Governance processes including working with Data Catalogs ", "techs": ["jira", "data modeling", "data governance", "data catalog"]}, "29467dcd628e49aa": {"terms": ["data analyst"], "salary_min": 35.0, "salary_max": 45.0, "title": "Digital Data Analyst", "company": "The Judge Group", "desc": "Position:  Digital Data Analyst \n Type:  Contract \n Location:  100% Remote \n \n \n Responsibilities: \n \n Develop and distribute reports and digital dashboards to track website and campaign performance, business trends, provider behavior, web engagement and other metrics for the provider space \n \n \n Perform in-depth analysis of website visitors across multiple websites to understand behavior and uncover key areas for improvement to drive engagement and success. \n \n \n Leverage business knowledge and analytical skills to translate results into clear insights and recommendations to support continuous improvement to websites and campaigns. \n \n \n Suggest ways to optimize and test websites and marketing programs based on analysis and reporting \n \n \n Share insights and recommendations to business partners and leadership through presentations and other communications. \n \n \n Evaluate current reporting tools and capabilities to identify and implement improvements and changes. \n \n \n Collaborate with team to ensure consistency of information and reports, share best practices and develop systems knowledge. \n \n \n \n Requirements: \n \n Strong analytics, strategic, and critical thinking skills \n \n \n Competent in completing in-depth analysis and development of clear recommendations. \n \n \n Hands-on experience with web analytics tools such as Adobe Analytics, CoreMetrics, WebTrends, Google Analytics, or similar tools (Adobe Analytics Preferred) \n \n \n Advanced Excel skills \n \n \n Strong understanding of the digital marketing landscape is a must \n \n \n Strong communication skills are essential; must be able to listen and understand the question and develop and present clear insights to all levels of the organization \n \n \n Ability to organize and prioritize multiple tasks with high degree of attention to detail \n \n \n Self-directed and strong personal initiative and accountability", "cleaned_desc": "", "techs": ""}, "529980800968460e": {"terms": ["data analyst"], "salary_min": 90000.0, "salary_max": 95000.0, "title": "Cyber Business Analyst", "company": "APPIC Solutions LLC", "desc": "Not open for C2C-ONLY W2 \n Location:  Remote \n Job Description: \n As a Cyber Business Analyst, you will play a pivotal role in bridging the gap between cybersecurity and business objectives. You will be responsible for analyzing and understanding the unique needs of our clients, translating them into actionable cybersecurity requirements, and supporting the implementation of effective cybersecurity solutions. This position will require a deep understanding of cybersecurity principles, business processes, and excellent communication skills. \n Key Responsibilities: \n -Collaborate with business stakeholders to gather, document, and analyze cybersecurity requirements, ensuring alignment with business goals. \n - Evaluate the organization's cyber risk posture by identifying potential vulnerabilities, threats, and recommending mitigation strategies. \n -Assess the potential impact of cybersecurity incidents on business operations and revenue, assisting in the development of incident response plans. \n - Analyze and recommend cybersecurity technologies, tools, and practices to enhance the organization's security posture. \n - Develop and maintain key performance indicators (KPIs) and metrics to measure the effectiveness of cybersecurity measures and report to management. \n -Stay up-to-date with relevant cybersecurity regulations and standards and ensure the organization's compliance with them. \n -Assist in the development of cybersecurity awareness programs to educate employees on best practices and threats. \n -Act as a liaison between the cybersecurity team and business stakeholders during cybersecurity incidents, providing guidance and support as needed. \n -Maintain accurate records of cybersecurity requirements, risk assessments, and security-related documentation. \n - Effectively communicate cybersecurity risks and recommendations to both technical and non-technical stakeholders. \n Qualifications: \n -Demonstrable experience gathering data from diverse groups to document technical requirements for cybersecurity architecture designs \n -Good verbal and written communication skills, including advanced level in policy and procedure development \n -Solid understanding of core Threat Intelligence concepts, such as Cyber Kill Chain and MITRE ATT&CK \n - Bachelor's degree in Computer Science, Information Technology, Business, or related field (Master's degree preferred). \n - Strong understanding of cybersecurity principles, technologies, and best practices. \n - Knowledge of relevant cybersecurity frameworks, such as NIST, ISO 27001, or CIS. \n - Excellent analytical and problem-solving skills. \n - Strong written and verbal communication skills. \n - Ability to work collaboratively with cross-functional teams. \n - Relevant certifications (e.g., Certified Information Systems Security Professional (CISSP), Certified Information Security Manager (CISM), Certified Business Analyst Professional (CBAP)) is a plus. \n Job Type: Full-time \n Pay: $90,000.00 - $95,000.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n This role is ONLY OPEN FOR W2 FULL TIME SEEKERS. Please confirm below that you are seeking a W2 full time role to be considered for this position. \n How many years do you have documenting technical requirements for cybersecurity architecture designs? \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n gathering data from diverse groups: 4 years (Required) \n policy and procedure development: 4 years (Required) \n Cyber Kill Chain and MITRE ATT&CK: 5 years (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "85f979a3153ad8d5": {"terms": ["data analyst"], "salary_min": 89330.96, "salary_max": 113112.9, "title": "Data Analyst - AS400 to DB2 Migration Specialist", "company": "The Infosoft Group", "desc": "Codeworks is an IT Services firm headquartered in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships. \n  Our client is looking for a Data Analyst - AS400 to DB2 Migration Specialist \n  Location - Remote  \n Employment - Contract role  \n \n Duties and Responsibilities: \n  As an AS400 to DB2 Migration Specialist at DMI (FIS), you will take the lead in planning, designing, and executing the migration of our legacy AS400 systems to DB2 on the AWS cloud platform. With a strong background in AS400 and DB2, as well as experience with AWS and Informatica, you will ensure a seamless and efficient migration process. \n   \n Key Responsibilities:  \n \n Lead the planning and execution of the AS400 to DB2 migration project. \n Collaborate with cross-functional teams to understand business requirements and data migration needs. \n Assess and document the current AS400 systems, including data structures, applications, and dependencies. \n Design and implement migration strategies and workflows to move data and applications to DB2 on AWS. \n Develop and optimize SQL scripts, ETL processes, and data migration routines. \n Ensure data integrity, security, and performance during and after the migration. \n Monitor and troubleshoot migration issues, providing timely resolutions. \n Collaborate with AWS services for database hosting and management (AWS RDS, Aurora, etc.). \n Utilize Informatica for ETL processes and data integration (experience a plus). \n Provide technical guidance and mentorship to team members involved in the migration. \n Keep up-to-date with industry best practices and emerging technologies related to migration and cloud services. \n \n   \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). \n Minimum of 8 years of experience in AS400 development and administration. \n Strong proficiency in AS400 and DB2 databases. \n In-depth knowledge of SQL and experience with query optimization. \n Familiarity with AWS cloud services and database management (AWS certification is a plus). \n Experience with Informatica for ETL processes (preferred). \n Proven track record of successfully leading migration projects. \n Strong problem-solving and debugging skills. \n Excellent communication and teamwork abilities. \n Self-motivated and able to work independently or in a team. \n \n   \n Additional Requirements: \n  Strong proficiency in AS400 and DB2 databases. \n \n In-depth knowledge of SQL and experience with query optimization. \n Familiarity with AWS cloud services and database management (AWS certification is a plus). \n Experience with Informatica for ETL processes (preferred). \n Proven track record of successfully leading migration projects. \n Strong problem-solving and debugging skills. \n Excellent communication and teamwork abilities. \n Self-motivated and able to work independently or in a team. \n \n \n \n  #LI-MG2\n  \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Codeworks, L.L.C. \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   8+ years", "cleaned_desc": "Codeworks is an IT Services firm headquartered in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships. \n  Our client is looking for a Data Analyst - AS400 to DB2 Migration Specialist \n  Location - Remote  \n Employment - Contract role  \n \n Duties and Responsibilities: \n  As an AS400 to DB2 Migration Specialist at DMI (FIS), you will take the lead in planning, designing, and executing the migration of our legacy AS400 systems to DB2 on the AWS cloud platform. With a strong background in AS400 and DB2, as well as experience with AWS and Informatica, you will ensure a seamless and efficient migration process. \n   \n Key Responsibilities:  \n \n Lead the planning and execution of the AS400 to DB2 migration project. \n Collaborate with cross-functional teams to understand business requirements and data migration needs. \n Assess and document the current AS400 systems, including data structures, applications, and dependencies. \n Design and implement migration strategies and workflows to move data and applications to DB2 on AWS. \n Develop and optimize SQL scripts, ETL processes, and data migration routines. \n Ensure data integrity, security, and performance during and after the migration. \n Monitor and troubleshoot migration issues, providing timely resolutions. \n Collaborate with AWS services for database hosting and management (AWS RDS, Aurora, etc.). \n Utilize Informatica for ETL processes and data integration (experience a plus).   Provide technical guidance and mentorship to team members involved in the migration. \n Keep up-to-date with industry best practices and emerging technologies related to migration and cloud services. \n \n   \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). \n Minimum of 8 years of experience in AS400 development and administration. \n Strong proficiency in AS400 and DB2 databases. \n In-depth knowledge of SQL and experience with query optimization. \n Familiarity with AWS cloud services and database management (AWS certification is a plus). \n Experience with Informatica for ETL processes (preferred). \n Proven track record of successfully leading migration projects. \n Strong problem-solving and debugging skills. \n Excellent communication and teamwork abilities. \n Self-motivated and able to work independently or in a team. \n \n   \n Additional Requirements:    Strong proficiency in AS400 and DB2 databases. \n \n In-depth knowledge of SQL and experience with query optimization. \n Familiarity with AWS cloud services and database management (AWS certification is a plus). \n Experience with Informatica for ETL processes (preferred). \n Proven track record of successfully leading migration projects. \n Strong problem-solving and debugging skills. \n Excellent communication and teamwork abilities. \n Self-motivated and able to work independently or in a team. \n \n \n \n  #LI-MG2\n  \n \n \n \n \n ", "techs": ["codeworks", "as400", "db2", "aws", "informatica", "aws rds", "aurora"]}, "172169a3ebc49c9e": {"terms": ["data analyst"], "salary_min": 79008.55, "salary_max": 100042.42, "title": "Business Analyst", "company": "INTEGRITYOne Partners", "desc": "Location \u2013 currently 100% remote, with the potential for occasional in-person meetings in Washington, DC. \n \n  As a Business Analyst with INTEGRITYOne Partners, you will be an integral resource capturing and coordinating business and technical requirements to support agile software development teams. Every day, you'll work with dedicated team members and clients to gather, analyze, and document requirements using Agile methodologies and tools. To thrive in this role, you must have experience working in cross-functional teams, delivering results quickly, be intellectually curious, have the drive to learn, identify and solve complex problems, and enjoy a high-tempo environment. Our clients need and demand results immediately. \n \n  We're looking for a Business Analyst with demonstrated experience in gathering, validating, and managing requirements. In this role, you will: \n \n  Leverage your experience over the last 2-4 years gathering, documenting, validating, and managing business and functional requirements. \n \n  Assist in documenting business process flows and rules. \n \n  Use your experience to support planning and facilitating working group sessions focused on requirements gathering. \n \n  Collaborate with project managers and product owners on deliverables, schedules, and milestones for the various work streams. \n \n  Demonstrate your excellent communication, facilitation, and mediation skills by creating and maintaining system lifecycle documents and supporting technical gate reviews. \n \n  Be the type of person who wants to grow their career and technical and consulting capabilities in the Federal environment. At INTEGRITYOne Partners, we reward hard work and outstanding results with raises, bonuses, promotions, and training. \n \n \n Requirements: \n  Our contract requires that you are a US Citizen and can obtain and maintain a DHS 6C (Public Trust). This requirement is not negotiable for this role. Please do not apply if you do not meet this requirement. \n \n  Bachelor's degree or beyond. \n \n  At INTEGRITYOne Partners, we have high standards for the members of our team - and when our people meet these standards, the personal and professional rewards are plentiful. We help INTEGRITYOne Partners\u2019 employees grow in their careers by gaining enhanced Federal knowledge and experience, sought-after skills, greater discipline and drive, and targeted education and training \n \n  INTEGRITYOne Partners is an equal opportunity employer Minorities / Females / Veterans / Disabilities. All qualified applicants will be considered without regard to race, ethnicity, color, national origin, religion, sexual orientation, gender identity, veteran status, or status as a qualified individual with a disability or any other personal characteristic protected by law. \n BN9FUG0SIu", "cleaned_desc": "", "techs": ""}, "5316cfeeb7b8789c": {"terms": ["data analyst"], "salary_min": 80296.51, "salary_max": 101673.27, "title": "Business Analyst, Partner Relationship Management", "company": "The Infosoft Group", "desc": "Milwaukee, Wisconsin, United States\n   United States of America Pennsylvania (remote)\n   United States of America Florida (remote)\n   United States of America Illinois (remote)\n   United States of America Michigan (remote)\n   United States of America Ohio (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n  Think of an app you simply cannot live without. For our company, the Commercial Operations organization is like that app. It is a strategic and indispensable component of an organized and knowledgeable sales organization. \n  Rockwell Automation's partnerships are governed by multiple programs and include main elements such as partnership agreements, incentives, pricing, policies, and communications. These programs require a modern, the best PRM platform to maximize our digital experience and engagement with our partners - including Distributors, System Integrators, OEM Partners and Technology Partners. \n  Commercial Operations ties together strategy and roles, supported by digital applications and analytics. The PRM team is responsible for an important part of this effort. You will work with a diverse, dynamic PRM team. This position is remote-friendly. You will report to PRM Platform Owner and support PRM Platform Owner by engaging with the Market Access regional teams, Commercial Program Managers, Marketing, Partner Enablement and Engagement team, and other BU team members to gather IT requirements and manage projects related to PRM evolution and adoption. The Business Analyst will be a PRM subject-matter expert able to demonstrate current functionality and provide support and analysis to identify or meet our needs. \n  Your Responsibilities:\n  \n \n  Guide Business Analysis activities and create Agile artifacts required to deliver relevant User Stories for IT. \n  Support IT Development efforts by analyzing and communicating with partners and IT, finding answers, and coordinating efforts to resolve issues and meet business commitments. \n  Support Product Owner in Agile ceremonies to help prioritize or find input from Market Access Operational team and other team members to ensure IT development or prioritization. \n  Facilitate meetings to gather customer approval, perform User Acceptance Testing and follow-up items after Agile Spring Demos. \n  Create or enhance PRM training documentation (videos, slides, and contents). \n  Communicate with partners to share training documentation and information on PRM current functionality, changes, and processes for Partners. \n  Track IT commitments and escalate if needed to meet delivery dates. \n  Help troubleshooting of ad-hoc issues with IT and Global Market Access team members. \n  Additional responsibilities to support peers in Global Market Access team when needed. \n \n  The Essentials - You Will Have:\n  \n  Bachelor's Degree or equivalent experience \n  You can work within the United States without sponsorship. We will not sponsor for this role now or in the future. \n \n  The Preferred - You Might Also Have:\n  \n  Bachelor's technical degree or equivalent experience \n  2+ years in requirements gathering, process mapping, wireframing, creating analysis artifacts, Agile and Software Development Life Cycle. \n  1+ year background in analytics or sales operations . \n  Understanding of CRM Systems, PowerApps, PowerBI, Websites, Jira, and Scrum methodology. \n  Understanding of APIs, Data Analysis, and data integrity. \n  Fluent in English \n  What We Offer:\n  \n  Health Insurance including Medical, Dental and Vision \n  401k \n  Paid Time off \n  Parental and Caregiver Leave \n  Flexible Work Schedule where you will work with your manager to enjoy a work schedule that works with your personal life. \n  To learn more about our benefits package, please visit at www.. \n \n \n  We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace. \n \n  At Rockwell Automation we are dedicated to building a diverse, inclusive and authentic workplace, so if you're excited about this role but your experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right person for this or other roles. \n \n  #LI-Remote \n  #LI-SH2 \n \n  Rockwell Automation is an Equal Opportunity Employer including disability and veterans. \n  If you are someone with a disability and you need assistance or reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7427. \n \n  We are an Equal Opportunity Employer including disability and veterans. \n \n  If you are an individual with a disability and you need assistance or a reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7247. \n  Rockwell Automation is an Equal Opportunity Employer \u2013 Disability/Veteran.\n  \n  If you are an individual with a disability and you need assistance or reasonable accommodation during the application process, email our Talent Acquisition representative at RAApplicationsupport@ra.rockwell.com.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Rockwell Automation \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   2+ years", "cleaned_desc": "", "techs": ""}, "848fa096cc3a1ad4": {"terms": ["data analyst"], "salary_min": 93899.445, "salary_max": 118897.62, "title": "Technical Business Analyst", "company": "SoftPro", "desc": "SoftPro  is the nation's leading provider of real estate closing and title insurance software. A division of Fidelity National Financial (NYSE: FNF), SoftPro\u2019s technology solutions are used in thousands of law firms and title companies throughout the country and are an essential part of residential and commercial Real Estate transactions. SoftPro\u2019s Headquarters is in Raleigh, North Carolina.\n   \n \n SoftPro  offers comprehensive health benefit offerings (medical, dental, vision, disability, etc), 401k and Employee Stock Purchase Plans with company matching, as well as generous paid vacation time and paid parental leave. We have positions that are eligible to be 100% remote. Employees who live near our Raleigh, NC Headquarters can choose to work a hybrid (office/home) schedule.\n   \n \n SoftPro  has received national recognition for our excellent customer service and products and we were recently recognized as a \n   2023 Best Places to Work  by the Triangle Business Journal! SoftPro has won this prestigious award \n   11 times since 2012! \n \n \n What are we looking for? \n  SoftPro is seeking a \n   Technical Business Analyst  in our Raleigh, NC office or as a remote employee. If candidate will work remotely, you must be able to work East Coast hours. The BA is responsible for gathering, defining, and supporting requirements, and assisting development teams with transforming those requirements into innovative designs.\n   \n \n \n What will I do as a Technical Business Analyst at SoftPro? \n \n \n Gather and document requirements \n \n \n Gather and translate business requirements into functional specs - focused on API projects \n Work with the vendor (when applicable) and business stakeholder to create an agreed upon high level set of requirements and review technical documentation needed for development to provide an estimate in a statement of work \n Work with vendors (if applicable) and stakeholders to detail business requirements \n Determine technical readiness of vendor partners (if applicable) \n Work with the product owner in determining project schedules \n Contribute to product direction and feature set \n \n \n Communicate requirements to others \n \n \n Document business process flow, use cases, and functional requirements \n Organize and lead presentations with development teams to communicate requirements \n Work with development teams to effectively translate business needs into creative software solutions \n Work with the business on production bugs, helpdesk tickets and user training to ensure proper and optimal usage of our integrations \n \n \n Verify resulting products meet customer needs \n \n \n Validate that completed product solutions meet the requirements and expectations \n Work with development teams to make sure products meet customer quality expectations \n \n \n Serve as a subject matter expert for your product areas \n \n \n Troubleshoot software, identify root causes, and propose solutions \n Conduct product demonstrations to internal and external customers \n Collaborate with the teams implementing products \n Keep abreast of new technologies and process innovation within our industry \n Look for ways to innovate within your product areas \n Work collaboratively and cohesively with all team members \n \n \n  Some travel required\n   \n \n What skills do I need to be a successful Technical Business Analyst at SoftPro? \n \n \n Solid technical skills in web services (REST and SOAP) and design for API integrations. \n Excellent verbal and written communication with customers, dev teams, and executive management \n Ability to multi-task, meet deadlines, and work in a fast-paced environment \n Must be detail-oriented, highly organized and results-driven \n Experience documenting user requirements \n Experience writing user stories and working within an agile development environment preferred \n Experience creating technical requirement documents through translation of business requirements \n Title or escrow experience within large organizations strongly preferred \n 5+ years as a Business Analyst focused on API projects \n \n \n \n Join us and live our Core Values \n  Deliver AMAZING Customer Service, Be an AWESOME Teammate, Adopt a Sense of Urgency, Innovate to be Efficient, Produce Quality Work, Take Initiative, Go the Extra Mile.\n   \n \n \n EQUAL OPPORTUNITY POLICY \n  FNF, its affiliates and subsidiaries, is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, protected veteran status, national origin, sexual orientation, gender identity or expression (including transgender status), genetic information or any other characteristic protected by applicable law.", "cleaned_desc": " Solid technical skills in web services (REST and SOAP) and design for API integrations. \n Excellent verbal and written communication with customers, dev teams, and executive management \n Ability to multi-task, meet deadlines, and work in a fast-paced environment \n Must be detail-oriented, highly organized and results-driven \n Experience documenting user requirements \n Experience writing user stories and working within an agile development environment preferred \n Experience creating technical requirement documents through translation of business requirements \n Title or escrow experience within large organizations strongly preferred \n 5+ years as a Business Analyst focused on API projects \n \n \n \n Join us and live our Core Values \n  Deliver AMAZING Customer Service, Be an AWESOME Teammate, Adopt a Sense of Urgency, Innovate to be Efficient, Produce Quality Work, Take Initiative, Go the Extra Mile.\n   \n ", "techs": ["web services (rest and soap)", "api integrations", "verbal and written communication", "multi-tasking", "meeting deadlines", "detail-oriented", "highly organized", "results-driven", "documenting user requirements", "writing user stories", "agile development environment", "creating technical requirement documents", "title or escrow experience", "business analyst", "core values", "customer service", "teamwork", "sense of urgency", "innovation", "efficiency", "quality work", "initiative"]}, "592426dafdbd0a30": {"terms": ["data analyst"], "salary_min": 72731.76, "salary_max": 83642.82, "title": "Production Support Business Analyst", "company": "Moda Health", "desc": "Let\u2019s do great things, together    Founded in Oregon in 1955, Moda is proud to be a company of real people committed to quality. Today, like then, we\u2019re focused on building a better future for healthcare. That starts by offering outstanding coverage to our members, compassionate support to our community and comprehensive benefits to our employees. It keeps going by connecting with neighbors to create healthy spaces and places, together. \n  Moda values diversity and inclusion in our workplace. We aim to demonstrate our commitment to diversity through all our business practices and invite applications from candidates that share our commitment to this diversity. Our diverse experiences and perspectives help us become a stronger organization. Let\u2019s be better together. \n  Job Summary: \n  Moda Health is seeking a Production Support Business Systems Analyst who will act as a liaison between business and technical users to gather and document business requirements, business processes, system flows and functional system designs for break fixes, system upgrades, ongoing product implementations and small IT service requests. The Production Support BSA is responsible for providing IT support throughout the software development lifecycle, including testing and production implementation. To excel in this position, you should be self-motivated with strong analytical skills, in-depth knowledge of business systems analysis techniques and possess strong verbal and written communication skills. Experience with TriZetto Facets and/or Edifecs Enrollment Management system preferred.\n  \n \n This a full-time remote position. \n \n  Please fill out an application on our company page, linked below, to be considered for this position \n \n  https://j.brt.mv/jb.do?reqGK=27699478&refresh=true \n \n  Benefits: \n \n  Medical, Dental, Pharmacy and vision coverage \n  401K \n  FSA \n  PTO and paid holidays \n \n  Schedule: \n \n  Full time minimum 7.5 work days with 37.5 work weeks \n \n  Primary Functions: \n \n \n  Performs ongoing production support and bug fixes for assigned applications. \n  Performs best practice requirements engineering for all aspects of SDLC activities. To include eliciting, analysis, and prioritization of functional and non-functional requirements. \n  Collaborates with business and technical teams in defining and documenting detailed functional specification requirements, reviewing, analyzing and approving acceptance criteria for conversion, interface, and system enhancements. \n  Creates the functional specifications based on the finalized requirements for the designated functional systems, and at the correct time, converting systems to Moda Company Standard Software Systems. \n  Participates as a team member in short-term stabilization efforts involving existing systems and processes. \n  Participates in the development of business cases, contingency plans, business metrics and measurements, process models, training materials, new procedures, test scripts, ad-hoc reports, and smart solutioning for process improvements. \n  Participates in the review and approval of system designs, logical data designs, report design, interface designs, and conversion plans. Reviews and approves high-level data flows, functional specifications, and system for implementation. Suggests design alternatives. \n  Acts in review and approval capacity in the establishment and maintenance of unit and user acceptance testing and prioritization of requests for system enhancements, and system implementations. \n  Performs system testing of enhancements, conversions, and interface systems. \n  Develops and documents test plans and outcomes at a level of details that allows research and analysis. \n  Performs post implementation, quality assurance and troubleshooting. Develops both user and business unit technical documentation for system enhancements. \n  Performs other duties as assigned. \n \n  Requirements: \n \n \n  2+ years of experience in analysis, either technical or business related. \n  Knowledge of PC, Server Based and desktop applications including spreadsheets, word-processing and email. \n  Must be able to facilitate large and small group meetings or working sessions. \n  Proven skills in critical thinking, time management, and problem solving. \n  Demonstrated procedural and technical writing skills. \n  Must be able to work effectively within a production support team and in collaboration with peers. \n  Ability to work well under pressure, in a fast-paced environment, with frequent interruptions and shifting priorities. This includes working on multiple assignments simultaneously. \n  Ability to independently plan, organize, and prioritize task assignments to ensure quality standards and deadlines are met. \n  Ability to communicate effectively, both verbally and in writing, with business and technical personnel. \n  As applicable; a commitment to acquire the ability to read, write, and execute SQL statements. \n  Ability to maintain confidentiality and demonstrate a professional business image. \n  Resilient work ethics; demonstrating professionalism, punctuality, and reliability. \n \n  Preferred Requirements: \n \n  College Degree or equivalent work experience in related field. \n  Experience as a Business Systems or Program Analyst \n  Experience in the health insurance administration industry \n  Experience with Facets systems development \n  Subject matter expertise in Claims Processing, Claims Pricing, Clinical Editing, Benefit Config, Membership and/or Provider Processing. \n  Ability to read, write, and execute SQL statement. \n \n  Moda Health seeks to allow equal employment opportunities for all qualified persons without regard to race, religion, color, age, sex, sexual orientation, national origin, marital status, disability, veteran status or any other status protected by law.\n   \n  For more information regarding \n   accommodations  please direct your questions to HRAdmin@modahealth.com.", "cleaned_desc": "  Requirements: \n \n \n  2+ years of experience in analysis, either technical or business related. \n  Knowledge of PC, Server Based and desktop applications including spreadsheets, word-processing and email. \n  Must be able to facilitate large and small group meetings or working sessions. \n  Proven skills in critical thinking, time management, and problem solving. \n  Demonstrated procedural and technical writing skills. \n  Must be able to work effectively within a production support team and in collaboration with peers. \n  Ability to work well under pressure, in a fast-paced environment, with frequent interruptions and shifting priorities. This includes working on multiple assignments simultaneously. \n  Ability to independently plan, organize, and prioritize task assignments to ensure quality standards and deadlines are met. \n  Ability to communicate effectively, both verbally and in writing, with business and technical personnel. \n  As applicable; a commitment to acquire the ability to read, write, and execute SQL statements. ", "techs": ["spreadsheets", "word-processing", "email", "critical thinking", "time management", "problem solving", "procedural writing", "technical writing", "production support team", "collaboration", "under pressure", "fast-paced environment", "multiple assignments", "planning", "organizing", "prioritizing", "communication", "sql statements"]}, "b29b3325f860b667": {"terms": ["data analyst"], "salary_min": 65112.676, "salary_max": 82447.16, "title": "CRM Business Analyst", "company": "Evoqua Water Technologies", "desc": "Date:  Sep 11, 2023  \n Location:  Pittsburgh, PA, US, 15106  \n Company:  Evoqua  \n \n \n   About Evoqua Water Technologies\n   \n \n   We are excited to announce that Evoqua has now joined Xylem. By uniting our complementary approaches, products, and expertise, we enable our customers to dramatically improve the way water and wastewater is used, managed, conserved, re-used, and returned to nature. Together, we bring uniquely powerful capabilities to solving the world's greatest water challenges.\n   \n \n   At every level, our global team is committed to access, equity, inclusion, and diversity. Our goal is for all our colleagues to be involved, respected, valued, connected, and free to bring their authentic selves and ideas. If you are excited and passionate about solving water, we want to hear from you.\n   \n \n   Our more than 22,000 diverse employees are helping communities in more than 150 countries become water-secure. Apply today and Let's Solve Water.\n   \n \n   At Evoqua, we are committed to fostering and maintaining an inclusive and diverse workplace where employees can be their authentic selves. If this position interests you and you possess the minimum qualifications, we encourage you to apply as you could be the right fit for this or other roles we are looking to fill. Evoqua encourages all candidates meeting the minimum qualifications/requirements for the position to apply.\n   \n \n \n \n \n       Position Summary\n      \n \n \n \n       The \n       CRM Sales Process Analyst  supports the company\u2019s MS Dynamics 365 CRM sales application by performing semi-complex work within the area of user and system support for the company\u2019s application. This role also interprets documented policies and procedures, develops and communicates best practices, and provides user instruction for utilizing the MS D365 tool effectively while performing the Sales function.\n      \n \n \n \n \n \n       Core Responsibilities and Tasks\n      \n \n \n \n       Develop sales process solutions by collaborating across departments / divisions\n       \n \n Understand internal customer pain-points; anticipate customer\u2019s needs and proactively develop solutions \n Support user guided training working with WalkMe Digital Adoption Software \n Interpret documented policies & procedures and develop / understand best practices \n Develop an in-depth knowledge of the CRM application and a working knowledge of software packages associated with the CRM tool \n Troubleshoot, resolve, and capture first level process / navigation / reporting support issues \n Conduct impact analysis based on user and business requirements \n Manage change requests and prioritize different business needs \n Work with the CRM professional services consulting partners \n Develop system testing scripts and perform system testing \n Prepare accurate testing data, both for initial implementation and ongoing project support \n Drive and maximize user adoption of the CRM systems by working with sales and business management \n Developing and execute projects relative to data governance and maintenance of CRM data and prospects / contacts / leads \n Cross train with CPQ system to support application as requested \n Communicate system changes and enhancements to the user base \n Escalate identified performance issues \n Represent MS D365 in all projects where impact to sales tools will occur \n \n \n \n \n \n \n \n       Position Requirements\n      \n \n \n \n Bachelor\u2019s degree in business or IT related field \n 2 years of experience with business systems preferred, Microsoft Dynamic 365 \n Ability to work in a cross-functional team environment, especially with IT & Sales \n Excellent written, oral and presentation skills \n Effective time management, organization, and leadership skills \n Strong computer skills; especially MS Office (Outlook, Word, Excel, PowerPoint) \n Self-motivated with ability to establish priorities and effectively manage time to complete multiple tasks within specified timeframes \n Respect for confidentiality, attention to detail, ability to prioritize and sound judgment required \n Strong service orientation is essential \n \n \n \n \n \n \n      Additional Details\n      \n \n \n \n       Travel Requirements - 10%\n      \n \n      #LI-NH1\n      \n \n      #LI- Remote\n      \n \n \n \n \n    Evoqua Water Technologies prohibits discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, national origin, sexual orientation or any other category protected by applicable federal, state or local law. Evoqua Water Technologies takes affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, national origin, protected veteran status or disability.\n   \n \n   EEO is The Law\n   \n \n   Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled/Sexual Orientation/Gender Identity\n   \n \n   EEO is the Law - Poster (PDF)\n   \n \n \n \n Evoqua does not accept unsolicited resumes/candidates from search firms. \n \n \n   Nearest Major Market:  Pittsburgh", "cleaned_desc": " Bachelor\u2019s degree in business or IT related field \n 2 years of experience with business systems preferred, Microsoft Dynamic 365 \n Ability to work in a cross-functional team environment, especially with IT & Sales \n Excellent written, oral and presentation skills \n Effective time management, organization, and leadership skills \n Strong computer skills; especially MS Office (Outlook, Word, Excel, PowerPoint) \n Self-motivated with ability to establish priorities and effectively manage time to complete multiple tasks within specified timeframes \n Respect for confidentiality, attention to detail, ability to prioritize and sound judgment required \n Strong service orientation is essential \n \n \n \n \n \n \n      Additional Details\n      \n \n \n \n       Travel Requirements - 10%\n      \n \n      #LI-NH1", "techs": ["microsoft dynamic 365", "ms office (outlook", "word", "excel", "powerpoint)"]}, "af8b1fd82d4c0c04": {"terms": ["data analyst"], "salary_min": 82479.336, "salary_max": 104437.23, "title": "Operations Research Analyst", "company": "ManTech International Corporation", "desc": "Secure our Nation, Ignite your Future  \n \n Become an integral part of a diverse team while working at an Industry Leading Organization, where our employees come first. At ManTech International, you\u2019ll help protect our national security while working on innovative projects that offer opportunities for advancement.  \n \n Currently, ManTech is seeking a motivated, career and customer-oriented  Operations Research Analyst  to join our team in the Washington, D.C. This position is fully remote.  \n \n Responsibilities include but are not limited to:  \n \n Recognizes business requirements in the context of Business Intelligence (BI) and create data models to transform raw data into relevant insights.  \n Using Power BI, creates dashboards and interactive visual reports.  \n Creates charts and data documentation with explanations of algorithms, parameters, models, and relationships.  \n Makes technological adjustments to current BI systems to improve their performance.  \n For a better understanding of the data, uses filters and visualizations.  \n Collects and analyzes structured and unstructured data, producing statistical results and conclusions in understandable and informative products.  \n Interprets structured and unstructured data as well as other agency data and exercise independent judgment to produce statistical analytic products using regression time series, confidence intervals, predictive modeling, and exploratory data analysis.  \n Uses scientific inquiry in the independent development of statistical models to evaluate and predict future activity.  \n Develops models to test, analyze, and evaluate data sets.  \n Serves as an expert on modeling techniques such as regression, predictive, and time-series.  \n Designs, develops, and maintains user-friendly data visualizations using complex datasets from different sources.  \n Oversees the development and delivery of the Toolkits Release Notes and Standard Operating Procedures (SOP) for customer Toolkits.  \n Assesses and improves data integration and services through automation of customer missions and needs.  \n Analyzes and evaluates the accuracy and validity of data.  \n \n \n Basic Qualifications:  \n \n A bachelor\u2019s degree in computer science or a related field  \n A minimum of (3) three years of related experience  \n Experience in the Microsoft Power Platform (MS PowerApps, Power Automate, and Power BI)  \n Experience with Microsoft Azure platform and service (Power BI, Flow, Cortana etc.)  \n Experience in requirements analysis, design, and prototyping  \n Strong understanding of data analytics application security layer models.  \n \n \n Preferred Qualifications:  \n \n A Microsoft Power BI Data Analyst or Microsoft Power Platform Functional - Consultant certified  \n \n \n Clearance Requirements:  \n \n Must be a U.S. citizen  \n Must be able to obtain and maintain DHS suitability  \n \n \n Physical Requirements:  \n \n Must be able to remain in a stationary position 50%  \n Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.  \n The person in this position frequently communicates with co-workers, management, and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.  \n \n \n For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone.  \n \n ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.  \n \n If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.  \n \n If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access", "cleaned_desc": " Makes technological adjustments to current BI systems to improve their performance.  \n For a better understanding of the data, uses filters and visualizations.  \n Collects and analyzes structured and unstructured data, producing statistical results and conclusions in understandable and informative products.  \n Interprets structured and unstructured data as well as other agency data and exercise independent judgment to produce statistical analytic products using regression time series, confidence intervals, predictive modeling, and exploratory data analysis.  \n Uses scientific inquiry in the independent development of statistical models to evaluate and predict future activity.  \n Develops models to test, analyze, and evaluate data sets.  \n Serves as an expert on modeling techniques such as regression, predictive, and time-series.  \n Designs, develops, and maintains user-friendly data visualizations using complex datasets from different sources.  \n Oversees the development and delivery of the Toolkits Release Notes and Standard Operating Procedures (SOP) for customer Toolkits.  \n Assesses and improves data integration and services through automation of customer missions and needs.  \n Analyzes and evaluates the accuracy and validity of data.    \n \n Basic Qualifications:  \n \n A bachelor\u2019s degree in computer science or a related field  \n A minimum of (3) three years of related experience  \n Experience in the Microsoft Power Platform (MS PowerApps, Power Automate, and Power BI)  \n Experience with Microsoft Azure platform and service (Power BI, Flow, Cortana etc.)  \n Experience in requirements analysis, design, and prototyping  \n Strong understanding of data analytics application security layer models.  \n ", "techs": ["microsoft power platform (ms powerapps", "power automate", "power bi)", "microsoft azure platform and service (power bi", "flow", "cortana)", "regression time series", "confidence intervals", "predictive modeling", "exploratory data analysis", "statistical models", "data visualizations", "toolkits release notes", "standard operating procedures (sop)", "automation."]}, "dedb39877c63be82": {"terms": ["data analyst"], "salary_min": 60.0, "salary_max": 100.0, "title": "ServiceNow IT Service Management (ITSM) Analyst", "company": "Synovize", "desc": "Synovize is a leading technology consulting firm that specializes in providing innovative solutions to businesses across various industries. With a team of experienced professionals, we aim to deliver exceptional services to our clients and help them achieve their digital transformation goals. As a remote-first company, we offer flexible work opportunities to talented individuals across the United States. \n Overview: \n We are currently seeking a skilled and experienced ServiceNow IT Service Management (ITSM) Analyst to join our team. As a ServiceNow ITSM Analyst, you will be responsible for analyzing, designing, and implementing IT service management solutions using the ServiceNow platform. This is a full-time, permanent or contract position with the flexibility of remote work. \n Responsibilities: \n \n Collaborate with clients and stakeholders to understand their IT service management needs and translate them into ServiceNow configurations. \n Analyze existing IT service management processes and workflows, identifying areas for improvement and optimization. \n Design and configure ServiceNow ITSM modules, including incident management, problem management, change management, and service catalog. \n Customize ServiceNow functionalities using JavaScript, Angular, and other web technologies to meet specific client requirements. \n Integrate ServiceNow with external systems through REST API, SOAP API, and other integration methods. \n Develop and maintain the Configuration Management Database (CMDB) to ensure accurate and up-to-date data. \n Conduct testing and quality assurance activities to ensure the stability and reliability of the implemented ITSM solutions. \n Provide end-user training and support during and after the implementation process. \n Collaborate with cross-functional teams to ensure successful project delivery within agreed timelines and budgets. \n Stay updated with the latest ServiceNow features and enhancements, recommending and implementing improvements to optimize IT service management processes. \n \n Requirements: \n \n Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Full-time, Contract, Permanent \n Pay: $60.00 - $100.00 per hour \n Benefits: \n \n 401(k) matching \n Dental insurance \n Disability insurance \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Parental leave \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 10 hour shift \n 8 hour shift \n Day shift \n Monday to Friday \n Night shift \n Overtime \n \n Application Question(s): \n \n Are you a US Citizen? If not, what is your citizenship status? \n Do you have any ServiceNow Certifications? If so, were they paid out of pocket? \n \n Experience: \n \n ServiceNow: 2 years (Required) \n \n Security clearance: \n \n Secret (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Full-time, Contract, Permanent ", "techs": ["servicenow itsm analyst", "servicenow platform", "itil", "javascript", "angular", "rest api", "soap api", "configuration management database (cmdb)", "servicenow certifications", "grc", "ham", "sam", "apm", "spm", "nosql databases", "itom", "sccm", "jamf"]}, "911ef236221647fd": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Clinical Data Analyst, Cardiology - ProHealth Care - PRN/As Needed", "company": "The Infosoft Group", "desc": "We Are Hiring: Clinical Data Analyst, Cardiology - ProHealth Care - PRN/As Needed  \n \n Begin your story with ProHealth Care. Herewe offer a culture that's warm, welcoming, and vibrant. Additionally, we offer a generous benefits plan and resources to help you further your education. After all, it's the way you should be treated.Enjoy ourfeaturing our own employees sharing why they choose ProHealth Care and what they enjoy about working here. \n \n Culture is built every day, and we want you to be a part of this. If you're like us and are passionate about providing exceptional patient care, we'd like to meet you! \n \n Schedule Details: Independent remote work, data abstraction for Heart Failure. This is a PRN position that is 100% remote. \n \n \n \n \n    What You Will Do: \n    \n \n  Responsible for abstraction and/or reporting of quality measures to meet identified organizational needs and goals for ProHealth Care.The individual will also be responsible for supporting clinical decision making through established teams and the analysis of clinical benchmarking data (in compliance with the philosophy, policies, procedures, goals and budget of the organization). \n   What you will need: \n \n Registered Health Information Admin (RHIA), Registered Health Information Tech (RHIT), and Certified Professional Healthcare Quality (CPHA) preferred. \n Bachelor's Degree in Nursing or other healthcare-related or technical field. \n Knowledge of data collection, submission and analysis. \n For data analyst roles that involve management of a database or use of a particular tool, experience with that tool or database preferred. \n For data analyst roles that involve regulatory requirements (such as Core Measures or Meaningful Use) experience in completing data submission to a federal or state program required. \n For data analyst roles in specialty-specific databases, past nursing or data collection experience in that subject matter area strongly preferred. \n \n \n #LI-KH \n \n CA \n \n \n \n \n  Why Join ProHealth Care: \n  We have nearly 5,000 dedicated clinical and non-clinical employees and physicians who work together every day to serve the health and well-being of our community. At ProHealth Care everyone contributes to the care our patients receive. And, everyone is treated with kindness and respect in our welcoming environment.  \n \n This Position Will Offer You: \n \n Engaging and community focused culture \n Competitive Salaries  \n Opportunity for professional career growth  \n Robust benefits including: Generous PTO;Choices in insurance; HSA;Tuition reimbursement;immediate 401K match;discounted tickets to various entertainment, social and sporting events \n \n \n ProHealth Care is an equal opportunity employer and is committed to an inclusive work environment and values the perspectives of our people. We maintain a drug-free workplace and perform pre-employment substance abuse testing. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, gender identity, sexual orientation, age, status as a protected veteran, among other things, or status as a qualified individual with disability. \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   ProHealth Care \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full or Part Time\n   \n \n \n \n   Required Experience\n   \n \n   Open", "cleaned_desc": " \n Registered Health Information Admin (RHIA), Registered Health Information Tech (RHIT), and Certified Professional Healthcare Quality (CPHA) preferred. \n Bachelor's Degree in Nursing or other healthcare-related or technical field. \n Knowledge of data collection, submission and analysis. \n For data analyst roles that involve management of a database or use of a particular tool, experience with that tool or database preferred. \n For data analyst roles that involve regulatory requirements (such as Core Measures or Meaningful Use) experience in completing data submission to a federal or state program required. \n For data analyst roles in specialty-specific databases, past nursing or data collection experience in that subject matter area strongly preferred. \n \n \n #LI-KH \n \n CA \n \n \n \n ", "techs": ["registered health information admin (rhia)", "registered health information tech (rhit)", "certified professional healthcare quality (cpha)", "bachelor's degree in nursing", "data collection", "submission and analysis", "management of a database or use of a particular tool", "regulatory requirements (such as core measures or meaningful use)", "data submission to a federal or state program", "specialty-specific databases", "past nursing or data collection experience"]}, "9fdb490beccfb683": {"terms": ["data analyst"], "salary_min": 80296.51, "salary_max": 101673.27, "title": "Business Analyst, Partner Relationship Management", "company": "The Infosoft Group", "desc": "Milwaukee, Wisconsin, United States\n   United States of America Pennsylvania (remote)\n   United States of America Florida (remote)\n   United States of America Illinois (remote)\n   United States of America Michigan (remote)\n   United States of America Ohio (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n  Think of an app you simply cannot live without. For our company, the Commercial Operations organization is like that app. It is a strategic and indispensable component of an organized and knowledgeable sales organization. \n  Rockwell Automation's partnerships are governed by multiple programs and include main elements such as partnership agreements, incentives, pricing, policies, and communications. These programs require a modern, the best PRM platform to maximize our digital experience and engagement with our partners - including Distributors, System Integrators, OEM Partners and Technology Partners. \n  Commercial Operations ties together strategy and roles, supported by digital applications and analytics. The PRM team is responsible for an important part of this effort. You will work with a diverse, dynamic PRM team. This position is remote-friendly. You will report to PRM Platform Owner and support PRM Platform Owner by engaging with the Market Access regional teams, Commercial Program Managers, Marketing, Partner Enablement and Engagement team, and other BU team members to gather IT requirements and manage projects related to PRM evolution and adoption. The Business Analyst will be a PRM subject-matter expert able to demonstrate current functionality and provide support and analysis to identify or meet our needs. \n  Your Responsibilities:\n  \n \n  Guide Business Analysis activities and create Agile artifacts required to deliver relevant User Stories for IT. \n  Support IT Development efforts by analyzing and communicating with partners and IT, finding answers, and coordinating efforts to resolve issues and meet business commitments. \n  Support Product Owner in Agile ceremonies to help prioritize or find input from Market Access Operational team and other team members to ensure IT development or prioritization. \n  Facilitate meetings to gather customer approval, perform User Acceptance Testing and follow-up items after Agile Spring Demos. \n  Create or enhance PRM training documentation (videos, slides, and contents). \n  Communicate with partners to share training documentation and information on PRM current functionality, changes, and processes for Partners. \n  Track IT commitments and escalate if needed to meet delivery dates. \n  Help troubleshooting of ad-hoc issues with IT and Global Market Access team members. \n  Additional responsibilities to support peers in Global Market Access team when needed. \n \n  The Essentials - You Will Have:\n  \n  Bachelor's Degree or equivalent experience \n  You can work within the United States without sponsorship. We will not sponsor for this role now or in the future. \n \n  The Preferred - You Might Also Have:\n  \n  Bachelor's technical degree or equivalent experience \n  2+ years in requirements gathering, process mapping, wireframing, creating analysis artifacts, Agile and Software Development Life Cycle. \n  1+ year background in analytics or sales operations . \n  Understanding of CRM Systems, PowerApps, PowerBI, Websites, Jira, and Scrum methodology. \n  Understanding of APIs, Data Analysis, and data integrity. \n  Fluent in English \n  What We Offer:\n  \n  Health Insurance including Medical, Dental and Vision \n  401k \n  Paid Time off \n  Parental and Caregiver Leave \n  Flexible Work Schedule where you will work with your manager to enjoy a work schedule that works with your personal life. \n  To learn more about our benefits package, please visit at www.. \n \n \n  We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace. \n \n  At Rockwell Automation we are dedicated to building a diverse, inclusive and authentic workplace, so if you're excited about this role but your experience doesn't align perfectly with every qualification in the job description, we encourage you to apply anyway. You may be just the right person for this or other roles. \n \n  #LI-Remote \n  #LI-SH2 \n \n  Rockwell Automation is an Equal Opportunity Employer including disability and veterans. \n  If you are someone with a disability and you need assistance or reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7427. \n \n  We are an Equal Opportunity Employer including disability and veterans. \n \n  If you are an individual with a disability and you need assistance or a reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7247. \n  Rockwell Automation is an Equal Opportunity Employer \u2013 Disability/Veteran.\n  \n  If you are an individual with a disability and you need assistance or reasonable accommodation during the application process, email our Talent Acquisition representative at RAApplicationsupport@ra.rockwell.com.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Rockwell Automation \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   2+ years", "cleaned_desc": "", "techs": ""}, "23e36c29ac564136": {"terms": ["data analyst"], "salary_min": 55000.0, "salary_max": 85000.0, "title": "Sr. Healthcare Technical Analyst (MedInsight)", "company": "The Infosoft Group", "desc": "Description\n  \n  Company Overview: \n  Leading with our core values of Quality, Integrity, and Opportunity, MedInsight is one of the healthcare industry's most trusted solutions for healthcare intelligence. Our company purpose is to empower easy, data-driven decision-making on important healthcare questions. Through our products, education, and services, MedInsight is making an impact on healthcare by helping to drive better outcomes for patients while reducing waste. Over 300 leading healthcare organizations have come to rely on MedInsight analytic solutions for healthcare cost and care management. \n  MedInsight is a subsidiary of Milliman; a global, employee-owned consultancy providing actuarial consulting, retirement funding and healthcare financing, enterprise risk management and regulatory compliance, data analytics and business transformation as well as a range of other consulting and technology solutions. \n  Position Summary: \n  We are looking for a Sr. Healthcare Technical Analyst to join our Strategic Analytics team and support the technical operations of our strategic services in healthcare benchmarking and research. \n  As a member of the consulting staff, this professional will join our team to support our clients in leveraging analytic technologies to understand patterns in healthcare, identify opportunities for improvement, and inform business decisions. This role will be expected to serve as a technical quality and documentation manager for projects, as a supportive technical developer for many projects, and as a checker for other projects. This professional must be comfortable in managing multiple concurrent projects in varying stages of completion. Knowledge sharing, documentation, collaboration, and opportunity identification are key desired attributes. \n  Primary Responsibilities: \n  As a Sr. Healthcare Technical Analyst, this professional will join our interdisciplinary team of developers, data analysts, and healthcare consultants on MedInsight's Strategic Services team. This role will be responsible for quality management, production and monitoring of standard and ad hoc meta-data outputs, and technical documentation for a range of analytic methodologies, including approaches on benchmarking, statistics, trend analyses, and research projects. This individual will work primarily with the Strategic Analytics team, in collaboration with the Client Services, Product Management, and Implementation teams, as well as other key partners on project design and content development. Responsibilities include, but are not limited to: \n \n Work both independently and in a cross-functional team environment. \n Standardize ad hoc processes and drive continuous improvement for automating and optimizing performance of ongoing processes, including development of data processing pipelines. \n Develop robust and scalable solutions that transform data into a useful format for analysis, enhance data flow, and enable users to consume and analyze data faster and easier. \n Write complex SQL queries to support analytics needs. \n Develop, maintain, and support processes for data feasibility tests, data quality checks, data validations, and sense-checking of results. \n Support documentation of analysis results and methodologies. \n Develop technical specifications for analyses of healthcare data. \n Perform ad hoc analyses of healthcare data using SQL Server, Azure Databricks, and other tools. \n Work independently on assigned tasks, i.e., plan, organize, problem solve and meet established deadlines. \n Manage multiple priorities in a fast-paced environment. \n Prioritize work under time pressure. Follow-through and exceptional attention to detail on all project tasks are essential. \n Listen to, understand, and break down questions into manageable tasks. \n Use a variety of proprietary products and technologies to answer simple and complex questions. \n Represent the Strategic Analytics team at external and internal meetings. \n \n Minimum Requirements: \n \n Bachelor's degree in mathematics, computer science, informatics, statistics, information systems, finance, economics, engineering, or related fields. \n 3+ years of relevant work experience in data engineering or technical management. \n 2+ years of programming/development experience with SQL Server 2016 or newer. \n Familiarity with big data technologies, such as Databricks, Spark, R, Python. \n Experience with optimizing and managing data testing and data validation. \n Experience with best practices in documenting and organizing data analytic approaches. \n Ability to work on a range of topics, including but not limited to metadata reporting, healthcare analytics, and nuanced data questions. \n Excellent organizational and project management skills. \n Ability to manage a program and deliver to targeted timeframes. \n Advanced experience with Microsoft Excel (formulas, charts/graphs, pivot tables, etc.). \n Experience with the Microsoft Office Suite of products. \n Healthcare informatics, analytics, and reporting knowledge. \n Data warehousing and/or large IT project experience. \n Experience working with large data sets. \n Excellent technical, written, and verbal communication skills. \n Willingness to learn on the job and own your professional development. \n Ability to work creatively and flexibly. \n Must have the ability to manage multiple priorities in a fast-paced environment. \n Willingness to travel occasionally, for example for professional development opportunities. (Less than 5% nationwide.) \n \n \n Preferred Skills and Experience: \n \n Previous experience working with large healthcare claims and/or EHR databases preferred. \n Comfort with statistical analyses would be helpful. \n Curiosity and confidence to take initiative in suggesting improvements to technical processes. \n \n Desired Experience and Traits: \n \n Candidates must be team players with excellent interpersonal skills. \n A self-starter with the ability to work both independently and as part of a cross-functional team. \n Ability to apply best practices in technical management. \n Follow-through and exceptional attention to detail on all project tasks is essential. \n Ability to prioritize assigned tasks and initiate action, i.e., plan, organize, delegate, problem solve, and meet established deadlines under time pressure. \n \n Compensation and Location: \n \n The salary range is $55,000 to $85,000, depending on relevant factors, including but not limited to education, work experience, certifications, location, etc. This role can be located remotely within the U.S. \n \n What makes this a great opportunity? \n \n Join an innovative, high growth company with a solid industry track record \n Bring your expertise and ideas to directly impact and help build the next generation of MedInsight products and solutions \n Enjoy significant visibility in your work and be recognized for your wins \n Work for a company that values your wellbeing and professional growth, offering a flexible work environment, generous benefits package, and investment in the development of your career. \n \n Milliman Benefits: \n  We offer competitive benefits which include the following based on plan eligibility: \n \n Medical, dental and vision coverage for employees and their dependents, including domestic partners \n A 401(k) plan with matching program, and profit sharing contribution \n Employee Assistance Program (EAP) \n A discretionary bonus program \n Paid Time Off (PTO) starts accruing on the first day of work and can be used for any reason; full-time employees will accrue \n 15 days of PTO per year, and employees working less than a full-time schedule will accrue PTO at a prorated amount based on hours worked \n Family building benefits, including adoption and fertility assistance and paid parental leave up to 12 weeks for employees who have worked for Milliman for at least 12 months and have worked at least 1,250 hours in the preceding 12-month period \n A minimum of 8 paid holidays \n Milliman covers 100% of the premiums for life insurance, AD&D, and both short-term and long-term disability coverage \n Flexible spending accounts allow employees to set aside pre-tax dollars to pay for dependent care, transportation, and applicable medical needs \n \n \n All qualified applicants will receive consideration for employment, without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities \n \n \n \n  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c) \n \n  Milliman is an equal opportunity employer\n  \n  Our company, with the full support of our Chief Executive Officer, is fully committed to the maximum utilization of all human resources and the goals of Equal Employment Opportunity and Affirmative Action. We recruit, hire, train, and promote, and consider qualified applicants for employment, in all job titles without regard to age, ancestry, citizenship status, color, creed, familial status, genetic information, marital status, national origin, political ideology, race, religion, sex, sexual orientation, gender identity, status as an individual with a disability, or veteran status, including qualified disabled veterans, Armed Forces service medal veterans, recently separated veterans, and active duty wartime or campaign badge veterans; and shall not discriminate against any individual, or any other characteristic protected by law.\n  \n  Reasonable Accommodation Notice\n  \n  Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Milliman, Inc \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   3+ years", "cleaned_desc": "Description\n  \n  Company Overview: \n  Leading with our core values of Quality, Integrity, and Opportunity, MedInsight is one of the healthcare industry's most trusted solutions for healthcare intelligence. Our company purpose is to empower easy, data-driven decision-making on important healthcare questions. Through our products, education, and services, MedInsight is making an impact on healthcare by helping to drive better outcomes for patients while reducing waste. Over 300 leading healthcare organizations have come to rely on MedInsight analytic solutions for healthcare cost and care management. \n  MedInsight is a subsidiary of Milliman; a global, employee-owned consultancy providing actuarial consulting, retirement funding and healthcare financing, enterprise risk management and regulatory compliance, data analytics and business transformation as well as a range of other consulting and technology solutions. \n  Position Summary: \n  We are looking for a Sr. Healthcare Technical Analyst to join our Strategic Analytics team and support the technical operations of our strategic services in healthcare benchmarking and research. \n  As a member of the consulting staff, this professional will join our team to support our clients in leveraging analytic technologies to understand patterns in healthcare, identify opportunities for improvement, and inform business decisions. This role will be expected to serve as a technical quality and documentation manager for projects, as a supportive technical developer for many projects, and as a checker for other projects. This professional must be comfortable in managing multiple concurrent projects in varying stages of completion. Knowledge sharing, documentation, collaboration, and opportunity identification are key desired attributes. \n  Primary Responsibilities: \n  As a Sr. Healthcare Technical Analyst, this professional will join our interdisciplinary team of developers, data analysts, and healthcare consultants on MedInsight's Strategic Services team. This role will be responsible for quality management, production and monitoring of standard and ad hoc meta-data outputs, and technical documentation for a range of analytic methodologies, including approaches on benchmarking, statistics, trend analyses, and research projects. This individual will work primarily with the Strategic Analytics team, in collaboration with the Client Services, Product Management, and Implementation teams, as well as other key partners on project design and content development. Responsibilities include, but are not limited to: \n \n Work both independently and in a cross-functional team environment. \n Standardize ad hoc processes and drive continuous improvement for automating and optimizing performance of ongoing processes, including development of data processing pipelines. \n Develop robust and scalable solutions that transform data into a useful format for analysis, enhance data flow, and enable users to consume and analyze data faster and easier. \n Write complex SQL queries to support analytics needs. \n Develop, maintain, and support processes for data feasibility tests, data quality checks, data validations, and sense-checking of results. \n Support documentation of analysis results and methodologies. \n Develop technical specifications for analyses of healthcare data. \n Perform ad hoc analyses of healthcare data using SQL Server, Azure Databricks, and other tools. \n Work independently on assigned tasks, i.e., plan, organize, problem solve and meet established deadlines. \n Manage multiple priorities in a fast-paced environment. \n Prioritize work under time pressure. Follow-through and exceptional attention to detail on all project tasks are essential. \n Listen to, understand, and break down questions into manageable tasks. \n Use a variety of proprietary products and technologies to answer simple and complex questions. \n Represent the Strategic Analytics team at external and internal meetings. \n \n Minimum Requirements: \n \n Bachelor's degree in mathematics, computer science, informatics, statistics, information systems, finance, economics, engineering, or related fields.   3+ years of relevant work experience in data engineering or technical management. \n 2+ years of programming/development experience with SQL Server 2016 or newer. \n Familiarity with big data technologies, such as Databricks, Spark, R, Python. \n Experience with optimizing and managing data testing and data validation. \n Experience with best practices in documenting and organizing data analytic approaches. \n Ability to work on a range of topics, including but not limited to metadata reporting, healthcare analytics, and nuanced data questions. \n Excellent organizational and project management skills. \n Ability to manage a program and deliver to targeted timeframes. \n Advanced experience with Microsoft Excel (formulas, charts/graphs, pivot tables, etc.). \n Experience with the Microsoft Office Suite of products. \n Healthcare informatics, analytics, and reporting knowledge. \n Data warehousing and/or large IT project experience. \n Experience working with large data sets. \n Excellent technical, written, and verbal communication skills. \n Willingness to learn on the job and own your professional development. \n Ability to work creatively and flexibly. \n Must have the ability to manage multiple priorities in a fast-paced environment. \n Willingness to travel occasionally, for example for professional development opportunities. (Less than 5% nationwide.) \n \n \n Preferred Skills and Experience: \n \n Previous experience working with large healthcare claims and/or EHR databases preferred. \n Comfort with statistical analyses would be helpful. \n Curiosity and confidence to take initiative in suggesting improvements to technical processes. \n \n Desired Experience and Traits: \n \n Candidates must be team players with excellent interpersonal skills. ", "techs": ["sql server 2016 or newer", "databricks", "spark", "r", "python", "microsoft excel", "microsoft office suite"]}, "a35ca63ca0259d5b": {"terms": ["data analyst"], "salary_min": 78679.46, "salary_max": 99625.73, "title": "Senior Business Analyst", "company": "Global Payments", "desc": "Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow.  \n \n Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow.  \n \n Global Payments, Inc. is looking for an experienced Business Analyst to join the Enterprise Compliance team. The Enterprise Compliance team\u2019s mission is to ensure Global Payments and our clients comply with payment industry rules, regulations, mandates, and laws which apply to credit card, debit card, and other forms of electronic payments.  \n \n The role:  \n This position is focused on compliance for Debit Merchant Acquiring relevant to authorization and clearing/settlement systems, other ancillary applications, and business processes. As part of a team of compliance professionals, you will be responsible for complex business and technical deliverables for enhancements mandated by card brands, debit networks, third party providers, and industry regulations. Additional responsibilities will include collaborating with application scrum teams, defining requirements, conducting impact analysis, validation of deliverables, and supporting production processes specific to card brand, debit network, and regulatory compliance rules.  \n \n Key Responsibilities  \n \n Serve as a subject matter expert in debit payment processing as it pertains to the payments industry and Global Payments\u2019 systems  \n Develop, maintain, and grow strategic partnerships with the card brands, debit networks, and other service providers  \n Analyze and interpret card brand and debit network technical and regulatory specifications, rules, requirements, and communications for impact to company systems and customers  \n Translate card brand, debit network, and industry rules into technical requirements, including process maps, gap analyses, and business test cases  \n Oversee and assist technology, business, and operations teams to implement and validate required changes  \n Facilitate inquiries, research, production support relating to mandated rules published by card brand and debit networks, third party providers, and industry regulations  \n Participate in scrum ceremonies and represent compliance priorities during planning discussions  \n Provide advisory services to all business units regarding existing regulations, regulatory requirements, new regulatory changes, and compliance risks for debit processing  \n Support new and existing merchant implementations/conversions as required  \n Initiate and lead projects/initiatives as necessary to ensure Global Payments\u2019 systems remain compliant with card brand and debit network specifications and operating rules  \n Stay abreast of payment brand and debit network rules, publications, products and services, industry news, and release documentation to identify impacts to Global Payments and its clients  \n \n \n Minimum Qualifications  \n \n 2+ years of experience in the payments industry  \n 5+ years of experience in a technical or analytical role in the IT field  \n \n \n Preferred Qualifications  \n \n Experience with ISO 8583 message specifications  \n Experience working in an Agile Development environment preferred  \n Ability to take ownership of issues and follow through to completion, be accountable  \n Critical thinker with strong analytical and problem-solving skills  \n Interact with a wide audience: IT, development, operations, security, account support, auditors, vendors, partners, customers, project managers, business analysts, and management  \n Not afraid to question \u201cwhy\u201d and create solutions, see other ways to do things, don\u2019t take things at face value  \n Ability to contribute effectively within a fast-paced, fluid environment and handle changing priorities with confident decision making  \n Excellent time-management, organization, and prioritization skills  \n Ability to build trust and rapport within a team and with internal and external stakeholders  \n Ability to collaborate across all levels of an organization and communicate in an articulate manner to a cross-functional audience to influence results  \n \n \n Ability to work independently, on own, for a remote manager  \n Proficient in Google G Suite applications or MS Office equivalent; SQL experience is a plus   \n \n \n \n Education Desired  \n \n Bachelor\u2019s degree, preferred in information services, information technology, computer science, business or similar area.   \n \n \n \n This position is Remote; preferably in TX, IN, or GA.  \n Global Payments Inc. is an equal opportunity employer.  \n Global Payments provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, marital status, sexual orientation, gender identity or expression, disability, veteran status, genetic information or any other basis protected by law. Those applicants requiring reasonable accommodation to the application and/or interview process should notify a representative of the Human Resources Department.", "cleaned_desc": " Experience working in an Agile Development environment preferred  \n Ability to take ownership of issues and follow through to completion, be accountable  \n Critical thinker with strong analytical and problem-solving skills  \n Interact with a wide audience: IT, development, operations, security, account support, auditors, vendors, partners, customers, project managers, business analysts, and management  \n Not afraid to question \u201cwhy\u201d and create solutions, see other ways to do things, don\u2019t take things at face value  \n Ability to contribute effectively within a fast-paced, fluid environment and handle changing priorities with confident decision making  \n Excellent time-management, organization, and prioritization skills  \n Ability to build trust and rapport within a team and with internal and external stakeholders  \n Ability to collaborate across all levels of an organization and communicate in an articulate manner to a cross-functional audience to influence results  \n \n ", "techs": ["agile development", "critical thinker", "analytical skills", "problem-solving skills", "it", "development", "operations", "security", "account support", "auditors", "vendors", "partners", "customers", "project managers", "business analysts", "management", "solutions creation", "alternative approaches", "fast-paced environment", "changing priorities", "confident decision making", "time-management", "organization", "prioritization skills", "trust building", "rapport building", "collaboration", "cross-functional communication."]}, "a09ba2809f0f53f1": {"terms": ["data analyst"], "salary_min": 78649.52, "salary_max": 99587.82, "title": "Sales Operations Analyst", "company": "The Infosoft Group", "desc": "Cox Automotive  is currently seeking a \n  Sales Operations Analyst  to join our team in a remote role.\n  \n  Come join an organization that is pushing the boundaries of the automotive industry in all directions. We are a powerhouse in providing software, inventory, digital, and mobility solutions to our clients with an exciting future of continued growth.\n  \n \n Your Role:  \n \n  As the Sales Strategy Analyst, you will be responsible for supporting our Sales Strategy team with strong problem-solving skills and analytic ability. You will work as part of the Sales Operations team for Dickinson Fleet Services, a leading brand in our Mobility division of Cox Automotive. You will help address key challenges and concerns, and have full responsibility for Salesforce data and operations, including troubleshooting and reporting.\n  \n  You will analyze data to provide valuable feedback and actionable insights to guide our sales team to actualize their goals. Your efforts will enhance sales productivity by identifying opportunities to streamline processes that impact sales.\n  \n \n What you'll do:   \n \n \n \n Obtain and maintain a working knowledge of Sales applications, clients, and business groups across multiple functional areas. You will be responsible for the daily operations of Salesforce CRM and own the process of data integrity and user troubleshooting.  \n Conduct detailed and creative analysis and clearly communicate results through written and verbal channels.  \n Identify opportunities to improve operational efficiency and provide actionable insights to guide the sales teams.  \n Partner cross-functionally with sales enablement, performance, training, and optimization teams to contribute to developing go-to-market strategies.  \n Identify, communicate, and manage risks that may interfere with project execution or success.  Be a strategic thinker, but also have exceptional attention to detail to drive project management and execution. \n  \n \n \n What's in it for you?  \n \n  As a dynamite Analyst, you deserve success in your life as well, and at Cox, we define \"success\" as being a part of a company that gives you lots of opportunities and options.\n  \n \n First, we've created an  exceptional salary package  , which includes an  annual bonus  .  \n We believe in taking good care of our team. You'll also have access to benefits like a  401(K) with generous company matching contributions  and  quality healthcare & life insurance options  .  \n Work/Life Balance:  Cox gives you flexible paid time off and provides access to a lifestyle coach, adoption assistance, fertility assistance, pet insurance, employee discounts, flexible spending accounts, tuition reimbursement, work-from-home options, and more. \n \n \n \n The bottom line is that we take good care of our employees  . Want to join us? Here's who we are looking for...\n  \n \n Who You Are:  \n \n  You'll be an analytical thinker with expert technical and data analysis skills who has the ability to manage multiple competing priorities and remain organized with excellent attention to detail and first-time quality.\n  \n \n Qualifications:  \n \n  Minimum Required:\n   Bachelor's degree in a related discipline and 2 years of experience in a related field. The right candidate could also have a different combination, such as a master's degree and up to 2 years of experience; or 6 years of experience in a related field\n  \n \n \n  Preferred:\n  \n \n Candidates who are experts in competency with Salesforce will be highly prioritized.  \n Three plus years of business experience, preferably in sales strategy or sales enablement.  \n Strong quantitative analytical skills, creativity in problem-solving and a keen business sense.  \n Strong interpersonal skills in teamwork, communication, presentation, and time management to enable effective collaboration with teams throughout the organization.  \n Ability to work in a high-performance, fast-paced, team-oriented environment.  \n Ability to apply task prioritization and work well under pressure with a sense of urgency while remaining focused.  \n Proficiency in Microsoft Office Suite, Strong Excel knowledge preferred.  \n Proficiency in BI tools (Microsoft PowerBI or Tableau) preferred.  Other duties as needed or required. \n  \n \n \n About Cox Automotive \n \n  At Cox Automotive, people of every background are driven by their passion for mobility, innovation and community. We transform the way the world buys, sells, owns and uses cars, accelerating the industry with global powerhouse brands like Autotrader, Kelley Blue Book, Manheim and more. What's more, we do it all with an emphasis on employee growth and happiness. Drive your future forward and join Cox Automotive today!\n  \n \n About Cox \n \n  Cox empowers employees to build a better future and has been doing so for over 120 years. With exciting investments and innovations across transportation, communications, cleantech and healthcare, our family of businesses - which includes Cox Automotive and Cox Communications - is forging a better future for us all. Ready to make your mark? Join us today!\n  \n  Benefits of working at Cox may include health care insurance (medical, dental, vision), retirement planning (401(k)), and paid days off (sick leave, parental leave, flexible vacation/wellness days, and/or PTO). For more details on what benefits you may be offered, visit our benefits page .\n  \n  Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law. Cox provides reasonable accommodations when requested by a qualified applicant or employee with disability, unless such accommodations would cause an undue hardship.\n  \n  Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Cox \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   2+ years\n   \n \n \n \n   Security Clearance Note\n   \n \n   Sales Operations Group", "cleaned_desc": "", "techs": ""}, "ad07d2e43eca2158": {"terms": ["data analyst"], "salary_min": 105000.0, "salary_max": 115000.0, "title": "Senior Principal Analyst - Data Management Technology - Remote NA", "company": "The Infosoft Group", "desc": "Senior Principal Analyst - Data Management Technology - Remote US \n \n  As a Senior Principle Analyst, you will create Gartner research and analysis, communicate it to clients and support the sales force in new sales and client retention.Your research will provide insight, predictions and actionable advice to clients around data management. In addition, you will understand adjacent research areas and practices. \n \n  The field of research you will work in \n \n \n  Data Management technologies and its intersection with Analytics, the broader applications market and digital business. \n  Best practices for selecting, implementing and managing data management systems, such as database, data warehouse, data lake, data integration, data catalogues, metadata management. \n  How modern data management environments need to be architected to future proof against new emerging and disruptive technologies, such as Data Mesh, Data Fabric, machine-learning enabled automation, knowledge-graphs. \n  Executing data management programs in the context of cloud migration plans and broader data&analytics strategies. \n \n \n  What you'll do \n \n \n  Impress with your understanding of best practices and inspire by detecting emerging next practices and trends in your field or research. \n  Identify critical questions facing Gartner clients and crafting appropriate research methods to address them. \n  Create and deliver high value presentations off the back of the body of research over time. \n  Conduct research and produce innovative, thought-leading, impactful, analytically-deep, fact-based research analysis. \n  Assist the Sales organization in selling and retention on any topic covered by the Analyst's team. \n \n Provide high quality and timely research peer review. \n \n  Lead or participate in research community meetings to discuss research issues and collaborate effectively with peers. \n \n \n  What we expect \n \n \n  You have 6-12 years of experience within the field of data management. \n  You demonstrate significant applicable experience in the related industry discipline and deep knowledge of a particular market, role, or user strategies in any of the specific areas mentioned above. \n  You have proven experience in presenting to clients at events and conferences, performing workshops and briefings. \n  You will have previously held a leadership role within business or technology field. \n  You bring deep understanding of both technology and industry to include the market, vendors, products and user strategies in specific areas. \n  Education \n  Bachelor's Degree and/or advanced professional qualification(s)) in related field. \n  Proven record of academic achievement at highest level. \n  Master's Degree in related discipline an advantage. \n \n \n  Skills \n \n  Exceptional analytical skills; ability to apply conceptual models, recognizing patterns and drawing and defending conclusions. \n  Exceptional influencing and leadership skills. \n  Very good story teller. Articulate and succinct communication skills; ability to explain complex ideas effectively. \n  Strong writing skills.Very strong team-working ethos. \n  Strong project planning and management skills. \n \n  #LI-NA1 #LI-Remote \n \n  Who are we? \n  Gartner delivers actionable, objective insight to executives and their teams. Our expert guidance and tools enable faster, smarter decisions and stronger performance on an organization's mission-critical priorities. We've grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries. \n \n  What makes Gartner a great place to work? \n  Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger-as individuals, as communities and as an organization. That's why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World's Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join #LifeAtGartner  \n \n What we offer: \n  Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you'll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you. \n  Gartner believes in fair and equitable pay. Certain locations in the United States require job postings to include a reasonable estimate of the base salary range and/or a general description of benefits and other compensation applicable to the role. For this role in those locations, the base salary range for new hires is:California Annualized Base Pay Range: 120,000 USD - 140,000 USDColorado Annualized Base Pay Range: 105,000 USD - 115,000 USDNew Jersey Annualized Base Pay Range: 105,000 USD - 115,000 USDNew York Annualized Base Pay Range: 105,000 USD - 115,000 USDWashington Annualized Base Pay Range: 105,000 USD - 115,000 USDPlease note that actual salaries may vary within the range, or be above or below the range, based on factors including, but not limited to, education, training, experience, professional achievement, business need, and location. In addition to base salary, employees will participate in either an annual bonus plan based on company and individual performance, or a role-based, uncapped sales incentive plan. Our talent acquisition team will provide the specific opportunity on our bonus or incentive programs to eligible candidates. We also offer market leading benefit programs including generous PTO, a 401k match up to $7,200 per year, the opportunity to purchase company stock at a discount, and more.\n  \n  The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively tunity. \n \n  Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job by sending an email to. \n  Job Requisition ID:77185\n  \n  By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence. \n \n  Gartner Applicant Privacy Link:  \n \n For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser. \n  The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively tunity.\n  \n  Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job by sending an email to ApplicantAccommodations@gartner.com.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Gartner \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   6 to 12 years", "cleaned_desc": "", "techs": ""}, "eb5deda9421f39f7": {"terms": ["data analyst"], "salary_min": 94995.695, "salary_max": 120285.71, "title": "Sr. Business Analyst", "company": "INTEGRITYOne Partners", "desc": "Location \u2013 currently 100% remote, with the potential for occasional in-person meetings in Washington, DC. \n \n  As a Senior Business Analyst with INTEGRITYOne Partners, you will be a lead resource capturing and coordinating business and technical requirements to support agile software development teams. Every day, you'll work with dedicated team members and clients to gather, analyze, and document requirements using Agile methodologies and tools. To thrive in this role, you must have experience working in cross-functional teams, delivering results quickly, be intellectually curious, have the drive to learn, identify and solve complex problems, and enjoy a high-tempo environment. Our clients need and demand results immediately. \n \n  We're looking for a Senior Business Analyst with demonstrated experience in gathering, validating, and managing requirements. In this role, you will: \n \n  Leverage your experience over the last 5-7 years gathering, documenting, validating, and managing business and functional requirements. \n \n  Research and lead the creation of business process flows and rules. \n \n  Use your experience to plan and facilitate requirements-gathering working group sessions. \n \n  Collaborate with project managers and product owners on deliverables, schedules, and milestones for the various work streams. \n \n  Demonstrate your excellent communication, facilitation, and mediation skills by creating and maintaining system lifecycle documents and supporting technical gate reviews. \n \n  Be the type of person who wants to grow their career and technical and consulting capabilities in the Federal environment. At INTEGRITYOne Partners, we reward hard work and outstanding results with raises, bonuses, promotions, and training. \n \n  Requirements \n \n  Our contract requires that you are a US Citizen and can obtain and maintain a DHS 6C (Public Trust). This requirement is not negotiable for this role. Please do not apply if you do not meet this requirement. \n \n  Bachelor's degree or beyond. \n \n  At INTEGRITYOne Partners, we have high standards for the members of our team - and when our people meet these standards, the personal and professional rewards are plentiful. We help INTEGRITYOne Partners\u2019 employees grow in their careers by gaining enhanced Federal knowledge and experience, sought-after skills, greater discipline and drive, and targeted education and training \n \n  INTEGRITYOne Partners is an equal opportunity employer Minorities / Females / Veterans / Disabilities. All qualified applicants will be considered without regard to race, ethnicity, color, national origin, religion, sexual orientation, gender identity, veteran status, or status as a qualified individual with a disability or any other personal characteristic protected by law. \n asgv5KQ6ZJ", "cleaned_desc": "", "techs": ""}, "0853f0208b17d807": {"terms": ["data analyst"], "salary_min": 78679.46, "salary_max": 99625.73, "title": "Senior Business Analyst", "company": "Global Payments (Beamery)", "desc": "Description \n Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow.  \n Global Payments, Inc. is looking for an experienced Business Analyst to join the Enterprise Compliance team. The Enterprise Compliance team\u2019s mission is to ensure Global Payments and our clients comply with payment industry rules, regulations, mandates, and laws which apply to credit card, debit card, and other forms of electronic payments.  \n The role:  \n This position is focused on compliance for Debit Merchant Acquiring relevant to authorization and clearing/settlement systems, other ancillary applications, and business processes. As part of a team of compliance professionals, you will be responsible for complex business and technical deliverables for enhancements mandated by card brands, debit networks, third party providers, and industry regulations. Additional responsibilities will include collaborating with application scrum teams, defining requirements, conducting impact analysis, validation of deliverables, and supporting production processes specific to card brand, debit network, and regulatory compliance rules.  \n Key Responsibilities  \n \n Serve as a subject matter expert in debit payment processing as it pertains to the payments industry and Global Payments\u2019 systems  \n Develop, maintain, and grow strategic partnerships with the card brands, debit networks, and other service providers  \n Analyze and interpret card brand and debit network technical and regulatory specifications, rules, requirements, and communications for impact to company systems and customers  \n Translate card brand, debit network, and industry rules into technical requirements, including process maps, gap analyses, and business test cases  \n Oversee and assist technology, business, and operations teams to implement and validate required changes  \n Facilitate inquiries, research, production support relating to mandated rules published by card brand and debit networks, third party providers, and industry regulations  \n Participate in scrum ceremonies and represent compliance priorities during planning discussions  \n Provide advisory services to all business units regarding existing regulations, regulatory requirements, new regulatory changes, and compliance risks for debit processing  \n Support new and existing merchant implementations/conversions as required  \n Initiate and lead projects/initiatives as necessary to ensure Global Payments\u2019 systems remain compliant with card brand and debit network specifications and operating rules  \n Stay abreast of payment brand and debit network rules, publications, products and services, industry news, and release documentation to identify impacts to Global Payments and its clients  \n \n Minimum Qualifications  \n \n 2+ years of experience in the payments industry  \n 5+ years of experience in a technical or analytical role in the IT field  \n \n Preferred Qualifications  \n \n Experience with ISO 8583 message specifications  \n Experience working in an Agile Development environment preferred  \n Ability to take ownership of issues and follow through to completion, be accountable  \n Critical thinker with strong analytical and problem-solving skills  \n Interact with a wide audience: IT, development, operations, security, account support, auditors, vendors, partners, customers, project managers, business analysts, and management  \n Not afraid to question \u201cwhy\u201d and create solutions, see other ways to do things, don\u2019t take things at face value  \n Ability to contribute effectively within a fast-paced, fluid environment and handle changing priorities with confident decision making  \n Excellent time-management, organization, and prioritization skills  \n Ability to build trust and rapport within a team and with internal and external stakeholders  \n Ability to collaborate across all levels of an organization and communicate in an articulate manner to a cross-functional audience to influence results  \n \n \n Ability to work independently, on own, for a remote manager  \n Proficient in Google G Suite applications or MS Office equivalent; SQL experience is a plus   \n \n \n \n Education Desired  \n \n Bachelor\u2019s degree, preferred in information services, information technology, computer science, business or similar area.   \n \n \n \n This position is Remote; preferably in TX, IN, or GA.", "cleaned_desc": " Experience working in an Agile Development environment preferred  \n Ability to take ownership of issues and follow through to completion, be accountable  \n Critical thinker with strong analytical and problem-solving skills  \n Interact with a wide audience: IT, development, operations, security, account support, auditors, vendors, partners, customers, project managers, business analysts, and management  \n Not afraid to question \u201cwhy\u201d and create solutions, see other ways to do things, don\u2019t take things at face value  \n Ability to contribute effectively within a fast-paced, fluid environment and handle changing priorities with confident decision making  \n Excellent time-management, organization, and prioritization skills  \n Ability to build trust and rapport within a team and with internal and external stakeholders  \n Ability to collaborate across all levels of an organization and communicate in an articulate manner to a cross-functional audience to influence results  ", "techs": ["agile development", "critical thinker", "analytical skills", "problem-solving skills", "it", "development", "operations", "security", "account support", "auditors", "vendors", "partners", "customers", "project managers", "business analysts", "management", "solutions", "time-management", "organization", "prioritization skills", "trust building", "collaboration", "communication"]}, "d9ca4f3d2ed75014": {"terms": ["data analyst"], "salary_min": 91448.94, "salary_max": 115794.734, "title": "Business Analyst with R&D", "company": "The Infosoft Group", "desc": "Role: Business Analyst with R&D background \n \n Location : Deerfield, IL (preferred but open to 100% remote for strong candidates \n )  \n \n Duration : 6+ months and potential for extension \n \n \n Note: Pharma/Med Device R&D background. \n \n \n Overview :\n   \n \n This is an IT business analyst role on the R&D IT team, supporting the Regulatory Affairs, Global Patient Safety, Medical Affairs and Clinical Affairs portfolio of projects. \n This role will be an IT business analyst on a large global project to implement a validated Regulatory Information Management (RIM) suite SaaS vendor solution and necessary system integrations to existing systems, as well as migrate legacy data into the new RIM solution. \n The ideal candidate will have the following experience: \n  o Implemented a new validated SaaS software vendor solution from beginning to end, including system integrations\n    o Led requirements gathering across many global functional teams for a new software solution\n    o Managed the creation and approval of the deliverables in a validation package\n    o Created business processes mapping to match the new software solution's functionality and data flow\n    o Created the data flow through a new software solution, including upstream and downstream interfaces\n    o Analyzed legacy data; analyzed legacy and new data models; designed data mapping from legacy system to new system; migrated legacy data into new system\n    o Led the validated testing effort for a new software solution\n    o Collaborated with a software vendor (i.e., understanding the capabilities of the software vendor solution and identifying gaps/mitigations, resolving test defects, etc.)\n    o Regulatory Affairs, Regulatory Information Management\n   \n \n Critical Responsibilities: \n \n \n Lead business functional requirements, technical requirements and solution delivery on enterprise/large projects within the R&D IT function. \n Gather, understand and document business objectives, requirements, functional specifications through workshops/interviews/meetings. \n Manage the creation and approval of the deliverables in a validation package \n Identify, evaluate, develop and /or redesign systems and procedures that meet user requirements. \n Define, design and document business flows and processes for large, highly complex projects. Understand interdependencies of systems for multiple businesses or functions. Provide cross-functional and business knowledge to develop business system and process alternatives. \n Design data flow through software solutions, including upstream and downstream interfaces \n Use technical tools (queries, process maps, etc.) for problem resolution. \n Conduct data analysis; design business rules for data accuracy and consistency; design data mapping and data migration. Identify and resolve data quality issues. \n Establish validation test strategy; develop and execute test cases; lead validation testing with IT and business partners; manage defects with software vendors and IT. \n Assist in development of training materials and/or conduct training. \n Provide support on R&D business applications. \n Understand and follow appropriate SDLC, quality validation processes and application processes. \n Communicate status, solutions and concerns. \n Disseminate information in a timely manner within the team and across functions. \n Make decisions that have a cross-functional or business impact and analyze financial impact. \n Collaborate with software vendors (i.e., understand capabilities of software vendor solution and identify gaps/mitigations, resolve issues, etc.) \n \n \n Key Qualifications: \n \n \n Bachelor's degree in Information Technology \n 8+ years of business analysis experience and implementing IT solutions \n Prefer 3+ years of regulatory affairs and/or regulatory information management experience \n Demonstrate strong business acumen, solution delivery expertise and a strong understanding of systems for both on-premise and SaaS offerings \n Proven success (3+ years) managing large project requirements highly desired \n Ability to accomplish results through others, utilizing effective influencing and leadership skills \n Must be able to solve complex business problems and present recommendations to senior management effectively \n Must be able to define, shape, and drive projects to completion while effectively collaborating with others \n Experience working on all SDLC business processes: requirements, design, development, testing, training and deployment \n Experience working with third-party external teams in the support and implementation of IT solutions \n Data analysis and data migration experience \n Require limited direction; give significant direction; detail and quality oriented; possess extensive knowledge of policies, standards and procedures; have excellent presentation, communication, teamwork and interpersonal skills. \n \n \n  Ampcus is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identify, national origin, age, protected veterans or individuals with disabilities.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Ampcus, Inc \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   8+ years", "cleaned_desc": "    o Analyzed legacy data; analyzed legacy and new data models; designed data mapping from legacy system to new system; migrated legacy data into new system\n    o Led the validated testing effort for a new software solution\n    o Collaborated with a software vendor (i.e., understanding the capabilities of the software vendor solution and identifying gaps/mitigations, resolving test defects, etc.)\n    o Regulatory Affairs, Regulatory Information Management\n   \n \n Critical Responsibilities: \n \n \n Lead business functional requirements, technical requirements and solution delivery on enterprise/large projects within the R&D IT function. \n Gather, understand and document business objectives, requirements, functional specifications through workshops/interviews/meetings. \n Manage the creation and approval of the deliverables in a validation package \n Identify, evaluate, develop and /or redesign systems and procedures that meet user requirements. \n Define, design and document business flows and processes for large, highly complex projects. Understand interdependencies of systems for multiple businesses or functions. Provide cross-functional and business knowledge to develop business system and process alternatives. \n Design data flow through software solutions, including upstream and downstream interfaces \n Use technical tools (queries, process maps, etc.) for problem resolution. \n Conduct data analysis; design business rules for data accuracy and consistency; design data mapping and data migration. Identify and resolve data quality issues. \n Establish validation test strategy; develop and execute test cases; lead validation testing with IT and business partners; manage defects with software vendors and IT. \n Assist in development of training materials and/or conduct training. \n Provide support on R&D business applications. \n Understand and follow appropriate SDLC, quality validation processes and application processes. \n Communicate status, solutions and concerns.   Disseminate information in a timely manner within the team and across functions. \n Make decisions that have a cross-functional or business impact and analyze financial impact. \n Collaborate with software vendors (i.e., understand capabilities of software vendor solution and identify gaps/mitigations, resolve issues, etc.) \n \n \n Key Qualifications: \n \n \n Bachelor's degree in Information Technology \n 8+ years of business analysis experience and implementing IT solutions \n Prefer 3+ years of regulatory affairs and/or regulatory information management experience \n Demonstrate strong business acumen, solution delivery expertise and a strong understanding of systems for both on-premise and SaaS offerings \n Proven success (3+ years) managing large project requirements highly desired \n Ability to accomplish results through others, utilizing effective influencing and leadership skills \n Must be able to solve complex business problems and present recommendations to senior management effectively \n Must be able to define, shape, and drive projects to completion while effectively collaborating with others \n Experience working on all SDLC business processes: requirements, design, development, testing, training and deployment \n Experience working with third-party external teams in the support and implementation of IT solutions \n Data analysis and data migration experience \n Require limited direction; give significant direction; detail and quality oriented; possess extensive knowledge of policies, standards and procedures; have excellent presentation, communication, teamwork and interpersonal skills. \n \n ", "techs": ["analyzed legacy data", "analyzed legacy and new data models", "designed data mapping from legacy system to new system", "migrated legacy data into new system", "validated testing effort for a new software solution", "collaborated with a software vendor", "regulatory affairs", "regulatory information management", "gather", "understand and document business objectives", "requirements", "functional specifications", "manage creation and approval of deliverables in a validation package", "identify", "evaluate", "develop and/or redesign systems and procedures", "define", "design and document business flows and processes", "design data flow through software solutions", "use technical tools for problem resolution", "conduct data analysis", "design business rules for data accuracy and consistency", "design data mapping and data migration", "establish validation test strategy", "develop and execute test cases", "lead validation testing with it and business partners", "manage defects with software vendors and it", "assist in development of training materials", "conduct training", "provide support on r&d business applications", "understand and follow appropriate sdlc", "quality validation processes and application processes", "communicate status", "solutions and concerns", "disseminate information in a timely manner", "make decisions with cross-functional or business impact", "analyze financial impact", "collaborate with software vendors", "bachelor's degree in information technology", "8+ years of business analysis experience", "3+ years of regulatory affairs and/or regulatory information management experience", "strong business acumen", "solution delivery expertise", "understanding of systems for on-premise and saas offerings", "managing large project requirements", "ability to accomplish results through others", "effective influencing and leadership skills", "solving complex business problems", "presenting recommendations to senior management", "defining", "shaping", "and driving projects to completion", "experience working on all sdlc business processes", "experience working with third-party external teams", "data analysis and data migration experience", "excellent presentation", "communication", "teamwork", "and interpersonal skills"]}, "4cb4c443a0b8f7c5": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Supply Chain Analyst - Transportation and Logistics", "company": "Ferguson Enterprises, LLC", "desc": "Job Posting:  \n Ferguson is North America\u2019s leading value-added distributor across residential, non-residential, new construction and repair, maintenance, and improvement (RMI) end markets. Spanning 34,000 suppliers and more than one million customers, we deliver local expertise, value-added solutions, and the industry\u2019s most extensive portfolio of products. From infrastructure, plumbing, and appliances, to HVAC, fire protection, fabrication, and more, we make our customers\u2019 complex projects simple, successful, and sustainable. \n \n  Ferguson is currently seeking a Supply Chain Analyst to assist our final mile organization! \n \n  This role will assist in the strategy and analysis of our routing approach for 1500 locations and 5000 delivery vehicles. The ideal candidate would have experience in routing customer deliveries and ability to build reports and analyze data. This role will also assist in the on-boarding of new technology and the use of the technology in the field locations. \n \n  The Supply Chain Analyst helps prepare and issue regular reporting and analyses to illustrate and explain variables that impact cost of deliveries, 3rd party carrier usage, technology use and compliance, supply chain challenges, and trends in the mix of businesses. This individual works in partnership with Senior Supply Chain Manager, field leadership, and logistics teams in the effort to supply accurate and timely data and insights in the performance of all Ferguson business units. \n \n  Areas of impact: \n  Assist in the maintenance and enhancement of final mile software, processes, and reporting affecting over 4 million deliveries annually. \n \n  Problem solving: \n  Create and reinforce business flows in a highly-matrixed, diverse environment comprised of several thousand associates with direct impact on the routing compliance and increased efficiencies. \n \n  Job duties: \n \n  Establish routing standard processes and help develop technology to support the field in meeting customer\u2019s need. \n  Assist in on-boarding and enhancing technology; become Ferguson\u2019s subject matter expert. \n  Develop and recommend specific courses of action based on analysis of special requests for management or internally generated opportunities. \n  Assist in the maintenance and creation final mile SOP\u2019s \n  Develop the supply chain with partnered vendors to achieve target business results that create and maintain a competitive advantage for the Company. \n  Assist in design, development, and implementation of data gathering and analysis tools and processes. \n  Drives and delivers analysis, concept development, planning and successful execution of routing processes that drive efficiency and effectiveness in our supply chain. \n  Drives collaborations with suppliers and key partners internally and externally, supporting the efficiency and effectiveness of the supply chain final mile. \n  Oversee a significant Supply Chain process or function and manage all aspects of executing said process or function. \n  Educate others throughout the organization on Supply Chain management and its impact on roles and collective opportunities. \n  Address, report, and resolve areas of risk or weakness in Ferguson\u2019s final mile organization \n \n \n  Preferred Qualifications  \n \n Proven experience in supply chain, finance, or distribution analysis \n  Bachelor\u2019s Degree in supply chain, engineering, Business, Logistics, Mathematics, or similar subject area. \n  Prior experience working in a branch or distribution center is a plus, but not required \n  Strong analytical skills including the ability to collect, organize, and analyze large datasets with attention to detail and accuracy \n  \u201cForward Thinker\u201d with excellent problem-solving skills \n  Excellent communication & presentation skills \n  Able to work independently as well as in a highly collaborative environment \n \n \n  Ferguson is dedicated to providing meaningful benefits programs and products to our associates and their families\u2014geared toward benefits, wellness, financial protection, and retirement savings. Ferguson offers a competitive benefits package that includes medical, dental, vision, retirement savings with company match, paid leave (vacation, sick, personal, holiday, and parental), employee assistance programs, associate discounts, community involvement opportunities, and much more! \n  #LI-REMOTE \n \n  Pay Range: \n \n  Actual pay rate may vary depending upon location. The estimated pay range for this position is below. The specific rate will depend on a candidate\u2019s qualifications and prior experience. \n  $4,124.70 - $6,783.70\n  \n  Estimated Ranges displayed are Monthly for Salaried roles  OR  Hourly for all other roles. \n \n  This role is Bonus or Incentive Plan eligible. \n \n  The Company is an equal opportunity employer as well as a government contractor that shall abide by the requirements of 41 CFR 60-300.5(a), which prohibits discrimination against qualified protected Veterans and the requirements of 41 CFR 60-741.5(A), which prohibits discrimination against qualified individuals on the basis of disability. \n \n  Ferguson Enterprises, LLC. is an equal employment employer  F/M/Disability/Vet/Sexual  Orientation/Gender  Identity. \n \n  Equal Employment Opportunity and Reasonable Accommodation Information", "cleaned_desc": "", "techs": ""}, "3ba8aebb2ace81e2": {"terms": ["data analyst"], "salary_min": 86985.02, "salary_max": 110142.43, "title": "Senior QAD Business Analyst (Remote)", "company": "The Infosoft Group", "desc": "Job Description\n   MiTek is a platform innovator and enabler that exists to transform the building industry with better building solutions. In 1955, MiTek transformed residential construction with the invention of the Gang-Nail plate and a digital platform that provided an affordable and scalable way to manufacture wood trusses. Today, MiTek delivers software, services, engineered products, and automated solutions that enable the building industry toimprove efficiencies by optimizingthe balance between off-site and on-site. With nearly 5,600 team members worldwide, MiTek collaborates across the building industry to enable and accelerate transformational breakthroughs in design and construction to transform the way the industry designs, makes, and builds. As a Berkshire Hathaway (NYSE: BRK-A, NYSE: BRK-B) company since 2001, MiTek has a record of continuous growth and innovation. Learn more at . \n  SummaryThe Senior QAD Business Analyst plays a pivotal role in bridging the gap between business processes and technology solutions. This role involves collaborating with stakeholders across different departments to understand their requirements, analyze existing business processes, and recommend improvements through the implementation and optimization of QAD, MiTek's Enterprise Resource Planning (ERP) system. The Senior QAD Business Analyst will ensure that QAD aligns with the organization's goals and objectives, enhancing operational efficiency and facilitating data-driven decision-making.\n   Job Responsibilities & RequirementsRESPONSIBILITIES:\n   Requirement Gathering and Analysis: \n \n  Collaborate with business stakeholders to gather and document detailed requirements for ERP system implementations or enhancements. \n  Analyze existing business processes, identifying pain points and areas for improvement. \n  Translate business requirements into clear and concise functional specifications for the development team. \n \n  ERP System Implementation: \n \n  Work closely with technical teams and vendors to ensure successful implementation of ERP solutions. \n  Participate in system configuration, customization, and testing activities. \n  Monitor project progress and communicate updates to stakeholders, addressing any issues that arise during implementation. \n \n  Process Mapping and Documentation: \n \n  Document current and future state business processes using process mapping techniques. \n  Create process flow diagrams, use cases, and other relevant documentation to facilitate clear understanding among stakeholders. \n \n  Change Management: \n \n  Assist in change management activities by preparing end-users for system changes, including training sessions and documentation. \n  Anticipate and address potential resistance to change and provide support to users during the transition period. \n \n  Quality Assurance and Testing: \n \n  Participate in user acceptance testing (UAT) to ensure that the ERP system meets business requirements and functions as intended. \n  Identify and report bugs, issues, and deviations from specifications to the development team. \n \n  QUALIFICATIONS:\n  \n  Experience with QAD ERP System required \n  Experience with EAGLE software highly preferred \n  Bachelors or Advanced degree preferred and 5+ years equivalent IT/Business experience \n  Proven experience as a Business Analyst in ERP system implementation and optimization \n  Strong understanding of ERP concepts, modules, and integration points \n  Excellent communication skills to effectively interact with technical and non-technical stakeholders \n  Proficiency in requirements gathering, process mapping, and documentation \n  Experience in change management and end-user training \n  Project management skills with the ability to manage multiple tasks and priorities \n \n  MiTek PERKS:\n  \n  Flexible Paid Time Off - take as much time off as you need! \n  All Benefits begin on Day 1! \n  Profit Sharing Plan and Annual Incentive Plan \n  13 Paid Holidays \n  401k Plan with Matching Contributions \n  A variety of Medical, Dental and Vision Plans to choose from \n  Short-Term Disability and Life Insurance \n  Tuition Reimbursement  \n Paid Parental Leave \n  Career advancement and training opportunities! \n \n \n  MiTek is an E-Verify and Drug and Tobacco-Free Workplace.  \n \n We are an equal opportunity employer; and all qualified applicants will receive consideration for employment without regard to race, color, creed, religion, national origin, ethnicity, physical or mental disability, sex (including pregnancy, sexual orientation, gender identity or expression, or transgender status), age (40 and over), genetic information (including family medical history), veteran status, or any other protected characteristic. \n \n  For accommodation to assist with completing this application, please contact Human Resources at +1 314-434-1200. \n \n  MiTek is an E-Verify and Drug and Tobacco-Free Workplace. We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   MiTek Inc. \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   5+ years", "cleaned_desc": " \n  Change Management: \n \n  Assist in change management activities by preparing end-users for system changes, including training sessions and documentation. \n  Anticipate and address potential resistance to change and provide support to users during the transition period. \n \n  Quality Assurance and Testing: \n \n  Participate in user acceptance testing (UAT) to ensure that the ERP system meets business requirements and functions as intended. \n  Identify and report bugs, issues, and deviations from specifications to the development team. \n \n  QUALIFICATIONS:\n  \n  Experience with QAD ERP System required \n  Experience with EAGLE software highly preferred \n  Bachelors or Advanced degree preferred and 5+ years equivalent IT/Business experience \n  Proven experience as a Business Analyst in ERP system implementation and optimization \n  Strong understanding of ERP concepts, modules, and integration points \n  Excellent communication skills to effectively interact with technical and non-technical stakeholders \n  Proficiency in requirements gathering, process mapping, and documentation ", "techs": ["qad erp system", "eagle software"]}, "e5acc4aeec3c3fb5": {"terms": ["data analyst"], "salary_min": 81721.02, "salary_max": 103477.02, "title": "Senior Business Analyst - Remote", "company": "The Infosoft Group", "desc": "Senior Business Analyst - Remote \n      \n \n \n     Org Structure : Job Posting Location Kenosha, WI - 1350 22nd Ave \n     \n \n \n \n \n \n        Category\n        \n \n        Operations \n        \n \n        Type\n        \n \n        Regular Full-Time \n        \n \n \n \n \n \n Job Description \n   \n \n \n First American Bank was founded in Chicago, and over the years has expanded throughout Wisconsin and Florida. As the largest privately held bank in Illinois, we now have over 60 locations and assets of $5+ billion. We are a community bank at heart with international expertise, traditional values, and a forward-looking philosophy. Our employees have the experience and vision to meet the needs of savers, borrowers, and businesses in the 21st century. First American Bank can offer employees a level of visibility, career growth, and stability that is difficult to find in many larger corporations. \n   \n This position is responsible for supporting process improvements for departments within First American Bank to optimize efficiencies, increase productivity, and reduce risks and costs. This individual will act as the subject matter expert for improving department processes and independently implement changes. \n   \n Duties & Responsibilities \n  Develop, implement, analyze, and update processes and procedures for a variety of First American Bank departments in accordance with regulations.  \n \n Ensure compliance by developing and delivering training sessions and materials to efficiently and comprehensively educate both new and existing employees to mitigate risk for the bank, maximize departmental efficiency, and reduce costs. \n   \n Analyze, implement, update improvements of existing processes and procedures to maximize departmental efficiencies, including building and reviewing process diagrams and requesting system program changes. \n   \n Acquire and maintain industry awareness within departments, knowledge of regulatory expectations, and legal expertise to interpret rules and guidelines. Serve as the Subject Matter Expert (SME) for changes to regulations, identifying the impact of the regulations on the bank and implement procedures to adhere to changes. \n   \n Lead various operational functions with minimal oversight. Develop and adapt operational functions to support projects unique to the departments' needs. \n   \n Prepare careful data review and testing, which involve data query and report generation prior to enhancement implementations. \n   \n Identify opportunities for operational efficiency and recommend improvements to streamline processes for a variety of departments. \n   \n Serve as the representative for the implementation of new processes and procedures that are relevant to the division. \n   \n Coordinate with the department manager, outside vendors, other First American Bank departments, and others within the department to ensure that all activities and projects are completed efficiently. \n   \n Conduct and complete additional assignments/projects as designated by management. \n   \n Qualifications \n  High school diploma or equivalent required. \n   \n Bachelor's Degree preferred. \n   \n Minimum three years of experience in process improvement and project coordination/management. \n   \n Experience in road mapping, building and reviewing process diagrams, and creating procedures required. \n   \n Strong organizational skills and a desire to work in a fast-paced, ever-changing environment are essential to succeed. \n   \n Demonstrate initiative, be resourceful and insightful, ability to work independently within a deadline, and ultimately be accountable for each project. \n   \n Must be professional, comfortable speaking with external and internal contacts with a demonstrated ability to tailor the message appropriately to the audience and situation effectively. \n   \n Demonstrated ability to convey thoughts and ideas effectively and succinctly via written formats, including emails, letters, and electronic platforms. Maintain professional standards relating to spelling and grammar. \n   \n Maintain credibility through professional demeanor, appearance, and presence by modeling standards appropriate to our environment and industry. \n   \n Maintain good working relationships with internal partners by exhibiting exemplary interpersonal skills, adopting a constructive, solutions-focused approach. \n   \n Use sound professional judgment to balance the interests of the organization and customer, understanding and using available resources to mitigate risks. \n   \n Minimum of five years experience with Relius, PensionPro, FIS AddVantage and Retirement Plan Services is required. \n   \n Must possess a high proficiency of reporting software, word processing and spreadsheet programs, and be quick to learn new programs as introduced. \n   \n Proficiency with Microsoft 365 products and applications, including the ability to effectively prepare or review documents, procedures, and reports. \n   \n Demonstrated ability to learn new systems and applications, as well as the ability to understand, adapt and adjust responsibilities/workflows as a result of system upgrades. \n   \n Aptitude for database management and query analysis is required. Prior design experience with MS Access and Power BI is preferred or candidate must be willing to be trained and become proficient. \n   \n Occasional travel to other First American Bank locations, Bank functions and training facilities may be required. \n   \n Typical hours are Monday through Friday 8:00 a.m. to 5:00 p.m. Additional hours may be required depending upon business need. \n \n \n \n \n \n  First American Bank is an Equal Opportunity Employer (Minorities/Females/Disabled/Veterans).\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   First American Bank \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   High School or Equivalent\n   \n \n \n \n   Required Experience\n   \n \n   3+ years", "cleaned_desc": " Qualifications \n  High school diploma or equivalent required. \n   \n Bachelor's Degree preferred. \n   \n Minimum three years of experience in process improvement and project coordination/management. \n   \n Experience in road mapping, building and reviewing process diagrams, and creating procedures required. \n   \n Strong organizational skills and a desire to work in a fast-paced, ever-changing environment are essential to succeed. \n   \n Demonstrate initiative, be resourceful and insightful, ability to work independently within a deadline, and ultimately be accountable for each project. \n   \n Must be professional, comfortable speaking with external and internal contacts with a demonstrated ability to tailor the message appropriately to the audience and situation effectively. \n   \n Demonstrated ability to convey thoughts and ideas effectively and succinctly via written formats, including emails, letters, and electronic platforms. Maintain professional standards relating to spelling and grammar. \n   \n Maintain credibility through professional demeanor, appearance, and presence by modeling standards appropriate to our environment and industry. \n   \n Maintain good working relationships with internal partners by exhibiting exemplary interpersonal skills, adopting a constructive, solutions-focused approach. \n   \n Use sound professional judgment to balance the interests of the organization and customer, understanding and using available resources to mitigate risks. \n   \n Minimum of five years experience with Relius, PensionPro, FIS AddVantage and Retirement Plan Services is required. \n   \n Must possess a high proficiency of reporting software, word processing and spreadsheet programs, and be quick to learn new programs as introduced. \n   \n Proficiency with Microsoft 365 products and applications, including the ability to effectively prepare or review documents, procedures, and reports. ", "techs": ["qualifications", "high school diploma", "bachelor's degree", "process improvement", "project coordination/management", "road mapping", "process diagrams", "creating procedures", "organizational skills", "fast-paced", "ever-changing environment", "initiative", "resourceful", "ability to work independently", "accountability", "professional", "external contacts", "internal contacts", "tailor the message", "convey thoughts and ideas", "written formats", "emails", "letters", "electronic platforms", "spelling", "grammar", "professional standards", "professional demeanor", "appearance", "presence", "interpersonal skills", "constructive approach", "sound professional judgment", "organization", "customer", "available resources", "mitigate risks", "relius", "pensionpro", "fis addvantage", "retirement plan services", "reporting software", "word processing", "spreadsheet programs", "microsoft 365 products", "prepare documents", "review documents", "procedures", "reports"]}, "17b7108e3d0ea48c": {"terms": ["data analyst"], "salary_min": 83610.234, "salary_max": 105869.19, "title": "Senior IT Business Analyst", "company": "The Infosoft Group", "desc": "Milwaukee, Wisconsin, United States\n   United States of America Mayfield Heights\n   United States of America Minnesota (remote)\n   United States of America Pennsylvania (remote)\n   United States of America Texas (remote)\n   United States of America Illinois (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n \n  We're hiring a Sr. IT Business Analyst to help us keep growing. If you're excited to be part of a winning team, this is a perfect place to get ahead. \n \n \n  Rockwell Automation's partnerships are governed by various programs and include key elements such as partnership agreements, incentives, pricing, policies, communications, etc. These programs require a modern, best in class platform to maximize our digital experience and engagement with our partners - including Distributors, System Integrators, OEM Partners, and Technology Partners. \n \n \n  The Sr IT Business Analyst will play a key role to drive the IT requirements to support these programs. \n \n \n  Key Responsibilities \n \n \n \n \n  Gather and analyze data to help clarify business objectives and expectations for advancing digital experience investment(s) \n  Engages with the business and teams during ideation and design, guides technology selection in partnership with lead engineer and dev team(s) and ensure compliance with security, identity and access management, Enterprise Architecture, etc. \n  Work closely with AGILE team - scrum master, developers, testers, and the business team. Managers and end users to determine best IT solution. \n  Support Product Owner in Agile ceremonies to help prioritize or find input from Global Market Access teams and other stakeholders to enable IT development or prioritization as needed. \n  Provide recommendations on hardware and software procurement to support business goals. \n  Coordinate the development of documentation to enable implementation and turnover of the process of system, including post-project evaluation. \n  Define objectives and scope of business system and drive business Analysis activities and agile artifacts required to deliver actionable User Stories for IT \n  Facilitate meetings to gather and/or perform User Acceptance Testing or follow-up items after Agile Spring Demos as needed. \n  Engage with IT Support by proactively finding answers and coordinating efforts to ticket resolution to reduce impact to environments. \n  Follow through on IT commitments and escalate if needed to meet delivery dates. \n  Provides cross-product/cross-technology expertise to capability teams, provides input on and evaluates solution design and is consulted during release planning. \n  Maintains policies, standards, and guidelines to ensure that a consistent technology framework is applied across the company, maintains awareness and visibility of organizational standards and best practices. \n \n \n \n \n \n \n  Basic Qualifications : \n \n \n \n \n \n  Bachelor's technical degree or equivalent relevant years experience required. \n  Legal authorization to work in the US is required.We will not sponsor individuals for employment visas, neither now nor in the future, for this job opening \n \n \n \n \n \n \n  Preferred Qualifications: \n \n \n \n \n \n  Minimum 8 years of experience in Business analysis  \n 5+ years of computer applications experience \n  5+ years in requirements gathering, process mapping, wireframing, creating analysis artifacts and Software Development Life Cycle \n  Experience with Agile development methodologies and Agile tools - Jira and Jira align. \n  Understanding of CRM Systems: Microsoft Dynamics 365, Salesforce, PowerApps, PowerBI, Agile CRM \n  Experience in systems development lifecycle \n  Experience managing multiple projects simultaneously, partner with stakeholders and influence project decisions. \n  Ability to adapt quickly to new technologies and changing business requirements. \n  Strong team orientation and ability to collaborate with the business and IT organization. \n  Expert level in Microsoft Office Applications, including Agile tools - Jira and Jira align. \n  Understanding of APIs, Data Analysis, and data integrity \n  Experience building strategic technology plans and roadmaps. \n  Ability to adapt quickly to new technologies and changing business requirements. \n  Excellent analytical, attention to detail and problem-solving skills \n  Excellent interpersonal, verbal and written communication skills \n  Comprehensive knowledge of hardware, software, application, and systems engineering \n  Strong leadership and negotiation skills with business and technical groups  \n Intellectual curiosity and the ability to question thought partners across functional areas. \n  Excellent understanding of business complexities and project interdependencies \n  Bachelor's Degree in computer science, management information systems or related field \n \n \n \n This position is part of a job family. Experience will be the determining factor for position level and compensation. \n \n \n  #LI-PC1 \n \n \n \n  We are an Equal Opportunity Employer including disability and veterans. \n \n  If you are an individual with a disability and you need assistance or a reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7247. \n  Rockwell Automation is an Equal Opportunity Employer \u2013 Disability/Veteran.\n  \n  If you are an individual with a disability and you need assistance or reasonable accommodation during the application process, email our Talent Acquisition representative at RAApplicationsupport@ra.rockwell.com.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Rockwell Automation \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   8+ years", "cleaned_desc": " \n \n  Preferred Qualifications: \n \n \n \n \n \n  Minimum 8 years of experience in Business analysis  \n 5+ years of computer applications experience \n  5+ years in requirements gathering, process mapping, wireframing, creating analysis artifacts and Software Development Life Cycle \n  Experience with Agile development methodologies and Agile tools - Jira and Jira align. \n  Understanding of CRM Systems: Microsoft Dynamics 365, Salesforce, PowerApps, PowerBI, Agile CRM \n  Experience in systems development lifecycle \n  Experience managing multiple projects simultaneously, partner with stakeholders and influence project decisions. \n  Ability to adapt quickly to new technologies and changing business requirements. \n  Strong team orientation and ability to collaborate with the business and IT organization. \n  Expert level in Microsoft Office Applications, including Agile tools - Jira and Jira align. \n  Understanding of APIs, Data Analysis, and data integrity \n  Experience building strategic technology plans and roadmaps. \n  Ability to adapt quickly to new technologies and changing business requirements. \n  Excellent analytical, attention to detail and problem-solving skills \n  Excellent interpersonal, verbal and written communication skills \n  Comprehensive knowledge of hardware, software, application, and systems engineering \n  Strong leadership and negotiation skills with business and technical groups  \n Intellectual curiosity and the ability to question thought partners across functional areas. \n  Excellent understanding of business complexities and project interdependencies \n  Bachelor's Degree in computer science, management information systems or related field ", "techs": ["jira", "jira align", "microsoft dynamics 365", "salesforce", "powerapps", "powerbi", "agile crm", "microsoft office applications"]}, "606c8b56e4ed71c4": {"terms": ["data analyst"], "salary_min": 87700.0, "salary_max": 159900.0, "title": "Senior IT Audit Analytics Business Analyst (Remote Consideration)", "company": "Lincoln Financial", "desc": "Date:  Sep 9, 2023  \n Primary Location:  Greensboro, NC, US  \n Company:  Lincoln Financial  \n \n \n Alternate Locations:  Greensboro, NC (North Carolina); Charlotte, NC (North Carolina); Fort Wayne, IN (Indiana); Hartford, CT (Connecticut); Omaha, NE (Nebraska); Radnor, PA (Pennsylvania); Work from Home\n   \n \n \n \n Work Arrangement: \n \n \n   Remote : Work at home employee residing outside of a commutable distance to an office location.\n   \n \n \n \n Relocation assistance:  is not available for this opportunity.\n   \n \n \n \n Requisition #:  72175\n   \n \n \n \n \n \n \n  The Role at a Glance \n \n \n \n \n       This is a dual position. You will serve as a data analyst as well as an IT auditor. As a Senior IT Audit Analytics Business Analyst, you will coordinate interactions between other Internal Audit staff, third-party consultants, the Development Analyst and business unit project sponsors for identification of technical requirements to develop various audit analytics projects. You will incorporate your knowledge of IT and Operational internal controls into the oversight of computer program development. This position will apply strong project management skills and working knowledge of the Agile development methodology to oversee various audit analytics projects in a dispersed/distributed development environment. In this role you must have a strong understanding of how data analytics are used to take large volumes of data and use skills in math, statistics and programming to clean, massage and organize the information into a readily useable format for management.\n       \n  This position will also be responsible for executing existing Audit Analytics projects including data analytic programs, board reportable projects and other operational audit activities. You will be accountable to follow up with business unit management on any exceptions identified during the execution of these projects and will then determine whether the exception is a finding that needs to be remediated by business unit management. You will also draft formal memos, draft audit reviews and reports.\n       \n  As a Senior IT Auditor, you will also direct the development, implementation and evaluation of his/her assigned complex IT audit plans/programs to evaluate the effectiveness of the internal controls and adherence to all applicable procedures, regulations, and/or laws for his/her assigned area(s) of responsibility.\n       \n \n \n \n \n \n \n What you'll be doing \n \n \n \n \n Direct IT audit activities including: developing, driving and executing complex audit plans for his/her assigned area(s) of responsibility. \n Direct IT audit engagements including risk assessments, audit planning, audit testing, control evaluations, audit communications and follow up and verification of issue closure. \n Identifies early identification of emerging complex IT control issues and reporting them timely to appropriate senior management and business stakeholders. \n Finalizes audit findings and using judgment opine on the control environment. \n Identify project requirements by expediting communication between the Audit Analytics team and project sponsors through use of conference calls, video conferences, and online meetings. If needed, may also arrange face to face meetings for all parties involved in the project to finalize key requirements. \n Prioritize the requirements to ensure there are quick wins in development process and that project stays on track and daily goals are achieved. \n Must be skilled in techniques to identify project sponsor needs, negotiate priorities between the different groups, and then collaborate with developers to ensure that the requirements are implemented effectively. \n Execute testing of data analytics programs and operational audit projects by use of various computer programming languages such as ACL, Visual Basic, SQL, Python and advanced Microsoft Office Excel. \n Track and resolve testing and project sponsor identified program problems until resolved. \n Perform quality review of all computer program documentation according to IT professional and LFG Internal Audit Data Analytics standards prior to delivery to Project Sponsor. \n Provide Internal Audit management and the project sponsor with periodic project status of the actual hours and dollars spent compared to the budget as well as an estimate of percent of completion of the project. \n Serve as a technical resource and consult with teammates and other Internal Audit staff on a broad variety of data analytics matters/issues related to his/her assigned projects. \n Participate in brainstorming and creation of ad hoc/continuous monitoring routines as needed to support internal investigations, special projects and the on-going monitoring of fraud risks. \n Communicate effectively, both verbally and in written form with team mates, third party consultants and business unit management. \n Be familiar with Institute of Internal Audit standards and know how to effectively execute operational audit testing and to validate and resolve audit findings. \n Responsible for execution of production data analytic programs and resolution of any exceptions identified by these programs in consultation with business unit management. \n Will draft final memos and reports to business unit and Internal Audit management for the completed data analytic work. \n Follow department and team protocols to maintain confidentiality of records and information used in all projects. \n Work well independently and in team environment.   \n \n \n \n \n \n \n What we\u2019re looking for \n \n \n \n \n  Must-haves \n \n \n 7+ years of experience in a business analyst or IT Auditor role in the financial services industry/data analytics field \n Bachelors' degree in Computer Science, Informatics, Data Analytics, Accounting, Actuary, or related area \n Experience in data analytics, operational auditing, and project management using ACL, Visual Basic, SQL, Alteryx, UIPath, Tableau, Python or other advanced analytics tool \n Strong interpersonal skills, strong verbal and written communication skills, attention to details, self-motivated with a sense of urgency. \n Other certifications such as ACL Certified Data Analyst (ACDA), CPA, CFE, CISA, CIA or others a plus. \n \n \n Nice-to-haves: \n \n \n Technical certifications in Project Management and Agile SCRUM training highly desirable \n \n \n \n \n \n \n \n What\u2019s it like to work here? \n \n \n   At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.\n   \n \n \n \n What\u2019s in it for YOU: \n \n \n \n \n     A clearly defined career framework to help you successfully manage your career\n       \n \n \n     Leadership development and virtual training opportunities\n       \n \n \n     PTO/parental leave\n       \n \n \n     Competitive 401K and employee benefits\n       \n \n \n     Free financial counseling, health coaching and employee assistance program\n       \n \n \n     Tuition assistance program\n       \n \n \n     A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations\n       \n \n \n     Effective productivity/technology tools and training\n       \n \n \n \n Pay Range:  $87,700 - $159,900\n   \n \n \n \n   Actual base pay could vary based on non-discriminatory factors including but not limited to work experience, education, location, licensure requirements, proficiency and qualifications required for the role. The base pay is just one component of Lincoln\u2019s total rewards package for employees. In addition, the role may be eligible for the Annual Incentive Program, which is discretionary and based on the performance of the company, business unit and individual. Other rewards may include long-term incentives, sales incentives and Lincoln\u2019s standard benefits package.\n   \n \n \n \n About The Company \n \n \n   Lincoln Financial Group provides advice and solutions that help people take charge of their financial lives with confidence and optimism. Today, approximately 16 million customers trust our retirement, insurance and wealth protection expertise to help address their lifestyle, savings and income goals, and guard against long-term care expenses.\n   \n \n \n  Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE:LNC) and its affiliates. The company had $290 billion in end-of-period account balances net of reinsurance as of March 31, 2023.\n   \n \n \n \n   Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and ranks among Newsweek\u2019s Most Responsible Companies. Dedicated to diversity, equity and inclusion, we are included on transparency benchmarking tools such as the Corporate Equality Index, the Disability Equality Index and the Bloomberg Gender-Equality Index. Committed to providing our employees with flexible work arrangements, we were named to FlexJobs\u2019 list of the Top 100 Companies to Watch for Remote Jobs in 2022. With a long and rich legacy of acting ethically, telling the truth and speaking up for what is right, Lincoln was recognized as one of Ethisphere\u2019s 2022 World\u2019s Most Ethical Companies\u00ae. We create opportunities for early career talent through our intern development program, which ranks among WayUp and Yello\u2019s annual list of Top 100 Internship Programs.\n   \n \n \n \n   Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.\n   \n \n \n \n   Follow us on Facebook, Twitter, LinkedIn, and Instagram.\n   \n \n \n \n Be Aware of Fraudulent Recruiting Activities \n \n \n   If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.\n   \n \n   Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.\n   \n \n \n \n Additional Information \n \n \n   This position may be subject to Lincoln\u2019s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln\u2019s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.\n   \n \n \n \n   Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.\n   \n \n \n \n   Lincoln Financial Group (\u201cLFG\u201d) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.", "cleaned_desc": " \n \n \n \n \n \n What you'll be doing \n \n \n \n \n Direct IT audit activities including: developing, driving and executing complex audit plans for his/her assigned area(s) of responsibility. \n Direct IT audit engagements including risk assessments, audit planning, audit testing, control evaluations, audit communications and follow up and verification of issue closure. \n Identifies early identification of emerging complex IT control issues and reporting them timely to appropriate senior management and business stakeholders. \n Finalizes audit findings and using judgment opine on the control environment. \n Identify project requirements by expediting communication between the Audit Analytics team and project sponsors through use of conference calls, video conferences, and online meetings. If needed, may also arrange face to face meetings for all parties involved in the project to finalize key requirements. \n Prioritize the requirements to ensure there are quick wins in development process and that project stays on track and daily goals are achieved. \n Must be skilled in techniques to identify project sponsor needs, negotiate priorities between the different groups, and then collaborate with developers to ensure that the requirements are implemented effectively. \n Execute testing of data analytics programs and operational audit projects by use of various computer programming languages such as ACL, Visual Basic, SQL, Python and advanced Microsoft Office Excel. \n Track and resolve testing and project sponsor identified program problems until resolved. \n Perform quality review of all computer program documentation according to IT professional and LFG Internal Audit Data Analytics standards prior to delivery to Project Sponsor. \n Provide Internal Audit management and the project sponsor with periodic project status of the actual hours and dollars spent compared to the budget as well as an estimate of percent of completion of the project. \n Serve as a technical resource and consult with teammates and other Internal Audit staff on a broad variety of data analytics matters/issues related to his/her assigned projects. \n Participate in brainstorming and creation of ad hoc/continuous monitoring routines as needed to support internal investigations, special projects and the on-going monitoring of fraud risks. \n Communicate effectively, both verbally and in written form with team mates, third party consultants and business unit management. \n Be familiar with Institute of Internal Audit standards and know how to effectively execute operational audit testing and to validate and resolve audit findings. \n Responsible for execution of production data analytic programs and resolution of any exceptions identified by these programs in consultation with business unit management. \n Will draft final memos and reports to business unit and Internal Audit management for the completed data analytic work. \n Follow department and team protocols to maintain confidentiality of records and information used in all projects. \n Work well independently and in team environment.   \n \n \n \n \n \n \n What we\u2019re looking for \n \n \n \n \n  Must-haves ", "techs": ["developing", "driving", "executing complex audit plans", "risk assessments", "audit planning", "audit testing", "control evaluations", "audit communications", "follow-up", "verification of issue closure", "identification of emerging complex it control issues", "reporting", "finalizing audit findings", "opining on the control environment", "expediting communication", "conference calls", "video conferences", "online meetings", "face-to-face meetings", "prioritizing requirements", "negotiating priorities", "collaborating with developers", "executing testing of data analytics programs", "computer programming languages (acl", "visual basic", "sql", "python", "advanced microsoft office excel)", "tracking and resolving testing and project sponsor identified program problems", "performing quality review of computer program documentation", "providing project status updates", "serving as a technical resource", "consulting on data analytics matters/issues", "brainstorming", "creation of ad hoc/continuous monitoring routines", "communicating verbally and in written form", "familiarity with institute of internal audit standards", "executing operational audit testing", "validating and resolving audit findings", "executing production data analytic programs", "resolving exceptions", "drafting final memos and reports", "maintaining confidentiality", "working independently", "working in a team environment."]}, "45e005991797a2a1": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Financial Analyst-Mid (2885)", "company": "SMX", "desc": "The Financial Analyst independently delivers services to clients through the demonstration of deep financial functional knowledge within the context of our organization. They lead and administer the financial management of a TDL(s) under a large contract. They are responsible for all the financial activities in support of that TDL. They are members of the program management team and work with the Sr. Financial Analyst and the Program Manager in meeting the overall contract goals and objectives. They interface with TDL Project Manager, senior technical staff, as well as other functional organizations including Contracts, Subcontracts, Finance, Accounts Receivable, and Procurement. \n  Essential Duties and Responsibilities: \n \n Lead the development of the TDL, or small contract, cost, schedule and funding planning, reporting, monitoring and analysis support to the TDL Project Manager. This includes Work Breakdown Structures (WBS), Basis of Estimates (BOEs) and development of time-phased budgets and schedules. \n Lead TDL Project set up in compliance with contractual terms, conditions and requirements. \n Prepare TDL Project financial Estimates at Complete (EAC) and meet deadlines for submission requirements. \n Identify TDL Project risks and profit improvement opportunities and provide analytical contribution in working financial resolution with PM, Contracts, Procurement and Finance/Accounting. \n Monitor TDL and manpower cost on a weekly basis ensuring that actuals are within budget and charged to the correct job number. Process incorrect cost transfers as required. \n Ensure cost reporting documentation is correct by performing TDL analytical review and arithmetic checks. \n Prepare accurate and complete TDL variance analysis and reporting. \n Monitor TDL funding status (to include subcontractor funding status), providing reliable and timely notification of funding status by line item detail as required. \n Support accounts receivable as required during the billing processing (i.e. Review TDL edit file and ensure cost that will be billed are accurate and allowable against the TDL). \n Perform administrative duties such as TARs/RIPs/PRs/PCRs/Expense Report processing. \n Ability to build relationships across functional teams and internal Business Partners. \n Possession of excellent oral and written communication skills. \n Possession of excellent data management, problem solving and critical thinking skills. \n Possession of excellent organization skills. \n \n Required Skills: \n \n Clearance Requirement: Must be able to obtain a clearance if a program requires it \n Knowledge of all contract types (CP, T&M, FFP). \n Experience and Knowledge with Joint Travel Regulations (JTR) rules and guidelines. \n Experience with Microsoft Office Suite, including Excel, PowerPoint, Word, SharePoint and Teams. \n Experience with Costpoint preferred. \n Collect and analyze data from multiple sources and identify, research and solve financial problems and program risks. \n Manage and direct work assignments of junior staff. Prioritize workload in a fast-paced environment and handle a high volume of work. \n 5 years' experience with project cost control, or financial management and contract interpretation, budget development, including financial data, analysis, and reconciliation of estimations verses actuals or 3 years' experience with related degree. \n BA or BS Degree is desired. \n \n  #LI-REMOTE \n \n \n \n \n \n Our tradition of delivering innovative, technical solutions dates back to 1995, however, you may know us better by one of our legacy company names: Trident Technologies, Smartronix, Datastrong or C2S Consulting Group. With the support of OceanSound Partners, our private equity investment sponsor, we began operating as one business starting in 2019 and became SMX in 2021. We operate in close proximity to our clients around the globe and have core locations in Alabama, California, DC Metro, Florida, Hawaii, Maryland, and Massachusetts. \n  Today, as SMX, we are one team and together empower government and commercial enterprises to become more effective, innovative, and resilient, no matter what challenges they face. \n  SMX is committed to hiring and retaining a diverse workforce. All qualified candidates will receive consideration for employment without regard to disability status, protected veteran status, race, color, age, religion, national origin, citizenship, marital status, sex, sexual orientation, gender identity or expression, pregnancy or genetic information. SMX is an Equal Opportunity/Affirmative Action employer including disability and veterans. \n  Selected applicant will be subject to a background investigation.", "cleaned_desc": " Knowledge of all contract types (CP, T&M, FFP). \n Experience and Knowledge with Joint Travel Regulations (JTR) rules and guidelines. \n Experience with Microsoft Office Suite, including Excel, PowerPoint, Word, SharePoint and Teams. \n Experience with Costpoint preferred. \n Collect and analyze data from multiple sources and identify, research and solve financial problems and program risks. \n Manage and direct work assignments of junior staff. Prioritize workload in a fast-paced environment and handle a high volume of work. \n 5 years' experience with project cost control, or financial management and contract interpretation, budget development, including financial data, analysis, and reconciliation of estimations verses actuals or 3 years' experience with related degree. ", "techs": ["microsoft office suite", "excel", "powerpoint", "word", "sharepoint", "teams", "costpoint"]}, "918512cb5251eb4a": {"terms": ["data analyst"], "salary_min": 83720.0, "salary_max": 136240.0, "title": "Business Analysis Specialist (FDIC specialized, BA COE-Remote)", "company": "TD Bank", "desc": "Business Analysis Specialist (FDIC specialized, BA COE-Remote) \n \n \n \n    419133BR\n    \n \n \n Job Category - Primary \n \n    Business Analysis / Reporting \n    \n \n \n Work Location \n \n    4140 Church Road \n    \n \n \n Employment Type \n \n    Regular \n    \n \n \n City \n \n    Atlanta, Baltimore City, Boston, Burlington, Charlotte, Cherry Hill, Concord, Fairfield, Greenville, Miami, Mount Laurel, New York, Philadelphia, Portland, Providence, TD Footprint, Vienna, Washington, Wilmington\n    \n \n \n Time Type \n \n    Full Time \n    \n \n \n State \n \n    Connecticut, District of Columbia, Delaware, Florida, Georgia, Massachusetts, Maryland, Maine, North Carolina, New Hampshire, New Jersey, New York, Pennsylvania, Rhode Island, South Carolina, Virginia, Vermont, TD Footprint\n    \n \n \n Hours \n \n    40\n    \n \n \n Pay Range \n \n    $83,720 - $136,240 annually \n    \n \n \n Job Searches Match \n \n    Statewide\n    \n \n \n Department Overview \n \n    Plan, manage, lead and oversee the end-to-end delivery of requirements throughout the lifecycle of the project in alignment with the business and/or enterprise needs and strategies. Provide leadership and work collaboratively with stakeholders including business, technology and finance partners to support project benefits and changes to business processes, policies and systems across single or multiple Lines of Business (LoB).\n    \n \n \n Job Details \n \n Depth & Scope: \n \n  Leads Requirements Management / work packages for Tier 2, high risk, strategic and regulatory projects or programs and may lead requirements may lead Requirements Management for Tier 1 projects/programs \n  Expert knowledge of business analysis, project delivery practices and standards across the project life-cycle \n  Gain/acquire advanced understanding of business and user interaction with technology throughout project delivery \n  Works autonomously as the lead business analyst and coaches and guides members within area of expertise \n  Identifies and leads problem resolution for complex requirements related issues at all levels \n  Contributes to the communication and change Management activities across multiple stakeholders \n \n \n \n \n Job Requirements \n \n \n Must be eligible for employment under regulatory standards applicable to the position.  Education & Experience:  \n Undergraduate degree required \n  Business Analysis Accreditation \n  7+ year related business analysis experience required \n \n \n \n \n Qualifications \n \n    Preferences: ECBA, CCBA, CBAP certification and familiarity with FDIC regulations, guidelines, with the ability to drive organizational adherence to FDIC regulations and guidelines.\n    \n \n \n Company Overview \n \n About TD Bank, America's Most Convenient Bank\u00ae  \n TD Bank, America's Most Convenient Bank, is one of the 10 largest banks in the U.S., providing over 9.8 million customers with a full range of retail, small business and commercial banking products and services at more than 1,100 convenient locations throughout the Northeast, Mid-Atlantic, Metro D.C., the Carolinas and Florida. In addition, TD Auto Finance, a division of TD Bank, N.A., offers vehicle financing and dealer commercial services. TD Bank and its subsidiaries also offer customized private banking and wealth management services through TD Wealth\u00ae. TD Bank is headquartered in Cherry Hill, N.J. \n \n We offer a competitive salary and benefit program, including: comprehensive, affordable health care through medical, dental, and vision coverage; financial security with life and disability insurance; opportunities to save using health savings and flexible spending accounts; retirement benefits to help prepare for the future; paid time off and work/life benefits to maintain a good balance. \n \n \n \n Inclusiveness \n \n At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live in and serve, and creating an environment where every employee has the opportunity to reach their potential. \n  If you are a candidate with a disability and need an accommodation to complete the application process, email the TD Bank US Workplace Accommodations Program at USWAPTDO@td.com . Include your full name, best way to reach you, and the accommodation needed to assist you with the application process. \n  EOE/Minorities/Females/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity. \n \n \n \n Business Line \n \n    TD Bank AMCB\n    \n \n \n Job Category(s) \n \n    Business Analysis / Reporting \n    \n \n \n Country \n \n    US TD Footprint \n    \n \n \n State (Primary) \n \n    New Jersey \n    \n \n \n City (Primary) \n \n    Mount Laurel \n    \n \n \n State #2 \n \n    New York \n    \n \n \n City #2 \n \n    New York \n    \n \n \n State #3 \n \n    Florida \n    \n \n \n City #3 \n \n    Miami \n    \n \n \n State #4 \n \n    Massachusetts \n    \n \n \n City #4 \n \n    Boston \n    \n \n \n State #5 \n \n    Pennsylvania \n    \n \n \n City #5 \n \n    Philadelphia \n    \n \n \n State #6 \n \n    South Carolina \n    \n \n \n City #6 \n \n    Greenville \n    \n \n \n State #7 \n \n    Connecticut \n    \n \n \n City #7 \n \n    Fairfield \n    \n \n \n State #8 \n \n    New Hampshire \n    \n \n \n City #8 \n \n    Concord \n    \n \n \n State #9 \n \n    Maine \n    \n \n \n City #9 \n \n    Portland \n    \n \n \n State #10 \n \n    Vermont \n    \n \n \n City #10 \n \n    Burlington \n    \n \n \n State #11 \n \n    Virginia \n    \n \n \n City#11 \n \n    Vienna \n    \n \n \n State #12 \n \n    Maryland \n    \n \n \n City #12 \n \n    Baltimore City \n    \n \n \n State #13 \n \n    Delaware \n    \n \n \n City #13 \n \n    Wilmington \n    \n \n \n State #14 \n \n    Rhode Island \n    \n \n \n City #14 \n \n    Providence \n    \n \n \n State #15 \n \n    District of Columbia \n    \n \n \n City #15 \n \n    Washington \n    \n \n \n State #16 \n \n    North Carolina \n    \n \n \n City #16 \n \n    Charlotte \n    \n \n \n State #17 \n \n    Georgia \n    \n \n \n City #17 \n \n    Atlanta \n    \n \n \n Job Expires \n \n    11-Oct-2023", "cleaned_desc": "", "techs": ""}, "e31fd669a0e422af": {"terms": ["data analyst"], "salary_min": 83720.0, "salary_max": 136240.0, "title": "Business Analysis Specialist (AML specialized, BA COE-Remote)", "company": "TD Bank", "desc": "Business Analysis Specialist (AML specialized, BA COE-Remote) \n \n \n \n    419135BR\n    \n \n \n Job Category - Primary \n \n    Business Analysis / Reporting \n    \n \n \n Work Location \n \n    4140 Church Road \n    \n \n \n Employment Type \n \n    Regular \n    \n \n \n City \n \n    Atlanta, Baltimore City, Boston, Burlington, Charlotte, Cherry Hill, Concord, Fairfield, Greenville, Miami, Mount Laurel, New York, Philadelphia, Portland, Providence, TD Footprint, Vienna, Washington, Wilmington\n    \n \n \n Time Type \n \n    Full Time \n    \n \n \n State \n \n    Connecticut, District of Columbia, Delaware, Florida, Georgia, Massachusetts, Maryland, Maine, North Carolina, New Hampshire, New Jersey, New York, Pennsylvania, Rhode Island, South Carolina, Virginia, Vermont, TD Footprint\n    \n \n \n Hours \n \n    40\n    \n \n \n Pay Range \n \n    $83,720 - $136,240 annually \n    \n \n \n Job Searches Match \n \n    Statewide\n    \n \n \n Department Overview \n \n    Plan, manage, lead and oversee the end-to-end delivery of requirements throughout the lifecycle of the project in alignment with the business and/or enterprise needs and strategies. Provide leadership and work collaboratively with stakeholders including business, technology and finance partners to support project benefits and changes to business processes, policies and systems across single or multiple Lines of Business (LoB).\n    \n \n \n Job Details \n \n Depth & Scope: \n \n  Leads Requirements Management / work packages for Tier 2, high risk, strategic and regulatory projects or programs and may lead requirements may lead Requirements Management for Tier 1 projects/programs \n  Expert knowledge of business analysis, project delivery practices and standards across the project life-cycle \n  Gain/acquire advanced understanding of business and user interaction with technology throughout project delivery \n  Works autonomously as the lead business analyst and coaches and guides members within area of expertise \n  Identifies and leads problem resolution for complex requirements related issues at all levels \n  Contributes to the communication and change Management activities across multiple stakeholders \n \n \n \n \n Job Requirements \n \n \n Must be eligible for employment under regulatory standards applicable to the position.  Education & Experience:  \n Undergraduate degree required \n  Business Analysis Accreditation \n  7+ year related business analysis experience required \n \n \n \n \n Qualifications \n \n    Preferences: ECBA, CCBA or CBAP Certification\n    \n \n \n Company Overview \n \n About TD Bank, America's Most Convenient Bank\u00ae  \n TD Bank, America's Most Convenient Bank, is one of the 10 largest banks in the U.S., providing over 9.8 million customers with a full range of retail, small business and commercial banking products and services at more than 1,100 convenient locations throughout the Northeast, Mid-Atlantic, Metro D.C., the Carolinas and Florida. In addition, TD Auto Finance, a division of TD Bank, N.A., offers vehicle financing and dealer commercial services. TD Bank and its subsidiaries also offer customized private banking and wealth management services through TD Wealth\u00ae. TD Bank is headquartered in Cherry Hill, N.J. \n \n We offer a competitive salary and benefit program, including: comprehensive, affordable health care through medical, dental, and vision coverage; financial security with life and disability insurance; opportunities to save using health savings and flexible spending accounts; retirement benefits to help prepare for the future; paid time off and work/life benefits to maintain a good balance. \n \n \n \n Inclusiveness \n \n At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live in and serve, and creating an environment where every employee has the opportunity to reach their potential. \n  If you are a candidate with a disability and need an accommodation to complete the application process, email the TD Bank US Workplace Accommodations Program at USWAPTDO@td.com . Include your full name, best way to reach you, and the accommodation needed to assist you with the application process. \n  EOE/Minorities/Females/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity. \n \n \n \n Business Line \n \n    TD Bank AMCB\n    \n \n \n Job Category(s) \n \n    Business Analysis / Reporting \n    \n \n \n Country \n \n    US TD Footprint \n    \n \n \n State (Primary) \n \n    New Jersey \n    \n \n \n City (Primary) \n \n    Mount Laurel \n    \n \n \n State #2 \n \n    New York \n    \n \n \n City #2 \n \n    New York \n    \n \n \n State #3 \n \n    Florida \n    \n \n \n City #3 \n \n    Miami \n    \n \n \n State #4 \n \n    Massachusetts \n    \n \n \n City #4 \n \n    Boston \n    \n \n \n State #5 \n \n    Pennsylvania \n    \n \n \n City #5 \n \n    Philadelphia \n    \n \n \n State #6 \n \n    South Carolina \n    \n \n \n City #6 \n \n    Greenville \n    \n \n \n State #7 \n \n    Connecticut \n    \n \n \n City #7 \n \n    Fairfield \n    \n \n \n State #8 \n \n    New Hampshire \n    \n \n \n City #8 \n \n    Concord \n    \n \n \n State #9 \n \n    Maine \n    \n \n \n City #9 \n \n    Portland \n    \n \n \n State #10 \n \n    Vermont \n    \n \n \n City #10 \n \n    Burlington \n    \n \n \n State #11 \n \n    Virginia \n    \n \n \n City#11 \n \n    Vienna \n    \n \n \n State #12 \n \n    Maryland \n    \n \n \n City #12 \n \n    Baltimore City \n    \n \n \n State #13 \n \n    Delaware \n    \n \n \n City #13 \n \n    Wilmington \n    \n \n \n State #14 \n \n    Rhode Island \n    \n \n \n City #14 \n \n    Providence \n    \n \n \n State #15 \n \n    District of Columbia \n    \n \n \n City #15 \n \n    Washington \n    \n \n \n State #16 \n \n    North Carolina \n    \n \n \n City #16 \n \n    Charlotte \n    \n \n \n State #17 \n \n    Georgia \n    \n \n \n City #17 \n \n    Atlanta \n    \n \n \n Job Expires \n \n    11-Oct-2023", "cleaned_desc": "", "techs": ""}, "3e06a47fd663e45d": {"terms": ["data analyst"], "salary_min": 85676.45, "salary_max": 108485.484, "title": "Senior Business Analyst - Remote", "company": "The Infosoft Group", "desc": "Senior Business Analyst - Remote \n      \n \n \n     Org Structure : Job Posting Location Elk Grove Village, IL - 700 Busse Rd \n     \n \n \n \n \n \n        Category\n        \n \n        Operations \n        \n \n        Type\n        \n \n        Regular Full-Time \n        \n \n \n \n \n \n Job Description \n   \n \n \n First American Bank was founded in Chicago, and over the years has expanded throughout Wisconsin and Florida. As the largest privately held bank in Illinois, we now have over 60 locations and assets of $5+ billion. We are a community bank at heart with international expertise, traditional values, and a forward-looking philosophy. Our employees have the experience and vision to meet the needs of savers, borrowers, and businesses in the 21st century. First American Bank can offer employees a level of visibility, career growth, and stability that is difficult to find in many larger corporations. \n   \n This position is responsible for supporting process improvements for departments within First American Bank to optimize efficiencies, increase productivity, and reduce risks and costs. This individual will act as the subject matter expert for improving department processes and independently implement changes. \n   \n Duties & Responsibilities \n  Develop, implement, analyze, and update processes and procedures for a variety of First American Bank departments in accordance with regulations.  \n \n Ensure compliance by developing and delivering training sessions and materials to efficiently and comprehensively educate both new and existing employees to mitigate risk for the bank, maximize departmental efficiency, and reduce costs. \n   \n Analyze, implement, update improvements of existing processes and procedures to maximize departmental efficiencies, including building and reviewing process diagrams and requesting system program changes. \n   \n Acquire and maintain industry awareness within departments, knowledge of regulatory expectations, and legal expertise to interpret rules and guidelines. Serve as the Subject Matter Expert (SME) for changes to regulations, identifying the impact of the regulations on the bank and implement procedures to adhere to changes. \n   \n Lead various operational functions with minimal oversight. Develop and adapt operational functions to support projects unique to the departments' needs. \n   \n Prepare careful data review and testing, which involve data query and report generation prior to enhancement implementations. \n   \n Identify opportunities for operational efficiency and recommend improvements to streamline processes for a variety of departments. \n   \n Serve as the representative for the implementation of new processes and procedures that are relevant to the division. \n   \n Coordinate with the department manager, outside vendors, other First American Bank departments, and others within the department to ensure that all activities and projects are completed efficiently. \n   \n Conduct and complete additional assignments/projects as designated by management. \n   \n Qualifications \n  High school diploma or equivalent required. \n   \n Bachelor's Degree preferred. \n   \n Minimum three years of experience in process improvement and project coordination/management. \n   \n Experience in road mapping, building and reviewing process diagrams, and creating procedures required. \n   \n Strong organizational skills and a desire to work in a fast-paced, ever-changing environment are essential to succeed. \n   \n Demonstrate initiative, be resourceful and insightful, ability to work independently within a deadline, and ultimately be accountable for each project. \n   \n Must be professional, comfortable speaking with external and internal contacts with a demonstrated ability to tailor the message appropriately to the audience and situation effectively. \n   \n Demonstrated ability to convey thoughts and ideas effectively and succinctly via written formats, including emails, letters, and electronic platforms. Maintain professional standards relating to spelling and grammar. \n   \n Maintain credibility through professional demeanor, appearance, and presence by modeling standards appropriate to our environment and industry. \n   \n Maintain good working relationships with internal partners by exhibiting exemplary interpersonal skills, adopting a constructive, solutions-focused approach. \n   \n Use sound professional judgment to balance the interests of the organization and customer, understanding and using available resources to mitigate risks. \n   \n Minimum of five years experience with Relius, PensionPro, FIS AddVantage and Retirement Plan Services is required. \n   \n Must possess a high proficiency of reporting software, word processing and spreadsheet programs, and be quick to learn new programs as introduced. \n   \n Proficiency with Microsoft 365 products and applications, including the ability to effectively prepare or review documents, procedures, and reports. \n   \n Demonstrated ability to learn new systems and applications, as well as the ability to understand, adapt and adjust responsibilities/workflows as a result of system upgrades. \n   \n Aptitude for database management and query analysis is required. Prior design experience with MS Access and Power BI is preferred or candidate must be willing to be trained and become proficient. \n   \n Occasional travel to other First American Bank locations, Bank functions and training facilities may be required. \n   \n Typical hours are Monday through Friday 8:00 a.m. to 5:00 p.m. Additional hours may be required depending upon business need. \n \n \n \n \n \n  First American Bank is an Equal Opportunity Employer (Minorities/Females/Disabled/Veterans).\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   First American Bank \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   High School or Equivalent\n   \n \n \n \n   Required Experience\n   \n \n   3+ years", "cleaned_desc": " Qualifications \n  High school diploma or equivalent required. \n   \n Bachelor's Degree preferred. \n   \n Minimum three years of experience in process improvement and project coordination/management. \n   \n Experience in road mapping, building and reviewing process diagrams, and creating procedures required. \n   \n Strong organizational skills and a desire to work in a fast-paced, ever-changing environment are essential to succeed. \n   \n Demonstrate initiative, be resourceful and insightful, ability to work independently within a deadline, and ultimately be accountable for each project. \n   \n Must be professional, comfortable speaking with external and internal contacts with a demonstrated ability to tailor the message appropriately to the audience and situation effectively. \n   \n Demonstrated ability to convey thoughts and ideas effectively and succinctly via written formats, including emails, letters, and electronic platforms. Maintain professional standards relating to spelling and grammar. \n   \n Maintain credibility through professional demeanor, appearance, and presence by modeling standards appropriate to our environment and industry. \n   \n Maintain good working relationships with internal partners by exhibiting exemplary interpersonal skills, adopting a constructive, solutions-focused approach. \n   \n Use sound professional judgment to balance the interests of the organization and customer, understanding and using available resources to mitigate risks. \n   \n Minimum of five years experience with Relius, PensionPro, FIS AddVantage and Retirement Plan Services is required. \n   \n Must possess a high proficiency of reporting software, word processing and spreadsheet programs, and be quick to learn new programs as introduced. \n   \n Proficiency with Microsoft 365 products and applications, including the ability to effectively prepare or review documents, procedures, and reports. ", "techs": ["relius", "pensionpro", "fis addvantage", "retirement plan services", "reporting software", "word processing programs", "spreadsheet programs", "microsoft 365 products"]}, "7637d7c15ede4c9f": {"terms": ["data analyst"], "salary_min": 34.09, "salary_max": 34.09, "title": "Business Analyst", "company": "TotalMed", "desc": "Position Title \u2013 Business Analyst Address \u2013 Remote FL Pay \u2013 34.09/HR Start date \u2013 ASAP Hours \u2013 8a-5p Vaccine Requirement \u2013 not required \n Required Skills & Education: \u2022\u2003\u20032+ years of business process or data analysis experience, in healthcare. \u2022\u2003\u2003Jira Experience required \u2022\u2003\u2003Bachelor\u2019s degree required \n Preferred Qualifications: \n \u2022\u2003\u2003Project management experience preferred. \u2022\u2003\u2003SQL Experience preferred \u2013 should be able to also help with testing \n Position Purpose: Perform various analysis and interpretation to link business needs and objectives for assigned function \n Responsibilities: \u2022\u2003\u2003Perform various analysis and interpretation to link business needs and objective for assigned function \u2022\u2003\u2003Run the business, and take away some of the day-to-day tasks from the project manager \u2022\u2003\u2003Proofing documents and ID Cards \u2022\u2003\u2003Following up on attestations, any data changes on the ID Cards, they will be working with leadership. \u2022\u2003\u2003Regression testing / scenario testing \u2022\u2003\u2003Test plans, created test plans, testing scenarios \u2022\u2003\u200316 million members with new cards, due to volume therefore there is an increase for headcount \n Job Type: Contract \n Salary: $34.09 per hour \n Application Question(s): \n \n How many years of business process or data analysis in a healthcare setting do you have? \n Do you have JIRA experience? For how long? \n What is your highest educational background? \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "868e37c7c8bd5a8d": {"terms": ["data analyst"], "salary_min": 33.1, "salary_max": 33.1, "title": "Business Analyst I Remote", "company": "Kaztronix", "desc": "Business Analyst I \n \n \n Duties: \n  An employer is looking for a Business Analyst to join their IT team in Ridgefield, CT. This person will be responsible for the digital transformation initiative in IT, delivering updates and communication for end-users throughout the organization. They will receive content from IT subject matter experts and will be responsible for making them end-user friendly and easy to understand material (email communication, user guidelines, instruction/infographics, other visuals, such as videos, tailored trainings). This person will also be tracking end user adoption of the distributed material, tracking how they have affected the end-users activity. Specifically, the Business Analyst will be responsible for developing training curricula for end user groups, prepare/gather material, and deliver the training in person or virtually. Additionally, the Business Analyst shoudl be familiar with UX methodologies, to be able to run UX activities, such as survey, user research, A/B testing, focus group, among others, with the user population. \n Their day will consist of communication/marketing/training with end users, as well as attending/hosting digital learning sessions, making web pages updates, analyzing metrics, organizing and conducting trainings and events on-site, and other projects as assigned. \n \n \n Skills: \n  Must-haves \n 1-2+ years experience in marketing/communications, learning experience desgin, or UX \n Understanding of IT basic knowledge, in particular knowledge of how every day technology works (main hardware and software tools, i.e. Office365 suite) \n Ability to create effective and catchy communication, training, content, events, and visual material pertaining to IT \n Strong communication skills, both written & verbal \n Experience with Office 365, Adobe Suite (Campaign, InDesign), Microsoft Teams \n Plusses \n Former role in marketing/communication in IT company or field \n UX and User Research knowledge \n Learning Experience Design (training, curricula design, delivery of training) \n Data Analytics (i.e. marketing/communication KPI tracking and dashboards)", "cleaned_desc": " Ability to create effective and catchy communication, training, content, events, and visual material pertaining to IT \n Strong communication skills, both written & verbal \n Experience with Office 365, Adobe Suite (Campaign, InDesign), Microsoft Teams ", "techs": ["ability to create effective and catchy communication", "training", "content", "events", "and visual material pertaining to it", "office 365", "adobe suite (campaign", "indesign)", "microsoft teams"]}, "887651650a40327f": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 106908.11, "salary_max": 135369.48, "title": "Data Engineer", "company": "Blackwell Security, Inc.", "desc": "Blackwell Security Inc. is a start-up backed by venture capital, focused on bridging the technology gap in healthcare. Our purpose-built ecosystem provides comprehensive cybersecurity managed services for life sciences and healthcare. We are building a customizable product that ensures health systems have access to a suite of security solutions, with built-in visualization and optimization to ensure the safety of patient information. \n  As we continue to build out our core team, we are adding a Data Engineer to our Engineering Team. You will be working cross-functionally with business domain experts, analytics, and engineering teams to design and implement our Data models. You will design, implement, and scale data pipelines that transform billions of records into action and insight. \n  This is a unique opportunity to jump into an early-stage start-up at a pivotal time and make a meaningful impact. If you thrive in a small, growing environment and love the energy of start-ups, this is the role for you! \n  While our headquarters are in Detroit, Michigan, this is a remote role but ideally a candidate would live in Detroit or Minneapolis, location of our core Engineering Team. This role is not eligible for visa sponsorship. \n   What you will do in the Data Engineer role: \n \n Collaborate with engineering to build and maintain an enterprise data ecosystem including ingestion, storage, organization and interface. \n Analyze the business and technical requirements for data systems and applications; Coordinate the integration of IT policies, procedures and development practices. \n Translate business requirements into data models that are easy to understand and used by different disciplines across the company. \n Design, implement, build/enhance pipelines that deliver data with measurable quality under the SLA. \n Partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service. \n Champion the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements. \n Own and document foundational company metrics and benchmarks with clear definition and data lineage. \n Identify, document and promote best practices. \n Design and architect data systems, focusing not only on performance and scalability, but also on crafting a beautiful user experience. \n Define/Implement data visualizations & UX for external/internal customers. \n Taking a thoughtful approach to decision making; balance speed and quality, with a focus on tangible results. \n Explore Blackwell\u2019s data to discover trends and opportunities, identify what questions we should be asking of our data. \n Analyze & evaluate transactional system data for transformation and use in reporting, analytics, and AI/ML. \n Evaluate and establish early strategies and usage of AI (machine learning, generative AI, etc.). \n \n Qualities and skills for success in the Data Engineer role: \n \n Bachelor's degree in Computer Science, Engineering, or related technical or business field. \n Attention to detail, and Agile development experience. \n Experience with Python and AWS services. \n Experience with various data storage systems, RDBMS, Document/NoSQL DBs, etc. \n Experience implementing data pipelines via methods such as ETL, ELT, EL/TL, DaaS, Data Lake or ODS. \n Experience experimenting with and applying AI (machine learning, generative AI, etc.) in an enterprise environment. \n Experience working with multi-customer multi-tenant environments preferred. Experience with cybersecurity data is not required but is a plus. \n Adaptable and focused on solutions. \n \n Equal Employment Opportunity \n  We\u2019re proud to be an equal opportunity employer and welcome our employee\u2019s differences, regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or Veteran status. Difference makes us better. Join us.", "cleaned_desc": " Collaborate with engineering to build and maintain an enterprise data ecosystem including ingestion, storage, organization and interface. \n Analyze the business and technical requirements for data systems and applications; Coordinate the integration of IT policies, procedures and development practices. \n Translate business requirements into data models that are easy to understand and used by different disciplines across the company. \n Design, implement, build/enhance pipelines that deliver data with measurable quality under the SLA. \n Partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service. \n Champion the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements.   Analyze & evaluate transactional system data for transformation and use in reporting, analytics, and AI/ML. \n Evaluate and establish early strategies and usage of AI (machine learning, generative AI, etc.). \n \n Qualities and skills for success in the Data Engineer role: \n \n Bachelor's degree in Computer Science, Engineering, or related technical or business field.   Attention to detail, and Agile development experience. \n Experience with Python and AWS services. \n Experience with various data storage systems, RDBMS, Document/NoSQL DBs, etc. \n Experience implementing data pipelines via methods such as ETL, ELT, EL/TL, DaaS, Data Lake or ODS. \n Experience experimenting with and applying AI (machine learning, generative AI, etc.) in an enterprise environment. \n Experience working with multi-customer multi-tenant environments preferred. Experience with cybersecurity data is not required but is a plus. ", "techs": ["collaborate with engineering to build and maintain an enterprise data ecosystem", "analyze the business and technical requirements for data systems and applications", "coordinate the integration of it policies", "procedures and development practices", "translate business requirements into data models", "design", "implement", "build/enhance pipelines", "partner with business domain experts", "data analysts and engineering teams", "champion the overall strategy for data governance", "security", "privacy", "quality and retention", "analyze & evaluate transactional system data for transformation and use in reporting", "analytics", "and ai/ml", "evaluate and establish early strategies and usage of ai", "bachelor's degree in computer science", "engineering", "or related technical or business field", "attention to detail", "agile development experience", "experience with python", "experience with aws services", "experience with various data storage systems", "rdbms", "document/nosql dbs", "etc.", "experience implementing data pipelines via methods such as etl", "elt", "el/tl", "daas", "data lake or ods", "experience experimenting with and applying ai (machine learning", "generative ai", "etc.) in an enterprise environment", "experience working with multi-customer multi-tenant environments preferred", "experience with cybersecurity data is a plus"]}, "9681da3bdbcc588f": {"terms": ["data engineer"], "salary_min": 87000.0, "salary_max": 147000.0, "title": "Data Engineer II, Infrastructure", "company": "Affinity.co", "desc": "USA (Remote)  \n \n \n At the heart of Affinity, you\u2019ll find a number of foundational infrastructure and operational challenges involved in building, running, and evolving our data-driven, processing-intensive product. \n  In this role, you'll join our Infrastructure Engineering team, which is responsible for driving performance, scalability, reliability, and developer efficiency at Affinity. Additionally, we deliver vital DevOps and DataOps services to both the Engineering and Analytics organizations. \n  What you\u2019ll be doing : \n \n Collaborate cross-functionally with go-to-market, analytics, engineering, and product teams \n Develop and maintain frameworks to support an organization\u2019s analytics data demands \n Build and optimize data pipelines to facilitate the extraction of data from multiple sources and load it into data warehouses \n Build complex ETL/ELT jobs to replicate and transform the data to power Internal Analytics reports and dashboards \n Design, implement, and optimize Data warehouses \n Ensure data security standards are applied across the data pipelines \n Provide various teams with access to structured datasets and analytics they will further analyze and derive insights from \n \n We'd love to hear from you if you have: \n \n 3+ years of proven experience as a Data Engineer, DataOps Engineer, or a similar role \n Exceptional SQL skills \n Experience with Relational, Columnar, and NOSQL databases \n Experience with ETL/ELT orchestration tools, such as DBT, Stitch, Fivetran, or Airflow \n Experience creating complex transform jobs to cleanup and aggregate data \n Problem-solving aptitude \n Excellent communication skills \n Experience writing Infrastructure as Code using Terraform, CloudFormation or similar \n \n Nice to have experience: \n \n Experience working with AWS Cloud \n Experience diagnosing and fixing database performance issues \n Experience with BI tools such as Looker or Amplitude \n \n Tech stack \n  Our infrastructure resides on AWS. For our primary relational data storage, we utilize PostgreSQL, and for semi-structured data, we leverage S3 buckets. On the analytics front, we use Aptitude to gather product insights, while AWS Redshift caters to our data warehousing requirements. In terms of infrastructure management, we employ Terraform for Infrastructure as Code (IaC). For our ETL/ELT processes, we've integrated DBT and Stitch \n  How we work: \n  Our culture is a key part of how we operate as well as our hiring process: \n \n We iterate quickly. As such, you must be comfortable embracing ambiguity, be able to cut through it, and deliver incremental value to our customers each sprint \n We are candid, transparent, and speak our minds while simultaneously caring personally with each person we interact with \n We make data driven decisions and make the best decision for the moment based on the information available \n \n Join us in enabling every professional on the planet to succeed by harnessing the power of their relationships. \n \n \n  What you'll enjoy at Affinity: \n \n We live our values as playmakers, obsessed with learning, care personally about our colleagues and clients, are radically open-minded, and take pride in everything we do. \n Health Care coverage and flexible personal & sick days. We want our team to be happy and healthy :) \n We provide an annual budget for you to spend on education and offer a comprehensive L&D program \u2013 after all, one of our core values is that we\u2019re #obsessedwithlearning! \n We support our employee\u2019s overall health and well-being and reimburse monthly for things such as; Transportation, Home Internet, Meals, and Wellness memberships/equipment. \n Virtual team building and socials. Keeping people connected is essential. \n \n Please note that the role compensation details below reflect the base salary only and do not include any variable pay, equity, or benefits. This represents the salary range that Affinity believes, in good faith, at the time of this posting, that it will pay for the posted job. \n  A reasonable estimate of the current range is  $87,000 to $147,000 USD . Within the range, individual pay is determined by factors such as job-related skills, experience, and relevant education or training. \n \n About Affinity \n  We have raised over $120M and are backed by some of Silicon Valley\u2019s best firms, with over 2,700 customers worldwide on our platform. We are proud to have a 4.5 Star Glassdoor rating and recently ranked; Inc.\u2019s Best Workplaces of 2022 and Great Places to Work 2022. Passionate about helping dealmakers in the world\u2019s biggest relationship-driven industries to find, manage, and close the most important deals; our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month.", "cleaned_desc": "USA (Remote)  \n \n \n At the heart of Affinity, you\u2019ll find a number of foundational infrastructure and operational challenges involved in building, running, and evolving our data-driven, processing-intensive product. \n  In this role, you'll join our Infrastructure Engineering team, which is responsible for driving performance, scalability, reliability, and developer efficiency at Affinity. Additionally, we deliver vital DevOps and DataOps services to both the Engineering and Analytics organizations. \n  What you\u2019ll be doing : \n \n Collaborate cross-functionally with go-to-market, analytics, engineering, and product teams \n Develop and maintain frameworks to support an organization\u2019s analytics data demands \n Build and optimize data pipelines to facilitate the extraction of data from multiple sources and load it into data warehouses \n Build complex ETL/ELT jobs to replicate and transform the data to power Internal Analytics reports and dashboards   Design, implement, and optimize Data warehouses \n Ensure data security standards are applied across the data pipelines \n Provide various teams with access to structured datasets and analytics they will further analyze and derive insights from \n \n We'd love to hear from you if you have: \n \n 3+ years of proven experience as a Data Engineer, DataOps Engineer, or a similar role \n Exceptional SQL skills \n Experience with Relational, Columnar, and NOSQL databases \n Experience with ETL/ELT orchestration tools, such as DBT, Stitch, Fivetran, or Airflow \n Experience creating complex transform jobs to cleanup and aggregate data   Problem-solving aptitude \n Excellent communication skills \n Experience writing Infrastructure as Code using Terraform, CloudFormation or similar \n \n Nice to have experience: \n \n Experience working with AWS Cloud \n Experience diagnosing and fixing database performance issues \n Experience with BI tools such as Looker or Amplitude \n \n Tech stack ", "techs": ["dbt", "stitch", "fivetran", "airflow", "terraform", "cloudformation", "aws cloud", "looker", "amplitude"]}, "b53e239895e31bd1": {"terms": ["data engineer"], "salary_min": 86953.56, "salary_max": 110102.59, "title": "Data Engineer", "company": "The Infosoft Group", "desc": "Description\n  \n  This position can be fully remote within our 10 state footprint - Michigan, Indiana, Ohio, Illinois, Wisconsin, Florida, Texas, Kansas, Louisiana or Kentucky. \n  Position Goals: \n  Collaborate with internal staff to create, manage, maintain and develop data warehouse and data mart implementations. \n  Essential Duties and Responsibilities: \n \n \n Expand and optimize the data pipeline framework across multiple applications and systems. \n \n \n Collaborate with the Business Intelligence team and business analysts to review requirements and translate to ETL design and implementation. \n \n \n Design ETL technical approaches and models. \n \n \n Provide support for existing data pipeline framework. \n \n \n Diagnose and troubleshoot problems with existing data structures, ETL processes and logic, etc. \n \n \n Participate in setting organizational data management and architecture strategy. \n \n \n Participate in cross-departmental projects. \n \n \n Determine, develop, document and maintain standards and procedures. \n \n \n Track and evaluate new standards, technologies and trends in data design, analysis and strategy. \n \n \n Participate in the selection, design and implementation of new analytical systems. \n \n \n Manage projects and workload according to FMB standard methodology.  \n \n \n Position Requirements : \n  Education - High school diploma or equivalent (GED). \n  Experience - A minimum of three (3) years of data management experience. \n  Other - A minimum of one (1) year of data warehouse development and design experience. \n   \n Preferred Requirements : \n  Bachelor's degree in computer science, business intelligence, data management or related field of study. \n  Over three (3) years of data warehouse development and design experience. \n  Warehouse/Management Certifications. \n   \n Key words: Snowflake; Airflow; Python \n  Qualifications\n  \n \n  Education \n \n \n   GED (required)\n    High School of General Studies (required)\n  \n \n \n  Experience \n \n \n   A minimum of three (3) years of data management experience. (required)\n    A minimum of one (1) year of data warehouse development and design experience. (required)\n  \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities \n \n \n \n  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c) \n \n  First Merchants Bank is an Equal Opportunity Employer and E-Verify participant (M/F/D/V).\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   First Merchants Bank \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   High School or Equivalent\n   \n \n \n \n   Required Experience\n   \n \n   3 years", "cleaned_desc": "Description\n  \n  This position can be fully remote within our 10 state footprint - Michigan, Indiana, Ohio, Illinois, Wisconsin, Florida, Texas, Kansas, Louisiana or Kentucky. \n  Position Goals: \n  Collaborate with internal staff to create, manage, maintain and develop data warehouse and data mart implementations. \n  Essential Duties and Responsibilities: \n \n \n Expand and optimize the data pipeline framework across multiple applications and systems. \n \n \n Collaborate with the Business Intelligence team and business analysts to review requirements and translate to ETL design and implementation. \n \n \n Design ETL technical approaches and models. \n \n \n Provide support for existing data pipeline framework. \n \n \n Diagnose and troubleshoot problems with existing data structures, ETL processes and logic, etc. \n \n \n Participate in setting organizational data management and architecture strategy.   \n \n Participate in cross-departmental projects. \n \n \n Determine, develop, document and maintain standards and procedures. \n \n \n Track and evaluate new standards, technologies and trends in data design, analysis and strategy. \n \n \n Participate in the selection, design and implementation of new analytical systems. \n \n \n Manage projects and workload according to FMB standard methodology.  \n \n \n Position Requirements : \n  Education - High school diploma or equivalent (GED). \n  Experience - A minimum of three (3) years of data management experience. \n  Other - A minimum of one (1) year of data warehouse development and design experience. \n   \n Preferred Requirements : \n  Bachelor's degree in computer science, business intelligence, data management or related field of study. ", "techs": ["data warehouse", "data mart", "etl design and implementation", "etl technical approaches and models", "data pipeline framework", "data structures", "etl processes and logic", "data management and architecture strategy", "cross-departmental projects", "standards and procedures", "new standards", "technologies and trends in data design", "analysis and strategy", "analytical systems", "fmb standard methodology"]}, "6b550a60e86147bc": {"terms": ["data engineer"], "salary_min": 110000.0, "salary_max": 145000.0, "title": "Data Analytics Engineer", "company": "COMPASS Pathways", "desc": "Company introduction : \n  COMPASS Pathways plc (Nasdaq: CMPS) is a biotechnology company dedicated to accelerating patient access to evidence-based innovation in mental health. Our focus is on improving the lives of those who are suffering with mental health challenges and who are not helped by current treatments. We are pioneering the development of a new model of psilocybin treatment, in which our proprietary formulation of synthetic psilocybin, COMP360, is administered in conjunction with psychological support. \n  Our vision is a world of mental wellbeing. COMPASS Pathways. \n \n  Role introduction: \n  As a Data Analytics Engineer at COMPASS Pathways, you will be responsible for maintaining and developing the data analytics platform and working cross-functionally with multiple departments to drive usage, dashboard creation and company-wide adoption. Our analytics platform serves various stakeholders, including clinical site coordinators, therapists, auditors, business partners as well as internal compass teams. \n  This role is perfect for someone who is proficient in gathering requirements, working with product and engineering teams, SQL as well as being eager to learn how each department in a biotech company conducts their business processes. We're looking for someone enthusiastic about data and the insights and stories provided. As a Data Analytics Engineer, you will get the chance to work with many varied teams at COMPASS, making a direct impact on how we achieve our mission to transform mental health care. \n  Location:  The role can be based in the United Kingdom or the United States (East Coast). \n  Reports to:  Vice President, Engineering. \n \n \n  Role and responsibilities  (include but are not limited to): \n \n Collaborate with stakeholders to understand every aspect of their processes, discern the data they possess or need, and propose comprehensive data analytics solutions that meet their requirements \n Liaise with engineers to ensure that the necessary data for analysis is efficiently delivered to the data warehouse \n Cleanse and transform ingested source data using DBT (data build tool), while also establishing clear data quality acceptance metrics \n Construct models, marts, aggregations, and cubes that will form the foundation of reporting dashboards \n Visualize data by leveraging our BI tool, Metabase \n Oversee dashboard management, regularly conduct audits on existing dashboards and assess their usage \n Sustain our DBT model repository, author and maintain models, macros, tests, documentation, and snapshots \n Ensure that our data privacy and access controls are in strict compliance with company policies. \n Communicate requests to Product Managers to align on priority builds \n \n Candidate Profile: \n \n Prior experience in a Data Analyst role or similar capacity \n Ability to understand the needs of non-technical stakeholders and transform these needs to measurable analytics and reporting \n Exceptional communication skills with team members from varied background and technical abilities \n Background in the pharmaceutical, clinical trial and/or health tech industry is highly beneficial \n Capable of explaining complex data insights in a lucid and concise manner to senior level stakeholders \n Self-motivated and autonomous, with the aptitude to flourish in a dynamic environment, managing multiple projects concurrently \n Strong design skills when presenting data to technical and non-technical audiences \u2013 data should be clear and easy to explain/understand \n Proven experience in data pre-processing, cleaning, and analysis \n Mastery of SQL, preferably PostgreSQL \n Proficiency with Git command-line tools for version control, and the capacity to operate comfortably within Unix command-line interfaces \n Experience with data modelling, testing, and transformations using DBT \n Basic familiarity with the Python programming language \n Knowledge of the pull request review process in GitHub \n Prior exposure to Meltano and Airbyte for data analysis is a plus \n Experience with data visualization tools, particularly Tableau, Looker, and Metabase \n Aligned with our company mission and values: Compassionate, Bold, Rigorous, and Inclusive \n \n \n \n  Please note that the base salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies, and work location. \n  Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work and any role at COMPASS, regardless of the location, is eligible for additional discretionary bonuses and equity. \n \n  \u3010For NYC\u3011Compensation Description (annually): \n \n    $110,000\u2014$145,000 USD\n   \n \n \n  Equal opportunities: \n  UK applicants \n  We are proud of our commitment to diversity and equality (pursuant to the Equality Act 2010). We do not discriminate based upon race, religion or belief, colour, nationality, ethnic or national origin, gender, pregnancy or maternity, marital or civil partner status, sexual orientation, gender reassignment, age or disability. \n  US applicants \n  COMPASS Pathways is proud to be an equal opportunity employer. All employment decisions are based on business needs, job requirements, and individual qualifications, without regard to race, religion, color, national origin, sex (including pregnancy, childbirth, and related medical conditions), ethnicity, age, disability, sexual orientation, gender identity, gender expression, military service, genetic information, familial or marital status, or any other status, category, or characteristic protected by applicable law.", "cleaned_desc": "  Role and responsibilities  (include but are not limited to): \n \n Collaborate with stakeholders to understand every aspect of their processes, discern the data they possess or need, and propose comprehensive data analytics solutions that meet their requirements \n Liaise with engineers to ensure that the necessary data for analysis is efficiently delivered to the data warehouse \n Cleanse and transform ingested source data using DBT (data build tool), while also establishing clear data quality acceptance metrics \n Construct models, marts, aggregations, and cubes that will form the foundation of reporting dashboards \n Visualize data by leveraging our BI tool, Metabase \n Oversee dashboard management, regularly conduct audits on existing dashboards and assess their usage \n Sustain our DBT model repository, author and maintain models, macros, tests, documentation, and snapshots \n Ensure that our data privacy and access controls are in strict compliance with company policies. \n Communicate requests to Product Managers to align on priority builds   \n Candidate Profile: \n \n Prior experience in a Data Analyst role or similar capacity \n Ability to understand the needs of non-technical stakeholders and transform these needs to measurable analytics and reporting \n Exceptional communication skills with team members from varied background and technical abilities \n Background in the pharmaceutical, clinical trial and/or health tech industry is highly beneficial \n Capable of explaining complex data insights in a lucid and concise manner to senior level stakeholders \n Self-motivated and autonomous, with the aptitude to flourish in a dynamic environment, managing multiple projects concurrently \n Strong design skills when presenting data to technical and non-technical audiences \u2013 data should be clear and easy to explain/understand \n Proven experience in data pre-processing, cleaning, and analysis   Mastery of SQL, preferably PostgreSQL \n Proficiency with Git command-line tools for version control, and the capacity to operate comfortably within Unix command-line interfaces \n Experience with data modelling, testing, and transformations using DBT \n Basic familiarity with the Python programming language \n Knowledge of the pull request review process in GitHub \n Prior exposure to Meltano and Airbyte for data analysis is a plus \n Experience with data visualization tools, particularly Tableau, Looker, and Metabase \n Aligned with our company mission and values: Compassionate, Bold, Rigorous, and Inclusive \n \n \n ", "techs": ["dbt", "metabase", "postgresql", "git", "unix command-line interfaces", "tableau", "looker", "meltano", "airbyte"]}, "47dd413a1d1e1cf7": {"terms": ["data engineer"], "salary_min": 119850.57, "salary_max": 151757.53, "title": "Sr. Data Integration Engineer", "company": "Bamboo Health", "desc": "Bamboo Health is a leader in cloud-based care coordination software and analytics solutions focused on patients with complex needs, including those suffering from physical health and mental health issues and substance use disorders. We are driven by our mission of enabling better care for patients across the continuum. Our software solutions help healthcare professionals collaborate on shared patients across the spectrum of care. Join us in improving healthcare for all! \n  Summary: \n  We are actively hiring a full-time Sr. Data Integration Engineer to focus on supporting and extending our data platform. Bamboo Health receives HL7 data from hospitals, EHRs and HIEs around the country and this role will be responsible for integrating new HL7 EHR senders to the data pipeline using in-house tools, scripts, and custom applications. The ideal candidate will work well in a team, have a data-first mentality, and thrive in customer-facing projects. \n  What You Will Do: \n \n Partner with Operations to ensure on-boarding HL7 integrations meet target deadlines through task resolution in a timely and organized manner \n \n \n Partner with broader Platform Engineering team on cross-functional initiatives focused on infrastructure scalability and stability. \n \n \n Partner with Software Engineers focused on improving our data pipeline \n \n \n Design and execute HL7 test plans for on-boarding new integrations \n \n \n Build a standard integration process to receive data and post events to new EHR systems \n \n \n Work with ADT senders to resolve customer issues and maintain high quality interfaces \n \n \n On-board and track standard HL7 integrations \n \n \n Triage customer issues related to HL7 integrations \n \n \n \n  What Success Looks Like\u2026 \n  In 3 months\u2026 \n  Execute: \n \n Develop solid understanding of Bamboo Health onboarding process for Technical Implementation Services \n \n \n Contribute to HL7 data validation, mapping, and testing processes \n \n \n Develop an understanding of our HL7 data pipeline \n \n \n Build relationships across the broader Product Platform organization \n \n \n \n  In 6 months\u2026 Manage: \n \n Work with our Product, Operations and Network Operations Center teams to drive streamlined data processing and continuous improvement initiatives. \n \n \n Contribute to the development and reporting of data quality metrics \n \n \n \n  In 12 months\u2026 Scale: \n \n Develop a comprehensive knowledge of our data ingestion architecture \n \n \n Manage complex customer integrations with a heavy focus on service and quality outcomes \n \n \n \n  What You Need: \n \n 5+ years professional experience in or around software development \n \n \n Experience in or around the Healthcare domain \n \n \n Experience in at least one modern language such as Java, Python, JavaScript \n \n \n Proficient in SQL \n \n \n Willingness to learn healthcare data exchange formats \n \n \n Ability to self-start project tasks and communicate progress clearly \n \n \n Ability to work autonomously on multiple concurrent projects and prioritize appropriately \n \n \n Experience organizing and delivering on several lines of work with clear communication on progress \n \n \n Desire to work in a fast-paced collaborative environment \n \n \n A work environment that is conducive to high quality virtual interactions. This includes but is not limited to being able to work from a quiet space with minimal interruptions or distractions, and a strong internet connection. \n \n \n \n  Helpful/Preferred Experience: \n \n Healthcare data integration tools (Mirth preferred) \n Cloud-native AWS solutions \n SDLC \u2013 Git, pull requests \n Docker & Kubernetes \n Atlassian product suite \n SumoLogic, Prometheus/Grafana, or equivalent \n \n \n \n  What You Get: \n \n Join one of the most innovative healthcare technology companies in the country. \n \n \n Have the autonomy to build something with an enthusiastically supportive team. \n \n \n Learn from working at the highest levels and on the most strategic priorities of the company, including from world class investors and advisors. \n \n \n Receive competitive compensation, including equity, with health, dental, vision and other benefits. \n \n \n \n  Bamboo Health is proud to be an Equal Employment Opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. \n   #LI-Remote", "cleaned_desc": " \n \n Contribute to the development and reporting of data quality metrics \n \n \n \n  In 12 months\u2026 Scale: \n \n Develop a comprehensive knowledge of our data ingestion architecture \n \n \n Manage complex customer integrations with a heavy focus on service and quality outcomes \n \n \n \n  What You Need: \n \n 5+ years professional experience in or around software development \n \n \n Experience in or around the Healthcare domain \n \n \n Experience in at least one modern language such as Java, Python, JavaScript \n   \n Proficient in SQL \n \n \n Willingness to learn healthcare data exchange formats \n \n \n Ability to self-start project tasks and communicate progress clearly \n \n \n Ability to work autonomously on multiple concurrent projects and prioritize appropriately \n \n \n Experience organizing and delivering on several lines of work with clear communication on progress \n \n \n Desire to work in a fast-paced collaborative environment \n \n \n A work environment that is conducive to high quality virtual interactions. This includes but is not limited to being able to work from a quiet space with minimal interruptions or distractions, and a strong internet connection. \n \n \n \n  Helpful/Preferred Experience: \n ", "techs": ["java", "python", "javascript", "sql"]}, "66df262ec807589a": {"terms": ["data engineer"], "salary_min": 12395.0, "salary_max": 12395.0, "title": "Data Engineer, Data Platform (Contract)", "company": "Pagoda", "desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Pagoda Data Platform team is looking for a Data Engineer to build and scale our data infrastructure to empower our core products and product analytics. \n  What You'll Be Doing \n \n Architect and manage data lakes and data marts needed to provide product analytics insights to product teams and executives (BigQuery, DataBricks); \n Create and manage data pipelines for both on-chain (NEAR) and off-chain (OLTP databases, http logs, UI analytics) data; \n Automate data quality monitoring and alerting tools; \n Optimize time to insight and work with Data Scientists to create data marts for various data products; \n Creating data extraction tools using Python, JavaScript, SQL, and Rust; \n Collaborate with internal and external engineers and product managers. \n \n What We're Looking For \n \n Experience building and managing data lakes aggregating dozens of data sources and providing insights to multiple different stakeholders based on terabytes of data; \n Experience in GCP and/or AWS data infrastructure products; \n Fluency in writing complex analytical SQL queries; \n Strong communication and remote friendly working skills; \n Bachelor's Degree in Computer Science, Applied Mathematics or related field is a must. \n \n We'd Love If You Have \n \n Deep understanding of DataBricks and BigQuery technologies; \n Knowledge of product analytics tools such as Segment, FullStory, MixPanel or Amplitude; \n Familiarity with crypto or blockchain technologies; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like \n  Our interviews take place via Zoom and typically consists of the following stages: \n \n Internal Recruiter Call (30 to 45 minutes) \n Technical Interviews (2 x 60 minutes) \n Pagoda Values Interview (30 to 45 minutes) \n \n Compensation \n  **This role is a 6  month contract with an opportunity for full time conversion depending on performance and business needs. Contractors will not receive any of the full time benefits shown below. \n  Pay Rate: $12,395/month - $14,583/month, which represents the cash payment range per month applicable to US locations only. \n  The actual pay rate within the range is dependent upon many factors, including: leveling, relevant skills, and work location. If you are based outside of the US, we there are other geographic considerations that may impact your final compensation. Your recruiter can share more about the compensation and benefits applicable to your preferred location during the hiring process. \n \n \n  Benefits & Perks \n \n Flexible Annual Leave / PTO with an encouraged 20 day per year minimum \n Paid Holiday Week: the last week of the year \n Paid Wellness Week: the first week of July \n $2,000 Yearly Continued Education Reimbursement \n $2,000 Home Office Setup Reimbursement \n Co-working Space Reimbursement \n Company Retreats (2023 in Spain!) & Team Offsites \n Mental Health Support and access to licensed therapists through Spill, 100% paid by Pagoda \n \n Our Values at Pagoda \n  Our values express our company culture. Learn more on our careers page. \n  Pagoda is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, color, religion, national origin, age, disability, veteran status, genetic data, or other legally protected status.", "cleaned_desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Pagoda Data Platform team is looking for a Data Engineer to build and scale our data infrastructure to empower our core products and product analytics. \n  What You'll Be Doing \n \n Architect and manage data lakes and data marts needed to provide product analytics insights to product teams and executives (BigQuery, DataBricks); \n Create and manage data pipelines for both on-chain (NEAR) and off-chain (OLTP databases, http logs, UI analytics) data; \n Automate data quality monitoring and alerting tools; \n Optimize time to insight and work with Data Scientists to create data marts for various data products;   Creating data extraction tools using Python, JavaScript, SQL, and Rust; \n Collaborate with internal and external engineers and product managers. \n \n What We're Looking For \n \n Experience building and managing data lakes aggregating dozens of data sources and providing insights to multiple different stakeholders based on terabytes of data; \n Experience in GCP and/or AWS data infrastructure products; \n Fluency in writing complex analytical SQL queries; \n Strong communication and remote friendly working skills; \n Bachelor's Degree in Computer Science, Applied Mathematics or related field is a must. \n ", "techs": ["bigquery", "databricks", "near (on-chain)", "oltp databases", "http logs", "ui analytics", "python", "javascript", "sql", "rust", "gcp", "aws"]}, "f4bd9226990379b9": {"terms": ["data engineer"], "salary_min": 88750.2, "salary_max": 112377.53, "title": "Data Engineer- Support Operations", "company": "The Infosoft Group", "desc": "Milwaukee, Wisconsin, United States\n   United States of America Wisconsin (remote)\n   United States of America Illinois (remote)\n   United States of America Michigan (remote)\n   United States of America Ohio (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n  The Data Engineer will design, develop, and deliver reliable, scalable data management (acquisition, integration, transformation) using DevOps methodologies and DA&I Microsoft PaaS platforms. Design and enable DA&I solutions and services throughout the company. This role is DA&I's competitive advantage to delivering business outcomes via actionable analytics, decision intelligence and help our businesses recognize value and here to shape how we deliver analytics solutions going forward. \n \n  The Data Engineer is multi-skilled engineer who helps to estimate work, accept stories into delivery increments and complete tasks to deliver the work. Is proficient in Source Data Analysis, profiling, integration, modelling. Has expertise in data management technologies such as SAP data services, Azure ADF, ADLS, Databricks, SQL DB, Open source data management tools or equivalent. \n \n  Key responsibilities: \n \n  Design, code and test new data management solutions, including supporting applications and interfaces. \n  Architect data structures to provision and enable \"Data as a Service\". \n  Supports cross-functional development activity in various DA&I and Connected Enterprise related projects, for internal and external customers. \n  Develops and tests infrastructure components in Cloud and Edge-level environments. \n  Proactively monitors industry trends and identifies opportunities to implement new technologies. \n  Manages the DevOps pipeline deployment model. \n  Implements software in all environments. \n  Leverages containerization models and works with other engineers and architects to keep the architecture current. \n  Assists in the support and enhancement of applications. \n  Writes high-quality code compliant with regulations. \n  Collaborates with business systems analysts and product owners to define requirements. \n \n \n  Basic Qualifications: \n \n  Bachelor's Degree in computer science, software engineering, management information systems, or related field \n  Legal authorization to work in the US is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. \n \n \n  Preferred Qualifications: \n \n  Experience in systems development lifecycle \n  Experience in Data management concepts and implementations \n  Experience with Agile development methodologies and system/process documentation \n  Experience with server-side architectures and containerization \n  Experience working with managing ServiceNow Queue, troubleshooting data integration failures and engaging the appropriate teams and resources as needed. \n  Experience in SAP Data Service. \n  Experience with Azure ADF, ADLS, SQL, Tabular models, or other domain-specific programming languages \n  Familiarity with business concepts and impact of data on business processes \n  Experience managing multiple projects simultaneously. \n  Excellent interpersonal, verbal, and written communication skills \n  Ability to adapt quickly to new technologies and changing business requirements. \n  Solid problem-solving skills, attention to detail, and critical thinking abilities \n  Ability to adapt to and assist colleagues to work through change and support change management processes. \n  Strong team orientation and ability to collaborate with business and IT organizations. \n  Ability to retain and convey a positive attitude in challenging circumstances. \n  Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required. \n  Ability to influence and obtain results through others within Rockwell in a respectful way. \n \n \n  Adapt appropriately to competing demands and shifting priorities \n  Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors. \n  Exercise judgment within defined procedures and practices to determine appropriate action. \n  deciding; demonstrate clear understanding of multiple viewpoints. \n  Leverage business insights in proposing solutions and facilitating change. \n  Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible \n  Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the \"story\" behind it, as well as recommendations for next steps \n \n \n  Unwavering commitment to, and the ability to model, the standards of behavior set in our Code of Conduct. \n  Enthusiasm for relationship building and partnership across the organization at all levels \n  Values working in a team-oriented culture and building consensus with stakeholders before making key decisions \n  Actively pursues personal continuous learning and development of skills \n \n \n  #LI-AO23 \n  #LI-Remote \n \n  We are an Equal Opportunity Employer including disability and veterans. \n \n  If you are an individual with a disability and you need assistance or a reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7247. \n  Rockwell Automation is an Equal Opportunity Employer \u2013 Disability/Veteran.\n  \n  If you are an individual with a disability and you need assistance or reasonable accommodation during the application process, email our Talent Acquisition representative at RAApplicationsupport@ra.rockwell.com.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Rockwell Automation \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   Open", "cleaned_desc": "Milwaukee, Wisconsin, United States\n   United States of America Wisconsin (remote)\n   United States of America Illinois (remote)\n   United States of America Michigan (remote)\n   United States of America Ohio (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n  The Data Engineer will design, develop, and deliver reliable, scalable data management (acquisition, integration, transformation) using DevOps methodologies and DA&I Microsoft PaaS platforms. Design and enable DA&I solutions and services throughout the company. This role is DA&I's competitive advantage to delivering business outcomes via actionable analytics, decision intelligence and help our businesses recognize value and here to shape how we deliver analytics solutions going forward. \n \n  The Data Engineer is multi-skilled engineer who helps to estimate work, accept stories into delivery increments and complete tasks to deliver the work. Is proficient in Source Data Analysis, profiling, integration, modelling. Has expertise in data management technologies such as SAP data services, Azure ADF, ADLS, Databricks, SQL DB, Open source data management tools or equivalent. \n \n  Key responsibilities: \n \n  Design, code and test new data management solutions, including supporting applications and interfaces. \n  Architect data structures to provision and enable \"Data as a Service\". \n  Supports cross-functional development activity in various DA&I and Connected Enterprise related projects, for internal and external customers. \n  Develops and tests infrastructure components in Cloud and Edge-level environments. \n  Proactively monitors industry trends and identifies opportunities to implement new technologies. \n  Manages the DevOps pipeline deployment model. \n  Implements software in all environments. \n  Leverages containerization models and works with other engineers and architects to keep the architecture current.    Assists in the support and enhancement of applications. \n  Writes high-quality code compliant with regulations. \n  Collaborates with business systems analysts and product owners to define requirements. \n \n \n  Basic Qualifications: \n \n  Bachelor's Degree in computer science, software engineering, management information systems, or related field \n  Legal authorization to work in the US is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. \n \n \n  Preferred Qualifications: \n \n  Experience in systems development lifecycle \n  Experience in Data management concepts and implementations \n  Experience with Agile development methodologies and system/process documentation \n  Experience with server-side architectures and containerization \n  Experience working with managing ServiceNow Queue, troubleshooting data integration failures and engaging the appropriate teams and resources as needed. \n  Experience in SAP Data Service. \n  Experience with Azure ADF, ADLS, SQL, Tabular models, or other domain-specific programming languages \n  Familiarity with business concepts and impact of data on business processes \n  Experience managing multiple projects simultaneously. \n  Excellent interpersonal, verbal, and written communication skills \n  Ability to adapt quickly to new technologies and changing business requirements.    Solid problem-solving skills, attention to detail, and critical thinking abilities \n  Ability to adapt to and assist colleagues to work through change and support change management processes. \n  Strong team orientation and ability to collaborate with business and IT organizations. \n  Ability to retain and convey a positive attitude in challenging circumstances. \n  Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required. \n  Ability to influence and obtain results through others within Rockwell in a respectful way. \n \n \n  Adapt appropriately to competing demands and shifting priorities \n  Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors. \n  Exercise judgment within defined procedures and practices to determine appropriate action. \n  deciding; demonstrate clear understanding of multiple viewpoints. \n  Leverage business insights in proposing solutions and facilitating change. \n  Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible \n  Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the \"story\" behind it, as well as recommendations for next steps \n \n \n  Unwavering commitment to, and the ability to model, the standards of behavior set in our Code of Conduct. \n  Enthusiasm for relationship building and partnership across the organization at all levels \n  Values working in a team-oriented culture and building consensus with stakeholders before making key decisions \n  Actively pursues personal continuous learning and development of skills \n \n \n  #LI-AO23 ", "techs": ["milwaukee", "wisconsin", "united states", "united states of america wisconsin", "united states of america illinois", "united states of america michigan", "united states of america ohio", "rockwell automation", "devops methodologies", "da&i microsoft paas platforms", "sap data services", "azure adf", "adls", "databricks", "sql db", "open source data management tools", "source data analysis", "cloud and edge-level environments", "devops pipeline deployment model", "containerization models", "servicenow queue", "sap data service", "tabular models", "agile development methodologies", "system/process documentation", "business concepts", "interpersonal communication skills", "critical thinking abilities", "positive attitude", "change management processes", "rockwell code of conduct", "relationship building", "personal continuous learning"]}, "2bd1c28c3074ab1c": {"terms": ["data engineer"], "salary_min": 103672.73, "salary_max": 131272.77, "title": "Full Stack Software Engineer, Data Platform", "company": "Pagoda", "desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Data Platform team at Pagoda is responsible for the data access infrastructure of NEAR Protocol. We focus on building scalable, performant, and reliable infrastructure to query and access blockchain data that power decentralized applications, such as the NEAR Blockchain Operating System (BOS). \n  What You'll Be Doing \n \n Developing user interfaces and services for software engineers around the world to build decentralized applications on NEAR Protocol; \n Collaboration with a fully distributed team around the world; \n Writing the code, fixing bugs, and participating in design discussions; \n Following the minimal processes, like technical roadmaps, OKRs, milestones, regular team meetings; \n Develop components and applications in public clouds like GCP and AWS; \n Participating in on-call rotations; \n Performance optimizations and scalability/reliability improvements. \n \n What We're Looking For \n \n Ability to quickly learn new programming languages and technologies. \n Creativity to come up with proof of concept from high level design while not knowing all the details. \n Experience building highly-interactive user interfaces using React; \n Experience building easy to use and scalable APIs, including REST and GraphQL; \n Ability to write clean yet efficient code in a variety of programming languages and technologies, including TypeScript, Rust, SQL, Python; \n Experience building cloud applications utilizing managed compute and data processing systems; \n Understanding data processing and storage solutions and ability to find balance between cost, performance and scalability. \n Effective communication skills to convey your ideas and discuss with team members for technical challenges \n Bachelor's Degree in Computer Science or related fields is a must \n \n We'd Love If You Have \n \n Open source contributions and previous or continued involvement in open source communities; \n Experience setting up continuous integration pipelines, observability tools and metrics; \n Familiarity with Ethereum development and related technologies (web3.js, ethers.js, etc) \n Familiarity with other crypto or blockchain technologies; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like \n  Our interviews take place via Zoom and typically consists of the following stages: \n \n Internal Recruiter Call (30 to 45 minutes) \n Technical Interviews (3 x 60 minutes) \n Meet with the Hiring Manager (60 minutes) \n Pagoda Values Interview (30 to 45 minutes) \n \n Compensation  \n The base salary range for this role is $148,750 - $195,000, which represents the salary range applicable to US locations only. This does not include bonus, incentives, or benefits. \n  The actual base pay within the range is dependent upon many factors, including: leveling, relevant skills, and work location. If you are based outside of the US, we there are other geographic considerations that may impact your final compensation. Your recruiter can share more about the compensation and benefits applicable to your preferred location during the hiring process. \n \n \n  Benefits & Perks \n \n Flexible Annual Leave / PTO with an encouraged 20 day per year minimum \n Paid Holiday Week: the last week of the year \n Paid Wellness Week: the first week of July \n $2,000 Yearly Continued Education Reimbursement \n $2,000 Home Office Setup Reimbursement \n Co-working Space Reimbursement \n Company Retreats (2023 in Spain!) & Team Offsites \n Mental Health Support and access to licensed therapists through Spill, 100% paid by Pagoda \n \n Our Values at Pagoda \n  Our values express our company culture. Learn more on our careers page. \n  Pagoda is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, color, religion, national origin, age, disability, veteran status, genetic data, or other legally protected status.", "cleaned_desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Data Platform team at Pagoda is responsible for the data access infrastructure of NEAR Protocol. We focus on building scalable, performant, and reliable infrastructure to query and access blockchain data that power decentralized applications, such as the NEAR Blockchain Operating System (BOS). \n  What You'll Be Doing \n \n Developing user interfaces and services for software engineers around the world to build decentralized applications on NEAR Protocol; \n Collaboration with a fully distributed team around the world; \n Writing the code, fixing bugs, and participating in design discussions; \n Following the minimal processes, like technical roadmaps, OKRs, milestones, regular team meetings; \n Develop components and applications in public clouds like GCP and AWS;   Participating in on-call rotations; \n Performance optimizations and scalability/reliability improvements. \n \n What We're Looking For \n \n Ability to quickly learn new programming languages and technologies. \n Creativity to come up with proof of concept from high level design while not knowing all the details. \n Experience building highly-interactive user interfaces using React; \n Experience building easy to use and scalable APIs, including REST and GraphQL; \n Ability to write clean yet efficient code in a variety of programming languages and technologies, including TypeScript, Rust, SQL, Python; \n Experience building cloud applications utilizing managed compute and data processing systems; \n Understanding data processing and storage solutions and ability to find balance between cost, performance and scalability.   Effective communication skills to convey your ideas and discuss with team members for technical challenges \n Bachelor's Degree in Computer Science or related fields is a must \n \n We'd Love If You Have \n \n Open source contributions and previous or continued involvement in open source communities; \n Experience setting up continuous integration pipelines, observability tools and metrics; \n Familiarity with Ethereum development and related technologies (web3.js, ethers.js, etc) \n Familiarity with other crypto or blockchain technologies; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like ", "techs": ["react", "rest", "graphql", "typescript", "rust", "sql", "python", "gcp", "aws"]}, "135f5745418fa428": {"terms": ["data engineer"], "salary_min": 120013.16, "salary_max": 151963.4, "title": "Data Engineer II, Infrastructure", "company": "Affinity.co", "desc": "At the heart of Affinity, you'll find a number of foundational infrastructure and operational challenges involved in building, running, and evolving our data-driven, processing-intensive product. \n  In this role, you'll join our Infrastructure Engineering team, which is responsible for driving performance, scalability, reliability, and developer efficiency at Affinity. Additionally, we deliver vital DevOps and DataOps services to both the Engineering and Analytics organizations. \n  What you'll be doing : \n \n Collaborate cross-functionally with go-to-market, analytics, engineering, and product teams \n Develop and maintain frameworks to support an organization's analytics data demands \n Build and optimize data pipelines to facilitate the extraction of data from multiple sources and load it into data warehouses \n Build complex ETL/ELT jobs to replicate and transform the data to power Internal Analytics reports and dashboards \n Design, implement, and optimize Data warehouses \n Ensure data security standards are applied across the data pipelines \n Provide various teams with access to structured datasets and analytics they will further analyze and derive insights from \n \n We'd love to hear from you if you have: \n \n 3+ years of proven experience as a Data Engineer, DataOps Engineer, or a similar role \n Exceptional SQL skills \n Experience with Relational, Columnar, and NOSQL databases \n Experience with ETL/ELT orchestration tools, such as DBT, Stitch, Fivetran, or Airflow \n Experience creating complex transform jobs to cleanup and aggregate data \n Problem-solving aptitude \n Excellent communication skills \n Experience writing Infrastructure as Code using Terraform, CloudFormation or similar \n \n Nice to have experience: \n \n Experience working with AWS Cloud \n Experience diagnosing and fixing database performance issues \n Experience with BI tools such as Looker or Amplitude \n \n Tech stack \n  Our infrastructure resides on AWS. For our primary relational data storage, we utilize PostgreSQL, and for semi-structured data, we leverage S3 buckets. On the analytics front, we use Aptitude to gather product insights, while AWS Redshift caters to our data warehousing requirements. In terms of infrastructure management, we employ Terraform for Infrastructure as Code (IaC). For our ETL/ELT processes, we've integrated DBT and Stitch \n  How we work: \n  Our culture is a key part of how we operate as well as our hiring process: \n \n We iterate quickly. As such, you must be comfortable embracing ambiguity, be able to cut through it, and deliver incremental value to our customers each sprint \n We are candid, transparent, and speak our minds while simultaneously caring personally with each person we interact with \n We make data driven decisions and make the best decision for the moment based on the information available \n \n Join us in enabling every professional on the planet to succeed by harnessing the power of their relationships. \n  If you'd want to learn more about our values click here. \n  What you'll enjoy at Affinity: \n \n We live our values as playmakers, obsessed with learning, care personally about our colleagues and clients, are radically open-minded, and take pride in everything we do. \n Health Care coverage and flexible personal & sick days. We want our team to be happy and healthy :) \n We provide an annual budget for you to spend on education and offer a comprehensive L&D program \u2013 after all, one of our core values is that we're #obsessedwithlearning! \n We support our employee's overall health and well-being and reimburse monthly for things such as; Transportation, Home Internet, Meals, and Wellness memberships/equipment. \n Virtual team building and socials. Keeping people connected is essential. \n \n Please note that the role compensation details below reflect the base salary only and do not include any variable pay, equity, or benefits. This represents the salary range that Affinity believes, in good faith, at the time of this posting, that it will pay for the posted job. \n  A reasonable estimate of the current range is  $87,000 to $147,000 USD . Within the range, individual pay is determined by factors such as job-related skills, experience, and relevant education or training. \n \n  About Affinity \n  We have raised over $120M and are backed by some of Silicon Valley's best firms, with over 2,700 customers worldwide on our platform. We are proud to have a 4.5 Star Glassdoor rating and recently ranked; Inc.'s Best Workplaces of 2022 and Great Places to Work 2022. Passionate about helping dealmakers in the world's biggest relationship-driven industries to find, manage, and close the most important deals; our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month.", "cleaned_desc": "At the heart of Affinity, you'll find a number of foundational infrastructure and operational challenges involved in building, running, and evolving our data-driven, processing-intensive product. \n  In this role, you'll join our Infrastructure Engineering team, which is responsible for driving performance, scalability, reliability, and developer efficiency at Affinity. Additionally, we deliver vital DevOps and DataOps services to both the Engineering and Analytics organizations. \n  What you'll be doing : \n \n Collaborate cross-functionally with go-to-market, analytics, engineering, and product teams \n Develop and maintain frameworks to support an organization's analytics data demands \n Build and optimize data pipelines to facilitate the extraction of data from multiple sources and load it into data warehouses \n Build complex ETL/ELT jobs to replicate and transform the data to power Internal Analytics reports and dashboards \n Design, implement, and optimize Data warehouses \n Ensure data security standards are applied across the data pipelines   Provide various teams with access to structured datasets and analytics they will further analyze and derive insights from \n \n We'd love to hear from you if you have: \n \n 3+ years of proven experience as a Data Engineer, DataOps Engineer, or a similar role \n Exceptional SQL skills \n Experience with Relational, Columnar, and NOSQL databases \n Experience with ETL/ELT orchestration tools, such as DBT, Stitch, Fivetran, or Airflow \n Experience creating complex transform jobs to cleanup and aggregate data \n Problem-solving aptitude   Excellent communication skills \n Experience writing Infrastructure as Code using Terraform, CloudFormation or similar \n \n Nice to have experience: \n \n Experience working with AWS Cloud \n Experience diagnosing and fixing database performance issues \n Experience with BI tools such as Looker or Amplitude \n \n Tech stack ", "techs": ["dbt", "stitch", "fivetran", "airflow", "terraform", "cloudformation", "aws cloud", "looker", "amplitude"]}, "06cf298fec9960ad": {"terms": ["data engineer"], "salary_min": 111726.26, "salary_max": 141470.34, "title": "Sr. Data Engineer", "company": "Oraanj Inc", "desc": "OPT EAD/H4 EAD/GC \n W2 \n Job Title: Data Engineer \n Duties: Top Skills:  Python, Spark, Spark Streaming, AWS, SQL \n Role responsibilities: \n \n Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology \n Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes \n Translate product backlog items into engineering designs and logical units of work \n Profile and analyze data for the purpose of designing scalable solutions \n Define and apply appropriate data acquisition and consumption strategies for given technical scenarios \n Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem \n Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns \n Implement complex automated routines using workflow orchestration tools \n Work with architecture, engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to \n Anticipate, identify and solve issues concerning data management to improve data quality \n Build and incorporate automated unit tests and participate in integration testing efforts \n Utilize and advance continuous integration and deployment frameworks \n Troubleshoot data issues and perform root cause analysis \n Work across teams to resolve operational & performance issues \n \n Job Types: Full-time, Contract \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology \n Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes \n Translate product backlog items into engineering designs and logical units of work \n Profile and analyze data for the purpose of designing scalable solutions \n Define and apply appropriate data acquisition and consumption strategies for given technical scenarios \n Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem   Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns \n Implement complex automated routines using workflow orchestration tools \n Work with architecture, engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to \n Anticipate, identify and solve issues concerning data management to improve data quality \n Build and incorporate automated unit tests and participate in integration testing efforts \n Utilize and advance continuous integration and deployment frameworks ", "techs": ["agile / scrum methodology", "architecture", "frameworks", "patterns", "data acquisition", "data consumption", "distributed data processing pipelines", "big data ecosystem tools", "utilities", "user defined functions", "libraries", "frameworks", "workflow orchestration tools", "automation routines", "quality solutions", "engineering best practices", "data management", "data quality", "automated unit tests", "integration testing", "continuous integration", "deployment frameworks"]}, "7c34d6bea4107feb": {"terms": ["data engineer"], "salary_min": 12395.0, "salary_max": 12395.0, "title": "Data Engineer, Data Platform (Contract)", "company": "NEAR", "desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Pagoda Data Platform team is looking for a Data Engineer to build and scale our data infrastructure to empower our core products and product analytics. \n  What You'll Be Doing \n \n Architect and manage data lakes and data marts needed to provide product analytics insights to product teams and executives (BigQuery, DataBricks); \n Create and manage data pipelines for both on-chain (NEAR) and off-chain (OLTP databases, http logs, UI analytics) data; \n Automate data quality monitoring and alerting tools; \n Optimize time to insight and work with Data Scientists to create data marts for various data products; \n Creating data extraction tools using Python, JavaScript, SQL, and Rust; \n Collaborate with internal and external engineers and product managers. \n \n What We're Looking For \n \n Experience building and managing data lakes aggregating dozens of data sources and providing insights to multiple different stakeholders based on terabytes of data; \n Experience in GCP and/or AWS data infrastructure products; \n Fluency in writing complex analytical SQL queries; \n Strong communication and remote friendly working skills; \n Bachelor's Degree in Computer Science, Applied Mathematics or related field is a must. \n \n We'd Love If You Have \n \n Deep understanding of DataBricks and BigQuery technologies; \n Knowledge of product analytics tools such as Segment, FullStory, MixPanel or Amplitude; \n Familiarity with crypto or blockchain technologies; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like \n  Our interviews take place via Zoom and typically consists of the following stages: \n \n Internal Recruiter Call (30 to 45 minutes) \n Technical Interviews (2 x 60 minutes) \n Pagoda Values Interview (30 to 45 minutes) \n \n Compensation \n  **This role is a 6  month contract with an opportunity for full time conversion depending on performance and business needs. Contractors will not receive any of the full time benefits shown below. \n  Pay Rate: $12,395/month - $14,583/month, which represents the cash payment range per month applicable to US locations only. \n  The actual pay rate within the range is dependent upon many factors, including: leveling, relevant skills, and work location. If you are based outside of the US, we there are other geographic considerations that may impact your final compensation. Your recruiter can share more about the compensation and benefits applicable to your preferred location during the hiring process. \n \n \n \n  Benefits & Perks \n \n Flexible Annual Leave / PTO with an encouraged 20 day per year minimum \n Paid Holiday Week: the last week of the year \n Paid Wellness Week: the first week of July \n $2,000 Yearly Continued Education Reimbursement \n $2,000 Home Office Setup Reimbursement \n Co-working Space Reimbursement \n Company Retreats (2023 in Spain!) & Team Offsites \n Mental Health Support and access to licensed therapists through Spill, 100% paid by Pagoda \n \n Our Values at Pagoda \n  Our values express our company culture. Learn more on our careers page. \n  Pagoda is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, color, religion, national origin, age, disability, veteran status, genetic data, or other legally protected status.", "cleaned_desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Pagoda Data Platform team is looking for a Data Engineer to build and scale our data infrastructure to empower our core products and product analytics. \n  What You'll Be Doing \n \n Architect and manage data lakes and data marts needed to provide product analytics insights to product teams and executives (BigQuery, DataBricks); \n Create and manage data pipelines for both on-chain (NEAR) and off-chain (OLTP databases, http logs, UI analytics) data; \n Automate data quality monitoring and alerting tools; \n Optimize time to insight and work with Data Scientists to create data marts for various data products;   Creating data extraction tools using Python, JavaScript, SQL, and Rust; \n Collaborate with internal and external engineers and product managers. \n \n What We're Looking For \n \n Experience building and managing data lakes aggregating dozens of data sources and providing insights to multiple different stakeholders based on terabytes of data; \n Experience in GCP and/or AWS data infrastructure products; \n Fluency in writing complex analytical SQL queries; \n Strong communication and remote friendly working skills; \n Bachelor's Degree in Computer Science, Applied Mathematics or related field is a must. \n ", "techs": ["bigquery", "databricks", "near", "oltp databases", "http logs", "ui analytics", "python", "javascript", "sql", "rust", "gcp", "aws"]}, "46b531b267647c7d": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 116773.836, "salary_max": 147861.7, "title": "Senior Data Engineer", "company": "CoreTrust Purchasing Group", "desc": "CoreTrust is the market leading commercial Group Purchasing Organization (GPO), leveraging the combined purchasing volume of its 3,000+ members to negotiate preferential pricing and terms across more than 80 indirect spend categories. Strategically aligned with private equity portfolios and large independent companies, we complement sourcing bandwidth and improve supply chain efforts with our industry-leading national contracts. \n  Recently acquired by Blackstone Private Equity, CoreTrust is growing rapidly and we're looking for a passionate  Senior Data Engineer.  Reporting to the Director of Data, you will be part of the data solutions team and be responsible for building our data platforms, enabling the use of advanced analytics to drive continued evolution and growth. \n  You will create and manage data pipelines to feed and curate our data lake solution and help develop our data roadmap. The ideal candidate has a great understanding of various data / tech solutions (e.g., data modeling tools, data pipeline, data catalogs, cloud databases) and a record of using them to bring tangible dollar impact. You should be excited to seek out and capitalize on a wide variety of opportunities to use data to create value across the organization. \n \n \n  Responsibilities \n \n Lead data projects to build innovative and highly available solutions while ensuring adherence to budget, schedule, and scope of project  \n Mentor other members in the data solutions team \n Develop and assist with oversight on the data tech infrastructure \n Drive data & analytics solutions from conception to deployment/delivery with clear ROI impact \n Develop and maintain relationships with all relevant business and tech stakeholders and functions \n Provide input to proposals for assigned projects including project objectives, technologies, systems, information specifications, timelines, and staffing \n Communicate timely status updates to affected internal or external customers and stakeholders \n Collect, analyze, and summarize information and trends as needed to prepare project status reports \n Assist in developing a culture of data-driven decision-making, including adoption of business intelligence, analysis, and advanced analytics globally \n Perform other related duties as assigned \n \n \n \n  Qualifications \n \n Bachelor's degree in computer or information science or relevant experience \n 9+ years of relevant experience in a data-driven professional setting \n Ability to assist with the vision of the team (e.g., mission, priorities, engagement model, tooling) \n A record of accomplishment of successfully managing complex cross-functional projects under tight deadlines  \n Strong technical background \u2013 familiarity with Python, SQL, cloud technologies like Azure and AWS, statistics / machine learning, Snowflake, DBT, FiveTran, Data Visualization Software \n Exceptional communication and presentation skills, particularly in the context of engaging senior management teams \n A successful history of manipulating, processing, and extracting value from large, disconnected datasets \n Build processes supporting data transformation, data structures, metadata, dependency, and workload management \n Working knowledge of creating and leveraging API or Stream based data extraction processes such as Salesforce API \n Strong command of databases and SQL  \n Proficiency with Python or R, especially for data manipulation and analysis, and ability to build, maintain and deploy sequences of automated processes with these tools  \n Ability to motivate groups of people to complete a project in a timely manner  \n Excellent analytical, logical thinking, and problem-solving skills \n Thorough understanding of project management principles and planning \n Thorough understanding of information technology procedures and practices \n Proficient with, or able to quickly become proficient with, a range of general and specialized applications, software, and hardware used in the organization and the industry \n \n \n \n  Benefits \n \n Competitive compensation package  \n Free individual employee medical coverage  \n Company subsidized dental and vision coverage  \n Dollar for dollar 401(k) match up to 6% of your salary with immediate vesting  \n Company-paid Short-Term and Long-Term Disability coverage  \n Employee Assistance Program to support your wellbeing and mental health  \n $1500 annual stipend for undergraduate/graduate college courses; $500 annual stipend for continuing education courses/certifications  \n Free snacks and beverages on-site  \n Brand new, state-of-the-art, tech-enabled work environment in downtown Nashville  \n Flexible/hybrid work culture", "cleaned_desc": "CoreTrust is the market leading commercial Group Purchasing Organization (GPO), leveraging the combined purchasing volume of its 3,000+ members to negotiate preferential pricing and terms across more than 80 indirect spend categories. Strategically aligned with private equity portfolios and large independent companies, we complement sourcing bandwidth and improve supply chain efforts with our industry-leading national contracts. \n  Recently acquired by Blackstone Private Equity, CoreTrust is growing rapidly and we're looking for a passionate  Senior Data Engineer.  Reporting to the Director of Data, you will be part of the data solutions team and be responsible for building our data platforms, enabling the use of advanced analytics to drive continued evolution and growth. \n  You will create and manage data pipelines to feed and curate our data lake solution and help develop our data roadmap. The ideal candidate has a great understanding of various data / tech solutions (e.g., data modeling tools, data pipeline, data catalogs, cloud databases) and a record of using them to bring tangible dollar impact. You should be excited to seek out and capitalize on a wide variety of opportunities to use data to create value across the organization. \n \n \n  Responsibilities \n \n Lead data projects to build innovative and highly available solutions while ensuring adherence to budget, schedule, and scope of project  \n Mentor other members in the data solutions team \n Develop and assist with oversight on the data tech infrastructure    Qualifications \n \n Bachelor's degree in computer or information science or relevant experience \n 9+ years of relevant experience in a data-driven professional setting \n Ability to assist with the vision of the team (e.g., mission, priorities, engagement model, tooling) \n A record of accomplishment of successfully managing complex cross-functional projects under tight deadlines  \n Strong technical background \u2013 familiarity with Python, SQL, cloud technologies like Azure and AWS, statistics / machine learning, Snowflake, DBT, FiveTran, Data Visualization Software \n Exceptional communication and presentation skills, particularly in the context of engaging senior management teams \n A successful history of manipulating, processing, and extracting value from large, disconnected datasets \n Build processes supporting data transformation, data structures, metadata, dependency, and workload management   Working knowledge of creating and leveraging API or Stream based data extraction processes such as Salesforce API \n Strong command of databases and SQL  \n Proficiency with Python or R, especially for data manipulation and analysis, and ability to build, maintain and deploy sequences of automated processes with these tools  \n Ability to motivate groups of people to complete a project in a timely manner  \n Excellent analytical, logical thinking, and problem-solving skills \n Thorough understanding of project management principles and planning \n Thorough understanding of information technology procedures and practices \n Proficient with, or able to quickly become proficient with, a range of general and specialized applications, software, and hardware used in the organization and the industry \n \n ", "techs": ["coretrust", "python", "sql", "azure", "aws", "statistics", "machine learning", "snowflake", "dbt", "fivetran", "data visualization software", "salesforce api", "r"]}, "1e8c4275a0b3c5cc": {"terms": ["data engineer"], "salary_min": 88750.2, "salary_max": 112377.53, "title": "Data Engineer- Support Operations", "company": "The Infosoft Group", "desc": "Milwaukee, Wisconsin, United States\n   United States of America Wisconsin (remote)\n   United States of America Illinois (remote)\n   United States of America Michigan (remote)\n   United States of America Ohio (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n  The Data Engineer will design, develop, and deliver reliable, scalable data management (acquisition, integration, transformation) using DevOps methodologies and DA&I Microsoft PaaS platforms. Design and enable DA&I solutions and services throughout the company. This role is DA&I's competitive advantage to delivering business outcomes via actionable analytics, decision intelligence and help our businesses recognize value and here to shape how we deliver analytics solutions going forward. \n \n  The Data Engineer is multi-skilled engineer who helps to estimate work, accept stories into delivery increments and complete tasks to deliver the work. Is proficient in Source Data Analysis, profiling, integration, modelling. Has expertise in data management technologies such as SAP data services, Azure ADF, ADLS, Databricks, SQL DB, Open source data management tools or equivalent. \n \n  Key responsibilities: \n \n  Design, code and test new data management solutions, including supporting applications and interfaces. \n  Architect data structures to provision and enable \"Data as a Service\". \n  Supports cross-functional development activity in various DA&I and Connected Enterprise related projects, for internal and external customers. \n  Develops and tests infrastructure components in Cloud and Edge-level environments. \n  Proactively monitors industry trends and identifies opportunities to implement new technologies. \n  Manages the DevOps pipeline deployment model. \n  Implements software in all environments. \n  Leverages containerization models and works with other engineers and architects to keep the architecture current. \n  Assists in the support and enhancement of applications. \n  Writes high-quality code compliant with regulations. \n  Collaborates with business systems analysts and product owners to define requirements. \n \n \n  Basic Qualifications: \n \n  Bachelor's Degree in computer science, software engineering, management information systems, or related field \n  Legal authorization to work in the US is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. \n \n \n  Preferred Qualifications: \n \n  Experience in systems development lifecycle \n  Experience in Data management concepts and implementations \n  Experience with Agile development methodologies and system/process documentation \n  Experience with server-side architectures and containerization \n  Experience working with managing ServiceNow Queue, troubleshooting data integration failures and engaging the appropriate teams and resources as needed. \n  Experience in SAP Data Service. \n  Experience with Azure ADF, ADLS, SQL, Tabular models, or other domain-specific programming languages \n  Familiarity with business concepts and impact of data on business processes \n  Experience managing multiple projects simultaneously. \n  Excellent interpersonal, verbal, and written communication skills \n  Ability to adapt quickly to new technologies and changing business requirements. \n  Solid problem-solving skills, attention to detail, and critical thinking abilities \n  Ability to adapt to and assist colleagues to work through change and support change management processes. \n  Strong team orientation and ability to collaborate with business and IT organizations. \n  Ability to retain and convey a positive attitude in challenging circumstances. \n  Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required. \n  Ability to influence and obtain results through others within Rockwell in a respectful way. \n \n \n  Adapt appropriately to competing demands and shifting priorities \n  Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors. \n  Exercise judgment within defined procedures and practices to determine appropriate action. \n  deciding; demonstrate clear understanding of multiple viewpoints. \n  Leverage business insights in proposing solutions and facilitating change. \n  Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible \n  Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the \"story\" behind it, as well as recommendations for next steps \n \n \n  Unwavering commitment to, and the ability to model, the standards of behavior set in our Code of Conduct. \n  Enthusiasm for relationship building and partnership across the organization at all levels \n  Values working in a team-oriented culture and building consensus with stakeholders before making key decisions \n  Actively pursues personal continuous learning and development of skills \n \n \n  #LI-AO23 \n \n  We are an Equal Opportunity Employer including disability and veterans. \n \n  If you are an individual with a disability and you need assistance or a reasonable accommodation during the application process, please contact our services team at +1 (844) 404-7247. \n  Rockwell Automation is an Equal Opportunity Employer \u2013 Disability/Veteran.\n  \n  If you are an individual with a disability and you need assistance or reasonable accommodation during the application process, email our Talent Acquisition representative at RAApplicationsupport@ra.rockwell.com.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Rockwell Automation \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   Open", "cleaned_desc": "Milwaukee, Wisconsin, United States\n   United States of America Wisconsin (remote)\n   United States of America Illinois (remote)\n   United States of America Michigan (remote)\n   United States of America Ohio (remote)\n   Rockwell Automation is a global technology leader focused on helping the world's manufacturers be more productive, sustainable, and agile. With more than 28,000 employees who make the world better every day, we know we have something special. Behind our customers - amazing companies that help feed the world, provide life-saving medicine on a global scale, and focus on clean water and green mobility -our people are energized problem solvers that take pride in how thework we do changes the world for the better. \n \n  We welcome all makers, forward thinkers, and problem solvers who are looking for a place to do their best work. And if that's you we would love to have you join us! \n \n  Job Description \n  The Data Engineer will design, develop, and deliver reliable, scalable data management (acquisition, integration, transformation) using DevOps methodologies and DA&I Microsoft PaaS platforms. Design and enable DA&I solutions and services throughout the company. This role is DA&I's competitive advantage to delivering business outcomes via actionable analytics, decision intelligence and help our businesses recognize value and here to shape how we deliver analytics solutions going forward. \n \n  The Data Engineer is multi-skilled engineer who helps to estimate work, accept stories into delivery increments and complete tasks to deliver the work. Is proficient in Source Data Analysis, profiling, integration, modelling. Has expertise in data management technologies such as SAP data services, Azure ADF, ADLS, Databricks, SQL DB, Open source data management tools or equivalent. \n \n  Key responsibilities: \n \n  Design, code and test new data management solutions, including supporting applications and interfaces. \n  Architect data structures to provision and enable \"Data as a Service\". \n  Supports cross-functional development activity in various DA&I and Connected Enterprise related projects, for internal and external customers. \n  Develops and tests infrastructure components in Cloud and Edge-level environments. \n  Proactively monitors industry trends and identifies opportunities to implement new technologies. \n  Manages the DevOps pipeline deployment model. \n  Implements software in all environments. \n  Leverages containerization models and works with other engineers and architects to keep the architecture current.    Assists in the support and enhancement of applications. \n  Writes high-quality code compliant with regulations. \n  Collaborates with business systems analysts and product owners to define requirements. \n \n \n  Basic Qualifications: \n \n  Bachelor's Degree in computer science, software engineering, management information systems, or related field \n  Legal authorization to work in the US is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. \n \n \n  Preferred Qualifications: \n \n  Experience in systems development lifecycle \n  Experience in Data management concepts and implementations \n  Experience with Agile development methodologies and system/process documentation \n  Experience with server-side architectures and containerization \n  Experience working with managing ServiceNow Queue, troubleshooting data integration failures and engaging the appropriate teams and resources as needed. \n  Experience in SAP Data Service. \n  Experience with Azure ADF, ADLS, SQL, Tabular models, or other domain-specific programming languages \n  Familiarity with business concepts and impact of data on business processes \n  Experience managing multiple projects simultaneously. \n  Excellent interpersonal, verbal, and written communication skills \n  Ability to adapt quickly to new technologies and changing business requirements.    Solid problem-solving skills, attention to detail, and critical thinking abilities \n  Ability to adapt to and assist colleagues to work through change and support change management processes. \n  Strong team orientation and ability to collaborate with business and IT organizations. \n  Ability to retain and convey a positive attitude in challenging circumstances. \n  Act courageously by sharing viewpoints openly and directly with others, providing relevant and timely information and feedback, as required. \n  Ability to influence and obtain results through others within Rockwell in a respectful way. \n \n \n  Adapt appropriately to competing demands and shifting priorities \n  Ability to work on issues of moderate scope where analysis of situations or data requires a review of relevant factors. \n  Exercise judgment within defined procedures and practices to determine appropriate action. \n  deciding; demonstrate clear understanding of multiple viewpoints. \n  Leverage business insights in proposing solutions and facilitating change. \n  Ability to manage competing demands, accept criticism and constructive feedback, while being extremely adaptable and flexible \n  Strong analytical skills; ability to distill information from disparate data sources and the capability to tell the \"story\" behind it, as well as recommendations for next steps \n \n \n  Unwavering commitment to, and the ability to model, the standards of behavior set in our Code of Conduct. \n  Enthusiasm for relationship building and partnership across the organization at all levels \n  Values working in a team-oriented culture and building consensus with stakeholders before making key decisions \n  Actively pursues personal continuous learning and development of skills \n \n \n  #LI-AO23 ", "techs": ["devops methodologies", "da&i microsoft paas platforms", "sap data services", "azure adf", "adls", "databricks", "sql db", "open source data management tools", "systems development lifecycle", "agile development methodologies", "server-side architectures", "containerization", "managing servicenow queue", "troubleshooting data integration failures", "sap data service", "tabular models", "business concepts", "change management processes", "rockwell code of conduct"]}, "673b9347c791bdba": {"terms": ["data engineer"], "salary_min": 113340.25, "salary_max": 143514.02, "title": "Big Data Engineer", "company": "Honeysys LLC", "desc": "Visa - OPT,CPT H4EAD \n Job Description: \n \n 8 years of experience \n Experience working with Hadoop stack (Hive, HDFS, Spark). \n Strong AWS/GCP/Azure experience. (GCP must have) \n Experience with Java or Scala or python. \n Good knowledge of SQL. \n Good Communication Skills. \n \n Job Type: Full-time \n Experience: \n \n Informatica: 1 year (Preferred) \n SQL: 1 year (Preferred) \n Data warehouse: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " 8 years of experience \n Experience working with Hadoop stack (Hive, HDFS, Spark). \n Strong AWS/GCP/Azure experience. (GCP must have)   Experience with Java or Scala or python. \n Good knowledge of SQL. \n Good Communication Skills. ", "techs": ["hadoop stack (hive", "hdfs", "spark)", "aws/gcp/azure", "java", "scala", "python", "sql"]}, "2b919e228ca7fade": {"terms": ["data engineer", "mlops"], "salary_min": 100000.0, "salary_max": -1.0, "title": "DevOPS Engineer/ Data Engineer", "company": "Tekshapers Inc", "desc": "|| URGENT REQUIREMENT || \n Role \u2013 DevOPS Engineer/ Data Engineer \n Location \u2013 Remote \n Hire Mode: Fulltime \n Required Skills: \n \n GCP \n Tekton \n Terraform \n Infra and Access provisioning \n SQL \n BigQuery \n Data Ingestion and Transformation \n Kafka \n \n Thanks & Regards, \n Karishma | Sr. Talent Acquisition Executive \n TekShapers INC \n E :  karishma@tekshapers.com \n #urgenthiring #fulltimerole #remotejob #gcp #devops #dataengineer #sql \n Job Type: Full-time \n Salary: From $100,000.00 per year \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "d7706f1f65d5d2a7": {"terms": ["data engineer"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Data Architecture (Remote Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Distinguished Engineer, Data Architecture (Remote Eligible)\n  \n  Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions. \n \n  Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices \n  Visionaries, collaborating on Capital One\u2019s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates \n  Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community \n  Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities \n \n \n  Responsibilities: \n \n  Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in \n  Strike the right balance between lending expertise and providing an inclusive environment where others\u2019 ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team \n  Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible \n  Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization \n  Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner \n  Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One\u2019s Tech talent \n \n \n  Capital One is open to hiring a remote employee for this position. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s Degree \n  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS \n  3+ years of experience working with Big Data \n \n \n   \n Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS ", "techs": ["python", "java", "scala", "aws"]}, "229452cc40a2ff53": {"terms": ["data engineer"], "salary_min": 129058.7, "salary_max": 163417.08, "title": "Full Stack Software Engineer, Data Platform", "company": "NEAR", "desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Data Platform team at Pagoda is responsible for the data access infrastructure of NEAR Protocol. We focus on building scalable, performant, and reliable infrastructure to query and access blockchain data that power decentralized applications, such as the NEAR Blockchain Operating System (BOS). \n  What You'll Be Doing \n \n Developing user interfaces and services for software engineers around the world to build decentralized applications on NEAR Protocol; \n Collaboration with a fully distributed team around the world; \n Writing the code, fixing bugs, and participating in design discussions; \n Following the minimal processes, like technical roadmaps, OKRs, milestones, regular team meetings; \n Develop components and applications in public clouds like GCP and AWS; \n Participating in on-call rotations; \n Performance optimizations and scalability/reliability improvements. \n \n What We're Looking For \n \n Ability to quickly learn new programming languages and technologies. \n Creativity to come up with proof of concept from high level design while not knowing all the details. \n Experience building highly-interactive user interfaces using React; \n Experience building easy to use and scalable APIs, including REST and GraphQL; \n Ability to write clean yet efficient code in a variety of programming languages and technologies, including TypeScript, Rust, SQL, Python; \n Experience building cloud applications utilizing managed compute and data processing systems; \n Understanding data processing and storage solutions and ability to find balance between cost, performance and scalability. \n Effective communication skills to convey your ideas and discuss with team members for technical challenges \n Bachelor's Degree in Computer Science or related fields is a must \n \n We'd Love If You Have \n \n Open source contributions and previous or continued involvement in open source communities; \n Experience setting up continuous integration pipelines, observability tools and metrics; \n Familiarity with Ethereum development and related technologies (web3.js, ethers.js, etc) \n Familiarity with other crypto or blockchain technologies; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like \n  Our interviews take place via Zoom and typically consists of the following stages: \n \n Internal Recruiter Call (30 to 45 minutes) \n Technical Interviews (3 x 60 minutes) \n Meet with the Hiring Manager (60 minutes) \n Pagoda Values Interview (30 to 45 minutes) \n \n Compensation  \n The base salary range for this role is $148,750 - $195,000, which represents the salary range applicable to US locations only. This does not include bonus, incentives, or benefits. \n  The actual base pay within the range is dependent upon many factors, including: leveling, relevant skills, and work location. If you are based outside of the US, we there are other geographic considerations that may impact your final compensation. Your recruiter can share more about the compensation and benefits applicable to your preferred location during the hiring process. \n \n \n  Benefits & Perks \n \n Flexible Annual Leave / PTO with an encouraged 20 day per year minimum \n Paid Holiday Week: the last week of the year \n Paid Wellness Week: the first week of July \n $2,000 Yearly Continued Education Reimbursement \n $2,000 Home Office Setup Reimbursement \n Co-working Space Reimbursement \n Company Retreats (2023 in Spain!) & Team Offsites \n Mental Health Support and access to licensed therapists through Spill, 100% paid by Pagoda \n \n Our Values at Pagoda \n  Our values express our company culture. Learn more on our careers page. \n  Pagoda is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, color, religion, national origin, age, disability, veteran status, genetic data, or other legally protected status.", "cleaned_desc": "About Pagoda \n  Pagoda is shepherding a future where NEAR becomes the blockchain operating system. We believe that re-inventing how software is made and distributed is our greatest opportunity to open economic access to those who are not fully integrated into the global economy. Our products empower people to find opportunity, invent new experiences, and collaborate. Let's build an Open Web world. A world where people control their assets, data, and power of governance. \n \n  About The Role \n  The Data Platform team at Pagoda is responsible for the data access infrastructure of NEAR Protocol. We focus on building scalable, performant, and reliable infrastructure to query and access blockchain data that power decentralized applications, such as the NEAR Blockchain Operating System (BOS). \n  What You'll Be Doing \n \n Developing user interfaces and services for software engineers around the world to build decentralized applications on NEAR Protocol; \n Collaboration with a fully distributed team around the world; \n Writing the code, fixing bugs, and participating in design discussions; \n Following the minimal processes, like technical roadmaps, OKRs, milestones, regular team meetings; \n Develop components and applications in public clouds like GCP and AWS;   Participating in on-call rotations; \n Performance optimizations and scalability/reliability improvements. \n \n What We're Looking For \n \n Ability to quickly learn new programming languages and technologies. \n Creativity to come up with proof of concept from high level design while not knowing all the details. \n Experience building highly-interactive user interfaces using React; \n Experience building easy to use and scalable APIs, including REST and GraphQL; \n Ability to write clean yet efficient code in a variety of programming languages and technologies, including TypeScript, Rust, SQL, Python; \n Experience building cloud applications utilizing managed compute and data processing systems; \n Understanding data processing and storage solutions and ability to find balance between cost, performance and scalability.   Effective communication skills to convey your ideas and discuss with team members for technical challenges \n Bachelor's Degree in Computer Science or related fields is a must \n \n We'd Love If You Have \n \n Open source contributions and previous or continued involvement in open source communities; \n Experience setting up continuous integration pipelines, observability tools and metrics; \n Familiarity with Ethereum development and related technologies (web3.js, ethers.js, etc) \n Familiarity with other crypto or blockchain technologies; \n Experience working at a startup. \n \n Here's What Our Interview Process Looks Like ", "techs": ["pagoda", "near", "blockchain operating system", "decentralized applications", "near protocol", "data platform", "user interfaces", "services", "software engineers", "react", "apis", "rest", "graphql", "typescript", "rust", "sql", "python", "cloud applications", "managed compute", "data processing systems", "data processing and storage solutions", "open source contributions", "continuous integration pipelines", "observability tools", "metrics", "ethereum development", "web3.js", "ethers.js", "crypto", "blockchain technologies", "startup"]}, "fb90560733c9dead": {"terms": ["data engineer"], "salary_min": 133742.28, "salary_max": 169347.53, "title": "Data Engineer TS/SCI", "company": "Cyberjin", "desc": "Hybrid/Remote position \n  Looking for a talented Data Engineer to support the acquisition of mission critical and mission support data sets. The preferred candidate will have a background in supporting cyber and/or network related missions within the military spaces, as either a developer, analyst or engineer. Work is mostly on customer site in San Antonio, TX with some hybrid support. \n \n  Essential Job Responsibilities \n  The ideal candidate will have worked with big data systems, complex structured and unstructured data sets, and have supported government data acquisition, analysis, and/or sharing efforts in the past.  \n To excel in the position, the candidate shall have a strong attention to detail, be able to understand technical complexities, and have the willingness to learn and adapt to the situation.  \n The candidate will work both independently and as part of a large team to accomplish client objectives.  \n Minimum Qualifications \n  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata. \n  Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). \n  Ability to decompose technical problems and troubleshoot system and dataflow issues. \n  Must be able to work on customer site most of the time. \n  Preferred Requirements \n  Experience with NOSQL databases such as Accumulo desired \n  Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer. \n   \n nePSLDdjHf", "cleaned_desc": "  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata.    Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). ", "techs": ["security clearance", "ts/sci level security clearance", "u.s. citizen", "python", "java", "acquisition", "network data", "metadata", "data extraction", "data translation", "data loading", "data analytics", "kibana", "elasticsearch", "log formats", "json", "xml", "data flow", "management", "storage solutions", "kafka", "nifi", "aws s3", "aws sqs"]}, "ca53c00ffe157b30": {"terms": ["data engineer"], "salary_min": 55.84, "salary_max": 60.0, "title": "Sr. Data Engineer with Compliance technology", "company": "Datanetiix", "desc": "Role : DATA Engineer + (Cloud or GCP) + Any compliance technology + Actimize \n Compliance Technology \u2013 (AML Transaction Monitoring, CDD, Sanctions Screening etc.) \n Type:  Contract \n Model : Remote \n Type : Onshore \n Duration: 6+ months \n NO OPT , H4 EAD \n Highlighted below are mandatory, need Data Engineer with any of the below compliance technology experience and GCP. \n Experience  : 7 + years \n Domain  - Actimize on Cloud \n Experience in any Compliance Technology ( AML Transaction Monitoring, CDD, Sanctions Screening etc.) \n Experience with Actimize SAM on Cloud is a BIG PLUS or Actimize on Prem \n Experience with any of the core banking platforms - FIS, Mission Lane, Fircosoft \n Experience with GCP/Azure, ETL, Operations Data Store (ODS) \n Must have skills: \n Experience in any Compliance Technology ( AML Transaction Monitoring, CDD, Sanctions Screening etc.) \n Experience with Actimize SAM on Cloud is a BIG PLUS or Actimize on Prem \n Nice to have skills: \n Experience with GCP/Azure, ETL, Operations Data Store (ODS) \n Experience with any of the core banking platforms - FIS, Mission Lane, Fircosoft \n Job Type: Contract \n Pay: $55.84 - $60.00 per hour \n Experience level: \n \n 7 years \n \n Experience: \n \n Compliance management: 6 years (Preferred) \n FIS: 6 years (Preferred) \n Google Cloud Platform: 6 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Experience with any of the core banking platforms - FIS, Mission Lane, Fircosoft \n Experience with GCP/Azure, ETL, Operations Data Store (ODS) \n Must have skills: \n Experience in any Compliance Technology ( AML Transaction Monitoring, CDD, Sanctions Screening etc.) \n Experience with Actimize SAM on Cloud is a BIG PLUS or Actimize on Prem \n Nice to have skills: ", "techs": ["fis", "mission lane", "fircosoft", "gcp/azure", "etl", "operations data store (ods)", "aml transaction monitoring", "cdd", "sanctions screening", "actimize sam"]}, "1e12e3f33e9c0646": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 102027.31, "salary_max": 129189.31, "title": "Data Engineer/Architect - Tableau", "company": "The Infosoft Group", "desc": "Codeworks is an IT Services firm in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships.  \n \n Who We're Looking For !...  \n A Data Engineer / Architect! For a 100% Remote long term contract role! \n   \n Summary \n  We're looking for an outstanding Data Engineer / Architect who has knowledge and passion about data in investment and Wealth management domain; who love working with data at scale; and are committed to innovation and continuous improvement. \n  As a part of the Data Engineering group, you will work with building data engineering pipelines daily using diverse technologies mainly IICS, snowflake on AWS eco system. You will be using your soft skills to optimally partner with upstream engineering teams and downstream analytical, ML and product consumers. \n \n  Description    Partner closely with machine learning engineers, data scientists, analysts, software engineers and researchers to build reliable, distributed data infrastructure and intuitive data products that feed into machine learning models, analytics, research, thereby allowing our partners to easily leverage data in a self-served manner. Educate your consumers on how to access your model, assuring transparency in logic definitions. This is a heads-down position, perfect for someone who likes to get a lot done! \n \n \n  Key Qualifications \n \n  -3-5 years of Data Engineering experience.\n   \n \n Deep knowledge of distributed data storage, processing, and serving technologies. \n Extensive hands-on experiences in design and application of mainstream data infrastructure offerings (Snowflake, IICS, Python, SQL, AWS RDS etc). \n Experience in schema design and Dimensional data modeling. Be able to analyze and explore data, identify patterns and draw insights. \n \n \n \n Proficiency in following languages: Python, SQL and Java demonstrating strong background in algorithms and data structures is a must. \n Ability to architect Loosely coupled data solutions using API, streaming and other design patterns would be deemed advantageous. \n \n \n \n Ability to work in a multi-functional environment across multiple stakeholders and convert abstract requirements into concrete technical deliverables. \n Creativity and curiosity for solving complex problems. \n \n   \n Local candidates to Milwaukee area will be given priority.  If you feel that you meet the qualifications listed above, please forward your resume in Word format  to  . \n   \n About CODEWORKS :  \n Headquartered in Milwaukee, WI with an office in Madison, WI-Codeworks has over 25+ years of experience serving Fortune 1000 companies in Wisconsin as well as our client's national locations. Our recruiting team is extremely good at evaluating, advising, and connecting IT professionals with new opportunities that will satisfy their expectations both in salary and opportunity for growth. \n  For more information \n   \n For priority career/job posting updates, please follow us on Twitter: @CodeworksIT \n   \n #LI-KH \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Codeworks, L.L.C. \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   3 to 5 years", "cleaned_desc": "Codeworks is an IT Services firm in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships.  \n \n Who We're Looking For !...  \n A Data Engineer / Architect! For a 100% Remote long term contract role! \n   \n Summary \n  We're looking for an outstanding Data Engineer / Architect who has knowledge and passion about data in investment and Wealth management domain; who love working with data at scale; and are committed to innovation and continuous improvement. \n  As a part of the Data Engineering group, you will work with building data engineering pipelines daily using diverse technologies mainly IICS, snowflake on AWS eco system. You will be using your soft skills to optimally partner with upstream engineering teams and downstream analytical, ML and product consumers. \n \n  Description    Partner closely with machine learning engineers, data scientists, analysts, software engineers and researchers to build reliable, distributed data infrastructure and intuitive data products that feed into machine learning models, analytics, research, thereby allowing our partners to easily leverage data in a self-served manner. Educate your consumers on how to access your model, assuring transparency in logic definitions. This is a heads-down position, perfect for someone who likes to get a lot done! \n \n \n  Key Qualifications \n \n  -3-5 years of Data Engineering experience.    \n \n Deep knowledge of distributed data storage, processing, and serving technologies. \n Extensive hands-on experiences in design and application of mainstream data infrastructure offerings (Snowflake, IICS, Python, SQL, AWS RDS etc). \n Experience in schema design and Dimensional data modeling. Be able to analyze and explore data, identify patterns and draw insights. \n \n \n \n Proficiency in following languages: Python, SQL and Java demonstrating strong background in algorithms and data structures is a must. \n Ability to architect Loosely coupled data solutions using API, streaming and other design patterns would be deemed advantageous. \n \n \n \n Ability to work in a multi-functional environment across multiple stakeholders and convert abstract requirements into concrete technical deliverables. \n Creativity and curiosity for solving complex problems. ", "techs": ["iics", "snowflake", "aws", "python", "sql", "aws rds", "java"]}, "1c2b6963327435f1": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 142004.61, "salary_max": 179809.48, "title": "Senior Software Engineer II, Clinical Data Pipeline (Remote)", "company": "Freenome", "desc": "This position is open to remote within the US or onsite at our headquarters in South San Francisco. \n  Why join Freenome? \n  Freenome is a high-growth biotech company developing tests to detect cancer using a standard blood draw. To do this, Freenome uses a multiomics platform that combines tumor and non-tumor signals with machine learning to find cancer in its earliest, most-treatable stages. \n  Cancer is relentless. This is why Freenome is building the clinical, economic, and operational evidence to drive cancer screening and save lives. Our first screening test is for colorectal cancer (CRC) and advanced adenomas, and it's just the beginning. \n  Founded in 2014, Freenome has ~500 employees and more than $1.1B in funding from key investors, such as the American Cancer Society, Andreessen Horowitz, Anthem Blue Cross, Bain Capital, Colorectal Cancer Alliance, DCVC, Fidelity, Google Ventures, Kaiser Permanente, Novartis, Perceptive Advisors, RA Capital, Roche, Sands Capital, T. Rowe Price, and Verily. \n  At Freenome, we aim to impact patients by empowering everyone to prevent, detect, and treat their disease. This, together with our high-performing culture of respect and cross-collaboration, is what motivates us to make every day count. \n  Become a Freenomer \n  Do you have what it takes to be a Freenomer? A \"Freenomer\" is a determined, mission-driven, results-oriented employee fueled by the opportunity to change the landscape of cancer and make a positive impact on patients' lives. Freenomers bring their diverse experience, expertise, and personal perspective to solve problems and push to achieve what's possible, one breakthrough at a time. \n  About this opportunity: \n  At Freenome, we are seeking a Senior Software Engineer to play a lead role in supporting the ingestion of Clinical Data through our data pipelines. Using our existing tooling, and working collaboratively with our Clinical Development, Informatics, Research and engineering teams, you will help plan, configure, troubleshoot and monitor our clinical data ingestion. You will also contribute to fixing and enhancing the pipeline tooling. \n  To succeed in this position, you should have strong analytical and communication skills, be detail-oriented, and have excellent organizational skills. You will have experience with data technologies, python, docker and kubernetes and are passionate about data quality. \n  The role reports to our engineering management team. \n  What you'll do: \n \n Work with scientists, product managers, and other engineers to solve complex problems in the face of dynamism and uncertainty \n Support and enhance tools and infrastructure that enables internal teams to effectively create efficient data-pipelines \n Collaborate with team members for code and design review \n Lead and champion data engineering best practices and team culture as a core part of the engineering backbone \n \n Must haves: \n \n 6+ years of experience as a part of a software engineering team successfully shipping one or more data pipelines used by multiple people or groups \n Expertise in Data Analysis \n Expertise with a scripting language: Python, Javascript, Ruby, Scala, Go, etc. \n Extensive knowledge of Redshift, BigQuery, or similar technologies \n Expertise with a variety of data stores: SQL, noSQL, columnar, timeseries, etc. \n Demonstrated experience with handling and transforming large multivariate datasets via ETL pipelines \n Experience in Kubernetes and Docker \n Strong analytical/troubleshooting skills \n Experience in Google Cloud Platform, AWS, or Azure \n Previous experience leading teams or managing projects  \n Experience designing and implementing scalable data systems \n Excellent written and verbal communication skills \n The ability to thrive in an environment where collaboration, communication, and compromise are an expected part of your day-to-day work \n A mindful, transparent, and humane approach to your work and your interactions with others \n BS or higher in computer science or a related technical field, or comparable \n \n Nice to haves: \n \n Experience with Grafana, Prometheus, or similar tools \n Data Visualization experience \n Experience with healthcare data/PII \n \n Benefits and additional information: \n  The US target range of our base salary rate for new hires is $157,000 - $240,000. You will also be eligible to receive pre-IPO equity, cash bonuses, and a full range of medical, financial, and other benefits dependent on the position offered. Please note that individual total compensation for this position will be determined at the Company's sole discretion and may vary based on several factors, including but not limited to, location, skill level, years and depth of relevant experience, and education. We invite you to check out our career page @ https://careers.freenome.com/ for additional company information. \n  Freenome is proud to be an equal opportunity employer and we value diversity. Freenome does not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. \n  Applicants have rights under Federal Employment Laws. \n \n Family & Medical Leave Act (FMLA) \n Equal Employment Opportunity (EEO) \n Employee Polygraph Protection Act (EPPA) \n \n #LI-Remote", "cleaned_desc": "  To succeed in this position, you should have strong analytical and communication skills, be detail-oriented, and have excellent organizational skills. You will have experience with data technologies, python, docker and kubernetes and are passionate about data quality. \n  The role reports to our engineering management team. \n  What you'll do: \n \n Work with scientists, product managers, and other engineers to solve complex problems in the face of dynamism and uncertainty \n Support and enhance tools and infrastructure that enables internal teams to effectively create efficient data-pipelines \n Collaborate with team members for code and design review \n Lead and champion data engineering best practices and team culture as a core part of the engineering backbone \n \n Must haves:   \n 6+ years of experience as a part of a software engineering team successfully shipping one or more data pipelines used by multiple people or groups \n Expertise in Data Analysis \n Expertise with a scripting language: Python, Javascript, Ruby, Scala, Go, etc. \n Extensive knowledge of Redshift, BigQuery, or similar technologies \n Expertise with a variety of data stores: SQL, noSQL, columnar, timeseries, etc. \n Demonstrated experience with handling and transforming large multivariate datasets via ETL pipelines \n Experience in Kubernetes and Docker \n Strong analytical/troubleshooting skills \n Experience in Google Cloud Platform, AWS, or Azure   Previous experience leading teams or managing projects  \n Experience designing and implementing scalable data systems \n Excellent written and verbal communication skills \n The ability to thrive in an environment where collaboration, communication, and compromise are an expected part of your day-to-day work \n A mindful, transparent, and humane approach to your work and your interactions with others \n BS or higher in computer science or a related technical field, or comparable \n \n Nice to haves: \n \n Experience with Grafana, Prometheus, or similar tools ", "techs": ["data technologies", "python", "docker", "kubernetes", "redshift", "bigquery", "sql", "nosql", "columnar", "timeseries", "etl pipelines", "kubernetes", "docker", "google cloud platform", "aws", "azure", "grafana", "prometheus"]}, "439e4725caf19b11": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 103793.69, "salary_max": 131425.94, "title": "Data Engineer/Architect", "company": "The Infosoft Group", "desc": "Codeworks is an IT Services firm in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships.  \n \n Who We're Looking For !...  \n A Data Engineer / Architect! For a 100% Remote long term contract role! \n   \n Summary \n  We're looking for an outstanding Data Engineer / Architect who has knowledge and passion about data in investment and Wealth management domain; who love working with data at scale; and are committed to innovation and continuous improvement. \n  As a part of the Data Engineering group, you will work with building data engineering pipelines daily using diverse technologies mainly IICS, snowflake on AWS eco system. You will be using your soft skills to optimally partner with upstream engineering teams and downstream analytical, ML and product consumers. \n \n  Description      Partner closely with machine learning engineers, data scientists, analysts, software engineers and researchers to build reliable, distributed data infrastructure and intuitive data products that feed into machine learning models, analytics, research, thereby allowing our partners to easily leverage data in a self-served manner. Educate your consumers on how to access your model, assuring transparency in logic definitions. This is a heads-down position, perfect for someone who likes to get a lot done! \n \n \n  Key Qualifications \n \n   \n  -3-5 years of Data Engineering experience.\n   \n \n Deep knowledge of distributed data storage, processing, and serving technologies. \n Extensive hands-on experiences in design and application of mainstream data infrastructure offerings (Snowflake, IICS, Python, SQL, AWS RDS etc). \n Experience in schema design and Dimensional data modeling. Be able to analyze and explore data, identify patterns and draw insights. \n \n \n \n Proficiency in following languages: Python, SQL and Java demonstrating strong background in algorithms and data structures is a must. \n Ability to architect Loosely coupled data solutions using API, streaming and other design patterns would be deemed advantageous. \n \n \n \n Ability to work in a multi-functional environment across multiple stakeholders and convert abstract requirements into concrete technical deliverables. \n Creativity and curiosity for solving complex problems. \n \n   \n Local candidates to Milwaukee area will be given priority.  If you feel that you meet the qualifications listed above, please forward your resume in Word format  to  . \n   \n About CODEWORKS :  \n Headquartered in Milwaukee, WI with an office in Madison, WI-Codeworks has over 25+ years of experience serving Fortune 1000 companies in Wisconsin as well as our client's national locations. Our recruiting team is extremely good at evaluating, advising, and connecting IT professionals with new opportunities that will satisfy their expectations both in salary and opportunity for growth. \n  For more information \n   \n For priority career/job posting updates, please follow us on Twitter: @CodeworksIT \n   \n #LI-KH \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Codeworks, L.L.C. \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   3 to 5 years", "cleaned_desc": "Codeworks is an IT Services firm in SE Wisconsin, known for our strong commitment to quality and for our direct client relationships.  \n \n Who We're Looking For !...  \n A Data Engineer / Architect! For a 100% Remote long term contract role! \n   \n Summary \n  We're looking for an outstanding Data Engineer / Architect who has knowledge and passion about data in investment and Wealth management domain; who love working with data at scale; and are committed to innovation and continuous improvement. \n  As a part of the Data Engineering group, you will work with building data engineering pipelines daily using diverse technologies mainly IICS, snowflake on AWS eco system. You will be using your soft skills to optimally partner with upstream engineering teams and downstream analytical, ML and product consumers. \n \n  Description      Partner closely with machine learning engineers, data scientists, analysts, software engineers and researchers to build reliable, distributed data infrastructure and intuitive data products that feed into machine learning models, analytics, research, thereby allowing our partners to easily leverage data in a self-served manner. Educate your consumers on how to access your model, assuring transparency in logic definitions. This is a heads-down position, perfect for someone who likes to get a lot done! \n \n \n  Key Qualifications \n \n      -3-5 years of Data Engineering experience.\n   \n \n Deep knowledge of distributed data storage, processing, and serving technologies. \n Extensive hands-on experiences in design and application of mainstream data infrastructure offerings (Snowflake, IICS, Python, SQL, AWS RDS etc). \n Experience in schema design and Dimensional data modeling. Be able to analyze and explore data, identify patterns and draw insights. \n \n \n \n Proficiency in following languages: Python, SQL and Java demonstrating strong background in algorithms and data structures is a must. \n Ability to architect Loosely coupled data solutions using API, streaming and other design patterns would be deemed advantageous. \n \n \n \n Ability to work in a multi-functional environment across multiple stakeholders and convert abstract requirements into concrete technical deliverables. ", "techs": ["codeworks", "iics", "snowflake", "aws rds", "python", "sql", "java"]}, "e2f772349b51788e": {"terms": ["data engineer"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Data Architecture (Remote Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Distinguished Engineer, Data Architecture (Remote Eligible)\n  \n  Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions. \n \n  Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices \n  Visionaries, collaborating on Capital One\u2019s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates \n  Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community \n  Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities \n \n \n  Responsibilities: \n \n  Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in \n  Strike the right balance between lending expertise and providing an inclusive environment where others\u2019 ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team \n  Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible \n  Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization \n  Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner \n  Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One\u2019s Tech talent \n \n \n  Capital One is open to hiring a remote employee for this position. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s Degree \n  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS \n  3+ years of experience working with Big Data \n \n \n   \n Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS ", "techs": ["python", "java", "scala", "aws"]}, "b8736d2ed0b45ce8": {"terms": ["data engineer"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Data Architecture (Remote Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Distinguished Engineer, Data Architecture (Remote Eligible)\n  \n  Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions. \n \n  Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices \n  Visionaries, collaborating on Capital One\u2019s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates \n  Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community \n  Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities \n \n \n  Responsibilities: \n \n  Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in \n  Strike the right balance between lending expertise and providing an inclusive environment where others\u2019 ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team \n  Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible \n  Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization \n  Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner \n  Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One\u2019s Tech talent \n \n \n  Capital One is open to hiring a remote employee for this position. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s Degree \n  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS \n  3+ years of experience working with Big Data \n \n \n   \n Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS ", "techs": ["python", "java", "scala", "aws"]}, "3790fb61896bf574": {"terms": ["data engineer"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Data Architecture (Remote Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Distinguished Engineer, Data Architecture (Remote Eligible)\n  \n  Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions. \n \n  Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices \n  Visionaries, collaborating on Capital One\u2019s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates \n  Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community \n  Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities \n \n \n  Responsibilities: \n \n  Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in \n  Strike the right balance between lending expertise and providing an inclusive environment where others\u2019 ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team \n  Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible \n  Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization \n  Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner \n  Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One\u2019s Tech talent \n \n \n  Capital One is open to hiring a remote employee for this position. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s Degree \n  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS \n  3+ years of experience working with Big Data \n \n \n   \n Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS ", "techs": ["python", "java", "scala", "aws"]}, "fc1b0b49b087accc": {"terms": ["data engineer"], "salary_min": 104903.87, "salary_max": 132831.67, "title": "Data Engineer \u2013 REMOTE WORK 45734", "company": "PRIMUS Global Services, Inc", "desc": "We have an urgent long-term opening with one of our major clients for a position of Data Engineer, to work on a remote basis. \n As a Data Engineer, you will be at the forefront of our data initiatives, responsible for designing, building, and optimizing our data infrastructure. \n To be successful in this role, the ideal candidate should possess the following qualifications and skills: \n \n  5-7+ years of proven experience as a Data Engineer in the consumer finance or a related industry. Strong educational background in math, statistics, computer science, data science, or a related discipline. Advanced proficiency in at least one of the following languages: Java, Scala, Python, C#. Production experience with a wide range of data technologies, including HDFS, YARN, Hive, Spark, Kafka, Oozie / Airflow, AWS, Docker / Kubernetes, and Snowflake. Familiarity with data mining and programming tools such as SAS, SQL, R, and Python. Experience with database technologies like PostgreSQL, Redshift, Snowflake, and Greenplum. Knowledge of data visualization tools such as Tableau, Looker, or MicroStrategy. \n  \n **ALL successful candidates for this position are required to work directly for PRIMUS. No agencies please only W-2**    For immediate consideration, please contact: \n Hemant   PRIMUS Global Services  Direct: 972-471-9489  Desk: 972-753-6500 Ext: 404  Email: jobs@primusglobal.com", "cleaned_desc": "  5-7+ years of proven experience as a Data Engineer in the consumer finance or a related industry. Strong educational background in math, statistics, computer science, data science, or a related discipline. Advanced proficiency in at least one of the following languages: Java, Scala, Python, C#. Production experience with a wide range of data technologies, including HDFS, YARN, Hive, Spark, Kafka, Oozie / Airflow, AWS, Docker / Kubernetes, and Snowflake. Familiarity with data mining and programming tools such as SAS, SQL, R, and Python. Experience with database technologies like PostgreSQL, Redshift, Snowflake, and Greenplum. Knowledge of data visualization tools such as Tableau, Looker, or MicroStrategy. ", "techs": ["java", "scala", "python", "c#", "hdfs", "yarn", "hive", "spark", "kafka", "oozie", "airflow", "aws", "docker", "kubernetes", "snowflake", "sas", "sql", "r", "postgresql", "redshift", "greenplum", "tableau", "looker", "microstrategy"]}, "14bfa15bf1309611": {"terms": ["data engineer"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Data Architecture (Remote Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Distinguished Engineer, Data Architecture (Remote Eligible)\n  \n  Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions. \n \n  Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices \n  Visionaries, collaborating on Capital One\u2019s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates \n  Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community \n  Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities \n \n \n  Responsibilities: \n \n  Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in \n  Strike the right balance between lending expertise and providing an inclusive environment where others\u2019 ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team \n  Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible \n  Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization \n  Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner \n  Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One\u2019s Tech talent \n \n \n  Capital One is open to hiring a remote employee for this position. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s Degree \n  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS \n  3+ years of experience working with Big Data \n \n \n   \n Capital One will consider sponsoring a new qualified applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  At least 7 years of Data Architecture or Enterprise Architecture experience \n  At least 5 years of experience in database management and data warehousing \n  At least 3 years of experience in solution design \n  At least 2 years of experience building real-time data products \n \n \n  Preferred Qualifications: \n \n  Masters\u2019 Degree \n  5+ years of experience developing in Python, Java, or Scala \n  8+ years experience architecting and delivering software systems or platforms \n  8+ years of data governance, data access, data lineage, data monitoring, and security controls experience \n  3+ years of experience with AWS ", "techs": ["python", "java", "scala", "aws"]}, "b803f9bc48c42262": {"terms": ["machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n BrDfv8muV3", "cleaned_desc": "", "techs": ""}, "0bcac22de6e21461": {"terms": ["machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Job description: \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n UvbWI4LCQN", "cleaned_desc": "", "techs": ""}, "eb7d256814a70d7c": {"terms": ["machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Ideal candidate traits: \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n \n   \n   \n 75RA3Autp8", "cleaned_desc": "", "techs": ""}, "e9de2a8dcc120293": {"terms": ["machine learning engineer"], "salary_min": 80000.0, "salary_max": 95000.0, "title": "Technical Support Engineer II", "company": "Arkestro", "desc": "Founded in 2017, Arkestro is a rapidly-growing early-stage startup that is transforming the way every company in the world does Procurement. Our platform leverages state-of-the-art machine learning methodologies, combined with game theory and behavioral science, to enable top global enterprises to manage their spend. By optimizing transactions and providing deep insight into spend data at a massive scale, our customers are able to mitigate supply chain risk, increase efficiency, and achieve best-in-class cost savings without increasing headcount.\n   \n \n \n \n   Join Arkestro on our journey to revolutionize procurement! Although we are a small startup, we have big dreams and potential. Our customers are some of the most successful and recognized large enterprise organizations in North America. We are seeking passionate individuals to work with our talented team to make an impact on our customer\u2019s lives. If you are a creative problem solver looking for a challenge, or just want to shake up the procurement world, apply now! See Arkestro in action at arkestro.com.\n   \n \n About this Role \n  The Technical Support Engineer II will report to the Director of Customer Support and will be responsible for resolving incoming issues reported by our customers related to their use of the Arkestro platform and for working directly with customers to promote their ongoing optimal use of the Arkestro platform. This person will be responsible for inbound email, chat, and phone support to maintain defined service levels and to ensure customers are productive and happy. \n  This position requires that your core hours will be Pacific Time - this could be either 9 am to 6 pm Pacific, or 10 am to 7 pm Pacific. \n  Responsibilities \n \n Respond to, troubleshoot, and resolve incoming technical and application support issues from customers \n Record and track customer issues with ticketing system \n Receiving incoming calls, chats and emails from customers during US Pacific Time hours. \n Develop strong relationships with customers and a deep understanding of their individual needs and use-cases \n Develop deep understanding of the Arkestro application including both the supplier and the procurement team experiences \n Develop and knowledge and appreciation of procurement as a business function \n Escalate and track resolution of customer issues \n Suggest and implement new procedures to improve customer service \n Create new and improved knowledge articles to reduce support cases \n Update knowledge and skills for changes with new product functionality \n Use customer relationship management software (CRM) and other tools to document customer interactions \n Share on-call rotation responsibilities for occasional 24x7 after-hours support escalations \n \n Qualifications \n \n You love people and you are authentically passionate about customer service \n You are located anywhere in the U.S. and you will work during Pacific Time (9 am to 6 pm Pacific, or 10 am to 7 pm Pacific) \n You have at least 2 years of experience working in a technical, customer-facing role supporting cloud-based/SaaS technology in a B2B environment \n You understand and genuinely care about common support metrics, best practices, and related success factors \n You have an understanding of SaaS/web application technologies (HTML, JS, CSS) \n You are experienced in writing clear replication steps to reproduce customer issue and facilitate escalations \n You have strong written and verbal communication skills \n You have proven problem solving abilities, including documenting and communicating solutions or workarounds \n You excel at collaborating both internally and externally to resolve customer issues in a timely and effective manner \n You enjoying learning and taking on new challenges \n \n Qualities of the Ideal Candidate \n \n Experience in a fast-paced, high-growth startup environment \n Familiarity with technical escalations (prioritization, replication steps, issue tracking) \n Preference for at least 1 or more years of experience with procurement/supply chain \n Microsoft Excel skills with ability to create, enhance, organize, and present data \n Familiarity with customer service quality metrics like NPS, CSAT, FCR, FRT, AHT, etc. \n Working knowledge of business processes, workflows and organizational structures \n \n \n \n \n    Pay Range\n    \n \n     $80,000\u2014$95,000 USD\n    \n \n \n \n \n Arkestro is committed to providing our employees with a benefits package designed to give you the flexibility you need to ensure a healthy life/work balance. Arkestro offers our employees great benefits and perks, including, but not limited to: \n \n Competitive salary and startup equity \n Health Benefits \n \n The option to have 100% paid medical and vision plan for you AND your dependents \n Dental Insurance \n \n Generous 401K matching \n Unlimited PTO \n We are highly supportive of flexible work hours \n We are a remote-first team, but we like to get together for team building, design sprints, and customer visits \n A one time budget of $1,500 for home office supplies \n Annual budget of $1,000 for learning and development \n Diverse, inclusive, highly collaborative, and vibrant culture \n \n \n \n   Arkestro is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.\n   \n \n \n Disclaimer \n \n  Please note this job description may not be inclusive of all assigned duties, responsibilities, or aspects of the job described and that additional tasks may be assigned to the employee from time to time; or the scope of the job may change as necessitated by business demands. Arkestro reserves the right to change duties, responsibilities and activities at any time with or without notice.", "cleaned_desc": " You have an understanding of SaaS/web application technologies (HTML, JS, CSS) \n You are experienced in writing clear replication steps to reproduce customer issue and facilitate escalations \n You have strong written and verbal communication skills \n You have proven problem solving abilities, including documenting and communicating solutions or workarounds \n You excel at collaborating both internally and externally to resolve customer issues in a timely and effective manner \n You enjoying learning and taking on new challenges \n \n Qualities of the Ideal Candidate \n \n Experience in a fast-paced, high-growth startup environment \n Familiarity with technical escalations (prioritization, replication steps, issue tracking) \n Preference for at least 1 or more years of experience with procurement/supply chain \n Microsoft Excel skills with ability to create, enhance, organize, and present data \n Familiarity with customer service quality metrics like NPS, CSAT, FCR, FRT, AHT, etc. \n Working knowledge of business processes, workflows and organizational structures \n ", "techs": ["html", "js", "css", "microsoft excel"]}, "f258a7c1a846e681": {"terms": ["machine learning engineer"], "salary_min": 105000.0, "salary_max": 160000.0, "title": "Computer Vision Engineer", "company": "Animantis LLC", "desc": "Animantis is a multidisciplinary startup seeking a Computer Vision/Machine Learning (CVML) engineer to help develop cell microscopy solutions in partnership with top pharmaceutical companies and academic institutions. CVML Engineers are core contributors at Animantis and can work end-to-end on a variety of vision-specific projects involving detailed object detection and tracking, as well as the recognition and quantification of specific behaviors of interest. The ideal candidate should have experience developing and optimizing custom vision models for production environments using common Python ML libraries such as PyTorch, Tensorflow, or Caffe2. \n At Animantis, your work will have an immense impact on the world of research and medicine, facilitating the development and validation of new treatments and diagnostic tools for a variety of diseases. Each project comes with a unique set of exciting challenges and requires engineers who excel in environments that demand creative thinking and dynamic problem-solving. If this sounds like you, apply today to join our team and help change the landscape of the biotech industry. \n Responsibilities \n \n Work within a multidisciplinary team of scientists and engineers to develop software solutions for a wide range of microscopy and cell biology systems \n Develop custom ML models (e.g., RNNs and CNNs) to detect and track cells in a variety of images and videos \n Build CVML pipelines from ideation through prototyping, development, and deployment \n Adapt generalized cell tracking solutions for specific customer use cases \n Remain current on new techniques and technologies in the CV space to evaluate their suitability for application in new and existing projects \n Collaborate in a fully remote environment using tools like Slack and Git \n \n We offer a comprehensive and competitive compensation package, including: \n \n Competitive salary \n 100%-covered Health/dental/vision insurance for employees and dependents \n 401(k) with employer contribution matching \n Flexible PTO \n A 100% remote work environment with emphasis on a protected work/life balance \n \n Applicants must reside in the US. Though education is considered, all applications will ultimately be evaluated based on their experience and aptitude in the following areas: \n \n Expertise with traditional CV approaches (e.g., OpenCV) \n Visual object tracking in crowded visual systems \n Applying Deep Learning models to unique vision problems using modern tools such as PyTorch, Tensorflow, or Caffe2 \n Building, testing, and deploying CV-based solutions, ideally on a Cloud service such as AWS \n \n Job Type: Full-time \n Pay: $105,000.00 - $160,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n People with a criminal record are encouraged to apply \n Education: \n \n Bachelor's (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Animantis is a multidisciplinary startup seeking a Computer Vision/Machine Learning (CVML) engineer to help develop cell microscopy solutions in partnership with top pharmaceutical companies and academic institutions. CVML Engineers are core contributors at Animantis and can work end-to-end on a variety of vision-specific projects involving detailed object detection and tracking, as well as the recognition and quantification of specific behaviors of interest. The ideal candidate should have experience developing and optimizing custom vision models for production environments using common Python ML libraries such as PyTorch, Tensorflow, or Caffe2. \n At Animantis, your work will have an immense impact on the world of research and medicine, facilitating the development and validation of new treatments and diagnostic tools for a variety of diseases. Each project comes with a unique set of exciting challenges and requires engineers who excel in environments that demand creative thinking and dynamic problem-solving. If this sounds like you, apply today to join our team and help change the landscape of the biotech industry. \n Responsibilities \n \n Work within a multidisciplinary team of scientists and engineers to develop software solutions for a wide range of microscopy and cell biology systems \n Develop custom ML models (e.g., RNNs and CNNs) to detect and track cells in a variety of images and videos \n Build CVML pipelines from ideation through prototyping, development, and deployment \n Adapt generalized cell tracking solutions for specific customer use cases \n Remain current on new techniques and technologies in the CV space to evaluate their suitability for application in new and existing projects ", "techs": ["animantis", "computer vision", "machine learning", "cvml engineer", "cell microscopy", "pharmaceutical companies", "academic institutions", "object detection", "tracking", "recognition", "quantification", "python", "pytorch", "tensorflow", "caffe2", "research", "medicine", "treatments", "diagnostic tools", "diseases", "software solutions", "microscopy", "cell biology systems", "ml models", "rnns", "cnns", "images", "videos", "pipelines", "prototyping", "development", "deployment", "cell tracking", "customer use cases", "cv space", "techniques", "technologies"]}, "aec5f357fe1b5fa7": {"terms": ["machine learning engineer"], "salary_min": 79800.0, "salary_max": 79800.0, "title": "IT Developer Analyst- Virtual", "company": "The Infosoft Group", "desc": "Our story \n  At Alight, we believe a company's success starts with its people. At our core, we Champion People, help our colleagues Grow with Purpose and true to our name we encourage colleagues to \"Be Alight.\" \n \n  Our Values: \n  Champion People  - be empathetic and help create a place where everyone belongs. \n  Grow with purpose -  Be inspired by our higher calling of improving lives. \n  Be Alight -  act with integrity, be real and empower others. \n \n  It's why we're so driven to connect passion with purpose. Our team's expertise in human insights and cloud technology gives companies and employees around the world the ability to power confident decisions, for life.  \n \n With a comprehensive total rewards package, continuing education and training, and tremendous potential with a growing global organization, Alight is the perfect place to put your passion to work. \n \n  Join our team if you Champion People, want to Grow with Purpose through acting with integrity and if you embody the meaning of Be Alight. \n \n  Learn more at careers.alight.com. \n \n  What You'll Do: \n \n  Understands best practices in software engineering, data management, data storage, data compute, and distributed systems. \n  Apply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and BI self-service. \n  Focuses on automation and optimization for all areas of DW/ETL maintenance and deployment. \n  Comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadership. \n  Design, develop, and operate highly scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologies. \n  Adopt next-generation data architecture strategies, proposing both data flows and storage solutions. \n  Collaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning models. \n  Build, analyze and present actionable data to drive marketing business development and product management decisions. \n  Keep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architecture. \n  Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation. \n \n \n  What We Offer: \n \n  Acompetitivetotal rewards package, continuing education & training, and tremendous potential with agrowingworldwide organization: \n  A full Benefits Package, starting on your first day of employment \n  Health, Dental, Vision, Life Insurance and more. \n  A 401k plan that includes a corporate match. \n  Paid Time Off \n  Three weeks (15 days) of paid vacation \n  Ten paid holidays per calendar year (8 fixed and 2 floating) \n  6 paid wellness days \n  Career Development & Growth: We provide ongoing training, coaching and development. We reward continuous improvement and encourage you to own your own development. Take advantage of some of the best training and tools in the world to learn more about multiple areas of Human Resources! \n \n \n  What You'll Need: \n \n  4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as S3, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies. \n  Prefer prior experience on Hadoop especially Cloudera Data Platform (CDP). \n  Proficiency in one of the scripting languages such as Shell, Python, Scala, Java. \n  Good understanding of Big Data technology trends, with knowledge of technologies such as Kafka, Spark, Hive, pySpark. \n  Experience in version control systems such as Git, GitLab, etc. \n  Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certification. \n  Experience with Big Data technologies e.g. Hadoop, Spark, Scala, and solutions in AWS/Azure. \n  Proficiency in Python and SQL. \n  Strong understanding of scaling, performance and scheduling, batch and streaming data architecture. \n  Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations. \n  Experience on data platform re-architecture projects or handling operational excellence in DW via automation. \n  Experience communicating with management as well as with colleagues from engineering, analytics, and business backgrounds. \n  Strong technical and analytical aptitude; Excellent oral and written communication skills \n \n \n  Flexible Working  \n \n So that you can be your best at work and home, we consider flexible working arrangements wherever possible. Alight has been a leader in the flexible workspace and \"Top 100 Company for Remote Jobs\" 5 years in a row. \n \n  Benefits \n  We offer programs and plans for a healthy mind, body, wallet and life because it's important our benefits care for the whole person. Options include a variety of health coverage options, wellbeing and support programs, retirement, vacation and sick leave, maternity, paternity & adoption leave, continuing education and training as well as a number of voluntary benefit options.  \n \n Our commitment to Diversity and Inclusion \n \n  Alight is committed to diversity, equity, and inclusion. We celebrate differences and believe in fostering an environment where everyone feels valued, respected, and supported. We know that diverse teams are stronger, more innovative, and more successful. \n \n  At Alight, we welcome and embrace all individuals, regardless of their background, and are dedicated to creating a culture that enables every employee to thrive. Join us in building a brighter, more inclusive future. \n \n  Diversity Policy Statement \n  Alight is an Equal Employment Opportunity employer and does not discriminate against anyone based on sex, race, color, religion, creed, national origin, ancestry, age, physical or mental disability, medical condition, pregnancy, marital or domestic partner status, citizenship, military or veteran status, sexual orientation, gender, gender identity or expression, genetic information, or any other legally protected characteristics or conduct covered by federal, state or local law. In addition, we take affirmative action to employ and advance in the employment of qualified minorities, women, disabled persons, disabled veterans and other covered veterans. \n \n  Alight provides reasonable accommodations to the known limitations of otherwise qualified employees and applicants for employment with disabilities and sincerely held religious beliefs, practices and observances, unless doing so would result in undue hardship. Applicants for employment may request a reasonable accommodation/modification by contacting his/her recruiter. \n \n  #LI-Remote \n  P&T \n  We offer you a competitive total rewards package, continuing education & training, and tremendous potential with a growing worldwide organization. \n  Pay Transparency Statement: Alight takes into consideration a candidate's experience, education, certification/credentials, market data, internal equity, and geography when determining an offer for a successful employment candidate, and Alight does so on an individualized, non-discriminatory basis. Therefore, an offer may fall anywhere between the estimated minimum base salary for this role of $79,800.00/year (for full time employees) and the estimated maximum base salary for this role of $140,000.00/year (for full-time employees). Alight also offers a comprehensive benefits package; for specific details on our benefits package, please visit: https://careers.alight.com/us/en/alight-us-benefits-2023\n   DISCLAIMER: \n  Nothing in this job description restricts management's right to assign or reassign duties and responsibilities of this job to other entities; including but not limited to subsidiaries, partners, or purchasers of Alight business units.  Alight Solutions provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, genetic information, pregnancy, childbirth or related medical condition, veteran, marital, parental, citizenship, or domestic partner status, or any other status protected by applicable national, federal, state or local law. Alight Solutions is committed to a diverse workforce and is an affirmative action employer.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Alight Solutions \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   4+ years", "cleaned_desc": "  Collaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning models. \n  Build, analyze and present actionable data to drive marketing business development and product management decisions. \n  Keep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architecture. \n  Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation. \n \n \n  What We Offer: \n \n  Acompetitivetotal rewards package, continuing education & training, and tremendous potential with agrowingworldwide organization: \n  A full Benefits Package, starting on your first day of employment \n  Health, Dental, Vision, Life Insurance and more. \n  A 401k plan that includes a corporate match. \n  Paid Time Off \n  Three weeks (15 days) of paid vacation \n  Ten paid holidays per calendar year (8 fixed and 2 floating) \n  6 paid wellness days \n  Career Development & Growth: We provide ongoing training, coaching and development. We reward continuous improvement and encourage you to own your own development. Take advantage of some of the best training and tools in the world to learn more about multiple areas of Human Resources! \n \n \n  What You'll Need: \n \n  4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as S3, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies. \n  Prefer prior experience on Hadoop especially Cloudera Data Platform (CDP). \n  Proficiency in one of the scripting languages such as Shell, Python, Scala, Java.    Good understanding of Big Data technology trends, with knowledge of technologies such as Kafka, Spark, Hive, pySpark. \n  Experience in version control systems such as Git, GitLab, etc. \n  Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certification. \n  Experience with Big Data technologies e.g. Hadoop, Spark, Scala, and solutions in AWS/Azure. \n  Proficiency in Python and SQL. \n  Strong understanding of scaling, performance and scheduling, batch and streaming data architecture. \n  Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations. \n  Experience on data platform re-architecture projects or handling operational excellence in DW via automation. \n  Experience communicating with management as well as with colleagues from engineering, analytics, and business backgrounds. \n  Strong technical and analytical aptitude; Excellent oral and written communication skills \n \n \n  Flexible Working  \n \n So that you can be your best at work and home, we consider flexible working arrangements wherever possible. Alight has been a leader in the flexible workspace and \"Top 100 Company for Remote Jobs\" 5 years in a row. \n \n  Benefits \n  We offer programs and plans for a healthy mind, body, wallet and life because it's important our benefits care for the whole person. Options include a variety of health coverage options, wellbeing and support programs, retirement, vacation and sick leave, maternity, paternity & adoption leave, continuing education and training as well as a number of voluntary benefit options.  \n \n Our commitment to Diversity and Inclusion \n \n  Alight is committed to diversity, equity, and inclusion. We celebrate differences and believe in fostering an environment where everyone feels valued, respected, and supported. We know that diverse teams are stronger, more innovative, and more successful. \n \n  At Alight, we welcome and embrace all individuals, regardless of their background, and are dedicated to creating a culture that enables every employee to thrive. Join us in building a brighter, more inclusive future. ", "techs": ["aws", "s3", "redshift", "ec2", "hadoop", "cloudera data platform (cdp)", "shell", "python", "scala", "java", "kafka", "spark", "hive", "pyspark", "git", "gitlab", "cloud technologies", "aws cloud services", "python", "sql"]}, "1d3ebdd6c4abcd6b": {"terms": ["machine learning engineer"], "salary_min": 149000.0, "salary_max": 253000.0, "title": "Senior Engineering Manager, Data Enrichment", "company": "Affinity.co", "desc": "USA (Remote)  \n \n \n Affinity stitches together billions of data points from massive datasets to create a powerful, accurate representation of the world's professional relationship graph. Based on this data, we offer our users the insights and visibility they need to nurture and tap into the opportunities in their team's network. \n  Reporting to the Director of Engineering, you'll support creating the magic that underlies Affinity's industry-leading relationship intelligence by leading Affinity\u2019s Data Enrichment team. \n  Our Data Enrichment team ingests data from various external data sources to build out a data platform that is used by our Relationship Intelligence (ML) team. This is a highly complex area with one record consisting of datapoints from many data sets, which makes entity merging and data correctness challenging. We are looking for an Senior Engineering Manager that values career development, mentorship, and is a technical leader who can drive the technical direction of the team while aligning with our strategic vision. \n  What you\u2019ll be doing: \n \n Drive design and build data engineering systems, services, and data platforms that serve as a repository for our ML engineering and CRM teams. \n Drive complex technical, architecture, design, and product discussions. \n Leading, coaching, and inspiring our engineers on the team. \n Identify and fill gaps on the team, and create the processes necessary for the teams\u2019 success. \n Lead SCRUM processes, e.g., daily standups, sprint plannings, and retrospectives. \n Scale the team by hiring additional talented engineers to fill existing gaps and provide the necessary velocity to meet product goals. \n Help define our Data Enrichment roadmap. You'll collaborate with our fast-growing team of engineering, product, and business leaders to improve the quality of our data and enable our teams to quickly iterate on feature engineering and model experimentation. \n \n Qualifications \n  Don\u2019t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every qualification. At Affinity, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you\u2019re excited about this role, but your past experience doesn\u2019t perfectly align with the qualifications above, we encourage you to apply anyways. You may be just the right candidate for this or other roles. \n  Required: \n \n You have 10+ years of experience working in data engineering with at least 4+ years of acting as an engineering manager, leading complex, sometimes ambiguous engineering projects across team boundaries. \n You have experience mentoring and helping the engineers around you grow. \n You have experience partnering with product and machine learning teams on large, strategic data projects and routine partner work. \n You have extensive hands-on experience in building scalable data platforms and reliable data pipelines using technologies such as Spark, Hadoop, DataBricks, AWS SQS, AWS Kinesis, and/or Kafka. \n You have experience working with large, multi-terabyte datasets and are comfortable with high-scale data ingestion, transformation, and distributed processing tools such as Apache Spark (Scala or Python).  \n Experience with AWS, DBX or related cloud technologies. \n You're comfortable with the building blocks of modern back-end systems, such as horizontally scalable data infrastructure, event-driven architecture, and beyond and can clearly articulate the pros/cons of different approaches, while also providing a recommended solution based on the current context. \n You have familiarity with databases and analytics technologies in the industry, including Data Warehousing, Data Lakes, ETL and Relational Databases. \n You take pride in delivering exceptionally high quality work in terms of data accuracy, performance, and reliability. \n You\u2019re eager to contribute your ideas and experiences to help Affinity continuously improve as a product and company. \n \n Nice to have: \n \n Experience with Ruby. \n Experience with Graph connectivity. \n \n How we work: \n  Our culture is a key part of how we operate as well as our hiring process: \n \n We iterate quickly. As such, you must be comfortable embracing ambiguity, be able to cut through it, and deliver incremental value to our customers each sprint. \n We are candid, transparent, and speak our minds while simultaneously caring personally with each person we interact with. \n We make data driven decisions and make the best decision for the moment based on the information available. \n \n Join us in enabling every professional on the planet to succeed by harnessing the power of their relationships. \n \n \n  What you'll enjoy at Affinity: \n \n We live our values as playmakers, obsessed with learning, caring personally about our colleagues and clients, are radically open-minded, and take pride in everything we do. \n We pay your medical, dental, and vision insurance with comprehensive PPO and HMO plans. And provide flexible personal & sick days. We want our team to be happy and healthy :) \n We offer a 401k plan to help you plan for retirement. \n We provide an annual budget for you to spend on education and offer a comprehensive L&D program \u2013 after all, one of our core values is that we're #obsessedwithlearning! \n We support our employee's overall health and well-being and reimburse monthly for things such as; transportation, Home Internet, Meals, and Wellness memberships/equipment. \n Virtual team building and socials. Keeping people connected is essential. \n \n Please note that the role compensation details below reflect the base salary only and do not include any variable pay, equity, or benefits. This represents the salary range that Affinity believes, in good faith, at the time of this posting, that it will pay for the posted job. \n  A reasonable estimate of the current range is  $149,000 to $253,000 USD . Within the range, individual pay is determined by factors such as job-related skills, experience, and relevant education or training. \n \n About Affinity \n  We have raised over $120M and are backed by some of Silicon Valley\u2019s best firms, with over 2,700 customers worldwide on our platform. We are proud to have a 4.5 Star Glassdoor rating and recently ranked; Inc.\u2019s Best Workplaces of 2022 and Great Places to Work 2022. Passionate about helping dealmakers in the world\u2019s biggest relationship-driven industries to find, manage, and close the most important deals; our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month.", "cleaned_desc": " You have experience partnering with product and machine learning teams on large, strategic data projects and routine partner work. \n You have extensive hands-on experience in building scalable data platforms and reliable data pipelines using technologies such as Spark, Hadoop, DataBricks, AWS SQS, AWS Kinesis, and/or Kafka. \n You have experience working with large, multi-terabyte datasets and are comfortable with high-scale data ingestion, transformation, and distributed processing tools such as Apache Spark (Scala or Python).  \n Experience with AWS, DBX or related cloud technologies. \n You're comfortable with the building blocks of modern back-end systems, such as horizontally scalable data infrastructure, event-driven architecture, and beyond and can clearly articulate the pros/cons of different approaches, while also providing a recommended solution based on the current context. \n You have familiarity with databases and analytics technologies in the industry, including Data Warehousing, Data Lakes, ETL and Relational Databases. \n You take pride in delivering exceptionally high quality work in terms of data accuracy, performance, and reliability. \n You\u2019re eager to contribute your ideas and experiences to help Affinity continuously improve as a product and company. \n \n Nice to have: \n ", "techs": ["spark", "hadoop", "databricks", "aws sqs", "aws kinesis", "kafka", "apache spark", "scala", "python", "aws", "dbx"]}, "3690083cc788325a": {"terms": ["machine learning engineer"], "salary_min": 187685.69, "salary_max": 237651.9, "title": "Senior Engineering Manager, Data Enrichment", "company": "Affinity.co", "desc": "Affinity stitches together billions of data points from massive datasets to create a powerful, accurate representation of the world's professional relationship graph. Based on this data, we offer our users the insights and visibility they need to nurture and tap into the opportunities in their team's network. \n  Reporting to the Director of Engineering, you'll support creating the magic that underlies Affinity's industry-leading relationship intelligence by leading Affinity's Data Enrichment team. \n  Our Data Enrichment team ingests data from various external data sources to build out a data platform that is used by our Relationship Intelligence (ML) team. This is a highly complex area with one record consisting of datapoints from many data sets, which makes entity merging and data correctness challenging. We are looking for an Senior Engineering Manager that values career development, mentorship, and is a technical leader who can drive the technical direction of the team while aligning with our strategic vision. \n  What you'll be doing: \n \n Drive design and build data engineering systems, services, and data platforms that serve as a repository for our ML engineering and CRM teams. \n Drive complex technical, architecture, design, and product discussions. \n Leading, coaching, and inspiring our engineers on the team. \n Identify and fill gaps on the team, and create the processes necessary for the teams' success. \n Lead SCRUM processes, e.g., daily standups, sprint plannings, and retrospectives. \n Scale the team by hiring additional talented engineers to fill existing gaps and provide the necessary velocity to meet product goals. \n Help define our Data Enrichment roadmap. You'll collaborate with our fast-growing team of engineering, product, and business leaders to improve the quality of our data and enable our teams to quickly iterate on feature engineering and model experimentation. \n \n Qualifications \n  Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every qualification. At Affinity, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you're excited about this role, but your past experience doesn't perfectly align with the qualifications above, we encourage you to apply anyways. You may be just the right candidate for this or other roles. \n  Required: \n \n You have 10+ years of experience working in data engineering with at least 4+ years of acting as an engineering manager, leading complex, sometimes ambiguous engineering projects across team boundaries. \n You have experience mentoring and helping the engineers around you grow. \n You have experience partnering with product and machine learning teams on large, strategic data projects and routine partner work. \n You have extensive hands-on experience in building scalable data platforms and reliable data pipelines using technologies such as Spark, Hadoop, DataBricks, AWS SQS, AWS Kinesis, and/or Kafka. \n You have experience working with large, multi-terabyte datasets and are comfortable with high-scale data ingestion, transformation, and distributed processing tools such as Apache Spark (Scala or Python).  \n Experience with AWS, DBX or related cloud technologies. \n You're comfortable with the building blocks of modern back-end systems, such as horizontally scalable data infrastructure, event-driven architecture, and beyond and can clearly articulate the pros/cons of different approaches, while also providing a recommended solution based on the current context. \n You have familiarity with databases and analytics technologies in the industry, including Data Warehousing, Data Lakes, ETL and Relational Databases. \n You take pride in delivering exceptionally high quality work in terms of data accuracy, performance, and reliability. \n You're eager to contribute your ideas and experiences to help Affinity continuously improve as a product and company. \n \n Nice to have: \n \n Experience with Ruby. \n Experience with Graph connectivity. \n \n How we work: \n  Our culture is a key part of how we operate as well as our hiring process: \n \n We iterate quickly. As such, you must be comfortable embracing ambiguity, be able to cut through it, and deliver incremental value to our customers each sprint. \n We are candid, transparent, and speak our minds while simultaneously caring personally with each person we interact with. \n We make data driven decisions and make the best decision for the moment based on the information available. \n \n Join us in enabling every professional on the planet to succeed by harnessing the power of their relationships. \n  If you'd want to learn more about our values click here. \n  What you'll enjoy at Affinity: \n \n We live our values as playmakers, obsessed with learning, caring personally about our colleagues and clients, are radically open-minded, and take pride in everything we do. \n We pay your medical, dental, and vision insurance with comprehensive PPO and HMO plans. And provide flexible personal & sick days. We want our team to be happy and healthy :) \n We offer a 401k plan to help you plan for retirement. \n We provide an annual budget for you to spend on education and offer a comprehensive L&D program \u2013 after all, one of our core values is that we're #obsessedwithlearning! \n We support our employee's overall health and well-being and reimburse monthly for things such as; transportation, Home Internet, Meals, and Wellness memberships/equipment. \n Virtual team building and socials. Keeping people connected is essential. \n \n Please note that the role compensation details below reflect the base salary only and do not include any variable pay, equity, or benefits. This represents the salary range that Affinity believes, in good faith, at the time of this posting, that it will pay for the posted job. \n  A reasonable estimate of the current range is  $149,000 to $253,000 USD . Within the range, individual pay is determined by factors such as job-related skills, experience, and relevant education or training. \n \n  About Affinity \n  We have raised over $120M and are backed by some of Silicon Valley's best firms, with over 2,700 customers worldwide on our platform. We are proud to have a 4.5 Star Glassdoor rating and recently ranked; Inc.'s Best Workplaces of 2022 and Great Places to Work 2022. Passionate about helping dealmakers in the world's biggest relationship-driven industries to find, manage, and close the most important deals; our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month.", "cleaned_desc": " Help define our Data Enrichment roadmap. You'll collaborate with our fast-growing team of engineering, product, and business leaders to improve the quality of our data and enable our teams to quickly iterate on feature engineering and model experimentation. \n \n Qualifications \n  Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every qualification. At Affinity, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you're excited about this role, but your past experience doesn't perfectly align with the qualifications above, we encourage you to apply anyways. You may be just the right candidate for this or other roles. \n  Required: \n \n You have 10+ years of experience working in data engineering with at least 4+ years of acting as an engineering manager, leading complex, sometimes ambiguous engineering projects across team boundaries. \n You have experience mentoring and helping the engineers around you grow. \n You have experience partnering with product and machine learning teams on large, strategic data projects and routine partner work. \n You have extensive hands-on experience in building scalable data platforms and reliable data pipelines using technologies such as Spark, Hadoop, DataBricks, AWS SQS, AWS Kinesis, and/or Kafka. \n You have experience working with large, multi-terabyte datasets and are comfortable with high-scale data ingestion, transformation, and distributed processing tools such as Apache Spark (Scala or Python).    Experience with AWS, DBX or related cloud technologies. \n You're comfortable with the building blocks of modern back-end systems, such as horizontally scalable data infrastructure, event-driven architecture, and beyond and can clearly articulate the pros/cons of different approaches, while also providing a recommended solution based on the current context. \n You have familiarity with databases and analytics technologies in the industry, including Data Warehousing, Data Lakes, ETL and Relational Databases. \n You take pride in delivering exceptionally high quality work in terms of data accuracy, performance, and reliability. \n You're eager to contribute your ideas and experiences to help Affinity continuously improve as a product and company. \n \n Nice to have: \n \n Experience with Ruby. \n Experience with Graph connectivity. \n ", "techs": ["spark", "hadoop", "databricks", "aws sqs", "aws kinesis", "kafka", "apache spark", "scala", "python", "aws", "dbx", "ruby", "graph connectivity"]}, "c21027bff0a8dcba": {"terms": ["machine learning engineer"], "salary_min": 118201.766, "salary_max": 149669.77, "title": "Senior Software Engineer (US REMOTE)", "company": "The Infosoft Group", "desc": "Company Overview\n   At Motorola Solutions, we believe that everything starts with safety.It's the constant that empowers people to confidently move forward. It can fill a flight or sell out a stadium. It can care for a patient or graduate a class.    As a global leader in public safety and enterprise security, we create and connect the technologies that help to keep people safe where they live, learn, work and play. Our integrated technology ecosystem unifies critical communications, video security and access control, and command center software, enabling collaboration in more powerful ways.    At Motorola Solutions, we're ushering in a new era in public safety and security. Bring your passion, potential and talents to a career that matters.  Department OverviewMotorola Solutions' innovations, products and services play essential roles in people's lives. Our end-to-end suite of software solutions helps our customers answer thousands of emergency calls and text messages, and process video, disparate evidence and records. We are also proud to be industry leaders in video security solutions installed in more than 120 countries at thousands of customer sites, including school campuses, transportation systems, healthcare centers, public venues, critical infrastructure, prisons, factories, casinos, airports, financial institutions, government facilities, and retailers.\n  \n  Our products leverage cutting edge voice technology, language models, natural language understanding, video analytics, and Machine Learning to enable our customers to focus on what matters while providing faster responses, safer outcomes and greater transparency. Our mission is to provide meaningful value to MSI's customers by developing domain-specific applications and services in the areas of Speech & Audio, Machine Translation, Natural Language Understanding and Computer Vision.\n  \n  Calipsa, which is part of MSI, is aiming at automating CCTV video monitoring. We are building a cloud-based platform that automatically connects with cameras, processes and analyzes their content and only forward actionable alerts to our customers. We are working with the biggest security companies in the world, actively monitoring over 25 thousand sites worldwide. We are expecting to massively grow the number of cameras and traffic on our platform in the near future. \n  \n  Our cloud-based platform connects seamlessly with all cameras regardless of their brand or model. In order to make this technology camera agnostic, we need to build a wide range of integrations with third-party systems which could be cameras, network video recorders or video management systems. We are looking for a software engineer who is going to be responsible for building those critical integrations for Calipsa but also for all the Motorola Solutions suite of products. Eager to learn new technologies and third-party frameworks is a strong requirement for the job as you will be working with very different systems and protocols. From the architecture design to the building of the software all the way to its maintenance; you will be expected to work on the complete end-to-end connector.\n  \n  You will be part of a small growing team who will focus on achieving robust and scalable adaptors in order to enable other systems to work on our platform. This responsibility is critical for the company as it is one of the major sources of growth for a number of different products in the Motorola Solutions ecosystem. Being able to make accurate estimates and deliver them is crucial in order to manage expectations from internal and external stakeholders.Job Description\n   Responsibilities:  \n \n Responsible for the building connectors that integrate MSI suite of products to third-party systems \n  Designing efficient architecture to work with external APIs or SDKs \n  Building highly scalable systems with a lot of traffic \n  Solve difficult issues, including performance or concurrency issues, and propose solutions \n  Guide product decisions and the team roadmap with an engineering perspective \n \n \n  Requirements: \n \n  5+ years of work experience as a software engineer \n  Advanced knowledge of node.js \n  Relevant experience with Java, C# \n  Knowledge of cloud computing, deployments, and infrastructure (AWS, Azure, GCP, etc.) \n  Good understanding of the different networking protocols \n  Demonstrate some strong team player skills \n  Excitement about building, operating, and maintaining resilient, scalable systems \n  Excitement about architecting scalable systems that impact a global community of users \n  Drive for observability to understand performance and be able to diagnose problems \n  The team is highly distributed across geographies and time-zones, and you will thrive in an environment of remote work and asynchronous communication \n \n \n  Note: Candidate can reside anywhere in US. \n \n  #LI-MP2  #LI-REMOTE  Basic Requirements\n  \n  Bachelors degree with 5+ years of software engineering/developer experience, 5+ years of cloud platform development, and 3+ years of node.js experience. \n  Legal authorization to work in the U.S. indefinitely is required. Employer work permit sponsorship is not available for this position. \n  Travel RequirementsNoneRelocation ProvidedNonePosition TypeExperiencedReferral Payment PlanNo\n  \n  Our  U.S.Benefitsinclude: \n \n  Incentive Bonus Plans \n  Medical, Dental, Visionbenefits \n  401K with Company Match \n  9 Paid Holidays \n  GenerousPaidTime Off Packages \n  Employee Stock Purchase Plan \n  PaidParental & Family Leave \n  and more! \n \n  EEO Statement \n  Motorola Solutions is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran's status, or, any other protected characteristic. \n \n  Motorola Solutions is an Equal Opportunity Employer committed to no discrimination because of race, color, creed, marital status, age, religion, sex, national origin, citizenship, sexual orientation, gender identity or expression, genetic information, disability, protected veteran, or any other legally protected characteristic.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Motorola Solutions \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   5+ years", "cleaned_desc": " \n  5+ years of work experience as a software engineer \n  Advanced knowledge of node.js \n  Relevant experience with Java, C# \n  Knowledge of cloud computing, deployments, and infrastructure (AWS, Azure, GCP, etc.) \n  Good understanding of the different networking protocols \n  Demonstrate some strong team player skills \n  Excitement about building, operating, and maintaining resilient, scalable systems \n  Excitement about architecting scalable systems that impact a global community of users \n  Drive for observability to understand performance and be able to diagnose problems \n  The team is highly distributed across geographies and time-zones, and you will thrive in an environment of remote work and asynchronous communication \n \n \n  Note: Candidate can reside anywhere in US. \n \n  #LI-MP2  #LI-REMOTE  Basic Requirements\n  \n  Bachelors degree with 5+ years of software engineering/developer experience, 5+ years of cloud platform development, and 3+ years of node.js experience. \n  Legal authorization to work in the U.S. indefinitely is required. Employer work permit sponsorship is not available for this position. \n  Travel RequirementsNoneRelocation ProvidedNonePosition TypeExperiencedReferral Payment PlanNo", "techs": ["node.js", "java", "c#", "aws", "azure", "gcp"]}, "f2b03a1812669b88": {"terms": ["machine learning engineer", "mlops"], "salary_min": 65.0, "salary_max": -1.0, "title": "Sr. DevOps/DataOps Engineer", "company": "NexGen.Media", "desc": "Our team is seeking a part-time/freelance DevOps/DataOps guru to assist with the support, implementation, administration and maintenance of various client DevOps/DataOps/web application environments, including providing support for existing development cycles, testing, staging and production environments. The role will also require expertise in enterprise-level technical consulting as well as the ability to develop innovative solutions to complex problems, while working without considerable direction. \n The applications and solutions that we architect and manage primarily reside on Linux or Windows Server environments deployed to Amazon Web Services (AWS) and Microsoft Azure. For some of our data-driven clients the role will also involve managing the flow of the data, data ingestion, management, and other areas of data processing. All deployments follow specific legal/regulatory compliance models and cyber security best practices, therefore deep knowledge in this area is also required. \n At the present time, this role is likely suited to individuals who are already employed in a similar role either on a part or full-time basis, who has the time and capacity for extra work. Candidates with the ability to travel anywhere in the US on occasion is also preferred. \n Basic Qualifications: \n \n A Bachelor\u2019s degree in computer science, data analytics, software engineering, or related technical field (preferred). \n 8+ years exp. in a DevOps engineering and technical consulting/management role. \n 8+ years exp. with production in data engineering role. \n 8+ years exp. with data streaming, ingest, ETL, and data warehousing technologies. \n Advanced Experience with scripting languages, including BASH, Ruby, Python, Scala, etc. \n 8+ years exp. with major programming/scripting languages like Java, C++, PHP, Ruby, Python, R, and others. \n Experience with infrastructure as code. \n MUST HAVE CURRENT EXPERIENCE with managing large-scale and complex public-facing website/web server architecture and deployments \n MUST HAVE CURRENT EXPERIENCE with Plesk deployments \n \n Additional Qualifications: \n \n Experience with DevOps and DataOps concepts \u2013 utilizing your knowledge and experience to identify and execute pragmatic solutions while avoiding technical debt. \n Database architecture, administration and security (MYSQL, MSSQL, MongoDB, PostgreSQL, Cassandra, Aurora, Oracle), and non-relational databases such as NoSQL WideTable, along with complex database queries, stored procedures, functions and views, and the scaling of complex and high-volume relational databases. \n Using conceptual data models to inform accurate, effective, and efficient database design. \n Data exploitation (e.g., acquiring data, storing data, processing data, analyzing data, visualizing data, turning data into intelligence products, disseminating data, and knowledge management). \n Research and development of applications/services in disciplines such as: Natural Language Processing, machine learning, Conceptual Modeling, Statistical Analysis, Predictive Modeling, and Hypothesis testing. \n Understanding of delivery methodology and lead teams in the implementation of the solution according to the design/architecture. \n Working with Extract, Transform, Load (ETL) tools. \n AWS ecosystem (including EC2, S3, SQS, SNS, Kinesis, RDS, CloudFormation, and others). Maintaining existing AWS provisioning systems; expand and modify to accommodate operational requirements. \n Supporting other types of cloud computing environments (e.g., private, hybrid, and/or public). \n Ability to develop build pipelines with Circle CI and Jenkins or similar. \n Work with JIRA or similar workflow and issue tracking framework. \n Extensive knowledge of legal and regulatory compliance models as it relates to information security, data privacy and governance. \n \n Job Types: Part-time, Contract \n Pay: From $65.00 per hour \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 8 years \n \n Experience: \n \n Azure: 8 years (Required) \n AWS: 8 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Our team is seeking a part-time/freelance DevOps/DataOps guru to assist with the support, implementation, administration and maintenance of various client DevOps/DataOps/web application environments, including providing support for existing development cycles, testing, staging and production environments. The role will also require expertise in enterprise-level technical consulting as well as the ability to develop innovative solutions to complex problems, while working without considerable direction. \n The applications and solutions that we architect and manage primarily reside on Linux or Windows Server environments deployed to Amazon Web Services (AWS) and Microsoft Azure. For some of our data-driven clients the role will also involve managing the flow of the data, data ingestion, management, and other areas of data processing. All deployments follow specific legal/regulatory compliance models and cyber security best practices, therefore deep knowledge in this area is also required. \n At the present time, this role is likely suited to individuals who are already employed in a similar role either on a part or full-time basis, who has the time and capacity for extra work. Candidates with the ability to travel anywhere in the US on occasion is also preferred. \n Basic Qualifications: \n \n A Bachelor\u2019s degree in computer science, data analytics, software engineering, or related technical field (preferred). \n 8+ years exp. in a DevOps engineering and technical consulting/management role. \n 8+ years exp. with production in data engineering role. \n 8+ years exp. with data streaming, ingest, ETL, and data warehousing technologies.   Advanced Experience with scripting languages, including BASH, Ruby, Python, Scala, etc. \n 8+ years exp. with major programming/scripting languages like Java, C++, PHP, Ruby, Python, R, and others. \n Experience with infrastructure as code. \n MUST HAVE CURRENT EXPERIENCE with managing large-scale and complex public-facing website/web server architecture and deployments \n MUST HAVE CURRENT EXPERIENCE with Plesk deployments \n \n Additional Qualifications: \n \n Experience with DevOps and DataOps concepts \u2013 utilizing your knowledge and experience to identify and execute pragmatic solutions while avoiding technical debt.   Database architecture, administration and security (MYSQL, MSSQL, MongoDB, PostgreSQL, Cassandra, Aurora, Oracle), and non-relational databases such as NoSQL WideTable, along with complex database queries, stored procedures, functions and views, and the scaling of complex and high-volume relational databases. \n Using conceptual data models to inform accurate, effective, and efficient database design. \n Data exploitation (e.g., acquiring data, storing data, processing data, analyzing data, visualizing data, turning data into intelligence products, disseminating data, and knowledge management). \n Research and development of applications/services in disciplines such as: Natural Language Processing, machine learning, Conceptual Modeling, Statistical Analysis, Predictive Modeling, and Hypothesis testing. \n Understanding of delivery methodology and lead teams in the implementation of the solution according to the design/architecture. \n Working with Extract, Transform, Load (ETL) tools. \n AWS ecosystem (including EC2, S3, SQS, SNS, Kinesis, RDS, CloudFormation, and others). Maintaining existing AWS provisioning systems; expand and modify to accommodate operational requirements. \n Supporting other types of cloud computing environments (e.g., private, hybrid, and/or public). \n Ability to develop build pipelines with Circle CI and Jenkins or similar. ", "techs": ["devops", "dataops", "linux", "windows server", "amazon web services (aws)", "microsoft azure", "scripting languages (bash", "ruby", "python", "scala)", "java", "c++", "php", "r", "infrastructure as code", "plesk", "mysql", "mssql", "mongodb", "postgresql", "cassandra", "aurora", "oracle", "nosql widetable", "database queries", "stored procedures", "functions", "views", "relational databases", "natural language processing", "machine learning", "conceptual modeling", "statistical analysis", "predictive modeling", "hypothesis testing", "extract", "transform", "load (etl) tools", "ec2", "s3", "sqs", "sns", "kinesis", "rds", "cloudformation", "circle ci", "jenkins."]}, "87ba8e8c425c9366": {"terms": ["machine learning engineer"], "salary_min": 108021.52, "salary_max": 136779.31, "title": "Senior Cloud Engineer", "company": "EquipmentShare", "desc": "EquipmentShare is Hiring a Senior Cloud Engineer \n Your role in our team \n  At  EquipmentShare , we believe it's more than just a job, we invest in our people and encourage you to choose the best path for your career. It's truly about you, your future and where you want to go. \n  We are looking for a Senior Cloud Engineer to help us continue to build the next evolution of our platform in a scalable, performant and customer-centric oriented architecture. \n  Our  main tech stack  includes : AWS cloud infrastructure (e.g. Kubernetes/EKS, Lambda, Aurora RDS PostgreSQL), AWS Cloud Development Kit (CDK), Terraform, Python, Typescript. \n  If you have  production scale  experience in a  different but similar stack  (e.g. Azure/Google Cloud Platform, other languages)   and are interested in moving to a new stack, we should chat. \n  What you'll be doing \n  We are typically organized into agile cross-functional teams composed of  Engineering ,  Product  and  Design , which allows us to develop deep expertise and rapidly deliver high value features and functionality to our next generation T3 Platform. \n  You'll be part of a  close knit  team of cloud engineers developing and maintaining AWS cloud infrastructure and internal applications/automation to support the  next generation  of our  T3 Fleet  and supporting applications that  enable  end-users to track, monitor and manage the health of their connected vehicles and deployed assets. \n  We'll be there to  support you  as you become familiar with our teams, product domains, tech stack and processes \u2014 generally how we all  work together . \n  As a Senior Cloud Engineer on the Cloud Operations team you will \n \n Collaborate with Product Managers, Designers and Engineers to take ideas from concept to delivery. \n Lead design and implementation of AWS cloud solutions to meet the organization's infrastructure and application requirements following community preferred practices to help ensure scalability, resilience, security and operational visibility. \n Implement and maintain infrastructure as code (IaC) using tools like Terraform, AWS CloudFormation, and AWS Cloud Development Kit (CDK) with Typescript and Python. \n Monitor and report on cloud costs and develop strategies to mitigate unnecessary spending. \n Maintain AWS managed Kubernetes (EKS) clusters and assist with deployment and troubleshooting of hosted applications. \n Participate in disaster recovery planning and execute backup and restoration procedures. \n Lead incident response procedures to triage, address, document, and perform post-mortem analysis. \n Participate in on-call rotation responding to critical production outages as well as non-urgent support/consultation requests. \n Maintain and augment CI/CD pipelines (GitLab) and automated deployment processes. \n Develop system monitoring and alerting capabilities. \n Document architecture, processes, and procedures for knowledge sharing and team collaboration. \n Perform systems administration to ensure operating systems, tools, and software remain up-to-date, functional, and secure. \n Stay up-to-date with AWS services, industry trends, and emerging technologies, providing recommendations for improvements. \n Mentor less-experienced engineers to help them build their skills. \n \n Who you are \n  You're a  hands-on developer  who gets stuck in, you enjoy solving complex problems and building impactful solutions. Most importantly, you care about making a difference. \n \n Take the initiative to  own outcomes from start to finish  \u2014 knowing what needs to be accomplished within your domain and how we work together to deliver the best solution. \n You have a passion for developing your craft \u2014 you understand what it takes to  build quality , robust and  scalable solutions. \n You'll see the learning opportunity when things don't quite go to plan \u2014 not only for you, but for how we  continuously improve  as a team. \n You take a hypothesis-driven approach \u2014 knowing how to source, create and  leverage data  to inform  decision making , using data to  drive how we improve , to shape how we  evaluate  and make platform  recommendations. \n \n So, what is important to us? \n  Above all,  you'll get stuff done.  More importantly, you'll collaborate to  do the right things , in the  right way  to achieve the  right outcomes . \n \n 7+ years of relevant cloud development experience building production grade solutions. \n Proficient with a high order object oriented language (especially Python and/or TypeScript). \n Experience with containerization technologies such as Docker. \n Practical experience building and managing production grade infrastructure in AWS with tools like Terraform, CDK, CloudFormation. \n Strong knowledge of AWS services including EC2, S3, Lambda, Aurora RDS, IAM. \n Experience with Linux/Unix system administration. \n Familiarity with \"DevOps\" practices, CI/CD pipelines, GitOps, and version control systems (Git). \n Experience partnering and collaborating with remote teams across time zones. \n Proven track record learning new technologies and applying that learning quickly. \n Experience building observability and monitoring into applications. \n Ability to troubleshoot and resolve technical issues related to cloud infrastructure and applications. \n Motivated to identify opportunities for automation to reduce manual toil. \n AWS certifications (e.g. AWS Certified Solutions Architect) are highly desirable. \n \n What we will offer you \n  We can promise that every day  will be a little different  with new ideas, challenges and rewards. \n  We've been growing as a team and we are not finished just yet\u2014 there is plenty of opportunity to  shape how we deliver together . \n  Our mission   is to enable the construction industry with tools that unlock substantial increases to productivity. Together with our team and customers, we are building the future of construction. \n  T3   is the only cloud-based operating system that brings together construction workflows & data from constantly moving elements in one place. \n \n Competitive base salary and market leading equity package (pre-IPO). \n Unlimited PTO. \n Remote first. \n True work/life balance. \n Medical, Dental, Vision and Life Insurance coverage. \n 401(k) + match. \n Opportunities for career and professional development with conferences, events, seminars and continued education. \n On-site fitness center at the Home Office in Columbia, Missouri, complete with weightlifting machines, cardio equipment, group fitness space, racquetball courts, a climbing wall, and much more! \n Volunteering and local charity support that help you nurture and grow the communities you call home through our Giving Back initiative . \n Stocked breakroom and full kitchen with breakfast and lunch provided daily by our chef and kitchen crew. \n \n We embrace diversity in all of its forms and foster an inclusive environment for all people to do their best work with us. \n  We're an equal opportunity employer. All applicants will be considered for employment without attention to ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status. \n  All appointments will be made on merit.", "cleaned_desc": " Implement and maintain infrastructure as code (IaC) using tools like Terraform, AWS CloudFormation, and AWS Cloud Development Kit (CDK) with Typescript and Python. \n Monitor and report on cloud costs and develop strategies to mitigate unnecessary spending. \n Maintain AWS managed Kubernetes (EKS) clusters and assist with deployment and troubleshooting of hosted applications. \n Participate in disaster recovery planning and execute backup and restoration procedures. \n Lead incident response procedures to triage, address, document, and perform post-mortem analysis. \n Participate in on-call rotation responding to critical production outages as well as non-urgent support/consultation requests. \n Maintain and augment CI/CD pipelines (GitLab) and automated deployment processes. \n Develop system monitoring and alerting capabilities. \n Document architecture, processes, and procedures for knowledge sharing and team collaboration. \n Perform systems administration to ensure operating systems, tools, and software remain up-to-date, functional, and secure. \n Stay up-to-date with AWS services, industry trends, and emerging technologies, providing recommendations for improvements. \n Mentor less-experienced engineers to help them build their skills. \n \n Who you are ", "techs": ["terraform", "aws cloudformation", "aws cloud development kit (cdk)", "typescript", "python", "aws managed kubernetes (eks)", "disaster recovery planning", "incident response procedures", "post-mortem analysis", "on-call rotation", "ci/cd pipelines (gitlab)", "system monitoring", "alerting capabilities", "documentation", "systems administration", "aws services", "mentoring"]}, "13f8a7c3e0e7c403": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior API Automation Test Engineer", "company": "Capgemini", "desc": "Duration : 6+ months \n \n  Job Description: \n \n \n \n  6-12 yrs. of experience in software engineering - QA testing \n  Expertise in API testing and Automation using Rest Assured / ReadyAPI / etc \n  Proficient in Java \n  Experience using Version control (GIT), CI/CD Tools (Jenkins), Build Tools, (Maven, ANT, etc), Debugging Tools (Charles/Fiddler), Agile Management Tool (JIRA), Test Management Tool (QMetry)\" \n  Test Analyst - Experience Seven to Ten Years \n  API Testing, Rest Assured, ReadyAPI, Java \n \n \n  The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job. \n \n  A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients\u2019 opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.", "cleaned_desc": "", "techs": ""}, "850cdfd63db870fa": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Director, Generative AI Infrastructure -(Remote-Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Senior Director, Generative AI Infrastructure -(Remote-Eligible)\n  \n  Senior Director, Generative AI Infrastructure \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Director, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n  Develop SDKs and APIs for our user community to build agents, information retrieval and anomaly/fraud detection systems on our enterprise platforms.  \n \n \n Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 5 years of experience leading teams of engineers and applied scientists \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Computer Science, a related technical field, or or equivalent practical experience with experience in leading applied science and engineering teams. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Authored research publications in top peer-reviewed conferences, or industry recognized contributions in the space of neural networks, distributed training and SysML. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML on GPU clusters with a focus on distributed training, checkpointing and fault tolerance. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the core components of a platform. \n  Experience working with public cloud infrastructure such as AWS, Azure or GCP. \n  Familiarity with deploying large neural network models in demanding production environments. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr. Dir, Machine Learning Engineering\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr. Dir, Machine Learning Engineering\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr. Dir, Machine Learning Engineering\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Senior Director, Generative AI Infrastructure -(Remote-Eligible)\n  \n  Senior Director, Generative AI Infrastructure \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Director, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities.   \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Computer Science, a related technical field, or or equivalent practical experience with experience in leading applied science and engineering teams. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Authored research publications in top peer-reviewed conferences, or industry recognized contributions in the space of neural networks, distributed training and SysML. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML on GPU clusters with a focus on distributed training, checkpointing and fault tolerance. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the core components of a platform. \n  Experience working with public cloud infrastructure such as AWS, Azure or GCP. \n  Familiarity with deploying large neural network models in demanding production environments. \n \n ", "techs": ["tensorflow", "pytorch", "lightning", "mosaic ml", "gpu instances", "public cloud infrastructure", "llms", "fms", "vector databases", "machine learning frameworks", "distributed training", "checkpointing", "fault tolerance", "aws", "azure", "gcp"]}, "db1bc8238d8a9a4f": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Director, Generative AI Infrastructure -(Remote-Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Senior Director, Generative AI Infrastructure -(Remote-Eligible)\n  \n  Senior Director, Generative AI Infrastructure \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Director, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n  Develop SDKs and APIs for our user community to build agents, information retrieval and anomaly/fraud detection systems on our enterprise platforms.  \n \n \n Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 5 years of experience leading teams of engineers and applied scientists \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Computer Science, a related technical field, or or equivalent practical experience with experience in leading applied science and engineering teams. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Authored research publications in top peer-reviewed conferences, or industry recognized contributions in the space of neural networks, distributed training and SysML. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML on GPU clusters with a focus on distributed training, checkpointing and fault tolerance. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the core components of a platform. \n  Experience working with public cloud infrastructure such as AWS, Azure or GCP. \n  Familiarity with deploying large neural network models in demanding production environments. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr. Dir, Machine Learning Engineering\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr. Dir, Machine Learning Engineering\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr. Dir, Machine Learning Engineering\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Senior Director, Generative AI Infrastructure -(Remote-Eligible)\n  \n  Senior Director, Generative AI Infrastructure \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Director, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities.   \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Computer Science, a related technical field, or or equivalent practical experience with experience in leading applied science and engineering teams. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Authored research publications in top peer-reviewed conferences, or industry recognized contributions in the space of neural networks, distributed training and SysML. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML on GPU clusters with a focus on distributed training, checkpointing and fault tolerance. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the core components of a platform. \n  Experience working with public cloud infrastructure such as AWS, Azure or GCP. \n  Familiarity with deploying large neural network models in demanding production environments. \n \n ", "techs": ["tensorflow", "pytorch", "lightning", "mosaic ml", "gpu clusters", "distributed training", "checkpointing", "fault tolerance", "aws", "azure", "gcp"]}, "409ee25eab6817f9": {"terms": ["machine learning engineer"], "salary_min": 160000.0, "salary_max": 190000.0, "title": "Backend Python Engineer / Architect", "company": "MindsDB", "desc": "ABOUT US \n \n  MindsDB is a fast-growing open-source company that enables developers to quickly integrate Artificial Intelligence Logic into applications and ship AI-powered solutions from prototyping & experimentation to production in a fast & scalable way.\n  \n \n \n  MindsDB was founded in 2017 by Adam Carrigan (COO) and Jorge Torres (CEO) and based in San Francisco, California, is backed with over $50M in total funding from Mayfield, Benchmark, YCombinator, OpenOcean, Walden Catalyst Ventures, MMC, Speedinvest, TQ Ventures and the University of California Berkeley SkyDeck fund. MindsDB is also recognized by Forbes as one of America's most promising AI companies (2021) and by Gartner as a Cool Vendor for Data and AI (2022).\n  \n \n \n THE ROLE \n \n \n    Our organization is looking for an experienced Backend Python Engineer & Systems Architect to join our technology team. This position is ideal for a seasoned professional looking to make a significant contribution to both our company and the open source community. In this role, you will be responsible for designing and implementing complex backend services. We're looking for someone with not just backend programming experience, but designing them in an highly-scalable fashion, and can take a step back and look at the bigger picture as an architect and see how any individual service will play out on a larger scale and how it'll interact with other services.\n    \n \n \n    The successful candidate will be proficient in Python and have demonstrable experience designing, developing, and deploying scalable & highly available services. We expect you to have a deep understanding of performance, multi-threading, data modeling, and distributed systems. An intimate knowledge of distributed microservice architecture will be critical in this role, as the development and maintenance of these services will form a significant part of your responsibilities.\n    \n \n \n    A substantial part of your role will involve developing and maintaining services intended to be run in a Kubernetes environment. As such, knowledge and experience in Kubernetes and containerization are essential. The ideal individual will need to understand how to write robust, resilient applications that can effectively scale and respond to changing conditions in a cloud-based, containerized environment. They will have multiple experiences as such and be able to explain in detail the challenges they've had in this space before and how to navigate around them.\n    \n \n \n    In addition to technical skills we are seeking a candidate who thrives in a collaborative environment. Excellent communication skills are key as you will be expected to interface with various teams and individuals within the organization and potentially external partners, being able to translate business needs into effective technology solutions will be crucial. We are looking for someone who is driven and motivated and is able to carry projects both on their own and with others.\n    \n \n \n    If you are a passionate Python professional with a strong background in backend development, systems architecture, microservices, and Kubernetes, we would like to meet you. This role promises not only technical challenges but also the opportunity to shape the future direction of our technology stack and services. With MindsDB, you will have the chance to bring and expand your skills, face unique challenges, and make a real impact on our business and your future. We have a number of talented and experienced individuals in both the ML/AI space and in the high-scalability space, so there is room for professional growth and tutoring from your fellow staff as well as the opportunity to teach others.\n    \n \n \n    Locale: This is preferably an hybrid role located in the Bay Area or at least in the West Coast of the USA time zone (PST). We prefer a candidate able to come into the office a few days/week which is located in the heart of the Mission District in San Francisco. If not local, we would consider someone who can regularly come visit (eg: 1 week out of every month) and work in the office.\n    \n \n \n RESPONSIBILITIES \n \n Engineering new microservices from the ground up for specific purpose-fit solutions \n Modifying existing services to perform in a higher-scalability capacity. Experienced with various fan-out patterns, queueing systems, etc. \n Migrating some services from a monolith to a scalable microservice pattern \n Devising solutions from a set of requirements \n Collaborating with team members or other industry professionals or partners about possible requirements, solutions, and deciding a path forward together \n Implementing that solution either on your own, or on larger projects with a team of engineers some which may be remote. \n You may be asked to manage your project and any resources (engineers, testers, staff) assigned to your project \n Having shared responsibility for our suite of services, infrastructure, uptime, and quality of our product \n Contributing to an open-source project \n \n REQUIREMENTS/QUALIFICATIONS \n \n \n 5+ years of industry experience working with Python (or comparable experience) \n 5+ years engineering backend/API/microservices (or comparable experience) \n Knowledge of and experience with designing highly-scalable microservices \n Deep knowledge of Docker, containerization, Kubernetes/docker orchestration \n Experience working in a team-based environment, in an agile workflow \n Interest and desire to learn in all items mentioned in \"Nice to have\" below on the job \n \n \n \n NICE TO HAVE \n \n Knowledge of and experience with Machine Learning / AI tools, technologies, concepts and frameworks \n Knowledge of Grafana, Prometheus, ElasticSearch/Kibana to assist with debugging \n Experience with kubectl, capable to debug services deployed into Kubernetes \n Experience with helm, capable to modify/improve/deploy services into Kubernetes \n Experience with our open-source library, MindsDB \n Experience working with Open-Source projects, ideally having contributed and/or authored code to various projects. Understanding what is necessary to successfully contribute \n Experience with Amazon Web Services (AWS) or Azure \n Experience with doing tracing and performance auditing and improvements to code and services \n \n BENEFITS & PERKS \n \n \n Remote and Hybrid Roles \n Flexible working hours \n Competitive Compensation \n Unlimited PTO \n New Hire Remote Setup budget \n Learning & Development budget \n Medical, Dental, Vision Insurance (US only) \n Monthly Wellbeing Budget \n Monthly (virtual) team events \n International in-person company retreats \n Wellbeing/Mental Health leave \n \n \n DIVERSITY, EQUALITY & INCLUSION \n \n \n   MindsDB is an equal-opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. MindsDB will give all qualified applicants consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations, and ordinances. \n   \n \n \n Salary Range \n \n    $160,000\u2014$190,000 USD", "cleaned_desc": " \n Engineering new microservices from the ground up for specific purpose-fit solutions \n Modifying existing services to perform in a higher-scalability capacity. Experienced with various fan-out patterns, queueing systems, etc. \n Migrating some services from a monolith to a scalable microservice pattern \n Devising solutions from a set of requirements \n Collaborating with team members or other industry professionals or partners about possible requirements, solutions, and deciding a path forward together \n Implementing that solution either on your own, or on larger projects with a team of engineers some which may be remote. \n You may be asked to manage your project and any resources (engineers, testers, staff) assigned to your project \n Having shared responsibility for our suite of services, infrastructure, uptime, and quality of our product \n Contributing to an open-source project \n \n REQUIREMENTS/QUALIFICATIONS \n \n \n 5+ years of industry experience working with Python (or comparable experience) \n 5+ years engineering backend/API/microservices (or comparable experience) \n Knowledge of and experience with designing highly-scalable microservices \n Deep knowledge of Docker, containerization, Kubernetes/docker orchestration \n Experience working in a team-based environment, in an agile workflow   Interest and desire to learn in all items mentioned in \"Nice to have\" below on the job \n \n \n \n NICE TO HAVE \n \n Knowledge of and experience with Machine Learning / AI tools, technologies, concepts and frameworks \n Knowledge of Grafana, Prometheus, ElasticSearch/Kibana to assist with debugging \n Experience with kubectl, capable to debug services deployed into Kubernetes \n Experience with helm, capable to modify/improve/deploy services into Kubernetes \n Experience with our open-source library, MindsDB \n Experience working with Open-Source projects, ideally having contributed and/or authored code to various projects. Understanding what is necessary to successfully contribute \n Experience with Amazon Web Services (AWS) or Azure \n Experience with doing tracing and performance auditing and improvements to code and services \n \n BENEFITS & PERKS \n \n \n Remote and Hybrid Roles ", "techs": ["microservices", "fan-out patterns", "queueing systems", "monolith", "scalable microservice pattern", "requirements", "python", "docker", "containerization", "kubernetes/docker orchestration", "team-based environment", "agile workflow", "machine learning", "ai tools", "grafana", "prometheus", "elasticsearch/kibana", "kubectl", "helm", "open-source library", "mindsdb", "open-source projects", "amazon web services", "azure", "tracing", "performance auditing"]}, "b1e70f96406f2594": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Lead Engineer - Generative AI Product Engineering (Remote- Eligible)", "company": "Capital One", "desc": "Center 1 (19052), United States of America, McLean, Virginia\n   Lead Engineer - Generative AI Product Engineering (Remote- Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Lead Generative AI Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services that enable real-time customer-facing applications. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience. \n  Enable our users to build new GenAI capabilities. \n  Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks \n \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $197,400 - $225,300 for Lead Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $209,200 - $238,700 for Lead Machine Learning Engineer\n   Remote (Regardless of Location): $167,400 - $191,000 for Lead Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Center 1 (19052), United States of America, McLean, Virginia\n   Lead Engineer - Generative AI Product Engineering (Remote- Eligible)\n  \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Lead Generative AI Engineer to help build and maintain APIs and SDKs to train, fine-tune and access AI models at scale. You will work as part of our Enterprise AI team and build systems that will enable our users to work with Large-Language Models (LLMs) and Foundation Models (FMs), using our public cloud infrastructure. You will work with a team of world-class AI engineers and researchers to design and implement key API products and services that enable real-time customer-facing applications. Examples of projects you will work on include: \n \n \n  Architect, build and deploy well-managed core APIs and SDKs to access LLMs and our proprietary FMs including training, fine-tuning and prompting tasks, including orchestration SDKs. \n  Design APIs for performance, real-time applications, scale, ease of use and governance automation. \n  Develop application-specific interfaces that leverage LLMs and FMs to continue to enhance the associate and customer experience. \n  Enable our users to build new GenAI capabilities.    Develop tools and processes to monitor API access patterns and operational health. \n  Design and implement AI safety and guardrails in the API layer working closely with researchers. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity. \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques \n  At least 4 years of experience programming with Python, Scala, or Java \n  At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks   \n \n  Preferred Qualifications: \n \n  Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product-driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the foundational capabilities. \n  Familiarity with deploying large neural network models in demanding production environments. \n  Have experience with API security, observability, cloud access control and privacy best practices. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. ", "techs": ["python", "scala", "java"]}, "e20376a21481c4eb": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Director, Generative AI Infrastructure -(Remote-Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Senior Director, Generative AI Infrastructure -(Remote-Eligible)\n  \n  Senior Director, Generative AI Infrastructure \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Director, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities. \n  Develop SDKs and APIs for our user community to build agents, information retrieval and anomaly/fraud detection systems on our enterprise platforms.  \n \n \n Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 5 years of experience leading teams of engineers and applied scientists \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Computer Science, a related technical field, or or equivalent practical experience with experience in leading applied science and engineering teams. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Authored research publications in top peer-reviewed conferences, or industry recognized contributions in the space of neural networks, distributed training and SysML. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML on GPU clusters with a focus on distributed training, checkpointing and fault tolerance. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the core components of a platform. \n  Experience working with public cloud infrastructure such as AWS, Azure or GCP. \n  Familiarity with deploying large neural network models in demanding production environments. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr. Dir, Machine Learning Engineering\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr. Dir, Machine Learning Engineering\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr. Dir, Machine Learning Engineering\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Senior Director, Generative AI Infrastructure -(Remote-Eligible)\n  \n  Senior Director, Generative AI Infrastructure \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Sr. Director, Generative AI Infrastructure to help us build the foundations of our AI capabilities. You will work on a wide range of initiatives, whether that\u2019s building large-scale distributed training clusters, or deploying LLMs on GPU instances for real-time applications and decisioning systems, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work closely with our cloud and container infrastructure teams as well as our world-class team of AI researchers to design and implement key capabilities. Examples of projects you will work on: \n \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build run-time infrastructure for serving large ML models such as LLMs and FMs in our public cloud. \n  Build infrastructure for deploying search indexes and embeddings in vector databases that will work closely with the rest of our capabilities.   \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Computer Science, a related technical field, or or equivalent practical experience with experience in leading applied science and engineering teams. \n  Background in machine learning with experience in large scale training and deployment of deep neural nets and/or transformer architectures. \n  Authored research publications in top peer-reviewed conferences, or industry recognized contributions in the space of neural networks, distributed training and SysML. \n  Experience with machine learning frameworks such as TensorFlow or Pytorch, Lightning, Mosaic ML on GPU clusters with a focus on distributed training, checkpointing and fault tolerance. \n  Ability to move fast in an environment with ambiguity at times, and with competing priorities and deadlines. Experience at tech and product driven companies/startups preferred. \n  Ability to iterate rapidly with researchers and engineers to improve a product experience while building the core components of a platform. \n  Experience working with public cloud infrastructure such as AWS, Azure or GCP. \n  Familiarity with deploying large neural network models in demanding production environments. \n \n ", "techs": ["tensorflow", "pytorch", "lightning", "mosaic ml", "gpu clusters", "distributed training", "checkpointing", "fault tolerance", "aws", "azure", "gcp."]}, "e65f7a74d411cc58": {"terms": ["machine learning engineer"], "salary_min": 96603.97, "salary_max": 122322.16, "title": "Senior Full Stack Developer", "company": "Aggregage", "desc": "Remote \n  Aggregage is building the next generation of B2B media and marketing. We launch business segment specific sites that bring together the widest content set from industry thought-leaders and use social media, machine intelligence/smart algorithms and big data personalization to compile newsletters with the most relevant content for each and every reader. Using our proprietary technology platform, we curate and rank hundreds of pieces of content coming daily into each site using the audience\u2019s social media signals. Our technology personalizes the content so that each reader sees the most interesting and relevant content. We have launched over 35 sites and using our highly scalable platform, we are planning to launch hundreds more. \n  Come join an experienced and successful group of founders \u2013 Clicker, eHarmony, etc. \u2013 and their team at this groundbreaking time. We are profitable and capitalized for growth over the next several years. Our billion dollar potential is based on a real business model, not just hope and dreams. \n  We are looking for a Senior Full Stack Developer to join our small, but passionate team. You will work closely with your fellow development team members to help us build out features and scale the systems. \n  We believe in building the best team possible, regardless of geographic location. That said we have meetings and collaboration time that overlaps with the US Pacific Time Zone so team members must be able to be available during some of those hours each work day. \n  As a team we strive for: \n  Stakeholder and team impact. Our business is based on doing great things for our stakeholders: subscribers, bloggers, partners and clients. The best teammates are the ones who, regardless of function or discipline, are eager and excited to find a way to connect their work directly to stakeholders and teammates. \n  Trusted independence with interdependence. You are fully trusted as a full owner of the work you do; self-determined, responsible, accountable, and celebrated.  Learn and improve. We are in a constant learning and improving mode. We learn from what happens without worrying about something that doesn\u2019t achieve the desired outcome. We continuously retro across the organization to improve. \n  As an engineer, we hope you strive for: \n  The ability to work independently and with other engineers to develop new features and support/maintain the existing system. \n  The ability to work on multiple parts of a web application, from server-side logic to dynamic frontend interfaces. \n  Collaborate with product, other engineers, and stakeholders to understand business goals, analyze requirements, formulate solutions, and ensure the successful execution of new functionality. \n  Participate in code review and other forms of knowledge sharing. \n  Support fellow team members by developing what they need from the application. \n  Experience and Skills we are looking for: \n  3+ years with Java, in particular with large codebases and several thousands of users. An understanding of how to organize code for clarity and maintainability. \n  3+ years experience in developing complex client-side functionality using HTML, JavaScript with JQuery, and CSS. \n  2+ years experience developing web applications with Java Frameworks such as Spring, Dropwizard, or Wicket. \n  1+ years experience working with MySQL, including schema design and query tuning. \n  1+ years deploying on Linux servers, using command line tools and performing basic server administration tasks and system performance analysis. \n  An excellent \u201csystem intuition.\u201d We have complex systems built up over more than 8 years which require a strong ability to debug and quickly understand what is going on. \n  Excellent planning, communication and collaboration skills. \n  Understanding of best practices for web development, software design, and DevOps principles. \n  Nice to have, but not fully required experience: \n  Previous remote working experience. \n  Prior client services, consulting, or freelancing experience. \n  Working in a startup environment. \n  Working on web applications that process large volumes of data and/or receive high volumes of traffic. \n  Java performance analysis. \n  Mustache templates for server-side rendering. \n  Using Lucene or SOLR for full-text indexing and searching. \n  Git source control management. \n  AWS and Terraform. \n  Ant or Maven build tools. \n  How to Apply \n  Direct applicants only. No recruiters and no agencies please. We\u2019d also like you to answer these two questions for us: \n \n Please provide some reasons why you\u2019re interested in joining our team at Aggregage and why you believe it may be a mutual fit? \n Tell us about an interesting technical challenge you\u2019ve faced in the past. Share the problem, your approach in scoping down potential solutions, and what the final outcome was. \n \n Email us at jobs@aggregage.com with a copy of your resume and answers to the two questions above.", "cleaned_desc": "  3+ years experience in developing complex client-side functionality using HTML, JavaScript with JQuery, and CSS. \n  2+ years experience developing web applications with Java Frameworks such as Spring, Dropwizard, or Wicket. \n  1+ years experience working with MySQL, including schema design and query tuning. \n  1+ years deploying on Linux servers, using command line tools and performing basic server administration tasks and system performance analysis. \n  An excellent \u201csystem intuition.\u201d We have complex systems built up over more than 8 years which require a strong ability to debug and quickly understand what is going on. \n  Excellent planning, communication and collaboration skills. \n  Understanding of best practices for web development, software design, and DevOps principles. \n  Nice to have, but not fully required experience:    Previous remote working experience. \n  Prior client services, consulting, or freelancing experience. \n  Working in a startup environment. \n  Working on web applications that process large volumes of data and/or receive high volumes of traffic. \n  Java performance analysis. \n  Mustache templates for server-side rendering. \n  Using Lucene or SOLR for full-text indexing and searching. \n  Git source control management. ", "techs": ["html", "javascript", "jquery", "css", "java", "spring", "dropwizard", "wicket", "mysql", "linux servers", "command line tools", "server administration", "system performance analysis", "system intuition", "planning", "communication", "collaboration", "web development", "software design", "devops principles", "remote working experience", "client services", "consulting", "freelancing experience", "startup environment", "large volumes of data", "high volumes of traffic", "java performance analysis", "mustache templates", "lucene", "solr", "git"]}, "a88dba59f37b62ca": {"terms": ["machine learning engineer"], "salary_min": 90000.0, "salary_max": 129400.0, "title": "Sr. Consultant Engineer, Pulp & Paper, Southeast MI/Northeast OH", "company": "FM Global", "desc": "More information about this job: \n  Overview: \n \n \n \n \n     FM Global is a market leading property insurer of the world's largest businesses, providing more than one-third of FORTUNE 1000-size companies with engineering-based risk management and property insurance solutions. FM Global helps clients maintain continuity in their business operations by drawing upon state-of-the-art loss-prevention engineering and research, risk management advising, risk transfer capabilities, and superior financial strength. To do so, we rely on a dynamic, culturally diverse group of employees, working in more than 100 countries, in a variety of challenging roles.\n     \n \n  With the company\u2019s nearly two centuries of knowledge and experience behind you, you will work hands on with some of the world\u2019s most influential organizations, helping them understand risk and protect their assets. At FM Global you have the power to influence outcomes and make a difference in the future of your clients. You will develop strong client relationships to advise on risks associated with client businesses as well as develop and implement risk improvement strategies.\n     \n \n  When you join our team at FM Global, you will use your engineering background to learn how to assess a broad range of industrial facility hazards such as fire hazards, explosion hazards, flood hazard zones, structural collapse potential, mechanical and electrical failures, and more. Initially, assignments will be of limited scope and complexity giving you the opportunity to learn FM Global\u2019s loss prevention expertise with the support of experienced mentors and a structured engineering training program. You will gradually begin assessing risks at larger complex industrial sites. Learning and developing continues throughout your career, with promotion and growth opportunities, in a variety of technical career paths.\n     \n \n  FM Global is currently seeking a senior consultant engineer with heavy industry experience, preferably within the pulp and paper industry. The ideal candidate should understand the pulp and paper manufacturing processes and possess production or engineering experience within a typical paper mill.\n     \n \n \n  Approximately 30-50% of workload would be expected within the pulp and paper industry, including pulp manufacturers, paper manufacturers, paper-converting operations, and associated industry facilities. The remaining workload would be varied across all other industries. Consultant Engineers at FM Global enjoy the challenges and weekly variety in working with clients across industries such as healthcare, education, distribution/logistics, a wide range of manufacturing, and more.\n     \n \n \n \n \n     This position is based in Southeast Michigan or Northeast Ohio (working remotely from a home office) and reporting to the FM Global Cleveland office.\n      \n \n \n \n \n   Responsibilities: \n \n \n \n \n     Responsibilities of a Consultant Engineer include:\n      Identify property hazards (such as fire, explosion, and natural catastrophe hazards) at insured client facilities and deliver practical solutions to minimize or eliminate the hazard.\n     \n \n       Communicate key risks and priorities to support clients in making sound risk management decisions based on what matters most to their business. \n            Apply consistent risk assessment and risk mitigation guidance, based on use of FM Global Property Loss Prevention Data Sheets and company operating procedures, with an attention to technical detail. \n            \n Prepare technical engineering reports, with sound engineering-based judgements, decisions, and technical writing to document conclusions. \n \n \n \n Collaborate with various departments such as Operations Engineering, Client Services, Account Management and Underwriting on risk assessment and risk mitigation strategies.\n     \n \n       Develop long-lasting relationships with clients and act as a trusted advisor and consultant within your field. \n            Work from a home office, while managing time, meeting report delivery timelines, and working independently with minimal supervision. \n       Expected overnight travel once fully trained is 30% (up to 50-70 nights per year). Typical travel responsibilities will be concentrated in a 2 to 3-hour radius around your home office; however overnight travel may include all of Kentucky, Ohio, Michigan, Western Pennsylvania, West Virginia, and upstate New York (Buffalo NY region).  \n \n \n \n \n Qualifications: \n \n \n Minimum bachelor\u2019s degree in engineering (varies engineering disciplines considered); A chemical engineering background is a plus.  \n Possessing technical aptitude, knowledge of engineering principles, a sound problem-solving approach, and an eagerness to learn across a broad range of industries and types of hazards.  \n Minimum of 5 years\u2019 experience in heavy industry, preferably in a pulp and paper manufacturing environment. Title and compensation will be commensurate with experience.  \n Hands-on understanding of various chemical and mechanical production processes and support systems, which may include paper machines, pulp dryers, boilers, various processes involving flammable/combustible materials such as lubrication oil systems, hydraulic oil systems, chemical recovery systems, heat transfer fluid systems, and dust collection systems.  \n Experience in process safety practices and safety devices. Familiarity with sprinkler protection is a plus.  \n Independent and focused within a home office environment, with strong planning and time management skills. Enjoys working independently.  \n Strong verbal and written English communication skills, geared towards a consulting role.  \n Proficiency in Microsoft Office products. \n  A valid driver\u2019s license is required, a company car is provided. This is a field-based role and will require travel to large, complex industrial client sites. \n  Physically able to walk 2-3 miles per day during site evaluations. Physically able to lift 25 pounds, able to climb ladders, and experience heights. \n \n \n \n  FM Global is an Equal Opportunity Employer and is committed to attracting, developing, and retaining a diverse workforce.\n   \n \n \n  Title and compensation will be commensurate with experience. The hiring range for this position is $90,000 to $129,400. The final salary offer will vary based on geographic location, individual education, skills, and experience. The position is eligible to participate in FM Global\u2019s comprehensive Total Rewards program that includes an incentive plan, generous health and well-being programs, a 401(k) and pension plan, career development opportunities, tuition reimbursement, flexible work, time off allowances and much more.", "cleaned_desc": " Minimum bachelor\u2019s degree in engineering (varies engineering disciplines considered); A chemical engineering background is a plus.  \n Possessing technical aptitude, knowledge of engineering principles, a sound problem-solving approach, and an eagerness to learn across a broad range of industries and types of hazards.  \n Minimum of 5 years\u2019 experience in heavy industry, preferably in a pulp and paper manufacturing environment. Title and compensation will be commensurate with experience.  \n Hands-on understanding of various chemical and mechanical production processes and support systems, which may include paper machines, pulp dryers, boilers, various processes involving flammable/combustible materials such as lubrication oil systems, hydraulic oil systems, chemical recovery systems, heat transfer fluid systems, and dust collection systems.  \n Experience in process safety practices and safety devices. Familiarity with sprinkler protection is a plus.  \n Independent and focused within a home office environment, with strong planning and time management skills. Enjoys working independently.  \n Strong verbal and written English communication skills, geared towards a consulting role.  \n Proficiency in Microsoft Office products. \n  A valid driver\u2019s license is required, a company car is provided. This is a field-based role and will require travel to large, complex industrial client sites. \n  Physically able to walk 2-3 miles per day during site evaluations. Physically able to lift 25 pounds, able to climb ladders, and experience heights. \n \n \n \n  FM Global is an Equal Opportunity Employer and is committed to attracting, developing, and retaining a diverse workforce.\n   ", "techs": ["minimum bachelor\u2019s degree in engineering", "chemical engineering background", "technical aptitude", "knowledge of engineering principles", "problem-solving approach", "eagerness to learn", "5 years\u2019 experience in heavy industry", "pulp and paper manufacturing environment", "various chemical and mechanical production processes", "paper machines", "pulp dryers", "boilers", "flammable/combustible materials", "lubrication oil systems", "hydraulic oil systems", "chemical recovery systems", "heat transfer fluid systems", "dust collection systems", "process safety practices", "safety devices", "sprinkler protection", "independent work environment", "planning and time management skills", "verbal and written english communication skills", "proficiency in microsoft office products", "valid driver\u2019s license", "company car provided", "field-based role", "travel to industrial client sites", "physically able to walk 2-3 miles per day", "lift 25 pounds", "climb ladders", "experience heights", "equal opportunity employer", "diverse workforce."]}, "f675faf01e68e0de": {"terms": ["mlops"], "salary_min": 101379.695, "salary_max": 128369.29, "title": "DevOps Engineer", "company": "Cornelis Networks", "desc": "The ability to effectively focus a significant amount of computational power on solving critical problems through the use of artificial intelligence, data analytics, and modeling/simulation techniques is vital to many scientific, commercial, and government organizations. It is the mission of Cornelis Networks to deliver innovative purpose-built interconnect solutions that enable our customers to optimally apply vast computational resources to solve the world\u2019s toughest problems.\n  \n \n \n  Cornelis Networks is looking to grow the DevOps team to maintain and improve the tools, product build infrastructure, and development/release process. The overall goal is to build a services organization to implement and support automation between different groups throughout the company.\n  \n \n \n  Key Responsibilities \n \n \n Building and deploying new development tools and infrastructure \n Coordinating automation and tool integration with developers and validation team \n Managing CI pipeline infrastructure \n Managing and executing software build infrastructure \n Aiding in software support for new distributions \n Managing software smoke testing \n Build failure triaging and Linux system debugging. \n Delivering software builds to stakeholders for validation and release. \n Managing and executing legal compliance, security, and code analysis scans required for release. \n GitHub repository management \n Regular maintenance and enforcement of processes, procedures, and tools listed above. \n \n \n \n \n  Minimum Qualifications \n \n \n Bachelor's Degree \n Proficient scripting experience, including shell and Python. \n Proficient with git and git workflows \n Jenkins experience, including pipelines and Jenkins files. \n Linux administration (including RedHat, SUSE, and Ubuntu) \n \n \n \n \n  Preferred Qualifications \n \n \n Docker or other containerization platform experience \n Ansible/AWX experience \n ELK stack experience \n Some familiarity with Cobbler or other provisioning tool \n Familiarity with various security/legal compliance scan tools: Blackduck, Klockwork, CodeQL \n RPM packaging experience \n GNU make experience. \n \n \n \n  Preferred Location \n \n \n   For this position, Cornelis Networks fully supports remote employees who live within the United States and are able to travel to our corporate offices in Wayne, PA periodically for in-person collaboration.\n  \n \n \n  Cornelis Networks is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.\n  \n \n \n \n \n \n   Location\n   \n \n    Remote\n   \n \n \n \n \n    Department\n   \n \n    Software Engineering\n   \n \n \n \n \n    Employment Type\n   \n \n    Full-Time\n   \n \n \n \n \n    Minimum Experience\n   \n \n    Mid-level", "cleaned_desc": "The ability to effectively focus a significant amount of computational power on solving critical problems through the use of artificial intelligence, data analytics, and modeling/simulation techniques is vital to many scientific, commercial, and government organizations. It is the mission of Cornelis Networks to deliver innovative purpose-built interconnect solutions that enable our customers to optimally apply vast computational resources to solve the world\u2019s toughest problems.\n  \n \n \n  Cornelis Networks is looking to grow the DevOps team to maintain and improve the tools, product build infrastructure, and development/release process. The overall goal is to build a services organization to implement and support automation between different groups throughout the company.\n  \n \n \n  Key Responsibilities \n \n \n Building and deploying new development tools and infrastructure \n Coordinating automation and tool integration with developers and validation team \n Managing CI pipeline infrastructure \n Managing and executing software build infrastructure \n Aiding in software support for new distributions \n Managing software smoke testing \n Build failure triaging and Linux system debugging. \n Delivering software builds to stakeholders for validation and release.    Preferred Qualifications \n \n \n Docker or other containerization platform experience \n Ansible/AWX experience \n ELK stack experience \n Some familiarity with Cobbler or other provisioning tool \n Familiarity with various security/legal compliance scan tools: Blackduck, Klockwork, CodeQL \n RPM packaging experience \n GNU make experience. \n \n \n \n  Preferred Location \n \n \n   For this position, Cornelis Networks fully supports remote employees who live within the United States and are able to travel to our corporate offices in Wayne, PA periodically for in-person collaboration.\n  \n ", "techs": ["artificial intelligence", "data analytics", "modeling/simulation techniques", "devops", "docker", "ansible/awx", "elk stack", "cobbler", "blackduck", "klockwork", "codeql", "rpm packaging", "gnu make"]}, "87af9d5c96053652": {"terms": ["mlops"], "salary_min": 70.0, "salary_max": 100.0, "title": "DevOps Engineer", "company": "Synovize", "desc": "DevOps Engineer \n Introduction to Synovize: \n At Synovize, we combine innovation with seamless functionality, striving to provide outstanding solutions for businesses looking to synthesize and optimize their operations. As a DevOps Engineer at Synovize, you'll have the opportunity to collaborate with a team of forward-thinking engineers that are working on some of the most cutting-edge technologies in DevOps. \n Job Overview: \n We are looking for a seasoned DevOps Engineer to join our dynamic team. In this role, you will work closely with the development and operations teams to design, build, and maintain deployment pipelines and operational procedures. \n Responsibilities: \n \n Develop and implement CI/CD pipelines. \n Monitor the performance of deployments and maintain the health of production and pre-production environments. \n Use Ansible, Docker, Kubernetes, and Terraform for infrastructure management and automation. \n Work with AWS to manage our cloud-based resources. \n \n Requirements: \n \n US Citizen with the ability to gain Security Clearance. \n Proven experience in a DevOps role. \n Proficient knowledge of Ansible, Docker, Kubernetes, Terraform, Python, and AWS. \n Excellent problem-solving skills. \n Familiarity with Agile development methodologies. \n \n Preferred: \n \n A degree in Computer Science, Information Technology or a related field. \n AWS Certified DevOps Engineer or similar certification. \n \n Outro: \n At Synovize, we value diversity, inclusivity, and creativity. If you are a committed, team-oriented professional who is eager to implement cutting-edge technologies and drive forward the future of DevOps, we encourage you to apply. \n Job Types: Full-time, Contract \n Pay: $70.00 - $100.00 per hour \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Life insurance \n Paid time off \n Referral program \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n Overtime pay \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n Overtime \n Weekends as needed \n \n Application Question(s): \n \n Are you a US Citizen? If not, what is your current citizenship status? \n \n Experience: \n \n AWS: 1 year (Preferred) \n Kubernetes: 1 year (Preferred) \n DevOps Engineering: 1 year (Preferred) \n \n Security clearance: \n \n Top Secret (Preferred) \n \n Work Location: Remote", "cleaned_desc": "DevOps Engineer \n Introduction to Synovize: \n At Synovize, we combine innovation with seamless functionality, striving to provide outstanding solutions for businesses looking to synthesize and optimize their operations. As a DevOps Engineer at Synovize, you'll have the opportunity to collaborate with a team of forward-thinking engineers that are working on some of the most cutting-edge technologies in DevOps. \n Job Overview: \n We are looking for a seasoned DevOps Engineer to join our dynamic team. In this role, you will work closely with the development and operations teams to design, build, and maintain deployment pipelines and operational procedures. \n Responsibilities: \n \n Develop and implement CI/CD pipelines. \n Monitor the performance of deployments and maintain the health of production and pre-production environments. \n Use Ansible, Docker, Kubernetes, and Terraform for infrastructure management and automation. \n Work with AWS to manage our cloud-based resources. \n \n Requirements: \n \n US Citizen with the ability to gain Security Clearance. \n Proven experience in a DevOps role. \n Proficient knowledge of Ansible, Docker, Kubernetes, Terraform, Python, and AWS. \n Excellent problem-solving skills. ", "techs": ["ansible", "docker", "kubernetes", "terraform", "python", "aws"]}, "b31c0c6630150d23": {"terms": ["mlops"], "salary_min": 70.0, "salary_max": 100.0, "title": "DevOps Manager", "company": "Synovize", "desc": "Introduction to Synovize: \n Synovize is committed to advancing the boundaries of technology and innovation. As the DevOps Manager at Synovize, you will be at the helm of our dynamic team, driving forward our operations and ensuring the deployment of top-tier solutions for our clients. \n Job Overview: \n We are in search of a DevOps Manager to lead our DevOps team. The ideal candidate will be responsible for overseeing our DevOps operations and ensuring smooth collaboration between our development and operations teams. \n Responsibilities: \n \n Manage and provide direction for the DevOps team in support of business operations. \n Develop, implement, and optimize continuous delivery pipelines. \n Utilize Docker, Kubernetes, Terraform, Ansible, Python, and AWS to manage and automate our infrastructure. \n Collaborate with stakeholders to identify operational needs and establish DevOps practices within the organization. \n \n Requirements: \n \n US Citizen with the ability to gain Security Clearance. \n Proven experience as a DevOps Manager or similar leadership role. \n Proficiency in Docker, Kubernetes, Terraform, Ansible, Python, and AWS. \n Strong communication and team management skills. \n Bachelor\u2019s degree in Computer Science, Engineering, or a related field. \n \n Preferred: \n \n Master's degree in a related field. \n Certifications in AWS and other DevOps tools. \n \n Outro: \n Synovize is committed to fostering an inclusive, innovative environment where every idea is heard and every individual matters. If you're an experienced DevOps professional who's ready to lead and inspire a team of like-minded innovators, we'd love to hear from you. \n Job Types: Full-time, Contract \n Pay: $70.00 - $100.00 per hour \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Life insurance \n Paid time off \n Referral program \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n Overtime pay \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n Overtime \n Weekends as needed \n \n Application Question(s): \n \n Are you a US Citizen? If not, what is your current citizenship status? \n \n Experience: \n \n AWS: 1 year (Preferred) \n Kubernetes: 1 year (Preferred) \n DevOps Engineering: 1 year (Preferred) \n \n Security clearance: \n \n Top Secret (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "bcff67c1331ca954": {"terms": ["mlops"], "salary_min": 106103.45, "salary_max": 134350.61, "title": "Manager, DevOps (Remote)", "company": "The Infosoft Group", "desc": "Do work that matters. \n  At AlertMedia, everything we do supports our mission:  to save lives and minimize loss by identifying active threats globally and facilitating timely communications when an emergency threatens personal safety and business continuity. \n  Our values, which reflect our view on what's important and what's right, include:  We're humans not robots, Customers always come first, We work better together, Simplicity is our strength, Our reputation is priceless, Hard work pays off. \n  AlertMedia is looking for a  Manager, DevOps,  to guide the evolution of our systems infrastructure with a collaborative team of DevOps engineers. This role provides an opportunity to manage and expand our extensive AWS infrastructure to meet the needs of our rapidly growing customer base. The ideal candidate is passionate about automation, scalability, and security with deep knowledge and experience with AWS technologies and is motivated to support the career growth and development of their team. As part of a small team, you will wear many hats and partner with the development team to design, develop, troubleshoot, and maintain all aspects of the AlertMedia platforms. \n  Who you are: \n  You're excited to lead a team of DevOps Engineers to help ensure the stability of a product that makes a huge impact and can never go down. You stay abreast of the latest security and networking technology to make sure you're ahead of the curve. You have disaster recovery down and have created contingency plans for a variety of scenarios. You're an AWS and Linux expert and have a meticulous drive for excellence in your work. You take mentoring seriously and create opportunities to grow your team members' skills. Others would call you a player/coach who is willing to jump in and help where needed, open to sharing ideas and best practices. \n  What you get to do every day: \n \n Manage the professional development and technical direction for a team of DevOps Engineers \n Work in a secure, reliable, and scalable infrastructure that cannot fail during critical local, national, and global events \n Become an expert in the AlertMedia platform and tools, and its uses for our customers \n Work with various AWS Services, Docker, Linux, and continuous deployment tools, and work with tools like Terraform for infrastructure as code \n Continually evaluate the security of our systems and applications, with an emphasis on data security \n Work with the team to determine tool requirements, then drive the implementation, documentation, maintenance, and improvement \n Collaborate in an Agile based environment using tools like Git, JIRA, Jenkins, and Slack \n Contribute to the technology lead that AlertMedia has over other solutions through innovative development and by helping contribute new ideas related to leveraging technology in our product line \n Invest in AlertMedia's culture, values, and vision for the future \n \n What you bring to the role: \n \n 6+ years of operations engineering experience \n Experience leading & developing a team of DevOps Engineers \n Extensive experience in designing, configuring, deploying, managing & automating AWS Core Services like S3, IAM, EC2, ECS, Route53, SNS, SQS, ELB, CloudWatch, Lambda and VPC \n Hands-on experience with Terraform and Docker \n Expertise with Linux, security, and networking fundamentals \n Experience developing and maintaining disaster recovery systems and automation \n Experience managing large scale deployments \n Expertise in troubleshooting complex customer-facing systems \n Proficiency in at least one coding language (Python is a plus) \n Strong organizational skills and ability to manage working on multiple projects in parallel \n Problem-solving attitude with a collaborative team spirit \n The ability and desire to work in a fast-paced challenging environment \n Bachelor's degree in a technical field such as computer science, computer engineering or related field preferred \n AlertMedia does not currently sponsor applicants for work visas \n Position is open for remotelocation in the United States except for in the followingstates:Alaska, Colorado, Hawaii, Louisiana, Montana, North Dakota, Oregon, or West Virginia \n \n Why you'll love working at AlertMedia: \n \n Competitive base salary +Company-wide bonus program \n Generous and flexible time off and parental leave policies \n Health benefits - Medical, Dental, Vision and Life Insurance are 100% paid for employees! \n Amazing rewards and incentives - we love celebrating each other! \n Commitment to community service with opportunities to give back \n A Best Places to Work company 6 years in a row and numerous other awards \n Access to brand new downtown office with 360 views of Austin, high-tech building gym, and nearby running trails \n \n About AlertMedia: \n  AlertMediais leading the evolution of employee safety for a modern workforce. We offer the most intuitive emergency communication software on the market with fully integrated threat warnings and employee safety monitoring. We believe any organization can improve safety and business outcomes during critical events by quickly identifying threats and simplifying fast, reliable communication to impacted audiences. We are headquartered in Austin, TX, and trusted by thousands of customers in over 100 countries-including DHL, British Petroleum, SurveyMonkey, and Walmart-to keep their people safe and connected anytime, anywhere. \n  We are an equal opportunity employer focused on creating a collaborative and exciting place for all to work. Ensuring a diverse, inclusive, and equitable workplace for all people is key to our success and core to our values.All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. \n  This is an amazing opportunity to be part of our wave of momentum and take our company, and your career, to the next growth stage. We'd love to get to know you better and share how we serve our amazing customers. For moreinformation,please visit . \n  Come join us in our mission to save lives and minimize loss through effective communication. \n  AlertMedia does not currently sponsor applicants for work visas. \n  Position is open for remotelocation except for in the followingstates:Alaska, Colorado, Hawaii, Louisiana, Montana, North Dakota, Oregon, West Virginia, US territories \n  By applying for the role, you agree that Alert Media will use your Personal Information in connection with the recruitment process and in accordance with our Privacy Policy - \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   AlertMedia \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   6+ years", "cleaned_desc": " \n 6+ years of operations engineering experience \n Experience leading & developing a team of DevOps Engineers \n Extensive experience in designing, configuring, deploying, managing & automating AWS Core Services like S3, IAM, EC2, ECS, Route53, SNS, SQS, ELB, CloudWatch, Lambda and VPC \n Hands-on experience with Terraform and Docker \n Expertise with Linux, security, and networking fundamentals \n Experience developing and maintaining disaster recovery systems and automation \n Experience managing large scale deployments \n Expertise in troubleshooting complex customer-facing systems \n Proficiency in at least one coding language (Python is a plus) \n Strong organizational skills and ability to manage working on multiple projects in parallel \n Problem-solving attitude with a collaborative team spirit \n The ability and desire to work in a fast-paced challenging environment \n Bachelor's degree in a technical field such as computer science, computer engineering or related field preferred \n AlertMedia does not currently sponsor applicants for work visas \n Position is open for remotelocation in the United States except for in the followingstates:Alaska, Colorado, Hawaii, Louisiana, Montana, North Dakota, Oregon, or West Virginia \n \n Why you'll love working at AlertMedia: \n ", "techs": ["terraform", "docker", "aws (s3", "iam", "ec2", "ecs", "route53", "sns", "sqs", "elb", "cloudwatch", "lambda", "vpc)", "linux", "python", "disaster recovery systems", "coding language", "networking fundamentals", "troubleshooting", "bachelor's degree"]}, "8d07e64736afc700": {"terms": ["mlops"], "salary_min": 70000.0, "salary_max": 140000.0, "title": "DevOps Engineer - IntelliScript (Remote)", "company": "The Infosoft Group", "desc": "Description\n  \n  What We Do \n  Milliman IntelliScript is a group of a few hundred experts in fields ranging from actuarial science to information technology to clinical practice. Together, we develop and deploy category-defining, data-driven, software-as-a-service (SaaS) products for a broad spectrum of insurance clients. We're a business unit within Milliman, Inc., a respected consultancy with offices around the world. \n  Candidates who have their pick of jobs are drawn to IntelliScript's entrepreneurial and collaborative culture of innovation, excellence, exceptional customer service, balance, and transparency. Every single person has a voice in our company, and we challenge each other to push the outer limits of our full, diverse potential. And, we've shown sustained growth that ensures you'll have room to grow your skillset, responsibilities, and career. \n  Our team is smart, down-to-earth, and ready to listen to your best ideas. We reward excellence and offer competitive compensation and benefits. Visit our for a closer look at our company, and learn more about our cultural values . \n  What this position entails \n  IntelliScript's Information Technology has been a key part of our success and is critical to our future. In this position, you will help define IntelliScript's DevOps strategy, acting as an automation advocate when interfacing with the development team. Leveraging your familiarity with DevOps processes, platforms and systems, you will develop and maintain the existing CI/CD pipelines using Azure DevOps Server. This position will emphasize incremental improvements to our DevOps strategy by presenting compelling data analysis - while also helping to perform the existing, semi-manual process. \n  What you'll be doing \n \n Track and coordinate releases for multiple development teams \n Build and release pipeline responsibilities \n Support existing manual release processes \n Identify and implement release automation best practices \n Collaborate with development, system engineer and database administrator teams \n Support evening and weekend releases, during scheduled maintenance windows \n \n What we need \n \n 4+ years of relevant experience \n Experience with DevOps tooling & practices (Git, CI-CD orchestration software, database automation, configuration-as-code, developing/improving the SDLC process) \n Experience performing build and release configuration & management \n Experience architecting, implementing, and supporting containers in a Windows environment \n Development/related technical expertise (preferably in an Agile/Scrum environment) \n Experience working with the following: PowerShell, C#, SQL, Javascript, .NET/.NET Core applications, APIs, NuGet and Microsoft Windows infrastructure \n Ability to ramp up quickly on both new technologies and existing technologies \n Ability to think both tactically & strategically \n Excellent documentation skills \n Excellent technical design, problem solving, and debugging skills \n Excellent collaborative skills, with strong written and verbal communication \n Self-motivated team player who can run with a project and is willing to pitch in as needed \n \n What you bring to the table \n \n Demonstrated \"let's find a way to do it\" attitude - no task is too big or too small \n Comfortable working through ambiguous situations \n Collaborative and diplomatic approach, willing to accept or challenge the status quo \n Ability to manage a variety of simultaneous projects \n Loves to learn, takes every opportunity to develop knowledge and skills \n Able to teach & mentor others on new/emerging technologies \n \n Wish List \n \n Continued education and/or advanced degree(s) \n Experience with database change automation \n Experience with Atlassian suite of products (Jira, Confluence) \n \n Location  \n This position will be based out of the Milliman office in Brookfield, WI; however, this position is open to remote work. Applicants must be willing to travel to the Milliman office in Brookfield, WI as needed. \n  The base salary for the position will vary with the candidate's qualications and experience. The salary range is $70,000 to $140,000, depending on relevant factors, including but not limited to education, skills, certifications, and location. If overall experience is less than 6 years the range would be $70,000 to $115,000; for experience of greater than 6 years, the range would be $85,000 to $140,000. In addition, we offer a performance-based bonus plan, prot sharing, and generous benets. \n  Milliman Benefits (U.S. only) \n  At Milliman, we focus on creating an environment that recognizes - and meets - the personal and professional needs of the individual and their family. We offer competitive benefits which include the following based on plan eligibility: \n \n Medical, dental and vision coverage for employees and their dependents, including domestic partners \n A 401(k) plan with matching program, and profit sharing contribution \n Employee Assistance Program (EAP) \n A discretionary bonus program \n Paid Time Off (PTO) starts accruing on the first day of work and can be used for any reason; full-time employees will accrue \n 15 days of PTO per year, and employees working less than a full-time schedule will accrue PTO at a prorated amount based on hours worked \n Family building benefits, including adoption and fertility assistance and paid parental leave up to 12 weeks for employees who have worked for Milliman for at least 12 months and have worked at least 1,250 hours in the preceding 12-month period \n A minimum of 8 paid holidays \n Milliman covers 100% of the premiums for life insurance, AD&D, and both short-term and long-term disability coverage \n Flexible spending accounts allow employees to set aside pre-tax dollars to pay for dependent care, transportation, and applicable medical needs \n \n \n All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities \n \n \n \n  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c) \n \n  Milliman is an equal opportunity employer\n  \n  Our company, with the full support of our Chief Executive Officer, is fully committed to the maximum utilization of all human resources and the goals of Equal Employment Opportunity and Affirmative Action. We recruit, hire, train, and promote, and consider qualified applicants for employment, in all job titles without regard to age, ancestry, citizenship status, color, creed, familial status, genetic information, marital status, national origin, political ideology, race, religion, sex, sexual orientation, gender identity, status as an individual with a disability, or veteran status, including qualified disabled veterans, Armed Forces service medal veterans, recently separated veterans, and active duty wartime or campaign badge veterans; and shall not discriminate against any individual, or any other characteristic protected by law.\n  \n  Reasonable Accommodation Notice\n  \n  Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Milliman, Inc \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Experience\n   \n \n   4+ years", "cleaned_desc": " Development/related technical expertise (preferably in an Agile/Scrum environment) \n Experience working with the following: PowerShell, C#, SQL, Javascript, .NET/.NET Core applications, APIs, NuGet and Microsoft Windows infrastructure \n Ability to ramp up quickly on both new technologies and existing technologies \n Ability to think both tactically & strategically \n Excellent documentation skills \n Excellent technical design, problem solving, and debugging skills \n Excellent collaborative skills, with strong written and verbal communication \n Self-motivated team player who can run with a project and is willing to pitch in as needed \n \n What you bring to the table \n \n Demonstrated \"let's find a way to do it\" attitude - no task is too big or too small \n Comfortable working through ambiguous situations \n Collaborative and diplomatic approach, willing to accept or challenge the status quo \n Ability to manage a variety of simultaneous projects \n Loves to learn, takes every opportunity to develop knowledge and skills \n Able to teach & mentor others on new/emerging technologies \n \n Wish List \n \n Continued education and/or advanced degree(s) \n Experience with database change automation \n Experience with Atlassian suite of products (Jira, Confluence) ", "techs": ["powershell", "c#", "sql", "javascript", ".net/.net core applications", "apis", "nuget", "microsoft windows infrastructure", "jira", "confluence"]}, "efab26c677245ddf": {"terms": ["mlops"], "salary_min": 106232.22, "salary_max": 134513.66, "title": "DevOps Cloud Engineer - Remote", "company": "The Infosoft Group", "desc": "Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today's most important industries. Our growth is driven by delivering real results for our clients. It's also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it's no wonder we're consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you're as passionate about your future as we are, join our team. \n  KPMG is currently tunity. \n  Responsibilities: \n \n  Develop and maintain reusable templates and code to automate solution delivery and deployment processes across multiple cloud providers \n  Collaborate with Enterprise architects, security, and SMEs to establish and enforce DevOps standards, best practices, and procedures \n  Identify manual processes and procedures and design and implement automation solutions using cloud native services \n  Develop and maintain technical documentation, including knowledge base articles and best practices \n  Provide third-tier support to the operations and support teams; troubleshoot and resolve issues related to cloud infrastructure and deployments \n  Stay up to date with industry trends and advancements in cloud technologies, evaluate and recommend new tools, services, and methodologies to improve the overall DevOps process \n \n  Qualifications: \n \n  Minimum five years of recent, practical experience delivering automated, secure cloud infrastructure solutions at enterprise scale \n  Bachelor's degree from an accredited college or university is preferred; any cloud certification is preferred \n  Proficiency in scripting languages such as Python, PowerShell, or Bash is preferred \n  Extensive direct experience with cloud platforms such as Azure, AWS, or Google Cloud Platform \n  Proven experience with infrastructure-as-code tools such as Terraform, ARM templates, CloudFormation; solid experience with CI/CD tooling (e.g., GitHub, Azure DevOps, etc.) \n  Excellent problem-solving and troubleshooting skills, with the ability to identify and resolve complex technical issues; strong oral and written communication skills, with the ability to effectively interact with individuals at all levels of responsibility and authority with poise \n  US Citizenship is required \n \n KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the salary range(s) are displayed via the URL below. The range is specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, performance, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your emotion and mental health. KPMG provides personal days off per fiscal year depending on job classification, standard work hours and years of service. Additionally, each year the firm publishes a calendar of holidays to be observed during the year. Available benefits are based on eligibility.  Albany Salary Range: Low: $113300 - High: $210500\n  \n   Colorado Salary Range: Low: $119000 - High: $221000\n  \n \n   New York City Salary Range: Low: $130300 - High: $242100\n  \n \n   Seattle Salary Range: Low: $124600 - High: $231600\n  \n \n   Melville Salary Range: Low: $127200 - High: $236200\n  \n \n   Rochester Salary Range: Low: $115600 - High: $214700\n    Follow this link to obtain salary ranges by city:   \n \n \n  https://www.kpmg.us/work-for-kpmg/pay-transparency.html/?id=6701-9\n   KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please. \n KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site). \n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   KPMG \n   \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   Bachelor's Degree\n   \n \n \n \n   Required Experience\n   \n \n   5+ years", "cleaned_desc": "Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today's most important industries. Our growth is driven by delivering real results for our clients. It's also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it's no wonder we're consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you're as passionate about your future as we are, join our team. \n  KPMG is currently tunity. \n  Responsibilities: \n \n  Develop and maintain reusable templates and code to automate solution delivery and deployment processes across multiple cloud providers \n  Collaborate with Enterprise architects, security, and SMEs to establish and enforce DevOps standards, best practices, and procedures \n  Identify manual processes and procedures and design and implement automation solutions using cloud native services \n  Develop and maintain technical documentation, including knowledge base articles and best practices \n  Provide third-tier support to the operations and support teams; troubleshoot and resolve issues related to cloud infrastructure and deployments \n  Stay up to date with industry trends and advancements in cloud technologies, evaluate and recommend new tools, services, and methodologies to improve the overall DevOps process \n \n  Qualifications: \n \n  Minimum five years of recent, practical experience delivering automated, secure cloud infrastructure solutions at enterprise scale \n  Bachelor's degree from an accredited college or university is preferred; any cloud certification is preferred \n  Proficiency in scripting languages such as Python, PowerShell, or Bash is preferred \n  Extensive direct experience with cloud platforms such as Azure, AWS, or Google Cloud Platform ", "techs": ["kpmg", "devops", "cloud providers", "enterprise architects", "security", "smes", "cloud native services", "technical documentation", "knowledge base articles", "best practices", "third-tier support", "troubleshooting", "industry trends", "cloud technologies", "tools", "services", "methodologies", "automated", "secure cloud infrastructure solutions", "python", "powershell", "bash", "azure", "aws", "google cloud platform"]}, "73b3f679d0091ec9": {"terms": ["mlops"], "salary_min": 105420.49, "salary_max": 133485.83, "title": "Sr. DevOps Engineer (US REMOTE)", "company": "The Infosoft Group", "desc": "Company Overview\n   At Motorola Solutions, we believe that everything starts with safety.It's the constant that empowers people to confidently move forward. It can fill a flight or sell out a stadium. It can care for a patient or graduate a class.    As a global leader in public safety and enterprise security, we create and connect the technologies that help to keep people safe where they live, learn, work and play. Our integrated technology ecosystem unifies critical communications, video security and access control, and command center software, enabling collaboration in more powerful ways.    At Motorola Solutions, we're ushering in a new era in public safety and security. Bring your passion, potential and talents to a career that matters.  Department OverviewThe Vehicle Intelligence group at Motorola Solutions is dedicated to providing innovative solutions to capture and provide value to Vehicle data. As part of the DevOps team for Vehicle Intelligence, we are dedicated to providing reliability, security, operations engineering, and integrations with our products and partners. We provide cutting-edge SaaS solutions while also using AI and advanced computing for our thousands of customers in Public Safety and Enterprise Security worldwide.Job Description\n   We are fostering innovation, we encourage you to apply. \n \n  Responsibilities: \n \n \n  As a Senior DevOps Engineer, you will be instrumental in enhancing our engineering practices and contributing to business objectives. \n  Collaborating with cross-functional teams to translate business requirements into technology solutions. \n  Participating in the complete software development lifecycle, from planning and design to testing, implementation, and maintenance. \n  Creating, developing, designing, and refining products, equipment, services, and procedures within engineering fields. \n  Defining technical direction for product portfolios and implementing strategies. \n  Assisting in the planning, design, testing, and implementation of enterprise applications and systems. \n  Supporting large scale SaaS solutions in AWS and Azure service implementations through architecture guidance, troubleshooting, and more. \n  Acting as a trusted technical advisor for SaaS applications to address complex Azure and AWS Infrastructure and DevOps challenges. \n  Communicating effectively via various mediums, including video conferencing, meetings, and technical reviews. \n  Guiding SaaS development team in configuring and deploying their Azure and AWS infrastructure for optimal scaling, security, and cost efficiency. \n  Designing solutions using Azure and AWS PaaS services, event-driven architecture, and container-based solutions. \n  Establishing modern DevOps practices and CI/CD pipelines. \n \n \n  Qualifications: \n \n  Proven expertise in multi-technology application design best practices, offering valuable guidance to internal teams for optimal application designs. \n  Proficiency in overage. \n  Strong analytical and problem-solving skills, capable of working with abstract concepts effectively. \n  Excellent interpersonal skills, enabling effective collaboration and interaction with various stakeholders. \n  In-depth technical understanding of development and platform engineering. \n  Client-centric mindset with a focus on driving business outcomes. \n  Highly organized and adept at planning. \n  Self-starter with exceptional self-management abilities. \n  Strategic thinker capable of defining technical direction for product portfolios, including devising technical strategies, execution plans, and fostering strong stakeholder relationships. \n  Outstanding communication skills for engaging with both technical and non-technical stakeholders. \n  Detail-oriented team player with a commitment to continuous improvement. \n  Proficient in project management principles to ensure successful large-scale project execution such as new technology migrations and expansions. \n  Strong contribution to enhancing internal effectiveness by refining methodologies, processes, and tools. \n  Solid organizational, analytical, written, verbal, and interpersonal skills. \n \n \n  Work Experience: \n \n  Demonstrated experience of 4+ years in Software Development and IT Support. \n  Hands-on experience deploying software solutions in high-volume web environments for 4+ years. \n  Proven track record of working in multi-team environments across diverse geographies. \n  Familiarity with IT security best practices, including encryption, certificates, and key management. \n  Expertise in Cloud adoption, migration, and deployment on Microsoft Azure and Amazon AWS. \n  Proficiency in tools like Kubernetes, Docker, GitHub Actions, Terraform. \n  Competence in CI/CD, Deployment Management, and defining/designing CI/CD pipelines on Azure Cloud. \n  Strong communication skills targeting both technical and non-technical audiences. \n  Background in CI/CD pipeline tools using source control, automated build/test, and code coverage analysis. \n  Proficiency in scripting languages, particularly adept in Python. \n  Hands-on experience with containerization and orchestration technologies, especially Docker Container Management. \n  Strong DevOps skills (7+ years), including expertise in deploying enterprise distributed solutions on hybrid infrastructures. \n \n \n  Education and Certifications: \n \n  Bachelor's degree in Computer Science, Software Engineering, Information Systems, or related field (Alternatively, Associate degree with 7+ years' compensating experience, or High School Diploma with 12+ years' compensating experience). \n  Relevant DevOps certifications, AWS, and Azure Certifications are a plus. \n  Agile-related certifications are preferable. \n \n \n  Note: Candidates must meet CJIS FBI background check requirements and be eligible to work in the United States. \n \n  #LI-MP2  #LI-REMOTE \n \n  Notes: Candidate can reside anywhere in the US.  Basic Requirements\n  \n  Bachelors Degree with 7+ years of professional IT experience and compensating DevOps experience \n  OR 12+ years of professional IT experience and compensating DevOps experience \n  Legal authorization to work in the U.S. indefinitely is required. Employer work permit sponsorship is not available for this position. \n  Travel RequirementsNoneRelocation ProvidedNonePosition TypeExperiencedReferral Payment PlanNo\n  \n  Our  U.S.Benefitsinclude: \n \n  Incentive Bonus Plans \n  Medical, Dental, Visionbenefits \n  401K with Company Match \n  9 Paid Holidays \n  GenerousPaidTime Off Packages \n  Employee Stock Purchase Plan \n  PaidParental & Family Leave \n  and more! \n \n  EEO Statement \n  Motorola Solutions is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran's status, or, any other protected characteristic. \n \n  Motorola Solutions is an Equal Opportunity Employer committed to no discrimination because of race, color, creed, marital status, age, religion, sex, national origin, citizenship, sexual orientation, gender identity or expression, genetic information, disability, protected veteran, or any other legally protected characteristic.\n \n \n \n \n \n  Job Summary \n  \n \n \n   Company\n   \n \n   Motorola Solutions \n   \n \n \n \n \n   Start Date\n   \n \n   As soon as possible\n   \n \n \n \n   Employment Term and Type\n   \n \n   Regular, Full Time\n   \n \n \n \n   Required Education\n   \n \n   High School or Equivalent\n   \n \n \n \n   Required Experience\n   \n \n   4+ years", "cleaned_desc": "Company Overview\n   At Motorola Solutions, we believe that everything starts with safety.It's the constant that empowers people to confidently move forward. It can fill a flight or sell out a stadium. It can care for a patient or graduate a class.    As a global leader in public safety and enterprise security, we create and connect the technologies that help to keep people safe where they live, learn, work and play. Our integrated technology ecosystem unifies critical communications, video security and access control, and command center software, enabling collaboration in more powerful ways.    At Motorola Solutions, we're ushering in a new era in public safety and security. Bring your passion, potential and talents to a career that matters.  Department OverviewThe Vehicle Intelligence group at Motorola Solutions is dedicated to providing innovative solutions to capture and provide value to Vehicle data. As part of the DevOps team for Vehicle Intelligence, we are dedicated to providing reliability, security, operations engineering, and integrations with our products and partners. We provide cutting-edge SaaS solutions while also using AI and advanced computing for our thousands of customers in Public Safety and Enterprise Security worldwide.Job Description\n   We are fostering innovation, we encourage you to apply. \n \n  Responsibilities: \n \n \n  As a Senior DevOps Engineer, you will be instrumental in enhancing our engineering practices and contributing to business objectives. \n  Collaborating with cross-functional teams to translate business requirements into technology solutions. \n  Participating in the complete software development lifecycle, from planning and design to testing, implementation, and maintenance. \n  Creating, developing, designing, and refining products, equipment, services, and procedures within engineering fields. \n  Defining technical direction for product portfolios and implementing strategies. \n  Assisting in the planning, design, testing, and implementation of enterprise applications and systems. \n  Supporting large scale SaaS solutions in AWS and Azure service implementations through architecture guidance, troubleshooting, and more. \n  Acting as a trusted technical advisor for SaaS applications to address complex Azure and AWS Infrastructure and DevOps challenges. \n  Communicating effectively via various mediums, including video conferencing, meetings, and technical reviews. \n  Guiding SaaS development team in configuring and deploying their Azure and AWS infrastructure for optimal scaling, security, and cost efficiency. \n  Designing solutions using Azure and AWS PaaS services, event-driven architecture, and container-based solutions. \n  Establishing modern DevOps practices and CI/CD pipelines. \n \n \n  Qualifications: \n \n  Proven expertise in multi-technology application design best practices, offering valuable guidance to internal teams for optimal application designs. \n  Proficiency in overage. \n  Strong analytical and problem-solving skills, capable of working with abstract concepts effectively.    Excellent interpersonal skills, enabling effective collaboration and interaction with various stakeholders. \n  In-depth technical understanding of development and platform engineering. \n  Client-centric mindset with a focus on driving business outcomes. \n  Highly organized and adept at planning. \n  Self-starter with exceptional self-management abilities. \n  Strategic thinker capable of defining technical direction for product portfolios, including devising technical strategies, execution plans, and fostering strong stakeholder relationships. \n  Outstanding communication skills for engaging with both technical and non-technical stakeholders. \n  Detail-oriented team player with a commitment to continuous improvement. \n  Proficient in project management principles to ensure successful large-scale project execution such as new technology migrations and expansions. \n  Strong contribution to enhancing internal effectiveness by refining methodologies, processes, and tools. \n  Solid organizational, analytical, written, verbal, and interpersonal skills. \n \n \n  Work Experience: \n \n  Demonstrated experience of 4+ years in Software Development and IT Support. \n  Hands-on experience deploying software solutions in high-volume web environments for 4+ years. \n  Proven track record of working in multi-team environments across diverse geographies. \n  Familiarity with IT security best practices, including encryption, certificates, and key management. \n  Expertise in Cloud adoption, migration, and deployment on Microsoft Azure and Amazon AWS. \n  Proficiency in tools like Kubernetes, Docker, GitHub Actions, Terraform. \n  Competence in CI/CD, Deployment Management, and defining/designing CI/CD pipelines on Azure Cloud. \n  Strong communication skills targeting both technical and non-technical audiences. \n  Background in CI/CD pipeline tools using source control, automated build/test, and code coverage analysis. \n  Proficiency in scripting languages, particularly adept in Python. \n  Hands-on experience with containerization and orchestration technologies, especially Docker Container Management. ", "techs": ["motorola solutions", "saas solutions", "ai", "advanced computing", "aws", "azure", "devops", "engineering practices", "business requirements", "software development lifecycle", "enterprise applications", "saas applications", "azure and aws infrastructure", "devops challenges", "event-driven architecture", "ci/cd pipelines", "application design", "analytical skills", "interpersonal skills", "project management principles", "new technology migrations", "software development", "it support", "web environments", "it security best practices", "encryption", "certificates", "key management", "kubernetes", "docker", "github actions", "terraform", "ci/cd", "deployment management", "azure cloud", "scripting languages", "python", "containerization", "docker container management."]}, "05787da83d4ad028": {"terms": ["mlops"], "salary_min": 109693.734, "salary_max": 138896.72, "title": "Azure DevOps Engineer", "company": "Precision Medicine Group", "desc": "Are you an Azure DevOps Engineer who wants to work in a high-volume build environment supporting Global Corporate IT Operations? Do you like orchestrating processes from scripts and automation to full DevOps builds? Our Cloud Solutions team is hiring an DevOps Engineer to help us build the next phases of our Global IT Infrastructure and grow our expanding team of professionals. \n  THIS IS A FULLY REMOTE OPPORTUNITY, but job seekers must currently reside in United States (ideally in US Eastern time zone). \n  About You: \n \n You are an experienced Azure DevOps Engineer who can support, maintain and configure the delivery of builds/deployments across a Global System. \n You have onboarding new clients/platforms into existing systems and customized configurations \n You have strong Azure skills along with Octopus Deployment tool or Dell Boomi experience. \n You can work in a dynamic and fast-paced environment with Global team partners. \n \n About The Role: \n  The DevOps Engineer will play a key role within the engineering and development teams to implement automation around CI/CD and other core processes to back-end and front-end processing. Responsible for building out pipelines and increasing quality and efficiency throughout CES processes. Works across internal development teams to automate key processes and create and maintain pipelines of automation. \n \n Implements various development, testing, automation tools, and IT infrastructure including selecting and deploying appropriate CI/CD tools with alignment from CES stakeholders \n Configures and deploys tools and required infrastructure for automation within key development and deployment streams \n Advocates for and builds automated processes wherever possible \n Defines and sets development, test, release, update, and support processes for DevOps operation \n Monitors the processes throughout the CES product lifecycle for adherence to standards and updating or creating new processes to minimize the wastage including incident management and root cause analysis \n Strives for continuous improvement to achieve an optimal state of integration, development practices, and efficient deployments (CI/CD Pipeline) \n Coordination and communication within the team and with customers to support adherence to automation and deployment standards \n Creates and maintains documentation around automation processes and standards \n Creates knowledge base materials dedicated towards operational efficiency while also empowering and enabling the greater CES team to leverage DevOps in multiple technical and non-technical capacities \n \n Required Experience: \n \n BA in Computer Science or Programming OR Equivalent \n 4+ years previous hands experience in DevOps engineering and or CI/CD pipeline development \n \n \n Working knowledge of various tools, open-source technologies, and cloud services \n Working knowledge of DevOps practices and removing manual processes \n Experience supporting multi-tier, consumer-facing web applications at more than just the UI level \n Experience with integrating tests and new technologies into in-place CI frameworks \n Knowledge of various Agile ways of working (Scrum/Kanban) and their benefits \n Working knowledge of Azure DevOps (formerly VSTS) and Git repositories \n Working knowledge of Octopus Deploy or similar automated deployment and release management tools \n \n \n Familiarity of database concepts and data management (RDBMS) and SQL \n \n \n Ability to multi-task and perform effectively under pressure \n Excellent troubleshooting \n \n #LI-Remote \n \n \n    Precision is required by law in some states or cities to include a reasonable estimate of the compensation range for this role. This compensation range takes into account the wide range of factors that are considered in making compensation decisions including but not limited to: skill sets, experience and training, licensure and certifications, and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Precision, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. This role is also eligible for a discretionary annual bonus, health insurance, retirement savings benefits, life insurance and disability benefits, parental leave, and paid time off for sick leave and vacation, among other benefits.\n   \n  Reasonable estimate of the current range \n \n    $100,000\u2014$140,000 USD\n   \n \n \n  Any data provided as a part of this application will be stored in accordance with our Privacy Policy. For CA applicants, please also refer to our CA Privacy Notice. \n  Precision Medicine Group is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. \u00a9 2020 Precision Medicine Group, LLC \n  If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact Precision Medicine Group at QuestionForHR@precisionmedicinegrp.com.", "cleaned_desc": " \n Implements various development, testing, automation tools, and IT infrastructure including selecting and deploying appropriate CI/CD tools with alignment from CES stakeholders \n Configures and deploys tools and required infrastructure for automation within key development and deployment streams \n Advocates for and builds automated processes wherever possible \n Defines and sets development, test, release, update, and support processes for DevOps operation \n Monitors the processes throughout the CES product lifecycle for adherence to standards and updating or creating new processes to minimize the wastage including incident management and root cause analysis \n Strives for continuous improvement to achieve an optimal state of integration, development practices, and efficient deployments (CI/CD Pipeline) \n Coordination and communication within the team and with customers to support adherence to automation and deployment standards \n Creates and maintains documentation around automation processes and standards \n Creates knowledge base materials dedicated towards operational efficiency while also empowering and enabling the greater CES team to leverage DevOps in multiple technical and non-technical capacities \n   Required Experience: \n \n BA in Computer Science or Programming OR Equivalent \n 4+ years previous hands experience in DevOps engineering and or CI/CD pipeline development \n \n \n Working knowledge of various tools, open-source technologies, and cloud services \n Working knowledge of DevOps practices and removing manual processes \n Experience supporting multi-tier, consumer-facing web applications at more than just the UI level \n Experience with integrating tests and new technologies into in-place CI frameworks \n Knowledge of various Agile ways of working (Scrum/Kanban) and their benefits   Working knowledge of Azure DevOps (formerly VSTS) and Git repositories \n Working knowledge of Octopus Deploy or similar automated deployment and release management tools \n \n \n Familiarity of database concepts and data management (RDBMS) and SQL \n \n \n Ability to multi-task and perform effectively under pressure \n Excellent troubleshooting \n \n #LI-Remote ", "techs": ["ci/cd tools", "automation tools", "it infrastructure", "devops operation", "incident management", "root cause analysis", "ci/cd pipeline", "coordination", "communication", "documentation", "knowledge base materials", "computer science", "programming", "devops engineering", "ci/cd pipeline development", "tools", "open-source technologies", "cloud services", "azure devops", "git repositories", "octopus deploy", "database concepts", "data management", "sql", "multitasking", "troubleshooting"]}, "4a2ee6b5a60132d8": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Cloud Engineer, DevOps", "company": "Zurich Insurance Company Ltd.", "desc": "Zurich North America is currently recruiting for a Cloud Engineer, DevOps and this person can work either in our Schaumburg North America HQ or can work remotely. This person will report to the Application Portfolio Manager \u2013 Infrastructure and Operations, Public Cloud. \n \n  In the Cloud Engineer, DevOps position you will oversee the design, implementation, and maintenance of our CI/CD pipelines. You will understand software development methodologies and be able to work with development, platform, security, and infrastructure teams to refine the Infrastructure as Code (IaC) delivery process. The successful candidate will possess very strong troubleshooting skills with the ability to work independently to research and resolve issues. \n \n  Responsibilities: \n \n \n \n  Engineer, automate and orchestrate system provisioning and maintenance processes using modern cloud tools and technologies. Evaluate, design, and implement supporting technologies in alignment with global and local requirements. \n  Author requirements and design document for public cloud services and patterns to be deployed within the environment. Engage with architects, engineers, developers, and security officers to develop solutions. \n  Manage repositories for IaC services, resources, and patterns. Develop SDLC standards for IaC and ensure they are communicated and adhered to. Mentor cloud engineers on key systems related to SDLC. \n  Solve complex architecture challenges, apply architectural standards, and start using them on new projects. \n  Design and build public cloud solutions using automation, orchestration, and deployment tools including Terraform, PowerShell, Ansible, Bash. \n  Lead by example, contributing to code reviews, documentation and take on complex bug fixes, especially on high-risk problems. \n  Perform system administration tasks including deployments, configuration, systems monitoring, troubleshooting, and support while innovating to automate as much as possible. \n  Install, configure, maintain, and support applications, services, and servers in public cloud environments. \n  Troubleshoot and resolve issues reported by monitoring systems and submitted through the ticketing system. Fully document issues, actions taken, and steps for resolution. \n  Engineer and maintain operational processes and procedures. \n  Focus on continued professional development to maintain knowledge and application of current industry best practices and security concepts. \n  Exhibit an innovative mindset by suggesting improvements as well as engineering and implementing related recommendations. Strong desire to learn, implement, and teach others in new processes and technologies. \n  Perform other tasks as defined, planned, and approved by leadership. \n \n \n  Basic Qualifications: \n \n \n \n  Bachelor\u2019s Degree in Computer Science or System Architecture and 6 or more years of experience in an IT operations area OR \n  Zurich Certified Insurance Apprentice, including Associate Degree in Computer Science or System Architecture and 6 or more years of experience in an IT operations area OR \n  High School Diploma or Equivalent, and 8 or more years of experience in an IT operations area AND \n  Experience with public and private Cloud technologies \n  5 or more years\u2019 project management experience \n  3 or more years\u2019 leadership experience in Infrastructure or Cloud implementations \n  Experience of migrating in-house services to a public cloud provider \n  Experience of delivering business solutions with cloud computing services/platforms \n  Experience with Virtual/Cloud infrastructure troubleshooting \n \n \n  Preferred Qualifications: \n \n \n \n  Good understanding of DevOps process, standards, best practices followed in enterprise level with Jira, Confluence, Azure DevOps  \n Demonstrated experience with software engineering, scripting, automation, and orchestration tools (Terraform, PowerShell, Ansible, GitHub) \n  Demonstrated experience provisioning, configuring, and maintaining cloud computing services such as Azure and AWS. \n  Demonstrated experience administering, monitoring, and maintaining both Microsoft and Linux server-based operating systems. \n  Operational understanding of security best practices and standards around cloud computing and access management. \n  Occasional travel may be required. \n \n \n  As a condition of employment at Zurich, employees must adhere to any COVID-related health and safety protocols in place at that time (https://www.zurichna.com/careers/faq). \n \n  A future with Zurich. What can go right when you apply at Zurich? \n \n  Now is the time to move forward and make a difference. At Zurich, we want you to share your unique perspectives, experiences and ideas so we can grow and drive sustainable change together. As part of a leading global organization, Zurich North America has over 150 years of experience managing risk and supporting resilience. Today, Zurich North America is a leading provider of commercial property-casualty insurance solutions and a wide range of risk management products and services for businesses and individuals. We serve more than 25 industries, from agriculture to technology, and we insure 90% of the Fortune 500\u00ae. Our growth strategy is not limited to our business. As an employer, we strive to provide ongoing career development opportunities, and we foster an environment where voices are diverse, behaviors are inclusive, actions drive equity, and our people feel a sense of belonging. Be a part of the next evolution of the insurance industry. Join us in building a brighter future for our colleagues, our customers and the communities we serve. Zurich maintains a comprehensive employee benefits package for employees as well as eligible dependents and competitive compensation. Please click here to learn more. \n \n  As a global company, Zurich recognizes the diversity of our workforce as an asset. We recruit talented people from a variety of backgrounds with unique perspectives that are truly welcome here. Taken together, diversity and inclusion bring us closer to our common goal: exceeding our customers\u2019 expectations. Zurich does not discriminate on the basis of age, race, ethnicity, color, religion, sex, sexual orientation, gender expression, national origin, disability, protected veteran status or any other legally protected status. EOE disability/vet \n \n  Zurich does not accept unsolicited resumes from search firms or employment agencies. Any unsolicited resume will become the property of Zurich American Insurance. If you are a preferred vendor, please use our Recruiting Agency Portal for resume submission. \n \n  Location(s): AM - Schaumburg  Remote Working: Yes  Schedule: Full Time  Employment Sponsorship Offered: Yes    Linkedin Recruiter Tag: #LI-MG1 #LI-ASSOCIATE", "cleaned_desc": "Zurich North America is currently recruiting for a Cloud Engineer, DevOps and this person can work either in our Schaumburg North America HQ or can work remotely. This person will report to the Application Portfolio Manager \u2013 Infrastructure and Operations, Public Cloud. \n \n  In the Cloud Engineer, DevOps position you will oversee the design, implementation, and maintenance of our CI/CD pipelines. You will understand software development methodologies and be able to work with development, platform, security, and infrastructure teams to refine the Infrastructure as Code (IaC) delivery process. The successful candidate will possess very strong troubleshooting skills with the ability to work independently to research and resolve issues. \n \n  Responsibilities: \n \n \n \n  Engineer, automate and orchestrate system provisioning and maintenance processes using modern cloud tools and technologies. Evaluate, design, and implement supporting technologies in alignment with global and local requirements. \n  Author requirements and design document for public cloud services and patterns to be deployed within the environment. Engage with architects, engineers, developers, and security officers to develop solutions. \n  Manage repositories for IaC services, resources, and patterns. Develop SDLC standards for IaC and ensure they are communicated and adhered to. Mentor cloud engineers on key systems related to SDLC. \n  Solve complex architecture challenges, apply architectural standards, and start using them on new projects.   \n \n \n  Bachelor\u2019s Degree in Computer Science or System Architecture and 6 or more years of experience in an IT operations area OR \n  Zurich Certified Insurance Apprentice, including Associate Degree in Computer Science or System Architecture and 6 or more years of experience in an IT operations area OR \n  High School Diploma or Equivalent, and 8 or more years of experience in an IT operations area AND \n  Experience with public and private Cloud technologies \n  5 or more years\u2019 project management experience \n  3 or more years\u2019 leadership experience in Infrastructure or Cloud implementations \n  Experience of migrating in-house services to a public cloud provider \n  Experience of delivering business solutions with cloud computing services/platforms \n  Experience with Virtual/Cloud infrastructure troubleshooting   \n \n  Preferred Qualifications: \n \n \n \n  Good understanding of DevOps process, standards, best practices followed in enterprise level with Jira, Confluence, Azure DevOps  \n Demonstrated experience with software engineering, scripting, automation, and orchestration tools (Terraform, PowerShell, Ansible, GitHub) \n  Demonstrated experience provisioning, configuring, and maintaining cloud computing services such as Azure and AWS. \n  Demonstrated experience administering, monitoring, and maintaining both Microsoft and Linux server-based operating systems. \n  Operational understanding of security best practices and standards around cloud computing and access management. \n  Occasional travel may be required. ", "techs": ["ci/cd pipelines", "infrastructure as code (iac)", "cloud tools and technologies", "sdlc standards for iac", "public cloud services", "public and private cloud technologies", "project management", "leadership in infrastructure or cloud implementations", "migrating in-house services to a public cloud provider", "delivering business solutions with cloud computing services/platforms", "virtual/cloud infrastructure troubleshooting", "jira", "confluence", "azure devops", "terraform", "powershell", "ansible", "github", "azure and aws cloud computing services", "microsoft and linux server-based operating systems", "security best practices and standards around cloud computing and access management."]}, "2120eaa8301adf11": {"terms": ["mlops"], "salary_min": 85800.0, "salary_max": 159400.0, "title": "Machine Learning Engineer", "company": "FM Global", "desc": "More information about this job: \n  Overview: \n \n \n \n \n This is a US based position that is eligible for remote work.  \n Candidate \n  must be open to periodic travel to headquarters  \n located \n  in Johnston, RI dependent on business needs. Must be willing to work EST hours. \n \n \n \n  FM Global is a leading property insurer of the world's largest businesses, providing more than one-third of FORTUNE 1000-size companies with engineering-based risk management and property insurance solutions. FM Global helps clients maintain continuity in their business operations by drawing upon state-of-the-art loss-prevention engineering and research; risk management skills and support services; tailored risk transfer capabilities; and superior financial strength. To do so, we rely on a dynamic, culturally diverse group of employees, working in more than 100 countries, in a variety of challenging roles.\n     \n \n \n \n \n   Responsibilities: \n \n \n \n \n     We currently have an opening for an ML engineer/data scientist with experience in building and deploying production predictive systems. The ideal candidate will have strong experience with ML models created using Python, have working knowledge of data pipelines and experience building production-ready ML models in Microsoft Azure.\n     \n \n \n \n \n     Previous experience with the Agile SDLC methodology is preferred.\n     \n \n \n  As an ML Engineer you bring:\n     \n \n \n \n  Strong problem-solving skills \n  Commitment to delivery \n  Excellent communication skills and a desire to collaborate openly within a fast-moving team \n  A deep desire to learn and apply technology in a pragmatic way to create client value \n \n \n  Experience designing and building systems that are maintainable, evolvable and highly tested \n \n \n \n  As an ML Engineer you will be responsible for:\n     \n \n \n \n  Explore and develop use cases for development based on business needs identified by the product owner \n  Develop and productionize Azure ML models by identifying opportunities to increase efficiencies and create new value \n  Devise performance improvement and maturation strategies for models based on feature performance, in-situ model performance and stakeholder feedback \n \n \n  Support development and improvement of shared libraries for data scientists \n  Optimize ML models for deployment, improving sustainability and performance \n  Contribute to improvement of the metadata catalog, A/B testing frameworks, and other associated toolkits \n  Work cross-functionally in AI/ML team to drive continued improvement of processes and deliver the next set of improvements \n  Partner with other functions to drive long-term roadmap, improved capabilities, and share results/processes with the organization more broadly \n \n \n \n \n Qualifications: \n \n \n 3-5 years of hands-on experience in an enterprise environment required \n \n \n \n  Skills/Knowledge \n \n \n  Experience working with deep learning and NLP toolsets, including new generative AI technologies such as Azure OpenAI and ChatGPT \n  Knowledge of common MLOps pipeline patterns and associated technologies \n  Experience with deep learning using PyTorch, Tensorflow, Keras \n  Knowledge of production systems, experience designing sustainable ML model deployments and driving those requirements to reality \n \n \n  Experience with scaling production models using containerization \n  Fluency in Python; some experience with production pipeline coding (Java/Go/Scala) \n  Master\u2019s degree in Computer Science, Computational Science, or related field is preferred \n \n \n \n  Additional Preferred Skills \n \n \n  Generative AI technologies and Azure OpenAI deployment \n  Experience working with Agile methodologies and frameworks \n  Experience working in Azure cloud and Azure Machine Learning \n \n \n \n  The hiring range for this position is $85,800 to $159,400. The final salary offer will vary based on geographic location, individual education, skills, and experience. The position is eligible to participate in FM Global\u2019s comprehensive Total Rewards program that includes an incentive plan, generous health and well-being programs, a 401(k) and pension plan, career development opportunities, tuition reimbursement, flexible work, time off allowances and much more.\n   \n \n \n  FM Global is an Equal Opportunity Employer and is committed to attracting, developing, and retaining a diverse workforce.\n   \n \n \n  #FMG", "cleaned_desc": " \n \n \n \n     We currently have an opening for an ML engineer/data scientist with experience in building and deploying production predictive systems. The ideal candidate will have strong experience with ML models created using Python, have working knowledge of data pipelines and experience building production-ready ML models in Microsoft Azure.\n     \n \n \n \n \n     Previous experience with the Agile SDLC methodology is preferred.\n     \n \n \n  As an ML Engineer you bring:\n     \n \n \n \n  Strong problem-solving skills \n  Commitment to delivery    Excellent communication skills and a desire to collaborate openly within a fast-moving team \n  A deep desire to learn and apply technology in a pragmatic way to create client value \n \n \n  Experience designing and building systems that are maintainable, evolvable and highly tested \n \n \n \n  As an ML Engineer you will be responsible for:\n     \n \n \n \n  Explore and develop use cases for development based on business needs identified by the product owner \n  Develop and productionize Azure ML models by identifying opportunities to increase efficiencies and create new value \n  Devise performance improvement and maturation strategies for models based on feature performance, in-situ model performance and stakeholder feedback \n \n \n  Support development and improvement of shared libraries for data scientists \n  Optimize ML models for deployment, improving sustainability and performance \n  Contribute to improvement of the metadata catalog, A/B testing frameworks, and other associated toolkits    Work cross-functionally in AI/ML team to drive continued improvement of processes and deliver the next set of improvements \n  Partner with other functions to drive long-term roadmap, improved capabilities, and share results/processes with the organization more broadly \n \n \n \n \n Qualifications: \n \n \n 3-5 years of hands-on experience in an enterprise environment required \n \n \n \n  Skills/Knowledge \n \n \n  Experience working with deep learning and NLP toolsets, including new generative AI technologies such as Azure OpenAI and ChatGPT \n  Knowledge of common MLOps pipeline patterns and associated technologies \n  Experience with deep learning using PyTorch, Tensorflow, Keras \n  Knowledge of production systems, experience designing sustainable ML model deployments and driving those requirements to reality \n   \n  Experience with scaling production models using containerization \n  Fluency in Python; some experience with production pipeline coding (Java/Go/Scala) \n  Master\u2019s degree in Computer Science, Computational Science, or related field is preferred \n \n \n \n  Additional Preferred Skills \n \n \n  Generative AI technologies and Azure OpenAI deployment \n  Experience working with Agile methodologies and frameworks \n  Experience working in Azure cloud and Azure Machine Learning \n \n \n \n  The hiring range for this position is $85,800 to $159,400. The final salary offer will vary based on geographic location, individual education, skills, and experience. The position is eligible to participate in FM Global\u2019s comprehensive Total Rewards program that includes an incentive plan, generous health and well-being programs, a 401(k) and pension plan, career development opportunities, tuition reimbursement, flexible work, time off allowances and much more.\n   \n \n \n  FM Global is an Equal Opportunity Employer and is committed to attracting, developing, and retaining a diverse workforce.", "techs": ["ml models", "python", "data pipelines", "microsoft azure", "agile sdlc methodology", "problem-solving skills", "communication skills", "ml model productionization", "azure ml models", "performance improvement strategies", "shared libraries", "ml model deployment optimization", "metadata catalog", "a/b testing frameworks", "ai/ml team collaboration", "deep learning", "nlp toolsets", "generative ai technologies", "mlops pipeline patterns", "pytorch", "tensorflow", "keras", "production systems", "containerization", "python fluency", "production pipeline coding", "master's degree in computer science", "azure openai deployment", "agile methodologies", "azure cloud", "azure machine learning."]}, "8938a214e17a0119": {"terms": ["mlops"], "salary_min": 115415.63, "salary_max": 146141.9, "title": "DevOps Automation Engineer - III", "company": "eTeam Inc.", "desc": "Title: DevOps Automation Engineer \n \n Location: Remote \n \n Duration: 6+ Months \n \n \n  *******Strong python programing experience is required with working cloud experience\n  \n  ****100% Remote\n  \n  The Telecommunication CyberSecurity (VCS) organization securely enables the business by protecting assets and information across Telecommunication networks, infrastructure and applications. CIS integrates cybersecurity governance, policies, technologies and operations across Telecommunication, and works to incorporate security into the design of technology systems and services.\n  \n  The Cloud Platform Governance Team is part of the VCS Organization and is primarily responsible for ensuring that the data and processes that are used in public cloud platforms are secured and controlled so that application workloads in those cloud platforms are not exposed to unintended users or services. The team is responsible for partnering with multiple stakeholders in framing and implementing governance policy frameworks for Cloud platforms primarily on AWS, GCP, OCI and Azure.\n  \n  We are looking for a Security Cloud Automation Engineer/Developer. In this role, you will be responsible for:\n  \n \n Design and automate security & governance framework across our AWS, Azure, GCP and OCI environments using Python, Boto3, Google Cloud SDKs, Unix Shell and other scripting languages \n Be a contributor with advanced capabilities to enable automation/integration across hybrid processing environments (LDAP, SSO, CI/CD, Cloud APIs, Messaging, Web, microservices, SAAS, ServiceNow, Networking...) \n Partner with application delivery teams in enabling cloud services after evaluating the risk exposure. \n Conduct POCs on services from security and risk stand points and create access management framework based on principle of least privileges. \n Automate Identity and Access management in AWS, Azure, GCP and OCI cloud platforms for enabling users and services. \n Work with stakeholders from both our application as well as other security teams to provide solutions that meet security and governance requirements while minimizing impact on developer productivity. \n Proactive monitoring, logging, audits and automated policy enforcement for security and cost compliance. \n Ensure services availability and continuity through proper response to threat incidents and requests. \n Work in a product operating model which is based on Agile/ Scrum practices. \n \n  Where you ll be working:\n  \n  In this role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\n  \n  You ll need to have:\n  \n \n \n Bachelor s degree or four or more years of work experience. \n Six or more years of relevant work experience cloud infrastructure automation is a must \n Experience in coding in Java, Python, Django, HTML, jQuery, Bash, Typescript and or .Net, nosql, node.js, javascript \n Experience with a continuous integration and delivery model of deploying software \n Experience with any two of the platform infrastructures in AWS, GCP, Azure and or OCI. \n Experience on Cloud Security & Governance practices and frameworks. \n \n  Even better if you have:\n  \n \n \n Knowledge of API, Microservices, network and security architectures and design patterns. \n You re confident in asking difficult questions and challenging your team and dependencies while being highly collaborative and open to input \n Experience in building cloud platform architecture solutions on public and/or private cloud platforms with an Client towards governance/security tools. \n Experience with modern source control repositories (e. g. Git) and DevOps toolsets (Jenkins/ Ansible etc.) and knowledge of Agile/ Scrum methodologies. \n Knowledge of distributed systems, asynchronous messaging, and networking protocols. \n Experience with open source applications, frameworks, and libraries. \n Knowledge and Hands on Skills with Docker, ECS, Kubernetes, and Container Security. \n Third party ecosystem tools for compliance and security such as Auto-Remediation/ Compliance (Cloud Custodian), PRISMA, Dome 9, TrendMicro, and Container Security Tools.. \n GCP, AWS and or Azure Associate or professional certifications \n Consistent track record of shaping and integrating complex infrastructure in the cloud \n Basic exposure to DBs and development experience with MySQL tables, queries, procedures and functions. \n Excellent verbal and written communication skills.", "cleaned_desc": "  The Telecommunication CyberSecurity (VCS) organization securely enables the business by protecting assets and information across Telecommunication networks, infrastructure and applications. CIS integrates cybersecurity governance, policies, technologies and operations across Telecommunication, and works to incorporate security into the design of technology systems and services.\n  \n  The Cloud Platform Governance Team is part of the VCS Organization and is primarily responsible for ensuring that the data and processes that are used in public cloud platforms are secured and controlled so that application workloads in those cloud platforms are not exposed to unintended users or services. The team is responsible for partnering with multiple stakeholders in framing and implementing governance policy frameworks for Cloud platforms primarily on AWS, GCP, OCI and Azure.\n  \n  We are looking for a Security Cloud Automation Engineer/Developer. In this role, you will be responsible for:\n  \n \n Design and automate security & governance framework across our AWS, Azure, GCP and OCI environments using Python, Boto3, Google Cloud SDKs, Unix Shell and other scripting languages \n Be a contributor with advanced capabilities to enable automation/integration across hybrid processing environments (LDAP, SSO, CI/CD, Cloud APIs, Messaging, Web, microservices, SAAS, ServiceNow, Networking...) \n Partner with application delivery teams in enabling cloud services after evaluating the risk exposure. \n Conduct POCs on services from security and risk stand points and create access management framework based on principle of least privileges.    \n \n \n Bachelor s degree or four or more years of work experience. \n Six or more years of relevant work experience cloud infrastructure automation is a must \n Experience in coding in Java, Python, Django, HTML, jQuery, Bash, Typescript and or .Net, nosql, node.js, javascript \n Experience with a continuous integration and delivery model of deploying software \n Experience with any two of the platform infrastructures in AWS, GCP, Azure and or OCI. \n Experience on Cloud Security & Governance practices and frameworks. \n \n  Even better if you have:   \n \n \n Knowledge of API, Microservices, network and security architectures and design patterns. \n You re confident in asking difficult questions and challenging your team and dependencies while being highly collaborative and open to input \n Experience in building cloud platform architecture solutions on public and/or private cloud platforms with an Client towards governance/security tools. \n Experience with modern source control repositories (e. g. Git) and DevOps toolsets (Jenkins/ Ansible etc.) and knowledge of Agile/ Scrum methodologies. \n Knowledge of distributed systems, asynchronous messaging, and networking protocols. \n Experience with open source applications, frameworks, and libraries. \n Knowledge and Hands on Skills with Docker, ECS, Kubernetes, and Container Security. \n Third party ecosystem tools for compliance and security such as Auto-Remediation/ Compliance (Cloud Custodian), PRISMA, Dome 9, TrendMicro, and Container Security Tools.. ", "techs": ["python", "boto3", "google cloud sdks", "unix shell", "java", "django", "html", "jquery", "bash", "typescript", ".net", "nosql", "node.js", "javascript", "git", "jenkins", "ansible", "docker", "ecs", "kubernetes", "cloud custodian", "prisma", "dome 9", "trendmicro."]}, "1154324d22d77f08": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Generative AI Systems (Remote-Eligible)", "company": "Capital One", "desc": "Locations: NY - New York, United States of America, New York, New York\n   Distinguished Engineer, Generative AI Systems (Remote-Eligible)\n  \n  Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["benchmarks", "llms", "fms", "mlops", "python", "c/c++", "ml frameworks", "public cloud", "large-scale distributed platforms", "aws", "azure", "gcp", "gpu clusters", "ml compilers", "pytorch", "tensorflow", "lightning", "prompt engineering", "vector databases/knowledge bases", "llm hosting", "fine-tuning"]}, "4772dc47acc1b2c2": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)\n  \n  Sr Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "python", "c/c++", "ai and ml frameworks", "public cloud", "aws", "azure", "gcp", "gpu clusters", "ml compilers", "distributed training frameworks", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting and fine-tuning."]}, "28645c375ec927c2": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)\n  \n  Sr Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "python", "c/c++", "ai", "ml", "ml frameworks", "public cloud", "master's degree", "phd", "engineering", "computer science", "related technical field", "modern ai techniques", "large-scale distributed platforms", "cloud environments", "aws", "azure", "gcp", "cloud systems", "security", "availability", "performance", "scalability", "cost", "gpu clusters", "tightly-coupled storage", "networking", "ml compilers", "distributed training frameworks", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases", "knowledge bases", "llm hosting", "fine-tuning", "research publications", "neural networks", "distributed training", "sysml."]}, "1ec653ecd3688f30": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)", "company": "Capital One", "desc": "Locations: VA - McLean, United States of America, McLean, Virginia\n   Sr Distinguished Engineer, Generative AI Systems - (Remote- Eligible)\n  \n  Sr Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $315,100 - $359,700 for Sr Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $333,900 - $381,000 for Sr Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $267,100 - $304,800 for Sr Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 9 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 6 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "python", "c/c++", "ai", "ml", "public cloud", "aws", "azure", "gcp", "gpu clusters", "ml compilers", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting", "fine-tuning", "neural networks", "distributed training", "sysml"]}, "995ac6d2dbc4f29c": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Generative AI Systems (Remote-Eligible)", "company": "Capital One", "desc": "Locations: NY - New York, United States of America, New York, New York\n   Distinguished Engineer, Generative AI Systems (Remote-Eligible)\n  \n  Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "hpc", "ml algorithms", "python", "c/c++", "ml development lifecycle", "ai frameworks", "public cloud", "modern ai techniques", "distributed platforms", "cloud environments", "aws", "azure", "gcp", "cloud systems", "gpu clusters", "ml compilers", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting and fine-tuning", "neural networks", "distributed training", "sysml."]}, "b1fd60fd3bdba31f": {"terms": ["mlops"], "salary_min": 150.0, "salary_max": 165.0, "title": "Sr Azure DevOps Architects", "company": "Fourans LLC", "desc": "Purpose: Create an Enterprise-wide plan for data and agile work item migrations and implement the migration with a pilot team: Trails to adjust and refine it before distribution Enterprise Wide. OIT has a central work item tracking tool for technical teams and is using it to improve and standardize process enterprise wide. Creating a standard migration path to this common tool will streamline the efforts by any team that requires a migration, thereby reducing cost and time needed. \n Minimum Resource Requirements - Required \n \u00b7 Familiarity with Azure DevOps migration tool options \n \u00b7 Familiarity with Azure DevOps work items (area paths, etc) \n \u00b7 Familiarity with TFS on-prem data, whether APIs or Direct SQL Data Access \n \u00b7 Familiarity with basic script/code writing and rest API calls \n Functional and Business Requirements: \n Move Epics, features and user stories, including comment history and attachments \n 1) Determine migration tool \n a) Research tool for import/export \n b) Considerations for choosing tool: \n i) How much customization would be needed to accommodate business requirements? \n ii) Epics, Features, User Stories, Tasks and links must be maintained during migration (Maintain current hierarchy) \n iii) Maintain assignee during migration \n iv) Can \u201cdiscussion entries\u201d (a.k.a. Comments) be migrated over? \n v) Links to other work items copied (other than hierarchy mentioned above)? \n vi) Attachments \n vii) Migrate/map \u201cstates\u201d (e.g. New, Committed, etc.) \n viii) Current \u201ccustom\u201d fields \n ix) Tool must have some sort of logging that racks successful copying \n 2) Determine migration scope \n a) Define which items need to be migrated \n b) Work in phases or full migration at once? \n 3) Map fields \n 4) Historical data \n a) Define scope of how much history must be migrated \n b) How long does CDHS AzD need to remain available as read-only? Are there audit requirements to consider? \n 5) Security Considerations \n a) Define and set security permissions, as well as any other security considerations prior to migration \n 6) Training and Access Considerations \n a) Define training and set access permissions \n 7) Perform Migration \n a) Migrate work items \n Job Types: Contract, Full-time \n Pay: $150.00 - $165.00 per hour \n Experience level: \n \n 11+ years \n \n Experience: \n \n 18 yrs: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Purpose: Create an Enterprise-wide plan for data and agile work item migrations and implement the migration with a pilot team: Trails to adjust and refine it before distribution Enterprise Wide. OIT has a central work item tracking tool for technical teams and is using it to improve and standardize process enterprise wide. Creating a standard migration path to this common tool will streamline the efforts by any team that requires a migration, thereby reducing cost and time needed. \n Minimum Resource Requirements - Required \n \u00b7 Familiarity with Azure DevOps migration tool options \n \u00b7 Familiarity with Azure DevOps work items (area paths, etc) \n \u00b7 Familiarity with TFS on-prem data, whether APIs or Direct SQL Data Access \n \u00b7 Familiarity with basic script/code writing and rest API calls \n Functional and Business Requirements: \n Move Epics, features and user stories, including comment history and attachments ", "techs": ["azure devops migration tool options", "azure devops work items", "tfs on-prem data", "apis", "direct sql data access"]}, "7840e2e81c49ba6f": {"terms": ["mlops"], "salary_min": 140.0, "salary_max": 150.0, "title": "Sr Azure DevOps Architects", "company": "Fourans LLC", "desc": "Purpose: Create an Enterprise-wide plan for data and agile work item migrations and implement the migration with a pilot team: CDHS Trails to adjust and refine it before distribution Enterprise Wide. OIT has a central work item tracking tool for technical teams and is using it to improve and standardize process enterprise wide. Creating a standard migration path to this common tool will streamline the efforts by any team that requires a migration, thereby reducing cost and time needed. \n Scope of Work \n \n Migration of work items from CDHS (TFS) on-prem to OIT AzD per business requirements. See Functional and Business Requirements. \n \n Minimum Resource Requirements - Required \n \u00b7 Familiarity with Azure DevOps migration tool options \n \u00b7 Familiarity with Azure DevOps work items (area paths, etc) \n \u00b7 Familiarity with TFS on-prem data, whether APIs or Direct SQL Data Access \n \u00b7 Familiarity with basic script/code writing and rest API calls \n Functional and Business Requirements: \n Move Epics, features and user stories, including comment history and attachments \n 1) Determine migration tool \n a) Research tool for import/export \n b) Considerations for choosing tool: \n i) How much customization would be needed to accommodate business requirements? \n ii) Epics, Features, User Stories, Tasks and links must be maintained during migration (Maintain current hierarchy) \n iii) Maintain assignee during migration \n iv) Can \u201cdiscussion entries\u201d (a.k.a. Comments) be migrated over? \n v) Links to other work items copied (other than hierarchy mentioned above)? \n vi) Attachments \n vii) Migrate/map \u201cstates\u201d (e.g. New, Committed, etc.) \n viii) Current \u201ccustom\u201d fields \n ix) Tool must have some sort of logging that racks successful copying \n 2) Determine migration scope \n a) Define which items need to be migrated \n b) Work in phases or full migration at once? \n 3) Map fields \n 4) Historical data \n a) Define scope of how much history must be migrated \n b) How long does CDHS AzD need to remain available as read-only? Are there audit requirements to consider? \n 5) Security Considerations \n a) Define and set security permissions, as well as any other security considerations prior to migration \n 6) Training and Access Considerations \n a) Define training and set access permissions \n 7) Perform Migration \n a) Migrate work items \n Job Types: Contract, Full-time \n Pay: $140.00 - $150.00 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Familiarity with TFS on-prem data, whether APIs or Direct SQL Data Access \n \u00b7 Familiarity with basic script/code writing and rest API calls \n Functional and Business Requirements: \n Move Epics, features and user stories, including comment history and attachments \n 1) Determine migration tool \n a) Research tool for import/export \n b) Considerations for choosing tool: \n i) How much customization would be needed to accommodate business requirements? ", "techs": ["tfs", "apis", "direct sql data access", "rest api calls", "migration tool"]}, "e1ef4e90d77da14f": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Distinguished Engineer, Generative AI Systems (Remote-Eligible)", "company": "Capital One", "desc": "Locations: NY - New York, United States of America, New York, New York\n   Distinguished Engineer, Generative AI Systems (Remote-Eligible)\n  \n  Distinguished Engineer, Generative AI Systems \n \n  Our mission at Capital One is to create trustworthy, reliable and human-in-the-loop AI systems, changing banking for good. For years, Capital One has been leading the industry in using machine learning to create real-time, intelligent, automated customer experiences. From informing customers about unusual charges to answering their questions in real time, our applications of AI & ML are bringing humanity and simplicity to banking. Because of our investments in public cloud infrastructure and machine learning platforms, we are now uniquely positioned to harness the power of AI. We are committed to building world-class applied science and engineering teams and continue our industry leading capabilities with breakthrough product experiences and scalable, high-performance AI infrastructure. At Capital One, you will help bring the transformative power of emerging AI capabilities to reimagine how we serve our customers and businesses who have come to love the products and services we build. \n \n  We are looking for an experienced Senior Distinguished Engineer, AI Systems, to help us build the foundations of our enterprise AI Capabilities. You will work on a wide range of initiatives, whether that\u2019s designing robust, secure infrastructure, building large-scale distributed training clusters, deploying LLMs on GPU instances for real-time use cases, or supporting cutting-edge AI research and development, all in our public cloud infrastructure. You will work with a team of AI engineers and researchers to envision the target state of our capabilities while helping to design and implement key services. Examples of projects you will work on include: \n \n \n  Design and build fault-tolerant infrastructure to support long-running large-scale training tasks reliably despite failure of individual nodes, using containers and check-pointing libraries. \n  Design and build infrastructure for serving large ML models, in our public cloud. \n  Deploy a thousand-node training cluster optimizing storage and networking stack, with tightly coupled training pipelines to take advantage of multiple parallelism strategies, in our public cloud. \n  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud. \n \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  New York City (Hybrid On-Site): $269,400 - $307,500 for Distinguished Machine Learning Engineer\n   San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Machine Learning Engineer\n   Remote (Regardless of Location): $228,300 - $260,600 for Distinguished Machine Learning Engineer\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Design and implement benchmarks to measure the performance of software systems within AI capabilities and make recommendations on technology selection \n  Develop applications that leverage LLMs and FMs. \n  Design and implement capabilities to support MLOps for foundation models. \n \n \n  Capital One is open to hiring a Remote Employee for this opportunity \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Computer Engineering or a technical field \n  At least 7 years of experience designing and building distributed computing HPC and large-scale ML systems \n  At least 5 years of experience developing AI and ML algorithms in Python or C/C++ \n  At least 3 years of experience with the full ML development lifecycle using AI and ML frameworks and public cloud.   \n \n  Preferred Qualifications: \n \n  Master\u2019s degree or PhD in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on modern AI techniques. \n  Experience designing large-scale distributed platforms and/or systems in cloud environments such as AWS, Azure, or GCP. \n  Experience architecting cloud systems for security, availability, performance, scalability, and cost. \n  Experience with delivering very large models through the MLOps life cycle from exploration to serving. \n  Experience with building GPU clusters in the public cloud with tightly-coupled storage and networking. \n  Experience with the complete stack for distributed training of large models including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning etc. \n  Experience with one or multiple areas of AI technology stack including prompt engineering, guardrails, vector databases/knowledge bases, LLM hosting and fine-tuning. \n  Authored research publications in top peer-reviewed conferences, or industry-recognized contributions in the space of neural networks, distributed training and SysML. \n ", "techs": ["llms", "fms", "mlops", "python", "c/c++", "ml development frameworks", "pytorch", "tensorflow", "lightning", "prompt engineering", "guardrails", "vector databases/knowledge bases", "llm hosting", "fine-tuning", "neural networks", "distributed training", "sysml"]}, "metadata": {"keywords": ["data science", "data analyst", "data engineer", "machine learning engineer", "mlops"], "locations": ["remote"], "time_ran": "14:50:31-11-09-23", "num_jobs": 7472, "timings": {"start_drivers": 44.73427438735962, "find_job_ids": 457.37644386291504, "get_job_descs": 89.50388669967651}, "models": {"classifier": {"clf": "data/classifier_models/job_desc_classifier_v1.0.pkl", "tfidf": "data/classifier_models/job_desc_tfidf_vectorizerv1.0.pkl"}, "NER": "gpt-3.5-turbo"}}}