{"ed6a1def7479047f": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 130000.0, "title": "ServiceNow Solutions Engineer / Business Solution Analyst", "company": "Kanini Software Solutions", "desc": "About Kanini \n Kanini provides Agile Software Development, Cloud Computing, Data Science, and Location Intelligence services to public and private organizations. We have successfully served our clients in government, finance, transportation, utility, and software industries since 2003. \n Why you should join \n Working at Kanini is flexible and personal. We are a highly motivated, collaborative team experimenting with the latest technologies. We are committed to everyone having a healthy work/life balance, and we provide extensive mentorship and training resources to help you succeed. \n Kanini is looking for a  ServiceNow Solution Service Engineer /    Business Solutions Analyst  who has a deep experience in ServiceNow Solutions Engineering, User Stories. \n Key Responsibilities \n \n ServiceNow Solution Engineering: \n \n \n Design, configure, and customize ServiceNow applications to meet business requirements. \n \n \n Collaborate with stakeholders to gather and document functional and technical requirements. \n \n \n Develop and maintain ServiceNow workflows, scripts, and integrations. \n \n \n Perform system testing and ensure the quality of ServiceNow solutions. \n \n Business Systems Analysis \n \n Analyze existing business processes and systems to identify areas for improvement. \n \n \n Work closely with business stakeholders to understand their needs and translate them into technical solutions. \n \n \n Create detailed documentation, including user stories, process diagrams, and system specifications. \n \n Qualifications \n \n Bachelor\u2019s degree in computer science, Information Technology, or a related field. \n \n \n Proven experience as a ServiceNow Solution Engineer or Business Systems Analyst. \n \n \n ServiceNow certification (e.g., Certified System Administrator, Certified Implementation Specialist) is a plus. \n \n \n Strong analytical and problem-solving skills. \n \n \n Excellent communication and interpersonal skills. \n \n \n Project management experience is desirable. \n \n \n Knowledge of ITIL principles and practices is a plus. \n \n Kanini Software Solutions, Inc. does not discriminate in employment matters based on race, gender, religion, age, national origin, citizenship, veteran status, family status, disability status, or any other protected class. We support workplace diversity. If you have a disability, please let us know if there is anything we can do to improve the interview process for you; we\u2019re happy to accommodate. \n Kanini Software Solutions, Inc., 25 Century Blvd., Ste. 602, Nashville, TN 37214 \n Job Type: Full-time \n Pay: $120,000.00 - $130,000.00 per year \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "c75bafaa0200d296": {"terms": ["data science", "machine learning engineer"], "salary_min": 105296.336, "salary_max": 133328.62, "title": "Machine Learning Lead Engineer - Startup Founder", "company": "Founding Teams", "desc": "Founding Teams  is a stealth AI Tech Incubator. We are supporting the next generation of AI startup founders with the resources they need including engineering, product, sales, marketing, and operations staff to create and launch their products with equity-only compensated talent. \n We are looking for lead AI engineers who have a startup idea they would like to launch on our upcoming platform/incubator. \n Please review our landing page  www.foundingteams.com \n The ideal candidate will have a passion for next-generation AI tech startups and working with great global startup talent. \n AI Startup Founder - Lead Machine Learning Engineer \n Job Description - \n - Build prototype AI/ ML models and tools to help us understand our customers and create personalized customer recommendations across multiple use cases and productize solutions to scale \n - Deeply understand customers, their behaviors and pain points, and develop a diversity of AI models addressing an array of customers\u2019 needs \n - Translate business needs into AI/ML problems and create innovative solutions to advance our business goals \n - Determine the types and amount of data needed and work with the data engineer to identify data sources and ingest into data lake \n - Structure, standardize, and annotate data into processable formats for ML; enrich data with necessary attributes to allow sophisticated personalization \n - Help shape the way our data science team does work - researching and making key decisions about what we build, how we build it, and which tools are best for solving our problems \n - Work alongside software and data engineers to implement data processing and visualization systems that make data readily available and simplify how insights are communicated \n - Evaluate the performance of AI models and make tradeoffs against quality metrics \n Investigate, and resolve performance issues in a timely manner \n Requirements \n - Bachelor\u2019s or Master\u2019s degree in Mathematics, ML, statistics, Computer Science, Software/Data Engineering, or a related field \n - Strong mathematical background in probability, statistics, and optimization algorithms. \n - Experience in building machine learning models and deploying them to production to make real decisions, then measuring the impact of these decisions. \n - Deep understanding of and have applied various machine learning techniques for solving real-world problems. \n - Expertise with advanced programming skills in Python, Java or any of the major languages to build robust algorithms \n - Proficient with SQL and can work \u201cfull stack\u201d to integrate solutions with our data ecosystem \n - Confident in taking ownership of projects from start to finish and enjoy the process of turning nebulous ideas into reality \n - Excellent communication skills \n - A self-starter who drives projects and builds strong relationships with stakeholders and teams to tackle large cross-functional efforts \n - Thrive with minimal guidance and process \n - Worked in both small teams/incubators and large corporations \n Job Type: Part-time \n Salary: $100.00 - $150,000.00 per year \n Application Question(s): \n \n Are you able to launch your AI startup on foundingteams.com within the next few months? \n \n Work Location: Remote", "cleaned_desc": " - Work alongside software and data engineers to implement data processing and visualization systems that make data readily available and simplify how insights are communicated \n - Evaluate the performance of AI models and make tradeoffs against quality metrics \n Investigate, and resolve performance issues in a timely manner \n Requirements \n - Bachelor\u2019s or Master\u2019s degree in Mathematics, ML, statistics, Computer Science, Software/Data Engineering, or a related field \n - Strong mathematical background in probability, statistics, and optimization algorithms.   - Experience in building machine learning models and deploying them to production to make real decisions, then measuring the impact of these decisions. \n - Deep understanding of and have applied various machine learning techniques for solving real-world problems. \n - Expertise with advanced programming skills in Python, Java or any of the major languages to build robust algorithms \n - Proficient with SQL and can work \u201cfull stack\u201d to integrate solutions with our data ecosystem \n - Confident in taking ownership of projects from start to finish and enjoy the process of turning nebulous ideas into reality \n - Excellent communication skills ", "techs": ["python", "java", "sql"]}, "f092946e2a86151f": {"terms": ["data science", "data engineer"], "salary_min": 116872.77, "salary_max": 147986.97, "title": "Data Engineer II - Platform Services", "company": "Verana Health", "desc": "Verana Health, a digital health company that delivers quality drug lifecycle and medical practice insights from an exclusive real-world data network, recently secured a $150 million Series E led by Johnson & Johnson Innovation \u2013 JJDC, Inc. (JJDC) and Novo Growth, the growth-stage investment arm of Novo Holdings. \n  Existing Verana Health investors GV (formerly Google Ventures), Casdin Capital, and Brook Byers also joined the round, as well as notable new investors, including the Merck Global Health Innovation Fund, THVC, and Breyer Capital. \n  We are driven to create quality real-world data in ophthalmology, neurology and urology to accelerate quality insights across the drug lifecycle and within medical practices. Additionally, we are driven to advance the quality of care and quality of life for patients. DRIVE defines our internal purpose and is the galvanizing force that helps ground us in a shared corporate culture. DRIVE is: Diversity, Responsibility, Integrity, Voice-of-Customer and End-Results. Click here to read more about our culture and values. \n  Our headquarters are located in San Francisco and we have additional offices in Knoxville, TN and New York City with employees working remotely in AZ, CA, CO, CT, FL, GA, IL, LA, MA, NC, NJ, NV, NY, OH, PA, SC, TN, TX, UT , VA, WA, Washington, D.C. All employees are required to have permanent residency in one of these states. Candidates who are willing to relocate are also encouraged to apply. \n  Job Title:  Data Engineer \n  Job Intro:  \n The Data Engineering team is dedicated to build the end to end engineering platform at Verana Health using cloud based solutions that are engineered for scale, availability and high performance in a distributed data processing environment \n  Job Duties and Responsibilities: \n  We are looking for a self-starter to join our Data Engineering team. You will work in a fast-paced environment where you will get an opportunity to build and contribute to the full lifecycle development and maintenance of the data engineering platform at Verana Health. \n  With the Data Engineering team you will get an opportunity to : \n \n Design and implement data engineering solutions that is scalable, reliable and secure on the Cloud environment \n Understand and translate Verana Health's business needs into data engineering solutions \n Build large scale data pipelines that can handle big data sets using distributed data processing techniques that supports the efforts of the data science and data application teams \n Partner with cross-functional stakeholder including Product managers, Architects, Data Quality engineers, Application and Quantitative Science end users to deliver engineering solutions \n Contribute to defining data governance across the Verana Health data platform \n \n Basic Requirements: \n \n A minimum of a BS degree in computer science, software engineering, or related scientific discipline is desired \n 3+ years of work experience in building scalable and robust data engineering solutions \n Strong understanding of Object Oriented programming and proficiency with programming in Python (TDD) and Pyspark to build scalable algorithms \n 3+ years of experience in distributed computing and big data processing using the Apache Spark framework including Spark optimization techniques \n 3+ years of experience with Databricks, Delta tables, unity catalog and incremental data processing \n Advanced SQL coding and query optimization experience including the ability to write analytical and nested queries \n 3+ years of experience in building scalable ETL/ ELT Data Pipelines on Databricks and AWS (EMR) \n 3+ Experience of orchestrating data pipelines using Apache Airflow/ MWAA \n Understanding and experience of AWS Services that include ADX, EC2, S3 \n 3+ years of experience with data modeling techniques for structured/ unstructured datasets \n Experience with relational/columnar databases - Redshift, RDS and interactive querying services - Athena/ Redshift Spectrum \n 2+ years of operating in a CI/CD environment \n Passion towards healthcare and improving patient outcomes \n Demonstrate analytical thinking with strong problem solving skills \n Stay on top of emerging technologies and posses willingness to learn \n \n Bonus Experience  \n \n Experience with Agile environment \n Knowledge in API's \n Healthcare experience \n \n Benefits: \n \n We provide health, vision, and dental coverage for employees \n \n \n \n \n Verana pays 100% of employee insurance coverage and 70% of family \n Plus an additional monthly $100 individual / $200 HSA contribution with HDHP \n \n \n \n Spring Health mental health support \n Flexible vacation plans \n A generous parental leave policy and family building support through the Carrot app \n $500 learning and development budget \n $25/wk in Doordash credit \n Headspace meditation app - unlimited access \n Gympass - 3 free live classes per week + monthly discounts for gyms like Soulcycle \n \n Final note: \n  You do not need to match every listed expectation to apply for this position. Here at Verana, we know that diverse perspectives foster the innovation we need to be successful, and we are committed to building a team that encompasses a variety of backgrounds, experiences, and skills. \n \n \n  #LI-Remote \n  #BI-Remote \n \n \n \n  Verana Health is committed to complying with all applicable pay transparency laws and supports equitable pay practices. We pay based on a market-based approach, supported with robust data and in alignment with the compensation of our existing team. We construct our compensation ranges based on the US national average but your pay may vary depending on your location and the cost of living index for that geographic area. In determining an offer, base salary will also be based on experience, qualifications, skills and market conditions.\n    \n  Please note pay ranges for major metropolitan areas may be different.\n   \n  National Pay Range \n \n    $114,253\u2014$154,577 USD", "cleaned_desc": " Contribute to defining data governance across the Verana Health data platform \n \n Basic Requirements: \n \n A minimum of a BS degree in computer science, software engineering, or related scientific discipline is desired \n 3+ years of work experience in building scalable and robust data engineering solutions \n Strong understanding of Object Oriented programming and proficiency with programming in Python (TDD) and Pyspark to build scalable algorithms \n 3+ years of experience in distributed computing and big data processing using the Apache Spark framework including Spark optimization techniques \n 3+ years of experience with Databricks, Delta tables, unity catalog and incremental data processing \n Advanced SQL coding and query optimization experience including the ability to write analytical and nested queries \n 3+ years of experience in building scalable ETL/ ELT Data Pipelines on Databricks and AWS (EMR) \n 3+ Experience of orchestrating data pipelines using Apache Airflow/ MWAA \n Understanding and experience of AWS Services that include ADX, EC2, S3 \n 3+ years of experience with data modeling techniques for structured/ unstructured datasets \n Experience with relational/columnar databases - Redshift, RDS and interactive querying services - Athena/ Redshift Spectrum ", "techs": ["python", "pyspark", "apache spark", "databricks", "delta tables", "unity catalog", "sql", "aws", "emr", "apache airflow", "mwaa", "adx", "ec2", "s3", "redshift", "rds", "athena", "redshift spectrum"]}, "112bfdfcb6be8ace": {"terms": ["data science"], "salary_min": 110000.0, "salary_max": 120000.0, "title": "Finance Senior BI Analyst", "company": "Ampush", "desc": "Who we are:\n  \n \n   Tinuiti is a performance and data-driven digital marketing leader, focused on every aspect of the customer journey across the quadropoly of Google, Facebook/Instagram, Amazon, Apple, and beyond. We believe success requires specialization across all channels, and our offerings cover the full spectrum from paid to earned to owned media. Our goal when we come to work every day is simple - to grow happiness. For our clients, their customers, our people and our partners. Growing happiness guides everything we do and our core values - Unleash Greatness, Never Stop Learning, Ignite Your Passion, Thankful Living, and Inspire Innovation & Change - inspire us to maintain a culture where our people take pride in their work and have fun doing it.\n  \n \n \n   We support 100% remote work for applicants who reside in the United States.\n  \n \n   Join our growing Finance team! Enjoy exposure to all areas of the business as a valued strategic partner to Executive and leadership teams. From deep-dive analysis to budgeting and planning, each day brings variety and the opportunity to work with a world-class team. You'll thrive in the supportive, fun-loving culture and will appreciate the team's dedication to success.\n  \n \n \n   The Sr. BI Analyst is integral to supporting all of the company's strategic finance needs. They are responsible for wrangling the company's data to drive insights, track and report performance metrics, and streamline finance team processes through automation. This is an ambitious individual who thrives on solving tough, often ambiguous problems in a fast-paced, dynamic environment. Their ability to make well-informed recommendations based on data analysis and communicate findings in concise and actionable reports is essential. Intellectual curiosity and a strong desire to learn are prerequisites for success in this role. This role reports into the VP, Revenue & Strategy.\n  \n \n   What you\u2019ll be doing:\n  \n \n \n \n     Collaborate with finance team members to identify data and reporting needs, including creating custom data tables in Google BigQuery.\n    \n \n \n     Design and implement automated data processes and tools to reduce the team's reliance on spreadsheets, streamlining reporting and analysis.\n    \n \n \n     Optimize data flow and reporting processes by collaborating with cross-functional teams.\n    \n \n \n     Conduct in-depth data analysis to provide valuable insights for business decision-making and financial planning.\n    \n \n \n     Research data issues, identify solutions, and communicate them to appropriate teams, implementing data cleansing and improvement initiatives to enhance data quality.\n    \n \n \n     Create and maintain Tableau dashboards that provide actionable insights to stakeholders.\n    \n \n \n     Assist in preparing executive-level presentation content to effectively communicate data-driven insights.\n    \n \n \n     Generate ad-hoc reporting and analysis as needed to support various corporate initiatives.\n    \n \n \n     Stay updated with industry trends and best practices in data analytics and finance, applying relevant knowledge to drive continuous improvement.\n    \n \n \n \n   We\u2019d love to hear from you if:\n  \n \n   Research shows that while men apply to jobs when they meet an average of 60% of the criteria, women and other marginalized folks tend to only apply when they check every box. So if you think you qualify, but don't necessarily meet every single point on the job description, please still get in touch.\n  \n \n \n   Requirements:\n  \n \n \n \n     Bachelor's Degree in a relevant field: computer science, data science, mathematics, finance, economics, statistics\n    \n \n \n     Strong ability to translate complex business needs into precise technical specs; Demonstrated expertise in crafting custom datasets for analytical demands, showcasing adept data management\n    \n \n \n     5+ years of demonstrated proficiency in advanced analytics, deriving insights from diverse data sources, databases, and big data. Expert command of SQL for extraction, manipulation, and analysis is crucial\n    \n \n \n     3+ years of hands-on experience with business intelligence tools, particularly Tableau. Proven ability in designing and developing impactful dashboards for informed decisions and strategic insights\n    \n \n \n \n   Preferred:\n  \n \n \n \n     Familiarity with Google Cloud Platform (GCP), particularly BigQuery\n    \n \n \n     Familiarity with ETL tools such as Fivetran\n    \n \n \n     Familiarity with Salesforce\n    \n \n \n     Data governance experience including data definition, issue management and data quality analysis\n    \n \n \n     Familiarity with Python or R for data analysis\n    \n \n \n     1+ years of experience in a finance department\n    \n \n \n \n   We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n  \n \n \n   Benefits:\n  \n \n   At Tinuiti, we want to ensure you have the time you need to rest and recharge. That's why Tinuitians have an estimated 70 days off per year through our time off programs\n  \n \n \n \n     Unlimited PTO: We encourage all Tinutians to Own their Offline by utilizing our unlimited PTO by working with your Manager to ensure all deliverables are met.\n    \n \n \n     Holidays: We offer 17 paid holidays, if one of your religious holidays is not covered, please by all means take advantage of your Flex PTO!\n    \n \n \n     Flex Fridays: Meetings are minimized and all Tinuitians have the option to start their weekend early at 1pm local time.\n    \n \n \n     Owning Our Offline: Clients are informed and all offices will be closed for 3 total weeks throughout the year to give everyone the chance to truly unplug.\n    \n \n \n \n   Workplace Flexibility: Office or Remote? Your choice.\n  \n \n   Healthcare: Medical, Dental, Vision, Life & Disability, Flex Spending Accounts\n  \n \n   Retirement: Match up to 4% of your contributions at 100% with immediate vesting\n  \n \n   Perks and Wellness: Fringe, Forma, Thankful giving, Equity\n  \n \n   Learning and Development: Bravely coaching session, Mentor program and more\n  \n \n \n   Compensation:\n  \n \n   The annual base salary range for this role\u2019s listed level is currently $110,000 - $120,000 plus performance bonus of (8%). Grade level and salary ranges are determined through interviews and a review of education, experience, knowledge, skills, abilities of the applicant, equity with other team members, and alignment with market data. We will provide more information on our benefits and equity upon requests. Sales roles are also eligible for incentive pay targeted up to or over 100% of the offered base salary (no cap). Disclosure as required by the Colorado Equal Pay for > Equal Work Act, C.R.S. \u00a7 8-5-101 et seq.\n  \n \n \n   FLSA Classification: Exempt\n  \n \n \n   Disclaimer: This description has been designed to indicate the general nature and level of work performed by employees within this position. The actual duties, responsibilities, and qualifications may vary based on assignment or group. Tinuiti is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, gender, sexual orientation, gender identity or expression, religion, national origin, marital status, age, disability, veteran status, genetic information, or any other protected status.", "cleaned_desc": " \n \n \n     Bachelor's Degree in a relevant field: computer science, data science, mathematics, finance, economics, statistics\n    \n \n \n     Strong ability to translate complex business needs into precise technical specs; Demonstrated expertise in crafting custom datasets for analytical demands, showcasing adept data management\n    \n \n \n     5+ years of demonstrated proficiency in advanced analytics, deriving insights from diverse data sources, databases, and big data. Expert command of SQL for extraction, manipulation, and analysis is crucial\n    \n \n \n     3+ years of hands-on experience with business intelligence tools, particularly Tableau. Proven ability in designing and developing impactful dashboards for informed decisions and strategic insights\n    \n \n \n \n   Preferred:\n  \n \n \n \n     Familiarity with Google Cloud Platform (GCP), particularly BigQuery\n    \n \n \n     Familiarity with ETL tools such as Fivetran\n    \n \n \n     Familiarity with Salesforce", "techs": ["sql", "tableau", "google cloud platform (gcp)", "bigquery", "etl", "fivetran", "salesforce"]}, "322eb7ffc68c1c8c": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "AI Graphics Software Development Engineer (f/m/d)", "company": "INTEL", "desc": "Job Description \n  Are you passionate about transforming the world of realtime 3D rendering with AI? If so, we have an exciting opportunity for you. Join Intel XeSS Research and Development team and be at the forefront of revolutionizing real-time 3D rendering with AI algorithms and neural rendering techniques. As a part our team, you'll delve deep into architecture, design, and development of optimized AI-based rendering software libraries, SDKs and algorithms for 3D game developers. \n \n  We are looking for a highly motivated senior Graphics Software Development engineer with a strong AI and 3D realtime graphics background, and expertise in neural rendering techniques with track record in delivering and leading successful AI and Graphics software projects.Working together with world-class AI and Graphics engineers, you will design the API and architecture for optimized AI-based rendering libraries and tools, and lead development of those in DX12 and Vulkan environments. \n  Qualifications \n  Required Skills: \n \n \n  BS, MS, or PhD in fields such as Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, or other related fields. \n  5+ years of optimized Graphics and AI software libraries development experience. \n  Deep understanding of 3D graphics APIs, including DX12 and Vulkan. \n  Ability to create low-level optimized extensions to the APIs and develop optimized HLSL/GLSL kernels for various AI and Graphics algorithms, including complex AI model inference engine for DX/Vulkan render queue. \n  Expertise in state-of-the-art techniques in real-time rendering, ray tracing, optimization techniques such as temporal antialiasing, supersampling, super-resolution, ray tracing denoising is essential to help us push the boundaries of what is possible in 3D rendering. \n  Solid understanding of modern GPU HW architectures, with skills to heavily optimize GPU kernels leveraging HW specifics. \n  Excellent interpersonal and communications skills in a cross-functional setting, exceptional team player \n  Solid written and spoken English skills, necessary to facilitate effective communication within our diverse, global team. \n \n \n  The following skills will be a plus: \n \n \n  Familiarity with Deep Learning network architectures, hands-on experience with DL frameworks such as TensorFlow and PyTorch, python programming skills. \n  Solid knowledge of broad range of AI algorithms and principles, experience with optimization of Deep Learning inference algorithms for various GPU architectures \n  Experience with extending and tuning 3D Game Engines, ex. Unreal Engine and Unity. \n  Expertise in creation of complex game engine plugins for rendering pipeline \n \n \n  Inside this Business Group \n  The Client Computing Group (CCG) is responsible for driving business strategy and product development for Intel's PC products and platforms, spanning form factors such as notebooks, desktops, 2 in 1s, all in ones. Working with our partners across the industry, we intend to continue to advance PC experiences to deliver the real-world performance people demand. As the largest business unit at Intel, CCG is investing more heavily in the PC, ramping its capabilities even more aggressively, and designing the PC experience even more deliberately, including delivering a predictable cadence of leadership products. As a result, we are able to fuel innovation across Intel, providing an important source of IP and scale, as well as help the company deliver on its purpose of enriching the lives of every person on earth.\n  \n  Posting Statement \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n  \n  Benefits \n  We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html\n  \n  Working Model \n  This role is available as a fully home-based and generally would require you to attend Intel sites only occasionally based on business need. This role may also be available as our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. \n  In certain circumstances the work model may change to accommodate business needs. \n  JobType  \n Fully Remote", "cleaned_desc": "  BS, MS, or PhD in fields such as Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, or other related fields. \n  5+ years of optimized Graphics and AI software libraries development experience. \n  Deep understanding of 3D graphics APIs, including DX12 and Vulkan. \n  Ability to create low-level optimized extensions to the APIs and develop optimized HLSL/GLSL kernels for various AI and Graphics algorithms, including complex AI model inference engine for DX/Vulkan render queue. \n  Expertise in state-of-the-art techniques in real-time rendering, ray tracing, optimization techniques such as temporal antialiasing, supersampling, super-resolution, ray tracing denoising is essential to help us push the boundaries of what is possible in 3D rendering. \n  Solid understanding of modern GPU HW architectures, with skills to heavily optimize GPU kernels leveraging HW specifics. \n  Excellent interpersonal and communications skills in a cross-functional setting, exceptional team player \n  Solid written and spoken English skills, necessary to facilitate effective communication within our diverse, global team.   \n \n  The following skills will be a plus: \n \n \n  Familiarity with Deep Learning network architectures, hands-on experience with DL frameworks such as TensorFlow and PyTorch, python programming skills. \n  Solid knowledge of broad range of AI algorithms and principles, experience with optimization of Deep Learning inference algorithms for various GPU architectures \n  Experience with extending and tuning 3D Game Engines, ex. Unreal Engine and Unity. ", "techs": ["dx12", "vulkan", "hlsl", "glsl", "ai model inference engine", "ray tracing", "temporal antialiasing", "supersampling", "super-resolution", "ray tracing denoising", "gpu hw architectures", "tensorflow", "pytorch", "python programming", "3d game engines", "unreal engine", "unity"]}, "69e2ed7dab191ca1": {"terms": ["data science"], "salary_min": 75792.94, "salary_max": 95970.75, "title": "Analytics Community Manager", "company": "Pax8", "desc": "Pax8 is the leading cloud-based technology marketplace, simplifying the cloud journey for our partners by integrating technology, business intelligence and proactive service to deliver an unparalleled experience. Serving thousands of partners through the indirect sales channel, our mission is to be the world's favorite place to buy cloud products. We are a fast-growing, dynamic and high-energy startup organization, allowing you to make a meaningful impact on the business. Culture is important to us, and at Pax8, it's business, and it \n    IS  personal. We are passionate, creative and humorously offbeat. We work hard, keep it fun, and expect the best.\n   \n \n \n   We Elev8 each other. We Advoc8 for our partners. We Innov8 continuously. We Celebr8 life.\n   \n  No matter who you are, Pax8 is a place you can call home. We know there's no such thing as a  \"perfect\"  candidate, so we don't look for the right \" fit \" \u2013 instead, we look for the add. We encourage you to apply for a role at Pax8 even if you don't meet 100% of the bullet points. We believe in cultivating an environment with a diversity of perspectives, in hopes that we can all thrive in an inclusive environment. \n  We are only as great as our people. And we have great people all over the world. No matter where you live and work, you're a part of the Pax8 team. This means embracing hybrid- and remote-work whenever possible. \n \n  Position Summary:  \n The Analytics Community Manager spearheads the establishment and growth of a Community of Practice (CoP) for Business Intelligence (BI) analysts. In this role, they work closely with the Analytics Engineering team, BI analysts, and various stakeholders to create a thriving and collaborative environment where knowledge sharing, best practices, and continuous learning are encouraged. Additionally, the Manager is responsible for owning the Analytics Engineering team's backlog and collaborating with the team on report maintenance. \n  Essential Responsibilities: \n \n Community Building: \n    \n Develop and execute a strategy for the BI Analysts' CoP, fostering knowledge sharing, best practices, and collaborative learning \n Organize and lead workshops, training sessions, and webinars for BI analysts to enhance their skills and knowledge \n Curate and share resources, templates, and best practices to support the community's growth and development \n Foster engagement and collaboration among community members, encouraging active participation and discussion \n \n Team Backlog Management: \n    \n Manage the Analytics Engineering team backlog, ensuring that project priorities align with organizational goals and objectives \n Collaborate with team members to define project requirements, deliverables, and timelines \n Track project progress and facilitate effective communication within the team \n Prioritize and allocate resources to meet project deadlines \n \n Report Maintenance: \n    \n Work closely with the Analytics Engineering team to ensure the ongoing maintenance and optimization of existing reports and dashboards \n Troubleshoot and resolve issues related to data sources, report functionality, and performance \n Collaborate with stakeholders to gather and prioritize enhancement requests for reports \n   \n \n Ideal Skills, Experience, and Competencies: \n \n Proven experience in business intelligence and analytics \n Strong project management and organizational skills \n Excellent communication and facilitation skills \n Proficiency in BI tools such as Power BI, Tableau, or similar platforms \n Understanding of data modeling, ETL processes, and data visualization best practices \n Previous experience in community management or a similar role is a plus \n Enthusiastic about knowledge sharing and community building \n Self-motivated, with the ability to work both independently and collaboratively \n Strong problem-solving skills and the ability to adapt to evolving requirements \n Excellent team leadership and communication skills \n Results-driven and committed to achieving and exceeding objectives \n \n Required Education & Certifications: \n \n B.A./B.S. in related field (e.g., Data Science, Business Intelligence, Computer Science) or equivalent work experience \n \n Compensation: \n \n \n \n Qualified candidates can expect a salary beginning at $84,000 or more depending on experience \n \n \n \n #LI-Remote #LI-JF1 #BI-Remote \n \n \n Note: Compensation is benchmarked on local Denver Metro area market rates. Qualified candidates in other locations can expect a salary package that may be adjusted based off applicable cost of wages in their respective location. \n \n \n \n   At Pax8 we believe that your Total Rewards should include a benefits package that shows how much we value our greatest assets. All \n    FTE  Pax8 people enjoy the following benefits:\n   \n \n Non-Commissioned Bonus Plans or Variable Commission \n 401(k) plan with employer match \n Medical, Dental & Vision Insurance \n Employee Assistance Program \n Employer Paid Short & Long Term Disability, Life and AD&D Insurance \n Flexible, Open Vacation \n Paid Sick Time Off \n Extended Leave for Life events \n RTD Eco Pass (For local Colorado Employees) \n Career Development Programs \n Stock Option Eligibility \n Employee-led Resource Groups \n \n \n \n   Pax8 is an EEOC Employer.", "cleaned_desc": " \n Ideal Skills, Experience, and Competencies: \n \n Proven experience in business intelligence and analytics \n Strong project management and organizational skills \n Excellent communication and facilitation skills \n Proficiency in BI tools such as Power BI, Tableau, or similar platforms \n Understanding of data modeling, ETL processes, and data visualization best practices \n Previous experience in community management or a similar role is a plus \n Enthusiastic about knowledge sharing and community building \n Self-motivated, with the ability to work both independently and collaboratively \n Strong problem-solving skills and the ability to adapt to evolving requirements \n Excellent team leadership and communication skills \n Results-driven and committed to achieving and exceeding objectives \n \n Required Education & Certifications: \n ", "techs": ["power bi", "tableau"]}, "5320300d1856fc21": {"terms": ["data science"], "salary_min": 95000.0, "salary_max": 105000.0, "title": "Senior Healthcare Decision Support Analyst (REMOTE)", "company": "University of Colorado Medicine", "desc": "CU Medicine is dedicated to providing healthcare and administrative support to the University of Colorado School of Medicine\u2019s nearly 3,000 providers and is affiliated with the leading medical institutions in the West. Located adjacent to the Anschutz Medical Campus, one of the largest and most advanced academic medical campuses in the country, CU Medicine offers a variety of administrative, technical and healthcare support career opportunities and serves as a resource for patients and physicians. \n \n  We are seeking a highly skilled Senior Decision Support Analyst to join our team. \n \n  This job can be performed 100% remotely and out of state candidates will be considered. \n \n  The Senior Decision Support Analyst will identify operational revenue cycle performance improvement opportunities through proactive collection, analysis and interpretation of data and communicate this insight to key decision makers. The individual in this position will participate in new initiatives as a partner in the original and continuous discovery of the link between business process improvement and actionable data. The Sr. Analyst will be tasked with researching and developing investigative and root cause tools and strategies that positively impact operational improvement. \n \n \n Duties include but are not limited to: \n \n \n Utilize revenue cycle data and statistical methods to provide diagnostic and predictive insight into operational performance based on knowledge of business objectives while proactively suggesting methods of improving operations and implementing methodologies. \n Identify user needs and product requirements for Decision Support reporting assets/tools including selection, design, documentation, testing and implementation of products based on these requirements. \n Facilitate strategic decisions through optimized reporting, advanced analytics and proactive discovery. \n Initiate/participate/influence in relevant meetings or presentations to provide subject matter expertise and guidance to executive leadership. \n Support decision makers in using appropriate analytics tools and processes in order to perform advanced data analysis. \n Maintain project plan and priority status for all projects to ensure project timelines are met. \n Perform other duties and assist with special projects as assigned. \n  Requires a bachelor\u2019s degree in statistics, computer science or business-related field and 7-10 years relevant experience, preferably in a physician billing or hospital environment. An MBA is highly preferred. Must have expert level proficiency in report development using SQL Server Management Studio and Microsoft Excel, with strong working experience in the development of spreadsheets, pivot tables and visualizations. Experience in GE/IDX Centricity Business is preferred. Experience in STATA or R (or similar data science tool/language); Visio; and visualization tools such as Tableau is highly desired. Epic Clarity Certification (in any Clinical and/or Revenue Cycle modules) is a plus. The ability to gather information and understand the context from several sources, analyze this information to draw conclusions and make proactive recommendations to high level decision makers is essential to success. Must have strong project management skills and the ability to ensure project timelines are met. Experience in Six Sigma or similar methods for process improvement initiatives is preferred. The ability to work in a team environment working cohesively with others to achieve goals and initiatives is required. Must be flexible and maintain positive working relationships. \n \n  All applications MUST be submitted via our website. \n \n  CU Medicine is dedicated to ensuring a safe and secure environment for our staff and visitors. To assist in achieving that goal, we conduct background investigations for all prospective employees prior to their employment. We are an equal opportunity employer. \n \n  The listed pay range (or hiring rate) represents CU Medicine\u2019s good faith and reasonable estimate of the range of possible compensation at the time of posting and is based on evaluation of competitive market data. \n \n  A variety of factors, including but not limited to, internal equity, experience, and education will be considered when determining the final offer. \n \n  CU Medicine provides generous leave, health plans and retirement contributions which take your total compensation beyond the number on your paycheck. Find information about our benefits here \n \n  CU Medicine supports a Tobacco Free Workplace Environment which prohibits smoking and the use of tobacco products on CU Medicine property, Anschutz Medical Campus and adjacent business locations.", "cleaned_desc": " Perform other duties and assist with special projects as assigned. \n  Requires a bachelor\u2019s degree in statistics, computer science or business-related field and 7-10 years relevant experience, preferably in a physician billing or hospital environment. An MBA is highly preferred. Must have expert level proficiency in report development using SQL Server Management Studio and Microsoft Excel, with strong working experience in the development of spreadsheets, pivot tables and visualizations. Experience in GE/IDX Centricity Business is preferred. Experience in STATA or R (or similar data science tool/language); Visio; and visualization tools such as Tableau is highly desired. Epic Clarity Certification (in any Clinical and/or Revenue Cycle modules) is a plus. The ability to gather information and understand the context from several sources, analyze this information to draw conclusions and make proactive recommendations to high level decision makers is essential to success. Must have strong project management skills and the ability to ensure project timelines are met. Experience in Six Sigma or similar methods for process improvement initiatives is preferred. The ability to work in a team environment working cohesively with others to achieve goals and initiatives is required. Must be flexible and maintain positive working relationships. \n \n  All applications MUST be submitted via our website. \n \n  CU Medicine is dedicated to ensuring a safe and secure environment for our staff and visitors. To assist in achieving that goal, we conduct background investigations for all prospective employees prior to their employment. We are an equal opportunity employer. ", "techs": ["sql server management studio", "excel", "spreadsheets", "pivot tables", "visualization", "ge/idx centricity business", "stata", "r", "visio", "tableau", "epic clarity certification", "six sigma"]}, "74940e332b08512b": {"terms": ["data science", "machine learning engineer"], "salary_min": 50.0, "salary_max": 55.0, "title": "Senior Data Scientist - OOP / Visualization / Normalization / Data Modeling", "company": "Staff Finders Technical of Oregon", "desc": "Preference candidates that can work onsite in Urbandale, but will consider remote candidates if needed:. \n \n \n \n  As a Data Scientist for John Deere\u2019s Intelligent Services Group (ISG), you will join a team leveraging petabyte-scale datasets for advanced analytics and model building to enable intelligent, automated equipment and improved decisions by farmers. Our team partners with product managers and data engineers to design, scale, and deliver full stack data science solutions. Join a passionate team making a difference by applying innovative technology to solve some of the world's biggest problems. You will:\n  \n \n Communicate with impact your findings and methodologies to stakeholders with a variety of backgrounds. \n Work with high resolution machine and agronomic data in the development and testing of predictive models. \n Develop and deliver production-ready machine learning approaches to yield insights and recommendations from precision agriculture data \n Define, quantify, and analyze Key Performance Indicators that define successful customer outcomes. \n Work closely with the Data Engineering teams to ensure data is stored efficiently and can support the required analytics. \n \n \n   \n \n \n  Relevant skills include :\n  \n \n Demonstrated competency in developing production-ready models in an Object-Oriented Prog language such as Python. \n Demonstrated competency in using data-access technologies such as SQL, Spark, Databricks, BigQuery, MongoDB, etc. \n Experience with Visualization tools such as Tableau, PowerBI, DataStudio, etc. \n Experience with Data Modeling techniques such as Normalization, data quality and coverage assessment, attribute analysis, performance management, etc. \n Experience building machine learning models such as Regression, supervised learning, unsupervised learning, probabilistic inference, natural language modeling, etc. \n Excellent communication skills. Able to effectively lead meetings, to document work for reproduction, to write persuasively, to communicate proof-of-concepts, and to effectively take notes. \n \n \n   \n \n \n  What makes candidates stand-out are skills such as :\n  \n \n Additional experience with other languages such as R, JavaScript, Scala, etc. \n Examples of professional work such as publications, patents, a portfolio of relevant project-work, etc. \n Familiarity with Distributed Datasets \n Experienced with a variety of data structures such as time-series, geo-tagged, text, structured, and unstructured. \n Experience with simulations such as Monte Carlo simulation, Gibbs sampling, etc. \n Experience with model validation, measuring model bias, measuring model drift, etc. \n Experience collaborating with stakeholders from disciplines such as Product, Sales, Finance, etc. \n Ability to communicate complex analytical insights in a manner which is clearly understandable by nontechnical audiences. \n \n \n \n \n About Staff Finders Technical of Oregon: \n \n \n Founded in Oregon and Servicing the U.S. from Manufacturing, Aero space, Semi Conductor, Electronics. Circuit Board Contractors I.T., Hardware and Software Engineering. We are a women owned business with our founder having over 30 years experience and contacts in these Industries. Let us help you with your next career move send all resumes to our email and we will promptly get busy on your career change. Welcome to our site www.stafffinders.com Best wishes on you next move forward in your career. call today 503 617 2979", "cleaned_desc": "Preference candidates that can work onsite in Urbandale, but will consider remote candidates if needed:. \n \n \n \n  As a Data Scientist for John Deere\u2019s Intelligent Services Group (ISG), you will join a team leveraging petabyte-scale datasets for advanced analytics and model building to enable intelligent, automated equipment and improved decisions by farmers. Our team partners with product managers and data engineers to design, scale, and deliver full stack data science solutions. Join a passionate team making a difference by applying innovative technology to solve some of the world's biggest problems. You will:\n  \n \n Communicate with impact your findings and methodologies to stakeholders with a variety of backgrounds. \n Work with high resolution machine and agronomic data in the development and testing of predictive models.    \n \n Demonstrated competency in developing production-ready models in an Object-Oriented Prog language such as Python. \n Demonstrated competency in using data-access technologies such as SQL, Spark, Databricks, BigQuery, MongoDB, etc. \n Experience with Visualization tools such as Tableau, PowerBI, DataStudio, etc. \n Experience with Data Modeling techniques such as Normalization, data quality and coverage assessment, attribute analysis, performance management, etc. \n Experience building machine learning models such as Regression, supervised learning, unsupervised learning, probabilistic inference, natural language modeling, etc. \n Excellent communication skills. Able to effectively lead meetings, to document work for reproduction, to write persuasively, to communicate proof-of-concepts, and to effectively take notes. \n   Familiarity with Distributed Datasets \n Experienced with a variety of data structures such as time-series, geo-tagged, text, structured, and unstructured. \n Experience with simulations such as Monte Carlo simulation, Gibbs sampling, etc. \n Experience with model validation, measuring model bias, measuring model drift, etc. \n Experience collaborating with stakeholders from disciplines such as Product, Sales, Finance, etc. \n Ability to communicate complex analytical insights in a manner which is clearly understandable by nontechnical audiences. \n \n \n ", "techs": ["python", "sql", "spark", "databricks", "bigquery", "mongodb", "tableau", "powerbi", "datastudio", "normalization", "regression", "supervised learning", "unsupervised learning", "natural language modeling", "distributed datasets", "time-series", "geo-tagged data", "text data", "structured data", "unstructured data", "monte carlo simulation", "model validation"]}, "00d924b204e8ba76": {"terms": ["data science", "data analyst"], "salary_min": 83612.055, "salary_max": 105871.49, "title": "Insurance Product Analyst (Remote - US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  We are seeking an  Insurance Product Analyst  to join the Insurance State Product Management function. This role offers the opportunity to lead exciting analyses and hone your analytical, technical, and communication skills while working closely with and in support of our Regional Product Managers. You will work across the Insurance State Product Management team to analyze and understand the data behind our product offering and solve real business challenges. \n  This role requires a self-motivated, high-energy individual who can efficiently function in a fast-paced, performance-driven environment while maintaining attention to detail. \n  Key Responsibilities \n \n Work individually and as a part of a team to gather and analyze data qualitatively and quantitatively to recommend solutions to drive business results. \n Partner with Regional Product Managers to provide support and insights on state and regional trends and performance. \n Perform market/competitor intelligence research on a state and regional level to provide insight on macro market trends. \n \n Requirements \n \n 2-4 years of combined experience in insurance product management roles \n A degree in Mathematics, Business, Economics, Statistics, or similar study \n Strong technical (SQL) and analytical skills, capable of developing quantitative analyses through data manipulation \n Strong communication skills \n Insurance experience is required, and P&C or homeowners insurance experience is a plus \n \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": "", "techs": ""}, "425cea52f83661f2": {"terms": ["data science"], "salary_min": 102687.73, "salary_max": 130025.54, "title": "Senior Insurance Product Analyst (Remote - US)", "company": "Openly", "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $100M Series D fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures, Advance Venture Partners, Eden Global Partners, and Clocktower Technology Ventures. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  Job Details \n  We are seeking an experienced  Senior   Insurance Product Analyst  to own reporting and analysis within Insurance Product Management. Reporting to the Director of Insurance Product Solutions, this highly visible role offers the opportunity to lead exciting analyses and own monthly reporting for the group. This role requires a self-motivated, high-energy individual who can efficiently function in a fast-paced, performance-driven environment. \n  Key Responsibilities \n \n Conducting analysis and making recommendations to drive business results \n Analyzing key performance indicators and drivers of profitability, including loss ratios, frequency/severity trends, sales conversion, persistency, and other data \n Presenting monthly results to the insurance product team and Openly leadership team \n Leading other product management initiatives, such as external data evaluations, market/competitor intelligence, and new product development \n \n Requirements \n \n 3-5 years of combined experience in insurance product management roles \n A degree in Mathematics, Business, Economics, Statistics, or similar study \n Strong technical (SQL) and analytical skills, capable of developing quantitative analyses through data manipulation \n Ability to identify and define complex business problems and develop relevant analytical frameworks to deliver solutions, often operating in ambiguity and leveraging creativity \n Strong communication skills and comfort presenting to various audiences \n P&C insurance experience is required, and homeowners insurance experience is a plus \n \n \n  Benefits & Perks \n \n Remote-First Culture - We supported #remotelife long before it was a given. We'll keep promoting it. \n Competitive Salary & Equity \n Comprehensive Medical, Dental, and Vision Plan Offerings \n Life and disability coverage including voluntary options \n Competitive PTO - 20 days and 11 paid holidays (including floating holidays) per year under the Company's vacation and holiday policies.  \n Parental Leave - 12 weeks paid for eligible employees \n 401K Company Contribution - Openly contributes 3% of the employee's gross income, even if the employee does not contribute. \n Work-from-home stipend - We provide a $1,500 allowance to spend on setting up your home workplace \n Annual Professional Development Fund: Each employee has $2,000 in professional development (PD) funds to spend on activities or resources annually. We want each Openly employee to achieve personal and professional success and to feel supported, confident, and informed about improving their efficiency and productivity. \n Be Well Program - Employees receive $50 per month to use towards your overall well-being \n Paid Volunteer Service Hours \n Referral Program and Reward \n \n Depending on position, Employees generally are eligible for cash incentive compensation, including commissions for sales eligible roles. In all cases, eligibility for compensation and benefits is subject to applicable plan and policy terms in effect from time to time. \n  U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.", "cleaned_desc": "", "techs": ""}, "05d424689f134289": {"terms": ["data science", "machine learning engineer"], "salary_min": 146013.4, "salary_max": 184885.5, "title": "Principal DataOps Engineer", "company": "Pluralsight", "desc": "Job Description:\n  \n \n   Working at Pluralsight\n  \n \n   Founded in 2004 and trusted by Fortune 500 companies, Pluralsight is the technology skills platform organizations and individuals in 150+ countries count on to create progress for the world.\n  \n \n   Our platform helps technologists master their craft and take control of their careers. We empower businesses everywhere to build adaptable teams, speed up release cycles and become scalable, reliable and secure. We come to work every day knowing we\u2019re helping our customers build the skills that power innovation.\n  \n \n   And we don\u2019t let fear, egos or drama distract us from our mission. Our mission to democratize technology skills is what drives us and our values are at the helm of how we work together. It\u2019s our commitment to practicing them day in, day out that enables our performance. We\u2019re adults, and we treat each other that way. We have the autonomy to do our jobs, transparency to eliminate office politics and trust each other to do the right thing. We thrive in an environment with creativity around every corner, challenges that keep us on our toes, and peers who inspire us to be the best we can be. We bring different viewpoints, backgrounds and experiences, and united by our mission, we are one.\n  \n \n   Bring yourself. Pluralsight is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age or veteran status.\n  \n \n   Our Offline Data Platform team is a force multiplier for data practitioners at Pluralsight. We provide platform, tooling and datasets to empower Pluralsight.\n  \n \n   Our work includes: building a data platform to support our product data scientists, data engineers and data analysts; replicating product data from our streaming platform and 3rd-party APIs to our data lake and warehouse; deploying data science models; and maintaining existing data infrastructure.\n  \n \n \n   You\u2019ll have the opportunity to work with data tools, like SQL, Python, Snowflake and Kafka, as well as platform tools like Kubernetes, Docker, AWS, and Terraform.\n  \n \n   Who you\u2019re committed to being:\n  \n \n \n \n     A problem solver who wields the data technology hammer\n    \n \n \n     Eager to teach / mentor team members and share your knowledge with others\n    \n \n \n     A phenomenal teammate who recognizes that we succeed or fail as team, not as individuals\n    \n \n \n     A collaborator with data scientists, engineers and analysts to understand their needs\n    \n \n \n     Eager to dive in to data sources to understand availability, utility, and integrity of our data\n    \n \n \n     Passionate about cloud computing; tailing new technologies for data processing and machine learning at scale in the cloud What you\u2019ll own:\n    \n \n \n     Deploying and supporting data intensive systems\n    \n \n \n     Building and maintaining production data pipelines for data science and analytics\n    \n \n \n     Improving observability in our data environment, including uptime, usage, data quality, and data freshness\n    \n \n \n     Building production applications from data science research and exploratory analytical work\n    \n \n \n \n  Experience you\u2019ll need:\n  \n \n \n \n     Requires a minimum of 8+ years of related or equivalent experience\n    \n \n \n     Strong experience with AWS services (EC2, ASG, ELB, Route53, RDS, S3, VPC, IAM)\n    \n \n \n     Strong experience with Terraform.\n    \n \n \n     Experience with Linux administration and python programming.\n    \n \n \n     Experience with Docker and Docker compose.\n    \n \n \n     Strong experience with Event Streaming Platforms like AWS MSK (Kafka)\n    \n \n \n     Experience with CI/CD tools like Teamcity or Github Actions.\n    \n \n \n     Given the nature of high incident response, Excellent organization and communication skills is required for this role. Good to Have:\n    \n \n \n     Knowledge of container orchestration tools like Kubernetes.\n    \n \n \n     Knowledge of Infrastructure management tools like Salt Stack or Ansible\n    \n \n \n     Knowledge of Monitoring tools like Cloudwatch, Grafana or New Relic.\n    \n \n \n \n   Our Perks & Benefits Include\n  \n \n \n \n     Competitive salary and meaningful benefits\n    \n \n \n     Fully funded comprehensive medical & dental coverage including OPD for you and your family\n    \n \n \n     Open vacation policy\n    \n \n \n     Stay active with our wellness program that allows you to expense your gym membership and other sports activities\n    \n \n \n     Tuition reimbursement\n    \n \n \n \n   Bring yourself. Pluralsight is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age or veteran status.\n  \n \n \n   #LI-Remote\n  \n \n   #LI-JM2", "cleaned_desc": " \n \n     A problem solver who wields the data technology hammer\n    \n \n \n     Eager to teach / mentor team members and share your knowledge with others\n    \n \n \n     A phenomenal teammate who recognizes that we succeed or fail as team, not as individuals\n    \n \n \n     A collaborator with data scientists, engineers and analysts to understand their needs\n    \n \n \n     Eager to dive in to data sources to understand availability, utility, and integrity of our data\n    \n \n \n     Passionate about cloud computing; tailing new technologies for data processing and machine learning at scale in the cloud What you\u2019ll own:\n    \n \n \n     Deploying and supporting data intensive systems\n    \n \n \n     Building and maintaining production data pipelines for data science and analytics     \n \n \n     Improving observability in our data environment, including uptime, usage, data quality, and data freshness\n    \n \n \n     Building production applications from data science research and exploratory analytical work\n    \n \n \n \n  Experience you\u2019ll need:\n  \n \n \n \n     Requires a minimum of 8+ years of related or equivalent experience\n    \n \n \n     Strong experience with AWS services (EC2, ASG, ELB, Route53, RDS, S3, VPC, IAM)\n    \n \n \n     Strong experience with Terraform.\n    \n \n \n     Experience with Linux administration and python programming.\n      \n \n     Experience with Docker and Docker compose.\n    \n \n \n     Strong experience with Event Streaming Platforms like AWS MSK (Kafka)\n    \n \n \n     Experience with CI/CD tools like Teamcity or Github Actions.\n    \n \n \n     Given the nature of high incident response, Excellent organization and communication skills is required for this role. Good to Have:\n    \n \n \n     Knowledge of container orchestration tools like Kubernetes.\n    \n \n \n     Knowledge of Infrastructure management tools like Salt Stack or Ansible\n    \n \n \n     Knowledge of Monitoring tools like Cloudwatch, Grafana or New Relic.\n    \n \n \n ", "techs": ["data technology hammer", "cloud computing", "aws", "ec2", "asg", "elb", "route53", "rds", "s3", "vpc", "iam", "terraform", "linux", "python", "docker", "docker compose", "aws msk", "kafka", "ci/cd", "teamcity", "github actions", "kubernetes", "salt stack", "ansible", "cloudwatch", "grafana", "new relic"]}, "94ff1d8d2a0d5d5d": {"terms": ["data science"], "salary_min": 139000.0, "salary_max": 266000.0, "title": "Lead Mixed Methods Researcher", "company": "Cisco Meraki", "desc": "Meraki makes setting up and maintaining reliable Internet and Internet-powered devices easier than ever before. We enable organizations everywhere, from local libraries to hotels operating worldwide, to focus on their mission and have technology that simply works. As the fastest growing cloud-managed networking team in the world and one of the highest performing acquisitions in Cisco's history, our products and technology architecture are changing the approach to enterprise networking and making cloud-managed IT a reality. \n  We're looking for a Lead UX Researcher to lead research and experience strategy projects, mentor others around research best practices, and help craft the team's processes. Working with design, product management, and engineering partners, you will identify the right projects to seek using mixed research methods that get answers to our questions and inspire our user experiences. You will work to understand the complex needs and motivations of IT administrators and help the organization develop empathy accordingly. \n  Meraki believes the quality of our products is dependent on the quality of our teams. We place a high value on cultivating the growth and development of everyone we hire. On the UX team, we give and get feedback early and often, share what we know, and learn from each other. As a Lead UX researcher, you will be key in helping bring further definition to our UX research practice. \n  Our team's primary focus is on software, but we also find opportunities to collaborate with teams across the organization and think about how to improve the entire customer journey. \n  You'd be a good fit if you: \n \n Have a desire to understand people; their behaviors, attitudes, and motivations \n Find excitement in working in an industry with complex workflows \n Led complex, mixed-method research initiatives to help companies to discover and tackle problems \n Can identify the best methods, qualitative or quantitative, to get to actionable insights and scalable solutions \n Demonstrate good judgment in tradeoffs between time/effort and quality \n Collaborate with other UXRs, Data Scientists, designers, engineers, PMs, market researchers etc. \n Skilled in listening to and helping product managers, partners, and other team members to identify the right research questions \n An effective verbal and written communication style to distill complex research results into understandable, compelling, and actionable insights \n A self-starter - you don't wait for orders and identify what we need to learn and find the answers \n Are adaptable, resilient, and welcome change \n Have a growth mentality - you are continually learning \n Bring energy, empathy, and a sense of humor to the office every day \n \n Your day-to-day: \n \n Define research roadmaps to ensure key strategic initiatives are customer centric \n Align cross functional stakeholders through workshops and other methods to define problem space \n Lead, coach, and collaborate with others on foundational, generative and evaluative research efforts \n Take initiative to help formalize a research practice on a growing design team (e.g., identify tools, establish standards and templates, refine process) \n Set standards for other team members (designers, PMs, etc.) to conduct research and/or gather sound data in conversations with customers \n Synthesize findings into models, stories, and frameworks that help teams take action on insights \n Inspire the team with new methods, training, and thought leadership, especially quant research \n \n Requirements & Qualifications: \n \n Graduate degree with a focus on Psychology, Research Methods, Sociology, Human-computer Interaction (HCI), or any other related field. The equivalent in work experience is acceptable \n At least 10 years' experience with qualitative research techniques such as ethnography, 1:1 interviews, co-creation sessions, diary studies, usability and concept testing \n 8- 10 years of experience with survey research. Good understanding of basic statistics and some experience working with Data Science to triangulate data from analytics. \n Experience with statistical tools such as Qualtrics, SPSS or R. \n Experience with other platforms such as Usertesting.com, Google Analytics or FullStory \n Experience researching end-to-end user experience \n Excellent storytelling skills, you should be able to create compelling ways to generate, evangelize and present results. \n \n Bonus Points \n \n Proficient in survey research and advanced understanding of statistical analysis and techniques like regression or categorical data analysis. \n Knowledge of Design thinking methods and brainstorm facilitation techniques \n \n Meraki headquarters are based in the Mission Bay area of San Francisco, less than a 5-minute walk from the Chase Center and with beautiful views of the AT&T Ballpark and the Bay beyond. In Chicago, we are located in the beautiful Old Post Office downtown. Walking distance to public transportation including the L, Metra and CTA busses. Both offices provide access to an onsite gym, multiple kitchens stocked with high-quality snacks, a coffee bar, catered lunches every single day, and a generous benefits package. \n  At Cisco Meraki, we're challenging the status quo with the power of diversity, inclusion, and collaboration. When we connect different perspectives, we can imagine new possibilities, inspire innovation, and release the full potential of our people. We're building an employee experience that includes appreciation, belonging, growth, and purpose for everyone. \n  Cisco is an Affirmative Action and Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis. Cisco will consider for employment, on a case by case basis, qualified applicants with arrest and conviction records. \n \n  Compensation Range:  \n \n   $139,000\u2014$266,000 USD\n   \n \n \n  Message to applicants applying to work in the U.S.:  When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process. \n  U.S. employees have access to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program. \n  Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco pays at the standard rate of 1% of incentive target for each 1% revenue attainment against the quota up to 100%. Once performance exceeds 100% quota attainment, incentive rates may increase up to five times the standard rate with no cap on incentive compensation. For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.", "cleaned_desc": " 8- 10 years of experience with survey research. Good understanding of basic statistics and some experience working with Data Science to triangulate data from analytics. \n Experience with statistical tools such as Qualtrics, SPSS or R. \n Experience with other platforms such as Usertesting.com, Google Analytics or FullStory \n Experience researching end-to-end user experience \n Excellent storytelling skills, you should be able to create compelling ways to generate, evangelize and present results. \n \n Bonus Points \n \n Proficient in survey research and advanced understanding of statistical analysis and techniques like regression or categorical data analysis. \n Knowledge of Design thinking methods and brainstorm facilitation techniques \n ", "techs": ["qualtrics", "spss", "r", "usertesting.com", "google analytics", "fullstory"]}, "e397c42581d4d9c2": {"terms": ["data science"], "salary_min": 95000.0, "salary_max": 105000.0, "title": "Senior Healthcare Decision Support Analyst (REMOTE)", "company": "University of Colorado Medicine", "desc": "CU Medicine is dedicated to providing healthcare and administrative support to the University of Colorado School of Medicine\u2019s nearly 3,000 providers and is affiliated with the leading medical institutions in the West. Located adjacent to the Anschutz Medical Campus, one of the largest and most advanced academic medical campuses in the country, CU Medicine offers a variety of administrative, technical and healthcare support career opportunities and serves as a resource for patients and physicians. \n \n  We are seeking a highly skilled Senior Decision Support Analyst to join our team. \n \n  This job can be performed 100% remotely and out of state candidates will be considered. \n \n  The Senior Decision Support Analyst will identify operational revenue cycle performance improvement opportunities through proactive collection, analysis and interpretation of data and communicate this insight to key decision makers. The individual in this position will participate in new initiatives as a partner in the original and continuous discovery of the link between business process improvement and actionable data. The Sr. Analyst will be tasked with researching and developing investigative and root cause tools and strategies that positively impact operational improvement. \n \n \n Duties include but are not limited to: \n \n \n Utilize revenue cycle data and statistical methods to provide diagnostic and predictive insight into operational performance based on knowledge of business objectives while proactively suggesting methods of improving operations and implementing methodologies. \n Identify user needs and product requirements for Decision Support reporting assets/tools including selection, design, documentation, testing and implementation of products based on these requirements. \n Facilitate strategic decisions through optimized reporting, advanced analytics and proactive discovery. \n Initiate/participate/influence in relevant meetings or presentations to provide subject matter expertise and guidance to executive leadership. \n Support decision makers in using appropriate analytics tools and processes in order to perform advanced data analysis. \n Maintain project plan and priority status for all projects to ensure project timelines are met. \n Perform other duties and assist with special projects as assigned. \n  Requires a bachelor\u2019s degree in statistics, computer science or business-related field and 7-10 years relevant experience, preferably in a physician billing or hospital environment. An MBA is highly preferred. Must have expert level proficiency in report development using SQL Server Management Studio and Microsoft Excel, with strong working experience in the development of spreadsheets, pivot tables and visualizations. Experience in GE/IDX Centricity Business is preferred. Experience in STATA or R (or similar data science tool/language); Visio; and visualization tools such as Tableau is highly desired. Epic Clarity Certification (in any Clinical and/or Revenue Cycle modules) is a plus. The ability to gather information and understand the context from several sources, analyze this information to draw conclusions and make proactive recommendations to high level decision makers is essential to success. Must have strong project management skills and the ability to ensure project timelines are met. Experience in Six Sigma or similar methods for process improvement initiatives is preferred. The ability to work in a team environment working cohesively with others to achieve goals and initiatives is required. Must be flexible and maintain positive working relationships. \n \n  All applications MUST be submitted via our website. \n \n  CU Medicine is dedicated to ensuring a safe and secure environment for our staff and visitors. To assist in achieving that goal, we conduct background investigations for all prospective employees prior to their employment. We are an equal opportunity employer. \n \n  The listed pay range (or hiring rate) represents CU Medicine\u2019s good faith and reasonable estimate of the range of possible compensation at the time of posting and is based on evaluation of competitive market data. \n \n  A variety of factors, including but not limited to, internal equity, experience, and education will be considered when determining the final offer. \n \n  CU Medicine provides generous leave, health plans and retirement contributions which take your total compensation beyond the number on your paycheck. Find information about our benefits here \n \n  CU Medicine supports a Tobacco Free Workplace Environment which prohibits smoking and the use of tobacco products on CU Medicine property, Anschutz Medical Campus and adjacent business locations.", "cleaned_desc": " Perform other duties and assist with special projects as assigned. \n  Requires a bachelor\u2019s degree in statistics, computer science or business-related field and 7-10 years relevant experience, preferably in a physician billing or hospital environment. An MBA is highly preferred. Must have expert level proficiency in report development using SQL Server Management Studio and Microsoft Excel, with strong working experience in the development of spreadsheets, pivot tables and visualizations. Experience in GE/IDX Centricity Business is preferred. Experience in STATA or R (or similar data science tool/language); Visio; and visualization tools such as Tableau is highly desired. Epic Clarity Certification (in any Clinical and/or Revenue Cycle modules) is a plus. The ability to gather information and understand the context from several sources, analyze this information to draw conclusions and make proactive recommendations to high level decision makers is essential to success. Must have strong project management skills and the ability to ensure project timelines are met. Experience in Six Sigma or similar methods for process improvement initiatives is preferred. The ability to work in a team environment working cohesively with others to achieve goals and initiatives is required. Must be flexible and maintain positive working relationships. \n \n  All applications MUST be submitted via our website. \n \n  CU Medicine is dedicated to ensuring a safe and secure environment for our staff and visitors. To assist in achieving that goal, we conduct background investigations for all prospective employees prior to their employment. We are an equal opportunity employer. ", "techs": ["sql server management studio", "microsoft excel", "spreadsheets", "pivot tables", "ge/idx centricity business", "stata", "r", "visio", "tableau", "epic clarity certification", "six sigma"]}, "e559c94d97e98314": {"terms": ["data science"], "salary_min": 101119.266, "salary_max": 128039.53, "title": "Business Intelligence Developer", "company": "Spalding Consulting, Inc.", "desc": "Spalding Consulting, Inc. is seeking a Business Intelligence Developer in Lexington Park, MD -Remote. Spalding Consulting, Inc. is a professional services company delivering cutting-edge solutions to the Department of Defense since 2001. Our expert-level solutions include software development, information technology, program management, financial management and business intelligence services. Spalding Consulting offers competitive compensation, career development, flexible work schedules and excellent benefits. \n \n \n Position Type:  Full-Time \n \n Work Location:  This is a remote position (see on-site requirements below). \n \n \n **On-Site Requirements:  On-boarding will require 1-2 visits to Patuxent River, MD for candidates that are local to the area. Candidates out of state will be onboarded virtually. Training will be virtual and telework maximized/permitted to the greatest extent possible, however for local candidates, training/tasking may require on-site work a few hours per week. Future on-site/telework requirements/schedules may change as additional client direction is received. \n \n \n Essential Functions: \n \n \n Collaborate with team to breakdown requirements into plausible increments \n Create visualizations and calculations to support customer needs \n Modify and construct data models as appropriate \n Assist with technical and user documentation \n Assist with team peer reviews and testing \n Support existing or develop new applications for numerous customers \n Other duties as assigned or required. \n \n Qualifications and Experience: \n \n Required: \n \n \n At least 5 years of experience developing software programs using any language \n At least 2 years' experience of developing solutions to support an ETL process \n Experience with Oracle, SQL, or Teradata databases \n Experience with working on a team of at least 5 developers \n Experience with understanding and modifying data models \n \n Desired: \n \n \n Development experience using Tableau or Qlik \n Experience using Atlassian Jira \n Experience making REST API calls \n Experience in an Agile development environment \n \n Security Clearance: \n  Must be eligible to obtain a Secret clearance. Requirements to obtain a clearance include US Citizenship, security investigation, etc. \n \n \n Education: \n  Bachelor's Degree in Computer Science, Information Systems, Data Science, Engineering, or related discipline from an accredited institution is required. \n \n  Spalding Consulting, Inc. is committed to providing equal employment opportunities to all applicants and employees. We will not discriminate against any employee or applicant on the basis of race, color, ethnic origin, national origin, creed, religion, political belief, sex (including pregnancy), sexual orientation, gender identity, marital status, age, military status, physical or mental disability, or any other legally protected basis, in accordance with applicable federal, state or local laws. Spalding Consulting, Inc. is an Affirmative Action/Equal Opportunity Employer and encourages minorities, women, disabled, and veterans to apply for job openings within our company.", "cleaned_desc": " At least 5 years of experience developing software programs using any language \n At least 2 years' experience of developing solutions to support an ETL process \n Experience with Oracle, SQL, or Teradata databases \n Experience with working on a team of at least 5 developers \n Experience with understanding and modifying data models \n \n Desired: \n \n ", "techs": ["etl", "oracle", "sql", "teradata"]}, "c97b021d80771598": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Quantitative Analytics / Analysis Manager (Remote)", "company": "CEDENT", "desc": "Req I:\n   Title: Model Risk Quant Analytics Manager (Cleveland, OH or Remote)\n   Terms of Hire: Full Time.\n   Salary: $ Open K/ YR + Benefits.\n  \n \n Job description \n : \n \n ESSENTIAL JOB FUNCTIONS \n : \n \n \n Act as a member of the validation team to complete in-depth technical validations and reviews of models in the fraud, identity authentication, anomaly detection, amongst other functional areas. \n \n \n Leverage relevant industry expertise on fraud/authentication typologies and risks to evaluate model suitability for use and leveraging best practices for model use. \n \n \n Employ and assess advanced analytics and machine learning approaches for design sutiability, appropriate performance, and necessary diagnostics (e.g. optimization, hyperparameter tuning, interpretability, etc.) \n \n \n Review and challenge the conceptual framework, assumptions, limitations, technical soundness, fitness-for-use, and monitoring of Client\u2019s high impact models. \n \n \n Verify the correct model implementation through review and understanding of version control software. \n \n \n Oversee critical projects on high impact models, plan and organize project scope, liaison with stakeholders, and evangelize on best practices. \n \n \n Mentor junior model validators within the team on best practices. \n \n \n Verify the model has been properly documented, and produce documentation of the validation testing and results robustly for internal and external communications. \n \n \n REQUIRED QUALIFICATIONS \n : \n \n \n PhD/Master\u2019s in computer science, mathematics, data science, statistics, applied mathematics, finance, economics, or other related field \n \n \n 3+ years of model development or model validation experience in high impact models within financial crimes and fraud applications (e.g. Fraud, Identity Authentication, Anomaly Detection, , etc.) \n \n \n 7+ years of model development or model validation experience preferred (relevant academic experience can be considered) \n \n \n Strong working knowledge of Python, R, Matlab or other programming languages for computational/statistical learning \n \n \n Advanced knowledge of data science, machine learning, statistics, mathematics and artificial intelligence theory and applications \n \n \n Preferred experience with productionizing machine learning development, monitoring and implementation in cloud technologies (e.g AWS, GCP, Azure, or others) \n \n \n Preferred experience with modern data pipelining practices and tools (e.g. Data Proc, BigQuery, Spark/PySpark, and others) \n \n \n Excellent written and oral communication skills \n \n \n Proficiency in the use of Microsoft Office \n \n \n Ability to perform multiple tasks simultaneously to meet strict deadlines \n \n \n Mentoring experience of junior staff experience \n \n \n Effective working both independently and as a team-member \n \n \n  Req 2:\n   Title: Sr. Manager, Quantitative Analysis - Mortgage (Cleveland, OH or Remote)\n   Terms of Hire: Full Time.\n   Salary: $ Open K/ YR + Benefits. \n  Essential Job Functions : \n \n \n Leading the development of the Credit Loss Forecasting models, including supporting the implementation of modeling and analytical methodologies \n \n \n Coordinating analysis and responses to Internal Model Risk Validation and External Auditors from the Federal Reserve and the OCC \n \n \n Working closely with the Finance Management team as well as other critical stakeholders to shape and prioritize the modeling and analytical work efforts and plans \n \n \n Providing advice and recommendations to business leaders within the company to ensure the highest standards of practice, including the incorporation of credit loss forecasts into the ongoing evaluation of risk \n \n \n Performing complex quantitative and thoughtful qualitative assessments on all aspects of models including theoretical decisions, model design and implementation as well as data quality and integrity \n \n \n Building and leading a team, providing professional guidance to highly skilled workforce, and establishing plans and development goals to promote growth and success of the team and individuals \n \n \n   \n   Required Qualifications :   \n \n \n 5+ years of risk modeling and analytics experience and industry knowledge in Home lending within financial services \n \n \n Prior experience in developing CECL models is a strong plus \n \n \n Preference for PhD or MS in quantitative field: finance, econometrics, mathematics, physics, engineering \n \n \n Excellent communications skills \u2013 internally and externally, including with regulators \n \n \n Experience in Python / SAS / R building credit loss models \n \n \n Experience in developing and defining analytical methodologies \n \n \n A leader and a motivator \u2013 who can recruit, retain and advance great people \n \n \n A relationship builder, who can establish trust and credibility across the organization as well as with regulators and other critical external constituents \n \n \n Impeccable integrity, sound judgment, and strategic vision \n \n \n  You Will Enjoy: \n  \n \n An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way! \n \n \n Apply today to learn more and be part of our Growth story. \n \n All applications will be kept strictly confidential and once shortlisted, our team will be in touch with you for further discussions.", "cleaned_desc": " Oversee critical projects on high impact models, plan and organize project scope, liaison with stakeholders, and evangelize on best practices. \n \n \n Mentor junior model validators within the team on best practices. \n \n \n Verify the model has been properly documented, and produce documentation of the validation testing and results robustly for internal and external communications. \n \n \n REQUIRED QUALIFICATIONS \n : \n \n \n PhD/Master\u2019s in computer science, mathematics, data science, statistics, applied mathematics, finance, economics, or other related field \n \n \n 3+ years of model development or model validation experience in high impact models within financial crimes and fraud applications (e.g. Fraud, Identity Authentication, Anomaly Detection, , etc.) \n \n \n 7+ years of model development or model validation experience preferred (relevant academic experience can be considered) \n \n \n Strong working knowledge of Python, R, Matlab or other programming languages for computational/statistical learning \n \n \n Advanced knowledge of data science, machine learning, statistics, mathematics and artificial intelligence theory and applications \n \n   Preferred experience with productionizing machine learning development, monitoring and implementation in cloud technologies (e.g AWS, GCP, Azure, or others) \n \n \n Preferred experience with modern data pipelining practices and tools (e.g. Data Proc, BigQuery, Spark/PySpark, and others) \n \n \n Excellent written and oral communication skills \n \n \n Proficiency in the use of Microsoft Office \n \n \n Ability to perform multiple tasks simultaneously to meet strict deadlines \n \n \n Mentoring experience of junior staff experience \n \n \n Effective working both independently and as a team-member \n \n \n  Req 2:\n   Title: Sr. Manager, Quantitative Analysis - Mortgage (Cleveland, OH or Remote)\n   Terms of Hire: Full Time.\n   Salary: $ Open K/ YR + Benefits. \n  Essential Job Functions : \n \n   Leading the development of the Credit Loss Forecasting models, including supporting the implementation of modeling and analytical methodologies \n \n \n Coordinating analysis and responses to Internal Model Risk Validation and External Auditors from the Federal Reserve and the OCC \n \n \n Working closely with the Finance Management team as well as other critical stakeholders to shape and prioritize the modeling and analytical work efforts and plans \n \n \n Providing advice and recommendations to business leaders within the company to ensure the highest standards of practice, including the incorporation of credit loss forecasts into the ongoing evaluation of risk \n \n \n Performing complex quantitative and thoughtful qualitative assessments on all aspects of models including theoretical decisions, model design and implementation as well as data quality and integrity \n \n \n Building and leading a team, providing professional guidance to highly skilled workforce, and establishing plans and development goals to promote growth and success of the team and individuals \n \n \n   \n   Required Qualifications :   \n \n \n 5+ years of risk modeling and analytics experience and industry knowledge in Home lending within financial services \n \n \n Prior experience in developing CECL models is a strong plus \n \n   Preference for PhD or MS in quantitative field: finance, econometrics, mathematics, physics, engineering \n \n \n Excellent communications skills \u2013 internally and externally, including with regulators \n \n \n Experience in Python / SAS / R building credit loss models \n \n \n Experience in developing and defining analytical methodologies \n \n \n A leader and a motivator \u2013 who can recruit, retain and advance great people \n \n \n A relationship builder, who can establish trust and credibility across the organization as well as with regulators and other critical external constituents \n \n \n Impeccable integrity, sound judgment, and strategic vision \n \n \n  You Will Enjoy: \n  \n \n An opportunity to be a part of a great culture, an awesome team, a challenging work environment, and some fun along the way! \n \n \n Apply today to learn more and be part of our Growth story. ", "techs": ["python", "r", "matlab", "aws", "gcp", "azure", "data proc", "bigquery", "spark/pyspark", "sas"]}, "e0a89543c1b950cc": {"terms": ["data science", "machine learning engineer"], "salary_min": 80818.99, "salary_max": 125966.76, "title": "Data Science", "company": "GTECH LLC", "desc": "Combine two of the fastest-growing fields on the planet with a culture of performance, collaboration and opportunity and this is what you get. Leading edge technology in an industry that is improving the lives of millions. Here, innovation is not about another gadget; it is about making health care data available wherever and whenever people need it, safely and reliably. There is no room for error. If you are looking for a better place to use your passion and your desire to drive change, this is the place to be. It's an opportunity to do your life's best work.(sm) \n Primary Responsibilities: \n Researching, designing, implementing and deploying full-stack scalable machine learning solutions to support intelligent operations initiatives \n Conduct hands-on data analysis and predictive analytics on large datasets \n Effectively communicate complex technical results to business partners \n Support and drive analytic efforts around machine learning and innovation \n Work with a great deal of autonomy to find solutions to complex problems \n Design and implement deep learning models for natural language processing \n Collaborate with data engineers to design and implement data pipelines \n Work with software engineers to integrate models into production systems \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n Job qualifications \n BA/BS in Applied Mathematics, Physics, Computer Science, Statistics or related technical field or equivalent experience \n 5+ years of hands-on experience in developing analytics with machine learning, deep learning, NLP, and/or other related modeling techniques \n 3+ years of experience using advanced data science tools such as R, Python, SQL, Spark and H2O \n 3+ years of experience developing and deploying analytic solutions using AWS/Azure/GCP \n Experience applying computational algorithms and statistical methods to structured and unstructured data \n Experience building end-to-end solutions using deep learning models \n Experience breaking down and clearly defining problems \n Experience communicating highly technical results to a diverse audience \n Experience with full-stack development is a plus \n Experience with agile development methodologies is a plus \n Solid execution mentality \n Job Type: Full-time \n Salary: $80,818.99 - $125,966.76 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Tuition reimbursement \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Python: 1 year (Preferred) \n SQL: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Collaborate with data engineers to design and implement data pipelines \n Work with software engineers to integrate models into production systems \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n Job qualifications \n BA/BS in Applied Mathematics, Physics, Computer Science, Statistics or related technical field or equivalent experience \n 5+ years of hands-on experience in developing analytics with machine learning, deep learning, NLP, and/or other related modeling techniques \n 3+ years of experience using advanced data science tools such as R, Python, SQL, Spark and H2O \n 3+ years of experience developing and deploying analytic solutions using AWS/Azure/GCP ", "techs": ["data pipelines", "models", "production systems", "r", "python", "sql", "spark", "h2o", "aws", "azure", "gcp"]}, "5747a78ffc167d18": {"terms": ["data science", "data analyst"], "salary_min": 80330.75, "salary_max": 101716.625, "title": "Data Analyst (Mid) - App & Platform Mgmt - IT - Corp - US", "company": "Bayer", "desc": "Chesterfield, MO, United States (Remote)\n    \n \n \n \n \n     Contract (12 months 1 day)\n    \n \n \n \n    Published today\n   \n \n \n \n \n     Java\n    \n \n \n \n     data visualization tools\n    \n \n \n \n     Advanced Excel\n    \n \n \n \n     relational databases\n    \n \n \n \n     Data Analytics\n    \n \n \n \n     Verbal and Written Communication skills\n    \n \n \n \n     Code development\n    \n \n \n \n     Python/R\n    \n \n \n \n     agronomy\n    \n \n \n \n     PL - SQL\n    \n \n \n \n \n \n  Candidates with a strong background in data/IT/analytics are highly desired for this position. \n  The individual will be responsible for data and pipeline management activities with enfaces around pre and post advancement set-up and support across row crops. \n  This position is expected to interact with various functions within the company, for example, supply chain, manufacturing, biotech, and across breeding. \n  Attention to detail, agility, and meeting deadlines on a fast pace environment are key for the success of this role. \n  Additionally, the individual will support short-term analytical projects during non-peak seasons. \n \n \n  Required Skills / Education \n \n  BS in life sciences, data science, statistics. \n  Excellent Excel and relational database skills. \n  Ability learn fast a number of processes with consistency and attention to detail. \n  Commitment to ensuring data quality and accuracy and attention to detail. \n  Self starter and be able to work as part of a team. \n  Fosters a sense of urgency, identifies and overcomes obstacles. \n  Good interpersonal and communication skills. \n \n \n  Desired Skills / Experience:  \n \n Knowledge of breeding, agriculture, and/or biotechnology. \n  Code development experience with any of these languages: R, Python, Java, C++, SAS. \n  Experience with Visualization tools. PL-SQL knowledge. \n  Strong Understanding of database systems and management of large data sets. \n  M.Sc. in an analytics field. Imagine better solutions. \n  4-6 Years of Experience \n \n \n  BAY1JP00020265", "cleaned_desc": "  Required Skills / Education \n \n  BS in life sciences, data science, statistics. \n  Excellent Excel and relational database skills. \n  Ability learn fast a number of processes with consistency and attention to detail. \n  Commitment to ensuring data quality and accuracy and attention to detail. \n  Self starter and be able to work as part of a team. \n  Fosters a sense of urgency, identifies and overcomes obstacles. \n  Good interpersonal and communication skills. \n \n \n  Desired Skills / Experience:  \n \n Knowledge of breeding, agriculture, and/or biotechnology. \n  Code development experience with any of these languages: R, Python, Java, C++, SAS. \n  Experience with Visualization tools. PL-SQL knowledge. \n  Strong Understanding of database systems and management of large data sets. \n  M.Sc. in an analytics field. Imagine better solutions. \n  4-6 Years of Experience ", "techs": ["excel", "relational database", "r", "python", "java", "c++", "sas", "visualization tools", "pl-sql", "database systems"]}, "950b7bace2be7973": {"terms": ["data science"], "salary_min": 111821.99, "salary_max": 141591.56, "title": "Data Scientist", "company": "American Recruiting & Consulting Group", "desc": "Sr. Data Scientist - Remote    ARC Group has an immediate opportunity for a Sr. Data Scientist with experience working with Unstructured Content, NLP, Python, R, ML, SAS for a client based in Jacksonville, FL. This position is starting out as a contract position running through May 2024 with strong potential to extend longer or possibly convert to FTE. This is a fantastic opportunity to get onboard with an established and well-respected organization that offers tremendous career growth opportunities!     Candidates must have permanent work authorization and work for any employer without sponsorship now or in the future. Third party candidates are not eligible for this role.     100% Remote!   Reference# 14782-1    Must Have Skills: \n \n  unstructured content \n  Text Classification \n  NLP \n  Python \n  PyTorch \n \n  Job Description:  Data Scientists produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries. Use a flexible, analytical approach to design, develop, and evaluate predictive models. Generate and test hypotheses. The Data Scientist proactively seeks to develop their skillsets and provide value-added support within the Data Science team.    Essential functions: \n \n  Communication & Project Ownership \n  Support large projects, and manage smaller projects in their entirety \n  Partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. \n  Communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. \n  Identify and communicate roadblocks. \n  Work on multiple concurrent projects and accommodate frequent interruptions and changing priorities \n  Effectively participate in meetings with customers and emerging ability to guide discussion and decision making. \n \n  Data Analysis \n \n  Acquire and bring structure to data so that it can be used in existing and new data systems. \n  Build tools that help you and the other Data Scientists translate insights into action at scale. \n  Identify, define and translate business needs/problems into analytical questions. \n  Design and execute experiments, models, algorithms, and visualizations \n  Understand data sources and limitations, warehousing system and the impact of the data on business decisions. \n  Identify, retrieve, and manipulate data from internal and external datasets. \n  Apply statistical and computational methodologies to provide actionable insights and identify opportunities that optimize quality, consumer experience, and healthcare costs. \n  Develop scalable, efficient, and automated processes for large scale data analyses and model development, validation, and implementation. \n \n  Reporting & Other \n \n  Contribute to technical reports, white papers, and publications. \n  Stay current on new processes and technology in Data Science and communicate findings to team \n  Perform all other tasks as assigned \n \n  Job Requirements: \n \n  Requires experience with Object oriented programming such as Python or Java. and statistical packages 3 years of SAS, SAS EG, and SAS EM, 1 yr of R or Python. \n  Requires expert proficiency in SQL \n  Requires experience with visual analytical packages such as Tableau or Microsoft Power BI \n  Strong analytical and problem-solving skills \n  Experience in supporting large projects, and manage smaller projects in their entirety \n  Ability to partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. \n  Ability to communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. \n  Must have applied experience with advanced analytics e.g. predictive analytics models \n  Must have applied experience in Machine Learning \n  Experience in Big Data - e.g. Hadoop \n  Business Intelligence tool development \n  Other programming experience - Java, Perl, Python, UNIX/Linux scripting \n  Healthcare, medical, or pharmaceutical work experience \n  Experience with analysis around quality, consumer experience, and healthcare costs \n  Experience in consumer analytics \n  Experience in business analytics \n \n  Required Experience: \n \n  5-8 years related work experience in advanced analytics or equivalent combination of transferable experience and education \n \n  Required Education:  Related Bachelors degree in Data Science, Applied Mathematics, Computer science (e.g. specialization: Machine learning/Artificial Intelligence /Visualization, databases, and Big Data), Statistics, Epidemiology, Health Services Research, or closely related field with Data Science specialization or additional related equivalent work experience    Must Have Skills: \n \n  unstructured content \n  Text Classification \n  NLP \n  Python \n  PyTorch \n \n  Nice to Have Skills: Healthcare experience, Medical Records experience    Required Experience: 5-8 years related work experience in advanced analytics or equivalent combination of transferable experience and education    Would you like to know more about our new opportunity? For immediate consideration, please send your resume directly to Suresh Gaddala at suresh@arcgonline.com, or apply online while viewing all of our open positions at www.arcgonline.com.    ARC Group is a Forbes-ranked a top 20 recruiting and executive search firm working with clients nationwide to recruit the highest quality technical resources. We have achieved this by understanding both our candidate's and client's needs and goals and serving both with integrity and a shared desire to succeed.    ARC Group is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce.    Position offered by \u201cNo Fee agency.\u201d \n  Would you like to know more about our new opportunity? For immediate consideration, please send your resume directly to Suresh Gaddala at suresh@arcgonline.com, or apply online while viewing all of our open positions at www.arcgonline.com.    ARC Group is a Forbes-ranked a top 20 recruiting and executive search firm working with clients nationwide to recruit the highest quality technical resources. We have achieved this by understanding both our candidate's and client's needs and goals and serving both with integrity and a shared desire to succeed.    ARC Group is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce.    Position offered by \u201cNo Fee agency.\u201d \n   \n 1j5RG2N42u", "cleaned_desc": "Sr. Data Scientist - Remote    ARC Group has an immediate opportunity for a Sr. Data Scientist with experience working with Unstructured Content, NLP, Python, R, ML, SAS for a client based in Jacksonville, FL. This position is starting out as a contract position running through May 2024 with strong potential to extend longer or possibly convert to FTE. This is a fantastic opportunity to get onboard with an established and well-respected organization that offers tremendous career growth opportunities!     Candidates must have permanent work authorization and work for any employer without sponsorship now or in the future. Third party candidates are not eligible for this role.     100% Remote!   Reference# 14782-1    Must Have Skills: \n \n  unstructured content \n  Text Classification \n  NLP \n  Python \n  PyTorch \n \n  Job Description:  Data Scientists produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets. Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries. Use a flexible, analytical approach to design, develop, and evaluate predictive models. Generate and test hypotheses. The Data Scientist proactively seeks to develop their skillsets and provide value-added support within the Data Science team.    Essential functions: \n \n  Communication & Project Ownership \n  Support large projects, and manage smaller projects in their entirety \n  Partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights.    Communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. \n  Identify and communicate roadblocks. \n  Work on multiple concurrent projects and accommodate frequent interruptions and changing priorities \n  Effectively participate in meetings with customers and emerging ability to guide discussion and decision making. \n \n  Data Analysis \n \n  Acquire and bring structure to data so that it can be used in existing and new data systems. \n  Build tools that help you and the other Data Scientists translate insights into action at scale. \n  Identify, define and translate business needs/problems into analytical questions. \n  Design and execute experiments, models, algorithms, and visualizations \n  Understand data sources and limitations, warehousing system and the impact of the data on business decisions. \n  Identify, retrieve, and manipulate data from internal and external datasets.    Apply statistical and computational methodologies to provide actionable insights and identify opportunities that optimize quality, consumer experience, and healthcare costs. \n  Develop scalable, efficient, and automated processes for large scale data analyses and model development, validation, and implementation. \n \n  Reporting & Other \n \n  Contribute to technical reports, white papers, and publications. \n  Stay current on new processes and technology in Data Science and communicate findings to team \n  Perform all other tasks as assigned \n \n  Job Requirements: \n \n  Requires experience with Object oriented programming such as Python or Java. and statistical packages 3 years of SAS, SAS EG, and SAS EM, 1 yr of R or Python. \n  Requires expert proficiency in SQL    Requires experience with visual analytical packages such as Tableau or Microsoft Power BI \n  Strong analytical and problem-solving skills \n  Experience in supporting large projects, and manage smaller projects in their entirety \n  Ability to partner with senior team members to assess customer needs and define business questions. Emerging ability to influence customers to take action on analytical insights. \n  Ability to communicate results and insights, both verbally and written (including visual graphics), in a clear and concise manner to a non-technical audience. \n  Must have applied experience with advanced analytics e.g. predictive analytics models \n  Must have applied experience in Machine Learning \n  Experience in Big Data - e.g. Hadoop \n  Business Intelligence tool development \n  Other programming experience - Java, Perl, Python, UNIX/Linux scripting \n  Healthcare, medical, or pharmaceutical work experience \n  Experience with analysis around quality, consumer experience, and healthcare costs \n  Experience in consumer analytics ", "techs": ["unstructured content", "nlp", "python", "r", "ml", "sas", "pytorch", "tableua", "power bi", "sql", "hadoop", "java", "perl", "unix/linux scripting"]}, "0f8a47ab076ba381": {"terms": ["data science"], "salary_min": 129791.12, "salary_max": 164344.47, "title": "Analytics Engineer (L5) - Member Product", "company": "Netflix", "desc": "Remote, United States\n      \n \n \n \n \n \n \n         Data Science and Engineering\n        \n \n \n \n \n \n \n \n     At Netflix, we seek to entertain the world. We have more than 200 million members in 190 countries, reflecting that great stories can come from anywhere and be loved everywhere. Within Product, we have a very high velocity in innovations in the member experience. We never stop challenging ourselves and are constantly thinking about connecting with our members in new ways or even in new domains!\n    \n \n \n  Member Product DSE is at the forefront of these innovations with a mission to relentlessly improve Netflix member experience within our streaming and new verticals services across TV, Mobile & Web by surfacing insights, streamlining experimentation and enabling decision making at scale. The team collaborates extensively with Product, Design and Engineering teams to identify, incubate and enable product innovations leveraging robust measurement techniques (analytics, experimentation, modeling) and scalable tooling.\n    \n \n \n  As a Senior Analytics Engineer, you\u2019ll be working closely with data scientists, data engineers, and business teams to develop and maintain data pipelines, tools, and products to inform product strategy across member product experience.\n    \n \n \n  The ideal candidate will excel in data analytics, storytelling with data, cross-functional collaboration, and share a passion for continuously improving the way we use data to make the Netflix product better.\n    \n \n \n  To learn more about analytics engineering at Netflix, read here.\n    \n \n \n  In this role, you will: \n \n  Create a vision for how to best tell the story of how our members are engaging with Netflix and build consensus around this vision with our partners in Product, Design and Engineering Leadership \n  Build best in class analytics products that realize this vision; create robust tooling to monitor and evaluate product performance. \n  Work with our Data Engineering partners, and other Data Scientists on the team to make sure we have great data to support the products we are building. Some examples of this work include data modeling and semantic layer for analytics, experimentation, and many more. \n  Provide mentorship and guidance to other Analytics Engineers on the team. \n  Visit our culture deck and our Research page to learn about what it\u2019s like to work on Analytics at Netflix. \n \n \n \n  To be successful in this role, you have: \n \n  At least four years of experience building scalable data pipelines and solutions that power product understanding \n  Practical experience with domain specific data modeling to scale analytics across complex organization \n  Passion for building scalable repeatable tooling and data solutions; curiosity for understanding needs from internal and external users. \n  Strong communication skills with technical and non-technical audiences; \n  Expertise in SQL for working with big data (e.g. Spark, Trino). Experienced in engineering data pipelines and orchestrating workflows (e.g. Airflow, Metaflow) \n  Fluent in Object Oriented Programming in Python. \n  Familiarity with web technologies (e.g. API calls) and engineering practices (e.g. code review, unit testing) \n  Practical experience with building compelling, narrative data visualizations with dashboard tools \n \n \n \n     At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location. The overall market range for this role is typically $150,000 - $750,000. This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.\n     \n \n \n \n \n We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.", "cleaned_desc": "  Create a vision for how to best tell the story of how our members are engaging with Netflix and build consensus around this vision with our partners in Product, Design and Engineering Leadership \n  Build best in class analytics products that realize this vision; create robust tooling to monitor and evaluate product performance. \n  Work with our Data Engineering partners, and other Data Scientists on the team to make sure we have great data to support the products we are building. Some examples of this work include data modeling and semantic layer for analytics, experimentation, and many more. \n  Provide mentorship and guidance to other Analytics Engineers on the team. \n  Visit our culture deck and our Research page to learn about what it\u2019s like to work on Analytics at Netflix. \n \n \n \n  To be successful in this role, you have: \n \n  At least four years of experience building scalable data pipelines and solutions that power product understanding \n  Practical experience with domain specific data modeling to scale analytics across complex organization \n  Passion for building scalable repeatable tooling and data solutions; curiosity for understanding needs from internal and external users. ", "techs": ["data engineering", "data modeling", "analytics"]}, "59195d0c3a5c2bdc": {"terms": ["data science"], "salary_min": 8892.66, "salary_max": 13000.0, "title": "Senior Data Scientist", "company": "Health & Human Services Comm", "desc": "The Fraud Analytics unit within the Fraud Analytics and Data Operations (FADO) Division of the Office of Inspector General (OIG) is seeking a Senior Data Scientist (Data Scientist II). The Fraud Analytics unit is responsible for performing innovative and advanced data analytics to detect fraud, waste and abuse in state health and human services programs such as Medicaid (including Managed Care), CHIP, SNAP and TANF by supporting data-driven investigations, reviews, audits, and inspections. The Senior Data Scientist will lead the Fraud Analytics unit\u2019s efforts to develop and implement algorithms, artificial intelligence/machine learning (AI/ML) models, and predictive analytics to generate insights and actionable leads to identify and respond to risks of fraud, waste, and abuse. \n     \n  The Senior Data Scientist performs advanced (senior-level) data science work to build models and tools that detect potential fraud, waste, and abuse. This position reports to the Deputy Inspector General of Fraud Analytics and works under minimal supervision, with extensive latitude for the use of initiative and independent judgment. This position works closely with Fraud Analytics team members, internal OIG units, and external entities, provides guidance to others, and may supervise the work of others. \n     \n  The Senior Data Scientist is responsible for performing advanced level programming to clean, prepare, and query large, complex health and human services related datasets and to research and develop algorithms and models that identify data trends, patterns, and anomalies. This position prepares written model documentation and methodology documents; communicates data analytics findings through data visualizations and presentations; and tests and evaluates new tools, methods, and techniques. \n     \n  This position contributes to the data science strategy for the OIG and develops, manages, and monitors data science projects. This position provides technical guidance and mentoring to team members on development and AI/ML, analytical, and statistical tools, methods, and techniques. This position also serves as a subject matter expert in health and human services program data. \n     \n  *** This position can telework 100% from locations within Texas consistent with HHS telework policies. ***\n     \n \n \n \n \n \n \n \n Essential Job Functions: \n  Attends work on a regular and predictable schedule in accordance with agency leave policy and performs duties as assigned: \n     \n  1. Researches, designs, implements, and deploys production AI/ML models and predictive analytics to identify risk and detect potential fraud, waste, and abuse in state health and human services programs, with a primary focus on Medicaid. Plans and conducts data analytics on large, complex datasets, including medical, pharmacy, and dental claims and encounter data, using Python, R, SQL, and/or SAS. Interprets and explains identified data trends, patterns, and anomalies. Develops, implements, and assesses the validity of existing and emerging AI/ML, analytical and statistical tools, methods, and techniques. Applies advanced analytical and statistical methods and techniques to known and new data sources. Identifies and implements best practices in advanced data analytics and reporting. (50%) \n     \n  2. Effectively communicates data analytics findings and related recommendations to technical and non-technical stakeholders both verbally and in writing, including written model documentation, methodology documents and detailed reporting of findings through data packages, data visualizations, and presentations. (15%) \n     \n  3. Engages in collaboration and communication across internal OIG units and with external entities, including but not limited to: OIG program area customers, the OIG executive team, contractors/vendors, and team members. (15%) \n     \n  4. Provides technical guidance and mentoring on algorithm development and AI/ML, analytical, and statistical tools, methods, and techniques. Peer reviews code and methodologies. Develops and conducts training for internal OIG units and external stakeholders. \n      (10%) \n     \n  5. Serves as a subject matter expert in health and human services program data. Serves as a liaison to other state agencies, licensures boards, and federal agencies regarding fraud, waste and abuse in state health and human services programs. (5%) \n     \n  6. Performs other duties necessary to achieve the mission of the Office of Inspector General. Statewide travel of about 5% may be required. (5%)\n     \n \n \n \n \n \n \n \n Knowledge Skills Abilities: \n  1. Knowledge of AI/ML (including supervised and unsupervised learning techniques), analytical, and statistical tools, methods, and techniques; of data models and querying relational databases; of data wrangling, data mining and data visualization techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data. \n     \n  2. Expert programming skill in data science/scientific computing programming languages (Python, R) in using open-source data science frameworks. Experience in using SQL to query databases. Skill in Excel and PowerPoint. \n     \n  3. Skill in cleaning, preparing, querying, and analyzing large, complex datasets to discover trends and patterns and deliver meaningful insights. Skill in automating data collection and processing. \n     \n  4. Skill in data visualization to present data analytics results and findings. \n     \n  5. Skill in critical thinking, analyzing problems, and devising effective solutions. \n     \n  6. Skill in verbal and written communication skills essential to effectively interacting with OIG customers, leadership, and team members. \n     \n  7. Ability to partner with stakeholders to translate and decompose program integrity or other agency problems into data science solutions. \n     \n  8. Ability to research, learn, and apply knowledge of existing and emerging data science principles, theories and techniques. \n     \n  9. Ability to compile, review, analyze, manage, and manipulate large, complex data sets. \n     \n  10. Ability to effectively communicate complex data findings and analytical methodologies, both verbally and in writing, to technical and non-technical audiences. \n     \n  11. Ability to work in teams that may cross departments and/or agencies. \n     \n  12. Ability to work independently, exercise independent judgment, prioritize tasks, and manage multiple projects/assignments/responsibilities in a fast-paced environment under time constraints. \n     \n  13. Ability to provide guidance to others and supervise the work of others. \n     \n  14. Ability to plan, organize, lead, and monitor data science projects. \n     \n \n \n \n \n \n Registration or Licensure Requirements: \n  None. \n    \n \n \n \n \n \n \n Initial Selection Criteria: \n  Minimum 5 years experience using Python, R, or other data science/scientific computing programming languages/tools appropriate for large scale data preparation and analysis. Minimum 5 years experience using SQL to query databases. \n     \n  Minimum 5 years experience as a data scientist working with very large structured, unstructured, and semi-structured data. A proven track record of using supervised and unsupervised learning techniques to derive data insights through AI/ML methods and of proposing models and data-driven solutions that provide value and address agency needs. \n     \n  Experience in providing AI/ML solutions to program integrity issues in the healthcare domain preferred. \n     \n  Advanced degree (Master's or Ph.D.) in data science, business analytics, healthcare analytics, computer science, computer information systems, management information systems, mathematics, statistics, economics, or a related quantitative field required.\n     \n \n \n \n \n \n \n \n \n Additional Information: \n  A copy of college transcript will be required. \n     \n  The OIG is responsible for preventing, detecting, auditing, inspecting, reviewing, and investigating fraud, waste, and abuse in the provision of HHS in Medicaid and other HHS programs. Potential employees of OIG are subject to criminal background checks in accordance with the HHS Human Resources policy. Selected applicants must complete a national fingerprint-based criminal background check through the Texas Department of Public Safety (TDPS) and Federal Bureau of Investigations (FBI) to determine if they have criminal history record information that constitutes a bar to employment. \n     \n  OIG will request that all applicants considered for an interview provide responses to essay questions. Failure to respond to the request could disqualify an applicant from the interview process. \n     \n  Any employment offer is contingent upon available budgeted funds. The offered salary will be determined in accordance with budgetary limits and the requirements of HHSC Human Resources Manual. \n     \n  HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work. \n     \n  In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888\u2014894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview. \n     \n \n \n \n \n \n MOS Code: \n  No direct military equivalent.\n     \n \n \n \n \n \n Top 10 Tips for Success when Applying to Jobs at HHSC and DSHS \n \n \n \n \n \n \n HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work. \n \n \n In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.", "cleaned_desc": "The Fraud Analytics unit within the Fraud Analytics and Data Operations (FADO) Division of the Office of Inspector General (OIG) is seeking a Senior Data Scientist (Data Scientist II). The Fraud Analytics unit is responsible for performing innovative and advanced data analytics to detect fraud, waste and abuse in state health and human services programs such as Medicaid (including Managed Care), CHIP, SNAP and TANF by supporting data-driven investigations, reviews, audits, and inspections. The Senior Data Scientist will lead the Fraud Analytics unit\u2019s efforts to develop and implement algorithms, artificial intelligence/machine learning (AI/ML) models, and predictive analytics to generate insights and actionable leads to identify and respond to risks of fraud, waste, and abuse. \n     \n  The Senior Data Scientist performs advanced (senior-level) data science work to build models and tools that detect potential fraud, waste, and abuse. This position reports to the Deputy Inspector General of Fraud Analytics and works under minimal supervision, with extensive latitude for the use of initiative and independent judgment. This position works closely with Fraud Analytics team members, internal OIG units, and external entities, provides guidance to others, and may supervise the work of others. \n     \n  The Senior Data Scientist is responsible for performing advanced level programming to clean, prepare, and query large, complex health and human services related datasets and to research and develop algorithms and models that identify data trends, patterns, and anomalies. This position prepares written model documentation and methodology documents; communicates data analytics findings through data visualizations and presentations; and tests and evaluates new tools, methods, and techniques. \n     \n  This position contributes to the data science strategy for the OIG and develops, manages, and monitors data science projects. This position provides technical guidance and mentoring to team members on development and AI/ML, analytical, and statistical tools, methods, and techniques. This position also serves as a subject matter expert in health and human services program data. \n     \n  *** This position can telework 100% from locations within Texas consistent with HHS telework policies. ***\n     \n \n \n \n \n \n \n \n Essential Job Functions: \n  Attends work on a regular and predictable schedule in accordance with agency leave policy and performs duties as assigned: \n     \n  1. Researches, designs, implements, and deploys production AI/ML models and predictive analytics to identify risk and detect potential fraud, waste, and abuse in state health and human services programs, with a primary focus on Medicaid. Plans and conducts data analytics on large, complex datasets, including medical, pharmacy, and dental claims and encounter data, using Python, R, SQL, and/or SAS. Interprets and explains identified data trends, patterns, and anomalies. Develops, implements, and assesses the validity of existing and emerging AI/ML, analytical and statistical tools, methods, and techniques. Applies advanced analytical and statistical methods and techniques to known and new data sources. Identifies and implements best practices in advanced data analytics and reporting. (50%) \n     \n  2. Effectively communicates data analytics findings and related recommendations to technical and non-technical stakeholders both verbally and in writing, including written model documentation, methodology documents and detailed reporting of findings through data packages, data visualizations, and presentations. (15%) \n     \n  3. Engages in collaboration and communication across internal OIG units and with external entities, including but not limited to: OIG program area customers, the OIG executive team, contractors/vendors, and team members. (15%) \n     \n  4. Provides technical guidance and mentoring on algorithm development and AI/ML, analytical, and statistical tools, methods, and techniques. Peer reviews code and methodologies. Develops and conducts training for internal OIG units and external stakeholders.        (10%) \n     \n  5. Serves as a subject matter expert in health and human services program data. Serves as a liaison to other state agencies, licensures boards, and federal agencies regarding fraud, waste and abuse in state health and human services programs. (5%) \n     \n  6. Performs other duties necessary to achieve the mission of the Office of Inspector General. Statewide travel of about 5% may be required. (5%)\n     \n \n \n \n \n \n \n \n Knowledge Skills Abilities: \n  1. Knowledge of AI/ML (including supervised and unsupervised learning techniques), analytical, and statistical tools, methods, and techniques; of data models and querying relational databases; of data wrangling, data mining and data visualization techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data. \n     \n  2. Expert programming skill in data science/scientific computing programming languages (Python, R) in using open-source data science frameworks. Experience in using SQL to query databases. Skill in Excel and PowerPoint. \n     \n  3. Skill in cleaning, preparing, querying, and analyzing large, complex datasets to discover trends and patterns and deliver meaningful insights. Skill in automating data collection and processing. \n     \n  4. Skill in data visualization to present data analytics results and findings. \n     \n  5. Skill in critical thinking, analyzing problems, and devising effective solutions. \n     \n  6. Skill in verbal and written communication skills essential to effectively interacting with OIG customers, leadership, and team members. \n     \n  7. Ability to partner with stakeholders to translate and decompose program integrity or other agency problems into data science solutions.       \n  8. Ability to research, learn, and apply knowledge of existing and emerging data science principles, theories and techniques. \n     \n  9. Ability to compile, review, analyze, manage, and manipulate large, complex data sets. \n     \n  10. Ability to effectively communicate complex data findings and analytical methodologies, both verbally and in writing, to technical and non-technical audiences. \n     \n  11. Ability to work in teams that may cross departments and/or agencies. \n     \n  12. Ability to work independently, exercise independent judgment, prioritize tasks, and manage multiple projects/assignments/responsibilities in a fast-paced environment under time constraints. \n     \n  13. Ability to provide guidance to others and supervise the work of others. \n     \n  14. Ability to plan, organize, lead, and monitor data science projects. \n     \n \n \n \n \n \n Registration or Licensure Requirements: \n  None. \n    \n \n \n \n   \n \n Initial Selection Criteria: \n  Minimum 5 years experience using Python, R, or other data science/scientific computing programming languages/tools appropriate for large scale data preparation and analysis. Minimum 5 years experience using SQL to query databases. \n     \n  Minimum 5 years experience as a data scientist working with very large structured, unstructured, and semi-structured data. A proven track record of using supervised and unsupervised learning techniques to derive data insights through AI/ML methods and of proposing models and data-driven solutions that provide value and address agency needs. \n     \n  Experience in providing AI/ML solutions to program integrity issues in the healthcare domain preferred. \n     \n  Advanced degree (Master's or Ph.D.) in data science, business analytics, healthcare analytics, computer science, computer information systems, management information systems, mathematics, statistics, economics, or a related quantitative field required.\n     \n \n \n \n \n \n \n \n \n Additional Information: \n  A copy of college transcript will be required. \n     \n  The OIG is responsible for preventing, detecting, auditing, inspecting, reviewing, and investigating fraud, waste, and abuse in the provision of HHS in Medicaid and other HHS programs. Potential employees of OIG are subject to criminal background checks in accordance with the HHS Human Resources policy. Selected applicants must complete a national fingerprint-based criminal background check through the Texas Department of Public Safety (TDPS) and Federal Bureau of Investigations (FBI) to determine if they have criminal history record information that constitutes a bar to employment. \n     \n  OIG will request that all applicants considered for an interview provide responses to essay questions. Failure to respond to the request could disqualify an applicant from the interview process. \n     \n  Any employment offer is contingent upon available budgeted funds. The offered salary will be determined in accordance with budgetary limits and the requirements of HHSC Human Resources Manual. ", "techs": ["python", "r", "sql", "sas", "excel", "powerpoint"]}, "d17f895ad92554cf": {"terms": ["data science", "data analyst"], "salary_min": 80747.055, "salary_max": 102243.76, "title": "Lead Customer & Agent Experience Data Analyst (hybrid/remote opportunity)", "company": "Grange Insurance Company", "desc": "Summary:  This position is responsible for partnering with the key stakeholders across business units to identify opportunities for the success of digital, operational, and experience programs by generating business insights. Gathering and maintaining knowledge in a wide array of business areas, ultimately all relating back to how customers and agents interact with Grange and Integrity. Responsible for accelerating the pace of digital innovation at Grange Insurance with high-impact actionable insight generation through analytics. Providing answers to complex analytical questions using a wide array of tools and techniques. Building solutions and processes that turn disparate and sometimes messy data into interpretable, valuable, and meaningful insights. Turning data into fact-based conclusions and delivering the result to stakeholders in a way that is best suited to their needs to help drive data-driven decision-making. Partnering with the data warehouse, data science, business intelligence, dev ops, and data governance teams to inform improvements and requirements for how data is collected, stored, and accessed by analytics teams. \n  What You\u2019ll Be Doing: \n \n Lead collaboration with cross-functional partners to understand their business needs. Formulate and complete end-to-end analysis that includes data gathering, analysis, and ongoing scaled deliverables. Deliver effective presentations of findings and recommendations to multiple levels of leadership, creative visual displays of quantitative information. \n Lead gathering and synthesizing data and other relevant information to develop fact-based conclusions and make business recommendations to improve customer and agent experience delivery. Employ a logical, systematic approach to problem solving and research using analytical techniques to achieve business objectives and drive change. \n Lead strategy and execution of digital/web analytics and serve as the digital/web analytics expert for Grange. \n Partner with Data Engineering and Data Warehouse team on requirements and enhancements to existing data pipelines, data sets, and data platforms. Partner with the Business Intelligence and Marketing teams to ensure synergies and a cohesive measurement system across operational/financial analytics, marketing analytics, digital experience analytics and customer and agent experience analytics. \n Interacts with business stakeholders and cross-functional business partners. Owns specific relationships with business stakeholders and cross-functional business partners. Examples include: discussing and identifying business problems, collaboration on possible solutions, data needs, upcoming project requirements, and results. \n Evaluate best method(s) to define, measure, investigate and track customer and agent experience performance and success measures. Iteratively prototype, build, and automate reports and share with stakeholders via established routine. Establish and automate post deployment reporting and analysis based on the success metrics, provide business and product teams with insights for post deployment performance. \n Identify improvement opportunities, form hypothesis proposals, design and implement tests to drive strategy enhancement and optimization. Customer/agent data and analytics efforts align with and support team/business objectives and strategy. \n Define, monitor and implement a customer & agent experience analytics strategy and associated data analysis. Ensure alignment of success measures with product and service delivery strategy. \n Develop and maintain processes for extracting, cleaning, and organizing data for analysis including implementing a moderate amount of code (Python, R, SQL, some limited JavaScript) to enable completion of repetitive and complicated tasks and handle large amounts of data. Examples include data pulls from multiple sources, complex data cleaning, SQL data pulls, Google Tag Manager, predictive models (machine learning), expanded use of APIs (Google APIs, Snowflake), and process automation. \n Support enterprise data governance/stewardship activities. \n Determine and conduct appropriate exploratory data analysis techniques on candidate data sets. Use appropriate sampling techniques and thoroughly document assumptions, methodology, validation and testing. \n Apply traditional and innovative analytical and modeling approaches to draw conclusions and make recommendations on business tactics and strategies. \n Explore data using a variety of advanced statistical techniques to answer business questions or shape future model development. Understand and leverage segmentation such as Lifetime Value, Behavioral analysis and Model behavior. \n Continuously learn the application of role-specific tools and techniques to solving analytical problems. Identify, leverage and develop expertise in emerging technologies and open source tools. Harness new mathematical techniques. \n Guide, train, and mentor other analysts in data, applications, methods, and presentation. \n \n What You\u2019ll Bring To The Company: \n \n BA/BS degree in Business, Finance, Economics, Technology or other relevant discipline, Master\u2019s Degree a plus. \n 5 years of experience in analytics related to product development, digital, mobile, user experience, customer and agent experience, or ecommerce. \n Experience with SAS, R, Python or a comparable data analysis tools \n Experience with programming, working with databases, working with operational data \n 3 - 5 years of experience working with a variety of digital technology, reflected in a thorough understanding of the digital space. \n Proven skills in data management and data extraction working with large data sets preferred. \n Must have an aptitude for critical thinking and problem resolution \n Enthusiastic and creative leader with the ability to inspire others. \n High level of competency collaborating, inspiring and leading others across all levels of the organization. \n Strong empathy for customers and passion for revenue and growth. \n Strategic and innovative thinker. \n Process-oriented mindset. \n Pro-active and results orientated. \n Candidate must have strong attention to detail. \n Ability to \u201chit the ground running\u201d \n Expertise with analytics tools (i.e. Google Analytics, Sitecore Experience Analytics, Power BI / Tableau / Microstrategy or similar, Python and/or R, Excel) \n Experience of analyzing complex data and large data volumes. \n Comprehensive understanding of customer insights, technical capabilities, and experience design principles to translate business, channel and marketing objectives into integrated digital strategies. \n Excellent organizational, verbal, presentation/facilitation and written communication skills. \n Advanced knowledge of statistics and models. \n \n \n \n  About Us: \n  Grange Insurance Company, with $3.1 billion in assets and more than $1 billion in annual revenue, is an insurance provider founded in 1935 and based in Columbus, Ohio. Through its network of independent agents, Grange offers auto, home and business insurance protection. Grange Insurance Company and its affiliates serve policyholders in Georgia, Illinois, Indiana, Iowa, Kentucky, Michigan, Minnesota, Ohio, Pennsylvania, South Carolina, Tennessee, Virginia and Wisconsin- the 13-state Grange Enterprise holds an A.M. Best rating of \"A\" (Excellent). \n  Who We Are: \n  We are committed to an inclusive work environment where we welcome and value diversity and inclusion. We hire great talent from a wide variety of backgrounds, and our associates are our biggest strength. The diversity of our associates, their backgrounds, experiences, and individual differences are the foundation for our success. Our inclusive culture empowers all of us to \u201cBe One Team\u201d, \u201cDeliver Excellence\u201d, \u201cCommunicate Openly\u201d, \u201cDo the Right Thing\u201d, and \u201cSolve Creatively for Tomorrow\u201d. We have active Associate Resource Groups and a Diversity and Inclusion Team, that focuses on professional development, networking, business value and community outreach; all which encourage and facilitate an environment that fosters learning, innovation, and growth. Together we use our individual experiences to learn from one another and grow as professionals and as humans. \n  We welcome the unique contributions that you bring from education, opinions, culture, beliefs, race, color, religion, age, sex, national origin, handicap, disability, sexual orientation, gender stereotyping, gender identity or expression, genetic information, ancestry, pregnancy, veteran status, and citizenship. \n  Grange Enterprise is proud to be part of the CEO Action for Diversity and Inclusion\u2122, a national initiative of more than 1400 CEOs working for the advancement of diversity and inclusion within the workplace.", "cleaned_desc": "Summary:  This position is responsible for partnering with the key stakeholders across business units to identify opportunities for the success of digital, operational, and experience programs by generating business insights. Gathering and maintaining knowledge in a wide array of business areas, ultimately all relating back to how customers and agents interact with Grange and Integrity. Responsible for accelerating the pace of digital innovation at Grange Insurance with high-impact actionable insight generation through analytics. Providing answers to complex analytical questions using a wide array of tools and techniques. Building solutions and processes that turn disparate and sometimes messy data into interpretable, valuable, and meaningful insights. Turning data into fact-based conclusions and delivering the result to stakeholders in a way that is best suited to their needs to help drive data-driven decision-making. Partnering with the data warehouse, data science, business intelligence, dev ops, and data governance teams to inform improvements and requirements for how data is collected, stored, and accessed by analytics teams. \n  What You\u2019ll Be Doing: \n \n Lead collaboration with cross-functional partners to understand their business needs. Formulate and complete end-to-end analysis that includes data gathering, analysis, and ongoing scaled deliverables. Deliver effective presentations of findings and recommendations to multiple levels of leadership, creative visual displays of quantitative information. \n Lead gathering and synthesizing data and other relevant information to develop fact-based conclusions and make business recommendations to improve customer and agent experience delivery. Employ a logical, systematic approach to problem solving and research using analytical techniques to achieve business objectives and drive change. \n Lead strategy and execution of digital/web analytics and serve as the digital/web analytics expert for Grange. \n Partner with Data Engineering and Data Warehouse team on requirements and enhancements to existing data pipelines, data sets, and data platforms. Partner with the Business Intelligence and Marketing teams to ensure synergies and a cohesive measurement system across operational/financial analytics, marketing analytics, digital experience analytics and customer and agent experience analytics. \n Interacts with business stakeholders and cross-functional business partners. Owns specific relationships with business stakeholders and cross-functional business partners. Examples include: discussing and identifying business problems, collaboration on possible solutions, data needs, upcoming project requirements, and results. \n Evaluate best method(s) to define, measure, investigate and track customer and agent experience performance and success measures. Iteratively prototype, build, and automate reports and share with stakeholders via established routine. Establish and automate post deployment reporting and analysis based on the success metrics, provide business and product teams with insights for post deployment performance.   Identify improvement opportunities, form hypothesis proposals, design and implement tests to drive strategy enhancement and optimization. Customer/agent data and analytics efforts align with and support team/business objectives and strategy. \n Define, monitor and implement a customer & agent experience analytics strategy and associated data analysis. Ensure alignment of success measures with product and service delivery strategy. \n Develop and maintain processes for extracting, cleaning, and organizing data for analysis including implementing a moderate amount of code (Python, R, SQL, some limited JavaScript) to enable completion of repetitive and complicated tasks and handle large amounts of data. Examples include data pulls from multiple sources, complex data cleaning, SQL data pulls, Google Tag Manager, predictive models (machine learning), expanded use of APIs (Google APIs, Snowflake), and process automation. \n Support enterprise data governance/stewardship activities. \n Determine and conduct appropriate exploratory data analysis techniques on candidate data sets. Use appropriate sampling techniques and thoroughly document assumptions, methodology, validation and testing. \n Apply traditional and innovative analytical and modeling approaches to draw conclusions and make recommendations on business tactics and strategies. \n Explore data using a variety of advanced statistical techniques to answer business questions or shape future model development. Understand and leverage segmentation such as Lifetime Value, Behavioral analysis and Model behavior. \n Continuously learn the application of role-specific tools and techniques to solving analytical problems. Identify, leverage and develop expertise in emerging technologies and open source tools. Harness new mathematical techniques. \n Guide, train, and mentor other analysts in data, applications, methods, and presentation.   \n What You\u2019ll Bring To The Company: \n \n BA/BS degree in Business, Finance, Economics, Technology or other relevant discipline, Master\u2019s Degree a plus. \n 5 years of experience in analytics related to product development, digital, mobile, user experience, customer and agent experience, or ecommerce. \n Experience with SAS, R, Python or a comparable data analysis tools \n Experience with programming, working with databases, working with operational data \n 3 - 5 years of experience working with a variety of digital technology, reflected in a thorough understanding of the digital space. \n Proven skills in data management and data extraction working with large data sets preferred.   Expertise with analytics tools (i.e. Google Analytics, Sitecore Experience Analytics, Power BI / Tableau / Microstrategy or similar, Python and/or R, Excel) \n Experience of analyzing complex data and large data volumes. \n Comprehensive understanding of customer insights, technical capabilities, and experience design principles to translate business, channel and marketing objectives into integrated digital strategies. \n Excellent organizational, verbal, presentation/facilitation and written communication skills. \n Advanced knowledge of statistics and models. \n \n \n \n  About Us: ", "techs": ["grange", "integrity", "data gathering", "data analysis", "analytics", "data visualization", "data warehouse", "data science", "business intelligence", "dev ops", "data governance", "digital analytics", "web analytics", "data engineering", "data pipelines", "data sets", "data platforms", "customer experience analytics", "agent experience analytics", "code (python", "r", "sql", "javascript)", "google tag manager", "predictive models", "machine learning", "apis (google apis", "snowflake)", "data cleaning", "exploratory data analysis", "statistical techniques", "segmentation analysis", "emerging technologies", "open-source tools", "sas", "operational data", "digital technology", "data management", "data extraction", "google analytics", "sitecore experience analytics", "power bi", "tableau", "microstrategy", "excel"]}, "b0b2f07e069265ca": {"terms": ["data science"], "salary_min": 99700.0, "salary_max": 137100.0, "title": "Data Scientist I", "company": "Bio-Rad Laboratories, Inc.", "desc": "In this role as a  Data Scientist,  you will be expected to create business insights from the available data. We are looking for a team member who has sound business understanding, data handling, programming and data visualization skills to formulate the questions that will help the business identify and overcome operational challenges using KPI\u2019s. You should be confident in your ability to structure the data in a useful manner, mine it, make relevant assumptions, build correlation models, prove causality, and search the data for signs of anything that can deliver a positive business impact. \n \n  How You'll Make An Impact: \n \n  Participate in identifying, experimenting and testing of new ways to deliver value from combinations of operational data, customer data and third-party data sources. \n Transform and blend datasets both structured and unstructured into business insights. \n Perform descriptive, exploratory and inferential statistical analysis as well as supervised and unsupervised machine learning. \n Stay on the cutting edge of technology and Data Science. \n Work with the application teams to source data, transform the data for analysis and compute usable insights from data.  \n Ability to create statistical models and data system programming as required. \n Understanding of structured SQL and / or other BI tools/packages.  \n Establish key performance indicators and analyze metrics to identify root causes behind shifts in performance.  \n Conduct extensive analysis on partner performance trends and provide insight into growth opportunities; synthesizing diverse, complex information to develop a story with data and insights. \n Monitor performance of business goals and communicate status through visual analytics.  \n Proactively identify new analytic techniques to develop differentiated analytic solutions to drive results. \n Establish and maintain relationships with key client decision makers.  \n Write queries and perform other duties as assigned.  \n Understand partner business objectives and provide actionable analytic insights on one or more of the following topics: schedule adherence, financial trending, marketing analysis, instrument performance, and/or marketing analysis patterns. \n Analyze sales trends, performs market assessments, and prepares ad hoc data analyses as needed. \n \n \n  What You Bring: \n \n  Bachelor\u2019s Degree in statistics, computer science or mathematics with at least 3+ years experience or strong work portfolio in Machine Learning, hypothesis testing, and data analysis. \n Master's Degree in statistics, computer science or mathematics or similar quantitative field with 0-2 years experience; PhD is a plus. \n Fluency in 1 or more of the following languages: R, Python, SQL, DAX, Java, C, C++, Go, Scala, Bash  \n Experience with Power BI, Tableau or a comparable data visualization tool. \n Solid understanding of the mathematical and theoretical foundations of statistical analysis and machine learning. \n Experience with time-based analysis, forecasting, and/or natural language processing.  \n Strong written and verbal communications skills \u00b7 Working knowledge of at least one of the following: Snowflake, Amazon Web Services, Microsoft Azure, Google Cloud Platform. \n Version Control with Git. \n Working knowledge of big data platforms including Hadoop, Hive, Spark. \n \n \n  Location:  Irvine, CA; Bio-Rad is pleased to offer the flexibility of Hybrid Work for this role. \n \n  Total Rewards Package:  At Bio-Rad, we\u2019re empowered by our purpose and recognize that our employees are as well. That\u2019s why we offer a competitive and comprehensive Total Rewards Program that provides value, quality, and inclusivity while satisfying the diverse needs of our evolving workforce. Bio-Rad's robust offerings serve to enrich the overall health, wealth, and wellbeing of our employees and their families through the various stages of an employee\u2019s work and life cycle. \n \n  Benefits:  We\u2019re proud to offer a variety of options, including competitive medical plans for you and your family, free HSA funds, a new fertility offering with stipend, group life and disability, paid parental leave, 401k plus profit sharing, an employee stock purchase program, a new upgraded and streamlined mental health platform, extensive learning and development opportunities, education benefits, student debt relief program, pet insurance, wellness challenges and support, paid time off, Employee Resource Groups (ERG\u2019s), and more! \n   \n Compensation:  The estimated base salary range for this position is $99,700 to $137,100 at the time of posting. Actual compensation will be provided in writing at the time of offer, if applicable, and is based on several factors we believe fairly and accurately impact compensation, including geographic location, experience, knowledge, skills, abilities, and other job permitted factors. This position is eligible for a variable annual bonus, which is dependent upon achievement of your individual objectives and Company performance. \n \n  Who We Are:  For 70 years, Bio-Rad has focused on advancing the discovery process and transforming the fields of science and healthcare. As one of the top five life science companies, we are a global leader in developing, manufacturing, and marketing a broad range of high-quality research and clinical diagnostic products. We help people everywhere live longer, healthier lives. Recently voted a Best Place to Work, Bio-Rad offers a unique employee experience with collaborative teams that span the globe. Here, you are supported by leadership to build your career and are empowered to drive change that makes an impact you can see. \n \n  EEO Statement:  Bio-Rad is an Equal Employment Opportunity/Affirmative Action employer, and we welcome candidates of all backgrounds. Veterans, people with physical or mental disabilities, and people of all race, color, sex, sexual orientation, gender identity, religion, national origin and citizenship status are encouraged to apply. \n \n  Agency Non-Solicitation:  Bio-Rad does not accept agency resumes, unless the agency has been authorized by a Bio-Rad Recruiting Representative. Please do not submit resumes unless authorized to do so. Bio-Rad will not pay for any fees related to unsolicited resumes. \n  #LI-TWAZ", "cleaned_desc": "In this role as a  Data Scientist,  you will be expected to create business insights from the available data. We are looking for a team member who has sound business understanding, data handling, programming and data visualization skills to formulate the questions that will help the business identify and overcome operational challenges using KPI\u2019s. You should be confident in your ability to structure the data in a useful manner, mine it, make relevant assumptions, build correlation models, prove causality, and search the data for signs of anything that can deliver a positive business impact. \n \n  How You'll Make An Impact: \n \n  Participate in identifying, experimenting and testing of new ways to deliver value from combinations of operational data, customer data and third-party data sources. \n Transform and blend datasets both structured and unstructured into business insights. \n Perform descriptive, exploratory and inferential statistical analysis as well as supervised and unsupervised machine learning. \n Stay on the cutting edge of technology and Data Science. \n Work with the application teams to source data, transform the data for analysis and compute usable insights from data.    Analyze sales trends, performs market assessments, and prepares ad hoc data analyses as needed. \n \n \n  What You Bring: \n \n  Bachelor\u2019s Degree in statistics, computer science or mathematics with at least 3+ years experience or strong work portfolio in Machine Learning, hypothesis testing, and data analysis. \n Master's Degree in statistics, computer science or mathematics or similar quantitative field with 0-2 years experience; PhD is a plus. \n Fluency in 1 or more of the following languages: R, Python, SQL, DAX, Java, C, C++, Go, Scala, Bash  \n Experience with Power BI, Tableau or a comparable data visualization tool.   Solid understanding of the mathematical and theoretical foundations of statistical analysis and machine learning. \n Experience with time-based analysis, forecasting, and/or natural language processing.  \n Strong written and verbal communications skills \u00b7 Working knowledge of at least one of the following: Snowflake, Amazon Web Services, Microsoft Azure, Google Cloud Platform. \n Version Control with Git. \n Working knowledge of big data platforms including Hadoop, Hive, Spark. \n \n \n  Location:  Irvine, CA; Bio-Rad is pleased to offer the flexibility of Hybrid Work for this role. \n ", "techs": ["python", "sql", "java", "power bi", "tableau", "r", "dax", "c", "c++", "go", "scala", "bash", "snowflake", "amazon web services", "microsoft azure", "google cloud platform", "git", "hadoop", "hive", "spark"]}, "e44821998d73e664": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "AI Algorithm Engineer (f/m/d)", "company": "INTEL", "desc": "Job Description \n  Are you passionate about transforming the world of realtime 3D rendering with AI? If so, we have an exciting opportunity for you. \n  Join Intel XeSS Research and Development team and be at the forefront of revolutionizing real-time 3D rendering with AI algorithms and neural rendering techniques. As a part of our team, you'll delve deep into research, design, and development of ground-breaking deep learning and machine learning algorithms. You'll create innovative AI models specifically tailored for 3D rendering in gaming. \n  Qualifications \n  Required skills: \n \n \n  BS, MS, or PhD in fields such as Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, or other related fields. \n  5+ years of Deep Learning and AI algorithm research and development experience. Solid math, problem solving and algorithm design skills. \n  Strong knowledge of Deep Learning network architectures, frameworks such as TensorFlow and PyTorch, solid knowledge in broad range of state-of-the-art AI algorithms and principles. Proven ability to create new AI model architectures, extend AI frameworks with advanced features, design complex domain-specific loss functions with optimized implementation and train challenging AI algorithms. Expertise in optimization techniques for neural networks are required to deliver realtime, lightweight and capable AI models. \n  Experience with realtime 3D rendering, image processing and/or computer vision domains \n  Hands-on experience in designing and fine-tuning domain-specific AI training and testing datasets in multidimensional image/media processing and/or 3D rendering domains. \n  Advanced Python and GPU programming skills (CUDA, OpenCL, DPC++) \n  Solid written and spoken English skills are necessary to facilitate effective communication within our diverse, global team. \n  Expertise in state-of-the-art techniques in real-time rendering, optimization techniques such as temporal antialiasing, supersampling, superresolution and ray tracing denoising is essential to help us push the boundaries of what's possible in 3D rendering. \n  Solid understanding of modern GPU HW architectures, with skills to heavily optimize AI algorithms and GPU kernels leveraging HW specifics. \n \n \n  Inside this Business Group \n  The Client Computing Group (CCG) is responsible for driving business strategy and product development for Intel's PC products and platforms, spanning form factors such as notebooks, desktops, 2 in 1s, all in ones. Working with our partners across the industry, we intend to continue to advance PC experiences to deliver the real-world performance people demand. As the largest business unit at Intel, CCG is investing more heavily in the PC, ramping its capabilities even more aggressively, and designing the PC experience even more deliberately, including delivering a predictable cadence of leadership products. As a result, we are able to fuel innovation across Intel, providing an important source of IP and scale, as well as help the company deliver on its purpose of enriching the lives of every person on earth.\n  \n  Posting Statement \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n  \n  Benefits \n  We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html\n  \n  Working Model \n  This role is available as a fully home-based and generally would require you to attend Intel sites only occasionally based on business need. This role may also be available as our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. \n  In certain circumstances the work model may change to accommodate business needs. \n  JobType  \n Fully Remote", "cleaned_desc": " \n  BS, MS, or PhD in fields such as Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, or other related fields. \n  5+ years of Deep Learning and AI algorithm research and development experience. Solid math, problem solving and algorithm design skills. \n  Strong knowledge of Deep Learning network architectures, frameworks such as TensorFlow and PyTorch, solid knowledge in broad range of state-of-the-art AI algorithms and principles. Proven ability to create new AI model architectures, extend AI frameworks with advanced features, design complex domain-specific loss functions with optimized implementation and train challenging AI algorithms. Expertise in optimization techniques for neural networks are required to deliver realtime, lightweight and capable AI models. \n  Experience with realtime 3D rendering, image processing and/or computer vision domains \n  Hands-on experience in designing and fine-tuning domain-specific AI training and testing datasets in multidimensional image/media processing and/or 3D rendering domains. ", "techs": ["tensorflow", "pytorch"]}, "acbdb430a3aa6368": {"terms": ["data science", "mlops"], "salary_min": 126304.35, "salary_max": 159929.45, "title": "Very Senior Data Scientist AI/LLM", "company": "chenoa inc", "desc": "Remote only Shift/Schedule - Full time (40 hour per week) Are you willing to look at candidates above the max bill rate? If have proven AI/LLM MLOPS experience - yes Top three skill sets: Proven AI/LLM experience (development. Tuning, maintenance)m Prompt engineering, MLOPS \n We are looking for a Data Scientist to join Vertex Emerging Technology Group to be part of our AI and data insight journey. Additionally, this person will help drive the technological exploration of AI related technologies/solutions to address current and future business opportunities. This person must have strong experience with prompt engineering, using a variety of data mining/ analysis methods, using a variety of data tools, building, and implementing models, using/creating algorithms, and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. \n ESSENTIAL JOB FUNCTIONS AND RESPONSIBILITIES: \n \n Interact and expand capacities of LLMs. \n Develop custom data models and algorithms to apply to data sets. \n Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions. \n Mine and analyze company and external datasets to drive predictions and actions. \n Assess the effectiveness and accuracy of new data sources and execute data wrangling techniques. \n Develop processes and tools to monitor and analyze model performance and data accuracy. \n \n SUPERVISORY RESPONSIBILITIES: \n \n No expectations of supervisory responsibility to begin with; however, this role will have multiple leadership opportunities over time \u2013 as such, candidates must be able to mentor and teach. \n \n KNOWLEDGE, SKILLS AND ABILITIES: \n \n Self-motivated / Creative / Innovative \n Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets. \n Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. \n Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. \n A drive to learn and master new technologies and techniques \n Strong understanding of AI/Client cloud services and infrastructure, including how to leverage them and experience with SaaS infrastructure technologies (AWS/Azure preferred) \n Ability to quickly assimilate, organize, analyze, abstract, and synthesize large amounts of information and to make decisions based on this analysis \n Excellent written and verbal communication skills \n Ability to present and explain technical concepts to non-technical audiences \n Comfortable working in a dynamically and changing environment. \n Comfortable working with loosely defined requirements where you exercise your creativity and analytical skills to deliver best in class solutions \n \n Job Type: Contract \n Salary: $80,818.99 - $100,966.76 per hour \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n AI AND LLM: 5 years (Required) \n Data Scientist: 10 years (Required) \n \n Work Location: Remote", "cleaned_desc": " \n Self-motivated / Creative / Innovative \n Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets. \n Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks. \n Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications. \n A drive to learn and master new technologies and techniques \n Strong understanding of AI/Client cloud services and infrastructure, including how to leverage them and experience with SaaS infrastructure technologies (AWS/Azure preferred) \n Ability to quickly assimilate, organize, analyze, abstract, and synthesize large amounts of information and to make decisions based on this analysis ", "techs": ["r", "python", "sql", "clustering", "decision tree learning", "artificial neural networks", "regression", "statistical tests", "aws", "azure"]}, "f8f9b36ef710ed17": {"terms": ["data science"], "salary_min": 80576.16, "salary_max": 102027.375, "title": "Inventory Management Data Scientist", "company": "Clark Associates", "desc": "Clark Associates, a distinguished leader in the foodservice equipment and supplies industry, is seeking a dedicated and visionary individual to join our Augmented Inventory Management (AIM) team. As the foremost and rapidly expanding foodservice equipment and supplies dealer in the USA, we leverage a network of over 20 strategically positioned national distribution centers to promptly deliver an extensive catalog of 70,000+ products to our valued customers within an efficient 1-2 business day timeframe. \n  Role Overview:  As a member of our Augmented Inventory Management team, you will play a pivotal role in shaping the future of inventory management within our dynamic organization. This team, composed of highly analytical professionals, is at the forefront of employing cutting-edge techniques to streamline decision-making processes, enhance accuracy, and achieve remarkable scalability through the integration of machine learning technologies. \n  Responsibilities: \n \n  Model Development: Create advanced statistical and machine learning models that optimize inventory management processes, fostering efficient allocation and utilization of resources. \n  Collaboration: Interface with stakeholders in procurement and operations to devise systematic solutions for intricate inventory management challenges. \n  Continuous Enhancement: Research and implement enhancements to existing models, keeping abreast of emerging methodologies in the field. \n  Actionable Insights: Extract meaningful insights from data and formulate actionable recommendations that tangibly bolster the company's financial performance. \n  Solution Validation: Implement robust monitoring mechanisms to validate the efficacy of deployed solutions. \n \n \n  Minimum Qualifications: \n \n  Experience: Over 3 years of practical experience using SQL and statistical/machine learning programming (Python preferred, R and Matlab accepted). \n  Education: Bachelor's degree in data science, statistics, or a closely related quantitative field; alternatively, over 4 years of experience with a data, research, or applied science team. \n  Adaptability: Demonstrated ability to swiftly acclimate to evolving environments, rapidly learn new skills, and apply them to intricate problem-solving scenarios. \n \n \n  Preferred Qualifications: \n \n  Supply Chain Expertise: Familiarity with supply chain and warehouse stock optimization practices. \n  Forecasting Acumen: Exposure to time series forecasting models. \n  Reporting Proficiency: Experience with reporting tools like Power BI and Excel for sharing results. \n  Communication: Exceptional written and verbal communication skills with the ability to translate technical processes for non-technical audiences. \n  Advanced Education: Master's degree in data science, statistics, operations research, or a closely related highly quantitative field \n \n \n  Remote work qualifications \n \n  Access to a reliable and secure high-speed internet connection. Cable or fiber internet connections (at least 75mbps download/10mbps upload) are preferred, as satellite connections often cannot support the technologies used to perform day-to-day tasks. \n  Access to a home router and modem. \n  A dedicated home office space that is noise- and distraction-free. The space should have strong wireless connection or a wired Ethernet connection (wired connection is preferred, if possible). \n  A valid, physical address (apartment, suite, etc.). PO Boxes are not supported, as a physical address is required for you to receive your computer equipment. \n  The desire and ability to work and communicate with other team members via chat, webcam, etc. \n  Legal residents of one of the following states: (). H-1B Visa Sponsorship Not Available, W2 only.", "cleaned_desc": " \n  Experience: Over 3 years of practical experience using SQL and statistical/machine learning programming (Python preferred, R and Matlab accepted). \n  Education: Bachelor's degree in data science, statistics, or a closely related quantitative field; alternatively, over 4 years of experience with a data, research, or applied science team. \n  Adaptability: Demonstrated ability to swiftly acclimate to evolving environments, rapidly learn new skills, and apply them to intricate problem-solving scenarios. \n \n    Preferred Qualifications: \n \n  Supply Chain Expertise: Familiarity with supply chain and warehouse stock optimization practices. \n  Forecasting Acumen: Exposure to time series forecasting models. \n  Reporting Proficiency: Experience with reporting tools like Power BI and Excel for sharing results. \n  Communication: Exceptional written and verbal communication skills with the ability to translate technical processes for non-technical audiences. ", "techs": ["sql", "python", "r", "matlab", "power bi", "excel"]}, "7f950bb1765d2889": {"terms": ["data science"], "salary_min": 152248.0, "salary_max": 228372.0, "title": "Principal Data Scientist", "company": "The Mom Project", "desc": "***The salary range for this position is $152,248.00 - $228,372.00 per year.*** \n The Mom Project is excited to partner with Kellanova in their search for a Principal Data Scientist . This role is 100% remote in Battle Creek, MI . \n Kellanova is a leader in global snacking, international cereal and noodles, and North America frozen foods with a legacy stretching back more than 100 years. Powered by differentiated brands including Pringles\u00ae, Cheez-It\u00ae, Pop-Tarts\u00ae, Kellogg Rice Krispies Treats\u00ae, RXBAR\u00ae, Eggo\u00ae, MorningStar Farms\u00ae, Special K\u00ae, Coco Pops\u00ae, and more, Kellanova\u2019s vision is to become the world\u2019s best-performing snacks-led powerhouse, unleashing the full potential of our differentiated brands and our passionate people. Kellanova generated an estimated $12.6 billion in net sales in 2022. \n Kellanova is guided by our purpose to create better days and a place at the table for everyone through our trusted food brands. We are advancing sustainable and equitable access to food by addressing the intersection of hunger, sustainability, well-being, and equity, diversity & inclusion, with the ambition of creating Better Days for 4 billion people by the end of 2030. Visit www.Kellanova.com for more information. \n As our Principal Data Scientist , your main mission is to use the scientific method, math and statistics, specialized programming, advanced analytics, AI, and storytelling to uncover and explain the business insights buried in data. This will be accomplished by using data mining techniques, including pattern detection, graph analysis, or statistical analysis \u2013 extracting knowledge from a dataset involving data management, data preprocessing, model, and post-processing of found structure. As our principal data scientist, you are well-versed in a wide array of analytical tools including artificial intelligence, machine learning, data mining, Bayesian regression, and econometrics, and are aware of new and emerging methodologies. With your expertise, you will communicate, educate, and elevate the skills of the organization. \n Join our dynamic, progressive team of IT professionals in an environment where you can learn, grow, and be an integral part of creating innovative technology solutions to help our business flourish. As a part of Kellanova, you are joining a leading company in global snacking, international cereal and noodles, plant-based foods, and North American frozen breakfast, with iconic, world-class brands. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, and ideas, and can bring their authentic selves to work. Become part of a team that works to better serve the needs of our diverse consumers by delivering winning ideas and innovations for brands like Cheez-Its, Pringles, and Eggo. \n \n \n A Taste of What You\u2019ll Be Doing: \n  Direct Business Partnering - In this role, you will be working with multiple levels of the business and leadership to better enable analytics and data across the supply chain organization in multiple regions. By leveraging your experience, leadership skills, positive attitude as well as your understanding of cross-functional relationships you will help deliver practical analytical and data solutions within a global environment. Lead the design, development, and deployment of data-driven predictive models to solve business problems using the most appropriate techniques in data mining, artificial intelligence/machine learning, and statistical modeling. \n Data Analysis Leadership - Diving into large, noisy, and complex real-world data to produce an innovative analysis of historical patterns in customer behaviors and product performance. Working closely with data warehouse architects and software developers to generate seamless business intelligence solutions for business partners. Piloting emerging \u201cbig data\u201d technologies to help Kellanova understand how to exploit new methodologies, technologies, and tools. Driving toward deep visibility of the business, end-to-end through analytics and fact-based data disciplines. Advocating for and training the organization during the deployment of analytic solutions. Establishing relationships with various data stakeholders and working with leadership to develop strategies for advanced analytics at Kellanova. In this role, you will be advising Executives on how data and predictive models (processes, practices, and technologies) play a critical role in improving business management and optimization. \n Decision Support \u2013 Understanding and identifying what data is available and relevant, including internal and external data sources, leveraging new data collection processes. Working with supply chain subject matter experts to select the relevant sources of information. Evaluating the data sources on multiple criteria including cost. Working with, and advising, appropriate IT members to translate analytic prototypes into production. This role has one or more direct reports. \n \n \n Your Recipe for Success: \n  Masters Degree or Ph.D. in Computer Science, Mathematics, Statistics, Actuarial Science, Engineering, Operations Research or related field and/or specialized training/certification and/or equivalent work experience \n We are looking for a leader with significant experience leading direct reports \n Do you have extensive related technical/business experience including experience in designing and developing data management processes and systems? This role is perfect for you! \n Do you have demonstrated experience and advanced skills in data analysis, modeling, data mining, and artificial intelligence/machine learning? Great, we\u2019d love to put them to good use! \n Like working with technology? We need strong experience with analytical software and technology (such as Python, R, SAS, Databricks, Sagemaker, Tableau, etc.) \n Strong ability to communicate with Supply Chain Executives to translate complex ideas and technical subjects into digestible messages with the proven ability to influence a variety of business partners \n Effectively lead and collaborate with people within a project team \n Do you have relevant Supply Chain, Manufacturing, or CPG (Consumer Package Goods) experience? Great, we\u2019d love to put it to good use in IT \n What\u2019s Next \n After you apply, your application will be reviewed by a real recruiter \u2013 not a bot. This means it could take us a little while to get back with you so watch your inbox for updates. In the meantime, visit our How We Hire page to get insights into our hiring process and how to best prepare for a Kellanova interview. \n If we can help you with reasonable accommodation throughout the application or hiring process, please email USA.Recruitment@Kellanova.com. \n About Kellanova \n Kellanova is a leading company in global snacking, international cereal and noodles, plant-based foods, and North America frozen breakfast, and a portfolio of iconic, world-class brands, including Pringles, Cheez-It, Pop-Tarts, Kellogg\u2019s Rice Krispies Treats, MorningStar Farms, Incogmeato, Gardenburger, Nutri-Grain, RXBAR, and Eggo. We also steward a suite of beloved international cereal brands, including Kellogg\u2019s, Frosties, Zucaritas, Special K, Krave, Miel Pops, Coco Pops, and Crunchy Nut, among others. \n At Kellanova, we are committed to Equity, Diversity, and Inclusion (ED&I), uplifting each other and embracing our differences to achieve our common goals. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, and ideas, and can bring their authentic selves to work. Learn more here. \n We\u2019re proud to offer industry competitive Total Health benefits (Physical, Financial, Emotional, and Social) that vary depending on region and type of role. Be sure to ask your recruiter for more information!", "cleaned_desc": " Data Analysis Leadership - Diving into large, noisy, and complex real-world data to produce an innovative analysis of historical patterns in customer behaviors and product performance. Working closely with data warehouse architects and software developers to generate seamless business intelligence solutions for business partners. Piloting emerging \u201cbig data\u201d technologies to help Kellanova understand how to exploit new methodologies, technologies, and tools. Driving toward deep visibility of the business, end-to-end through analytics and fact-based data disciplines. Advocating for and training the organization during the deployment of analytic solutions. Establishing relationships with various data stakeholders and working with leadership to develop strategies for advanced analytics at Kellanova. In this role, you will be advising Executives on how data and predictive models (processes, practices, and technologies) play a critical role in improving business management and optimization. \n Decision Support \u2013 Understanding and identifying what data is available and relevant, including internal and external data sources, leveraging new data collection processes. Working with supply chain subject matter experts to select the relevant sources of information. Evaluating the data sources on multiple criteria including cost. Working with, and advising, appropriate IT members to translate analytic prototypes into production. This role has one or more direct reports. \n \n \n Your Recipe for Success:    Masters Degree or Ph.D. in Computer Science, Mathematics, Statistics, Actuarial Science, Engineering, Operations Research or related field and/or specialized training/certification and/or equivalent work experience \n We are looking for a leader with significant experience leading direct reports \n Do you have extensive related technical/business experience including experience in designing and developing data management processes and systems? This role is perfect for you! \n Do you have demonstrated experience and advanced skills in data analysis, modeling, data mining, and artificial intelligence/machine learning? Great, we\u2019d love to put them to good use! \n Like working with technology? We need strong experience with analytical software and technology (such as Python, R, SAS, Databricks, Sagemaker, Tableau, etc.) ", "techs": ["data analysis", "business intelligence", "big data", "analytics", "predictive models", "decision support", "data collection", "supply chain", "data management", "data analysis", "data mining", "artificial intelligence", "machine learning", "python", "r", "sas", "databricks", "sagemaker", "tableau"]}, "351ba4be1cf70871": {"terms": ["data science"], "salary_min": 95751.086, "salary_max": 121242.21, "title": "Associate Director - Quality Data and Analytics (Remote)", "company": "BD Philippines", "desc": "Be part of something bigger at BD.  Here, you\u2019ll help us continually improve how we do things every day; to be more efficient, more effective and better serve our customers. You\u2019ll do this within an exceptional team all striving to make sure that everything we do complies with regulations and standards, not just because it\u2019s the right thing to do, but because our products impact people\u2019s quality of life. Here, you\u2019ll put your compliance experience, high expectations and attention to detail to the very best use: advancing the world of health\u2122. At BD, you can make a true difference of one. \n \n \n \n \n Job Type:  \n  Full-Time\n      \n \n \n \n \n Job Level:  \n  Entry to Senior\n      \n \n \n \n \n Travel:  \n  Varies\n      \n \n \n \n \n Salary:  \n  Competitive\n      \n \n \n \n \n \n \n RESPONSIBILITIES \n \n Job Description Summary  The Assoc. Director \u2013 Quality Data and Analytics will lead the implementation and management of a data governance strategy, transforming raw data into actionable insights, enabling the organization to make informed decisions, optimize performance and deliver on the BD Data Governance strategy by identifying opportunities and defining tactics to execute and deliver on the strategy. This position reports directly to the Senior Director of Digital Quality and Analytics.\n    \n  As a member of the BD Quality Management group, this role is responsible for leading a dedicated team of data analysts and scientists who work with internal stakeholders to deliver outcomes that support BD\u2019s Global Data Governance objective of defining Quality as a business enabler. Through effective problem solving, exemplary analytical skills, outstanding organization and communication skills, and effective direct and indirect leadership, the right candidate can make a significant difference!\n    \n  Through close collaboration within and outside the Quality function, the right candidate will deliver consistently high level results supporting the Inspire Quality initiative to achieve adoption, standardization, simplification, and continuous improvement of overall Data Governance processes.\n    \n  Job Description \n  We are the makers of possible \n \n  BD is one of the largest global medical technology companies in the world. Advancing the world of health\u2122 is our Purpose, and it\u2019s no small feat. It takes the creativity and passion of all of us\u2014from design and engineering to the manufacturing and marketing of our billions of MedTech products per year\u2014to look at the impossible and find transformative solutions that turn dreams into possibilities. \n \n  We believe that the human element, across our global teams, is what allows us to continually evolve. Join us and discover an environment in which you\u2019ll be supported to learn, grow and become your best self. Become a maker of possible with us. \n \n  Job Title: Assoc. Director \u2013 Quality Data and Analytics \n \n  Location: USA NJ \u2013 Franklin Lakes \n  Remote Type: Remote/Hybrid \n  Time Type: Full Time \n  Job Type: Regular \n \n  Our people make all the difference in our success. \n \n  The Assoc. Director \u2013 Quality Data and Analytics will lead the implementation and management of a data governance strategy, redefining raw data into actionable insights, enabling the organization to make informed decisions, optimize performance and deliver on the BD Data Governance strategy by finding opportunities and defining tactics to complete and deliver on the strategy. This position reports directly to the Senior Director of Digital Quality and Analytics. \n  As a member of the BD Quality Management group, this role is responsible for leading a dedicated team of data analysts and scientists who work with internal stakeholders to deliver outcomes that support BD\u2019s Global Data Governance objective of defining Quality as a business enabler. Through effective problem solving, exemplary analytical skills, outstanding organization and communication skills, and effective direct and indirect leadership, the right candidate can make a significant difference! \n  Through close collaboration within and outside the Quality function, the right candidate will deliver consistently high level results supporting the Inspire Quality initiative to achieve adoption, standardization, simplification, and continuous improvement of overall Data Governance processes. \n \n  Main Responsibilities \n  The Assoc. Director \u2013 Quality Data and Analytics is a champion for all aspects of data management, analytics, and reporting within the BD Quality group. This role will be responsible for: \n \n  Data Strategy: Develop and complete a comprehensive and sustainable data strategy aligned with the company's goals, ensuring data quality, governance, and security. \n  Team Leadership: Lead and mentor a team of data analysts, data engineers, and data scientists, fostering a culture of innovation and continuous learning. \n  Data Architecture: Design and maintain a scalable and efficient data architecture that supports analytics and reporting needs and seamlessly integrates with other BD data architecture models. \n  Analytics and Insights: Drive data-driven decision-making by analyzing large datasets, generating insights, and communicating findings to senior leadership. \n  Data Governance: Work with the Global Data Governance Team to establish data governance policies, standards, and processes to maintain data integrity and compliance with regulations. \n  Data Integration: Be responsible for the integration of data from various sources, both internal and external, to create a unified view of the business. \n  Technology Evaluation: Stay up-to-date with emerging data and analytics technologies, recommending tools or platforms that can enhance the company's capabilities and information awareness. \n  Performance Metrics: Define and track key performance indicators (KPIs) related to data quality, analytics, and reporting. \n  Cross-functional Collaboration: Collaborate with other departments within Quality, the different business units and across the corporate enterprise to identify product and operational opportunities for data-driven improvements and efficiencies. \n  Budget Management: Assist in the management of the Digital Quality and Analytics group's budget, helping to resolve effective and efficient allocation of financial and staffing resources to achieve departmental goals. \n \n \n  Education and Experience \n \n  Bachelor's or Master's degree in Data Science, Computer Science, Business Analytics, or a related field. \n  Proven experience (5+ years) in a direct and/or matrixed leadership role in data and analytics. \n  Strong understanding of data management, analytics tools, and data visualization. \n  Ability to think strategically and drive problem-solving and innovation through data. \n  Proficiency in data-related technologies (e.g., SQL, Python, Hadoop, etc.). \n  Knowledge of Quality Excellence models (e.g., six sigma or other QE programs) a plus. \n  Experience with regulated products, e.g. medical device and/or pharmaceutical \n  Excellent organizational, written and verbal communication and presentation skills. \n  Demonstrated experience interacting with Senior Leaders and Managers globally. \n  Ability to collaboratively partner and influence global teams to achieve results \n  Effectively able to manage conflicting priorities \n \n \n  Physical Demand \n  Travel up to 10%, both domestic and international. \n \n  Benefits \n \n  Competitive salary and bonus structure \n  Comprehensive healthcare and wellness benefits \n  401(k) retirement plan \n  Professional development opportunities \n  Collaborative and innovative work environment \n \n \n  For certain roles at BD, employment is contingent upon the Company\u2019s receipt of sufficient proof that you are fully vaccinated against COVID-19. In some locations, testing for COVID-19 may be available and/or required. Consistent with BD\u2019s Workplace Accommodations Policy, requests for accommodation will be considered pursuant to applicable law. \n \n  Why Join Us? \n  A career at BD means being part of a team that values your opinions and contributions and that encourages you to bring your authentic self to work. It\u2019s also a place where we help each other be great, we do what\u2019s right, we hold each other accountable, and learn and improve every day. \n \n  To find purpose in the possibilities, we need people who can see the bigger picture, who understand the human story that underpins everything we do. We welcome people with the creativity and aim to help us reinvent the future of health. At BD, you\u2019ll discover a culture in which you can learn, grow, and thrive. And find satisfaction in doing your part to make the world a better place. \n \n  To learn more about BD visit https://bd.com/careers \n \n  Becton, Dickinson and Company is an Equal Opportunity/Affirmative Action Employer. We do not unlawfully discriminate on the basis of race, color, religion, age, sex, creed, national origin, ancestry, citizenship status, marital or domestic or civil union status, familial status, affectional or sexual orientation, gender identity or expression, genetics, disability, military eligibility or veteran status, or any other protected status. \n \n  PDN \n \n  Primary Work Location  USA NJ - Franklin Lakes\n    \n  Additional Locations \n \n  Work Shift", "cleaned_desc": "  Technology Evaluation: Stay up-to-date with emerging data and analytics technologies, recommending tools or platforms that can enhance the company's capabilities and information awareness. \n  Performance Metrics: Define and track key performance indicators (KPIs) related to data quality, analytics, and reporting. \n  Cross-functional Collaboration: Collaborate with other departments within Quality, the different business units and across the corporate enterprise to identify product and operational opportunities for data-driven improvements and efficiencies. \n  Budget Management: Assist in the management of the Digital Quality and Analytics group's budget, helping to resolve effective and efficient allocation of financial and staffing resources to achieve departmental goals. \n \n \n  Education and Experience \n \n  Bachelor's or Master's degree in Data Science, Computer Science, Business Analytics, or a related field. \n  Proven experience (5+ years) in a direct and/or matrixed leadership role in data and analytics. \n  Strong understanding of data management, analytics tools, and data visualization. \n  Ability to think strategically and drive problem-solving and innovation through data. \n  Proficiency in data-related technologies (e.g., SQL, Python, Hadoop, etc.). \n  Knowledge of Quality Excellence models (e.g., six sigma or other QE programs) a plus. \n  Experience with regulated products, e.g. medical device and/or pharmaceutical \n  Excellent organizational, written and verbal communication and presentation skills. \n  Demonstrated experience interacting with Senior Leaders and Managers globally. \n  Ability to collaboratively partner and influence global teams to achieve results \n  Effectively able to manage conflicting priorities \n \n \n  Physical Demand \n  Travel up to 10%, both domestic and international. \n ", "techs": ["sql", "python", "hadoop"]}, "9861d87455c4a6a6": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 125500.0, "salary_max": 209100.0, "title": "Senior AI Engineer - Remote", "company": "The Cigna Group", "desc": "Join our dynamic team that is transforming healthcare and improving the lives and vitality of the millions of members we serve. We leverage cutting-edge Artificial Intelligence (AI) and Machine Learning (ML) algorithms to develop solutions for automated document processing and customer service chat bots. We are looking for Senior AI Engineers with strong engineering, full stack expertise to build the best fit solutions leveraging Large Language Models (LLMs) and Generative AI capabilities. The work you do will impact millions of customers, members, and employers that rely on Cigna every day. Extreme focus on speed to market and getting Products and Services in the hands of customer and passion to transform healthcare is key to the success of this role. \n \n  Responsibilities \n \n  Architect, build, and deploy scalable software solutions using LLMs and other ML models to solve challenges in healthcare. \n  Build enterprise-grade AI solutions with focus on privacy, security, fairness. \n  Work with Product Development as a Generative Artificial Intelligence (AI) subject matter expert and architect and develop scalable, resilient, ethical AI solutions \n  Design AI outputs with nodes and nested nodes in JSON or array, HTML formats. \n  Build extensible API Integrations, low code UI/UX solutions, with extremely short cycle times, to extract information from sources, integrate with LLM, receive insights and make them available in intuitive user-friendly dashboards. \n  Develop solutions that align with responsible AI practices. \n  Envision the solution outcomes to solve for the business problem with actionable insights and design viable solutions to meet the outcomes. \n  Understand how AI is interpreting the data set and use that understanding to build prompts that lead to expected outcomes \n  Architect and develop software or infrastructure for scalable, distributed systems and with ML technologies. \n  Work with ML frameworks (Tensorflow, PyTorch) and open-source platforms like Hugging Face to deliver the best solutions. \n  Optimize existing generative AI models for improved performance, scalability, and efficiency. \n  Develop and maintain AI pipelines, including data preprocessing, feature extraction, model training, and evaluation. \n  Develop clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. \n  Contribute to the establishment of best practices and standards for generative AI development within the organization. \n \n \n  Qualifications: \n \n  Degree in Computer Science, Artificial Intelligence, or a related field. \n  5+ years of Full stack engineering expertise with languages like C#, Python and Proficiency in designing architecture, building API Integrations, configuring and deploying cloud services, setting up authentication, monitoring and logging. \n  5+ years of leading design of architecture (design patterns, reliability, and scaling) of new and existing systems experience. \n  3+ years of experience in a technical leadership role leading project teams and setting technical direction. \n  3+ years of experience working in a complex, matrixed organization involving cross-functional or cross-business projects. \n  Experience in implementing enterprise systems in production setting for AI, computer vision, natural language processing. Exposure to self-supervised learning, transfer learning, and reinforcement learning is a plus. \n  In-depth understanding of LLM, transformers, RAG techniques, etc. with a proclivity to learn and adopt latest techniques. \n  Experience with information storage/retrieval using vector databases like Weviate, Pinecone, ChromaBD, etc. \n  Strong understanding and exposure in natural language generation or Gen AI like transformers, LLM\u2019s, text embeddings. \n  Experience with designing scalable software systems for classification, text extraction/summary, data connectors for different formats(pdf, csv, doc, etc) \n  Experience with ML libraries and frameworks such as PyTorch or TensorFlow, Hugging Face, LangChain, Llama Index. \n  Programming experience in C/C++, Java, Python. \n  Strong understanding of LLMOps/MLOps (e.g., Kubeflow, MLFlow or equivalent) and familiarity with DevOps. \n  Strong knowledge of data structures, algorithms, and software engineering principles. \n  Familiarity with cloud-based platforms and services, such as AWS, GCP, or Azure. \n  Excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. \n  Strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. \n  Proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment \n \n \n  If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.\n   For this position, we anticipate offering an annual salary of 125,500 - 209,100 USD / yearly, depending on relevant factors, including experience and geographic location.\n  \n  This role is also anticipated to be eligible to participate in an annual bonus plan. \n \n  We want you to be healthy, balanced, and feel secure. That\u2019s why you\u2019ll enjoy a comprehensive range of benefits, with a focus on supporting your whole health. Starting on day one of your employment, you\u2019ll be offered several health-related benefits including medical, vision, dental, and well-being and behavioral health programs. We also offer 401(k) with company match, company paid life insurance, tuition reimbursement, a minimum of 18 days of paid time off per year and paid holidays. For more details on our employee benefits programs, visit Life at Cigna Group. \n \n  About The Cigna Group  \n Doing something meaningful starts with a simple decision, a commitment to changing lives. At The Cigna Group, we\u2019re dedicated to improving the health and vitality of those we serve. Through our divisions Cigna Healthcare and Evernorth Health Services, we are committed to enhancing the lives of our clients, customers and patients. Join us in driving growth and improving lives.\n  \n  Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws. \n \n  If you require reasonable accommodation in completing the online application process, please email:  SeeYourself@cigna.com  for support. Do not email  SeeYourself@cigna.com  for an update on your application or to provide your resume as you will not receive a response. \n \n  The Cigna Group has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.", "cleaned_desc": "  Understand how AI is interpreting the data set and use that understanding to build prompts that lead to expected outcomes \n  Architect and develop software or infrastructure for scalable, distributed systems and with ML technologies. \n  Work with ML frameworks (Tensorflow, PyTorch) and open-source platforms like Hugging Face to deliver the best solutions. \n  Optimize existing generative AI models for improved performance, scalability, and efficiency. \n  Develop and maintain AI pipelines, including data preprocessing, feature extraction, model training, and evaluation. \n  Develop clear and concise documentation, including technical specifications, user guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders. \n  Contribute to the establishment of best practices and standards for generative AI development within the organization. \n \n \n  Qualifications: \n    Degree in Computer Science, Artificial Intelligence, or a related field. \n  5+ years of Full stack engineering expertise with languages like C#, Python and Proficiency in designing architecture, building API Integrations, configuring and deploying cloud services, setting up authentication, monitoring and logging. \n  5+ years of leading design of architecture (design patterns, reliability, and scaling) of new and existing systems experience. \n  3+ years of experience in a technical leadership role leading project teams and setting technical direction. \n  3+ years of experience working in a complex, matrixed organization involving cross-functional or cross-business projects. \n  Experience in implementing enterprise systems in production setting for AI, computer vision, natural language processing. Exposure to self-supervised learning, transfer learning, and reinforcement learning is a plus. \n  In-depth understanding of LLM, transformers, RAG techniques, etc. with a proclivity to learn and adopt latest techniques. \n  Experience with information storage/retrieval using vector databases like Weviate, Pinecone, ChromaBD, etc. \n  Strong understanding and exposure in natural language generation or Gen AI like transformers, LLM\u2019s, text embeddings. \n  Experience with designing scalable software systems for classification, text extraction/summary, data connectors for different formats(pdf, csv, doc, etc) \n  Experience with ML libraries and frameworks such as PyTorch or TensorFlow, Hugging Face, LangChain, Llama Index.    Programming experience in C/C++, Java, Python. \n  Strong understanding of LLMOps/MLOps (e.g., Kubeflow, MLFlow or equivalent) and familiarity with DevOps. \n  Strong knowledge of data structures, algorithms, and software engineering principles. \n  Familiarity with cloud-based platforms and services, such as AWS, GCP, or Azure. \n  Excellent problem-solving skills, with the ability to think critically and creatively to develop innovative AI solutions. \n  Strong communication skills, with the ability to effectively convey complex technical concepts to a diverse audience. \n  Proactive mindset, with the ability to work independently and collaboratively in a fast-paced, dynamic environment \n \n \n  If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.\n   For this position, we anticipate offering an annual salary of 125,500 - 209,100 USD / yearly, depending on relevant factors, including experience and geographic location.", "techs": ["tensorflow", "pytorch", "hugging face", "llm", "transformers", "rag techniques", "weaviate", "pinecone", "chromadb", "langchain", "llama index", "c/c++", "java", "mlflow", "kubeflow", "devops", "aws", "gcp", "azure"]}, "2e7f6313bcc5c2e4": {"terms": ["data science", "data engineer"], "salary_min": 112819.664, "salary_max": 142854.83, "title": "Senior Data Engineer - Remote", "company": "Watts Water Technologies", "desc": "The Watts Water Technologies family of companies designs and manufactures valves and drains and related products that promote the comfort and safety of people and the quality, conservation and control of water used in commercial, residential, industrial, and municipal applications. Everything we design is made to keep the Earth's most precious resource safer, cleaner, and more useful for our customers.\n  \n \n \n   We are looking for a Data Engineer to join the Watts Digital team. In this role, you will have the opportunity to build a next generation data platform that serves digital solutions and other teams within Watts. You will be responsible for designing, developing, and maintaining our data architecture, ensuring the availability and reliability of data for various business functions. You will work with key stakeholders to apply data analytics, models, and techniques to assist in realizing the value of data. You will architect and implement scalable ETL pipelines that contribute to a centralized data repository leveraging data lake architecture. As a valued technical leader, you will be responsible for ensuring our technology decisions align and scale with our architectural north star. You will directly contribute to a culture of excellence in Watts Digital\u2019s growing engineering organization and be a pivotal member in enhancing our engineering standards and processes.\n  \n \n \n   You Will:\n  \n \n \n   Technical Implementation and Architecture\n  \n \n \n \n     Design, implement, and own ETL pipelines and data lakehouse architecture across Watts digital solutions\n    \n \n \n     Build large-scale batch and real-time data pipelines with data processing frameworks like Spark and Databricks\n    \n \n \n     Utilize optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources into a central Watts data repository that supports varying use-cases\n    \n \n \n     Work closely with Watts business units and engineering teams to develop a strategy for long term data platform architecture which will be efficient, reliable and scalable\n    \n \n \n     Lead and contribute to technical architecture discussions and driving technical decisions across engineering teams\n    \n \n \n     Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way\n    \n \n \n     Communicate technology decisions and outcomes to key stakeholders (e.g. sponsors, partners, product teams)\n    \n \n \n     Determine and implement a security model based on privacy requirements; addressing data quality issues, and evolving governance processes within allocated areas of ownership\n    \n \n \n     Ensure that the systems we develop and maintain result in highly scalable, feature-rich solutions that minimize support costs and deliver value to customers\n    \n \n \n     Develop and maintain solution architecture diagrams and documentation\n    \n \n \n     Advise and support the team on selection and implementation of modern technologies including languages, open-source and third-party tools to increase efficiency and improve technology and product offerings\n    \n \n \n \n   Execution, Product Delivery and Results\n  \n \n \n \n     Lead the architecture and delivery of scalable ETL pipelines and data stores\n    \n \n \n     Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts\n    \n \n \n     Enable streamlining our data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models\n    \n \n \n     Clean, prepare and optimize data at scale for ingestion and consumption\n    \n \n \n     Working closely with other Engineers, Quality Assurance, Operations, and 3rd party vendors to successfully deliver and deploy solutions to production\n    \n \n \n     Define and manage SLA for all data sets\n    \n \n \n     Identify and implement the right analytical libraries, programming languages, and frameworks for each task\n    \n \n \n     Advocate a continuous improvement mindset regarding our development process, with a focus on how we can automate regular, high-quality, releases in an agile environment\n    \n \n \n     Continuously rebalancing features, which maximize value and minimize effort to focus on the highest returning initiatives for business and customer\n    \n \n \n     Champion a culture of learning, measurement, accountability, and quality via code reviews, paired programming, and other collaboration opportunities with the team\n    \n \n \n     Collaborate with Product Owners on the backlog and providing high level effort estimation to plan feature prioritization more accurately and development\n    \n \n \n \n   BUs, Operations, IT, Information Security and Infrastructure\n  \n \n \n \n     Partner with hardware BUs to understand their needs and deliver platform-oriented solutions\n    \n \n \n     Continuing to evolve security practices and controls to meet the needs of protecting customer data\n    \n \n \n     Champion a culture of compliance as it pertains to data to meet legal, regulatory, and operational data requirements\n    \n \n \n     Partner with IT and operations in support of enterprise IT strategy\n    \n \n \n     Ensure we are building necessary observability into our systems that provide transparency across the entire data architecture stack\n    \n \n \n     Work with engineering teams and assisting Customer Success and Operations team in triaging and resolving production issues\n    \n \n \n   You Have:\n  \n \n \n \n     Bachelor\u2019s degree in computer science, information technology, engineering, or related discipline\n    \n \n \n     5+ years of experience with ETL technologies\n    \n \n \n     5+ years of experience with Databricks, specifically within Azure\n    \n \n \n     5+ years of experience with Python, Scala, .NET, Java or similar languages\n    \n \n \n     7+ years of SQL experience (No-SQL experience is a plus)\n    \n \n \n     5+ years of experience with schema design and dimensional data modeling\n    \n \n \n     Excellent product strategic thinking and communication to influence product and cross-functional teams by identifying data opportunities that drive impact\n    \n \n \n     Proven ability around managing and communicating data roadmap plans to internal stakeholders\n    \n \n \n     Experience designing, building and maintaining data processing systems\n    \n \n \n     Deep understanding of software engineering practices (e.g. Agile software development, test driven development, unit testing, code reviews, design documentation, etc.)\n    \n \n \n     An entrepreneurial spirit that is flexible, experimental, and resourceful\n    \n \n \n \n   What\u2019s In It For You:\n  \n \n People-First Culture \u2013 Enriching and caring for people is at the core of who we are; this includes our Diversity, Equity, and Inclusion (DEI) strategy, and providing our employees with meaningful career growth opportunities, a positive and safe work environment, and affirmation that they are heard, valued, and respected. \n 401K Plan \n Flexible PTO & Generous Paid Holidays \n Educational Assistance \n Variety of Medical plan options \u2013 choose the one that is right for you! \n Sustainability \u2013 One of Newsweek\u2019s Top 400 of \u201cAmerica\u2019s Most Responsible Companies\u201d for sustainability performance, three years running. \n \n \n \n   PHYSICAL REQUIREMENTS:\n  \n \n   While performing the responsibilities of this job, the employee is frequently required to walk, talk, and/or hear. The employee is occasionally required to stand, sit, and use hands to finger, handle, or feel. You must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include: close vision, color vision, peripheral vision, depth perception and ability to adjust focus.\n  \n \n \n   WORK ENVIRONMENT:\n  \n \n   Work in both office and manufacturing environment. May occasionally be required to perform job responsibilities outside the typical office setting.\n  \n \n   #LI-Remote\n  \n  Watts is committed to equal employment opportunity. We follow a policy of administering all employment decisions and personnel actions without regard to race, color, religion, creed, sex, pregnancy, national origin, sexual orientation, age, physical or mental disability, genetic disposition or carrier status, marital status, military or veteran status, minorities, or any other category protected under applicable federal, state, or local law. Consistent with the obligations of state and federal law, Watts will make reasonable accommodations for qualified individuals with disabilities. Any employee who needs a reasonable accommodation should contact Human Resources.\n  \n   #LI-Remote", "cleaned_desc": "The Watts Water Technologies family of companies designs and manufactures valves and drains and related products that promote the comfort and safety of people and the quality, conservation and control of water used in commercial, residential, industrial, and municipal applications. Everything we design is made to keep the Earth's most precious resource safer, cleaner, and more useful for our customers.\n  \n \n \n   We are looking for a Data Engineer to join the Watts Digital team. In this role, you will have the opportunity to build a next generation data platform that serves digital solutions and other teams within Watts. You will be responsible for designing, developing, and maintaining our data architecture, ensuring the availability and reliability of data for various business functions. You will work with key stakeholders to apply data analytics, models, and techniques to assist in realizing the value of data. You will architect and implement scalable ETL pipelines that contribute to a centralized data repository leveraging data lake architecture. As a valued technical leader, you will be responsible for ensuring our technology decisions align and scale with our architectural north star. You will directly contribute to a culture of excellence in Watts Digital\u2019s growing engineering organization and be a pivotal member in enhancing our engineering standards and processes.\n  \n \n \n   You Will:\n  \n \n \n   Technical Implementation and Architecture\n  \n \n \n \n     Design, implement, and own ETL pipelines and data lakehouse architecture across Watts digital solutions\n    \n \n \n     Build large-scale batch and real-time data pipelines with data processing frameworks like Spark and Databricks\n    \n \n \n     Utilize optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources into a central Watts data repository that supports varying use-cases\n    \n \n \n     Work closely with Watts business units and engineering teams to develop a strategy for long term data platform architecture which will be efficient, reliable and scalable\n    \n \n \n     Lead and contribute to technical architecture discussions and driving technical decisions across engineering teams\n    \n \n \n     Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way\n    \n \n \n     Communicate technology decisions and outcomes to key stakeholders (e.g. sponsors, partners, product teams)\n    \n   \n     Determine and implement a security model based on privacy requirements; addressing data quality issues, and evolving governance processes within allocated areas of ownership\n    \n \n \n     Ensure that the systems we develop and maintain result in highly scalable, feature-rich solutions that minimize support costs and deliver value to customers\n    \n \n \n     Develop and maintain solution architecture diagrams and documentation\n    \n \n \n     Advise and support the team on selection and implementation of modern technologies including languages, open-source and third-party tools to increase efficiency and improve technology and product offerings\n    \n \n \n \n   Execution, Product Delivery and Results\n  \n \n \n \n     Lead the architecture and delivery of scalable ETL pipelines and data stores\n    \n \n \n     Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts\n    \n \n \n     Enable streamlining our data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models\n    \n \n \n     Clean, prepare and optimize data at scale for ingestion and consumption\n    \n \n \n     Working closely with other Engineers, Quality Assurance, Operations, and 3rd party vendors to successfully deliver and deploy solutions to production\n    \n \n \n     Define and manage SLA for all data sets     \n \n \n     Identify and implement the right analytical libraries, programming languages, and frameworks for each task\n    \n \n \n     Advocate a continuous improvement mindset regarding our development process, with a focus on how we can automate regular, high-quality, releases in an agile environment\n    \n \n \n     Continuously rebalancing features, which maximize value and minimize effort to focus on the highest returning initiatives for business and customer\n    \n \n \n     Champion a culture of learning, measurement, accountability, and quality via code reviews, paired programming, and other collaboration opportunities with the team\n    \n \n \n     Collaborate with Product Owners on the backlog and providing high level effort estimation to plan feature prioritization more accurately and development\n    \n \n \n \n   BUs, Operations, IT, Information Security and Infrastructure\n  \n \n \n \n     Partner with hardware BUs to understand their needs and deliver platform-oriented solutions\n    \n \n \n     Continuing to evolve security practices and controls to meet the needs of protecting customer data\n    \n \n \n     Champion a culture of compliance as it pertains to data to meet legal, regulatory, and operational data requirements\n    \n \n \n     Partner with IT and operations in support of enterprise IT strategy\n    \n   \n     Ensure we are building necessary observability into our systems that provide transparency across the entire data architecture stack\n    \n \n \n     Work with engineering teams and assisting Customer Success and Operations team in triaging and resolving production issues\n    \n \n \n   You Have:\n  \n \n \n \n     Bachelor\u2019s degree in computer science, information technology, engineering, or related discipline\n    \n \n \n     5+ years of experience with ETL technologies\n    \n \n \n     5+ years of experience with Databricks, specifically within Azure\n    \n \n \n     5+ years of experience with Python, Scala, .NET, Java or similar languages\n    \n \n \n     7+ years of SQL experience (No-SQL experience is a plus)\n    \n \n \n     5+ years of experience with schema design and dimensional data modeling\n    \n \n \n     Excellent product strategic thinking and communication to influence product and cross-functional teams by identifying data opportunities that drive impact\n    \n \n \n     Proven ability around managing and communicating data roadmap plans to internal stakeholders\n    ", "techs": ["databricks", "azure", "python", "scala", ".net", "java", "sql"]}, "c2206c0c792fd066": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "requirements elicitation", "testing", "data analysis"]}, "f4ad36636dca8571": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance"]}, "fe763fe1fc90ae5c": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "data analysis"]}, "40fc7b7a5c4f9189": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "data analysis"]}, "81171e5c06f33d47": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n Supplemental pay types: \n \n Signing bonus \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "45fc2d0adc85c2a8": {"terms": ["data analyst"], "salary_min": 40.0, "salary_max": 64.0, "title": "Board Certified Behavior Analyst (BCBA) (Remote)", "company": "MASS SERVICES LLC", "desc": "About us \n Our mission is to support individuals in achieving their full potential by using evidence-based Applied Behavior Analysis (ABA) strategies. We believe that everyone has the potential to lead a fulfilling life, and we are committed to helping individuals overcome barriers and achieve their goals. \n THIS IS A remote position however, candidates must be willing to go in home for medically necessary clients \n Service areas includes (Perris, Hemet, San Jacinto, and Menifee) \n Thank you for considering our organization. We look forward to partnering with you to help you achieve your goals and reach your full potential. \n Job Description: Board Certified Behavior Analyst \n Duties: \n - Conduct assessments and develop individualized treatment plans for clients with developmental disabilities, particularly children with special needs. - Implement evidence-based behavioral therapy techniques to address behavioral challenges and promote skill development. - Provide direct supervision and training to behavior technicians and other team members. - Collect and analyze data to monitor progress and make data-driven decisions regarding treatment interventions. - Collaborate with families, caregivers, and other professionals involved in the client's care to ensure a comprehensive approach to treatment. - Stay up-to-date with the latest research and best practices in the field of applied behavior analysis (ABA) and special education. \n Skills: \n - Board Certified Behavior Analyst (BCBA) certification required. - Experience working with children with autism or other developmental disabilities. - Strong knowledge of behavioral therapy techniques, including positive reinforcement, discrete trial training, and functional behavior assessments. - Proficient in data collection and analysis methods. - Excellent communication skills, both verbal and written, to effectively collaborate with clients, families, and other professionals. - Ability to work independently as well as part of a multidisciplinary team. - Strong problem-solving skills and the ability to adapt interventions based on individual client needs. \n We offer competitive compensation packages based on experience and qualifications. As a BCBA at our organization, you will have the opportunity to make a meaningful impact on the lives of individuals with special needs and their families. Join our dedicated team of professionals committed to providing high-quality behavioral therapy services. \n To apply for this position, please submit your resume and cover letter highlighting your relevant experience in working with children with special needs and your BCBA certification. \n Job Types: Full-time, Part-time \n Pay: $40.00 - $64.00 per hour \n Expected hours: 15 \u2013 25 per week \n Benefits: \n \n Flexible schedule \n \n Schedule: \n \n 4 hour shift \n 8 hour shift \n \n Supplemental pay types: \n \n Bonus opportunities \n \n License/Certification: \n \n BCBA (Required) \n \n Ability to Commute: \n \n Moreno Valley, CA (Required) \n \n Ability to Relocate: \n \n Moreno Valley, CA: Relocate before starting work (Required) \n \n Willingness to travel: \n \n 50% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "f079b558c66d8e9b": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n Supplemental pay types: \n \n Signing bonus \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "8d9fb33d5670f8d2": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "e26baa9bee8f7d57": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "99ecd4a14c7dff3f": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n Supplemental pay types: \n \n Signing bonus \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "9563c23e0881e388": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "3fe96ff4f0f79e9a": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "64a316540bb97290": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n Supplemental pay types: \n \n Signing bonus \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "90b5388b2dfbd578": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "87e944c8ea06b0fc": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 95000.0, "title": "Board Certified Behavior Analyst (BCBA)", "company": "Supportive Care ABA", "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "ac480d921c1c3a8d": {"terms": ["data analyst"], "salary_min": 83512.13, "salary_max": 105744.98, "title": "Business Analyst", "company": "Random Bit", "desc": "Job Summary \n  We are currently searching for an experienced Business Analyst to work closely with our Enterprise Architects on enterprise system modernization planning projects. This position will help analyze business processes and develop implementations to transform the architecture, capabilities, and overall outcomes for organizations throughout the Medicaid domain. From supporting work sessions, developing models, documenting requirements, and evaluating implementation impacts, the ideal candidate will be a detailed planner, expert communicator, and first-rate analyst. The position can be remote but work hours will be based on EST business hours (8am - 5pm EST). This is a full-time W-2 position with a full benefits package. \n  Responsibilities and Duties \n \n  Interview subject matter experts, technical staff, architects, and other resources to gather requirements, analyze artifacts, and identify opportunities for transformative system modernization. \n  Serve as thought leader for both the business and technical processes analyzed. \n  Create, maintain, and update detailed documentation including business requirements, process flows, use cases, and user stories to convey the current state and target goals. \n  Thoroughly capture business, information, and application models as output from work sessions, research, and independent analysis. \n  Evaluate, analyze, and communicate systems requirements in conjunction with the architectural impacts to the business, data exchange, and application implementation viewpoints. \n  Prepare document outlines to manage expectations with stakeholders. \n  Produce and present easy-to-understand documentation and supporting visuals for clear and concise representation of the analysis completed. \n  Conduct quality assurance on completed deliverables. \n \n  Qualifications and Skills \n \n  Bachelor\u2019s degree in computer science, information technology, or related discipline. \n  5+ Years proven working experience in business analysis. \n  Applicable certification such as Certified Business Analyst Professional (CBAP) or PMI Professional in Business Analysis (PMI-PBA). \n  Proficiency in requirement gathering techniques, process modeling, and documentation. \n  Strong working knowledge of relevant tools such as Microsoft Office, Visio, JIRA, Confluence, SPARX/EA, Draw.io, etc.  \n Strong experience in modeling frameworks such as UML, ArchiMate, etc. \n  Strong experience in modeling Activity Diagrams, Mind Maps, Process Flows, Entity-Relationship Diagrams, etc. \n  Experience working in the Health and Human Services field, preferably Medicaid. \n  Detail-oriented and capable to deliver high quality documentation. \n  Ability to quickly grasp complex technical concepts and make them easily understandable in text and diagrams. \n \n   \n   \n 8r4PyiYwOE", "cleaned_desc": " Strong experience in modeling frameworks such as UML, ArchiMate, etc. \n  Strong experience in modeling Activity Diagrams, Mind Maps, Process Flows, Entity-Relationship Diagrams, etc. \n  Experience working in the Health and Human Services field, preferably Medicaid. \n  Detail-oriented and capable to deliver high quality documentation. \n  Ability to quickly grasp complex technical concepts and make them easily understandable in text and diagrams. ", "techs": ["uml", "archimate"]}, "324532a5f08178ec": {"terms": ["data analyst"], "salary_min": 83512.13, "salary_max": 105744.98, "title": "Business Analyst", "company": "Random Bit", "desc": "Job Summary \n  We are currently searching for an experienced Business Analyst to work closely with our Enterprise Architects on enterprise system modernization planning projects. This position will help analyze business processes and develop implementations to transform the architecture, capabilities, and overall outcomes for organizations throughout the Medicaid domain. From supporting work sessions, developing models, documenting requirements, and evaluating implementation impacts, the ideal candidate will be a detailed planner, expert communicator, and first-rate analyst. The position can be remote but work hours will be based on EST business hours (8am - 5pm EST). This is a full-time W-2 position with a full benefits package. \n  Responsibilities and Duties \n \n  Interview subject matter experts, technical staff, architects, and other resources to gather requirements, analyze artifacts, and identify opportunities for transformative system modernization. \n  Serve as thought leader for both the business and technical processes analyzed. \n  Create, maintain, and update detailed documentation including business requirements, process flows, use cases, and user stories to convey the current state and target goals. \n  Thoroughly capture business, information, and application models as output from work sessions, research, and independent analysis. \n  Evaluate, analyze, and communicate systems requirements in conjunction with the architectural impacts to the business, data exchange, and application implementation viewpoints. \n  Prepare document outlines to manage expectations with stakeholders. \n  Produce and present easy-to-understand documentation and supporting visuals for clear and concise representation of the analysis completed. \n  Conduct quality assurance on completed deliverables. \n \n  Qualifications and Skills \n \n  Bachelor\u2019s degree in computer science, information technology, or related discipline. \n  5+ Years proven working experience in business analysis. \n  Applicable certification such as Certified Business Analyst Professional (CBAP) or PMI Professional in Business Analysis (PMI-PBA). \n  Proficiency in requirement gathering techniques, process modeling, and documentation. \n  Strong working knowledge of relevant tools such as Microsoft Office, Visio, JIRA, Confluence, SPARX/EA, Draw.io, etc.  \n Strong experience in modeling frameworks such as UML, ArchiMate, etc. \n  Strong experience in modeling Activity Diagrams, Mind Maps, Process Flows, Entity-Relationship Diagrams, etc. \n  Experience working in the Health and Human Services field, preferably Medicaid. \n  Detail-oriented and capable to deliver high quality documentation. \n  Ability to quickly grasp complex technical concepts and make them easily understandable in text and diagrams. \n \n   \n   \n 4ihpBNRESf", "cleaned_desc": " Strong experience in modeling frameworks such as UML, ArchiMate, etc. \n  Strong experience in modeling Activity Diagrams, Mind Maps, Process Flows, Entity-Relationship Diagrams, etc. \n  Experience working in the Health and Human Services field, preferably Medicaid. \n  Detail-oriented and capable to deliver high quality documentation. \n  Ability to quickly grasp complex technical concepts and make them easily understandable in text and diagrams. ", "techs": ["uml", "archimate", "activity diagrams", "mind maps", "process flows", "entity-relationship diagrams"]}, "67fb494c24b5e6a0": {"terms": ["data analyst"], "salary_min": 89064.336, "salary_max": 112775.29, "title": "Integrity Analyst", "company": "Pinterest", "desc": "About Pinterest : \n  Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet. \n  Creating a life you love also means finding a career that celebrates the unique perspectives and experiences that you bring. As you read through the expectations of the position, consider how your skills and experiences may complement the responsibilities of the role. We encourage you to think through your relevant and transferable skills from prior experiences. \n  Our new progressive work model is called PinFlex, a term that's uniquely Pinterest to describe our flexible approach to living and working. Visit our  PinFlex  landing page to learn more. \n \n  The Trust & Safety team is dedicated to ensuring that all Pinners have a safe experience on Pinterest. This includes tackling challenging adversarial problems at scale, detecting policy-violating content, and ensuring Pinterest is legally-compliant. We're looking for an analyst to analyze data and create strong signals and strategies to minimize abuse on the platform. This is a high-visibility role that touches almost every product area at Pinterest. \n \n \n  What you'll do: \n \n Protect users on Pinterest from bad actors and problematic trends \n Analyze intelligence sources to scope problems and identify monitoring strategies \n Prototype proactive detection and monitoring solutions \n Partner closely with Product Managers, Engineers, Policy and Operations to devise and execute on new strategies for combating abuse on Pinterest \n Make actionable recommendations to Product, Policy, Operations, and Engineering to improve Pinterest's Trust & Safety ecosystem \n Standardize and automate workflows to scale existing processes \n \n What we're looking for: \n \n 2+ years of experience working with / analyzing data \n Technical background or relevant work experience in Trust & Safety, Fraud, Spam, Investigations, or Cyber \n Proficiency in SQL and at least one programming language (Python or R) \n Basic knowledge of machine learning lifecycle and experience with implementing or improving machine learning models \n Ability to communicate complex concepts clearly to cross-functional stakeholders \n \n \n \n  This position is not eligible for relocation assistance. \n \n \n  #LI-NM4 \n  #LI-REMOTE \n \n \n  At Pinterest we believe the workplace should be equitable, inclusive, and inspiring for every employee. In an effort to provide greater transparency, we are sharing the base salary range for this position. The position is also eligible for equity. Final salary is based on a number of factors including location, travel, relevant prior experience, or particular skills and expertise. \n  Information regarding the culture at Pinterest and benefits available for this position can be found  here . \n \n  US based applicants only \n \n    $96,900\u2014$200,000 USD\n   \n \n \n  Our Commitment to Diversity: \n  Pinterest is an equal opportunity employer and makes employment decisions on the basis of merit. We want to have the best qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic under federal, state, or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you require an accommodation during the job application process, please notify accessibility@pinterest.com for support.", "cleaned_desc": " \n What we're looking for: \n \n 2+ years of experience working with / analyzing data \n Technical background or relevant work experience in Trust & Safety, Fraud, Spam, Investigations, or Cyber \n Proficiency in SQL and at least one programming language (Python or R) \n Basic knowledge of machine learning lifecycle and experience with implementing or improving machine learning models \n Ability to communicate complex concepts clearly to cross-functional stakeholders ", "techs": ["sql", "python", "r"]}, "88a2ca7c3c455aea": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Analyst, Business Analytics, Retail", "company": "Sephora", "desc": "Job ID:  238616   Location Name:  FSC REMOTE SF/NY/DC -173(USA_0173)   Address:  FSC, Remote, CA 94105, United States (US)   Job Type:  Full Time   Position Type:  Regular   Job Function:  Business Strategy & Innovation   Remote Eligible:  Yes \n \n  Company Overview: \n  At Sephora we inspire our customers, empower our teams, and help them become the best versions of themselves. We create an environment where people are valued, and differences are celebrated. Every day, our teams across the world bring to life our purpose: to expand the way the world sees beauty by empowering the Extra Ordinary in each of us. We are united by a common goal - to  reimagine the future of beauty . \n \n  The Opportunity: \n  The Sephora Business Intelligence & Analytics team works in close partnership with key stakeholders across the organization identifying strategic opportunities and making data-driven decisions. We play a critical role in helping cross-functional teams understand the drivers of business performance through the lens of our clients and provide actionable insights across multiple departments from Marketing to Merchandising to Omnichannel Retail to Loyalty. Our team of analysts are all data savvy individuals that share a common goal to answer Sephora\u2019s toughest questions weaving together quantitative and qualitative information into a holistic story. Our VP reports directly to the CEO and interacts frequently with senior leadership across the organization. \n \n  Retail Analytics Team:  The Sephora Retail Analytics team works in close partnership with key stakeholders across the organization identifying strategic opportunities and making data-driven decisions. We deliver actionable client insights to the Store Experience and Retail Operations teams to drive the performance of our Brick and Mortar business. We report to the Director of Channel Intelligence and Analytics and interact frequently with senior leadership across the organization. \n \n  Your role at Sephora:  The Analyst, Retail Analytics is responsible for supporting analyses and insights for business partners across the Retail organization. This includes understanding client behavior and measuring performance of programs and strategic initiatives. The ideal candidate has outstanding analytics skills, excellent interpersonal abilities, and a passion for analysis. The role reports to the Senior Manager, Retail Analytics. \n \n  In addition, you will:  \n \n Work with key stakeholders to formulate and support performance analysis, identifying key deliverables and translating those into business solutions \n  Build and maintain dashboards/reports that are accurate, intuitive, actionable and provide business partners insight into performance/highlights across programs \n  Transform business questions into fact-based analyses in a way that tells a story, delivering clear insights and actionable recommendations \n  Perform ad hoc analyses to answer strategic business questions \n  Improve current analytics communications, reports, dashboards through automations, improved insights, and visualizations \n  Clearly and concisely present findings to varying business partners and audience levels \n \n \n  Demonstrate our Sephora values of Passion for Client Service, Innovation, Expertise, Balance, Respect for All, Teamwork, and Initiative. \n \n \n  We\u2019re excited about you if you have:  \n \n 2+ years in an analytics role  \n Strong SQL programming skills \n  Advanced Excel and Powerpoint Skills \n  Experience with data visualization tools such as Tableau  \n Experience with R/Python a plus \n  Exceptional problem solving and analysis skills \n  Ability to manage several projects simultaneously and prioritize appropriately \n  Strong interpersonal skills to collaborate with cross-functional teams \n  Strong written and verbal communication skills with the ability to communicate findings \n \n \n  The annual base salary range for this position is $94,435.00 - $117,230.00. The actual base salary offered depends on a variety of factors, which may include, as applicable, the applicant\u2019s qualifications for the position; years of relevant experience; specific and unique skills; level of education attained; certifications or other professional licenses held; other legitimate, non-discriminatory business factors specific to the position; and the geographic location in which the applicant lives and/or from which they will perform the job. Individuals employed in this position may also be eligible to earn bonuses. Sephora offers a generous benefits package to full-time employees, which includes comprehensive health, dental and vision plans; a superior 401(k) plan, various paid time off programs; employee discount/perks; life insurance; disability insurance; flexible spending accounts; and an employee referral bonus program. \n \n  While at Sephora, you\u2019ll enjoy\u2026 \n \n \n  The people.  You will be surrounded by some of the most talented leaders and teams \u2013 people you can be proud to work with. \n  The learning . We invest in training and developing our teams, and you will continue evolving and building your skills through personalized career plans. \n  The culture . As a leading beauty retailer within the LVMH family, our reach is broad, and our impact is global. It is in our DNA to innovate and, at Sephora, all 40,000 passionate team members across 35 markets and 3,000+ stores, are united by a common goal - to reimagine the future of beauty. \n \n \n  You can  unleash your creativity , because we\u2019ve got disruptive spirit. You can  learn and evolve , because we empower you to be your best. You can  be yourself , because you are what sets us apart.  This , is the future of beauty. Reimagine your future, at Sephora. \n \n  Sephora is an equal opportunity employer and values diversity at our company.  We do not discriminate on the basis of race, religion, color, national origin, ancestry, citizenship, gender, gender identity, sexual orientation, age, marital status, military/veteran status, or disability status. Sephora is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. \n \n  Sephora will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law.", "cleaned_desc": "", "techs": ""}, "760cd1165d623417": {"terms": ["data analyst"], "salary_min": 115000.0, "salary_max": -1.0, "title": "Technical Business Analyst", "company": "BluMotif", "desc": "bluMotif is seeking a Technical Business Analyst to work with our business clients. The right candidate will come with at least  10 years experience  in an analyst role eliciting requirements from business stakeholders and delivering technical expertise and guidance to developers and engineers. This opportunity will be on a 1099 or C2C contract only (benefits only include pay to start) \n Required skills & responsibilities \n * Ability to read customer requirements and generate internal documentation and design documentation to meet custom needs. * Responsible for solution design, implementation, debugging, assurance testing, and creation of necessary documentation. * Responsible for working with biometric technologies in software modules or applications. * Plans and develops all technical delivery aspects of a project. * This is not a hands-on software development position but requires an in-depth understanding of software development practices. Software development management, development, or technical lead experience is required. * Must be familiar with Windows and Linux OS. * Ideally would be familiar with AngularJS development platform (Expertise not required). * Ideally would have experience integrating external hardware devices via an API/SDK layer. * Must have experience working in an Agile Development process. * Knowledge of Database Communications including AWS PostgreSQL, Microsoft SQL Server, data migration, and general DB communication * Ideally would have some knowledge of AWS Cloud development and infrastructure \n \n Ability to translate specifications and technical designs into detailed actions resulting in successful deliveries. \n Understanding of the software development lifecycle. \n Background in deploying software applications to the end user. \n Strong communication and writing skills. \n \n Qualifications \n - Bachelor\u2019s degree in Information Technology or related field \n - 10+ years Business Analyst experience \n - Experience in analyzing data to draw business-relevant conclusions \n - Strong written and verbal communication skills including technical writing skills \n Reasons to Join bluMotif: \n \n We are a fully fun and supportive team. We have each other\u2019s back \n Work with the latest tools and technology \n Growth opportunity \n \n Job Types: Full-time, Contract \n Pay: From $115,000.00 per year \n Benefits: \n \n Work from home \n \n Compensation package: \n \n Hourly pay \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Describe your experience with Windows and Linux OS \n Describe your knowledge of Angular JS \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Business Analysis: 10 years (Required) \n \n Work Location: Remote", "cleaned_desc": "bluMotif is seeking a Technical Business Analyst to work with our business clients. The right candidate will come with at least  10 years experience  in an analyst role eliciting requirements from business stakeholders and delivering technical expertise and guidance to developers and engineers. This opportunity will be on a 1099 or C2C contract only (benefits only include pay to start) \n Required skills & responsibilities \n * Ability to read customer requirements and generate internal documentation and design documentation to meet custom needs. * Responsible for solution design, implementation, debugging, assurance testing, and creation of necessary documentation. * Responsible for working with biometric technologies in software modules or applications. * Plans and develops all technical delivery aspects of a project. * This is not a hands-on software development position but requires an in-depth understanding of software development practices. Software development management, development, or technical lead experience is required. * Must be familiar with Windows and Linux OS. * Ideally would be familiar with AngularJS development platform (Expertise not required). * Ideally would have experience integrating external hardware devices via an API/SDK layer. * Must have experience working in an Agile Development process. * Knowledge of Database Communications including AWS PostgreSQL, Microsoft SQL Server, data migration, and general DB communication * Ideally would have some knowledge of AWS Cloud development and infrastructure \n \n Ability to translate specifications and technical designs into detailed actions resulting in successful deliveries. \n Understanding of the software development lifecycle. \n Background in deploying software applications to the end user. \n Strong communication and writing skills. \n \n Qualifications ", "techs": ["biometric technologies", "windows", "linux", "angularjs", "api", "sdk", "agile development", "aws", "postgresql", "microsoft sql server", "data migration", "database communication", "aws cloud"]}, "cc9fc091daf325e5": {"terms": ["data analyst"], "salary_min": 67216.13, "salary_max": 85110.6, "title": "Business Intelligence Analyst", "company": "ServiceMaster", "desc": "We Play to Win! \n \n  Big goals. Big achievements. Big impact. \n \n  ServiceMaster employs empowered and engaged teams, delivering growth in an ever-evolving world. Our goal is to double in size over the next few years, which means ambition and risk-taking are part of our daily life. If you are tired of the status quo and complacency, join our team to help franchisees dominate in their respective areas. You\u2019ll be around other winners chasing big goals, guaranteed to bring out the best work of your career! \n   What We Offer: \n \n  Medical, Dental, and Vision start the first day of the month following your date of hire \n  401 (k) match \n  15 days paid time off and paid holidays, including 2 floating holidays \n  Mental health support through Headspace Health \n  Career growth and advancement \n \n \n  Business Intelligence Analyst \n  We are currently looking for a Business Intelligence Analyst to provide analysis of  quantitative and qualitative data  from internal and external data sources in support of business decisions. In this role, you'll have the opportunity to use standard or ad hoc queries or reports to extract data from disparate databases or data sources with the focus on driving the business forward. \n \n \n  What you'll do: \n \n  Analyze data to produce dashboards, metrics, or insights, and identify trends or anomalies. \n  Consult with users or decision makers to identify data sources, required data elements, or data validation standards. \n  Collaborate with development teams to design business intelligence solutions to facilitate data gathering, storage, and retrieval. \n  Act as a trusted advisor when questions arise regarding BI solutions and metrics. \n  Assist with day-to-day support of reports and dashboard users, including fielding questions and ad-hoc customizations to reports. \n  Assist with the creation of training resources related to business intelligence reports, consulting models, or other related projects \n \n  What you bring: \n \n  The ability to handle moderately complex issues and problems \n  Solid working knowledge of quantitative and qualitative data collection and analysis \n  Good working knowledge of Power BI visualization software \n  Strong oral and written communication skills \n  You are a problem solver and can identify and seek needed information \n  You have strong research skills and are an analytical thinker \n  Statistical knowledge and the technical expertise to support queries \n   Bachelor's degree \n  2 to 4 years of experience \n \n \n  Work Location: \n  This role is 100% remote with up to 10% travel expected. \n \n  About ServiceMaster Brands \n  ServiceMaster\u00ae Brands\u00ae is a leading franchise provider of needs-based residential and commercial services in the restoration, cleaning, moving, and bioremediation industries. Founded in 1929, the company is home to over 3,200 franchisees across 4,600+ locations serving over 1,000,000 homes and businesses each year. ServiceMaster was founded with a deep commitment to integrity and customer service and does business under seven brands today  across 50 states and nine countries  that generate more than $3.5B in system-wide sales: ServiceMaster Restore\u00ae, ServiceMaster Clean\u00ae, Merry Maids\u00ae, TWO MEN AND A TRUCK\u00ae, Aftermath Services\u00ae, Indoor Science. \n  While each brand maintains a distinct identity, we share a commitment to our mission to  Making Everyday Heroes More Heroic \u2122. From our franchisee experience to career development to our community outreach efforts, our values \u2013  We Serve, We Care, We Deliver, We Do  - guide us. \n  Working as part of our team means bringing your best ideas to work every day and seeing the impact of your contributions. Stars in our company at all levels are builders\u2014they love to create, lead and see their plan come to life. Our best people understand that while great ideas are important, they require incredible focus and teamwork to execute. Life inside our company is the opportunity to do the best work of your career. \n  ServiceMaster Brands is headquartered in Atlanta, Georgia. \n  Roark Capital Group acquired ServiceMaster Brands in October 2020. Roark focuses on investing in the consumer and business services sectors, with a specialization in multi-location and franchised businesses. Since inception, affiliates of Roark have invested in 100 multi-location, franchised brands, which collectively generate $62 billion in annual system revenues from 66,000 locations in 50 states and 89 countries. Please visit www.roarkcapital.com to learn more. \n  It is the policy of ServiceMaster Brands, in accordance with all applicable laws, to recruit, hire, train, and promote persons in all job titles without regard to race, color, national origin, genetic information, religious beliefs, sex, gender identity, sexual orientation, age, marital status, pregnancy, disability, protected veteran status, or any other protected classifications, activities, or conditions as required by federal, state and local laws. \n  If you are unable to complete this application due to a disability, contact this employer to ask for an accommodation or an alternative application process at weacknowledge@servicemaster.com \n \n   California Applicant Policy: https://www.servicemaster.com/california-applicant-privacy-notice/", "cleaned_desc": "  Analyze data to produce dashboards, metrics, or insights, and identify trends or anomalies. \n  Consult with users or decision makers to identify data sources, required data elements, or data validation standards. \n  Collaborate with development teams to design business intelligence solutions to facilitate data gathering, storage, and retrieval. \n  Act as a trusted advisor when questions arise regarding BI solutions and metrics. \n  Assist with day-to-day support of reports and dashboard users, including fielding questions and ad-hoc customizations to reports. \n  Assist with the creation of training resources related to business intelligence reports, consulting models, or other related projects \n \n  What you bring: \n \n  The ability to handle moderately complex issues and problems    Solid working knowledge of quantitative and qualitative data collection and analysis \n  Good working knowledge of Power BI visualization software \n  Strong oral and written communication skills \n  You are a problem solver and can identify and seek needed information \n  You have strong research skills and are an analytical thinker \n  Statistical knowledge and the technical expertise to support queries \n   Bachelor's degree \n  2 to 4 years of experience \n \n ", "techs": ["power bi"]}, "9f2fedeae04af40f": {"terms": ["data analyst"], "salary_min": 70000.0, "salary_max": 75000.0, "title": "BUSINESS ANALYST", "company": "State of Arizona", "desc": "CORPORATION COMMISSION \n The Arizona Corporation Commission (ACC) is one of the most unique state agencies in Arizona and one of only 13 public utility commissions in the country where commissioners are elected. Established by the Arizona Constitution, the ACC is a medium-sized agency with offices in Phoenix and Tucson. Our mission is diverse\u2014spanning utility rate making; securities registration and enforcement; rail and pipeline safety; and corporate business filings\u2014and we boast an average employment tenure of nearly 10 years. Learn more by visiting www.azcc.gov. \n \n BUSINESS ANALYST \n Job Location:  \n \n Address: 1300 W. Washington, Phoenix AZ 85007  Hybrid remote work schedule available \n \n Posting Details:  \n \n Salary: $70,000 - $75,000   \n Grade: 24 \n \n Job Summary:  \n \n The IT Division provides network, hardware, help desk, project management, and application development services to in support of the mission of the Corporation Commission. We are responsible for applications used internally and by the public to access information and services. \n \n Job Duties:  \n \n You are the primary liaison between IT and various agency units, working to support key business processes and applications. You will gather and document business requirements for projects and production support tickets and translate those requirements into written business, function, and use case documentation. You will troubleshoot existing customer issues and will design new screens or changes as necessary. Duties include participating in the testing of software applications by developing and executing comprehensive system test plans, conditions, test scripts, and test cases, as well as coordinating user acceptance testing. You will provide functional expertise to developers during the design and construction phases of projects and tasks and translate that expertise into training materials and guides for end users.  \n \n Knowledge, Skills & Abilities (KSAs):  \n \n \n General knowledge of methodologies and techniques for systems analysis and design, business process modeling, requirements gathering, quality assurance, and software development \n Ability to quickly absorb the programs and goals of the Corporation Commission and its divisions  \n Familiarity with Business Analysis Body of Knowledge (BABOK)  \n Excellent interpersonal, written, and oral communication skills \n Strong customer service and analytical skills to evaluate input gathered from multiple sources and extract to functional requirements \n Ability to balance, prioritize and organize multiple tasks, to work collaboratively in teams and across organizations, to synthesize feedback and adjust plans accordingly, to build strong relationships inside and outside the organization, as well as develop and write technical documentation, to breakdown processes into sub-tasks, to see patterns in data and business processes. \n \n \n \n  Selective Preference(s):  \n \n PMI certification a plus but not required \n \n Pre-Employment Requirements:  \n \n Any offer of employment is contingent upon successful completion of an employment/reference check and confirmation of any degrees/certifications.    A.R.S. Section 40-101 prohibits Commission employees from having certain financial interests in entities that the Commission regulates. Applicants shall be required to disclose any interests they may have in the regulated entities during the application process, and as a condition of employment, to divest themselves of any prohibited interests. \n  All newly hired State employees are subject to and must successfully complete the Electronic Employment Eligibility Verification Program (E-Verify). \n \n Benefits:  \n \n \n Excellent comprehensive benefits, including a top-ranked retirement plan, low-cost health coverage, supplemental policies such as vision and short-term disability, generous paid vacation and sick leave programs, and Paid Parental Leave for those who qualify  \n Career and personal development support; multiple training and education opportunities and resources; qualifying Public Service Loan Forgiveness employer \n Interesting, challenging work in a public sector environment with the chance to make a real difference in our state \n We are a recognized Arizona Veteran Supportive Employer \n \n  By providing the option of a full-time or part-time remote work schedule, employees enjoy improved work/life balance, report higher job satisfaction, and are more productive. Remote work is a management option and not an employee entitlement or right. An agency may terminate a remote work agreement at its discretion. \n \n \n \n Retirement:  \n \n This position qualifies for participation in the Arizona State Retirement System (ASRS) defined benefit pension program \n \n Contact Us:  \n \n If you have any questions, please email HumanResources@azcc.gov for assistance.", "cleaned_desc": " General knowledge of methodologies and techniques for systems analysis and design, business process modeling, requirements gathering, quality assurance, and software development \n Ability to quickly absorb the programs and goals of the Corporation Commission and its divisions  \n Familiarity with Business Analysis Body of Knowledge (BABOK)  \n Excellent interpersonal, written, and oral communication skills \n Strong customer service and analytical skills to evaluate input gathered from multiple sources and extract to functional requirements \n Ability to balance, prioritize and organize multiple tasks, to work collaboratively in teams and across organizations, to synthesize feedback and adjust plans accordingly, to build strong relationships inside and outside the organization, as well as develop and write technical documentation, to breakdown processes into sub-tasks, to see patterns in data and business processes. \n \n \n \n  Selective Preference(s):  \n \n PMI certification a plus but not required ", "techs": ["babok", "pmi"]}, "e6552f94f0e402ea": {"terms": ["data analyst"], "salary_min": 100000.0, "salary_max": 110000.0, "title": "Business Analyst", "company": "Kaleyra", "desc": "We are looking to hire a Business Analyst with strong technical skills related to data management, data queries, analysis and presentation. Our cloud platform provides registration services with capture of company and messaging campaign information, with high demands for quality control, availability and information security. The Business Analyst will be responsible for analysis and planning, and the the full range of internal and external reporting, using Alteryx, Tableau and similar tools. It is critical for the Business Analyst to be highly analytical and agile with a passion for success and ability to bring business acumen to the role. While being part of a very large, global enterprise, we are a young, very fast moving company with a startup culture. The right candidate will be ambitious and willing and able to take responsibility, in a very demanding environment. \n  Ideally looking for hybrid candidates within commuting distance to, Santa Clara CA, Atlanta GA, Reston or Vienna VA, Matawan NJ, or Montreal Quebec, but open to the right remote candidate.  \n Responsibilities: \n \n Establish terminology, ensure quality, consistency and proper interpretation of terms across the organization. \n Manage the design, development and delivery of reports, dashboards and insights that analyze business functions and key operations and performance metrics. \n Manage and optimize processes for data capture, validation and mining as well as modeling, visualization and communication deliverables. \n Oversee the data/report requests process with prioritization and tracking. \n Define, develop and implement a wide range of operational procedures for delivery of ad-hoc and scheduled reports. \n Ensure accuracy of data and deliverables of reporting for internal and external customers. \n Maintain a secure environment, consistent with company policies and procedures \n \n Requirements \n \n BSc in Business Analytics, Management Information Systems, or related field. \n A minimum of 3 years, preferably 5 years experience as Data- or Business Analyst, with hands-on experience and in-depth understanding of Tableau (preferred) and/or Microsoft BI. \n Knownledge of data mining principles with data collection and mapping from multiple data systems on premises and cloud-based data sources. \n Demonstrated ability to produce high quality output, including effective visuals. \n SQL skills, and ability to perform effective querying involving multiple tables and subqueries. \n Experience with common security practices for storing and exchange of business information \n Strong problem solving, quantitative and analytical abilities. \n Good communication skills, orally and written. \n Ability to work independently as part of a small, high-energy, fast moving startup environment. \n Strong preference for candidate with experience in subscription services in the technology sector.  \n \n Benefits \n  Benefits \n \n Health Care Plan (Medical, Dental & Vision) \n Retirement Plan (401k, IRA) \n Life Insurance (Basic, Voluntary & AD&D) \n Paid Time Off (Vacation, Sick & Public Holidays) \n Training & Development \n \n \n \n \"If you are a United States Job Applicant see our Privacy Notice and our Notice at Collection for California Employees and Applicants here :  https://www.kaleyra.com/privacy-policy-kaleyra/# .  By applying to a Kaleyra job posting, you agree to our collection and use of such data as provided in the aforementioned links. \"", "cleaned_desc": "We are looking to hire a Business Analyst with strong technical skills related to data management, data queries, analysis and presentation. Our cloud platform provides registration services with capture of company and messaging campaign information, with high demands for quality control, availability and information security. The Business Analyst will be responsible for analysis and planning, and the the full range of internal and external reporting, using Alteryx, Tableau and similar tools. It is critical for the Business Analyst to be highly analytical and agile with a passion for success and ability to bring business acumen to the role. While being part of a very large, global enterprise, we are a young, very fast moving company with a startup culture. The right candidate will be ambitious and willing and able to take responsibility, in a very demanding environment. \n  Ideally looking for hybrid candidates within commuting distance to, Santa Clara CA, Atlanta GA, Reston or Vienna VA, Matawan NJ, or Montreal Quebec, but open to the right remote candidate.  \n Responsibilities: \n \n Establish terminology, ensure quality, consistency and proper interpretation of terms across the organization. \n Manage the design, development and delivery of reports, dashboards and insights that analyze business functions and key operations and performance metrics. \n Manage and optimize processes for data capture, validation and mining as well as modeling, visualization and communication deliverables.   BSc in Business Analytics, Management Information Systems, or related field. \n A minimum of 3 years, preferably 5 years experience as Data- or Business Analyst, with hands-on experience and in-depth understanding of Tableau (preferred) and/or Microsoft BI. \n Knownledge of data mining principles with data collection and mapping from multiple data systems on premises and cloud-based data sources. \n Demonstrated ability to produce high quality output, including effective visuals. \n SQL skills, and ability to perform effective querying involving multiple tables and subqueries. \n Experience with common security practices for storing and exchange of business information \n Strong problem solving, quantitative and analytical abilities.   Good communication skills, orally and written. \n Ability to work independently as part of a small, high-energy, fast moving startup environment. \n Strong preference for candidate with experience in subscription services in the technology sector.  \n \n Benefits \n  Benefits \n ", "techs": ["alteryx", "tableau", "microsoft bi", "sql"]}, "cdac984799573eff": {"terms": ["data analyst"], "salary_min": 91292.03, "salary_max": 115596.05, "title": "Sr Business Analyst", "company": "LineVision, Inc.", "desc": "Located in one of our offices in Boston, MA, Denver, CO, or Louisville, KY or fully remote. \n  About us: \n  LineVision is a rapidly growing technology company, enabling electric utilities around the world to lead the energy transition with enhanced transmission grid flexibility, increased resiliency, and more grid capacity for renewable energy. \n  About the team: \n  Business Development is an expanding group within our Commercial organization focused on delivering the insight and perspective necessary to shape and land our largest deals. This team engages with C-suite clients, collaborates across organizations, and shapes, quantifies, and validates our collective vision for decarbonization to make the energy transition real. Business Development partners closely with our Sales, Client Engagement, Solutions Engineering, and Executive teams to orchestrate wins for our clients, the company, and the planet. \n  About the role: \n  This is a dynamic and high-profile role, with wide opportunity to build a career and expertise: from developing hypotheses for C-suite meetings to creating the tools that model our solutions\u2019 CO2 reduction potential to shaping our go-to-market campaigns and ensuring we tell the right stories, at the right times, to our customers. On any given day, this individual could be working on detailed financial models, leading customer workshops to design major programs for DOE funding pursuits, or collaborating to build deeply researched account plans with our sales directors. \n  We are looking for a candidate who is flexible, has a strong background in utilities, and who is organized, data-driven, and good at telling stories about why the energy transition matters. You should be able to hold rich conversations with our clients (at all levels), produce high quality work, and be willing to join us on the road periodically. \n  What will you do? \n \n  Account planning  \u2013 shape our path for a discrete number of our largest accounts by owning the hypotheses around big business problems, justifying those with qualitative and quantitative evidence, and rallying colleagues to realize those opportunities with qualified sales leads. While you aren\u2019t responsible for direct sales, you should have a commercial mindset. \n  Market intelligence  \u2013 gather and share insights from customer earnings calls, industry sustainability reports, and RTO/ISO proceedings on future grid investments by getting excited about developing a deep understanding of our customers, the ecosystems in which they exist, and the ways those create, or hinder, potential partnerships. \n  Customer collaboration  \u2013 distill insights and create frameworks in PowerPoint or Word for VP/C-Suite engagement, facilitate meetings and workshops, and develop customer relationships at the Analyst to Manager-level to supercharge and accelerate our wins by producing rigorous and jointly-created white papers, grant applications, and roadmaps that excite a bias to action with our customers. \n  Quantitative modeling  \u2013 architect rigorous business cases by collaborating with customers to elicit the right inputs and shape those into the right outputs that make inaction impossible through financial, climate, or reliability modeling in Excel, R, Python, etc. to tell clear and decisive stories with data. \n  Capability development  \u2013 develop key assets and templates for LineVision to engage customers around value, benefits, and decision making that extends from early-stage conversations through realized KPI tracking. Assemble well-crafted slide decks and white papers that demonstrate our investment in our customer\u2019s success. \n \n  What do you need to succeed in this role? \n \n  Strong quantitative skills and comfort or a quick learning around key stats like IRR and NPV \n  Experience reviewing and evaluating utility rate cases, IRPs, or FERC dockets \n  Conceptual thinking skills to synthesize disparate information into value-led stories \n  The innate ability to ask the right questions and get the right information from others \n  A bias toward action and personal satisfaction from seeing your work deliver real outcomes \n  Organization and a logical thought process to bring others along with your thinking \n \n  What does joining LineVision mean for you? \n \n  Impact.  Your talent, time, and energy will determine whether utilities around the world gain the flexibility and capacity to maximize their existing grid to deliver renewable energy. \n  Growth.  You will be the go-to person for strategic intel and knowledge on our customers. You will deepen and then broaden your experience to build the skills and leadership for a rewarding clean energy career. \n  Distinction.  You will help build a new capability for the company that delivers transformative returns to your colleagues and the planet. \n  Ownership.  You hold broad responsibilities with high autonomy in a communicative, collaborative, and fast-paced environment. \n  Compensation.  You are vested in a high-potential success story, with competitive compensation, benefits, and comprehensive PTO and leave policies, complemented by stock options in a high-growth company with world-class venture capital backing. \n \n  Who we are... \n \n  We are a team of dedicated individuals who are passionate about helping to solve the biggest challenges facing today\u2019s electric grid. \n  We believe unlocking transmission capacity is critical to the resilience of our future grid and the ability to integrate renewables at scale. \n  We value and benefit from the wide-ranging perspectives that come from a diverse and inclusive work environment. \n \n  If you are a Colorado resident, please email us at apply@linevisioninc.com to receive compensation and benefits information for this role. Please include this job title in the subject line of the email. \n  LineVision Inc is an EEO/Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or any other legally protected status. \n  For more information, visit http://www.linevisioninc.com \n  TO APPLY,  please send a resume and cover letter to apply@linevisioninc.com with  Sr. Business Analyst  in the subject line.", "cleaned_desc": "", "techs": ""}, "5e22954b124acca6": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "SEO Analyst", "company": "Strategic America", "desc": "Location: Des Moines (Hybrid) or Remote within the United States only. \n  About SA - Our People \n  Think of the world\u2019s most talented creative thinkers. Problem-solvers. Strategists. At Strategic America, we don\u2019t bring on anything less. The way we see it, if you\u2019re going to make the best work of your life, you may as well do it with people you like. \n  At SA, we\u2019ve always been passionate about our employees. Since 2021, we\u2019re also employee owned with participation in an Employee Stock Option Plan (ESOP). Employee ownership ensures SA remains independent and allows our talented team members to share in the company\u2019s success. With each year of employment, SAers build equity in the company, becoming fully vested after six years. \n  Our employee-led, leadership-supported ERGs celebrate the diversity of our team, foster inclusivity and belonging, and create a space to connect to each other. Through connections and understanding, we build a stronger and more dynamic team and help every person reach their personal peak. \n  About SA \u2013 The Company \n  When you join SA, you join a strategic team (yes, it\u2019s in our name!) who is also wired for action. Authenticity is our focus, and every day we help our clients propel their potential. If you\u2019re ready for a fast-paced environment that challenges you, supports you, and rewards you, then look no further. Our clients rely on us and we rely on each other to go the extra mile, to hold ourselves accountable because we\u2019re better together and we know we can always find the better way. \n  About The Role \n  We strive to create meaning in work and provide more than just a job; a place to belong and grow. As we leap toward our goals that will shape our future, our employee experience is unique. Flexibility, connection, inclusiveness, and collaboration support our well-being and help us be our best. Because when you feel like you belong, work is no longer work \u2013 it's personal. We believe better employees lead to better results. \n  Join us as we transform your career! \n  As a SEO Analyst, you will... \n \n  Work with cross-functional teams to establish and implement SEO strategies for clients. \n  Develop strong, trusting relationships between clients and agency partners, providing leadership and support during strategy, ideation, execution and analysis. \n  Evaluate SEO performance based on key performance indicators (KPIs) on a weekly basis in order to make recommendations and alterations in a timely manner. \n  Perform keyword research and monitors keyword performance. \n  Manage local SEO programs individually and at scale.  \n Collaborate with content strategists to incorporate keywords and searcher intent into writing. \n  Perform technical SEO audits to uncover issues and inhibitors to website performance. \n  Analyze data at an advanced level to identify the root cause of issues. \n  Identify backlink opportunities and performs necessary outreach. \n  Actively stay current with industry and client research in order to help facilitate early adoption of new technologies and advertising channels. \n  Other duties as assigned. \n \n  Minimum Qualifications \n  We realize applying for jobs can feel daunting at times. Even if you don\u2019t check all the boxes in the job description, we encourage you to apply anyway. \n \n  Minimum 2-3 years full-time experience in search engine optimization. \n  Demonstrable experience in SEO copywriting, backlinking, technical SEO, local SEO, keyword research and overall ability to optimize websites for SEO. \n  Prior content management system (CMS) experience a plus. \n  Strong technical SEO knowledge. \n  Experience using Google Analytics, Google Tag Manager, and Google Search Console. \n  Solid understanding of web protocols, web application architectures and frameworks. \n  Experience with WordPress websites a plus. \n \n  Our Commitment to Inclusivity and Diversity \n  We are proud to be one of only 14 agencies nationwide, and the first in the Midwest, to earn the 4A\u2019s Workplace Enlightenment Certification\u00ae, and we couldn\u2019t have done it without our associates, who participated in digital learning sessions on race, ethnicity, gender, sexuality, age, disabilities, and faith. At SA, we are committed to creating an inclusive and diverse environment where people of every background can thrive and feel welcome. Learn more about our commitments here. \n  Don\u2019t meet every single requirement for this role? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. Because we are fully committed to our culture of diversity and inclusion, one that reflects the clients we serve and communities we work in, if you\u2019re excited about this role but your qualifications don\u2019t align perfectly, we encourage you to apply anyway. You may be just the right candidate for this or other roles. \n  Location:  Des Moines (Hybrid) or Remote in the United States (excluding CA, CO, NY, NJ, and WA). \n   \n Ff5GIP7Qj8", "cleaned_desc": "", "techs": ""}, "cae70863150558aa": {"terms": ["data analyst"], "salary_min": 49.0, "salary_max": 55.0, "title": "Business Analyst Senior (Remote)", "company": "Excelraise, LLC", "desc": "Job Detail \n \n \n \n \n \n     Job Code 723683\n     \n \n \n     Tax Term W2 Hourly1099Corp To Corp\n     \n \n \n     Career Level Executive\n     \n \n \n     Experience 7 Years\n     \n \n \n     US Work Status US CitizenGreen Card Holder\n     \n \n \n     Job Duration 12 Months\n     \n \n \n     Qualifications Bachelor's Degree \n     \n \n \n \n Job Description \n \n \n Excelraise, LLC  is a rapidly growing full service IT solutions integrator and talent management company headquartered in  Denver, CO . Our valued client*s includes fortune 500 companies, Government Agencies. \n  Currently, we are looking for a qualified individual to work as a  Business Analyst- Senior (Remote)  with our direct client   in  Raleigh, NC \n  NC Department of Health and Human Services seeks a Senior Business Analyst to support the business case development, process improvement and requirements analysis, testing and implementation for new software solution projects for DMHDDSUS and DSOHF. \n  Primary tasks include: \n \n Identify and document stakeholders, data flows, and current and future state process flows. \n Gather, document, validate, and maintain business, functional, and technical/non-functional solution requirements needed as input to market analysis, software procurement, and solution development process. \n Translate client\u2019s business needs into agile themes, product backlogs, epics, user stories or detailed business requirement documents and use cases depending on the development approach. \n Work with Product Owners, and business SMEs to groom user stories and define acceptance criteria to ensure that stories meet the team-defined definition of ready. \n Work with vendor or internal developers and testers to confirm the functionality meets the story\u2019s acceptance criteria. \n Participate in gap analysis and detailed requirement development efforts. \n Assist the Business/Product Owner in planning, preparing for and conducting user acceptance testing, including developing test scenarios and test cases. \n Perform requirements traceability throughout the project lifecycle to support user acceptance testing and production rollout. \n Develop procurement documents such as Requests for Proposals, Requests for Quotes, and Requests for Information. \n Support vendor proposal evaluation efforts and assist in documenting evaluation results. \n Support process improvement initiatives. \n Perform market research for proposed automation projects. \n Support options analysis and business case development for proposed automation projects. \n Document meeting agendas and notes. \n Facilitate requirements gathering meetings. \n Support project manager in maintaining project artifacts and developing status reports. \n Support the development of surveys, assessment tools, project methodologies, policies and procedures. \n Maintain SharePoint site for each assigned project. \n Perform other analysis assignments as assigned.", "cleaned_desc": "", "techs": ""}, "393fe749cc6beacb": {"terms": ["data analyst"], "salary_min": 93096.18, "salary_max": 117880.51, "title": "Salesforce Business Analyst", "company": "Palladin Consulting, LLC DBA Palladin Technologies", "desc": "Part Art, Part Science, All Salesforce!  \n Palladin Technologies is a rapidly-growing Salesforce consulting firm based out of Atlanta with customers across North America. An aptitude for problem-solving, critical thinking, focus on client satisfaction, and desire to be a crucial part of our explosive growth are some of the ingredients of the successful candidate. \n  Does data motivate you? Identifying key insights? Mapping out a winning business strategy? We are looking for a high performing Salesforce  Business Analyst . This role is a project based, business improvement role. Do you dream in improved processes and efficiencies? Here\u2019s your chance to elicit, document and analyze requirements around business challenges \u2013 and produce data-driven solutions! The Salesforce  Business Analyst  is the interpreter between IT and business stakeholders to ensure the best results are achieved. \n  Responsibilities   \n \n Communicate. \n    \n When you think about communication, you think about speaking and presenting, but listening is just as important.  \n A BA creates an environment for open conversations, and clearly communicates information back out to the appropriate teams.  \n \n Elicit. \n    \n The BA asks lots of questions, with the purpose of understanding project goals and getting clarification on what stakeholders want to accomplish.  \n They interview stakeholders, research information or processes related to the project, and observe teams as they work. This sets the foundation for the project.  \n \n Document requirements. \n    \n Documenting requirements involves recording what was learned. This should be clear and concise, so the information can be easily understood by stakeholders and anyone else involved.  \n The BA must be thoughtful about how they choose to document requirements so they can easily share between teams.  \n \n Analyze Information. \n    \n Next, the BA reviews requirements and gets a sense of how to accomplish their team\u2019s business goals.  \n They dive into more detail and use data insights to identify what the business needs to do to achieve the desired outcome.  \n \n Facilitate solutions. \n    \n Based on analysis, the BA then identifies options for solving business challenges.  \n Then they choose the best option and move forward with the best solution.  \n \n Implement solutions. \n    \n Once the BA comes up with a great business solution, they need to make sure it\u2019s running smoothly and as expected. Are stakeholders seeing benefits? Is anything else needed to support the implementation? Essentially, the BA is a project manager at this point. It\u2019s their job to make sure they reach the end goal, that it\u2019s working well, and stakeholders are happy.  \n The BA keeps the end solution in mind and makes adjustments if anything goes off course.  \n \n Test. \n    \n Remember to test after the implementation!  \n At this time the BA builds training material to support the implemented solution, and records feedback to start eliciting requirements for the next iteration of the project, if needed. \n   \n \n Relevant Industry & Functional Experience   \n \n Telecommunications or high-tech (software development, software product companies) industry experience highly preferred.  \n Client-side experience as a Salesforce user, champion, administrator, etc.  \n Prior consulting experience highly preferred.  \n \n Requirements and Skills   \n \n BSc degree in Sales, Business Administration, or relevant field with 5+ years of related experience.  \n Required Salesforce Certifications ADM201 (Salesforce Certified Administrator), Sales or Service Cloud Consultant, Salesforce Certified  Business Analyst  (ok to achieve this within 30 days of hire)  \n Excellent analytical and problem-solving skills.  \n Hands on experience with CRM software and Account management systems, specifically Salesforce.  \n Ability to develop and maintain effective working relationships with others and display strong communication skills with colleagues and client stakeholders.  \n Self-motivated with the ability to manage time and resources effectively, meet deadlines and execute strategic objectives.  \n Adheres to Palladin\u2019s project methodology, while contributing to continuous process improvement.  \n Leverages and adds to Palladin\u2019s library of Best Practice and Success toolkits. \n Act with a high level of integrity, professionalism, and collaboration. \n Maintain a positive attitude and be eager to be successful. \n This is a remote position with location preference of metro-Atlanta, GA or East/Central time zone. \n \n Compensation & Benefits   \n \n Position is full-time, salaried with a strong variable compensation plan. Salary is commensurate with experience. \n 100% Company paid Employee coverage for Medical, Dental, Vision insurance \n 30% Company paid Dependent coverage for Medical, Dental, Vision insurance  \n Employer paid Life and Short-Term Disability for the Employee  \n 401k with company match  \n Three (3) weeks of flexible, paid time off  \n One (1) week of sick leave  \n Ten (10) company-paid holidays  \n Company shutdown during the last week of the year (subject to business conditions)  \n And, more!", "cleaned_desc": " \n Telecommunications or high-tech (software development, software product companies) industry experience highly preferred.  \n Client-side experience as a Salesforce user, champion, administrator, etc.  \n Prior consulting experience highly preferred.  \n \n Requirements and Skills   \n \n BSc degree in Sales, Business Administration, or relevant field with 5+ years of related experience.  \n Required Salesforce Certifications ADM201 (Salesforce Certified Administrator), Sales or Service Cloud Consultant, Salesforce Certified  Business Analyst  (ok to achieve this within 30 days of hire)  \n Excellent analytical and problem-solving skills.  \n Hands on experience with CRM software and Account management systems, specifically Salesforce.  \n Ability to develop and maintain effective working relationships with others and display strong communication skills with colleagues and client stakeholders.  \n Self-motivated with the ability to manage time and resources effectively, meet deadlines and execute strategic objectives.  \n Adheres to Palladin\u2019s project methodology, while contributing to continuous process improvement.  ", "techs": ["salesforce"]}, "c187cc53b38f85d5": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["there are no specific tools or technologies mentioned in the given text."]}, "4812c35a0bf64856": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "requirements elicitation", "testing", "data analysis"]}, "9ec0c609ac98dee9": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "data analysis"]}, "d33f6b519054e3df": {"terms": ["data analyst"], "salary_min": 69643.44, "salary_max": 88184.11, "title": "Data Analyst", "company": "Netsmart Technologies", "desc": "Responsible for collecting and processing data to create engaging data visualizations and compelling statistical data insights\n  \n \n   Responsibilities\n  \n \n \n \n     Interpret data, analyze results using statistical techniques and provide ongoing reports\n    \n \n \n     Develop and implement databases, data collection systems, data analytics, reports, and other strategies that optimize statistical efficiency and quality\n    \n \n \n     Acquire data from primary or secondary data sources and maintain databases/data systems\n    \n \n \n     Identify, analyze, and interpret trends or patterns in complex data sets\n    \n \n \n     Filter and \u201cclean\u201d data by reviewing data analysis and BI reports, to locate trends and correct code problems\n    \n \n \n     Work with management to prioritize business and information needs\n    \n \n \n     Identify and define process improvement opportunities\n    \n \n \n \n   Qualifications\n    Required\n  \n \n \n \n     Bachelor\u2019s degree in Mathematics, Computer Science, Statistics, Economics, Information Management or related experience\n    \n \n \n     At least 1 year of professional business analytics experience including developing queries, report writing, and data visualization\n    \n \n \n     Experience with reporting packages (Microsoft SSRS, SAP Crystal Reports, etc.) and industry leading BI tools such as Power BI, Tableau or Qlik\n    \n \n \n     Experience with SQL and RDBMS databases\n    \n \n \n     Programming languages and coding technologies. Preferably VB.NET, Python, XML\n    \n \n \n     Experience analyzing large datasets from ETL frameworks\n    \n \n \n     Experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.)\n    \n \n \n     Experience with relational and NoSQL database systems\n    \n \n \n \n   Preferred\n  \n \n \n \n     Work experience in the healthcare industry including clinical, financial and operational data\n    \n \n \n \n   Netsmart is proud to be an equal opportunity workplace and is an affirmative action employer, providing equal employment and advancement opportunities to all individuals. We celebrate diversity and are committed to creating an inclusive environment for all associates. All employment decisions at Netsmart, including but not limited to recruiting, hiring, promotion and transfer, are based on performance, qualifications, abilities, education and experience. Netsmart does not discriminate in employment opportunities or practices based on race, color, religion, sex (including pregnancy), sexual orientation, gender identity or expression, national origin, age, physical or mental disability, past or present military service, or any other status protected by the laws or regulations in the locations where we operate.\n  \n \n \n   Netsmart desires to provide a healthy and safe workplace and, as a government contractor, Netsmart is committed to maintaining a drug-free workplace in accordance with applicable federal law. Pursuant to Netsmart policy, all post-offer candidates are required to successfully complete a pre-employment background check, including a drug screen, which is provided at Netsmart\u2019s sole expense. In the event a candidate tests positive for a controlled substance, Netsmart will rescind the offer of employment unless the individual can provide proof of valid prescription to Netsmart\u2019s third party screening provider.\n  \n \n \n  All applicants for employment must be legally authorized to work in the United States. Netsmart does not provide work visa sponsorship for this position.", "cleaned_desc": "Responsible for collecting and processing data to create engaging data visualizations and compelling statistical data insights\n  \n \n   Responsibilities\n  \n \n \n \n     Interpret data, analyze results using statistical techniques and provide ongoing reports\n    \n \n \n     Develop and implement databases, data collection systems, data analytics, reports, and other strategies that optimize statistical efficiency and quality\n    \n \n \n     Acquire data from primary or secondary data sources and maintain databases/data systems\n      \n   Qualifications\n    Required\n  \n \n \n \n     Bachelor\u2019s degree in Mathematics, Computer Science, Statistics, Economics, Information Management or related experience\n    \n \n \n     At least 1 year of professional business analytics experience including developing queries, report writing, and data visualization\n    \n \n \n     Experience with reporting packages (Microsoft SSRS, SAP Crystal Reports, etc.) and industry leading BI tools such as Power BI, Tableau or Qlik\n    \n   \n     Experience with SQL and RDBMS databases\n    \n \n \n     Programming languages and coding technologies. Preferably VB.NET, Python, XML\n    \n \n \n     Experience analyzing large datasets from ETL frameworks\n    \n \n \n     Experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.)\n    \n \n \n     Experience with relational and NoSQL database systems", "techs": ["microsoft ssrs", "sap crystal reports", "power bi", "tableau", "qlik", "sql", "rdbms", "vb.net", "python", "xml", "etl frameworks", "excel", "spss", "sas", "relational database systems", "nosql database systems"]}, "125f174b895b0bb6": {"terms": ["data analyst"], "salary_min": 92765.61, "salary_max": 117461.94, "title": "Business Analyst", "company": "Tunabear", "desc": "Work Location:  Remote \n \n  Contract through February 29 2024 \n \n \n Contract Type:  1099 | C2C \n \n  Open to visa workers with authorization to work in the US \n \n  Job Description \n \n  Application Reviewers will evaluate project narrative of the Initial Proposals. \n \n  Minimum Requirements \n \n \n \n Review grants applications assess the completeness and adequacy of the submission based on the requirements published \n Identify potential policy issues raised by an Eligible Entity\u2019s proposed approach \n Critically evaluate Eligible Entities\u2019 Initial Proposals and spot potential issues \n Proficiently synthesize review comments into coherent, actionable, and straightforward guidance to Eligible Entities \n Use an online tool/checklist and user guide and follow prescribed steps to review applications and move them forward in the application review process \n Support clients in the completion of their review \n Attend all required trainings; all trainings and technology enablement will be provided by the project team \n Be responsible for quality assurance practices and fostering completion and accuracy of tasks", "cleaned_desc": "", "techs": ""}, "16ec6df38447f8eb": {"terms": ["data analyst"], "salary_min": 102000.0, "salary_max": 142000.0, "title": "Customer Success Research Analyst", "company": "Truveta", "desc": "Customer Success Research Analyst \n  Truveta is the world's first health provider led data platform with a vision of Saving Lives with Data. Our mission is to enable researchers to find cures faster, empower every clinician to be an expert, and help families make the most informed decisions about their care. Achieving Truveta' s ambitious vision requires an incredible team of talented and inspired people with a special combination of health, software and big data experience who share our company values. \n  Truveta was born in the Pacific Northwest, but we have employees who live across the country. Our team enjoys the flexibility of a hybrid model and working from anywhere. In person attendance is required for two weeks during the year for Truveta Planning Weeks. \n  For overall team productivity, we optimize meeting hours in the pacific time zone. We avoid scheduling recurring meetings that start after 3pm PT, however, ad hoc meetings occur between 8am-6pm Pacific time. \n  Who We Need \n  Truveta is rapidly building a talented and diverse team to tackle complex health and technical challenges. Beyond core capabilities, we are seeking problem solvers, passionate and collaborative teammates, and those willing to roll up their sleeves while making a difference. If you are interested in the opportunity to pursue purposeful work, join a mission-driven team, and build a rewarding career while having fun, Truveta may be the perfect fit for you. \n \n  This Opportunity \n \n \n   This customer facing Customer Success Research Analyst role is a high impact, challenging role that requires a diverse set of skills. It provides unique opportunities for growth using an unprecedented amount of high-quality real-word Electronic Health Record (EHR) data. You will be solving consequential problems in healthcare using an EHR database of ~100 Million patients (and growing!) and make an impact on patient care. This position will report to our Director of Research Success on the Partner team and support strategic engagements with its Life Sciences partners.\n  \n \n \n \n  Responsibilities \n \n \n Use technical skills to scope out customer analyses requests, produce studies and results using SQL, R and Python within an agreed upon deadline. \n Collaborate with life sciences customers on analyses, helping them produce peer-reviewed publications. \n Communicate on the status of various projects and collaborate with success managers to ensure that Truveta clients can be successful with the platform. \n Required to excel in providing technical analytics support as well as directly working with customers on calls to troubleshooting customer analysis. \n Work with customers to achieve their goals, teaching them how to wrangle and analyze data using SQL, R and Python on RWD to address their empirical questions. \n Write regex queries using Databricks SQL to extract clinical concepts from clinical notes per customer request.  \n Create enablement materials as the Truveta platform evolves to help onboard new researchers to our increasing capabilities. \n Collaborate closely with other Truveta teams to conduct investigations of data sources to demonstrate veracity to current customers. \n Deliver feedback to internal teams based on customer requests to inform Truveta's product roadmap. \n \n \n Required Skills \n \n \n Undergraduate or graduate level  educational in clinical research, data analysis, clinical informatics or related field. \n Experience is working with large database consisting of millions of patients' data. \n 3+ years  of experience wrangling and analyzing  Electronic Health Record data  or other  Real World Data  sources in life science companies, CROs, other EHR data companies or healthcare using SQ, R and Python. \n Willingness to learn new coding languages including internal proprietary coding language to analyze data and build cohorts. \n 2+ year's  experience working with customers to deliver high quality research analyses. \n Ability to learn and adapt quickly in a dynamic start-up environment. \n \n \n Preferred Qualifications \n \n  These qualifications are preferred but not required, please do not let them stop you from applying for this role. You will likely get the opportunity to learn how to do these more advanced analyses if you don't already have experience with them. \n \n Regex query writing experience \n Statistics \n Regression \n Propensity Score Matching \n Kaplan-Meier Analyses \n Survival Analyses \n Spark/PySpark experience \n \n \n Why Truveta? \n \n  Be a part of building something special. Now is the perfect time to join Truveta. We have strong, established leadership with decades of success. We are well-funded. We are building a culture that prioritizes people and their passions across personal, professional and everything in between. Join us as we build an amazing company together. \n  We Offer: \n \n Interesting and meaningful work for every career stage \n Great benefits package \n Comprehensive benefits with strong medical, dental and vision insurance plans \n 401K plan \n Professional development & training opportunities for continuous learning \n Work/life autonomy via flexible work hours and flexible paid time off \n Generous parental leave \n Regular team activities (virtual and in-person as soon as we are able) \n The base pay for this position is $102,000 to $142,000. The pay range reflects the minimum and maximum target. Pay is based on several factors including location and may vary depending on job-related knowledge, skills, and experience. Certain roles are eligible for additional compensation such as incentive pay and stock options. \n \n If you are based in California, we encourage you to read this important information for California residents  linked   here. \n  Truveta is committed to creating a diverse, inclusive, and empowering workplace. We believe that having employees, interns, and contractors with diverse backgrounds enables Truveta to better meet our mission and serve patients and health communities around the world. We recognize that opportunities in technology historically excluded and continue to disproportionately exclude Black and Indigenous people, people of color, people from working class backgrounds, people with disabilities, and LGBTQIA+ people. We strongly encourage individuals with these identities to apply even if you don't meet all of the requirements.", "cleaned_desc": " \n \n  Responsibilities \n \n \n Use technical skills to scope out customer analyses requests, produce studies and results using SQL, R and Python within an agreed upon deadline. \n Collaborate with life sciences customers on analyses, helping them produce peer-reviewed publications. \n Communicate on the status of various projects and collaborate with success managers to ensure that Truveta clients can be successful with the platform. \n Required to excel in providing technical analytics support as well as directly working with customers on calls to troubleshooting customer analysis. \n Work with customers to achieve their goals, teaching them how to wrangle and analyze data using SQL, R and Python on RWD to address their empirical questions. \n Write regex queries using Databricks SQL to extract clinical concepts from clinical notes per customer request.  \n Create enablement materials as the Truveta platform evolves to help onboard new researchers to our increasing capabilities. \n Collaborate closely with other Truveta teams to conduct investigations of data sources to demonstrate veracity to current customers.   Deliver feedback to internal teams based on customer requests to inform Truveta's product roadmap. \n \n \n Required Skills \n \n \n Undergraduate or graduate level  educational in clinical research, data analysis, clinical informatics or related field. \n Experience is working with large database consisting of millions of patients' data. \n 3+ years  of experience wrangling and analyzing  Electronic Health Record data  or other  Real World Data  sources in life science companies, CROs, other EHR data companies or healthcare using SQ, R and Python. \n Willingness to learn new coding languages including internal proprietary coding language to analyze data and build cohorts. \n 2+ year's  experience working with customers to deliver high quality research analyses. \n Ability to learn and adapt quickly in a dynamic start-up environment. \n ", "techs": ["sql", "r", "python", "databricks"]}, "168fe7a7e2cd4462": {"terms": ["data analyst"], "salary_min": 73422.58, "salary_max": 92969.34, "title": "Business Analyst, Information Technology", "company": "CIEE Inc", "desc": "Position : Business Analyst, IT\n                    \n Reports to : Product Manager\n                    \n Department : Information Technology\n                    \n Location : US Remote (see location requirements below), Canada Remote\n                    \n  Who we are: \n  CIEE is a non-profit study abroad and intercultural exchange organization that transforms lives and builds bridges between individuals and nations through study abroad and international exchange experiences that help people develop skills for living in a globally interdependent and culturally diverse world. \n \n \n  Why work with us: \n \n \n  You will change the world . CIEE builds bridges between different people, different countries, and different cultures. We help young people participate in high-quality international exchange and study abroad programs that bring the world together. We change lives, our alumni change the world. Be part of the change! \n \n \n \n  You will receive a competitive total rewards package (only applicable for U.S. employees).  CIEE provides all employees with exceptional benefits offerings that increase total compensation by up to 25%. Our top-tier benefits include: \n \n \n \n  Paid time off and Parental leave \n  Gym Reimbursement Program \n  Employee Assistance Program \n  Short-term & Long-term Disability \n  6 floating Fridays (based on our eligibility rules) \n  CIEE Study Abroad and TEFL Program discounts \n  403(b) Retirement Plan with employer contribution \n  Insurance Coverage (life, travel, medical, dental, and vision) \n  Flexible Spending Accounts/Health Savings Accounts (medical and dependent) \n  Voluntary Benefits (identity theft protection, pet insurance, accident, and critical illness) \n \n \n \n \n  You will be part of a fast-paced, international, diverse, and collaborative team of professionals.  CIEE operates the largest nonprofit network of study-abroad locations, with facilities and staff in 26 countries. Additionally, we help international participants from over 130 countries come to the USA each year. Committed to excellence and solving whatever problem the world throws at them, CIEE professionals work on international teams and are dedicated to advancing our 75-year-old mission to make the world a more peaceful place. \n \n \n  Who you are: \n  CIEE\u2019s Business Analysts are a critical link between our engineering teams and business units. They support all functions involved in the design, development, documentation, training, testing, and maintenance of our software applications. These applications are used to market to, acquire, and support on-program CIEE participants. With a commitment to innovation, CIEE\u2019s Business Analysts are continually finding ways to improve our business processes and systems. \n  The Business Analyst is expected to have excellent communication skills, a knack for troubleshooting and tracking down elusive issues, and a desire to work in collaboration with Product Managers. \n  What you\u2019ll do : \n \n \n  Be an active member of an agile team(s) and follow the Scrum framework \n  Work side by side with engineering as well as multiple business units \n  Assist in translating roadmap features to epics and stories \n  Assist in developing and documenting business requirements \n  Create reports, dashboards, and metrics to showcase outcomes \n  Work closely with Product Managers on planning, refinement, and prioritization \n  Test and document systems, software, and services \n  Identify opportunities to improve efficiencies and performance with our systems, software, services, and ways of working \n \n  What you\u2019ll bring: \n \n \n  A minimum of 3 years of relevant experience \n  Excellent written and oral communication skills \u2013 including the ability to summarize and present complex information to all levels of the business \n  A driving curiosity to understand why and how things work (or don\u2019t) \n  An analytical mindset and strong problem-solving skills \n  Extreme attention to detail \n  Experience and competence in the analysis and comprehension of data \n  2 years of experience working with Salesforce \n  International Education/Exchange experience preferred \n  Readiness to grow and develop yourself, our client group, and our Company \n  Ability to embrace CIEE\u2019s Core Values (Excellence, Integrity, Respect, Inclusion, and Problem-Solving) and culture \n \n \n \n  Location Requirements: \n \n \n                      The position is available to candidates in the United States, \n                      except for candidates residing in :\n                     \n \n  New York (State and City) \n  Washington (State) \n  Colorado \n  California \n  Jersey City, NJ \n \n \n \n  Diversity Matters: \n  CIEE believes that diversity matters and that professionals with diverse backgrounds provide diverse approaches and ideas to solving problems and finding ways to advance our mission to bring the world together. Candidates from underrepresented groups with diverse backgrounds and experiences are strongly encouraged to apply. \n \n  Due to federal regulations, a background check will be conducted as a condition of employment.", "cleaned_desc": "  Work closely with Product Managers on planning, refinement, and prioritization \n  Test and document systems, software, and services \n  Identify opportunities to improve efficiencies and performance with our systems, software, services, and ways of working \n \n  What you\u2019ll bring: \n \n \n  A minimum of 3 years of relevant experience \n  Excellent written and oral communication skills \u2013 including the ability to summarize and present complex information to all levels of the business \n  A driving curiosity to understand why and how things work (or don\u2019t) \n  An analytical mindset and strong problem-solving skills \n  Extreme attention to detail \n  Experience and competence in the analysis and comprehension of data \n  2 years of experience working with Salesforce \n  International Education/Exchange experience preferred \n  Readiness to grow and develop yourself, our client group, and our Company \n  Ability to embrace CIEE\u2019s Core Values (Excellence, Integrity, Respect, Inclusion, and Problem-Solving) and culture ", "techs": ["salesforce"]}, "7d0c25194ac39c6f": {"terms": ["data analyst"], "salary_min": 50000.0, "salary_max": 50000.0, "title": "ELR Public Health Data Quality Analyst (HL7)", "company": "WiredPeople, Inc.", "desc": "Overview: \n  The Electronic Laboratory Reporting (ELR) Public Health Data Quality Analyst supports the ability to deploy data and analytical capabilities that scale rapidly in emergencies, provide predictive ability to identify emerging threats, reduce the burden on health care and public health partners reporting data, and ensure bidirectional data flow. This position requires a considerable exercise of independent judgment, excellent interpersonal skills, good computer skills, and the ability to perform against high standards of excellence. \n  Essential Functions / Responsibilities: \n \n  Perform daily review of data quality and active communication with facilities regarding ELR issues associated with file transfer and data quality. \n  Ensure file transport and processing of data from new and existing ELR senders. \n  Assist with operating the ELR helpdesk. \n  Ensure onboarding of ELR, including establishing transport, reviewing test messages, validating messages, providing feedback to partners on message content and structure issues, and providing technical assistance or support. \n  Conduct quality and field level completeness review of all data stored in the ELR database in accordance with the industry and  Health Level 7 (HL7)  translation standards. \n  Perform queries and produce ad hoc reports and datasets of ELR data collected by the Bureau of Epidemiology. \n  Participate in special surveillance projects during key events. \n  Assist with ELR data quality efforts including monitoring dashboards and infrastructure development to support data quality efforts. \n  Facilitate, attend, and participate in ELR team meetings. \n  Document and maintain business and system requirements, implementation guides, metadata documents, and processes as it relates to ELR. \n  Attend national ELR calls or trainings, quarterly grantee calls, and other relevant national calls or trainings related to the implementation of syndromic surveillance. \n  Assist with the submission of project deliverable updates for grants related to ELR to the Center for Disease Control. \n \n  Qualifications: \n \n  Bachelor's degree or equivalent work experience. \n  Two years of experience working in disease surveillance and surveillance systems. \n  Two years of experience working with electronic medical records using the  Health Level 7 (HL7)  messaging standard. \n  Two years of experience with data analysis, data integration or database management. \n  Two years of programming experience with Statistical Analysis Software (SAS), R software, Qlik, SQL, or Python software in the last five years. \n  Two years of programming experience with Statistical Analysis Software (SAS), R software, Qlik, SQL, or Python software in the last five years. \n  Two years of experience with and applying informatics principles for standardized vocabulary transport, and interoperability between systems. \n  Excellent organizational skills. \n \n  WiredPeople provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, WiredPeople complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. \n   \n jdjLSSJRIR", "cleaned_desc": "Overview: \n  The Electronic Laboratory Reporting (ELR) Public Health Data Quality Analyst supports the ability to deploy data and analytical capabilities that scale rapidly in emergencies, provide predictive ability to identify emerging threats, reduce the burden on health care and public health partners reporting data, and ensure bidirectional data flow. This position requires a considerable exercise of independent judgment, excellent interpersonal skills, good computer skills, and the ability to perform against high standards of excellence. \n  Essential Functions / Responsibilities: \n \n  Perform daily review of data quality and active communication with facilities regarding ELR issues associated with file transfer and data quality. \n  Ensure file transport and processing of data from new and existing ELR senders.   \n  Bachelor's degree or equivalent work experience. \n  Two years of experience working in disease surveillance and surveillance systems. \n  Two years of experience working with electronic medical records using the  Health Level 7 (HL7)  messaging standard. \n  Two years of experience with data analysis, data integration or database management. \n  Two years of programming experience with Statistical Analysis Software (SAS), R software, Qlik, SQL, or Python software in the last five years. ", "techs": ["hl7", "sas", "r software", "qlik", "sql", "python"]}, "22a372ccecc4d3fe": {"terms": ["data analyst"], "salary_min": 95673.08, "salary_max": 121143.44, "title": "Power BI Data Analyst", "company": "Octo", "desc": "Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes. \n  Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region\u2019s best places to work multiple times, Octo is an employer of choice! \n You\u2026 \n  As a  Power BI Data Analyst  with Octo, you will support an initiative within the Department of Veterans Affairs (VA). This role will support efforts to transform an enterprise level environment by leveraging data and analytics to support strategic and tactical business decisions. This is an opportunity for an enthusiastic and analytical professional that wants to help grow the business intelligence function within the program. The Data Analyst will be expected to analyze and create data sets from disparate data sources analyze and translate the results into non-technical insights for users to consume across the organization. The qualified candidate will have experience with supporting business, functional, and technical activities. They will have experience working with customers, users and project leads in analyzing, designing, implementing, and supporting analytics solutions. The initial efforts will be focused on Data Analysis and Business Intelligence reporting. Must have experience with Power BI.  \n Us\u2026   \n We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client\u2019s missions. \n  Program Mission\u2026 \n  The Digital Transformation Center (DTC) supports Veterans Affairs (VA) with onboarding and maintaining enterprise SaaS and PaaS solutions used to support the mission of serving our Veterans and their associated stakeholders. We are digitizing information and processes for improved implementation, leveraging modern tools and low code/no code for reusability and faster delivery. \n  Requirements: \n \n   \n Octo is an Equal Opportunity/Affirmative Action employer. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation. \n  Octo is an IBM subsidiary which has been acquired by IBM and will be integrated into the IBM organization. Octo will be the hiring entity. By proceeding with this application, you understand that Octo will share your personal information with other IBM affiliates involved in your recruitment process, wherever these are located. More Information on how IBM protects your personal information, including the safeguards in case of cross-border data transfer, are available here:   https://www.ibm.com/careers/us-en/privacy-policy/ \u201d. \n \n \n Responsibilities\u2026 \n \n Research and develop data and statistical models for analysis. \n Analyze and model structured data using advanced statistical methods and implement algorithms and software needed to perform analyses. \n Collaborate with client to understand and recommend activities related to Analytics. \n Analyze data, data sets and create data sets. \n Analyze broad data sets and provides actionable insights to better inform business decisions.  \n Develop and document overall data sourcing, data transformation and semantic layer designs.  \n Develop ETL data flows between data sources as required to create data sets and perform analysis. \n Integrates and prepares large, varied datasets for analysis. Identify and assess data attributes using statistical software packages in order to develop recommendations and analytical processes based on mission requirements. \n Researches, develops, implements and utilizes statistical methods and strategies to address tactical and strategic problem sets, while working with a technical team. \n Interprets and analyzes data collected from a variety of sources using exploratory and statistical techniques, validating findings using an experimental and iterative approach. \n \n Requirements... \n \n At least 5 years related experience in business intelligence and analytics performing increasingly complex data analysis and report/dashboard development. \n Must have at least 5-8 years of related experience data modeling, report/dashboard development using Power BI and other business intelligence tools.  \n Proficiency querying PaaS data sources including Salesforce and D365/Azure environments. \n Experience working with unstructured, structured data including CSV, XML, SQL. \n Proven ability to analyze data sets, identify patterns and draw insights. \n Ability to clearly communicate both verbally and in writing with client and team members. This will include experience documenting and presenting findings. \n Excellent analytical skills, organizational abilities and problem-solving skills. \n Self-starter who works efficiently in a fast-paced environment with changing priorities. \n Must be able to obtain and maintain public trust clearance. \n \n Desired Skills... \n \n Demonstrated experience in the use of Scrum and Agile methodology and processes. \n Experience supporting Department of Veterans Affairs or other federal organizations. \n Prefer current Power BI certifications. \n \n \n \n  Years of Experience : 5+ years of related experience data modeling, report/dashboard development using Power BI and other business intelligence tools. \n  Education : Bachelor's Degree or 4 years of related experience. \n  Location : Remote within the United States. \n  Clearance : Ability to obtain and maintain a Public Trust security clearance.", "cleaned_desc": " Analyze data, data sets and create data sets. \n Analyze broad data sets and provides actionable insights to better inform business decisions.  \n Develop and document overall data sourcing, data transformation and semantic layer designs.  \n Develop ETL data flows between data sources as required to create data sets and perform analysis. \n Integrates and prepares large, varied datasets for analysis. Identify and assess data attributes using statistical software packages in order to develop recommendations and analytical processes based on mission requirements. \n Researches, develops, implements and utilizes statistical methods and strategies to address tactical and strategic problem sets, while working with a technical team. \n Interprets and analyzes data collected from a variety of sources using exploratory and statistical techniques, validating findings using an experimental and iterative approach. \n \n Requirements... \n   At least 5 years related experience in business intelligence and analytics performing increasingly complex data analysis and report/dashboard development. \n Must have at least 5-8 years of related experience data modeling, report/dashboard development using Power BI and other business intelligence tools.  \n Proficiency querying PaaS data sources including Salesforce and D365/Azure environments. \n Experience working with unstructured, structured data including CSV, XML, SQL. \n Proven ability to analyze data sets, identify patterns and draw insights. \n Ability to clearly communicate both verbally and in writing with client and team members. This will include experience documenting and presenting findings. \n Excellent analytical skills, organizational abilities and problem-solving skills. \n Self-starter who works efficiently in a fast-paced environment with changing priorities. \n Must be able to obtain and maintain public trust clearance. \n   Desired Skills... \n \n Demonstrated experience in the use of Scrum and Agile methodology and processes. \n Experience supporting Department of Veterans Affairs or other federal organizations. \n Prefer current Power BI certifications. \n \n \n \n  Years of Experience : 5+ years of related experience data modeling, report/dashboard development using Power BI and other business intelligence tools. \n  Education : Bachelor's Degree or 4 years of related experience. ", "techs": ["data analysis", "data sets", "data sourcing", "data transformation", "etl", "statistical software packages", "statistical methods", "exploratory analysis", "statistical techniques", "business intelligence", "analytics", "data modeling", "power bi", "paas", "salesforce", "d365", "azure", "unstructured data", "structured data", "csv", "xml", "sql", "patterns", "insights", "communication", "problem-solving", "scrum", "agile methodology", "department of veterans affairs"]}, "5b98acb584bb029d": {"terms": ["data analyst"], "salary_min": 64549.266, "salary_max": 81733.75, "title": "Business Systems Analyst", "company": "Zenith American", "desc": "Title:  Business System Analyst  Department:  Platform: Claims \n  Position Type:  Exempt  Hours per Week:  40 \n  Position Summary: \n  Analyzes system-related situations, writes system specifications, designs and develops ad hoc and standard reports, and performs/assists with testing and implementation in accordance with Company guidelines, client needs and legislative requirements. \n  NOTE:  Position requires access to Personally Identifiable Information and/or Personal Health Information to complete job requirements.  \n General Duties: \n \n  Conducts best practice requirements engineering steps, including elicitation, analysis, solution implementation, negotiation, and documentation. \n  Formulate and document test plans and test cases. Test programming changes due to bug fixes, enhancements, development, and version upgrades. Collaborate with programmers to drive quality output. \n  Conduct and document testing activities including, but not limited to, functional testing, regression testing, usability testing, and performance testing. \n  Analyzes data files to and from trading partners, file formats and problems related to client conversions and implementations. \n  Analyzes the impact of compliance and regulation changes to existing programs and data file interfaces. \n  Writes detailed design specifications for data conversions; coordinates and monitors data interfaces with trading partners, vendors and clients. \n  Owns business as usual (BAU) ticket items from triage to resolution. Evaluates and tests ad-hoc and canned reports, queries, data extracts and procedures for IT systems, including forms and mailings. \n  Develops, coordinates, and supports installation plans for new client implementations, to include trading partner coordination and testing. \n  Provides technical support, training, and problem resolution to super users in the operations community. \n  Documents system and client support processes and procedures, to include process improvement recommendations  \n Performs other similar and related duties as required. \n \n  Minimum Qualifications: \n \n  Associate's degree in Computer Science, IT or two years of technical training. An equivalent combination of experience and education may be acceptable. \n  Two to three years of related experience. \n  SQL Knowledge used to develop reports \n  Reporting Experience \n  Healthcare/Claims Experience and X12 experience is preferred \n  Basic understanding of business practices with good understanding of project management methodology needed. \n  Ability to understand database systems and excellent knowledge of Microsoft Office. \n  Strong organizational, analytical, problem-solving, and time-management skills.  \n Ability to exercise independent judgment. \n  Excellent attention to detail. \n  Excellent oral and written communication skills, including the ability to work with diverse group of professionals in close cooperation. \n \n  Zenith American Solutions \n  Real People. Real Solutions. National Reach. Local Expertise. \n  We are currently seeking an experienced  Business Systems Analyst  with the necessary skills, initiative, and personality, along with the desire to get the most out of their working life, to help us be our best every day. \n  Zenith American Solutions is the largest independent Third Party Administrator in the United States and currently operates over 40 offices nationwide. The original entity of Zenith American has been in business since 1944. Our company was formed as the result of a merger between Zenith Administrators and American Benefit Plan Administrators in 2011. By combining resources, best practices and scale, the new organization is even stronger and better than before \n  We realize the importance a comprehensive benefits program to our employees and their families. As part of our total compensation package, we offer an array of benefits including health, vision, and dental coverage, a retirement savings 401(k) plan with company match, paid time off (PTO), great opportunities for growth, and much, much more! \n  Internals to Apply: \n  If you meet the minimum qualifications and are interested in applying for the above position, please submit an application. All applications must be received by 5:00 pm on the Internal Posting Deadline listed above in order to be considered prior", "cleaned_desc": "  Conducts best practice requirements engineering steps, including elicitation, analysis, solution implementation, negotiation, and documentation. \n  Formulate and document test plans and test cases. Test programming changes due to bug fixes, enhancements, development, and version upgrades. Collaborate with programmers to drive quality output. \n  Conduct and document testing activities including, but not limited to, functional testing, regression testing, usability testing, and performance testing. \n  Analyzes data files to and from trading partners, file formats and problems related to client conversions and implementations. \n  Analyzes the impact of compliance and regulation changes to existing programs and data file interfaces. \n  Writes detailed design specifications for data conversions; coordinates and monitors data interfaces with trading partners, vendors and clients. \n  Owns business as usual (BAU) ticket items from triage to resolution. Evaluates and tests ad-hoc and canned reports, queries, data extracts and procedures for IT systems, including forms and mailings.    Associate's degree in Computer Science, IT or two years of technical training. An equivalent combination of experience and education may be acceptable. \n  Two to three years of related experience. \n  SQL Knowledge used to develop reports \n  Reporting Experience \n  Healthcare/Claims Experience and X12 experience is preferred \n  Basic understanding of business practices with good understanding of project management methodology needed. \n  Ability to understand database systems and excellent knowledge of Microsoft Office. ", "techs": ["requirements engineering", "test plans", "test cases", "functional testing", "regression testing", "usability testing", "performance testing", "data files", "compliance", "regulation changes", "design specifications", "data conversions", "data interfaces", "triage", "ad-hoc reports", "canned reports", "sql", "reporting", "x12", "project management methodology", "database systems", "microsoft office"]}, "85782d9a0b8f1600": {"terms": ["data analyst"], "salary_min": 95968.0, "salary_max": 143952.0, "title": "Lead IT Business Analyst", "company": "The Mom Project", "desc": "***The salary range for this position is $95,968.00 - $143,952.00 per year.*** \n The Mom Project is excited to partner with Kellanova in their search for a Lead IT Business Analyst . This role is 100% remote in Chicago, IL. \n Kellanova is a leader in global snacking, international cereal and noodles, and North America frozen foods with a legacy stretching back more than 100 years. Powered by differentiated brands including Pringles\u00ae, Cheez-It\u00ae, Pop-Tarts\u00ae, Kellogg Rice Krispies Treats\u00ae, RXBAR\u00ae, Eggo\u00ae, MorningStar Farms\u00ae, Special K\u00ae, Coco Pops\u00ae, and more, Kellanova\u2019s vision is to become the world\u2019s best-performing snacks-led powerhouse, unleashing the full potential of our differentiated brands and our passionate people. Kellanova generated an estimated $12.6 billion in net sales in 2022. \n Kellanova is guided by our purpose to create better days and a place at the table for everyone through our trusted food brands. We are advancing sustainable and equitable access to food by addressing the intersection of hunger, sustainability, well-being, and equity, diversity & inclusion, with the ambition of creating Better Days for 4 billion people by the end of 2030. Visit www.Kellanova.com for more information. \n Description \n As an IT Business Analyst Lead you will learn, grow, and create innovative technology solutions to help our business flourish. This critical role will establish and maintain a strategic relationship with our key North America and global stakeholders and others in Research and Development (R&D), defining IT strategy and delivering solutions that enable the function to meet its goals. \n At the heart of Kellanova is technology \u2014 a key enabler of how we market, sell and manufacture our well-known and beloved brands to consumers around the globe. Be a part of a leading company in global snacking, international cereal and noodles, and North America frozen foods, with iconic, world-class brands including Pringles, Cheez-It, and Pop-Tarts. \n A Taste of What You\u2019ll Be Doing \n Partner with IT and the R&D Business Function - This critical role will be the IT Business Analyst for all KNA R&D technology solutions for our function. In this role, you will be working closely with R&D leadership and global key stakeholders across the organization in designing and delivering technology capabilities and driving projects, roadmaps, strategy, and total cost of ownership \n Business Case Development - Works with business teams to understand project requirements, shapes the initial project request, and provides a high-level estimate of the project effort and cost used in cost-benefit analysis. Plan expenditures based on the size, scope, and cost of hardware and software components. Reviews and evaluates business cases to confirm identified financials and risks, validate value and business alignment, and recommend a course of action \n Requirements Documentation \u2013 Works with business and project teams to capture and document requirements and expected functionality of the proposed solution. Leads clarification and validation of requirements during the development and delivery of the solution. Works closely with IT architects, security, delivery partners, and others to ensure a safe and successful solution launch \n Deliver IT Projects - You\u2019ll deliver the technology platform strategy by providing leadership to our project teams and driving the successful delivery of capabilities within the function. You will manage the Regional R&D platform(s) from an IT product perspective including vendor and Global IT relationships \n Your Recipe for Success \n A Bachelor\u2019s degree in Computer Science, Information Systems, Business Administration, or related field, or equivalent work experience \n Experience implementing and working with industry-leading Research & Development platforms such as SAP Recipe Management, SAP Product Lifecycle Management, Ideation technologies, Microsoft Portfolio Management Tools, and Analytics (ie. Tableau, Power BI) solutions \n Experience managing a product line and clearly articulating the total cost of ownership to leadership \n Strong analytical, project management, and team leadership skills \n Strong background in systems/software development lifecycle \n Excellent written and verbal communication \n Experience in CPG (Consumer Packaged Goods) industry \n PMP, Agile, or similar Certification \n What\u2019s Next \n After you apply, your application will be reviewed by a real recruiter \u2013 not a bot. This means it could take us a little while to get back to you so watch your inbox for updates. In the meantime, visit our How We Hire page to get insights into our hiring process and how to best prepare for a Kellanova interview. \n If we can help you with reasonable accommodation throughout the application or hiring process, please email USA.Recruitment@Kellanova.com. \n About Kellanova \n Kellanova is a leading company in global snacking, international cereal and noodles, plant-based foods, and North America frozen breakfast, and a portfolio of iconic, world-class brands, including Pringles, Cheez-It, Pop-Tarts, Kellogg\u2019s Rice Krispies Treats, MorningStar Farms, Incogmeato, Gardenburger, Nutri-Grain, RXBAR, and Eggo. We also steward a suite of beloved international cereal brands, including Kellogg\u2019s, Frosties, Zucaritas, Special K, Krave, Miel Pops, Coco Pops, and Crunchy Nut, among others. \n At Kellanova, we are committed to Equity, Diversity, and Inclusion (ED&I), uplifting each other and embracing our differences to achieve our common goals. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, and ideas, and can bring their authentic selves to work. Learn more here. \n We\u2019re proud to offer industry-competitive Total Health benefits (Physical, Financial, Emotional, and Social) that vary depending on region and type of role. Be sure to ask your recruiter for more information!", "cleaned_desc": " Requirements Documentation \u2013 Works with business and project teams to capture and document requirements and expected functionality of the proposed solution. Leads clarification and validation of requirements during the development and delivery of the solution. Works closely with IT architects, security, delivery partners, and others to ensure a safe and successful solution launch \n Deliver IT Projects - You\u2019ll deliver the technology platform strategy by providing leadership to our project teams and driving the successful delivery of capabilities within the function. You will manage the Regional R&D platform(s) from an IT product perspective including vendor and Global IT relationships \n Your Recipe for Success \n A Bachelor\u2019s degree in Computer Science, Information Systems, Business Administration, or related field, or equivalent work experience \n Experience implementing and working with industry-leading Research & Development platforms such as SAP Recipe Management, SAP Product Lifecycle Management, Ideation technologies, Microsoft Portfolio Management Tools, and Analytics (ie. Tableau, Power BI) solutions   Experience managing a product line and clearly articulating the total cost of ownership to leadership \n Strong analytical, project management, and team leadership skills \n Strong background in systems/software development lifecycle \n Excellent written and verbal communication \n Experience in CPG (Consumer Packaged Goods) industry ", "techs": ["sap recipe management", "sap product lifecycle management", "ideation technologies", "microsoft portfolio management tools", "tableau", "power bi"]}, "b8d5eb9437b4e9c1": {"terms": ["data analyst"], "salary_min": 106200.0, "salary_max": 242000.0, "title": "Business Analyst", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Leavenworth,KS,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0183430\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Business Analyst\n           The Opportunity: \n  As a defense mission professional, you ask questions others don\u2019t. You understand the nuances of complex situations. You use your skills to think bigger and push further, solving complex problems. We\u2019re looking for an expert like you to drive solutions for missions that keep our nation safe. \n \n  As a defense mission professional, you\u2019ll bring your analytical and technical expertise as you lead a team on projects across the training and simulation community. You\u2019ll develop, analyze, and assess current capability solutions while seeking growth opportunities. You\u2019ll be a trusted advisor to our clients, and we\u2019ll look to you to identify, analyze, and evaluate complex systems, policies, and processes. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  15+ years of experience with the Military \n  2+ years of experience with contract project and program management \n  Experience with Army and Joint Doctrine and Training Policy \n  Experience with integrating Joint Land Component Constructive Training Capability (JLCCTC) training enablers \n  Experience with Office 365 products \n  Secret clearance \n  Bachelor's degree \n \n  Nice If You Have: \n \n  Experience with leading support functions \n  Experience with contract financial management and program planning \n  Experience with hiring, staffing, and recruitment activities \n  Ability to pay strict attention to detail \n  Possession of excellent verbal and written communication skills \n  Possession of excellent problem-solving skills \n  TS/SCI clearance \n  Master's degree \n  Program Management Professional (PMP) Certification \n \n \n  Clearance:   Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n  Grow With Us  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $106,200.00 to $242,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  15+ years of experience with the Military \n  2+ years of experience with contract project and program management \n  Experience with Army and Joint Doctrine and Training Policy \n  Experience with integrating Joint Land Component Constructive Training Capability (JLCCTC) training enablers \n  Experience with Office 365 products \n  Secret clearance \n  Bachelor's degree \n \n  Nice If You Have: \n \n  Experience with leading support functions \n  Experience with contract financial management and program planning \n  Experience with hiring, staffing, and recruitment activities \n  Ability to pay strict attention to detail \n  Possession of excellent verbal and written communication skills \n  Possession of excellent problem-solving skills \n  TS/SCI clearance \n  Master's degree \n  Program Management Professional (PMP) Certification \n ", "techs": ["army", "joint doctrine and training policy", "jlcctc", "office 365", "secret clearance", "leading support functions", "contract financial management", "program planning", "hiring", "staffing", "recruitment activities", "attention to detail", "verbal communication skills", "written communication skills", "problem-solving skills", "ts/sci clearance", "master's degree", "pmp certification"]}, "e960a2372eb550e8": {"terms": ["data analyst"], "salary_min": 55000.0, "salary_max": 85000.0, "title": "Data Analyst", "company": "Ohio Shared Information Services Inc", "desc": "The Data Analyst is responsible for understanding business requirements and designing data models to transform raw data into meaningful insights. They will be responsible for designing data pipelines and infrastructure, developing reports and dashboards, interpreting data, and communicating to technical and non-technical audiences. The individual in this role must be analytical and resourceful, have excellent communication skills, and can work directly with end users and stakeholders. \n \n  ESSENTIAL JOB FUNCTIONS: \n \n  Develops professional-quality business intelligence, data visualization, and analytics content in support of OSIS\u2019s strategic priorities, using Power BI and Crystal Reports. \n  Provide Subject Matter Expertise (SME) support in common functions of the BI technologies including reporting, analytics, analytical processing, data transformation, and data. \n \n \n  Identify, design, and implement internal process improvements, such as automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. \n  Optimizes performance and usability of Power BI reports and dashboards by tuning queries, implementing efficient data models, and applying best practices. \n  Collaborates with business stakeholders to understand their requirements, translates them into technical specifications, and designs efficient and visually appealing Power BI reports and dashboards. \n  Provides a high level of internal and external customer service. \n \n \n  REQUIRED EDUCATION AND EXPERIENCE: \n \n  BS degree in Computer Science or Computer Engineering, or equivalent experience \n  Minimum 2 years of demonstrated experience developing accurate, effective, and appealing visualizations using Microsoft Power BI. \n  Knowledge of Power BI application security layer models \n  Proficient in SQL, T-SQL, and SQL Server Management Studio \n  Strong Knowledge of DW architecture and ETL frameworks \n  Understand relational Database concepts, including normalization and query optimization \n \n \n  PREFERRED EXPERIENCE: \n \n  Experience using Azure Data Factory (ADF), building and managing data pipelines to enable the flow of data into an Azure-based Enterprise Data Platform \n  Experience developing reports with Crystal Reports \n  Familiar with Azure DevOps, Agile development, and Git", "cleaned_desc": "The Data Analyst is responsible for understanding business requirements and designing data models to transform raw data into meaningful insights. They will be responsible for designing data pipelines and infrastructure, developing reports and dashboards, interpreting data, and communicating to technical and non-technical audiences. The individual in this role must be analytical and resourceful, have excellent communication skills, and can work directly with end users and stakeholders. \n \n  ESSENTIAL JOB FUNCTIONS: \n \n  Develops professional-quality business intelligence, data visualization, and analytics content in support of OSIS\u2019s strategic priorities, using Power BI and Crystal Reports.    Provide Subject Matter Expertise (SME) support in common functions of the BI technologies including reporting, analytics, analytical processing, data transformation, and data. \n \n \n  Identify, design, and implement internal process improvements, such as automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. \n  Optimizes performance and usability of Power BI reports and dashboards by tuning queries, implementing efficient data models, and applying best practices.   \n  BS degree in Computer Science or Computer Engineering, or equivalent experience \n  Minimum 2 years of demonstrated experience developing accurate, effective, and appealing visualizations using Microsoft Power BI. \n  Knowledge of Power BI application security layer models \n  Proficient in SQL, T-SQL, and SQL Server Management Studio ", "techs": ["power bi", "crystal reports", "sql", "t-sql", "sql server management studio"]}, "f9945f7095c07a46": {"terms": ["data analyst"], "salary_min": 92493.555, "salary_max": 117117.445, "title": "LU Tableau Developer/Data Visualization", "company": "FOCUSED HR SOLUTIONS LLC", "desc": "** Candidates will be allowed to work 100% remotely. Candidates must be able to come ONSITE to Richmond, VA to pick up laptop and complete orientation, NO exceptions. Candidate must work EST Business Hours. \n **  Our direct client has an opening for a Tableau Developer/Data Visualization Specialist position # 702041. This position is for 6-12+ months, with option of extension, and will be worked in remotely (must work EST business hours). If you are interested, please submit the following:YOUR CURRENT RESUMEYOUR HOURLY RATE Below is the job description \u2013 Resumes due ASAP \u2013 Description: Data Visualization Specialist who can analyze data from multiple sources of health-related information, create visualizations, and assist in support and training of public health based Tableau Desktop content creators Work on the analytics team, with technical and business stewards to help synthesize questions, understand the data structures and query the correct answer in way that is easily understood. Assisting business users in coming up with the right data and visualization solutions for their requirements which will involve rapidly transforming raw data into actionable information using ETL, analytics and visualization tools and techniques Analyze, define requirements, develop, and create documentation for dashboards. Design data models and data architecture. Champion dashboard quality, consistency, usability and reliability by documenting and applying best practices to design and development. Define and interpret SQL queries (Microsoft SQL Server, Oracle, BigQuery). Collaborate with technical staff and end users to understand and troubleshoot platform issues and develop appropriate solutions. Spread awareness and offer assistance in ensuring proper public accessibility standards for dashboards. Integrate various datasets and build data models for visualization in Tableau or Power BI or using data gateways. Assist in license management for Tableau Desktop users Assist, guide, and provide support to Tableau Desktop users to create effective visualizations and dashboards. Utilize Tableau Prep for optimal data structuring before visualization. Support the data curation process by feeding the data catalog and knowledge base with key information. Contributes to strategic planning meetings and provides guidance and expertise on system options, risk, cost vs benefit analysis etc. Creates proof of concepts and prototypes on implementation/use new BI software tools/systems. Required Qualifications* Bachelor Degree in Computer Science, Management Information Systems, Business or related field* Demonstrated successful organizational, creativity, and problem-solving skills* Ability to multi-task and manage time effectively.* Working knowledge of databases and database system structures. (Education can substitute for this skill)* 3+ years of experience in visual report building, development of analytics dashboards, and working with complex data sets* 3+ years of Tableau Dashboard experience* Working Experience with Tableau Desktop 2021.2 or higher* Advanced knowledge of Tableau Desktop content creation* Working experience on data modeling and data integration using databases like SQL Server and Oracle* Excellent visual skills, including demonstrable design knowledge, such as layout, typography, color, and interaction design* 3+ years of experience working with data stewards and executive leadership* Strong communication skills (verbal and written) and attention to detail* Creative vision, a passion for learning and willingness to adopt and share new ideas. Required/Desired Skills: Bachelor Degree in Computer Science, Management Information Systems, Business or related Field - Required - 3 YearsDemonstrated successful organizational creativity, and proven problem solving skills - Required - 3 YearsAbility to multi-task and manage time effectively - Required - 3 YearsWorking knowledge of Databases and Database system structures. (Education can substitute for this skill) - Required - 3 Years3+ years of experience in visual reporting, building, development of analytics, dashboards and working with complex data sets. - Required - 3 Years3+ years Tableau Dashboard experience - Required - 3 YearsWorking experience with Tableau Desktop 2021.2 or higher - Required - 3 YearsAdvanced knowledge of Tableau Desktop and content creation - Required - 3 YearsWorking experience in data modeling and data integration using Databases like SQL Services and Oracle - Required - 3 YearsExcellent visual skills, including demonstrable design knowledge such as layout, typography, color, and interaction design - Required - 3 YearsStrong Communication skills (verbal and written) and attention to detail - Required - 3 YearsCreative vision, a passion for learning and willingness to adopt and share new ideas - Required - 3 YearsPublic Health Experience - Desired - 3 YearsData Modeling - Desired - 3 YearsData Integration - Desired - 3 YearsAuthoring Tableau Prep Flows - Desired - 3 YearsFamiliarity with Power BI - Desired - 3 YearsR and /or Python Scripting experience - Desired - 3 Years\n  \n  By replying to this job advertisement, I agree I want to receive additional job advertisements from Focused HR Solutions, including email, phone and mail to the contact information I am submitting. I consent to Focused HR Solutions, its affiliates, third parties and partners processing my personal data for these purposes and as described in the Privacy Policy. I understand that I can withdraw my consent at any time.\n  \n This is a remote position.", "cleaned_desc": " **  Our direct client has an opening for a Tableau Developer/Data Visualization Specialist position # 702041. This position is for 6-12+ months, with option of extension, and will be worked in remotely (must work EST business hours). If you are interested, please submit the following:YOUR CURRENT RESUMEYOUR HOURLY RATE Below is the job description \u2013 Resumes due ASAP \u2013 Description: Data Visualization Specialist who can analyze data from multiple sources of health-related information, create visualizations, and assist in support and training of public health based Tableau Desktop content creators Work on the analytics team, with technical and business stewards to help synthesize questions, understand the data structures and query the correct answer in way that is easily understood. Assisting business users in coming up with the right data and visualization solutions for their requirements which will involve rapidly transforming raw data into actionable information using ETL, analytics and visualization tools and techniques Analyze, define requirements, develop, and create documentation for dashboards. Design data models and data architecture. Champion dashboard quality, consistency, usability and reliability by documenting and applying best practices to design and development. Define and interpret SQL queries (Microsoft SQL Server, Oracle, BigQuery). Collaborate with technical staff and end users to understand and troubleshoot platform issues and develop appropriate solutions. Spread awareness and offer assistance in ensuring proper public accessibility standards for dashboards. Integrate various datasets and build data models for visualization in Tableau or Power BI or using data gateways. Assist in license management for Tableau Desktop users Assist, guide, and provide support to Tableau Desktop users to create effective visualizations and dashboards. Utilize Tableau Prep for optimal data structuring before visualization. Support the data curation process by feeding the data catalog and knowledge base with key information. Contributes to strategic planning meetings and provides guidance and expertise on system options, risk, cost vs benefit analysis etc. Creates proof of concepts and prototypes on implementation/use new BI software tools/systems. Required Qualifications* Bachelor Degree in Computer Science, Management Information Systems, Business or related field* Demonstrated successful organizational, creativity, and problem-solving skills* Ability to multi-task and manage time effectively.* Working knowledge of databases and database system structures. (Education can substitute for this skill)* 3+ years of experience in visual report building, development of analytics dashboards, and working with complex data sets* 3+ years of Tableau Dashboard experience* Working Experience with Tableau Desktop 2021.2 or higher* Advanced knowledge of Tableau Desktop content creation* Working experience on data modeling and data integration using databases like SQL Server and Oracle* Excellent visual skills, including demonstrable design knowledge, such as layout, typography, color, and interaction design* 3+ years of experience working with data stewards and executive leadership* Strong communication skills (verbal and written) and attention to detail* Creative vision, a passion for learning and willingness to adopt and share new ideas. Required/Desired Skills: Bachelor Degree in Computer Science, Management Information Systems, Business or related Field - Required - 3 YearsDemonstrated successful organizational creativity, and proven problem solving skills - Required - 3 YearsAbility to multi-task and manage time effectively - Required - 3 YearsWorking knowledge of Databases and Database system structures. (Education can substitute for this skill) - Required - 3 Years3+ years of experience in visual reporting, building, development of analytics, dashboards and working with complex data sets. - Required - 3 Years3+ years Tableau Dashboard experience - Required - 3 YearsWorking experience with Tableau Desktop 2021.2 or higher - Required - 3 YearsAdvanced knowledge of Tableau Desktop and content creation - Required - 3 YearsWorking experience in data modeling and data integration using Databases like SQL Services and Oracle - Required - 3 YearsExcellent visual skills, including demonstrable design knowledge such as layout, typography, color, and interaction design - Required - 3 YearsStrong Communication skills (verbal and written) and attention to detail - Required - 3 YearsCreative vision, a passion for learning and willingness to adopt and share new ideas - Required - 3 YearsPublic Health Experience - Desired - 3 YearsData Modeling - Desired - 3 YearsData Integration - Desired - 3 YearsAuthoring Tableau Prep Flows - Desired - 3 YearsFamiliarity with Power BI - Desired - 3 YearsR and /or Python Scripting experience - Desired - 3 Years", "techs": ["tableau", "power bi", "sql server", "oracle", "tableau desktop", "tableau prep", "sql", "microsoft sql server", "bigquery", "databases", "visualization tools", "etl", "analytics", "data modeling", "data integration", "data structures", "layout", "typography", "color", "interaction design", "public health", "r", "python"]}, "d8e241ac9fc8201b": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "requirements elicitation", "testing", "data analysis"]}, "69eea40ade835bbc": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "requirements elicitation", "testing", "data analysis"]}, "e67063cad819eb00": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "testing", "data analysis"]}, "cff5d0a3eb4d0d60": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "requirement elicitation", "testing", "data analysis"]}, "2226a28510e6dfa1": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "data analysis"]}, "bd53808a485d6f38": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "data analysis"]}, "d669eb1c1896cee0": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "data analysis"]}, "434352340fbca1f5": {"terms": ["data analyst"], "salary_min": 67185.41, "salary_max": 85071.69, "title": "Business Analyst", "company": "Tree Top Staffing LLC", "desc": "We are looking for a Business Analyst who will play the main role in linking information technology capacity and business objectives. Your main goal will be to support and ensure the successful completion of analytical, building, testing and deployment tasks.\n  \n \n Responsibilities: \n \n \n \n Define configuration specifications \n Define business requirements \n Define KPIs and reporting requirements \n Own and develop relationship with partners \n Work with partners to optimize and enhance our integration \n Help design, document and maintain system processes \n Report on common sources of technical issues or questions \n Make recommendations to product team \n Excellent communicate skills \n Find and communicate key insights and findings to product team \n Perform Quality Assurance \n Constantly be on the lookout for ways to improve monitoring \n Discover issues, suggest changes and better solutions to the customer \n \n \n Qualifications: \n \n \n \n Bachelor's degree or equivalent experience \n Fluency in Microsoft Office suite (Outlook, Excel, Word, PowerPoint, etc.) \n Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n \n This is a remote position.", "cleaned_desc": " Strong written, verbal and collaboration skills \n Previous experience in Business or Systems Analysis or Quality Assurance \n Proven experience in eliciting requirements and testing \n Experience in analyzing data to draw business-relevant conclusions \n \n \n ", "techs": ["business analysis", "systems analysis", "quality assurance", "testing", "data analysis"]}, "a8584473738db61e": {"terms": ["data analyst"], "salary_min": 94146.586, "salary_max": 119210.555, "title": "LU- Medicaid Business Analyst", "company": "FOCUSED HR SOLUTIONS LLC", "desc": "This job is 100% remote Our client has an opening for a Business Analyst (712637) This position is for 12 months, with the option of extension, and the client is located in Raleigh, NC.  \n \n \n If you are interested please send rate,resume and please send back the attached form completed. If you are interested please send your rate, resume and please send back the attached form completed. \n \n \n Rates $45-$54 c-c $40-$49w2 \n \n Experience working in a fast-paced (preferably Agile) IT environment. Highly desired 7 YearsExperience translating technical information into clear, concise documents to be used by technical and non-technical personnel. Required 7 YearsExperience documenting communications, minutes, agendas, and presentations for stakeholder groups. Required 7 YearsExperience documenting system documentation, requirements, and release notes. Required 7 YearsExperience documenting status reports, standard operating procedures (SOP), policies and procedures, CMS documentation related to MMIS Certification. Required 7 YearsJira Highly desired 3 YearsSharePoint Required 7 YearsVisio Required 7 YearsExperience with Agile/SCRUM development methodology. Highly desired 3 YearsState Government experience. Highly desired 7 YearsExcellent communication skills, both verbal and written. Required 7 Years \n \n \n By replying to this job advertisement, I agree I want to receive additional job advertisements from Focused HR Solutions, including email, phone and mail to the contact information I am submitting. I consent to Focused HR Solutions, its affiliates, third parties and partners processing my personal data for these purposes and as described in the Privacy Policy. I understand that I can withdraw my consent at any time. \n \n \n This is a remote position.", "cleaned_desc": "", "techs": ""}, "ee083aab25d1bc30": {"terms": ["data analyst"], "salary_min": 76539.805, "salary_max": 96916.445, "title": "LU- Sharepoint Business Analyst/Designer - Remote", "company": "FOCUSED HR SOLUTIONS LLC", "desc": "** The candidate will be allowed to work remotely. Candidates who live outside of North Carolina will not be issued any computer equipment, and they are required to use their personal equipment. Candidates that reside in NC will be required to come on-site to pick up equipment in Raleigh. Candidate must work EST Business Hours. \n ** \n \n  Our direct client has an opening for Sharepoint Business Analyst/Designer # 713689, 713690 & 713691. This position is for 12+ months, with option of extension, and will be worked in remotely (must work EST business hours).\n  \n  If you are interested, please submit the following:\n   YOUR CURRENT RESUME\n   YOUR HOURLY RATE\n  \n  Below is the job description \u2013 Resumes due ASAP \u2013\n  \n \n NOTE:  This is a SharePoint Product Specialist position responsible for Business Analysis, Design and Quality Assurance. There will \n  not  be any coding or SharePoint Administration work performed by the candidate in this position.\n  \n  Description:\n  \n  Our client is seeking a SharePoint Product Specialist for the Engineering Application Services Department as an ECM Business Analyst. This person will be responsible for business analysis and solution design in support of Preconstruction business processes that are valuable to the transportation lifecycle. This individual will define and prioritize SharePoint and web based projects delivering content management and business process support on behalf of these business units, breaking down the design into work items, tracking status, managing communication and dependencies. This individual will also perform quality assurance testing, coordinate test validation and rollout for these projects, ensuring customers are informed & trained, sufficient help & training materials are created and delivered, and that operational support is arranged. This individual should have experience with standard business analysis processes, quality assurance testing as well as experience with business process transformation. The individual must be knowledgeable and experienced with project management, product ownership and the system development life cycle. This individual must have proven SharePoint experience with designing custom Microsoft SharePoint lists, libraries & content types.\n  \n \n \n Design SharePoint and web-based solutions to support Preconstruction business processes that are valuable to the transportation lifecycle \n Break down design into clearly defined, manageable work items for the development team \n Prioritize and track progress on work items and deliverables \n Ensure work items and deliverables are scheduled, completed, and delivered to the clients on time and with high quality & excellent, usable documentation. \n Document the program and project deliverables as assigned \n Coordinate with clients to implement re-engineered business processes \n Test SharePoint and web-based content management deliverables as required to support the re-engineered business processes \n Draft and deliver training materials for changed business processes and IT applications \n Consult with clients to prototype, refine, test, and debug applications and processes to meet needs \n Provide quality control for program and project deliverables \n \n  Required Skills: (2+ years)\n  \n \n Experience as a Business Analyst \n SharePoint experience with designing custom Microsoft SharePoint lists, libraries, and content types \n Designing and testing SharePoint and web-based content management solutions \n Strong analytical and conceptual skills \n Positive interpersonal skills \n Strong written and verbal communication skills, including ability to explain business processes to IT users and IT applications to business users \n Excellent organizational and presentation skills \n Strong Microsoft Suite experience (e.g., Outlook, Word, Excel, PowerPoint, Teams) \n Proven experience evaluating business processes and re-engineering \n Proven experience writing clear and concise technical training materials and other user documentation \n Working knowledge of application development life cycle \n \n  Preferred Skills:\n  \n \n Experience as a SharePoint Business Analyst \n Experience in Quality Assurance testing \n Working knowledge of NCDOT Preconstruction business processes \n Understanding of NCDOT transportation life cycle business processes \n Extensive experience with designer or owner roles in SharePoint \n Experience with AGILE development methodology \n Experience with Team Foundation Server (TFS) or Azure DevOps tool suite \n Experience with Balsamiq \n \n  By replying to this job advertisement, I agree I want to receive additional job advertisements from Focused HR Solutions, including email, phone and mail to the contact information I am submitting. I consent to Focused HR Solutions, its affiliates, third parties and partners processing my personal data for these purposes and as described in the Privacy Policy. I understand that I can withdraw my consent at any time.\n  \n This is a remote position.", "cleaned_desc": " SharePoint experience with designing custom Microsoft SharePoint lists, libraries, and content types \n Designing and testing SharePoint and web-based content management solutions \n Strong analytical and conceptual skills \n Positive interpersonal skills \n Strong written and verbal communication skills, including ability to explain business processes to IT users and IT applications to business users \n Excellent organizational and presentation skills \n Strong Microsoft Suite experience (e.g., Outlook, Word, Excel, PowerPoint, Teams) \n Proven experience evaluating business processes and re-engineering \n Proven experience writing clear and concise technical training materials and other user documentation \n Working knowledge of application development life cycle \n \n  Preferred Skills:", "techs": ["sharepoint", "microsoft suite"]}, "c594444c071a2b10": {"terms": ["data analyst"], "salary_min": 0.0, "salary_max": 40.0, "title": "Healthcare Business Analyst II-Medicaid/Medicare-Fully Remote", "company": "The Maxis Group", "desc": "Business Analyst II-Large Managed Care Company \n 6-month contract \n $40 an hour \n Fully Remote-CST Hours \n General Information \n Job Description Summary: \n \u00b7 Position is remote and candidates can sit anywhere in the US. Prefers candidates located in CST but will accept candidates in any time zone. \n \u00b7 Scheduling requirements will be from 8am-5pm CST \n \u00b7 Candidates will need strong PowerBI experience. The ideal candidate would know how to integrate R with PowerBI. \n \u00b7 Candidates need to be able to extract data with SQL and work around disconnected databased to be able to build out reporting. \n \u00b7 Candidates need to be able to take analysis and build out summary slides from existing reporting \n \u00b7 Candidates with Healthcare analytics experience or experience with Medicaid/Medicare would be preferred. \n Must Have Skills: SQL, Power BI, Salesforce, etc. \n Responsibilities (Purpose of the job and high-level summary of duties): \n \u00b7 Designs and implements processes and solutions associated with a wide variety of data sets used for data/text mining, analysis, modeling, and predicting to enable informed business decisions. \n \u00b7 Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. \n \u00b7 Collaborates across departments and with customers to define requirements and understand business problems. \n \u00b7 Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. \n \u00b7 Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. \n \u00b7 Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. \n \u00b7 Effectively uses current and emerging technologies. \n Job Duties (Main duties & responsibilities of the role): \n \u00b7 Extracts and compiles various sources of information and large data sets from various systems to identify and analyze outliers. \n \u00b7 Sets up process for monitoring, tracking, and trending department data. \n \u00b7 Prepares any state mandated reports and analysis. \n \u00b7 Works with internal, external and enterprise clients as needed to research, develop, and document new standard reports or processes. \n \u00b7 Implements and uses the analytics software and systems to support the departments goals. \n Required Experience/Knowledge, Skills & Abilities:  Minimum of 1 year of Power BI experience and 3 years of SQL experience \n Required Education: Associate\u2019s Degree or equivalent combination of education and experience \n Preferred Education: Bachelor\u2019s Degree or equivalent combination of education and experience \n Preferred Experience: 3-5 years \n Job Type: Contract \n Pay: Up to $40.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Health insurance \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Experience: \n \n SQL: 3 years (Required) \n Power BI: 1 year (Required) \n SaleForce: 2 years (Preferred) \n Healthcare Analytics: 3 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Candidates with Healthcare analytics experience or experience with Medicaid/Medicare would be preferred. \n Must Have Skills: SQL, Power BI, Salesforce, etc. \n Responsibilities (Purpose of the job and high-level summary of duties): \n \u00b7 Designs and implements processes and solutions associated with a wide variety of data sets used for data/text mining, analysis, modeling, and predicting to enable informed business decisions. \n \u00b7 Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. \n \u00b7 Collaborates across departments and with customers to define requirements and understand business problems. \n \u00b7 Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. \n \u00b7 Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. \n \u00b7 Creates solutions from initial concept to fully tested production and communicates results to a broad range of audiences. \n \u00b7 Effectively uses current and emerging technologies. \n Job Duties (Main duties & responsibilities of the role): ", "techs": ["sql", "power bi", "salesforce"]}, "11ca12e5e0df0f5f": {"terms": ["data engineer"], "salary_min": 109036.62, "salary_max": 138064.66, "title": "Data Engineer", "company": "Capgemini", "desc": "Job Description: \n \n  USC Aero Data Engineer primarily with Skills on Snowflake, SQL and Informatica ETL. \n  Experienced with 5+ yrs \n  Remote within US. \n  Extensive experience on Data Engineering field including ingestion, Data lake, Datawarehouse, reporting and analytics. \n  Strong knowledge and experience on Data Analysis, Big Data Pipelines, Data reconciliation, Data transformation rules, data flow diagram including data replication, data integration and data orchestration tools.  \n Hands-on experience in migrating other databases to snowflake. \n  Experience in Snowflake utilities - Snow SQL, Snowpark, SnowPipe, Tasks, Streams, Stored Procedures, Time-Travel, Resource Monitor, Data sharing, zero-copy cloning and Data Replication  \n Extensive knowledge in Snowflake query and cost optimization techniques.", "cleaned_desc": "  Experienced with 5+ yrs    Strong knowledge and experience on Data Analysis, Big Data Pipelines, Data reconciliation, Data transformation rules, data flow diagram including data replication, data integration and data orchestration tools.  ", "techs": ["data analysis", "big data pipelines", "data reconciliation", "data transformation rules", "data flow diagram", "data replication", "data integration", "data orchestration tools"]}, "5b30cb192989fcc6": {"terms": ["data engineer"], "salary_min": 120000.0, "salary_max": 172000.0, "title": "Senior Data Engineer", "company": "Swiss RE", "desc": "About the role - 100% Remote \n You are an engineer with very strong programming skills in Java/Kotlin and experience using Microsoft Azure to create solutions. You understand how to run and deploy Linux containers to Kubernetes, and you are familiar with resources such as Key Vault, relational and NoSQL Database Platforms, and Application Telemetry and Monitoring. You are able to put on an architect's hat to think about the best solution to a problem and understand the advantages and trade-offs of different approaches. \n \n \n Your responsibilities include: \n \n Crafting and writing containerized Microservices with Java and/or Kotlin \n Docker and kubernetes knowledge essential \n Debugging skills and writing telemetry \n Strong api controller design and implementation skills \n Writing unit and integration tests to verify public endpoints \n Utilizing appropriate data stores (relational, non-relational, binary etc) \n Documenting design proposals and implementations (Visio, Markdown) \n Experience with Azure resources and environments \n Understanding of Events and Event Driven Architecture (Event Streaming, Kafka) \n Security design and applied knowledge \n Devops skills useful (IaC, scripting in bash/sh or Powershell Core, yaml pipelines) \n Understanding of golang preferred \n \n \n   \n About the team \n The CorSo Accident and Health team has been created to address the challenges of the future and position CorSo as a risk innovation leader. This is an opportunity to join a fast-faced working environment that utilizes the latest technologies to provide unique and compelling solutions in a competitive marketplace. We operate with a startup mentality, challenge boundaries, and strive to combine leading-edge technology capabilities with new and emergent business models. \n \n \n About you \n Are you eager to reinvent the insurance industry with us and make an impact? Do you wish to have your talent recognized and rewarded? Then join our growing team and become part of the next wave of insurance innovation. Your profile: \n \n Cloud experience with previous work, Azure preferred \n Constant learner who keeps on top of industry trends \n Enjoys writing code \n Self-motivated and good interpersonal skills \n Proficient in English \n \n \n   \n This position is 100% remote. \n \n \n For this remote position the estimated base salary range is $120,000 to $172,000. The specific salary offered for this or any given role will take into account a number of factors including but not limited to job location, scope of role, qualifications, complexity/specialization/scarcity of talent, experience, education, and employer budget. At Swiss Re, we take a \"total compensation approach\" when making compensation decisions. This means that we consider all components of compensation in their totality (such as base pay, short-and long-term incentives, and benefits offered), in setting individual compensation. \n \n \n \n About Swiss Re Corporate Solutions \n \n \n \n Swiss Re is one of the world\u2019s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer. We anticipate and manage risks, from natural catastrophes and climate change to cybercrime.    Swiss Re Corporate Solutions is the commercial insurance arm of the Swiss Re Group. We offer innovative insurance solutions to large and midsized multinational corporations from our approximately 50 locations worldwide. We help clients mitigate their risk exposure, whilst our industry-leading claims service provides them with additional peace of mind.    Our success depends on our ability to build an inclusive culture encouraging fresh perspectives and innovative thinking. Swiss Re Corporate Solutions embraces a workplace where everyone has equal opportunities to thrive and develop professionally regardless of their age, gender, race, ethnicity, gender identity and/or expression, sexual orientation, physical or mental ability, skillset, thought or other characteristics. In our inclusive and flexible environment everyone can bring their authentic selves to work and their passion for sustainability. \n \n \n \n Keywords: \n \n Reference Code:  127212", "cleaned_desc": "About the role - 100% Remote \n You are an engineer with very strong programming skills in Java/Kotlin and experience using Microsoft Azure to create solutions. You understand how to run and deploy Linux containers to Kubernetes, and you are familiar with resources such as Key Vault, relational and NoSQL Database Platforms, and Application Telemetry and Monitoring. You are able to put on an architect's hat to think about the best solution to a problem and understand the advantages and trade-offs of different approaches. \n \n \n Your responsibilities include: \n \n Crafting and writing containerized Microservices with Java and/or Kotlin \n Docker and kubernetes knowledge essential \n Debugging skills and writing telemetry \n Strong api controller design and implementation skills   Writing unit and integration tests to verify public endpoints \n Utilizing appropriate data stores (relational, non-relational, binary etc) \n Documenting design proposals and implementations (Visio, Markdown) \n Experience with Azure resources and environments \n Understanding of Events and Event Driven Architecture (Event Streaming, Kafka) \n Security design and applied knowledge \n Devops skills useful (IaC, scripting in bash/sh or Powershell Core, yaml pipelines) \n Understanding of golang preferred \n \n ", "techs": ["java", "kotlin", "microsoft azure", "linux", "kubernetes", "key vault", "relational database platforms", "nosql database platforms", "application telemetry", "monitoring", "docker", "api", "unit testing", "integration testing", "data stores", "visio", "markdown", "azure resources", "events", "event driven architecture", "kafka", "security design", "devops", "bash", "powershell core", "yaml pipelines", "golang"]}, "de03f2592df37187": {"terms": ["data engineer"], "salary_min": 65.0, "salary_max": 70.0, "title": "Duck Creek Data Insights Engineer", "company": "optime-tech LLC", "desc": "Title: Duck Creek Data Insights Engineer \n Location: Tampa FL (remote) \n Duration: 1+ year \n Description: \n - Collaborate between business and IT to build strategies for engaging with, operating on, and leveraging data for creating competitive advantages and enhancing customer experiences. \n - Work with data visualization tools and data-driven workflows, resulting in better decisions in areas like identifying opportunities for cross-sell and up-sell, balancing portfolios with optimal risk profiles, segmenting risks for more profitable underwriting, and identifying fraud to lower the cost of claims. \n - Increase business agility and empower business users to create and propagate data changes quickly and efficiently. \n - Work on data strategy \u2013 mappings, data dictionaries, and rules. \n - Work with partner ecosystem features, integrations to data and analytics providers who specialize in optimizing outcomes for different insurance use cases. \n - Build analytics solutions to enable P&C insurers to use data as a strategic asset at the speed of business, empowering insurers to rapidly adapt core applications, capture and leverage data across and beyond their organizations, deliver the crucial information needed to execute intelligent action. \n - Interpret data, formulate hypotheses and develop an analytical approach to meet business requirements. \n - Knowledge of Duck Creek - Policy, Billing & Claims. \n - Carry data insights analysis of data sets policy, billing & claims to provide insights that help businesses make informed decisions and reduces the risk that comes with trial-and-error methods. \n - Assist to use analyze as a strategic asset at the speed of business, empowering insurers to rapidly adapt core applications, capture and leverage data across and beyond their organizations, deliver the crucial information needed to execute intelligent action, and employ new decisioning methods. \n Job Type: Contract \n Salary: $65.00 - $70.00 per hour \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "342f7b272c5ff82d": {"terms": ["data engineer"], "salary_min": 88537.91, "salary_max": 112108.72, "title": "SQL ETL Developer / Data Engineer", "company": "Civica Rx", "desc": "About Civica \n  Civica is a 501(c)(4) social welfare organization established in 2018 by health systems and philanthropies to reduce chronic generic drug shortages and related high prices in the United States. Civica is led by an experienced team of healthcare and pharmaceutical industry leaders. \n  Today, more than 55 health systems have joined Civica. They represent over 1,500 hospitals and one-third of all U.S. hospital beds. Civica has also begun to supply the U.S. Department of Veteran\u2019s Affairs, the U.S. Department of Defense and the U.S. Strategic National Stockpile of essential medicines. \n  Civica recently announced plans to expand its mission, via a unit called CivicaScript, to into the outpatient pharmacy space and to manufacture and distribute insulins that, once approved, will be available to people with diabetes at significantly lower prices than insulins currently on the market. The availability of Civica\u2019s affordable insulins, beginning in 2024, will benefit people with diabetes who have been forced to choose between life sustaining medicines and living expenses, particularly those uninsured or underinsured who often pay the most out of pocket for their medications. \n  Civica\u2019s mission is to ensure that quality generic medications are accessible and affordable to everyone. Since established, the #1 Policy for the Civica team has been \u201cDo What Is in the Best Interest of Patients.\u201d Civica\u2019s manufacturing facility in Petersburg, Virginia, is the future home of affordable insulin and essential sterile injectable medicines. The facility is currently in late-stage construction and hiring for the site is well-underway. \n  To find out more about how Civica\u2019s innovative model is directly impacting patient care, click here to read a summary from the New England Journal of Medicine. (https://catalyst.nejm.org/doi/full/10.1056/CAT.21.0189) \n  To learn more about Civica\u2019s plans to bring affordable insulin to Americans living with diabetes, click here to read an article in BioSpace. \n  (https://www.biospace.com/article/civica-is-rallying-leaders-to-make-insulin-affordable-by-2024-/) \n  Position Summary \n \n  Looking for an ETL developer to automate the ingestion and transformation of data to the company\u2019s enterprise data warehouse (EDW). Company located in Lehi, UT and Petersburg, VA \u2013 but remote work is an option. \n  Essential Duties and Responsibilities \n \n Build data systems and pipelines:  Scope, design, and document extract, transform, load (ETL) requirements to provide accurate data (mostly with SQL) in the EDW. Exceptional, in-depth, professional experience with SQL is mandatory. Provide production support to ensure stability, accuracy, and efficiency of datasets in the EDW. Python and JSON would be very helpful.  \n Agile:  Work in monthly sprints to deploy a high volume of completed and thorough solutions in a fast-paced, dynamic environment with a team of talented and dedicated collegues. Adhere to work plans and track assignments with minimal guidance.  \n EDW Management:  Manage enterprise data warehouse (EDW) architecture and improve performance. This includes but is not limited to: \n    \n Establish and follow standards, processes, and tools for data management.  \n Develop automated systems to monitor data integrity/quality and data lineage.  \n Design and document processes/tools to manage users and permissions.  \n Develop, implement, and monitor database backup and recovery procedures.  \n Lead research, design, and implementation of database technology solutions.  \n \n \n \n Continuous Improvement:  Contribute to the continuous improvement of the overall data infrastructure. Identify ways data can be more accurate, trustworthy, and timely. Provide thought leadership around best practices and emerging concepts in Data & Analytics domain. Find opportunities for automating operational database activities to enable the organization to scale and reduce costs.  \n Perform other duties as required.  \n \n Minimum Qualifications (Knowledge, Skills, and Abilities) \n \n 2+ years\u2019 professional (not academic) SQL experience. 1+ year experience writing ETLs.  \n Excellent SQL skills - Common Table Expressions (CTE), Complex Stored Procedures, Queries, Views, User Defined Functions.  \n Must have demonstrated the ability to solve complex problems with minimal direction.  \n Ability to balance multiple tasks simultaneously.  \n Extreme attention to detail and data accuracy.  \n A spirit of collaboration, transparent and timely communication.  \n Bachelor\u2019s degree in analytics, mathematics, computer science, engineering, business, or related field.  \n Domain experience in healthcare or pharma is a plus.  \n Experience with Snowflake, Python, JSON and/or Bash a plus.", "cleaned_desc": "  (https://www.biospace.com/article/civica-is-rallying-leaders-to-make-insulin-affordable-by-2024-/) \n  Position Summary \n \n  Looking for an ETL developer to automate the ingestion and transformation of data to the company\u2019s enterprise data warehouse (EDW). Company located in Lehi, UT and Petersburg, VA \u2013 but remote work is an option. \n  Essential Duties and Responsibilities \n \n Build data systems and pipelines:  Scope, design, and document extract, transform, load (ETL) requirements to provide accurate data (mostly with SQL) in the EDW. Exceptional, in-depth, professional experience with SQL is mandatory. Provide production support to ensure stability, accuracy, and efficiency of datasets in the EDW. Python and JSON would be very helpful.    Agile:  Work in monthly sprints to deploy a high volume of completed and thorough solutions in a fast-paced, dynamic environment with a team of talented and dedicated collegues. Adhere to work plans and track assignments with minimal guidance.  \n EDW Management:  Manage enterprise data warehouse (EDW) architecture and improve performance. This includes but is not limited to: \n    \n Establish and follow standards, processes, and tools for data management.  \n Develop automated systems to monitor data integrity/quality and data lineage.  \n Design and document processes/tools to manage users and permissions.  \n Develop, implement, and monitor database backup and recovery procedures.    Minimum Qualifications (Knowledge, Skills, and Abilities) \n \n 2+ years\u2019 professional (not academic) SQL experience. 1+ year experience writing ETLs.  \n Excellent SQL skills - Common Table Expressions (CTE), Complex Stored Procedures, Queries, Views, User Defined Functions.  \n Must have demonstrated the ability to solve complex problems with minimal direction.  \n Ability to balance multiple tasks simultaneously.  \n Extreme attention to detail and data accuracy.  ", "techs": ["sql", "python", "json", "agile", "edw"]}, "7a2cd3fc98458e23": {"terms": ["data engineer"], "salary_min": 127986.02, "salary_max": 162058.83, "title": "STAFF SOFTWARE ENGINEER, DATA", "company": "UniGroup", "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com", "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ", "techs": ["python", "javascript", "typescript", "sql", "postgres", "mongodb", "microservices", "aws", "docker", "kubernetes", "git", "gitlab", "github", "kafka"]}, "1c590c5382bd5fe0": {"terms": ["data engineer"], "salary_min": 105000.0, "salary_max": 160000.0, "title": "Data Engineer - HYBRID", "company": "Inclusively", "desc": "Inclusively is partnering with a life insurance company to hire a Data Engineer - HYBRID. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Senior Insights Data Engineer must be passionate about digging into data and understanding the stories the data are telling. You will be equally passionate about helping others solve problems, gain insights, and make decisions using data. You will work to solidify, enhance and support our data quality, analytics and dashboards/reports. \n \n Actively partner with Corporate Data Strategy and Governance and other Corporate Technology divisions to design and implement solutions for extraction and integration of data to and from data warehouses, data marts and data lakes for the purposes of reporting, decision support and driving insights. \n Identify, investigate, and resolve data discrepancies by finding the root cause of issues; work with partners across various cross-functional teams to prevent future occurrences. \n Proactively look for opportunities to optimize the data loading structure and develop new approaches to improve the onboarding and integrity of the data. \n Provide basic reporting and respond to inquiries asking for insights about the data sets from stakeholders, in a timely fashion thru data. \n Ensure that data is clean, consistent and synchronized across platforms as you oversee the design and implantation of data cleansing procedures. \n Represent area on projects, be a key player in meetings with all levels of management. \n Act as a mentor to team members and the Foundational Business on all technical issues. \n \n Experience: \n \n Proficient knowledge of SQL \n Experience working with Redshift and Hadoop. \n Ability to interpret data to help in strategic decision making. \n Excellent problem-solving and critical thinking skills required \n Ability to clearly articulate and present ideas both in writing and verbally to all levels within \n Experience manipulating large data sets leveraging tools such as Python & R \n Knowledge of the ETL process \n Solid proficiency in all Microsoft Office applications; expert Excel skills \n Expertise in doing Root Cause Analysis and resolving performance bottlenecks \n Professional, positive demeanor \n \n #LI - EM1 \n #LI - REMOTE \n Salary range:  $105,000-$160,000 \n Overtime eligible:  Exempt \n Discretionary bonus eligible:  Yes \n Sales bonus eligible:  No \n Job Type: Full-time \n Pay: $105,000.00 - $160,000.00 per year \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " \n Proficient knowledge of SQL \n Experience working with Redshift and Hadoop. \n Ability to interpret data to help in strategic decision making. \n Excellent problem-solving and critical thinking skills required \n Ability to clearly articulate and present ideas both in writing and verbally to all levels within \n Experience manipulating large data sets leveraging tools such as Python & R ", "techs": ["sql", "redshift", "hadoop", "python", "r"]}, "cfb93c633b0c5a85": {"terms": ["data engineer"], "salary_min": 100000.0, "salary_max": 115000.0, "title": "Senior Engineer BOI Insights (Healthcare SQL Data Analytics)", "company": "Agilon Health", "desc": "Agilon health is transforming healthcare by empowering community-based physicians with the resources and expertise they need to innovate the payment and delivery of care for seniors. \n The agilon health Total Care Model is powered by our purpose-built platform and frees physicians from the constraints of the traditional fee-for-service reimbursement model, all enabled through a growing national network of like-minded physician partners. With agilon health, physicians are able to practice team-based, coordinated care to serve the individual needs of their senior patients and to transition to a sustainable and predictable, long-term business model. \n As you might imagine, analytics and insights are the heart of how we support our physician partners and is our special sauce. We have a lot of analytics programs in place already, but we need more! From generating insights related to our risk adjustment programs to helping analyze health plan attribution, health plan and membership trends, building our next generation Cube or analytics surrounding our brand-new data lake, there's a lot of data to process and actionable insights to present, as well as analytics infrastructure to build. You will be executing some of this work individually, and others in tight partnership with other critical teams such as Finance, Clinical Analytics, and Medical Economics. \n There\u2019s much more data we can be leveraging and analyzing to generate and test our hypotheses to help improve patient outcomes and reduce medical waste. Come join the team and help make a direct impact on our senior members\u2019 lives! \n More about this role: \n - Be part of an agile team working collaboratively with Agilon leadership and many different cross-functional teams, including UX, Product, Technology, Operations, and Clinician teams - Leverage your analytical thinking to explore our ever-growing datasets to test hypotheses and bring life to your own insights - Generate insights that help improve patient outcomes and/or reduce medical waste - Continuously learn and share your new-found knowledge with others \n Desired Traits: \n 1. Experience: A minimum of 4 years of experience performing data analysis and generating intuitive dashboards. \n 2. Healthcare domain expertise: \n a. Exposure to the healthcare industry & domain is preferred, with specific knowledge in either risk adjustment, clinical analytics, clinical quality, or health economics. b. Familiarity with healthcare data models. \n 3. Education: A bachelor's degree or equivalent education is required. \n 4. Technical skills: \n a. should have strong proficiency in SQL, and expertise in Snowflake would be a plus. b. Data modeling skills are also important. c. Familiarity with data visualization tools such as Sigma, Tableau, Power BI, or Excel is necessary to create intuitive dashboards. d. Some experience with coding in Python or other programming languages is nice to have. \n 5. Analytical and problem-solving skills: Strong analytical and problem-solving abilities are essential for effectively analyzing data and providing meaningful insights. 6. Business Acumen: should be able to translate business needs into data analysis requirements, understanding the goals and objectives of the organization. 7. Curiosity and exploration: Should have an intellectual curiosity about data and the ability to go beyond immediate problems. Balancing deadlines and exploring new opportunities for analysis and insights is important. 8. Ownership and user focus: Takes ownership over the insights the team generates, and the processes used to develop those analyses, keeping our users' needs in clear focus 9. Startup environment readiness: Comfortable in a startup environment and ready to \u201croll up your sleeves!\u201d 10. Communication skills: Excellent communication skills are necessary to effectively convey complex findings to both technical and non-technical stakeholders. 11. Nimble learner: Should be eager to learn and adapt quickly to new technologies, methodologies, and industry trends. 12. Enthusiasm and drive: A proactive and enthusiastic approach to getting things done is valued in a candidate. \n Job Type: Full-time \n Pay: $100,000.00 - $115,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Vision insurance \n \n Compensation package: \n \n Yearly pay \n \n Experience level: \n \n 4 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " 2. Healthcare domain expertise: \n a. Exposure to the healthcare industry & domain is preferred, with specific knowledge in either risk adjustment, clinical analytics, clinical quality, or health economics. b. Familiarity with healthcare data models. \n 3. Education: A bachelor's degree or equivalent education is required. \n 4. Technical skills: \n a. should have strong proficiency in SQL, and expertise in Snowflake would be a plus. b. Data modeling skills are also important. c. Familiarity with data visualization tools such as Sigma, Tableau, Power BI, or Excel is necessary to create intuitive dashboards. d. Some experience with coding in Python or other programming languages is nice to have. \n 5. Analytical and problem-solving skills: Strong analytical and problem-solving abilities are essential for effectively analyzing data and providing meaningful insights. 6. Business Acumen: should be able to translate business needs into data analysis requirements, understanding the goals and objectives of the organization. 7. Curiosity and exploration: Should have an intellectual curiosity about data and the ability to go beyond immediate problems. Balancing deadlines and exploring new opportunities for analysis and insights is important. 8. Ownership and user focus: Takes ownership over the insights the team generates, and the processes used to develop those analyses, keeping our users' needs in clear focus 9. Startup environment readiness: Comfortable in a startup environment and ready to \u201croll up your sleeves!\u201d 10. Communication skills: Excellent communication skills are necessary to effectively convey complex findings to both technical and non-technical stakeholders. 11. Nimble learner: Should be eager to learn and adapt quickly to new technologies, methodologies, and industry trends. 12. Enthusiasm and drive: A proactive and enthusiastic approach to getting things done is valued in a candidate. \n Job Type: Full-time \n Pay: $100,000.00 - $115,000.00 per year ", "techs": ["healthcare data models", "sql", "snowflake", "data visualization tools (sigma", "tableau", "power bi", "excel)", "python", "analytical and problem-solving skills", "business acumen", "curiosity and exploration", "ownership and user focus", "startup environment readiness", "communication skills", "nimble learner", "enthusiasm and drive"]}, "f5aee2de2bbc7a19": {"terms": ["data engineer"], "salary_min": 104706.99, "salary_max": 132582.39, "title": "Data Engineer - Hybrid", "company": "Inclusively", "desc": "Inclusively is partnering with a  multinational financial services company   to hire a  Data Engineer - Hybrid. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n Job Description: \n We are looking for a Data Engineer. This person will be playing a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support Equity Compensation products for the Global markets. This person will be working closely with other engineers and business SMEs to build and release solutions that help customers get the information they need fast and intuitively. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required \n 4+ years of hands-on experience in Data engineering, data warehousing and analytics technologies \n Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform \n Strong knowledge of designing data engineering solutions and platforms \n Working experience with Relational Databases like Oracle \n Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau \n Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc. \n Experience building scalable patterns for data consumption from cloud based data-lakes. \n Advanced experience with PL/SQL and complex queries \n Working experience with Python focused on Data Engineering \n Solid understanding of Cloud technologies like AWS, Azure and DevOps concepts including CI/CD pipelines \n Significant experience with ELT data integration and data movement design patterns \n Strong knowledge of ETL technologies like Informatica, Snaplogic \n Knowledge of streaming platforms such as Apache Kafka \n Your ability to learn and experiment with new technologies and patterns \n Your penchant for modern test driven and automation driven software development methodologies \n Your experience in executing projects in an Agile environment \n \n Job Type: Full-time \n Experience level: \n \n 4 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " \n Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required \n 4+ years of hands-on experience in Data engineering, data warehousing and analytics technologies \n Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform \n Strong knowledge of designing data engineering solutions and platforms \n Working experience with Relational Databases like Oracle   Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau \n Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc. \n Experience building scalable patterns for data consumption from cloud based data-lakes. \n Advanced experience with PL/SQL and complex queries \n Working experience with Python focused on Data Engineering \n Solid understanding of Cloud technologies like AWS, Azure and DevOps concepts including CI/CD pipelines   Significant experience with ELT data integration and data movement design patterns \n Strong knowledge of ETL technologies like Informatica, Snaplogic \n Knowledge of streaming platforms such as Apache Kafka \n Your ability to learn and experiment with new technologies and patterns \n Your penchant for modern test driven and automation driven software development methodologies \n Your experience in executing projects in an Agile environment ", "techs": ["oracle", "obiee", "powerbi", "tableau", "snowflake", "redshift", "pl/sql", "python", "aws", "azure", "informatica", "snaplogic", "apache kafka"]}, "25f8cba3ddae4468": {"terms": ["data engineer"], "salary_min": 135083.78, "salary_max": 171046.16, "title": "Software Engineer (API, Data, Customer Support) - Hybrid/Remote", "company": "Themis Insight", "desc": "Themis Insight solves difficult business, IT, and analytic problems by addressing the whole problem \u2013 not just the symptoms \u2013 using interdisciplinary approaches that are both practical and innovative. We provide fresh alternatives to ordinary, mainstream consulting firms through small, highly skilled, and hand-picked teams that can meet clients' needs in any industry. Our broad interdisciplinary understanding allows us to provide the right solution, even if it is from outside the industry or traditionally defined problem space. We bring Public and Private, Civilian and Military expertise to every case.     We are hiring a multiple Software Engineers to support various teams in Linthicum Heights, MD. These positions offer a hybrid/remote schedule. Position location is subject to change based on central MD client's needs. \n Required:  TS/SCI with a Polygraph  \n The Software Engineer develops, maintains, and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of extremely large data sets, real-time systems, and business management information systems) based upon documented requirements. Works individually or as part of a team. Reviews and tests software components for adherence to the design requirements and documents test results. Resolves software problem reports. Utilizes software development and software design methodologies appropriate to the development environment. Provides specific input to the software components of system design to include hardware/software trade-offs, software reuse, use of Commercial Off-the-shelf (COTS)/Government Off-the-shelf (GOTS) in place of new development, and requirements analysis and synthesis from system level to individual software components. \n We're hiring for the below teams:  \n \n API:  Provide the development, test, deploy, and sustainment of various Python based ReST end points, microservices, and data model management capabilities utilizing Django and Flask frameworks to interact with data models such as MariaDB, MongoDB, and PostgreSQL and send data upon request, in JSON format, to UI front ends. \n  Data Management:  Focused on delivering reliable, accurate data to our end users.  \n Customer Support Services:  Primarily focuses on requirements gathering, tier 1 support, technical writing, help documentation, and internal testing.  \n Data Pipeline:  Responsible for ensuring that our day-to-day operations are successful. That data arrives from A to B, both coming into our system and leaving to third parties.  \n \n Individual Capabilities/Experience Required: \n \n Seven (7) years experience as a SWE, in programs and contracts of similar scope, type, and complexity is required. Bachelor's degree in Computer Science or related discipline from an accredited college or university is required. Four (4) years of additional SWE experience on projects with similar software processes may be substituted for a bachelor's degree. \n  API: \n    \n Required: Python, Django or Flask, Database experience using MongoDB or MariaDB, ReST endpoint development, Micro service model \n  Desired: Swagger, AWS, C2S or other cloud experience, Docker, Visual Studio Code or similar IDEs, JSON and/or XML serialization, Jira, Confluence, Git version control, Experience working in Agile environment \n \n  Data Management: \n    \n Primary Skills: PIG, Py-Spark \n  Secondary Skills: NiFi, PressureWave \n \n  Data Pipeline: \n    \n Primary Skills: NiFi, PressureWave \n  Secondary Skills: Patch Management and IAVA tracking, Bash Scripting \n \n \n \n  Customer Support Services:\n    \n  Primary Skills: Technical writing, Confluence \n  Secondary Skills: System Engineering/requirements gathering, JIRA \n \n \n Themis Insight has all the PERKS! \n You are our most valuable resource \u2014 your ambition, your knowledge, your creativity. We offer an industry-leading set of benefits to supplement your normal salary compensation. Themis Insight has you covered with flexible ways to balance work and home life, full health benefit premium coverage, and generous contributions toward your retirement. \n \n Competitive health, dental, and vision plans with 100% paid premiums. \n 401k: We contribute 6% even if you don't! \n Time Off: 11 standard holidays, and 20 days of PTO \n Career Development: Get career counseling and individualized career development plans, including education and training. \n Employee referral bonuses for successful hires \n \n Themis Insight is an Equal Opportunity/Affirmative Action employer. \n Themis Insight provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.", "cleaned_desc": " \n Individual Capabilities/Experience Required: \n \n Seven (7) years experience as a SWE, in programs and contracts of similar scope, type, and complexity is required. Bachelor's degree in Computer Science or related discipline from an accredited college or university is required. Four (4) years of additional SWE experience on projects with similar software processes may be substituted for a bachelor's degree. \n  API: \n    \n Required: Python, Django or Flask, Database experience using MongoDB or MariaDB, ReST endpoint development, Micro service model \n  Desired: Swagger, AWS, C2S or other cloud experience, Docker, Visual Studio Code or similar IDEs, JSON and/or XML serialization, Jira, Confluence, Git version control, Experience working in Agile environment \n ", "techs": ["python", "django", "flask", "mongodb", "mariadb", "swagger", "aws", "c2s", "docker", "visual studio code", "json", "xml", "jira", "confluence", "git", "agile"]}, "bccc0835dd407039": {"terms": ["data engineer"], "salary_min": 42.14, "salary_max": 50.75, "title": "Senior AWS Data engineer W2 role FULL Time role NO C2C \u2013 REMOTE", "company": "Neon IT Solutions", "desc": "Role : Senior AWS Data engineer \n Must have AWS EXP with Python \n Send resumes to recruit@neonitsol.comNEED Seniors please have 9+ years \n REMOTE REMOTE REMOTE \n Job Type: Contract \n Pay: $42.14 - $50.75 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Data engineer: 10 years (Preferred) \n AWS: 4 years (Preferred) \n PYTHON: 3 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "b9f9c8afefdf3187": {"terms": ["data engineer"], "salary_min": 130456.03, "salary_max": 165186.4, "title": "STAFF SOFTWARE ENGINEER, DATA", "company": "UniGroup", "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com", "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ", "techs": ["python", "javascript/typescript", "sql", "nosql", "postgres", "mongodb", "microservices", "aws", "docker", "kubernetes", "git", "gitlab", "github", "kafka"]}, "fc5e0ab23cc56fe9": {"terms": ["data engineer"], "salary_min": 60.0, "salary_max": 70.0, "title": "Solutions Engineer/ Systems Data Management Consultant", "company": "TechIntelli Solutions, Inc.", "desc": "CANDIDATE QUALIFICATIONS \n \n Bachelors Degree in Computer Science \n \n \n Minimum of between 3-5 years of application administration experience with large, multi-tiered applications \n \n \n Comfortable taking initiative and working independently but knows when to involve others \n \n \n Comfortable working with stakeholders from a wide range of functions and seniority levels \n \n \n Strong collaboration skills and the ability to work in a team-based environment \n \n \n Excellent communication skills with ability to address and resolve conflicts diplomatically \n \n \n Ability to work through complexity with ease, identifying themes across complicated issues in time-critical situations \n \n \n Experience in agile and DevOps tools and delivery is a plus \n \n \n Experience in cloud administration and maintenance (e.g. IAAS) is a plus, AWS preferred \n \n \n Experience in the investments and/or finance data domain is a plus. \n \n Job Type: Contract \n Salary: $60.00 - $70.00 per hour \n Experience level: \n \n 11+ years \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Data management: 10 years (Required) \n \n Willingness to travel: \n \n 50% (Required) \n \n Work Location: In person", "cleaned_desc": " \n \n Ability to work through complexity with ease, identifying themes across complicated issues in time-critical situations \n \n \n Experience in agile and DevOps tools and delivery is a plus \n \n \n Experience in cloud administration and maintenance (e.g. IAAS) is a plus, AWS preferred ", "techs": ["agile", "devops", "iaas", "aws"]}, "e24a41bc499d439e": {"terms": ["data engineer"], "salary_min": 129731.945, "salary_max": 164269.55, "title": "STAFF SOFTWARE ENGINEER, DATA", "company": "UniGroup", "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com", "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ", "techs": ["python", "javascript/typescript", "sql", "nosql", "postgres", "mongodb", "microservices", "aws", "docker", "kubernetes", "git/gitlab/github", "kafka"]}, "21a389ff6f2558b4": {"terms": ["data engineer"], "salary_min": 110400.0, "salary_max": 151800.0, "title": "Data Engineer III", "company": "ZoomInfo Technologies LLC", "desc": "At ZoomInfo, we encourage creativity, value innovation, demand teamwork, expect accountability and cherish results. We value your take charge, take initiative, get stuff done attitude and will help you unlock your growth potential. One great choice can change everything. Thrive with us at ZoomInfo. \n \n  At  ZoomInfo  we encourage creativity, value innovation, demand teamwork, expect accountability and cherish results. If you are a take charge, take initiative, get stuff done individual we want to talk to you! We have high aspirations for the company and are looking for the right people to help fulfill the dream. We strive to continually improve every aspect of the company and use cutting edge technologies and processes to delight our customers and rapidly increase revenues. \n  As a Senior Data Engineer, you'll have a key role in building and designing the strategy of our finance analytics engineering team under the Enterprise Data Engineering group. \n  Our Technological Stack includes: Airflow, DBT, Python, Snowflake, AWS, GCP, Amplitude, Fivetran, and more. \n  What will you actually be doing? \n \n Building, and continuously improving our data gathering, modeling, reporting capabilities and self-service data platforms. \n Working closely with Data Engineers, Data Analysts, Data Scientists, Product Owners, and Domain Experts to identify data needs. \n \n Required Experience: \n \n Relevant Bachelor degree \u2013 preferably CS, Engineering/ Information Systems or other equivalent Software Engineering background. \n 5+ years of experience as a Data/BI engineer. \n Strong SQL abilities and hands-on experience with SQL and no-SQL DBs, performing analysis and performance optimizations. \n Hands-on experience in Python or equivalent programming language \n Experience with data warehouse solutions (like BigQuery/ Redshift/ Snowflake) \n Experience with data modeling, data catalog concepts, data formats, data pipelines/ETL design, implementation and maintenance. \n Experience with AWS/GCP cloud services such as GCS/S3, Lambda/Cloud Function, EMR/Dataproc, Glue/Dataflow, Athena. \n Experience with Airflow and DBT - Advantage. \n Experience with data visualization tools and infrastructures (like Tableau/SiSense/Looker/other) - Advantage. \n Experience with development practices \u2013 Agile, CI/CD, TDD - Advantage. \n Experience with Infrastructure as Code practices - Terraform - Advantage \n \n About us: \n  For over a decade, ZoomInfo has helped companies achieve their most important objective: profitable growth. Backed by the world's most comprehensive B2B database, our platform puts sales and marketing professionals in position to identify, connect, and engage with qualified prospects. \n  Our mission is to provide every company with a 360-degree view of their ideal customer, empowering each phase of their go-to-market strategy and driving their ability to hit their number. \n \n  The US base salary range for this position is $110,400.00 to $151,800.00 variable compensation + benefits. \n  Actual compensation offered will be based on factors such as the candidate's work location, qualifications, skills, experience and/or training. Your recruiter can share more information about the specific salary range for your desired work location during the hiring process. \n  We want our employees and their families to thrive. In addition to comprehensive benefits we offer holistic mind, body and lifestyle programs designed for overall well-being. Learn more about ZoomInfo benefits here. \n \n \n  About us: \n  ZoomInfo (NASDAQ: ZI) is the trusted go-to-market platform for businesses to find, acquire, and grow their customers. It delivers accurate, real-time data, insights, and technology to more than 35,000 companies worldwide. Businesses use ZoomInfo to increase efficiency, consolidate technology stacks, and align their sales and marketing teams \u2014 all in one platform. \n  ZoomInfo may use a software-based assessment as part of the recruitment process. More information about this tool, including the results of the most recent bias audit, is available here. \n  ZoomInfo is proud to be an Equal Opportunity employer. We are committed to equal employment opportunities for applicants and employees regardless of sex, race, age, color, national origin, sexual orientation, gender identity, marital status, disability status, religion, protected military or veteran status, medical condition, or any other characteristic or status protected by applicable law. At ZoomInfo, we also consider qualified candidates with criminal histories, consistent with legal requirements.", "cleaned_desc": " Building, and continuously improving our data gathering, modeling, reporting capabilities and self-service data platforms. \n Working closely with Data Engineers, Data Analysts, Data Scientists, Product Owners, and Domain Experts to identify data needs. \n \n Required Experience: \n \n Relevant Bachelor degree \u2013 preferably CS, Engineering/ Information Systems or other equivalent Software Engineering background. \n 5+ years of experience as a Data/BI engineer.   Strong SQL abilities and hands-on experience with SQL and no-SQL DBs, performing analysis and performance optimizations. \n Hands-on experience in Python or equivalent programming language \n Experience with data warehouse solutions (like BigQuery/ Redshift/ Snowflake) \n Experience with data modeling, data catalog concepts, data formats, data pipelines/ETL design, implementation and maintenance. \n Experience with AWS/GCP cloud services such as GCS/S3, Lambda/Cloud Function, EMR/Dataproc, Glue/Dataflow, Athena. \n Experience with Airflow and DBT - Advantage. \n Experience with data visualization tools and infrastructures (like Tableau/SiSense/Looker/other) - Advantage. ", "techs": ["sql", "no-sql", "python", "bigquery", "redshift", "snowflake", "aws", "gcp", "gcs", "s3", "lambda", "cloud function", "emr", "dataproc", "glue", "dataflow", "athena", "airflow", "dbt", "tableau", "sisense", "looker"]}, "1d12a460880e9bbb": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 90000.0, "salary_max": 110000.0, "title": "Data Engineer", "company": "Step Up For Students", "desc": "Do you have a passion for children and education? Would you like to positively impact families in need of help? We want to speak with you! \n \n  Step Up For Students empowers families to pursue and engage in the most appropriate learning options for their children. \n \n \n Step Up For Students offers an excellent benefits package: \n  SUFS Total Rewards \n \n  Medical - HSA/FSA - Dental - Vision \n Company Paid Disability - Life Insurance \n 401K Match - Tuition Reimbursement \n Generous Time off Policy - Professional Development \n \n  Position Overview \n The Data Engineer will play a crucial role in the field of data management and analytics by designing, developing, and maintaining data infrastructure, pipelines, and systems to ensure that data is collected, stored, and made accessible for analysis and decision-making. This position will be leveraging cloud technologies to build enterprise-wide data service solutions, data products, CI/CD pipeline, and analytics platforms. The position will be reporting to the Sr. Manager, Enterprise Data Modernization and Governance which is part of the Enterprise Data Operations and Strategy Department. \n This is a remote position. \n \n  Essential Functions \n \n \n Clear understanding of the industry domain and relevant metrics to support the organizational needs. \n Develop and maintain ETL processes and data pipelines to move and transform data from source systems (databases, APIs, logs) to data warehouses or data lakes. \n Integrate and merge data from multiple sources to create a unified and consistent data repository for analysis. \n Design and implement data models and schemas to optimize data storage, query performance, and data access for analytical purposes. \n Implement data quality checks and validation processes to ensure data accuracy, completeness, and consistency. \n Work with data warehousing technologies to store and manage large datasets efficiently. \n Transform and clean data as needed to make it suitable for analysis, including handling missing data, data normalization, and data aggregation. \n Design data systems that can scale to accommodate growing data volumes and user demands. \n Monitor and optimize data pipelines and systems for performance and efficiency. \n Collaborate and partner with IT counterparts, Enterprise Data Operations and Strategy, and management team to employ analysis and design techniques including database schema to ensure business goals are met. \n Collaborate and partner closely with Application Development teams to help design better and optimal data integrations techniques and mechanisms. \n Provide critical feedback and participation in SUFS\u2019s \u2018data as a product\u2019 modernization theme and respective initiatives to achieve goals under this theme. \n Awareness of Agile and SCRUM methodologies that are utilized by the organization to bring projects to fruition. \n Experience in leveraging cloud technology (i.e., Azure Data Services) to build enterprise-wide data solutions and data products. (Event Hub, ADF, ADLS, Azure Managed Instances, Databricks, Synapse, Purview, CosmosDB) \n Experience in setting up and maintaining DataOps CI/CD (i.e., Azure DevOps, GitHub, Azure {Code} Pipelines). Mentoring team members in code repository management. Performing code reviews and managing releases. \n Experience in securing access to Azure Data Services (Key vault, Managed Identity, Service Principal, roles & privileges for AAD group access). \n Automate data movement and orchestration, industrialize the processes to include altering, notification, and escalation on exception conditions. \n Transfer and optimize data and reporting functionalities from outdated legacy systems to modern, cutting-edge Business Intelligence solutions. \n Develop, test, document, and implement high quality Business Intelligence solutions using tools such as the Microsoft BI stack including SSRS, SSIS, ADF, SSAS, and T-SQL stored procedures as well as Cubes in MDX & DAX in accordance with specifications and supporting documents. \n Proactively analyze performance of stored procedures, queries, and reports to take actions to correct any discrepancies. \n Provide the implementation and deployment of data pipeline and solutions. \n Develop and manage effective working relationships with other departments, groups, or personnel with whom work and various processes must be coordinated. \n Cognizant of emerging technologies and operate dynamically to integrate those technologies into the BI solutions, where appropriate. \n  The above is not an all-inclusive list of all duties performed by this job title, only a representative summary of the primary duties and responsibilities. Incumbents may be required to perform other additional duties as assigned/requested. \n \n  Minimum Qualifications \n \n \n Process/Program Management: \n \n \n Documentation: Maintain documentation for data pipelines and schemas to facilitate collaboration and understanding among team members. Contributes to documentation and documentation of BI report life cycle. \n Standards: Accountable and maintain best practice BI and Data Engineering standards. \n \n Qualifications: \n \n \n Five (5) years of SQL OLTP or Data Warehouse development and big data technologies experience. \n Three (3) years of development experience with Microsoft SQL Server / BI Stack components including T-SQL, SSIS, ADF, SSRS, and SSAS (MDX & DAX). \n Three (3) years of developing and delivering database solutions in an enterprise environment. \n Proficient at dimensional data modeling, Database performance tuning, data base design principles and data architecture. \n Proficient at ETL tools and frameworks, incremental loading, parameter driven data movement frameworks. \n Strong programming skills in languages such as Python, Java, Scala, or SQL. \n Familiarity with cloud computing platforms (preferably \u2013 Azure) \n Understanding of data security, privacy, and compliance requirements. \n Experience with semi structured data ingestion and publication (JSON) \n Experience Migrating SQL Server databases to Azure Cloud Services. \n Experience with machine learning and other automated technologies to better data pattern and knowledge identification. \n Bachelor's degree in computer science, Information Technology, or a related field \n \n Environment: \n \n \n 2 (Two) years of experience with Version Control Systems such as Microsoft TFS / Azure DevOps Server, Github or other comparable systems. \n Proven experience working with cloud technologies such as Snowflake, Databricks, Cloudera, or AWS Lake Formation solutions - demonstrated skills with reporting solutions from data lakes or other unstructured or semi structured data. \n 2 (Two) years of experience in integrating Warehouse and SSRS and Power BI Reporting with Azure data sources \u2013 Cosmos DBs, SaaS, and Synapse Analytics. \n \n Preferred: \n \n \n Prior experience with Power BI, Paginated Reports, Tableau, QlikView, and other visualization tools is a plus. \n Experience with Streaming data, Kafka, Event hubs, or other message-based data movements \n Experience with Azure Data Lake storage, preferably in support of medallion zones in a Delta Lakehouse. \n MCTS (Microsoft Certified Technology Specialist), MCSA (Microsoft Certified Solutions Associate) or MCSE (Microsoft Certified Solutions Expert) in SQL Server / Data Platform is preferred. \n \n Key Behaviors and Abilities: \n \n \n Maintain a positive and optimistic attitude, be a team player. \n Communicate effectively (verbal & written) with teammates, stakeholders, and other partners. \n High attention to detail and focus on the quality of reports, process, and designs. \n Strong problem-solving skills, self motivated and the capacity to work under tight deadlines. \n Ability to multitask, be accountable, have a sense of urgency and work in a team environment with a can-do attitude. \n Quick to learn and adapt to new technologies. \n Ability to take initiative, be innovative, exercise good judgment, have high work-ethic, and exhibit business savvy orientation. \n \n Knowledge and Skills: \n \n \n Understands and demonstrates the knowledge of information systems, data modeling, business intelligence, relational and dimensional database design and how to access multiple information sources for analytical purposes. \n Knowledge of and the ability to apply best practices including change management, effective error handling and performance instrumentation. \n Exhibits ability to develop and optimize T-SQL statements, stored procedures, database schemas, Microsoft SQL Reporting Services Reports, visualizations, and Microsoft SQL Server Integration Services Packages. \n Excellent verbal and written communication skills. \n  Core Values \n Step Up For Students believes strongly in two key core values, and it is the responsibility of all employees to demonstrate these values in their everyday work in order to maintain a positive and effective organizational culture. \n \n  Everyone is an asset. \n Every event is an improvement opportunity. \n \n  Physical Demands \n This position occasionally requires the abilities of standing, walking, lifting, or exerting forces up to 20lbs., reaching or stretching, climbing, or balancing, crouching, or stooping, crawling, depth perception. \n This position frequently requires the abilities of sitting or manual dexterity, repetitive finger motion, speaking, hearing, and seeing colors. \n \n  Work Environment \n This position is an office environment with very limited exposure to any outside fumes, odors, heat and/or weather. \n \n  Step Up For Students is an equal opportunity employer committed to diversity & inclusion in the workplace.", "cleaned_desc": "Do you have a passion for children and education? Would you like to positively impact families in need of help? We want to speak with you! \n \n  Step Up For Students empowers families to pursue and engage in the most appropriate learning options for their children. \n \n \n Step Up For Students offers an excellent benefits package: \n  SUFS Total Rewards \n \n  Medical - HSA/FSA - Dental - Vision \n Company Paid Disability - Life Insurance \n 401K Match - Tuition Reimbursement \n Generous Time off Policy - Professional Development \n \n  Position Overview \n The Data Engineer will play a crucial role in the field of data management and analytics by designing, developing, and maintaining data infrastructure, pipelines, and systems to ensure that data is collected, stored, and made accessible for analysis and decision-making. This position will be leveraging cloud technologies to build enterprise-wide data service solutions, data products, CI/CD pipeline, and analytics platforms. The position will be reporting to the Sr. Manager, Enterprise Data Modernization and Governance which is part of the Enterprise Data Operations and Strategy Department. \n This is a remote position. \n \n  Essential Functions \n \n \n Clear understanding of the industry domain and relevant metrics to support the organizational needs. \n Develop and maintain ETL processes and data pipelines to move and transform data from source systems (databases, APIs, logs) to data warehouses or data lakes. \n Integrate and merge data from multiple sources to create a unified and consistent data repository for analysis.   Design and implement data models and schemas to optimize data storage, query performance, and data access for analytical purposes. \n Implement data quality checks and validation processes to ensure data accuracy, completeness, and consistency. \n Work with data warehousing technologies to store and manage large datasets efficiently. \n Transform and clean data as needed to make it suitable for analysis, including handling missing data, data normalization, and data aggregation. \n Design data systems that can scale to accommodate growing data volumes and user demands. \n Monitor and optimize data pipelines and systems for performance and efficiency. \n Collaborate and partner with IT counterparts, Enterprise Data Operations and Strategy, and management team to employ analysis and design techniques including database schema to ensure business goals are met. \n Collaborate and partner closely with Application Development teams to help design better and optimal data integrations techniques and mechanisms. \n Provide critical feedback and participation in SUFS\u2019s \u2018data as a product\u2019 modernization theme and respective initiatives to achieve goals under this theme. \n Awareness of Agile and SCRUM methodologies that are utilized by the organization to bring projects to fruition. \n Experience in leveraging cloud technology (i.e., Azure Data Services) to build enterprise-wide data solutions and data products. (Event Hub, ADF, ADLS, Azure Managed Instances, Databricks, Synapse, Purview, CosmosDB) \n Experience in setting up and maintaining DataOps CI/CD (i.e., Azure DevOps, GitHub, Azure {Code} Pipelines). Mentoring team members in code repository management. Performing code reviews and managing releases. \n Experience in securing access to Azure Data Services (Key vault, Managed Identity, Service Principal, roles & privileges for AAD group access). \n Automate data movement and orchestration, industrialize the processes to include altering, notification, and escalation on exception conditions. \n Transfer and optimize data and reporting functionalities from outdated legacy systems to modern, cutting-edge Business Intelligence solutions. \n Develop, test, document, and implement high quality Business Intelligence solutions using tools such as the Microsoft BI stack including SSRS, SSIS, ADF, SSAS, and T-SQL stored procedures as well as Cubes in MDX & DAX in accordance with specifications and supporting documents. \n Proactively analyze performance of stored procedures, queries, and reports to take actions to correct any discrepancies. \n Provide the implementation and deployment of data pipeline and solutions. \n Develop and manage effective working relationships with other departments, groups, or personnel with whom work and various processes must be coordinated. \n Cognizant of emerging technologies and operate dynamically to integrate those technologies into the BI solutions, where appropriate. \n  The above is not an all-inclusive list of all duties performed by this job title, only a representative summary of the primary duties and responsibilities. Incumbents may be required to perform other additional duties as assigned/requested. \n \n  Minimum Qualifications   \n \n Process/Program Management: \n \n \n Documentation: Maintain documentation for data pipelines and schemas to facilitate collaboration and understanding among team members. Contributes to documentation and documentation of BI report life cycle. \n Standards: Accountable and maintain best practice BI and Data Engineering standards. \n \n Qualifications: \n \n \n Five (5) years of SQL OLTP or Data Warehouse development and big data technologies experience. \n Three (3) years of development experience with Microsoft SQL Server / BI Stack components including T-SQL, SSIS, ADF, SSRS, and SSAS (MDX & DAX). \n Three (3) years of developing and delivering database solutions in an enterprise environment. \n Proficient at dimensional data modeling, Database performance tuning, data base design principles and data architecture. \n Proficient at ETL tools and frameworks, incremental loading, parameter driven data movement frameworks. \n Strong programming skills in languages such as Python, Java, Scala, or SQL. \n Familiarity with cloud computing platforms (preferably \u2013 Azure) \n Understanding of data security, privacy, and compliance requirements. \n Experience with semi structured data ingestion and publication (JSON) \n Experience Migrating SQL Server databases to Azure Cloud Services. \n Experience with machine learning and other automated technologies to better data pattern and knowledge identification. \n Bachelor's degree in computer science, Information Technology, or a related field   \n Environment: \n \n \n 2 (Two) years of experience with Version Control Systems such as Microsoft TFS / Azure DevOps Server, Github or other comparable systems. \n Proven experience working with cloud technologies such as Snowflake, Databricks, Cloudera, or AWS Lake Formation solutions - demonstrated skills with reporting solutions from data lakes or other unstructured or semi structured data. \n 2 (Two) years of experience in integrating Warehouse and SSRS and Power BI Reporting with Azure data sources \u2013 Cosmos DBs, SaaS, and Synapse Analytics. \n \n Preferred: \n \n \n Prior experience with Power BI, Paginated Reports, Tableau, QlikView, and other visualization tools is a plus. \n Experience with Streaming data, Kafka, Event hubs, or other message-based data movements \n Experience with Azure Data Lake storage, preferably in support of medallion zones in a Delta Lakehouse. \n MCTS (Microsoft Certified Technology Specialist), MCSA (Microsoft Certified Solutions Associate) or MCSE (Microsoft Certified Solutions Expert) in SQL Server / Data Platform is preferred. \n \n Key Behaviors and Abilities: \n \n \n Maintain a positive and optimistic attitude, be a team player. \n Communicate effectively (verbal & written) with teammates, stakeholders, and other partners. \n High attention to detail and focus on the quality of reports, process, and designs. \n Strong problem-solving skills, self motivated and the capacity to work under tight deadlines.   Ability to multitask, be accountable, have a sense of urgency and work in a team environment with a can-do attitude. \n Quick to learn and adapt to new technologies. \n Ability to take initiative, be innovative, exercise good judgment, have high work-ethic, and exhibit business savvy orientation. \n \n Knowledge and Skills: \n \n \n Understands and demonstrates the knowledge of information systems, data modeling, business intelligence, relational and dimensional database design and how to access multiple information sources for analytical purposes. \n Knowledge of and the ability to apply best practices including change management, effective error handling and performance instrumentation. \n Exhibits ability to develop and optimize T-SQL statements, stored procedures, database schemas, Microsoft SQL Reporting Services Reports, visualizations, and Microsoft SQL Server Integration Services Packages. \n Excellent verbal and written communication skills. \n  Core Values \n Step Up For Students believes strongly in two key core values, and it is the responsibility of all employees to demonstrate these values in their everyday work in order to maintain a positive and effective organizational culture. \n \n  Everyone is an asset. \n Every event is an improvement opportunity. \n \n  Physical Demands \n This position occasionally requires the abilities of standing, walking, lifting, or exerting forces up to 20lbs., reaching or stretching, climbing, or balancing, crouching, or stooping, crawling, depth perception. \n This position frequently requires the abilities of sitting or manual dexterity, repetitive finger motion, speaking, hearing, and seeing colors. \n \n  Work Environment \n This position is an office environment with very limited exposure to any outside fumes, odors, heat and/or weather. ", "techs": ["sql", "etl", "data warehouse", "t-sql", "ssis", "adf", "ssrs", "ssas", "azure", "python", "java", "scala", "cloud computing", "json", "power bi", "tableau", "kafka", "event hubs", "azure data lake", "delta lakehouse", "microsoft certified technology specialist", "microsoft certified solutions associate", "microsoft certified solutions expert"]}, "32d0437b29a479b9": {"terms": ["machine learning engineer"], "salary_min": 104000.0, "salary_max": 130000.0, "title": "Senior Software Engineer", "company": "OneStream", "desc": "Senior Software Engineer  Remote, USA OneStream Software LLC \n \n \n  Benefits Offered Vision, Medical, Life, Dental, 401K  Compensation Range $104,000.00 - $130,000.00 (Range applies to US candidates only) + Benefits/Variable Comp/Equity \u2013 Range may vary based on experience  Employment Type Full-Time \n \n \n  ABOUT THE JOB \n  OneStream Software is a leading provider of Corporate Performance Management (CPM) solutions, offering a unified platform for financial planning, consolidation, reporting and analytics. We are seeking a talented and motivated Senior Software Engineer to join our dynamic team. As a Senior Software Engineer at OneStream Software, you will play a vital role in designing, developing, and implementing innovative software solutions that empower our clients to optimize their financial processes and drive business success. \n \n \n  RESPONSIBILITIES: \n \n Integrate data storage solutions. \n Ensure the best possible performance, quality, and responsiveness of applications. \n Identify bottlenecks and bugs, devise solutions to mitigate and address these issues. \n Help maintain code quality, organization, and automatization. \n Analyze and refactor inherited code, apply standards, separation of concerns. \n Participate and contribute to design discussions and planning. \n Mentor Software Engineer team members regarding source code management process, system setup, environment access. \n Ability to enhance the QA process and create framework of the unit tests. \n Ability to use, manage and optimize relational database systems. \n Work on technology migrations for legacy solutions, create new solutions, team member with mentorship. \n Participates in requirements discussions to get clear understanding of user flows and patterns of consuming/using the features being implemented. \n Collaborate with cross-functional teams, including product managers, architects, and quality assurance to gather and analyze software requirements. \n Design and develop high-quality, scalable, and maintainable software solutions using cutting-edge technologies and best practices. \n Write clean, efficient, and well documented code that adheres to industry standards, OneStream defined patterns and guidelines. \n Perform unit testing, debugging, and troubleshooting to ensure software functionality and reliability. \n Collaborate with the quality assurance team to ensure proper testing of software applications and resolve any identified issues. \n Other ad hoc duties as assigned by leadership \n \n Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions. \n \n \n  DESIRED SKILLS AND EXPERIENCE \n  Formal Education and Certification \n \n Bachelor\u2019s Degree in Computer Science, Computer Information Systems, Software Development, Electrical Engineering. Mathematics, Physics or equivalent technical discipline experience. \n \n \n \n  Required  Knowledge and Experience \n \n 5+ years of developing and industry experience with large scale distributed systems, multi-threading, and object-oriented programming and building/consuming REST services. \n Proficient in language frameworks such as: C#, VB.NET, .NET, Core, ASP.NET, Blazor. \n Experience accessing Cloud areas to locate needed information to achieve development tasks (VMs, KeyVaults, SQL, Storage, etc.). \n Experience using SQL Management Studio, SQL Queries for data retrieval, Joins, aliasing, connections. \n Understands the capability/value being delivered to the end users for all stories and features. Ensures it is reflected in the acceptance criteria for all user stories. \n Understanding of IIS Management, websites, services, application pools, configuration. \n Strong problem solving and analytical skills, with the ability to quickly grasp complex technical concepts and troubleshoot software issues. \n Excellent communication and collaboration skills, with the ability to work effectively in a team environment and communicate technical concepts to non-technical stakeholders. \n Experience in the finance or accounting domain is a plus \n \n \n \n  Preferred Education and Experience \n \n Azure certification such as Azure certifications: AZ-900 \u2013 Fundamentals a plus. \n Experience with financial application development (i.e. HFM, Planning, etc.). \n \n \n \n  Personal Attributes \n \n Ethical. \n Credible. \n Professional. \n Results-driven. \n Detail-oriented. \n Able to multi-task. \n Flexible and adaptable. \n Team player. \n Legally authorized to work for any company in the United States without sponsorship. \n \n \n \n  WHO WE ARE \n  OneStream\u00ae is an independent software company backed by private equity investors. OneStream provides an intelligent finance platform built to enable confident decision-making and maximize business impact. \n  OneStream unleashes organizational value by unifying data management, financial close and consolidation, planning, reporting, analytics, and machine learning. We empower Finance and Operations teams with AI-enabled insights to make faster and more intelligent decisions every single day. All in a single, modern CPM platform designed to continually evolve and scale with your organization. To learn more visit www.onestream.com. \n \n \n  WHY JOIN THE ONESTREAM TEAM \n \n Transparency around corporate structure, salary, and benefits \n Core value of customer success \n Variety of project work (not industry specific) \n Strong culture and camaraderie \n Multiple training opportunities \n \n \n \n  Benefits at OneStream Software \n  OneStream employees are passionate, hardworking individuals who go above and beyond to keep our customers happy and follow through on our mission statement. They consistently deliver the best and in turn, we make every effort to keep them cared for and happy. A sample of the benefits we provide are: \n \n Excellent Medical Plan \n Dental & Vision Insurance \n Life Insurance \n Short & Long Term Disability \n Vacation Time \n Paid Holidays \n Professional Development \n Retirement Plan \n \n \n \n  OneStream Software is an Equal Opportunity Employer. \n  #LI-Remote  #LI-JP1", "cleaned_desc": " Work on technology migrations for legacy solutions, create new solutions, team member with mentorship. \n Participates in requirements discussions to get clear understanding of user flows and patterns of consuming/using the features being implemented. \n Collaborate with cross-functional teams, including product managers, architects, and quality assurance to gather and analyze software requirements. \n Design and develop high-quality, scalable, and maintainable software solutions using cutting-edge technologies and best practices. \n Write clean, efficient, and well documented code that adheres to industry standards, OneStream defined patterns and guidelines. \n Perform unit testing, debugging, and troubleshooting to ensure software functionality and reliability. \n Collaborate with the quality assurance team to ensure proper testing of software applications and resolve any identified issues. \n Other ad hoc duties as assigned by leadership \n \n Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions. \n \n \n  DESIRED SKILLS AND EXPERIENCE \n  Formal Education and Certification \n \n Bachelor\u2019s Degree in Computer Science, Computer Information Systems, Software Development, Electrical Engineering. Mathematics, Physics or equivalent technical discipline experience. \n \n \n \n  Required  Knowledge and Experience \n   5+ years of developing and industry experience with large scale distributed systems, multi-threading, and object-oriented programming and building/consuming REST services. \n Proficient in language frameworks such as: C#, VB.NET, .NET, Core, ASP.NET, Blazor. \n Experience accessing Cloud areas to locate needed information to achieve development tasks (VMs, KeyVaults, SQL, Storage, etc.). \n Experience using SQL Management Studio, SQL Queries for data retrieval, Joins, aliasing, connections. \n Understands the capability/value being delivered to the end users for all stories and features. Ensures it is reflected in the acceptance criteria for all user stories. \n Understanding of IIS Management, websites, services, application pools, configuration. \n Strong problem solving and analytical skills, with the ability to quickly grasp complex technical concepts and troubleshoot software issues. \n Excellent communication and collaboration skills, with the ability to work effectively in a team environment and communicate technical concepts to non-technical stakeholders. \n Experience in the finance or accounting domain is a plus \n \n \n \n  Preferred Education and Experience \n \n Azure certification such as Azure certifications: AZ-900 \u2013 Fundamentals a plus. \n Experience with financial application development (i.e. HFM, Planning, etc.). \n \n \n \n  Personal Attributes \n ", "techs": ["c#", "vb.net", ".net", "core", "asp.net", "blazor", "sql management studio", "iis", "azure", "rest", "sql"]}, "84d8ae186249095f": {"terms": ["machine learning engineer"], "salary_min": 82620.93, "salary_max": 104616.51, "title": "Applications Engineer", "company": "Cnc Software Inc", "desc": "Here at Mastercam, we fully embrace remote work and believe you work best, where you feel most comfortable. Whether you work in our CT headquarters or from the comfort of your home office, we provide the optimal setup for success. Growth and development are a top priority and we wholeheartedly believe in investing in your future to help you achieve your career goals. \n \n  If you have a passion for your work, an inquisitive nature, and a pride in exceeding the expectations others have set for you \u2013 then Mastercam may just be the place you have been looking for. \n \n  Position Overview: \n  The Applications Engineer provides overall applications support of CNC Software\u2019s products; interfacing and collaborating with other CNC Software teams, resellers, partners, and customers as needed. \n \n  Essential Duties & Responsibilities: \n \n  Interact with internal stakeholders [Product Development and Product Owners] to work on specific areas/items as needed and to enhance and improve the Mastercam software. \n  Provide pro-active support for resellers, partners, customers, and internal departments and teams as needs arise or projects unfold. Support can range from the basic to the significant or complex, and the AE is the primary contact to research, investigate, and resolve each item in a timely manner. \n  Support customers directly with on-site visits and applications programming assistance. \n  Assist the CNC internal training team with multi-axis programming training, as well as Mill, Lathe, Wire, Router, and Art, virtually, internally, and externally. \n  Collaborate with Posts Department to resolve NC code issues. Modify and customize post processors. \n  Program, run, and maintain all machine tools in the CNC Manufacturing Lab. \n  Discover, research, and report programming defects and requests. Suggests temporary solutions to provide work arounds until problems are resolved with a permanent solution. \n  Produce presentations, documentation, and training materials with the use of Microsoft Office suite of products including Word, Excel, and PowerPoint. \n  Travel required for trade shows, reseller open houses, or machine tool dealer events. \n \n \n  Minimum Requirements & Qualifications: \n \n  4 - 6 years\u2019 experience programming CNC machine tools. \n  Bachelor\u2019s in Manufacturing, Mechanical or Software Engineering required or equivalent technical work experience. \n  Working knowledge of CAD/CAM programming software a plus (specifically Mastercam). \n  Possess a working knowledge of all types of CNC manufacturing processes. \n  Excellent trouble shooting, problem-solving and risk assessment skills. \n  Proven ability to work independently, with self-direction and organization, to complete tasks and projects in a pro-active manner. \n  Proven ability to multi-task and to manage several projects/tasks at once while projecting a positive outward demeanor. \n  Time management skills with proven experience contributing within a team environment successfully supporting others. \n  Above average communication skills, both written and verbal, with the ability to provide accurate and timely information in a succinct and easy to understand manner. \n  Client-centric approach to work, with ownership and pride in serving the customer experience in a professional and pleasant manner. \n \n \n  Company Introduction: \n  Our mission is to create software and services that solve the world\u2019s manufacturing challenges. Our software, Mastercam, is the most widely used CAM software in the world. Headquartered in Tolland, CT, we are a culture that embraces remote work, with a growing global team spanning three continents: Asia, Europe, and North America. As the industry leader, we strive to innovate, and we partner with our resellers and customers to make the impossible, well, possible. \n \n  CNC Software, LLC is an Equal Opportunity Employer . All qualified applicants will receive consideration for employment  without regard to race, religion, creed, color, national origin, alienage or citizenship status, sex, sexual orientation, gender identity or expression, transgendered status, partnership status, caregiver status, age, ancestry, physical, intellectual, learning or mental disability, pregnancy, childbirth or related condition, genetic information, medical condition including medical characteristics, marital or civil union status, familial status, veteran or military status , use of tobacco or other lawful products off premises and during non-working hours, or any other classification protected by applicable local, state or federal laws. \n \n  EOE/M/F/Vet/Disabled are encouraged to apply. \n  We are an E-Verify Employer.", "cleaned_desc": "  Produce presentations, documentation, and training materials with the use of Microsoft Office suite of products including Word, Excel, and PowerPoint. \n  Travel required for trade shows, reseller open houses, or machine tool dealer events. \n \n \n  Minimum Requirements & Qualifications: \n \n  4 - 6 years\u2019 experience programming CNC machine tools. \n  Bachelor\u2019s in Manufacturing, Mechanical or Software Engineering required or equivalent technical work experience.    Working knowledge of CAD/CAM programming software a plus (specifically Mastercam). \n  Possess a working knowledge of all types of CNC manufacturing processes. \n  Excellent trouble shooting, problem-solving and risk assessment skills. \n  Proven ability to work independently, with self-direction and organization, to complete tasks and projects in a pro-active manner. \n  Proven ability to multi-task and to manage several projects/tasks at once while projecting a positive outward demeanor. \n  Time management skills with proven experience contributing within a team environment successfully supporting others. \n  Above average communication skills, both written and verbal, with the ability to provide accurate and timely information in a succinct and easy to understand manner. \n  Client-centric approach to work, with ownership and pride in serving the customer experience in a professional and pleasant manner. ", "techs": ["microsoft office", "word", "excel", "powerpoint", "cad/cam", "mastercam"]}, "8c786ed93da7a39b": {"terms": ["machine learning engineer", "mlops"], "salary_min": 140000.0, "salary_max": 150000.0, "title": "WhereTo - Lead DevOps Engineer - Remote, USA", "company": "Flight Centre Travel Group", "desc": "JOB NO:  519214\n   \n BRAND:  FLIGHT CENTRE TRAVEL GROUP\n   \n WORK TYPE:  FULL TIME, REMOTE\n   \n LOCATION:  VIRTUAL - USA\n   \n CATEGORIES:  INFORMATION & TECHNOLOGY\n   \n \n \n \n WhereTo is a business travel startup from San Francisco that evolved into an agile development and design studio within the Flight Centre family. We build travel solutions used by some of the largest companies on the planet - we have just one goal: making business travel better for everybody. \n  WhereTo provides an AI-powered travel platform for corporate travel. Their platform uses machine learning algorithms to recommend personalized travel options based on a traveler's preferences, company policies, and budget. WhereTo's technology also allows for real-time travel tracking, reporting, and cost analysis, enabling companies to optimize their travel programs and reduce costs. \n  To learn more about WhereTo click HERE \n  About The Opportunity \n  As a Lead DevOps Engineer at WhereTo, you will play a pivotal role in shaping and managing our DevOps practices and infrastructure. You will lead a team of talented DevOps engineers and collaborate closely with cross-functional teams to ensure the reliability, scalability, and security of our travel platform. Your expertise will be essential in streamlining development and operations, automating processes, and implementing best practices for CI/CD pipelines \n  Key Responsibilities \n \n Leadership: Lead and mentor a team of DevOps engineers, providing guidance, coaching, and fostering a culture of collaboration and continuous improvement. \n DevOps Strategy: Develop and execute the DevOps strategy for WhereTo, including infrastructure as code (IAC), automation, and monitoring practices \n Infrastructure Management: Manage and scale our cloud-based infrastructure (AWS, Azure, or GCP) to meet the needs of our growing travel platform. \n CI/CD Pipeline: Design, implement, and maintain efficient and reliable CI/CD pipelines to accelerate the software development lifecycle. \n Automation: Identify opportunities for automation and implement tools and scripts to streamline deployments, configuration management, and other operational tasks. \n Security: Collaborate with the security team to ensure the security and compliance of our infrastructure and applications. \n Monitoring and Alerting: Implement robust monitoring and alerting solutions to proactively identify and resolve issues in our production environment. \n Performance Optimization: Continuously analyze and optimize system performance, scalability, and reliability. \n Documentation: Maintain clear and up-to-date documentation of the infrastructure, processes, and procedures. \n Budget Management: Manage the DevOps budget, ensuring cost-effectiveness and resource allocation. \n \n Experience & Qualifications \n \n Proven experience (5+ years) as a DevOps Engineer, with a strong background in infrastructure and automation. \n Previous experience leading projects and managing teams. \n Extensive knowledge of cloud platforms (Azure, AWS). \n Extensive knowledge of infrastructure as code (Terraform, Ansible, Chef etc.). \n Expertise in containerization and orchestration tools (Docker and Kubernetes). \n Proficiency in CI/CD tools (Github Actions, Jenkins, GitLab CI/CD, etc.) \n Strong scripting and coding skills (Python, Bash, etc.). \n Experience with monitoring and logging tools (Prometheus, ELK stack, etc.). \n Knowledge of all things networking: TCP / IP, ICMP, SSH, DNS, HTTP, SSL / TLS. \n Knowledge of storage systems, RAID, distributed file systems, HDFS, NFS, iSCSI / CIFS. \n Ability to compile and install Unix / Linux applications from source, test, and create package managed versions of such. \n Working knowledge of firewalls, VPN, routing, switching, load balancing, security, and DNS. \n Familiarity with security best practices and compliance standards. \n Extremely proficient with the Unix command line, shell scripting, and configuring systems monitoring tools. \n Excellent problem-solving skills and the ability to work under pressure. \n Ability to fight fires at scale, wrestle with lost instances on Azure/AWS, and can troubleshoot awry processes and servers with your eyes closed. \n Strong communication and interpersonal skills. \n A strong desire and ability to learn quickly. \n You are excited about providing services that affect millions of users at the world's largest companies. \n \n Work Perks! - What\u2019s in it for you: \n  FCTG is renowned internationally for having amazing perks and an even better culture. We understand that our people are our most valuable asset. It is the passion and dedication of our teams that keep the company on top of the industry ladder. It\u2019s also why we offer some great employee benefits and perks outside of the norm. \n \n Enjoy the freedom and flexibility  of a hybrid work structure that combines both remote and in-person work. \n Have fun:  At the heart of everything we do at Flight Centre is a desire to have fun. \n Reward & Recognition:  Celebrate the success of yourself and others at our regular Buzz Nights and at the annual Global Gathering - You'll have to experience it to believe it! \n Use your smarts:  Our people use their quick thinking, expertise, and tenacity to always figure things out. \n Love for travel:  We were founded by people who wanted to travel and want others to do the same. That passion is something you can\u2019t miss in our people or service. \n Personal connections:  We are a big business founded on personal relationships. \n Diversity, Equity & Inclusion \n \n Diversity Day: paid leave to observe holiday or cultural celebration of your choice \n DEI education \n Commitment to fair practices such as regular equity assessments and inclusive recruitment protocols \n \n \n \n A career, not a job:  We offer genuine opportunities for people to grow and evolve \n We back our people all the way:  We are strongly committed to supporting every single employee in their professional and personal development. \n Giving Back:  Proud Corporate Social Responsibility program supporting nominated charities through Workplace Giving, volunteering, and fundraising \n \n Employee giving program \n Office Environmental Program \n 1 Volunteer Day per Calendar Year \n \n \n Benefits Include: \n \n Paid Time Off * \n \n Up to 15 Vacation Days accrued per year - prorated upon hire and increased by tenure after 2 years of employment (up to 25 days) \n 5 Sick Days accrued per year \n 3 Personal Days \n 1 Diversity Day \n 1 Volunteer Day \n 8 Recognized Holidays \n \n Travel perks/discounts \n Health & Wellness Programs and Employee Financial Wellness Services \n National/International Award Nights and Conferences \n Health benefits including, medical, dental and vision \n Insurance including hospital indemnity, AD&D, critical illness, long-term and short-term disability \n Flexible Spending Accounts \n Employee Assistance Program \n 401k program with partial match \n Tuition Reimbursement Program \n Employee Share Plan \u2013 Ability to purchase company stock on Australian Stock Exchange with partial company match, subject to terms and conditions \n Global career opportunities in a network of brands and businesses \n \n \n Vacation, Personal, and Sick time accrual rates will vary based on full-time or part-time employee status. Recognized Holidays are either paid time off or, if required to work due to job requirements, holiday pay rate, and may vary depending on state. \n \n  #LI-SM1#WTO#LI-Remote \n \n \n  Location \u2013 Remote, USA \n  If this sounds like the opportunity you have been waiting for then . \n  The role can be performed onsite, remote or on a hybrid schedule, in compliance with the Company\u2019s Remote and Flexible Work Policy. \n  For this position, we anticipate offering an annual salary of  $140,000 - $150,000.  Base salary is dependent on relevant factors, including experience, geographic location, and job requirements. \n  We thank all candidates for their interest; however, only those selected to continue in the process will be contacted. \n  Our number one philosophy? Our people. Flight Center Travel Group USA\u2019s promise is to provide an environment with equality of respect, dignity and opportunity for all our employees. We value an inclusive and supportive workplace which truly reflects the diversity of our society. \n  We are an affirmative action and equal opportunity employer committed to providing a barrier-free pathway throughout our recruitment process. We welcome accommodation requests to help make our hiring and onboarding experience as accessible as possible. Please advise us about accommodation needs at any point by contacting our Recruitment Team at careers@us.flightcentre.com \n \n Applications close:  30 Nov 2023 Eastern Standard Time", "cleaned_desc": " CI/CD Pipeline: Design, implement, and maintain efficient and reliable CI/CD pipelines to accelerate the software development lifecycle. \n Automation: Identify opportunities for automation and implement tools and scripts to streamline deployments, configuration management, and other operational tasks. \n Security: Collaborate with the security team to ensure the security and compliance of our infrastructure and applications. \n Monitoring and Alerting: Implement robust monitoring and alerting solutions to proactively identify and resolve issues in our production environment. \n Performance Optimization: Continuously analyze and optimize system performance, scalability, and reliability. \n Documentation: Maintain clear and up-to-date documentation of the infrastructure, processes, and procedures. \n Budget Management: Manage the DevOps budget, ensuring cost-effectiveness and resource allocation. \n \n Experience & Qualifications \n \n Proven experience (5+ years) as a DevOps Engineer, with a strong background in infrastructure and automation. \n Previous experience leading projects and managing teams. \n Extensive knowledge of cloud platforms (Azure, AWS). \n Extensive knowledge of infrastructure as code (Terraform, Ansible, Chef etc.). \n Expertise in containerization and orchestration tools (Docker and Kubernetes). \n Proficiency in CI/CD tools (Github Actions, Jenkins, GitLab CI/CD, etc.) \n Strong scripting and coding skills (Python, Bash, etc.). \n Experience with monitoring and logging tools (Prometheus, ELK stack, etc.). \n Knowledge of all things networking: TCP / IP, ICMP, SSH, DNS, HTTP, SSL / TLS. \n Knowledge of storage systems, RAID, distributed file systems, HDFS, NFS, iSCSI / CIFS. \n Ability to compile and install Unix / Linux applications from source, test, and create package managed versions of such. \n Working knowledge of firewalls, VPN, routing, switching, load balancing, security, and DNS. \n Familiarity with security best practices and compliance standards. ", "techs": ["ci/cd pipeline", "automation", "security", "monitoring", "alerting", "performance optimization", "documentation", "budget management", "azure", "aws", "terraform", "ansible", "chef", "docker", "kubernetes", "github actions", "jenkins", "gitlab ci/cd", "python", "bash", "prometheus", "elk stack", "networking", "storage systems", "hdfs", "nfs", "iscsi/cifs", "unix/linux", "firewalls", "vpn", "routing", "switching", "load balancing", "dns", "security best practices."]}, "8e141cdf7ed1e7d4": {"terms": ["machine learning engineer"], "salary_min": 80000.0, "salary_max": 120000.0, "title": "Linux System Administrator", "company": "Tamaki Control", "desc": "Tamaki Control is looking for an independently motivated System Administrator to join our team of 10-15 engineers in the Twin Falls, ID branch. The System Administrator will be responsible for the maintenance, development, and configuration of industrial automation solutions. \n About Us \n At Tamaki Control, we use our expertise in PLC programming, HMI/SCADA, MES, machine learning, IIOT, robotics and many other technologies to design and implement real-time control systems for our customer\u2019s industrial processes. A global industrial systems integrator, Tamaki is a privately held company owned by its 70+ employees and has provided automation solutions for over 30 years. \n Key Responsibilities: \n \n Administer, maintain, and support Linux systems (Ubuntu and RedHat), Windows Server, VMWare, MariaDB, and MSSQL environments. \n Collaborate with project teams to design and configure systems for new automation projects, ensuring seamless integration and optimal performance. \n Provide technical support for both internal and customer systems, resolving issues in a timely and efficient manner. \n Monitor system performance and security, implementing necessary patches and updates to ensure system integrity. \n Manage backup and recovery processes, ensuring data availability and integrity. \n Assist in the documentation of system configurations, procedures, and policies. \n Provide training and guidance to junior staff members and end-users as needed. \n Participate in on-call rotation for after-hours support. \n \n Qualifications: \n \n Bachelor\u2019s degree in Computer Science, Information Technology, or related field. \n Minimum of 3 years of experience in IT systems administration, with a strong focus on Linux environments. \n Proven experience in managing and configuring VMWare environments. \n Familiarity with industrial automation systems, particularly Allen Bradley PLCs and Ignition SCADA/MES. \n Strong problem-solving skills and ability to work in a fast-paced environment. \n Excellent communication and collaboration skills. \n Detail-oriented with strong organizational skills. \n \n Nice-to-Haves: \n \n Cisco networking experience and certifications. \n Proficiency in SQL and database administration. \n Programming skills in Python, Java, or Javascript. \n Experience in network architecture design. \n \n Benefits: \n \n Competitive salary \n Comprehensive benefits package \n Opportunities for professional development and training \n Dynamic and collaborative work environment \n \n Job Type: Full-time \n Pay: $80,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Commission pay \n Employee stock ownership plan \n Employee stock purchase plan \n Hourly pay \n Profit sharing \n Yearly bonus \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n Monday to Friday \n \n Willingness to travel: \n \n 25% (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Qualifications: \n \n Bachelor\u2019s degree in Computer Science, Information Technology, or related field. \n Minimum of 3 years of experience in IT systems administration, with a strong focus on Linux environments. \n Proven experience in managing and configuring VMWare environments. \n Familiarity with industrial automation systems, particularly Allen Bradley PLCs and Ignition SCADA/MES. \n Strong problem-solving skills and ability to work in a fast-paced environment. \n Excellent communication and collaboration skills. \n Detail-oriented with strong organizational skills. \n \n Nice-to-Haves: \n \n Cisco networking experience and certifications. \n Proficiency in SQL and database administration. ", "techs": ["linux", "vmware", "allen bradley plcs", "ignition scada/mes", "cisco", "sql", "database administration"]}, "498bc89f8668bed8": {"terms": ["machine learning engineer"], "salary_min": 100607.055, "salary_max": 127390.945, "title": "ELK Elastic Search Engineer", "company": "Radiant Digital", "desc": "About Us: \n  Radiant Digital delivers technology consulting and business solutions for commercial and government clients.  \n Our flexible delivery model allows us to provide end-to-end solution delivery, single project execution, and, or strategic resources.  \n CMMI Maturity Level III and ISO 9001 \u2013 2015 certified. \n  Description: \n \n  Expertise in Elasticsearch, Logstash, Kibana, and employing machine learning-based anomaly detection. Proficiently manage the entire ELK stack, encompassing design, deployment, configuration, and ongoing maintenance of new ELK clusters.  \n On-call rotations to provide 24/7 support and rapid incident response for critical ELK Platform.  \n Streamline Elasticsearch cluster performance through proactive monitoring using PagerDuty, Prometheus and Grafana or equivalent to ensure minimal downtime and efficient issue resolution.  \n Working knowledge of Security and reliability of ELK and Splunk servers using Ansible and/or Salt automation, as well as manual maintenance and OS patching for Linux systems Hands on experience in CI/CD pipeline tools such as GitHub/GitLab/Jenkins etc. for efficient code updates and seamless distribution across  \n Our Global Technology Solutions group is looking for a Senior Systems & Software Engineer to lead and collaborate with portfolio teams across all LOB\u2019s to support a framework that combines engineering and application development to drive operational stability. The ideal candidate will collaborate with the core teams combining software practices and engineering to strengthen the enterprise logging practices along with operational support.  Advanced knowledge of system architecture, network, Centralized Logging (ELK), and operational stability will help transform the way the teams operate today. \n  \n \n \n Required Skills: \n  Five or more years of experience as a Full stack Linux Systems/Elastic & Application Support Engineer (Elastic Certified Engineer preferred) \n \n Strong knowledge of Systems Administration in Linux(RHEL/CentOS) and experience in troubleshooting applications running on these systems  \n Strong Hands on experience Elastic Stack of tools(Elastic Search, Logstash & Kibana) that monitor and manage critical applications and infrastructure  \n Securing, maintenance, optimization, documentation, and some design and build, Data Analytics & Visualization; \n Provide work breakdown and estimates for new requirements & Applying best practices for managing cluster, scaling and capacity planning. \n Create and manage Elasticsearch Clusters on premise, including configuration parameters, indexing, search and query performance tuning, RBAC security governance and administration;  \n Design and configuration of ETL data pipelines using Elastic Common Schema to onboard application logs and metrics; Configuration of index templates and data life cycle management ILM for data retention;  \n Designing and implementing solutions for centralized logs, infrastructure and health metrics, distributed tracing for different applications.  \n Create Dashboard on KPIs and Fine tune bulk load process.  \n Hands on Scripting & Programming in Python, Ansible, bash, data parsing (regex) etc.  \n Good knowledge with Tomcat, MySQL,nginx, haproxy  \n Experience with Security Hardening & Vulnerability/Compliance, OS patching, SSL/SSO/LDAP  \n Understanding of HA design, cross-site replication, local and global load balancers, etc  \n Data ingestion & enrichment from various sources, webhooks, and REST APIs with JSON/YAML/XML payloads & testing POSTMAN etc.  \n \n \u2022 CI/CD - Deployment pipeline experience (Ansible, GIT) \u2022 Strong knowledge of performance monitoring, metrics, capacity planning, and management  \n \n Familiarity with Confluence and JIRA  \n Ability to apply a systematic & creative approach to solve problems, out of box thinking with a sense of ownership and focus  \n Strong skills in creating documentation - engineering runbooks, support procedures, user onboarding and support documentation  \n Experience with application onboarding - capturing requirements, understanding data sources, architecture diagrams, application relationships etc.  \n Influencing other teams and engineering groups in adopting logging best practices.  \n Effective communication skills with the ability to articulate technical details to different audience \n \n \n  This is a remote position.", "cleaned_desc": " Streamline Elasticsearch cluster performance through proactive monitoring using PagerDuty, Prometheus and Grafana or equivalent to ensure minimal downtime and efficient issue resolution.  \n Working knowledge of Security and reliability of ELK and Splunk servers using Ansible and/or Salt automation, as well as manual maintenance and OS patching for Linux systems Hands on experience in CI/CD pipeline tools such as GitHub/GitLab/Jenkins etc. for efficient code updates and seamless distribution across  \n Our Global Technology Solutions group is looking for a Senior Systems & Software Engineer to lead and collaborate with portfolio teams across all LOB\u2019s to support a framework that combines engineering and application development to drive operational stability. The ideal candidate will collaborate with the core teams combining software practices and engineering to strengthen the enterprise logging practices along with operational support.  Advanced knowledge of system architecture, network, Centralized Logging (ELK), and operational stability will help transform the way the teams operate today. \n  \n \n \n Required Skills: \n  Five or more years of experience as a Full stack Linux Systems/Elastic & Application Support Engineer (Elastic Certified Engineer preferred)   \n Strong knowledge of Systems Administration in Linux(RHEL/CentOS) and experience in troubleshooting applications running on these systems  \n Strong Hands on experience Elastic Stack of tools(Elastic Search, Logstash & Kibana) that monitor and manage critical applications and infrastructure  \n Securing, maintenance, optimization, documentation, and some design and build, Data Analytics & Visualization; \n Provide work breakdown and estimates for new requirements & Applying best practices for managing cluster, scaling and capacity planning. \n Create and manage Elasticsearch Clusters on premise, including configuration parameters, indexing, search and query performance tuning, RBAC security governance and administration;  \n Design and configuration of ETL data pipelines using Elastic Common Schema to onboard application logs and metrics; Configuration of index templates and data life cycle management ILM for data retention;  \n Designing and implementing solutions for centralized logs, infrastructure and health metrics, distributed tracing for different applications.    Create Dashboard on KPIs and Fine tune bulk load process.  \n Hands on Scripting & Programming in Python, Ansible, bash, data parsing (regex) etc.  \n Good knowledge with Tomcat, MySQL,nginx, haproxy  \n Experience with Security Hardening & Vulnerability/Compliance, OS patching, SSL/SSO/LDAP  \n Understanding of HA design, cross-site replication, local and global load balancers, etc  \n Data ingestion & enrichment from various sources, webhooks, and REST APIs with JSON/YAML/XML payloads & testing POSTMAN etc.  \n \n \u2022 CI/CD - Deployment pipeline experience (Ansible, GIT) \u2022 Strong knowledge of performance monitoring, metrics, capacity planning, and management    \n Familiarity with Confluence and JIRA  \n Ability to apply a systematic & creative approach to solve problems, out of box thinking with a sense of ownership and focus  \n Strong skills in creating documentation - engineering runbooks, support procedures, user onboarding and support documentation  \n Experience with application onboarding - capturing requirements, understanding data sources, architecture diagrams, application relationships etc.  \n Influencing other teams and engineering groups in adopting logging best practices.  \n Effective communication skills with the ability to articulate technical details to different audience \n ", "techs": ["pagerduty", "prometheus", "grafana", "ansible", "salt", "linux", "github", "gitlab", "jenkins", "elk", "splunk", "elastic search", "logstash", "kibana", "python", "bash", "tomcat", "mysql", "nginx", "haproxy", "ssl", "sso", "ldap", "confluence", "jira", "postman"]}, "64c818d1ebeae7e3": {"terms": ["machine learning engineer"], "salary_min": 134761.48, "salary_max": 170638.08, "title": "Senior CloudOps Engineer (Remote)", "company": "BD Philippines", "desc": "JOB ID  R-473164\n    \n \n DATE POSTED  08/23/2023\n    \n \n \n \n \n Job Description Summary  Are you an experienced Microsoft Azure Cloud Engineer? Do you enjoy working in fast paced environments? Does leveraging cutting-edge technology to reimagine how Healthcare is provided intrigue you? We are the Cloud Infrastructure team at Liberator Medical, and we are looking for a seasoned Azure Engineer to join our team. The Cloud Infrastructure team is responsible for establishing Cloud Operational standards and ensuring the reliability, availability, and performance of the Production cloud environments. You will work in a dynamic team and partner with teams across the company to ensure that our Cloud Infrastructure meets the needs of our growing customer base. This is an opportunity to define and inform a modern future state automated self service cloud operations platform. \n    \n  This is a unique experience with opportunity to work and develop your skillset across modern areas within IT, including Infrastructure, Site reliability engineering ,FinOps, DevOps, Developer experience, security and end user services.\n    \n  We are excited to be looking for someone passionate about modernization, automation, culture building, mentoring, and focused on taking us to the next level of maturity.\n    \n  Job Description \n  We are the makers of possible \n \n  BD is one of the largest global medical technology companies in the world. Advancing the world of health\u2122 is our Purpose, and it\u2019s no small feat. It takes the creativity and passion of all of us\u2014from design and engineering to the manufacturing and marketing of our billions of MedTech products per year\u2014to look at the impossible and find ground-breaking solutions that turn dreams into possibilities. \n \n  We believe that the human element, across our global teams, is what allows us to continually evolve. Join us and discover an environment in which you\u2019ll be supported to learn, grow and become your best self. Become a maker of possible with us. \n \n  Responsibilities: \n \n  Help define and implement the Infrastructure and Operations strategy and 3-year roadmap ensuring programs are defined and driven. Gain alignment with senior leadership and key collaborators.Ensure technology roadmaps for infrastructure and operations services are maintained with timelines, impacts and dependencies communicated. \n  Leverage best in class automation strategies to change and improve the way we do business. We are an automation first organization looking for passionate team members that want to challenge the status quo. \n  Serve as mentor to developing staff members, reshaping our infrastructure platform and services. \n  Work on all areas of infrastructure and application services: Partner with versatile and dynamic team members and peers showcase the true possibilities of a modern cloud environment. \n  Automate the volume ! Help our teams focus on what's next and what's possible by implementing automation, redundant systems and a dynamic scalable architecture. \n  Work and supply across all areas of IT...including Infrastructure, Site reliability engineering, FinOps, DevOps, Developer experience, security and end user services. Break down silos and implement modern scalable platforms and process \n  Implement an Azure Cloud First Strategy. \n \n \n  Qualifications: \n \n  BS degree in Computer Science, Business, Engineering or equivalent experience welcomed! \n  5 to 10+ years of experience with Cloud Infrastructure and modern IT approaches \n  Experience supporting custom software development (SDLC) \n \n \n  PROFESSIONAL COMPETENCIES \n \n  Advanced skills and knowledge in building cloud platforms, demonstrating public/private cloud and container ecosystems \n  Excellent proficiency in a variety of platforms including databases, machine learning, modern runtimes, cloud native architectures and paradigms, continuous build, testing, and deployment platforms \n  Knowledge of networking, compute, storage, IaaS, PaaS solutions, cloud operations, system administration, service desk. \n  Optimally influences IT senior leaders and supporting IT teams on industry trends and emerging technologies in anticipation of new business processes and systems; challenge the status quo in support of the technology direction \n  Excellent verbal and written communication skills, demonstrating effective listening through concise, clear communication, required. \n  Excellent social skills that inspire and build trust resulting in effective working relationships across the company, required. \n  Keen attention to detail in planning, organization, and execution of tasks, while still seeing the big picture and understanding how all of the pieces fit together and affect one another, required. \n  Ability to rapidly adapt and respond to changes in environment and priorities. \n  Excellent problem solving, root cause analysis skills. Able to readily diagnose system deficiencies and independently design and implement effective solutions to sophisticated technical problems \n  Exceptional management & organizational skills enabling real time prioritization, an effective intake process for the team and a strong ability for holding the team accountable to results \n  Command of Terraform standard processes and implementation \n  CI/CD / DevOps and or SRE experience \n  Proven track record to take ownership and manage technical projects, including identification of project scope, requirements, deliverables, and coordination of project design and implementation activities \n  Prior experience evaluating and implementing \u201cBest in Class\u201d enterprise-wide Infrastructure solutions \n  Prior experience working with Infrastructure team in a SOX and/or SOC 2 /HIPAA regulated company \n  Direct experience improving and scaling an operations team demonstrating ITSM and ITIL practices. \n  Demonstrated experience working in an environment with PHI \n \n  For certain roles at BD, employment is contingent upon the Company\u2019s receipt of sufficient proof that you are fully vaccinated against COVID-19. In some locations, testing for COVID-19 may be available and/or required. Consistent with BD\u2019s Workplace Accommodations Policy, requests for accommodation will be considered pursuant to applicable law. \n \n  Why Join Us? \n  A career at BD means being part of a team that values your opinions and contributions and that encourages you to bring your authentic self to work. It\u2019s also a place where we help each other be great, we do what\u2019s right, we hold each other accountable, and learn and improve every day. \n \n  To find purpose in the possibilities, we need people who can see the bigger picture, who understand the human story that underpins everything we do. We welcome people with the creativity and aim to help us reinvent the future of health. At BD, you\u2019ll discover a culture in which you can learn, grow, and thrive. And find satisfaction in doing your part to make the world a better place. \n \n  To learn more about BD visit https://bd.com/careers \n \n  Becton, Dickinson and Company is an Equal Opportunity/Affirmative Action Employer. We do not unlawfully discriminate on the basis of race, color, religion, age, sex, creed, national origin, ancestry, citizenship status, marital or domestic or civil union status, familial status, affectional or sexual orientation, gender identity or expression, genetics, disability, military eligibility or veteran status, or any other protected status. \n \n  PDN \n \n  #LI-PRO \n \n  Primary Work Location  USA FL - Stuart Airport Road\n    \n  Additional Locations \n \n  Work Shift", "cleaned_desc": "  Implement an Azure Cloud First Strategy. \n \n \n  Qualifications: \n \n  BS degree in Computer Science, Business, Engineering or equivalent experience welcomed! \n  5 to 10+ years of experience with Cloud Infrastructure and modern IT approaches \n  Experience supporting custom software development (SDLC) \n \n \n  PROFESSIONAL COMPETENCIES \n \n  Advanced skills and knowledge in building cloud platforms, demonstrating public/private cloud and container ecosystems \n  Excellent proficiency in a variety of platforms including databases, machine learning, modern runtimes, cloud native architectures and paradigms, continuous build, testing, and deployment platforms \n  Knowledge of networking, compute, storage, IaaS, PaaS solutions, cloud operations, system administration, service desk.    Optimally influences IT senior leaders and supporting IT teams on industry trends and emerging technologies in anticipation of new business processes and systems; challenge the status quo in support of the technology direction \n  Excellent verbal and written communication skills, demonstrating effective listening through concise, clear communication, required. \n  Excellent social skills that inspire and build trust resulting in effective working relationships across the company, required. \n  Keen attention to detail in planning, organization, and execution of tasks, while still seeing the big picture and understanding how all of the pieces fit together and affect one another, required. \n  Ability to rapidly adapt and respond to changes in environment and priorities. \n  Excellent problem solving, root cause analysis skills. Able to readily diagnose system deficiencies and independently design and implement effective solutions to sophisticated technical problems \n  Exceptional management & organizational skills enabling real time prioritization, an effective intake process for the team and a strong ability for holding the team accountable to results \n  Command of Terraform standard processes and implementation \n  CI/CD / DevOps and or SRE experience \n  Proven track record to take ownership and manage technical projects, including identification of project scope, requirements, deliverables, and coordination of project design and implementation activities \n  Prior experience evaluating and implementing \u201cBest in Class\u201d enterprise-wide Infrastructure solutions \n  Prior experience working with Infrastructure team in a SOX and/or SOC 2 /HIPAA regulated company \n  Direct experience improving and scaling an operations team demonstrating ITSM and ITIL practices. \n  Demonstrated experience working in an environment with PHI \n ", "techs": ["azure", "terraform", "ci/cd", "devops", "sre", "sox", "soc 2", "hipaa", "itsm", "itil"]}, "85a8782735a3549e": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior UX Engineer - Partial Telework", "company": "GliaCell Technologies", "desc": "Are you a Senior UX Engineer who is ready for a new challenge that will launch your career to the next level? \n \n  Tired of being treated like a company drone? \n  Tired of promised adventures during the hiring phase, then being dropped off on a remote contract and never seen or heard from the mothership again? \n  Our engineers were certainly tired of the same. \n \n  At GliaCell our slogan is \u201cWe make It happen\u201d. \n \n  We will immerse you in the latest technologies. \n  We will develop and support your own personalized training program to continue your individual growth. \n  We will provide you with work that matters with our mission-focused customers, and surround you with a family of brilliant engineers.   \n \n Culture isn\u2019t something you need to talk about\u2026if it just exists. \n  If this sounds interesting to you, then we\u2019d like to have a discussion regarding your next adventure! If you want to be a drone, this isn\u2019t the place for you. \n  We Make It Happen! \n  GliaCell Technologies focuses on Software & System Engineering in Enterprise and Cyber Security solution spaces. We excel at delivering stable and reliable software solutions using Agile Software Development principles. These provide us the capability to deliver a quick turn-around using interactive applications and the integration of industry standard software stacks.  \n GliaCell\u2019s Enterprise capabilities include Full-Stack Application Development, Big Data, Cloud Technologies, Analytics, Machine Learning, AI, and DevOps Containerization. We also provide customer solutions in the areas of CND, CNE, and CNO by providing our customers with assessments and solutions in Threat Mitigation, Vulnerability Exposure, Penetration Testing, Threat Hunting, and Preventing Advanced Persistent Threat. \n  We Offer: \n \n  Long term job security \n  Competitive salaries & bonus opportunities \n  Challenging work you are passionate about \n  Ability to work with some amazingly talented people \n \n  Job Description: \n  GliaCell is seeking a  Senior User Experience (UX) Engineer  on one of our subcontracts. This is a full-time position offering the opportunity to support a U.S. Government customer. The mission is to provide technical expertise that assists in sustaining critical mission-related software and systems to a large government contract. \n  Position Description: \n \n  The Design team is focused on solving user experience challenges for technologies used within the IC.  \n The UX team partners with developers, managers, and system engineers to keep intelligence products modern and cutting-edge.  \n The team researches and documents user workflows, designs front-end systems, creates mockups, engages with users, and interacts with multiple development teams using tools like Axure and Adobe Creative Cloud Suite (Figma and XD are a plus). \n \n  Job Responsibilities: \n \n  Experience developing workshop scripts and facilitating UX methods to extract user feedback and synthesize UX artifacts. \n  Evaluate and produce information architectures to determine appropriate product structure and layout. \n  Develop wireframes to help users evaluate product structure before development. \n  Collaborate with other Designers to create UX artifacts. \n  Collaborate with Developers to provide UX expertise during development. \n  Implement usability tests with multiple UX practitioners. \n  Perform heuristic evaluations using standard UX principles to review user interfaces. \n  Conduct qualitative and quantitative research studies such as surveys, interviews, and usability tests. \n  Analyze qualitative and quantitative data to generate strategic and tactical insights. \n \n  Key Requirements: \n  To be considered for this position you must have the following: \n \n  Possess an active or rein-statable TS/SCI with Polygraph security clearance. \n  U.S. Citizenship. \n  The candidate shall have over 10 years of experience and a bachelor\u2019s degree in Graphics Design, Psychology, Human Factors, and Ergonomics (HFE), or an SE-related degree (SE, CompSci, Software, Business Process Engineering) or a related field is required. Other qualifications include: \n  Works well independently as well as on a team. \n  Strong communication skills. \n \n  Key Skills: \n \n  Ability to design graphic user interface elements, like menus, tabs, and widgets. \n  Experience with UI prototyping, visual communication, and interactive design. \n  Strong problem-solving abilities used to turn complex ideas into easily understood visuals. \n  Enterprise UX experience across multiple applications. \n  Omni channel marketing/design experience is a plus. \n  Background in workflow and usability testing and the capability to generate suggested changes per user and customer requests. \n  Ability to collaborate effectively with cross-functional product development teams. \n \n \n  Location:  Columbia, MD / Partial Telework \n  Salary:  Based on Education, Years of Experience, Skill and Abilities \n  Check Out Our Benefits: \n \n  Paid Time Off \n  Medical, Dental & Vision Benefits \n  Life & Disability Insurance \n  Tuition, Training & Certification Reimbursement \n  401K Contribution \n  Employee Referral Bonus Program \n  Equipment Reimbursement \n  Team Engagement & Outings \n  Swag \n \n  \u2026And more! \n  Learn more about GliaCell Technologies: https://gliacelltechnologies.applytojob.com/apply/ \n  To apply for this position, respond to this job posting and attach an updated resume for us to review. \n  GliaCell Technologies, LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. \n   \n Z7JbYsO8NY", "cleaned_desc": "  U.S. Citizenship. \n  The candidate shall have over 10 years of experience and a bachelor\u2019s degree in Graphics Design, Psychology, Human Factors, and Ergonomics (HFE), or an SE-related degree (SE, CompSci, Software, Business Process Engineering) or a related field is required. Other qualifications include: \n  Works well independently as well as on a team. \n  Strong communication skills. \n \n  Key Skills: \n \n  Ability to design graphic user interface elements, like menus, tabs, and widgets. \n  Experience with UI prototyping, visual communication, and interactive design. \n  Strong problem-solving abilities used to turn complex ideas into easily understood visuals. \n  Enterprise UX experience across multiple applications. \n  Omni channel marketing/design experience is a plus. \n  Background in workflow and usability testing and the capability to generate suggested changes per user and customer requests. \n  Ability to collaborate effectively with cross-functional product development teams. \n \n ", "techs": ["graphics design", "psychology", "human factors", "ergonomics", "software engineering", "computer science", "communication skills", "user interface design", "ui prototyping", "visual communication", "interactive design", "problem-solving", "enterprise ux", "omni channel marketing", "workflow", "usability testing", "collaboration"]}, "74871667ac4985ed": {"terms": ["machine learning engineer"], "salary_min": 121409.016, "salary_max": 153730.86, "title": "Technical Solutions/Engineering Team Lead", "company": "Pantheon Data", "desc": "Company Overview \n  Pantheon Data (a Kenific Holding company) is a private, small business based in the Washington, DC, area. Pantheon Data was founded in 2011, initially providing acquisition and supply chain management services to the US Coast Guard. Our service offerings have grown in the past ten years, including infrastructure resiliency, contact center operations, information technology, software engineering, program management, strategic communications, engineering, and cybersecurity. We have also grown our customer base to include commercial clients. The company has used this experience to expand our service offerings to other agencies within the Department of Homeland Security (DHS), the Department of Defense (DoD), and other Federal Civilian Agencies.   \n \n Position Overview: \n  Pantheon Data is seeking a  Technical Solutions/Engineering Team Lead  with a strong background in data-driven solution architecture and development to serve as a leader of a growing team of engineers. A successful candidate will have a history of proven leadership of small to mid-sized engineering teams. He/she should have extensive knowledge of the functional areas that support modern data-centric solutions, including, but not limited to, artificial intelligence and machine learning (AI/ML), data engineering, data science, and data analytics. Though proven technical knowledge is a requirement, this position focuses on team leadership. A successful candidate should be prepared to manage projects, product implementations, product backlogs, and people. He/she will also be able to communicate clearly and effectively with engineers as well as less technical team members (e.g., engineers, project managers, customers, executive teams). \n  Responsibilities \n \n  Manage project resources, including allocation and budget. \n  Direct and encourage engineering team members toward prompt delivery of best-in-class technical solutions. \n  Leverage cloud-based architectures, technologies, and/or platforms to deliver optimized ML backed solutions at scale. \n  Supply leadership and technical guidance to a growing team of engineers during product development lifecycle. \n  Communicate with project manager(s) to interpret customer requirements and assign engineering tasks accordingly. \n  Collaborate with project manager(s) and team members to architect solutions that exceed customer expectations.  \n Recruit team members by reviewing resumes, conducting interviews, and delivering hiring recommendations. \n \n  Requirements \n \n  Bachelor's degree or higher in a technical field \n  Professional experience and a project or product manager \n  5+ years professional hands-on experience as an AI/ML engineer, data engineer, or data scientist \n  Strong understanding of Python programming language \n  Professional experience as a technical team lead \n  Strong understanding of all components that make up modern datacentric products, solution design, and development. \n  Excellent communication skills with the ability to interact clearly and succinctly in written and oral presentations. \n  Detail-oriented, self-motivated, and organized \n \n  Clearance Requirements  \n This role requires U.S. Citizenship and the ability to obtain/maintain Secret clearance. \n  Work Location: \n  Remote  \n Benefits Overview \n  We are always looking for good people! Pantheon Data is committed to providing its employees with competitive salaries and benefits in order to increase employee satisfaction and productivity. In addition to our benefits, we also offer SmartBenefits through the Washington Metro Area Transportation Authority, where you specify an amount of your pre-tax wages be paid directly to your SmarTrip account. In some cases, tuition assistance may be available for continuing education expenses and certifications related to their position. Additional details may be found at https://pantheon-data.com/careers/ \n  This employer uses E-Verify.", "cleaned_desc": "  Professional experience and a project or product manager \n  5+ years professional hands-on experience as an AI/ML engineer, data engineer, or data scientist \n  Strong understanding of Python programming language \n  Professional experience as a technical team lead \n  Strong understanding of all components that make up modern datacentric products, solution design, and development. \n  Excellent communication skills with the ability to interact clearly and succinctly in written and oral presentations. ", "techs": ["python"]}, "52bce49f459a23df": {"terms": ["machine learning engineer"], "salary_min": 124207.5, "salary_max": 157274.38, "title": "Senior Java Engineer", "company": "NTENT", "desc": "Senior Java Engineer \n \n \n \n Position:  Full time\n  \n \n Location:  Toronto, Ontario (Initially Remote)\n  \n \n \n About Us: \n \n \n  We are a unique group of brilliant minds intent on discovering, learning and building. We work in a vibrant atmosphere, with an emphasis on personal and professional development. This is an opportunity to tackle complex problems usually reserved for a handful of large companies in the search industry and build cutting edge Machine Learning and AI based Applications.\n  \n \n  NTENT provides a Platform-as-a-Service (PaaS), allowing industry partners to customize, localize and integrate Search technologies directly into their business-to-consumer offerings. NTENT utilizes advanced machine learning to decipher meaning and surface the most relevant answers.\n  \n \n \n About the Opportunity: \n \n \n  We are a dynamic company and our team is growing! We are looking for our next great hires to join our satellite team in Toronto, Ontario.\n  \n \n  We are looking for a talented \n   Senior Java Engineer  to deliver world-class search engine technologies. You will be working with a smart team of machine learning scientists and software developers on both full applications and tools that power NTENT\u2019s powerful search platform. Seeking mid-level up to Architect level candidates.\n  \n \n \n Duties and Responsibilities: \n \n \n Building the backend engine that runs our product. This includes extending our existing Machine Learning and Big Data pipelines and building entirely new capabilities, including: \n    \n Big Data cluster, workflows and applications: data pipelines at scale, and real-time processing \n Machine learning and Data Scientist support: used in linguistics, ranking, classification, and other artificial intelligence applications \n \n Ingestion Pipeline: process data that comes from our web crawler which discovers and fetches content from the web and other sources \n \n \n \n Skills and Qualifications: \n \n \n BS or MS degree in Computer Science \n Solid experience with Java programming (we also use Spring, Spring Webflux, Reactor, Netty) \n Multi-threading experience is a must \n Experience in scalable architectures and high-throughput application design \n Experience working with microservices/REST APIs (HTTP, XML, JSON) \n Comfortable in Linux and Windows environments. \n Prefer some experience with Big Data Technologies (at least one of the following): \n    \n Hadoop ecosystem (HDFS, Hadoop, Hive) \n Spark \n Samza \n Kafka \n Aerospike \n Lucene NLP (Solr or ElasticSearch) \n \n \n \n \n The following experience is a plus: \n \n \n Machine Learning \n Continuous Integration and Deployment \n Tool usage: Git/Gitlab and IntelliJ \n Functional programming experience (Scala) \n Gradle \n Avro \n Docker/Kubernetes \n \n \n \n  The ideal candidate will be self-motivated, possess excellent communication skills (both oral and written) and be able to work efficiently and independently in an agile development environment.\n  \n \n \n  We offer a full comprehensive benefits package including medical, dental and vision. Employees receive a generous time off (PTO) plan and 13 holidays per year. We also offer 401(k) benefits, long term disability benefits and life insurance. With a casual and flexible work environment.", "cleaned_desc": " Duties and Responsibilities: \n \n \n Building the backend engine that runs our product. This includes extending our existing Machine Learning and Big Data pipelines and building entirely new capabilities, including: \n    \n Big Data cluster, workflows and applications: data pipelines at scale, and real-time processing \n Machine learning and Data Scientist support: used in linguistics, ranking, classification, and other artificial intelligence applications \n \n Ingestion Pipeline: process data that comes from our web crawler which discovers and fetches content from the web and other sources \n \n \n \n Skills and Qualifications: \n \n \n BS or MS degree in Computer Science   Solid experience with Java programming (we also use Spring, Spring Webflux, Reactor, Netty) \n Multi-threading experience is a must \n Experience in scalable architectures and high-throughput application design \n Experience working with microservices/REST APIs (HTTP, XML, JSON) \n Comfortable in Linux and Windows environments. \n Prefer some experience with Big Data Technologies (at least one of the following): \n    \n Hadoop ecosystem (HDFS, Hadoop, Hive) \n Spark \n Samza \n Kafka \n Aerospike \n Lucene NLP (Solr or ElasticSearch) \n \n \n   \n The following experience is a plus: \n \n \n Machine Learning \n Continuous Integration and Deployment \n Tool usage: Git/Gitlab and IntelliJ \n Functional programming experience (Scala) \n Gradle \n Avro \n Docker/Kubernetes \n \n \n \n  The ideal candidate will be self-motivated, possess excellent communication skills (both oral and written) and be able to work efficiently and independently in an agile development environment.\n  ", "techs": ["machine learning", "big data", "java", "spring", "spring webflux", "reactor", "netty", "multi-threading", "scalable architectures", "microservices", "rest apis", "linux", "windows", "hadoop ecosystem", "hdfs", "hadoop", "hive", "spark", "samza", "kafka", "aerospike", "lucene nlp", "solr", "elasticsearch", "machine learning", "continuous integration", "continuous deployment", "git", "gitlab", "intellij", "functional programming", "scala", "gradle", "avro", "docker", "kubernetes"]}, "4ecfc08a4211ffcd": {"terms": ["mlops"], "salary_min": 136001.84, "salary_max": 172208.66, "title": "Senior DevOps/Cloud Engineer", "company": "FutureFit AI", "desc": "Come join our Engineering team!     \n  FutureFit AI is looking for a Senior DevOps/Cloud Engineer to join our team. We have a culture of high trust, high impact, high velocity and a gritty determination to win. If you are passionate about all things devops/cloud, like to have fun, do it right, and get things done we would love to hear from you! \n  An important note: Data shows that men on average apply for a role if they meet 3/10 requirements while women often only do so if it\u2019s 10/10. We work hard to be clear and specific about what our roles include and encourage you to apply if you see a strong (but not necessarily perfect) fit between you and the opportunity. \n \n  About You: \n \n  CI/CD - You can build and maintain pipelines that achieve continuous delivery with confidence and quality \n  Cloud - You have experience deploying, running and maintaining scalable and resilient applications in AWS via infrastructure as code \n  Security - You have designed and built secure cloud networks and the associated controls/processes to maintain and monitor that performance and security \n  Best Practices - You believe in and foster a culture of strong engineering principles around logging, monitoring, test automation and designing for reliability, scalability, observability and security \n  Test Automation - You are a firm believer in all levels of test automation (unit, api, UI) to support continuous delivery with confidence and quality \n  Communication - You can share your perspective clearly and constructively, you are comfortable challenging ideas and collaborating to find the best approach \n  Grit - You like to solve challenging problems, are not afraid of the unknown, eager to learn and take a systematic approach to solving problems \n  AI - You are interested in integrating advances in AI into FutureFit AI products and the development process to drive improvements in velocity, quality and engineer experience \n  Values - You are a good person who shares our values of excellence, transparency, and humanity \n \n \n  Core Requirements: \n \n  CI/CD - proven experience managing repositories and pipelines (GitHub Actions preferred) \n  Infrastructure as Code - proven experience with CDK, Terraform or Pulumi \n  AWS - proven experience deploying, running, maintaining, monitoring, securing, and scaling multi-tenant, web applications on AWS \n \n \n  Our Technology Stack: \n \n  Front End - React, TypeScript, Tailwind, Storybook \n  Back End - Node.js, Nest.js, Python, Flask, GraphQL, Elasticsearch \n  Data Stores - Postgres, Mongo, S3, Redshift \n  DevOps/Cloud - GitHub, SonarCloud, Sentry, New Relic, AWS (GuardDuty, Cognito, CloudFront, ECS, RDS, S3, SQS, Lambda, etc) \n \n \n  Location: \n  Most days we work from home but everyone comes to the office at least once a week for face to face collaboration and team building. The office is located at 325 Front St West (a short walk from Union Station). \n \n  Our Company: \n  In looking at a job posting, it\u2019s often hard to get a basic picture of the company profile (size, stage, structure, etc.) which is why we are sharing it with you upfront. This helps you quickly decide and helps us focus any time we spend together on going beyond the basics: \n \n  Funding : We have raised one round of funding led by JP Morgan which fueled a significant growth trajectory for us and we have a safe financial runway to execute against. \n \n  Problem Domain:  Future of Work / Workforce Development - important that the problem domain interests you even if you haven\u2019t worked in the space before. \n \n  Customers : We partner with workforce development agencies, government agencies, and employers/enterprises. \n \n  Structure : We are organized around the following key departments: Growth, Customer Success, Product, Engineering, Data, People & Culture, Finance & Operations. \n \n  Team : We are a team of 30-50 across US and Canada with main hubs in New York and Toronto. This role will be based in Toronto. \n  Core Principles : Be Curious, Drive to Outcomes, Raise the Bar, Speed Matters, Own It, Put We Over Me \n \n  About FutureFit AI \n  At FutureFit AI, we\u2019re on a mission to unlock pathways between talent and opportunity using the power of AI. We focus on personalized, AI-powered career guidance for job seekers, emphasizing skills over extensive resumes, and partner with workforce development partners, governments, and employers to level access to opportunity. \n \n  FutureFit AI is a growing, venture-backed company focused on using technology to improve the lives and outcomes for people going through career transitions. We\u2019re a small, driven team, united by our commitment to the job seekers and workforce ecosystems we serve. We're not just building a company; we're shaping the future of work. \n \n  We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, perform essential job functions, and receive other benefits and privileges of employment. Please contact us to request an accommodation. \n   FutureFit AI All rights reserved, we are proud to be an equal opportunity workplace. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, religion, color, gender identity, sexual orientation, age, disability, veteran status, or other applicable legally protected characteristics. We encourage people of different backgrounds, experiences, abilities, and perspectives to apply.", "cleaned_desc": "  Communication - You can share your perspective clearly and constructively, you are comfortable challenging ideas and collaborating to find the best approach \n  Grit - You like to solve challenging problems, are not afraid of the unknown, eager to learn and take a systematic approach to solving problems \n  AI - You are interested in integrating advances in AI into FutureFit AI products and the development process to drive improvements in velocity, quality and engineer experience \n  Values - You are a good person who shares our values of excellence, transparency, and humanity \n \n \n  Core Requirements: \n \n  CI/CD - proven experience managing repositories and pipelines (GitHub Actions preferred) \n  Infrastructure as Code - proven experience with CDK, Terraform or Pulumi \n  AWS - proven experience deploying, running, maintaining, monitoring, securing, and scaling multi-tenant, web applications on AWS ", "techs": ["github actions", "cdk", "terraform", "pulumi", "aws"]}, "38d5b2f771e6a19e": {"terms": ["mlops"], "salary_min": 90.0, "salary_max": 100.0, "title": "Sr Azure DevOps Architect", "company": "GSK Solutions", "desc": "Job Title: Sr Azure DevOps Architect (Remote - Locals Only) \n Location: Remote (Denver, CO) \n Duration: 8 Months \n Scope of Work \n Build a proof of concept to replace the Colorado Child Care Licensing System (CCCLS) Legacy application using the Microsoft PowerApps Platform, Azure Dataverse, running on Azure infrastructure and achieve compliance in statutory and regulatory audit findings. \n Minimum Resource Requirements - Required \n \u00b7 Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n \u00b7 Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n \u00b7 3 years - hands on experience: \n o Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n o Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations \n o Common data services (Dataverse) \n o Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. \n o Designing and developing elegant applications with Microsoft Power Platform (Apps, Portal, Automate, Dataverse, etc.) precisely supporting the architectural vision \n o Developing and automating business process flows, approval flows, etc. with a focus on Automate \n o Contributing to solution design activities supporting the architectural vision and an enterprise-wide approach \n o Integration to enterprise components, such as: support system ticketing, CI/CD, Git commands, Branching, Azure Repos, Devops, Pipelines, Test, etc. \n o Applying proper governance throughout the SDLC. \n Additional Important Requirements: \n \u00b7 Infrastructure as Code with tools, such as: Terraform (some experience required), Terragrunt, CloudFormation, Resource Manager, Octopus, Pulumi, Ansible, Chef, Puppet, Crossplane, Vagrant, Saltstack, etc.) \n \u00b7 Configuration of Power Platform environments (Dev, Test, Prod) \n \u00b7 Technical documentation \n \u00b7 Strong teaching/mentoring/knowledge transfer skills/experience \n Job Type: Contract \n Salary: $90.00 - $100.00 per hour \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n \u00b7 Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n \u00b7 3 years - hands on experience: \n o Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n o Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations \n o Common data services (Dataverse) ", "techs": ["agile", "safe", "power platform", "azure devops", "pipelines", "powerapps", "portal", "automate", "canvas", "integrations", "common data services", "dataverse"]}, "9cd6d6c9059d9924": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Senior Manager, DevOps, Test Automation Framework and Tools (Remote/Flexible)", "company": "Insulet Corporation", "desc": "Insulet started in 2000 with an idea and a mission to enable our customers to enjoy simplicity, freedom and healthier lives through the use of our Omnipod\u00ae product platform. In the last two decades we have improved the lives of hundreds of thousands of patients by using innovative technology that is wearable, waterproof, and lifestyle accommodating.\n  \n \n \n \n \n \n \n       We are looking for highly motivated, performance driven individuals to be a part of our expanding team. We do this by hiring amazing people guided by shared values who exceed customer expectations. Our continued success depends on it!\n      \n \n \n \n \n \n \n   Job Title: Senior Manager, DevOps, Test Automation Framework and Tools\n  \n \n   Department: R&D Medical Devices\n  \n \n   FLSA Status: Exempt\n  \n \n \n   Insulet started in 2000 with an idea and a mission to enable our customers to enjoy simplicity, freedom and healthier lives through the use of our Omnipod\u00ae product platform. In the last two decades we have improved the lives of hundreds of thousands of patients by using innovative technology that is wearable, waterproof, and lifestyle accommodating.\n  \n \n   We are looking for highly motivated, performance driven individuals to be a part of our expanding team. We do this by hiring amazing people guided by shared values who exceed customer expectations. Our continued success depends on it!\n  \n \n   Position Overview:\n  \n \n   The Senior Manager, DevOps, Test Automation Framework and Tools will be responsible for delivering critical strategic guidance and planning efforts to core DevOps, Test Automation Framework and Tools development capabilities. This role will drive the continuous integration of cross functional capabilities that will enable Insulet to establish a world class continuous integration and continuous delivery pipeline. This is a full-time exempt position reporting to the Sr Director, Mobile Applications.\n  \n \n   Responsibilities\n  \n \n  Identify opportunities of improvement in the end-to-end release process in Insulet and lead the DevOps, Test Automation Framework and Tools team in developing the tools and solutions to address them. \n  Develop and drive a clear vision and strategic roadmap of initiatives that improve the scalability, reliability, and efficiency of end-to-end release delivery and validation. \n  Identify, present, and implement strategies that address future needs for technology and lab expansion to ensure Insulet\u2019s future product roadmap is supported. \n  Ensure that critical test automation and release management infrastructure meets the standards of operational excellence to support continuous validation and release processes. \n  Ensure the automation and integration requirements for internal customers are responded by the team in a timely and flexible manner. \n  Drive the DevOps, Test Automation Framework and Tools team to deliver capabilities to track and provide a platform to monitor metrics on the performance of Insulet\u2019s continuous integration and delivery infrastructure. \n  Lead and manage a large team of engineers, providing mentorship, guidance, and professional development opportunities. \n  Foster a culture of innovation, collaboration, and continuous improvement within the team. \n  Manage and prioritize the budget, resources, and timelines to ensure successful team execution. \n  Drive the team to meet critical Quality, Regulatory, and Manufacturing requirements across all deliverables. \n  Collaborate closely with the cross functional SW Mobile Applications leadership on organizational-wide initiatives. \n \n \n \n   Education and Experience Requirements\n  \n \n   Minimum Requirements\n  \n \n  Requires a BS degree and 10-15 years of prior relevant experience or Masters with 8-10 years of prior relevant experience. \n  Demonstrated success in driving improvements in automation of continuous integration and continuous delivery of mobile solutions as a team leader. \n  Demonstrated ability to adapt to new technologies and grasp new concepts quickly. \n \n \n   Preferred Requirements\n  \n \n  Experience collaborating and responding to multiple releases in a fast-paced environment with cross functional teams of 100+ developers and partners. \n  Strong verbal and written communication tools, able to communicate at multiple levels of an organization. \n  A passionate, inspirational leader who leads with an enterprise mindset, challenges the status quo, and can align their organization behind a clear vision and strategy. \n  Has strong emotional intelligence and ability to engage and lead others through change to advance new ways of working. \n  Experience building high performance teams, driving accountability, empowerment, customer centricity and collaboration across functions and teams. \n  Talent leader with demonstrated success attracting, growing, and developing talent. \n  Strong technical background in working with both android and iOS mobile platforms \n  Proven experience working with automation and test management tools such as JIRA, ALM, Confluence, and Helix. \n  Experience in MedTech, Fintech, or other regulated industry a plus \n \n \n \n  Additional Information\n  \n \n  The position can be remote, hybrid or in-person at our San Diego, CA location. \n  Travel is estimated at 20% but will be flexible depending on business need. \n \n \n \n   Physical Requirements (if applicable):\n  \n \n  It is expected that you can travel to Insulet\u2019s San Diego (CA), Acton (MA) or Tijuana (MX) offices at least twice per quarter to support critical planning and executive coordination activities. \n \n \n \n   NOTE: This position is eligible for 100% remote working arrangements (may work from home/virtually 100%; may also work hybrid on-site/virtual as desired). #LI-remote\n  \n \n \n   Additional Information:\n   The US base salary range for this full-time position is $157,360.00 - $223,750.00. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position in the primary work location in the US. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your Talent Acquisition Specialist can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.\n  \n \n \n    At Insulet Corporation all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\n   \n \n \n \n \n \n \n \n \n \n           (\n           \n           Know Your Rights\n           )", "cleaned_desc": "  Experience collaborating and responding to multiple releases in a fast-paced environment with cross functional teams of 100+ developers and partners. \n  Strong verbal and written communication tools, able to communicate at multiple levels of an organization. \n  A passionate, inspirational leader who leads with an enterprise mindset, challenges the status quo, and can align their organization behind a clear vision and strategy. \n  Has strong emotional intelligence and ability to engage and lead others through change to advance new ways of working. \n  Experience building high performance teams, driving accountability, empowerment, customer centricity and collaboration across functions and teams. \n  Talent leader with demonstrated success attracting, growing, and developing talent. \n  Strong technical background in working with both android and iOS mobile platforms \n  Proven experience working with automation and test management tools such as JIRA, ALM, Confluence, and Helix. \n  Experience in MedTech, Fintech, or other regulated industry a plus \n \n \n \n  Additional Information\n  \n \n  The position can be remote, hybrid or in-person at our San Diego, CA location. \n  Travel is estimated at 20% but will be flexible depending on business need. \n \n \n \n   Physical Requirements (if applicable):\n  \n ", "techs": ["jira", "alm", "confluence", "helix"]}, "b52b86dd6970763a": {"terms": ["mlops"], "salary_min": 122415.17, "salary_max": 155004.89, "title": "Senior DevOps Engineer", "company": "Saas.group", "desc": "saas.group was founded in 2017 with a simple goal in mind: to help promising, profitable SaaS companies reach their full potential. \n  We are a fully remote, international team with colleagues in over 31 countries around the world. Our portfolio currently consists of 17 well-known SaaS companies and is continuously growing. We extended our team from 50 to 250+ people in the last 2 years through hiring and acquisitions. \n  This position is part of our Central DevOps team. \n  Position overview \n  The DevOps Team is responsible for managing saas.group central infrastructure but also acts as a consultant for our brands. The main idea behind it is to create and maintain a set of central services, like observability, backups or SSO, that our brands can just use instead of managing them on their own. As a member of the team, you will be responsible for creating solutions and supervising the progress as well as assisting the brands with various infrastructure-related projects and tasks like; \n \n Leading and performing infrastructure-related projects for saas.group brands: maintenance, performance optimization, incident management, migrations to Kubernetes, dockerizing apps, etc \n Assisting saas.group brands in their day-to-day infrastructure tasks: performing upgrades, deployments, configuring CI/CD pipelines, securing the infrastructure, etc \n Automating various aspects in the infrastructure: provisioning, deployments, etc \n Cooperating with dev team to ensure the high level of availability, stability and security for all applications \n Performing cloud costs optimizations \n Performing on call duties and incident management best practices \n \n What you bring to the table \n \n You have 5+ years of experience as DevOps / Platform Engineer or SRE; \n You have a good practical knowledge of Docker and Kubernetes; \n You are comfortable with a couple of cloud providers (AWS, GCP, Azure, Heroku, Digital Ocean, Hetzner - we run on a multi cloud infrastructure); \n You have a knowledge of commercial log and observability services like Datadog, New Relic and/or self-hosted observability tools like ELK, Prometheus; \n You have experience with Cloudflare, Redis, Kafka, RabbitMQ; \n You have experience with IaC tools (preferably Terraform); \n You are familiar with CI/CD concepts and methodologies; \n You have experience with Linux (any major distribution); \n You have experience in Relational (PostgreSQL, MySQL) and non-relational databases (MongoDB) - prior DBA experience would be a great plus \n You have the ability to code in any modern scripting language (Python, Ruby, etc) \n You have knowledge about security best practices \n You have experience with Git tools \n Outstanding communication, stakeholder management skills and a consultative approach \n \n What we offer \n \n Ultimate flexibility:  We\u2019re 100% remote. You can work from wherever you like, whenever you like. European time zone preferred. \n Freedom and autonomy:  We\u2019re a high-trust team, and you\u2019ll be given lots of independence to solve problems in your own way \u2014 with plenty of help from the team when you need it. \n Minimum bureaucracy:  We don\u2019t like to get bogged down with meetings and red tape. We like to be efficient and keep momentum steady & sustainable. \n Small & friendly team:  We help each other out, have fun, and joke around. \n Unlimited paid time off:  We want you to recharge your batteries when needed.", "cleaned_desc": " \n You have 5+ years of experience as DevOps / Platform Engineer or SRE; \n You have a good practical knowledge of Docker and Kubernetes; \n You are comfortable with a couple of cloud providers (AWS, GCP, Azure, Heroku, Digital Ocean, Hetzner - we run on a multi cloud infrastructure); \n You have a knowledge of commercial log and observability services like Datadog, New Relic and/or self-hosted observability tools like ELK, Prometheus; \n You have experience with Cloudflare, Redis, Kafka, RabbitMQ; \n You have experience with IaC tools (preferably Terraform);   You are familiar with CI/CD concepts and methodologies; \n You have experience with Linux (any major distribution); \n You have experience in Relational (PostgreSQL, MySQL) and non-relational databases (MongoDB) - prior DBA experience would be a great plus \n You have the ability to code in any modern scripting language (Python, Ruby, etc) \n You have knowledge about security best practices \n You have experience with Git tools \n Outstanding communication, stakeholder management skills and a consultative approach ", "techs": ["docker", "kubernetes", "aws", "gcp", "azure", "heroku", "digital ocean", "hetzner", "datadog", "new relic", "elk", "prometheus", "cloudflare", "redis", "kafka", "rabbitmq", "terraform", "linux", "postgresql", "mysql", "mongodb", "python", "ruby", "git"]}, "61504a9588562582": {"terms": ["mlops"], "salary_min": 95.0, "salary_max": 105.0, "title": "Sr Azure DevOps Architect", "company": "SohanIT Inc", "desc": "Job Description \n *****Direct Client Requirement***** \n Job Title:  Sr Azure DevOps Architect \n Location: Denver, Colorado (Remote) \n Duration: 9 months \n Interview: type Skype or Phone \n Job type: C2C,W2,1099 \n Experience: 10+ years \n Job Description \n Period of Performance \n  The Trails Developer shall commence on or before November 6, 2023 and continue through June 30, 2024 or earlier depending on the maximum of 800 hours being exhausted. \n Purpose : The project is to implement the specific business requirements on this new cloud no-code/low-code platform and requires particular expertise to support the Trails team in the development and implementation of the project as this is a new platform for the state of Colorado. \n Scope of Work \n  Build a proof of concept to replace the Colorado Child Care Licensing System (CCCLS) Legacy application using the Microsoft PowerApps Platform, Azure Dataverse, running on Azure infrastructure and achieve compliance in statutory and regulatory audit findings. \n Minimum Resource Requirements - Required \n \n Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n 3 years - hands on experience: \n Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations \n Common data services (Dataverse) \n Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. \n Designing and developing elegant applications with Microsoft Power Platform (Apps, Portal, Automate, Dataverse, etc.) precisely supporting the architectural vision \n Developing and automating business process flows, approval flows, etc. with a focus on Automate \n Contributing to solution design activities supporting the architectural vision and an enterprise-wide approach \n Integration to enterprise components, such as: support system ticketing, CI/CD, Git commands, Branching, Azure Repos, Devops, Pipelines, Test, etc. \n Applying proper governance throughout the SDLC. \n \n Additional Important Requirements: \n \n Infrastructure as Code with tools, such as: Terraform (some experience required), Terragrunt, CloudFormation, Resource Manager, Octopus, Pulumi, Ansible, Chef, Puppet, Crossplane, Vagrant, Saltstack, etc.) \n Configuration of Power Platform environments (Dev, Test, Prod) \n Technical documentation \n Strong teaching/mentoring/knowledge transfer skills/experience \n \n Job Type: Contract \n Salary: $95.00 - $105.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n Azure: 10 years (Required) \n Kubernetes: 10 years (Required) \n Azure devops: 10 years (Required) \n Power Apps: 10 years (Required) \n Integration power platform: 10 years (Required) \n Common data services: 8 years (Required) \n CI/ CD: 10 years (Required) \n \n Work Location: Remote", "cleaned_desc": " Purpose : The project is to implement the specific business requirements on this new cloud no-code/low-code platform and requires particular expertise to support the Trails team in the development and implementation of the project as this is a new platform for the state of Colorado. \n Scope of Work \n  Build a proof of concept to replace the Colorado Child Care Licensing System (CCCLS) Legacy application using the Microsoft PowerApps Platform, Azure Dataverse, running on Azure infrastructure and achieve compliance in statutory and regulatory audit findings. \n Minimum Resource Requirements - Required \n \n Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n 3 years - hands on experience: \n Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations \n Common data services (Dataverse)   Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. \n Designing and developing elegant applications with Microsoft Power Platform (Apps, Portal, Automate, Dataverse, etc.) precisely supporting the architectural vision \n Developing and automating business process flows, approval flows, etc. with a focus on Automate \n Contributing to solution design activities supporting the architectural vision and an enterprise-wide approach \n Integration to enterprise components, such as: support system ticketing, CI/CD, Git commands, Branching, Azure Repos, Devops, Pipelines, Test, etc. \n Applying proper governance throughout the SDLC. \n \n Additional Important Requirements: \n \n Infrastructure as Code with tools, such as: Terraform (some experience required), Terragrunt, CloudFormation, Resource Manager, Octopus, Pulumi, Ansible, Chef, Puppet, Crossplane, Vagrant, Saltstack, etc.) \n Configuration of Power Platform environments (Dev, Test, Prod) ", "techs": ["microsoft powerapps", "azure dataverse", "azure infrastructure", "power platform", "azure devops", "pipelines", "powerapps portal", "power automate", "canvas", "integrations", "common data services", "security frameworks", "rbac", "login.gov", "adfs", "solution design", "enterprise components", "ci/cd", "git commands", "branching", "azure repos", "test", "sdcl", "terraform", "terragrunt", "cloudformation", "resource manager", "octopus", "pulumi", "ansible", "chef", "puppet", "crossplane", "vagrant", "saltstack"]}, "e32e02e3a17bb2ef": {"terms": ["mlops"], "salary_min": 100.0, "salary_max": 110.0, "title": "Azure DevOps Architect", "company": "Gsk solutions inc", "desc": "Job Title: Sr Azure DevOps Architect (Remote - Locals Only) \n Location: Remote (Denver, CO) \n Duration: 8 Months \n Pay Rate: $100/hr \n Job Description:  Purpose: The project is to implement the specific business requirements on this new cloud no-code/low-code platform and requires particular expertise to support the Trails team in the development and implementation of the project as this is a new platform for the state of Colorado. \n Scope of Work \n Build a proof of concept to replace the Colorado Child Care Licensing System (CCCLS) Legacy application using the Microsoft PowerApps Platform, Azure Dataverse, running on Azure infrastructure and achieve compliance in statutory and regulatory audit findings. \n Minimum Resource Requirements - Required \n \u00b7 Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n \u00b7 Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n \u00b7 3 years - hands on experience: \n \n Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations \n Common data services (Dataverse) \n Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. \n Designing and developing elegant applications with Microsoft Power Platform (Apps, Portal, Automate, Dataverse, etc.) precisely supporting the architectural vision \n Developing and automating business process flows, approval flows, etc. with a focus on Automate \n Contributing to solution design activities supporting the architectural vision and an enterprise-wide approach \n Integration to enterprise components, such as: support system ticketing, CI/CD, Git commands, Branching, Azure Repos, Devops, Pipelines, Test, etc. \n Applying proper governance throughout the SDLC. \n \n Additional Important Requirements: \n \u00b7 Infrastructure as Code with tools, such as: Terraform (some experience required), Terragrunt, CloudFormation, Resource Manager, Octopus, Pulumi, Ansible, Chef, Puppet, Crossplane, Vagrant, Saltstack, etc.) \n \u00b7 Configuration of Power Platform environments (Dev, Test, Prod) \n \u00b7 Technical documentation \n \u00b7 Strong teaching/mentoring/knowledge transfer skills/experience \n Job Type: Contract \n Salary: $100.00 - $110.00 per hour \n Benefits: \n \n Dental insurance \n Vision insurance \n \n Experience level: \n \n 10 years \n 11+ years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n \u00b7 Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n \u00b7 3 years - hands on experience: \n \n Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations \n Common data services (Dataverse) \n Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. ", "techs": ["power platform", "azure devops", "pipelines", "powerapps", "portal", "automate", "canvas", "common data services", "dataverse", "security frameworks", "rbac", "login.gov", "adfs"]}, "fba2c3e0c9fd6d24": {"terms": ["mlops"], "salary_min": 130906.04, "salary_max": 165756.22, "title": "Senior MLOps Consultant - Contract", "company": "Vouched", "desc": "We're looking for a skilled MLops Engineer consultant to help us build a model training pipeline. We have labeled image data and would like to design and build a pipeline to train classification models.   \n \n \n Responsibilities \n \n Design, implement, and build machine learning pipelines from data ingestion to model deployment, primarily using Vertex AI and Labelbox. \n Consult on the overall architecture and data strategy. \n Collaborate with Full Stack Engineers to integrate machine learning models into the application. \n Assist in identifying bottlenecks and optimize the performance of the machine learning pipeline. \n Develop monitoring tools to track the performance of models and the data pipeline. \n \n Requirements \n \n 5+ years of experience in machine learning and data pipeline architecture. \n Proven experience in building machine learning pipelines for classification models. \n Experience building and tuning machine learning models \n Must have experience with Google Cloud Platform (GCP). \n Proficient in Python and experience with machine learning libraries such as TensorFlow or PyTorch. \n Strong communication skills, with the ability to explain technical concepts to non-technical stakeholders. \n \n Benefits \n  Our commitment \n  At Vouched, we are committed to providing an environment where everyone receives equal consideration and treatment regardless of gender, gender identity, gender expression, sex, sexual orientation, race, color, religion, creed, national origin, ancestry, age, physical disability, mental disability, medical condition, HIV/AIDS/Hepatitis C status, genetic information, marital status, domestic partner status, military or veteran status, height, weight, and any other protected category under the law. \n \n Self-managed paid time off \n Medical/Vision \n Dental \n Flexible remote, work-from-home arrangements \n Salary: This is a contract position", "cleaned_desc": " Design, implement, and build machine learning pipelines from data ingestion to model deployment, primarily using Vertex AI and Labelbox. \n Consult on the overall architecture and data strategy. \n Collaborate with Full Stack Engineers to integrate machine learning models into the application. \n Assist in identifying bottlenecks and optimize the performance of the machine learning pipeline. \n Develop monitoring tools to track the performance of models and the data pipeline.   \n Requirements \n \n 5+ years of experience in machine learning and data pipeline architecture. \n Proven experience in building machine learning pipelines for classification models.   Experience building and tuning machine learning models \n Must have experience with Google Cloud Platform (GCP). \n Proficient in Python and experience with machine learning libraries such as TensorFlow or PyTorch. \n Strong communication skills, with the ability to explain technical concepts to non-technical stakeholders. \n ", "techs": ["vertex ai", "labelbox", "gcp", "python", "tensorflow", "pytorch"]}, "3ae39a795f0b4822": {"terms": ["mlops"], "salary_min": 49800.0, "salary_max": 102000.0, "title": "DevOps Engineer, Junior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182588\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Junior\n           The Opportunity:  \n Are you looking for an opportunity to make a difference in the DoD\u2019s pursuit of Offensive and Defensive Cyber Operations tools and capabilities? What if you could find a position that is tailor made for your mix of development, engineering, and communication skills? Everyone is trying to \u201charness the cloud,\u201d but not everyone knows how. That\u2019s why we need you, an experienced DevOps engineer, to help us shorten the time it takes to get critical tools developed. \n \n  As a DevOps engineer, you\u2019re eager to develop, manage, and secure a container platform that meets your client\u2019s needs and takes advantage of cloud capabilities. We need you to develop container management software to solve some of our client's toughest challenges. As a senior platform DevOps engineer at Booz Allen, you can use your technical skills to affect the development of Cyber Capabilities directly. On our team, you\u2019ll hone your skills using the latest cloud technologies as you look for ways to improve your client\u2019s environment with container software to ensure seamless orchestration. Using your DevOps platform experience, you\u2019ll support your team as you inform strategy and design while ensuring standards are met throughout the containerization process. You\u2019ll recommend and build out resources that will help your client manage and securely adopt container technology. Additionally, you\u2019ll continue to strengthen your DevOps skills while supporting the development of critical cloud platforms. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CICD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, and automation \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience with developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools such as AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public Cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Certified Kubernetes Administrator (CKA) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $49,800.00 to $102,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  Experience with Linux systems use, including patching, optimization, scripting, and automation \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience with developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools such as AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public Cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Certified Kubernetes Administrator (CKA) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: ", "techs": ["linux", "patching", "optimization", "scripting", "automation", "kubernetes", "docker", "aws", "jenkins", "azure", "atlassian suite", "cross domain solutions", "aws diode", "cka"]}, "d31d68c60d982a31": {"terms": ["mlops"], "salary_min": 140000.0, "salary_max": 160000.0, "title": "Sr. Azure DevOps Engineer", "company": "Prometheus, LLC", "desc": "Active Secret Clearance Required \n Remote Position \n Position Requirements: \n This position is for a Cloud Architect supporting a Microsoft Azure Government (MAG) environment. This position is for an architect to support application development, deployment, and sustainment activities. \n JOB DUTIES: \n \n Provide Technical Leadership and guidance to Developers building cloud applications using node.js, Angular and various other web-based frameworks in the Azure Platform utilizing Azure resources such as Azure Functions and Logic Apps. \n Develop, Maintain and Define continuous integration activities on the Jenkins platform to support the Development Activities across the Azure space \n Full stack developer with Understanding and experience with the following concepts/frameworks: \n REST \n SOAP \n HTTP \n API Management and Gateways \n ServiceNow \n Java - Spring Boot \n Jenkins \n node.js \n Angular \n Nrwl \n Monorepos \n Git \n Command Line Operations such as node, nvm, nrwl, npx, ng \n PKI \n Develop, Maintain, Define and Manage Database Structures in Microsoft SQL Server Database to support various applications \n Experience with planning, scheduling and executing production deployments for node applications including supporting artifacts such as Database Schema migrations as well as orchestration through CI/CD Pipelines \n Prepare and submit build and process documentation internally and with external providers to facilitate application deployment and upgrades. \n Troubleshooting and root cause analysis of customer application issues to include network, storage, operating system, and application-level analysis. \n Develop, deploy, and maintain infrastructure as code (IaC) for deployment and sustainment of customer enclaves. \n Make recommendations for improvements to security, scalability, manageability, and performance across a wide variety of network, storage, and compute services and technologies. \n Design, develop and maintain automation framework for iterative software development and testing. Provide operational support, and develop solutions that provide monitoring, logging and alerting capabilities. \n Manage CI/CD infrastructure using Jenkins, SonarQube, Fortify, and UFT, including patching and security updates on the infrastructure. \n Develop and maintain build scripts to automate deployments for multiple environments including dev/test, QA, and production. \n Work with QA team to integrate automated testing into CI/CD pipeline. \n Manage promoting Logic Apps and APIM between environments using ARM templates. \n Participate in architecture review, reviewing technology designs and best practices \n Coordinate bi-weekly software releases of frontend and backend services hosted on Azure \n \n REQUIRED SKILLS: \n \n Knowledge of Microsoft Azure cloud resources \n Understanding of network, storage, server, and application technologies \n Strong troubleshooting skills across the entire technology stack \u2013 network, storage, server, and applications \n Working knowledge of DoD STIGs, and IA Vulnerability Management (IAVM) \n Strong communication and presentation skills. \n Hands-on experience with MS Azure technologies, specifically ARM templates and deployment scripting. \n Hands-on CI/CD engineering experience working with scripting and build management tools for a variety of frameworks and technologies, including Angular, Java, C#/.NET, Bash, Groovy, Gradle, and Maven. \n Hands-on experience working on Windows, and Linux distributions (CentOS and Ubuntu) \n Hands-on experience working in Agile and DevOps cultures and teams with a keen focus on process improvement and automation through internal and external collaboration. \n Experience with Azure GovCloud a plus \n Strong verbal and written communication skills \n Experience effectively managing multiple large-scale projects \n Experience with Atlassian product suite (JIRA and Confluence) \n \n Preferred Background- full stack developer \n Job Type: Full-time \n Pay: $140,000.00 - $160,000.00 per year \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Microsoft Azure: 5 years (Preferred) \n Agile SW Development: 5 years (Preferred) \n Software Development: 10 years (Required) \n \n License/Certification: \n \n Microsoft Azure Administration Certification (Required) \n \n Security clearance: \n \n Secret (Required) \n \n Work Location: Remote", "cleaned_desc": " Java - Spring Boot \n Jenkins \n node.js \n Angular \n Nrwl \n Monorepos \n Git \n Command Line Operations such as node, nvm, nrwl, npx, ng \n PKI \n Develop, Maintain, Define and Manage Database Structures in Microsoft SQL Server Database to support various applications \n Experience with planning, scheduling and executing production deployments for node applications including supporting artifacts such as Database Schema migrations as well as orchestration through CI/CD Pipelines \n Prepare and submit build and process documentation internally and with external providers to facilitate application deployment and upgrades. \n Troubleshooting and root cause analysis of customer application issues to include network, storage, operating system, and application-level analysis. \n Develop, deploy, and maintain infrastructure as code (IaC) for deployment and sustainment of customer enclaves.   Make recommendations for improvements to security, scalability, manageability, and performance across a wide variety of network, storage, and compute services and technologies. \n Design, develop and maintain automation framework for iterative software development and testing. Provide operational support, and develop solutions that provide monitoring, logging and alerting capabilities. \n Manage CI/CD infrastructure using Jenkins, SonarQube, Fortify, and UFT, including patching and security updates on the infrastructure. \n Develop and maintain build scripts to automate deployments for multiple environments including dev/test, QA, and production. \n Work with QA team to integrate automated testing into CI/CD pipeline. \n Manage promoting Logic Apps and APIM between environments using ARM templates. \n Participate in architecture review, reviewing technology designs and best practices \n Coordinate bi-weekly software releases of frontend and backend services hosted on Azure \n \n REQUIRED SKILLS: \n \n Knowledge of Microsoft Azure cloud resources \n Understanding of network, storage, server, and application technologies \n Strong troubleshooting skills across the entire technology stack \u2013 network, storage, server, and applications   Working knowledge of DoD STIGs, and IA Vulnerability Management (IAVM) \n Strong communication and presentation skills. \n Hands-on experience with MS Azure technologies, specifically ARM templates and deployment scripting. \n Hands-on CI/CD engineering experience working with scripting and build management tools for a variety of frameworks and technologies, including Angular, Java, C#/.NET, Bash, Groovy, Gradle, and Maven. \n Hands-on experience working on Windows, and Linux distributions (CentOS and Ubuntu) \n Hands-on experience working in Agile and DevOps cultures and teams with a keen focus on process improvement and automation through internal and external collaboration. \n Experience with Azure GovCloud a plus \n Strong verbal and written communication skills \n Experience effectively managing multiple large-scale projects \n Experience with Atlassian product suite (JIRA and Confluence) \n \n Preferred Background- full stack developer \n Job Type: Full-time \n Pay: $140,000.00 - $160,000.00 per year ", "techs": ["java", "spring boot", "jenkins", "node.js", "angular", "nrwl", "monorepos", "git", "microsoft sql server database", "pki", "ci/cd pipelines", "infrastructure as code (iac)", "jenkins", "sonarqube", "fortify", "uft", "logic apps", "apim", "azure", "arm templates", "network", "storage", "server", "application technologies", "dod stigs", "ia vulnerability management (iavm)", "ms azure technologies", "angular", "java", "c#/.net", "bash", "groovy", "gradle", "maven", "windows", "linux", "agile", "devops", "azure govcloud", "atlassian product suite (jira and confluence)"]}, "cde9f77b4d87a183": {"terms": ["mlops"], "salary_min": 58300.0, "salary_max": 133000.0, "title": "DevOps Engineer", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182585\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer\n           The Opportunity:  \n Are you looking for an opportunity to make a difference in the DoD\u2019s pursuit of Offensive and Defensive Cyber Operations tools and capabilities? What if you could find a position that is tailor made for your mix of development, engineering, and communication skills? Everyone is trying to \u201charness the cloud,\u201d but not everyone knows how. That\u2019s why we need you, an experienced DevOps engineer, to help us shorten the time it takes to get critical tools developed. \n \n  As a DevOps engineer, you\u2019re eager to develop, manage, and secure a container platform that meets your client\u2019s needs and takes advantage of cloud capabilities. We need you to develop container management software to solve some of our client's toughest challenges. As a senior platform DevOps engineer at Booz Allen, you can use your technical skills to affect the development of Cyber Capabilities directly. On our team, you\u2019ll hone your skills using the latest cloud technologies as you look for ways to improve your client\u2019s environment with container software to ensure seamless orchestration. Using your DevOps platform experience, you\u2019ll support your team as you inform strategy and design while ensuring standards are met throughout the containerization process. You\u2019ll recommend and build out resources that will help your client manage and securely adopt container technology. Additionally, you\u2019ll continue to strengthen your DevOps skills while supporting the development of critical cloud platforms. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CICD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, and automation \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience with developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools such as AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public Cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Certified Kubernetes Administrator (CKA) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  Experience with Linux systems use, including patching, optimization, scripting, and automation \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience with developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools such as AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public Cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Certified Kubernetes Administrator (CKA) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: ", "techs": ["linux", "scripting", "automation", "kubernetes", "docker", "aws", "jenkins", "azure", "atlassian", "aws diode", "dod approved cds", "python", "shell script", "secret clearance", "certified kubernetes administrator (cka)"]}, "09800d52cb9979af": {"terms": ["mlops"], "salary_min": 70.0, "salary_max": 100.0, "title": "DevOps and Containers Consultant", "company": "Synovize", "desc": "DevOps and Containers Consultant \n Introduction to Synovize: \n Synovize is an innovator in the tech industry, and we're currently seeking a DevOps and Containers Consultant to offer expert advice on our DevOps strategies and containerization practices. \n Job Overview: \n We're looking for a DevOps and Containers Consultant. This role involves advising our team on best practices for DevOps and containerization using tools like Docker and Kubernetes. \n Responsibilities: \n \n Provide expert advice on DevOps and containerization practices. \n Leverage Docker and Kubernetes for containerization and orchestration. \n Use Terraform for infrastructure management and Ansible for process automation. \n Develop Python scripts as necessary. \n \n Requirements: \n \n US Citizen. \n Proven experience as a DevOps and Containers Consultant or similar role. \n Proficiency in Docker, Kubernetes, Terraform, Ansible, and Python. \n Bachelor\u2019s degree in Computer Science, Engineering, or a related field. \n \n Preferred: \n \n Familiarity with AWS. \n Docker and Kubernetes certifications. \n \n Outro: \n Synovize is a dynamic work environment that promotes innovation and professional growth. If you're a DevOps consultant eager to make an impact, we invite you to apply. \n Job Types: Contract, Full-time \n Pay: $70.00 - $100.00 per hour \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Life insurance \n Paid time off \n Referral program \n Vision insurance \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n Overtime \n Weekends as needed \n \n Application Question(s): \n \n Are you a US Citizen? If not, what is your current citizenship status? \n \n Experience: \n \n DevOps Engineering: 1 year (Preferred) \n \n Security clearance: \n \n Top Secret (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "4d4418f9aa2ad5f8": {"terms": ["mlops"], "salary_min": 140.0, "salary_max": 145.0, "title": "Sr. Azure DevOps Architect", "company": "Skywalk Global", "desc": "Hi, \n We are currently hiring for  Sr. Azure DevOps Architect . This is a remote and contract position. Please find the JD below and apply. \n Primary Skills \n Azure \n Description \n Candidate Must Be Local \n Period of Performance \n The Trails Developer shall commence on or before  November 6, 2023  and continue through  June 30, 2024  or  earlier  depending on the  maximum of 800 hours  being exhausted. \n Purpose: The project is to implement the specific business requirements on this new cloud no-code/low-code platform and requires particular expertise to support the Trails team in the development and implementation of the project as this is a new platform for the state of Colorado. \n Scope of Work \n Build a proof of concept to replace the Colorado Child Care Licensing System (CCCLS) Legacy application using the Microsoft PowerApps Platform, Azure Dataverse, running on Azure infrastructure and achieve compliance in statutory and regulatory audit findings. \n Minimum Resource Requirements - Required \n \n Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n 3 years - hands on experience:Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n \n Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations Common data services (Dataverse) Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. Designing and developing elegant applications with Microsoft Power Platform (Apps, Portal, Automate, Dataverse, etc.) precisely supporting the architectural vision Developing and automating business process flows, approval flows, etc. with a focus on Automate Contributing to solution design activities supporting the architectural vision and an enterprise-wide approach Integration to enterprise components, such as: support system ticketing, CI/CD, Git commands, Branching, Azure Repos, Devops, Pipelines, Test, etc. Applying proper governance throughout the SDLC. \n Additional Important Requirements: \n \n Infrastructure as Code with tools, such as: Terraform (some experience required), Terragrunt, CloudFormation, Resource Manager, Octopus, Pulumi, Ansible, Chef, Puppet, Crossplane, Vagrant, Saltstack, etc.) \n Configuration of Power Platform environments (Dev, Test, Prod) \n Technical documentation \n Strong teaching/mentoring/knowledge transfer skills/experience \n \n Job Type: Contract \n Pay: $140.00 - $145.00 per hour \n Experience level: \n \n 4 years \n 5 years \n 6 years \n 7 years \n \n Schedule: \n \n 10 hour shift \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n Azure: 1 year (Preferred) \n AWS: 1 year (Preferred) \n Kubernetes: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Scope of Work \n Build a proof of concept to replace the Colorado Child Care Licensing System (CCCLS) Legacy application using the Microsoft PowerApps Platform, Azure Dataverse, running on Azure infrastructure and achieve compliance in statutory and regulatory audit findings. \n Minimum Resource Requirements - Required \n \n Ability to work in a matrix environment as the Technical Owner or reporting to the Technical Owner, but working across business and technical teams teams through an Agile (SAFe) process \n Required Education Level: Associate\u2019s degree or higher required in Computer Science, Information Technology, Management Information Systems, or equivalent experience \n 3 years - hands on experience:Integrating Power Platform to Azure Devops, Pipelines, 3rd systems, etc. \n \n Advanced PowerApps work specifically including: Portal, Automate, Canvas, Integrations Common data services (Dataverse) Security including, for example: various security frameworks, RBAC, Login.Gov, ADFS, etc. Designing and developing elegant applications with Microsoft Power Platform (Apps, Portal, Automate, Dataverse, etc.) precisely supporting the architectural vision Developing and automating business process flows, approval flows, etc. with a focus on Automate Contributing to solution design activities supporting the architectural vision and an enterprise-wide approach Integration to enterprise components, such as: support system ticketing, CI/CD, Git commands, Branching, Azure Repos, Devops, Pipelines, Test, etc. Applying proper governance throughout the SDLC. ", "techs": ["microsoft powerapps", "azure dataverse", "azure infrastructure", "power platform", "azure devops", "pipelines", "powerapps portal", "power automate", "canvas", "common data services (dataverse)", "rbac", "login.gov", "adfs", "microsoft power platform (apps", "portal", "automate", "dataverse)", "ci/cd", "git commands", "branching", "azure repos", "sdic"]}, "9520125d6d20f1e1": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "DevOps Engineer", "company": "Vass", "desc": "Description \n \n \n \u00bfEres un/a Ingeniero/a DevOps? Si buscas un gran equipo con un alto nivel t\u00e9cnico, donde se valore la proactividad y las ganas de hacer cosas diferentes,  \u00a1VASS ES TU LUGAR! \n \n  Somos l\u00edderes en soluciones digitales con 26 sedes en los 5 continentes y un equipo de m\u00e1s de 4.500 personas, apoyamos a grandes empresas y administraciones p\u00fablicas en su proceso de transformaci\u00f3n digital end2end, desarrollando y ejecutando los proyectos m\u00e1s innovadores y escalables desde la estrategia hasta la operaci\u00f3n.   \n \n \n Todo este crecimiento se basa en el talento y la pasi\u00f3n por la innovaci\u00f3n y la mejora continua, siempre a nuestra manera: simplificando lo complejo \n \n  Dentro del Grupo VASS, en el \u00c1rea Investment Industry Comunytek estamos especializados en Capital Markets y Tecnolog\u00eda, desarrollando soluciones tecnol\u00f3gicas ante problemas de negocio utilizando la \u00faltima tecnolog\u00eda. \n \n  \u00bfQu\u00e9 buscamos? \n \n  Buscamos personas que tengan experiencia en la integraci\u00f3n de servicios en Cloud. Las principales tareas ser\u00e1n:   \n \n \n \n Automatizaci\u00f3n, con Pipelines por tecnolog\u00edas, los procesos de subida a entornos, cambios y mejoras en las apps, microservicios etc.   \n \n \n \n \u00bfQu\u00e9 requisitos debes cumplir? \n   \n \n Perfil DevOps. \n Lenguajes de programaci\u00f3n: Java bajo arquitectura de microservicios.  \n Experiencia y/o conocimientos en Python, Ansible, Terraform y Scripting (JavaScript, Ruby, Groovy). \n Tecnolog\u00eda Cloud (Azure). \n Metodolog\u00edas agile. \n Nivel alto de ingl\u00e9s.  \n Experiencia de al menos 3 a\u00f1os trabajando con las tecnolog\u00edas mencionadas. \n \n \n  \u00bfCompartimos el mismo ADN?   \n \n \n \n Eres flexible y orientado/a a un prop\u00f3sito.  \n Tienes una mente creativa e innovadora.  \n Te sientes seguro/a y disfrutas de lo que haces.  \n Eres aut\u00f3nomo/a y con iniciativa.   \n \n \n \n Beneficios de trabajar juntos: \n \n  \ufe0f 23+2 d\u00edas de vacaciones \n  Contrato indefinido. \n  Longweekend \n  Concilia Days \n  Movilidad Internacional \n  Jornada intensiva los viernes y todos los d\u00edas durante los meses de julio y agosto. \n  \u200d Acceso a webinars abiertos y Udemy. \n  Clases de idiomas y certificaciones t\u00e9cnicas \n  Gran ambiente de trabajo, \u00a1nuestros equipos lo hacen posible! \n  Metodologia SmartWorking \n  Beneficios sociales con nuestra plataforma de Retribuci\u00f3n Flexible. \n  Estabilidad y proyecci\u00f3n de futuro a trav\u00e9s del plan de desarrollo profesional. \n  Ser\u00e1s parte de una empresa din\u00e1mica en constante crecimiento. \n  \u200d Participar\u00e1s en proyectos con tecnolog\u00edas de vanguardia. \n  Formar\u00e1s parte de un equipo diverso, multifuncional y aut\u00f3nomo. \n  Formar\u00e1s parte de un amplio equipo de profesionales de alto nivel, cuya motivaci\u00f3n es la aportaci\u00f3n de valor al trabajo diario y a la excelencia profesional. \n \n  Si quieres unirte a una empresa din\u00e1mica donde los retos tecnol\u00f3gicos se encontrar\u00e1n en tu d\u00eda a d\u00eda, te esperamos en el gran equipo VASS. \n \n  Queremos que seas la mejor versi\u00f3n de ti mismo. TU TALENTO, NUESTRO ADN \n \n  \u00a1Bienvenido a tu futuro! \n \n  VASS se enorgullece de ser un empleador que ofrece igualdad de oportunidades. No discriminamos por motivos de raza, religi\u00f3n, color, sexo, identidad de g\u00e9nero, orientaci\u00f3n sexual, edad, origen nacional, estado civil o discapacidad. Nuestro reclutamiento se decide sobre la base de las calificaciones, el m\u00e9rito y la necesidad comercial. \n \n \n \n \n \n \n \n \n \n \n \n    Location Remote", "cleaned_desc": "", "techs": ""}, "2d79316b92a742f4": {"terms": ["mlops"], "salary_min": 49800.0, "salary_max": 102000.0, "title": "DevOps Engineer, Junior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Annapolis Junction,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0182589\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Junior\n           The Opportunity:  \n Are you looking for an opportunity to make a difference in the DoD\u2019s pursuit of Offensive and Defensive Cyber Operations tools and capabilities? What if you could find a position that is tailor made for your mix of development, engineering, and communication skills? Everyone is trying to \u201charness the cloud,\u201d but not everyone knows how. That\u2019s why we need you, an experienced DevOps engineer, to help us shorten the time it takes to get critical tools developed. \n \n  As a DevOps engineer, you\u2019re eager to develop, manage, and secure a container platform that meets your client\u2019s needs and takes advantage of cloud capabilities. We need you to develop container management software to solve some of our client's toughest challenges. As a senior platform DevOps engineer at Booz Allen, you can use your technical skills to affect the development of Cyber Capabilities directly. On our team, you\u2019ll hone your skills using the latest cloud technologies as you look for ways to improve your client\u2019s environment with container software to ensure seamless orchestration. Using your DevOps platform experience, you\u2019ll support your team as you inform strategy and design while ensuring standards are met throughout the containerization process. You\u2019ll recommend and build out resources that will help your client manage and securely adopt container technology. Additionally, you\u2019ll continue to strengthen your DevOps skills while supporting the development of critical cloud platforms. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience in the development of tools and processes to drive DevOps or DevSecOps maturity by automating builds, regression testing, monitoring, and pushing releases across environments \n  Experience working with, building, and maintaining DevSecOps services with infrastructure as code (IaC) platforms and configuration management tools \n  Experience with containerization tools, including Docker and Kubernetes \n  Experience with automation tools, including SaltStack, Ansible, or Puppet \n  Experience with DevOps and CICD tools and automation, including Jenkins and GitHub Actions \n  Experience with network and server infrastructure monitoring and management \n  Experience with Linux systems use, including patching, optimization, scripting, and automation \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience with developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools such as AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public Cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Certified Kubernetes Administrator (CKA) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $49,800.00 to $102,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "  Experience with Linux systems use, including patching, optimization, scripting, and automation \n  Experience working with application development teams across the software development lifecycle \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  5+ years of experience in an infrastructure, DevSecOps, or application development role \n  Experience with developing enterprise cloud-native solutions, including Kubernetes, Docker, AWS, Jenkins, or Azure \n  Experience with installing, configuring, and managing Atlassian suite of development tools \n  Experience with Cross Domain Solutions, including tools such as AWS Diode and DoD approved CDS technologies \n  Experience triaging and resolving issues related to both open-source and commercial tools in public Cloud environments \n  Knowledge of scripting languages, including Python, Linux, or Shell Script \n  Master\u2019s degree \n  Certified Kubernetes Administrator (CKA) \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: ", "techs": ["linux", "patching", "optimization", "scripting", "automation", "application development", "devsecops", "kubernetes", "docker", "aws", "jenkins", "azure", "atlassian suite", "cross domain solutions", "aws diode", "dod approved cds technologies", "triaging", "open-source", "commercial tools", "public cloud environments", "python", "shell script", "secret clearance", "certified kubernetes administrator (cka)"]}, "030cfc3cccb7b5b9": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Senior Consultant, Product Management", "company": "Dell", "desc": "GenAI Solutions Senior Product Manager  \n \n Do you have a passion for digital transformation, and more importantly the role consulting and professional services play in driving customer outcomes? Are you seen as a thought leader and visionary about the future of GenAI, AI and Machine Learning? Do you have ideas about how to actualize that vision within Global Enterprises? If so, Dell Technologies Services (DTS) is looking for you. \n \n  The DTS Consulting Services team is a key growth area within Dell Technologies. Essential to this growth is building and expanding our GenAI Consulting Services portfolio. DTS is looking for a Senior Product Manager who can translate customer and market insights into outcome-based, end-to-end services that support our customers\u2019 GenAI transformation journey. \n \n  In this role you will help drive the vision, strategy, leadership, and overall success for the next generation of Dell Technologies GenAI professional services portfolio. You will be in a dynamic environment with other motivated, talented individuals who inspire greatness in their teammates. Our unique position as a technology leader ensures that you\u2019ll always be challenged in your work and supported in reaching your most ambitious goals. \n \n  Join us to do the best work of your career and make a profound social impact as the  Gen AI Solutions Sr Product Manager  on our Professional Services  Product Management  Team  in Remote - United States \n  What you\u2019ll achieve \n  As a  Senior Product Manager , you will be responsible for working with us on key strategic initiatives in the area of Generative AI Consulting Services. \n \n  You Will \n \n  Identify new growth areas and emerging service / solution opportunities for DTS Consulting and Professional Services in GenAI and artificial intelligence \n  Provide technical leadership around Gen AI and AI topics to other members of the Dell Professional Services portfolio team and collaborate with Product Management stakeholders across the DT Services portfolio, including Deploy, Support, Consult, Managed Services and Education Services \n  Drive thought leadership and IP development and ensure IP is leveraged across the DTS Services portfolio \n  Author strategy docs, white papers, market research and vision documents along with user stories for current and future products \n  Work across all functional areas, gathering inputs, updating plans and roadmaps, and communicating the impact of portfolio outcome to all stakeholders. \n \n  Take the first step towards your dream career  Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role: \n \n  Essential Requirements \n \n  12+ years of related experience, in a professional role with a Bachelor's degree, or 6+ years with a Master's degree with at least, 5+ years of experience working in the fields of Artificial Intelligence and Big Data in a customer-facing services delivery role \n  Deep knowledge of Generative AI, specifically model selection, data preparation for GenAI training, model finetuning and customization and guardrail implementation \n  Deep understanding of the GenAI tooling ecosystem including knowledge and experience of Kubernetes, MLOps and AIOps tools \n  Experience and deep knowledge of Large Language Models (LLM), hands on experience with MLOps and AIOps tools such as cnvrg.io, MLFlow and Domino. Business and entrepreneurial acumen with strategic and critical thinking \n  Strong technical acumen with a history of building/delivering enterprise solutions. Experience in writing product and customer requirements and using qualitative and quantitative data to prioritize decision-making \n \n \n  Desirable Requirements \n \n  Strong understanding of data models, metadata, data dictionaries, sequences, warehousing concepts, and technologies \n  Experience with data management, including data profiling, sourcing, quality, and transformation. Experience with Python, R, Spark, SQL programing experience and experimental design \n \n  Who we are \n \n  We believe that each of us has the power to make an impact. That\u2019s why we put our team members at the center of everything we do. If you\u2019re looking for an opportunity to grow your career with some of the best minds and most advanced tech in the industry, we\u2019re looking for you.    Dell Technologies is a unique family of businesses that helps individuals and organizations transform how they work, live and play. Join us to build a future that works for everyone because Progress Takes All of Us.     Application closing date: 11/01/2023    Dell Technologies is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. Read the full Equal Employment Opportunity Policy here. \n \n  Job ID: R234708\n   Dell\u2019s Flexible & Hybrid Work Culture    At Dell Technologies, we believe our best work is done when flexibility is offered.    We know that freedom and flexibility are crucial to all our employees no matter where you are located and our flexible and hybrid work style allows team members to have the freedom to ideate, be innovative, and drive results their way. To learn more about our work culture, please visit our locations page.", "cleaned_desc": "  12+ years of related experience, in a professional role with a Bachelor's degree, or 6+ years with a Master's degree with at least, 5+ years of experience working in the fields of Artificial Intelligence and Big Data in a customer-facing services delivery role \n  Deep knowledge of Generative AI, specifically model selection, data preparation for GenAI training, model finetuning and customization and guardrail implementation \n  Deep understanding of the GenAI tooling ecosystem including knowledge and experience of Kubernetes, MLOps and AIOps tools \n  Experience and deep knowledge of Large Language Models (LLM), hands on experience with MLOps and AIOps tools such as cnvrg.io, MLFlow and Domino. Business and entrepreneurial acumen with strategic and critical thinking \n  Strong technical acumen with a history of building/delivering enterprise solutions. Experience in writing product and customer requirements and using qualitative and quantitative data to prioritize decision-making \n \n \n  Desirable Requirements ", "techs": ["generative ai", "kubernetes", "mlops", "aiops", "large language models", "cnvrg.io", "mlflow", "domino"]}, "metadata": {"keywords": ["data science", "data analyst", "data engineer", "machine learning engineer", "mlops"], "locations": ["remote"], "time_ran": "19:18:11-30-10-23", "num_jobs": 120, "timings": {"start_drivers": 53.34000039100647, "find_job_ids": 149.60300207138062, "get_job_descs": 63.488999128341675}, "models": {"classifier": {"clf": "data/classifier_models/job_desc_classifier_v1.0.pkl", "tfidf": "data/classifier_models/job_desc_tfidf_vectorizer_v1.0.pkl"}, "NER": {"model": "gpt-3.5-turbo", "prompt": "You identify specific technologies from a paragraph and return them in lowercase.", "examples": {"example_1": "Return specific tools and technologies from the following text: Meta is seeking a Research Engineer to join our Large Language Model (LLM) Research team. We conduct focused research and engineering to build state-of-the-art LLMs, which we often open-source, like our team\u2019s recent Llama 2.  Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU). Programming experience in Python and hands-on experience with frameworks such as PyTorch. \n  Exposure to architectural patterns of large scale software applications. Direct experience in generative AI and LLM research.", "example_response_1": "llama 2, python, pytorch", "example_2": "Return specific tools and technologies from the following text: Proficiency in Python for data manipulation and analysis \n Prior experience in working with Spark SQL for data processing and querying \n Hands-on experience with Snowflake ETL processes and data integration \n Superior expertise in creating interactive dashboards and reports to present findings and key performance indicators (KPIs) using Tableau    \n Basic understanding of Airflow for simple job orchestration. Preferred Qualifications: \n \n Experience with cloud platforms like AWS, Azure \n Knowledge of statistical analysis and machine learning concepts \n Familiarity with data modeling and database design \n Familiarity with data visualization tools other than Tableau (e.g., Power BI) \n \n", "example_response_2": "python, spark, sql, snowflake, tableau, airflow, aws, azure, power bi"}}}}}