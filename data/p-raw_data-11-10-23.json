{"33cb550174b4672d": {"terms": ["data science"], "salary_min": 82800.0, "salary_max": 106425.0, "title": "Data Scientist (Remote)", "company": "Vail Resorts", "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary: \n  The Data Science & Data Engineering team is responsible for using our internal data assets to deliver performant, scalable, and impactful data-focused solutions across the business! The team supports modeling initiatives in collaboration with our technology and business partners to enable strategic opportunities and guest facing initiatives.  \n As a Data Scientist on the team, your goals will be to help maintain our existing portfolio of in-market models and partner in the development of new solutions that support strategic initiatives across the business. To reach these goals, you will utilize our proprietary first party guest database that is unmatched by any other company in the industry and collaborate closely with your teammates and our business partners. \n   \n Job Specifications: \n \n  Outlet: Corporate \n  Expected Pay Range: $82,800 - $106,425 \n  Shift Availability: Full Time, Year Round \n \n \n  Job Responsibilities \n \n  Support scalable machine learning solutions that positively impact marketing campaigns, operational excellence, and the guest experience \n  Partner with senior teammates in the model development life cycle \n  Build and maintain dashboards and documentation communicating model results \n  Develop deep understanding of the business and the stakeholders we support \n \n \n  Job Requirements \n \n  At least 1-2 years of hands-on data science experience \n  Advanced degree in a quantitative field (Computer Science, Statistics / Math, Engineering, etc.) \n  Demonstrated ability to design data-focused solutions that support business requirements while accounting for data availability and technical implementation considerations \n  Knowledge of the strengths and weaknesses of various machine learning algorithms and ability to evaluate model performance using appropriate metrics \n  Exposure to productionizing machine learning models, model monitoring, and CI/CD \n  Strong communication skills including the ability to solicit requirements from and explain technical solutions to non-technical stakeholders \n  Eagerness to learn new skills  \n Intermediate Python and SQL skills \n \n \n  The expected Total Compensation for this role is $82,800 - $106,425. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 497116   Reference Date: 08/04/2023   Job Code Function: Marketing", "cleaned_desc": "  Develop deep understanding of the business and the stakeholders we support \n \n \n  Job Requirements \n \n  At least 1-2 years of hands-on data science experience \n  Advanced degree in a quantitative field (Computer Science, Statistics / Math, Engineering, etc.) \n  Demonstrated ability to design data-focused solutions that support business requirements while accounting for data availability and technical implementation considerations \n  Knowledge of the strengths and weaknesses of various machine learning algorithms and ability to evaluate model performance using appropriate metrics \n  Exposure to productionizing machine learning models, model monitoring, and CI/CD ", "techs": ["none"]}, "66d0204de75533bf": {"terms": ["data science"], "salary_min": 90712.18, "salary_max": 114861.836, "title": "Data Scientist", "company": "Catholic Relief Services", "desc": "***NOTE: This is a global telecommuter position; CRS will give preference to candidates who are based in countries where we have existing offices. CRS does not sponsor visas for telecommuting employees.***  \n About CRS  \n Catholic Relief Services is the official international humanitarian agency of the Catholic community in the United States. CRS works to  save, protect, and transform  lives in need in more than 100 countries, without regard to race, religion or nationality. CRS\u2019 relief and development work is accomplished through programs of emergency response, HIV, health, agriculture, education, microfinance and peacebuilding.  \n Job Summary  \n The Data Scientist will lead the development of appropriate data products for CRS\u2019s program and sector teams, in line with industry best practices. They will work as part of a cross-functional team, identifying opportunities to leverage data science within specific programmatic sectors, leading the search and identification of data sources, supporting the preparation of data, and developing and maintaining relevant data products. They also provide technical assistance to project and sector teams in interpreting and using the results of the analyses. The Data Scientist\u2019s expertise, leadership, and influence will be key in determining how effective, adaptive and innovative CRS\u2019 data science practices are across the globe.  \n Roles and Key Responsibilities  \n \n Contribute to the identification of opportunities to apply data science to specific projects and sectors  \n Lead the search and identification of new data sources, the ingestion, preparation, and onboarding of data for operational and programmatic Use Cases  \n Engaging with sector teams, review data collected and make decisions on how to transform data, what approaches to apply when analyzing data, and recommendations for data cleansing  \n Lead the development of appropriate data products for CRS\u2019s program and sector teams, following industry best practices and through engagement with sector teams  \n Lead the maintenance and development of data products for operational and programmatic Use Cases, ensuring both data and models are functioning properly, and cataloged, accessible, and used appropriately  \n Share data insights with to sector and project teams and provide technical assistance in interpreting and using results from data analyses.  \n Contribute to the knowledge management and learning agenda in data science through helping implement conditions for collective learning that ensure the capturing, documenting, and sharing of key successes, promising practices, and lessons learned.  \n \n Key Working Relationships:  \n \n Internal  \u2013 Colleagues within the Data Science Centre of Practice; Members of the ICT4D team; Regional, country, and project staff; data science colleagues; Senior Advisor for data science; Director and Deputy Director for MEAL; Global and Regional MEAL Technical Advisors  \n External  - peers in other NGOs, data science consultants", "cleaned_desc": " Job Summary  \n The Data Scientist will lead the development of appropriate data products for CRS\u2019s program and sector teams, in line with industry best practices. They will work as part of a cross-functional team, identifying opportunities to leverage data science within specific programmatic sectors, leading the search and identification of data sources, supporting the preparation of data, and developing and maintaining relevant data products. They also provide technical assistance to project and sector teams in interpreting and using the results of the analyses. The Data Scientist\u2019s expertise, leadership, and influence will be key in determining how effective, adaptive and innovative CRS\u2019 data science practices are across the globe.  \n Roles and Key Responsibilities    \n Contribute to the identification of opportunities to apply data science to specific projects and sectors  \n Lead the search and identification of new data sources, the ingestion, preparation, and onboarding of data for operational and programmatic Use Cases    Engaging with sector teams, review data collected and make decisions on how to transform data, what approaches to apply when analyzing data, and recommendations for data cleansing  \n Lead the development of appropriate data products for CRS\u2019s program and sector teams, following industry best practices and through engagement with sector teams  \n Lead the maintenance and development of data products for operational and programmatic Use Cases, ensuring both data and models are functioning properly, and cataloged, accessible, and used appropriately    Share data insights with to sector and project teams and provide technical assistance in interpreting and using results from data analyses.  \n Contribute to the knowledge management and learning agenda in data science through helping implement conditions for collective learning that ensure the capturing, documenting, and sharing of key successes, promising practices, and lessons learned.  \n ", "techs": ["data products", "data sources", "data preparation", "data cleansing", "data insights", "data analyses", "data models", "knowledge management", "learning agenda", "collective learning"]}, "87ad9542aa5a710c": {"terms": ["data science", "mlops"], "salary_min": 130000.0, "salary_max": 150000.0, "title": "Senior Data Scientist", "company": "Transcarent", "desc": "Who we are \n  Transcarent is the One Place for health and care. We cut through the complexity, making it easy for people to access high-quality, affordable care. With a personalized app tailored for each Member, an on-demand care team, and a connected ecosystem of high-quality, in-person care and virtual point solutions, Transcarent eliminates the guesswork to confidently guide Members to the right level of care. We take accountability for results \u2013 offering at-risk pricing models and transparent impact reporting to align incentives towards measurably better experience, better health, and lower costs. At Transcarent, you will be part of a world-class team, supported by top tier investors like 7wireVentures and General Catalyst, and founded by a mission-driven team committed to transforming the health and care experience for all. We closed on our Series C funding in January 2022, raising our total funding to $298 million and enabling us to respond to the demand for our offering. \n  Transcarent is committed to growing and empowering a diverse and inclusive community within our company. We believe that a team with diverse lived experiences, working together will strengthen our organization, and our ability to deliver \"not just better but different\" experiences for our members. \n  We are looking for teammates to join us in building our company, culture, and Member experience who: \n \n Put people first, and make decisions with the Member\u2019s best interests in mind \n Are active learners, constantly looking to improve and grow \n Are driven by our mission to measurably improve health and care each day \n Bring the energy needed to transform health and care, and move and adapt rapidly \n Are laser focused on delivering results for Members, and proactively problem solving to get there \n \n \n What you'll do \n  The Senior Data Scientist will report to the Head of Data Science and work with other data scientist, medical coding specialists, solutions managers and digital marketing specialists. The Senior Data Scientist will be responsible for researching, creating and deploying machine learning algorithms used to identify and prioritize needs for various medical services and optimize outreach efforts to increase member engagement and utilization of medically appropriate services while decreasing churn and costs of acquisition. \n  The Senior Data Scientist should have familiarity and experience with medical codes including ICD-10, CPT, PCS, PII and PHI, in addition to non-medical data including SDoH, and digital marketing data. The Senior Data Scientist will also work with the Data Engineering and Product teams to develop robust pipelines for data acquisition and model deployment. \n  A successful candidate in this role will serve as an advocate for data science across the organization, helping business leaders understand data science capabilities, identify new use cases and promote a data-centric, evidence-based culture across the entire company. They will serve a key role within the Data Science organization, modeling best practices in agile project management, code development, review, testing, deployment and monitoring. \n  What we're looking for \n \n Strong focus on data-driven decision-making \n Ability to work with stakeholders to translate business needs into data science questions \n Strong problem solving skills and ability to identify new opportunities and methods \n Expert in Python and machine learning libraries including sklearn and tensorflow \n Strong experience in successfully deploying supervised, unsupervised and reinforcement learning models to production  \n Expert in SQL and RDBMS best practices such as normalization  \n Experience with no-SQL and semi-structured data  \n Familiarity with MLOps frameworks  \n Experience with data science platforms such as Snowflake, Databricks, Sagemaker, MLFlow, AWS EC2, S3 and Spark  \n Expert in statistical techniques including hypothesis testing, experiment design and online learning  \n Effective communication skills, including the ability to present information, write reports, and correspond with leaders, clients, customers, and the general public.  \n Proficiency with GitHub and code versioning in production-based environments.  \n Experience with healthcare data \n \n \n \n \n    As a remote position, the salary range for this role is:\n    \n \n     $130,000\u2014$150,000 USD\n    \n \n \n \n Total Rewards \n  Individual compensation packages are based on a few different factors unique to each candidate, including primary work location and an evaluation of a candidate\u2019s skills, experience, market demands, and internal equity. \n  Salary is just one component of Transcarent's total package. All regular employees are also eligible for the corporate bonus program or a sales incentive (target included in OTE) as well as stock options. \n  Our benefits and perks programs include, but are not limited to: \n \n Competitive medical, dental, and vision coverage \n Competitive 401(k) Plan with a generous company match \n Flexible Time Off/Paid Time Off, 12 paid holidays \n Protection Plans including Life Insurance, Disability Insurance, and Supplemental Insurance \n Mental Health and Wellness benefits \n \n Location \n  You must be authorized to work in the United States. Depending on the position we may have a preference to a specific location, but are generally open to remote work anywhere in the US. \n  Transcarent is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. If you are a person with a disability and require assistance during the application process, please don\u2019t hesitate to reach out! \n  Research shows that candidates from underrepresented backgrounds often don\u2019t apply unless they meet 100% of the job criteria. While we have worked to consolidate the minimum qualifications for each role, we aren\u2019t looking for someone who checks each box on a page; we\u2019re looking for active learners and people who care about disrupting the current health and care with their unique experiences.", "cleaned_desc": " \n What you'll do \n  The Senior Data Scientist will report to the Head of Data Science and work with other data scientist, medical coding specialists, solutions managers and digital marketing specialists. The Senior Data Scientist will be responsible for researching, creating and deploying machine learning algorithms used to identify and prioritize needs for various medical services and optimize outreach efforts to increase member engagement and utilization of medically appropriate services while decreasing churn and costs of acquisition. \n  The Senior Data Scientist should have familiarity and experience with medical codes including ICD-10, CPT, PCS, PII and PHI, in addition to non-medical data including SDoH, and digital marketing data. The Senior Data Scientist will also work with the Data Engineering and Product teams to develop robust pipelines for data acquisition and model deployment. \n  A successful candidate in this role will serve as an advocate for data science across the organization, helping business leaders understand data science capabilities, identify new use cases and promote a data-centric, evidence-based culture across the entire company. They will serve a key role within the Data Science organization, modeling best practices in agile project management, code development, review, testing, deployment and monitoring. \n  What we're looking for \n \n Strong focus on data-driven decision-making \n Ability to work with stakeholders to translate business needs into data science questions \n Strong problem solving skills and ability to identify new opportunities and methods \n Expert in Python and machine learning libraries including sklearn and tensorflow   Strong experience in successfully deploying supervised, unsupervised and reinforcement learning models to production  \n Expert in SQL and RDBMS best practices such as normalization  \n Experience with no-SQL and semi-structured data  \n Familiarity with MLOps frameworks  \n Experience with data science platforms such as Snowflake, Databricks, Sagemaker, MLFlow, AWS EC2, S3 and Spark  \n Expert in statistical techniques including hypothesis testing, experiment design and online learning  \n Effective communication skills, including the ability to present information, write reports, and correspond with leaders, clients, customers, and the general public.  \n Proficiency with GitHub and code versioning in production-based environments.  \n Experience with healthcare data \n \n ", "techs": ["icd-10", "cpt", "pcs", "pii", "phi", "sdoh", "python", "sklearn", "tensorflow", "sql", "rdbms", "no-sql", "mlops", "snowflake", "databricks", "sagemaker", "mlflow", "aws ec2", "s3", "spark", "statistical techniques", "hypothesis testing", "experiment design", "online learning", "github", "healthcare data"]}, "01101c023354409d": {"terms": ["data science", "mlops"], "salary_min": 130000.0, "salary_max": 150000.0, "title": "Senior Data Scientist", "company": "Transcarent", "desc": "Who we are \n  Transcarent is the One Place for health and care. We cut through the complexity, making it easy for people to access high-quality, affordable care. With a personalized app tailored for each Member, an on-demand care team, and a connected ecosystem of high-quality, in-person care and virtual point solutions, Transcarent eliminates the guesswork to confidently guide Members to the right level of care. We take accountability for results \u2013 offering at-risk pricing models and transparent impact reporting to align incentives towards measurably better experience, better health, and lower costs. At Transcarent, you will be part of a world-class team, supported by top tier investors like 7wireVentures and General Catalyst, and founded by a mission-driven team committed to transforming the health and care experience for all. We closed on our Series C funding in January 2022, raising our total funding to $298 million and enabling us to respond to the demand for our offering. \n  Transcarent is committed to growing and empowering a diverse and inclusive community within our company. We believe that a team with diverse lived experiences, working together will strengthen our organization, and our ability to deliver \"not just better but different\" experiences for our members. \n  We are looking for teammates to join us in building our company, culture, and Member experience who: \n \n Put people first, and make decisions with the Member's best interests in mind \n Are active learners, constantly looking to improve and grow \n Are driven by our mission to measurably improve health and care each day \n Bring the energy needed to transform health and care, and move and adapt rapidly \n Are laser focused on delivering results for Members, and proactively problem solving to get there \n \n \n  What you'll do \n  The Senior Data Scientist will report to the Head of Data Science and work with other data scientist, medical coding specialists, solutions managers and digital marketing specialists. The Senior Data Scientist will be responsible for researching, creating and deploying machine learning algorithms used to identify and prioritize needs for various medical services and optimize outreach efforts to increase member engagement and utilization of medically appropriate services while decreasing churn and costs of acquisition. \n  The Senior Data Scientist should have familiarity and experience with medical codes including ICD-10, CPT, PCS, PII and PHI, in addition to non-medical data including SDoH, and digital marketing data. The Senior Data Scientist will also work with the Data Engineering and Product teams to develop robust pipelines for data acquisition and model deployment. \n  A successful candidate in this role will serve as an advocate for data science across the organization, helping business leaders understand data science capabilities, identify new use cases and promote a data-centric, evidence-based culture across the entire company. They will serve a key role within the Data Science organization, modeling best practices in agile project management, code development, review, testing, deployment and monitoring. \n  What we're looking for \n \n Strong focus on data-driven decision-making \n Ability to work with stakeholders to translate business needs into data science questions \n Strong problem solving skills and ability to identify new opportunities and methods \n Expert in Python and machine learning libraries including sklearn and tensorflow \n Strong experience in successfully deploying supervised, unsupervised and reinforcement learning models to production  \n Expert in SQL and RDBMS best practices such as normalization  \n Experience with no-SQL and semi-structured data  \n Familiarity with MLOps frameworks  \n Experience with data science platforms such as Snowflake, Databricks, Sagemaker, MLFlow, AWS EC2, S3 and Spark  \n Expert in statistical techniques including hypothesis testing, experiment design and online learning  \n Effective communication skills, including the ability to present information, write reports, and correspond with leaders, clients, customers, and the general public.  \n Proficiency with GitHub and code versioning in production-based environments.  \n Experience with healthcare data \n \n \n As a remote position, the salary range for this role is: \n \n    $130,000\u2014$150,000 USD\n   \n \n \n  Total Rewards \n  Individual compensation packages are based on a few different factors unique to each candidate, including primary work location and an evaluation of a candidate's skills, experience, market demands, and internal equity. \n  Salary is just one component of Transcarent's total package. All regular employees are also eligible for the corporate bonus program or a sales incentive (target included in OTE) as well as stock options. \n  Our benefits and perks programs include, but are not limited to: \n \n Competitive medical, dental, and vision coverage \n Competitive 401(k) Plan with a generous company match \n Flexible Time Off/Paid Time Off, 12 paid holidays \n Protection Plans including Life Insurance, Disability Insurance, and Supplemental Insurance \n Mental Health and Wellness benefits \n \n Location \n  You must be authorized to work in the United States. Depending on the position we may have a preference to a specific location, but are generally open to remote work anywhere in the US. \n  Transcarent is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. If you are a person with a disability and require assistance during the application process, please don't hesitate to reach out! \n  Research shows that candidates from underrepresented backgrounds often don't apply unless they meet 100% of the job criteria. While we have worked to consolidate the minimum qualifications for each role, we aren't looking for someone who checks each box on a page; we're looking for active learners and people who care about disrupting the current health and care with their unique experiences.", "cleaned_desc": " \n \n  What you'll do \n  The Senior Data Scientist will report to the Head of Data Science and work with other data scientist, medical coding specialists, solutions managers and digital marketing specialists. The Senior Data Scientist will be responsible for researching, creating and deploying machine learning algorithms used to identify and prioritize needs for various medical services and optimize outreach efforts to increase member engagement and utilization of medically appropriate services while decreasing churn and costs of acquisition. \n  The Senior Data Scientist should have familiarity and experience with medical codes including ICD-10, CPT, PCS, PII and PHI, in addition to non-medical data including SDoH, and digital marketing data. The Senior Data Scientist will also work with the Data Engineering and Product teams to develop robust pipelines for data acquisition and model deployment. \n  A successful candidate in this role will serve as an advocate for data science across the organization, helping business leaders understand data science capabilities, identify new use cases and promote a data-centric, evidence-based culture across the entire company. They will serve a key role within the Data Science organization, modeling best practices in agile project management, code development, review, testing, deployment and monitoring. \n  What we're looking for \n \n Strong focus on data-driven decision-making \n Ability to work with stakeholders to translate business needs into data science questions   Strong problem solving skills and ability to identify new opportunities and methods \n Expert in Python and machine learning libraries including sklearn and tensorflow \n Strong experience in successfully deploying supervised, unsupervised and reinforcement learning models to production  \n Expert in SQL and RDBMS best practices such as normalization  \n Experience with no-SQL and semi-structured data  \n Familiarity with MLOps frameworks  \n Experience with data science platforms such as Snowflake, Databricks, Sagemaker, MLFlow, AWS EC2, S3 and Spark  \n Expert in statistical techniques including hypothesis testing, experiment design and online learning  \n Effective communication skills, including the ability to present information, write reports, and correspond with leaders, clients, customers, and the general public.  \n Proficiency with GitHub and code versioning in production-based environments.  ", "techs": ["icd-10", "cpt", "pcs", "pii", "phi", "sdoh", "sklearn", "tensorflow", "sql", "rdbms", "mlops", "snowflake", "databricks", "sagemaker", "mlflow", "aws ec2", "s3", "spark", "hypothesis testing", "experiment design", "online learning", "github"]}, "382b78faa8215ef2": {"terms": ["data science"], "salary_min": 107107.77, "salary_max": 110990.01, "title": "Data Scientist", "company": "IStream Solutions", "desc": "Required: \n \n Generative AI \n LLM \n AI Models \n Python \n \n Responsibilities \u2003\u2022\u2003\u2003Build and deploy GenAI enabled applications using client\u2019s tech stack \u2003\u2022\u2003\u2003Fine tune open source models and/or build telecom specific Generative AI models \u2003\u2022\u2003\u2003Evaluate and make recommendations to use services provided by different vendors to speed time to market \u2003\u2022\u2003\u2003Actively involve in ongoing AI training and refinement \u2003\u2022\u2003\u2003Collaborate with cross-disciplinary teams - developers, other data scientist, data analysts, business \u2003\u2022\u2003\u2003Monitor and correlate inputs and outputs, establish meaningful metrics \u2003\u2022\u2003\u2003Lead and act as a technical liaison between business, executives and data science teams to deliver POC\u2019s / pilot on need basis. \u2003\u2022\u2003\u2003Keep up to date with technological developments and make recommendations for improvements Requirements \u2003\u2022\u2003\u2003Master\u2019s degree in Data science \u2003\u2022\u2003\u200310+ years of experience in data science , with a focus on generative  AI technology/data science \u2003\u2022\u2003\u20035+ years of data querying languages  (e.g. SQL), scripting languages (e.g. Python) \u2003\u2022\u2003\u2003Telecommunication domain experience \u2003\u2022\u2003\u2003Strong analytical and problem-solving skills \u2003\u2022\u2003\u2003Excellent verbal and written communication skills \u2003\u2022\u2003\u2003Ability to work independently and as part of a team in a fast-paced environment \u2003\u2022\u2003\u2003Hands on fine tuning  AI models (SBERT, ScaNN, PaLM, ChatGPT, LLM) \u2003\u2022\u2003\u2003Strong background in Natural Language Processing, including experience with text representation, language modelling, sequence-to-sequence architectures, and semantic understanding \u2003\u2003\u2022\u2003\u2003Technical skills : Data science, Python, Javascript, MongoDB, AWS/GCP, API Programming \n Job Types: Contract, Full-time \n Pay: $107,107.77 - $110,990.01 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " AI Models \n Python \n \n Responsibilities \u2003\u2022\u2003\u2003Build and deploy GenAI enabled applications using client\u2019s tech stack \u2003\u2022\u2003\u2003Fine tune open source models and/or build telecom specific Generative AI models \u2003\u2022\u2003\u2003Evaluate and make recommendations to use services provided by different vendors to speed time to market \u2003\u2022\u2003\u2003Actively involve in ongoing AI training and refinement \u2003\u2022\u2003\u2003Collaborate with cross-disciplinary teams - developers, other data scientist, data analysts, business \u2003\u2022\u2003\u2003Monitor and correlate inputs and outputs, establish meaningful metrics \u2003\u2022\u2003\u2003Lead and act as a technical liaison between business, executives and data science teams to deliver POC\u2019s / pilot on need basis. \u2003\u2022\u2003\u2003Keep up to date with technological developments and make recommendations for improvements Requirements \u2003\u2022\u2003\u2003Master\u2019s degree in Data science \u2003\u2022\u2003\u200310+ years of experience in data science , with a focus on generative  AI technology/data science \u2003\u2022\u2003\u20035+ years of data querying languages  (e.g. SQL), scripting languages (e.g. Python) \u2003\u2022\u2003\u2003Telecommunication domain experience \u2003\u2022\u2003\u2003Strong analytical and problem-solving skills \u2003\u2022\u2003\u2003Excellent verbal and written communication skills \u2003\u2022\u2003\u2003Ability to work independently and as part of a team in a fast-paced environment \u2003\u2022\u2003\u2003Hands on fine tuning  AI models (SBERT, ScaNN, PaLM, ChatGPT, LLM) \u2003\u2022\u2003\u2003Strong background in Natural Language Processing, including experience with text representation, language modelling, sequence-to-sequence architectures, and semantic understanding \u2003\u2003\u2022\u2003\u2003Technical skills : Data science, Python, Javascript, MongoDB, AWS/GCP, API Programming ", "techs": ["ai models", "python", "sbert", "scann", "palm", "chatgpt", "llm", "natural language processing", "text representation", "language modelling", "sequence-to-sequence architectures", "semantic understanding", "data science", "javascript", "mongodb", "aws/gcp", "api programming"]}, "1f5163ef1af02230": {"terms": ["data science"], "salary_min": 60.0, "salary_max": 65.0, "title": "Data Science Instructor", "company": "Institute of Data", "desc": "About the Institute of Data \n The Institute of Data is a Professional Network of Data Scientists, Cyber Security Analysts and Software Engineering. In partnership with leading universities in Australia, New Zealand & America, the government of Singapore and hundreds of employers, we transform careers for a data-driven world. \n About the role \n We are looking for Lead Trainers to lead this transformative experience in partnership with  University of Louisiana Layafette and Virginia Commonwealth University . The work is  remote  in virtual classroom and with classes of up to 15 students. \n Next cohort:  Mondays & Wednesdays 6-9pm  and  fortnightly Saturdays 9am-5pm from 6 November 2023 to 4 May 2024.  Note this is Louisiana Central time. \n The content is provided and covers how to apply machine learning and AI techniques for businesses and government organisations including business consulting and simulating commercial projects. Assessment is in the form of labs and project work. Students graduating from the course are well-equipped to take on junior data analyst roles. \n \n Deliver cirriculum and support students to enter the industry \n Provide students with meaningful and prompt feedback on their progress \n Guide students through the development of real-world projects that will showcase their abilities to hiring managers \n Facilitate a dynamic and collaborative classroom community \n Inspire students to persevere through the challenges of learning complex subjects. \n Work with and guide Assistant Trainer to provide support to students. \n \n About you \n \n Minimum 5 years of professional data science experience. \n Expert in SQL, Python, and related Python libraries (pandas, numpy). \n Domain expertise in statistics, mathematics, and probability. \n Ability to build and apply statistical models in python using machine learning libraries, such as scikit-learn and statsmodels. \n Deep understanding of statistical hypothesis testing and experimental design, data visualisation techniques and tools (i.e. matplotlib, bokeh, etc), and manipulation of large data sets. \n Demonstrate and explain the function of machine learning algorithms such as regularised regression, naive bayes, decision trees, ensemble methods, KNN, K-means clustering, and neural networks. \n Excellent verbal communication with the ability to express technical material in an accessible way \n Desire to help others learn and grow and comfortable in a classroom environment. \n \n Culture & Benefits \n \n Remote work \n Contract opportunities outside of business hours \n Work in a fun supportive virtual environment \n Make a life-changing impact by doing what you know and love \n Speaking opportunities at industry events \n \n Job Types: Contract, Part-time \n Salary: $60.00 - $65.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n Evening shift \n Weekends as needed \n \n Application Question(s): \n \n The hours required are in Central Time: Mondays and Wednesdays 6-9pm and fortnightly Saturdays 9am-5pm. Are you able to commit to this? \n The project dates are 6 November 2023 to 4 May 2024. Are you available for all classes during this time? \n \n Experience: \n \n Data science & AI: 5 years (Required) \n \n Work Location: Remote", "cleaned_desc": " Facilitate a dynamic and collaborative classroom community \n Inspire students to persevere through the challenges of learning complex subjects. \n Work with and guide Assistant Trainer to provide support to students. \n \n About you \n \n Minimum 5 years of professional data science experience. \n Expert in SQL, Python, and related Python libraries (pandas, numpy). \n Domain expertise in statistics, mathematics, and probability. \n Ability to build and apply statistical models in python using machine learning libraries, such as scikit-learn and statsmodels.   Deep understanding of statistical hypothesis testing and experimental design, data visualisation techniques and tools (i.e. matplotlib, bokeh, etc), and manipulation of large data sets. \n Demonstrate and explain the function of machine learning algorithms such as regularised regression, naive bayes, decision trees, ensemble methods, KNN, K-means clustering, and neural networks. \n Excellent verbal communication with the ability to express technical material in an accessible way \n Desire to help others learn and grow and comfortable in a classroom environment. \n \n Culture & Benefits \n \n Remote work \n Contract opportunities outside of business hours \n Work in a fun supportive virtual environment ", "techs": ["sql", "python", "pandas", "numpy", "scikit-learn", "statsmodels", "matplotlib", "bokeh", "regularised regression", "naive bayes", "decision trees", "ensemble methods", "knn", "k-means clustering", "neural networks"]}, "968ba32b37e9d243": {"terms": ["data science", "data analyst"], "salary_min": 98085.43, "salary_max": 124198.01, "title": "Senior Data Analyst", "company": "Mammoth Freighters", "desc": "Senior Data Analyst \n We are seeking a highly skilled and experienced Senior Data Analyst to join our dynamic team in a critical role that bridges the gap between data analysis and program management within the realms of engineering, supply chain, and production. The ideal candidate will possess strong expertise in utilizing Power BI for data visualization, along with a proven track record of setting up and managing complex program metrics. Your ability to understand and interpret data-driven insights will be instrumental in driving informed decisions across various operational domains. This role demands proficiency in the DAX language and a deep understanding of establishing robust table relationships. This role will report to the SVP of Program Management. \n Job Responsibilities \n \u00b7 Collaborate closely with cross-functional teams in engineering, supply chain, and production to identify key performance metrics and indicators. \n \u00b7 Design, develop, and implement comprehensive Power BI dashboards and reports that provide actionable insights for program management and decision-making. \n \u00b7 Utilize DAX language to create advanced calculations, measures, and transformations to ensure accurate representation of metrics in reports. \n \u00b7 Build and maintain complex data models with a keen focus on establishing accurate and efficient table relationships, enabling seamless data flow and analysis. \n \u00b7 Analyze large datasets to extract valuable insights, identify trends, and present findings in a clear and concise manner. \n \u00b7 Work closely with stakeholders to understand their data needs and translate requirements into effective data visualizations. \n \u00b7 Lead the development of data-driven solutions that enhance program efficiency, quality, and overall performance. \n \u00b7 Establish data quality standards and procedures to ensure accuracy, consistency, and reliability of metrics. \n \u00b7 Stay current with industry trends, best practices, and advancements in data visualization, DAX language, and program management techniques. \n Education/Experience \n \u00b7 Bachelor's degree in a relevant field such as Engineering, Supply Chain Management, Business Analytics, or a related discipline. Master's degree is a plus. \n \u00b7 Proven experience (5+ years) in utilizing Power BI for data visualization and creating advanced dashboards and reports. \n \u00b7 Demonstrated expertise in setting up and managing metrics for complex programs within engineering, supply chain, or production environments. \n \u00b7 Proficiency in the DAX language is essential, with the ability to create complex calculations and measures. \n \u00b7 Strong aptitude for establishing and optimizing table relationships to ensure accurate data modeling. \n \u00b7 Excellent analytical skills and the ability to transform raw data into meaningful insights. \n \u00b7 Effective communication skills to collaborate with technical and non-technical stakeholders. \n \u00b7 Experience in data manipulation, transformation, and cleaning for accurate analysis. \n \u00b7 Detail-oriented mindset with a commitment to data accuracy and quality. \n \u00b7 Ability to work independently, prioritize tasks, and manage multiple projects simultaneously. \n \u00b7 Familiarity with engineering, supply chain, or production processes is a plus. \n \u00b7 Certifications in Power BI and relevant data analysis fields are valuable. \n Location \n This is a hybrid role with occasional travel to our headquarters in Fort Worth, Texas. Travel requirements are anticipated to be no more than 25% of the time. \n Residing within the Dallas Fort Worth Metroplex area would be highly advantageous, facilitating convenience for both remote work and in-person collaboration. \n Job Type: Full-time \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "Senior Data Analyst \n We are seeking a highly skilled and experienced Senior Data Analyst to join our dynamic team in a critical role that bridges the gap between data analysis and program management within the realms of engineering, supply chain, and production. The ideal candidate will possess strong expertise in utilizing Power BI for data visualization, along with a proven track record of setting up and managing complex program metrics. Your ability to understand and interpret data-driven insights will be instrumental in driving informed decisions across various operational domains. This role demands proficiency in the DAX language and a deep understanding of establishing robust table relationships. This role will report to the SVP of Program Management. \n Job Responsibilities \n \u00b7 Collaborate closely with cross-functional teams in engineering, supply chain, and production to identify key performance metrics and indicators. \n \u00b7 Design, develop, and implement comprehensive Power BI dashboards and reports that provide actionable insights for program management and decision-making. \n \u00b7 Utilize DAX language to create advanced calculations, measures, and transformations to ensure accurate representation of metrics in reports. \n \u00b7 Build and maintain complex data models with a keen focus on establishing accurate and efficient table relationships, enabling seamless data flow and analysis. \n \u00b7 Analyze large datasets to extract valuable insights, identify trends, and present findings in a clear and concise manner.   \u00b7 Work closely with stakeholders to understand their data needs and translate requirements into effective data visualizations. \n \u00b7 Lead the development of data-driven solutions that enhance program efficiency, quality, and overall performance. \n \u00b7 Establish data quality standards and procedures to ensure accuracy, consistency, and reliability of metrics. \n \u00b7 Stay current with industry trends, best practices, and advancements in data visualization, DAX language, and program management techniques. \n Education/Experience \n \u00b7 Bachelor's degree in a relevant field such as Engineering, Supply Chain Management, Business Analytics, or a related discipline. Master's degree is a plus. \n \u00b7 Proven experience (5+ years) in utilizing Power BI for data visualization and creating advanced dashboards and reports. \n \u00b7 Demonstrated expertise in setting up and managing metrics for complex programs within engineering, supply chain, or production environments.   \u00b7 Proficiency in the DAX language is essential, with the ability to create complex calculations and measures. \n \u00b7 Strong aptitude for establishing and optimizing table relationships to ensure accurate data modeling. \n \u00b7 Excellent analytical skills and the ability to transform raw data into meaningful insights. \n \u00b7 Effective communication skills to collaborate with technical and non-technical stakeholders. \n \u00b7 Experience in data manipulation, transformation, and cleaning for accurate analysis. \n \u00b7 Detail-oriented mindset with a commitment to data accuracy and quality. \n \u00b7 Ability to work independently, prioritize tasks, and manage multiple projects simultaneously. \n \u00b7 Familiarity with engineering, supply chain, or production processes is a plus. ", "techs": ["power bi", "dax language"]}, "95366459480edaf7": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "VP, Data Science", "company": "Attain", "desc": "About Attain \n  Built for consumers and companies, alike \n  In a world driven by data, we believe consumers and businesses can coexist. Our founders had a vision to empower consumers to leverage their greatest asset\u2014their data\u2014in exchange for modern financial services. Built with this vision in mind, our platform allows consumers to access savings tools, earned wages and rewards without cost or hidden fees. In exchange, they give permission to use their real-time data for research, insights and targeted advertising. \n  At Attain, your contribution will help us build a more equitable and efficient data sharing ecosystem\u2014whether helping consumers access modern financial services or businesses leverage data to achieve better outcomes. You'll have the opportunity to work directly with hands-on leaders and mission-driven individuals everyday. \n  About the role \n  As the VP of Data Science, you will be responsible for shaping our data science strategy, leading a high-performing team, and driving data-driven initiatives that have a significant impact on our business. You will collaborate closely with cross-functional teams to develop and implement data science solutions, leveraging advanced analytics and machine learning techniques. The ideal candidate will have a strong track record in data science leadership, a deep understanding of data-driven business strategies, and the ability to drive innovation through data. \n  Responsibilities \n \n Collaborate with stakeholders to understand business needs and translate them into actionable data science projects \n Drive the development and implementation of advanced analytics initiatives and unlock the power of the new generation of AI tools to capitalize our most powerful asset: our data (e.g. predictive modeling, generative AI, time-series forecasting, machine learning for media targeting, advanced data visualization, etc) \n Collaborate with other teams to integrate data science solutions into existing systems and infrastructure. \n Lead a team of data scientists and analysts, providing guidance, mentorship, and fostering a collaborative and high-performance culture \n Stay abreast of emerging technologies, trends, and best practices in data analytics to identify innovative opportunities \n \n Preferred Qualifications \n \n 12+ years of experience in data science or analytics \n 8+ years of experience in leading and mentoring a team of data scientists or analysts \n An advanced degree in computer science data science, information management or a related field, strongly preferred \n Proven expertise in leveraging data analytics tools, techniques, and technologies to extract insights and drive data-informed decision-making \n Strong experience working in SQL, Python, and/or R \n Experience working with BI tools such as Looker \n Knowledge and experience working with Google Cloud Platform suite (e.g. BigQuery, Vertex AI) \n Excellent problem-solving skills with the ability to approach complex business challenges from a data-driven perspective \n Demonstrated ability to work in a fast-paced, dynamic environment \n \n We're excited to hear from you. \n  At Attain, we are passionate about finding people to continuously help us grow our organization. We encourage you to apply, even if your experience doesn't match every detail of the job description. If we don't see something that immediately fits, we will keep your resume on file for future opportunities.", "cleaned_desc": "  As the VP of Data Science, you will be responsible for shaping our data science strategy, leading a high-performing team, and driving data-driven initiatives that have a significant impact on our business. You will collaborate closely with cross-functional teams to develop and implement data science solutions, leveraging advanced analytics and machine learning techniques. The ideal candidate will have a strong track record in data science leadership, a deep understanding of data-driven business strategies, and the ability to drive innovation through data. \n  Responsibilities \n \n Collaborate with stakeholders to understand business needs and translate them into actionable data science projects \n Drive the development and implementation of advanced analytics initiatives and unlock the power of the new generation of AI tools to capitalize our most powerful asset: our data (e.g. predictive modeling, generative AI, time-series forecasting, machine learning for media targeting, advanced data visualization, etc)   Collaborate with other teams to integrate data science solutions into existing systems and infrastructure. \n Lead a team of data scientists and analysts, providing guidance, mentorship, and fostering a collaborative and high-performance culture \n Stay abreast of emerging technologies, trends, and best practices in data analytics to identify innovative opportunities \n \n Preferred Qualifications   \n 12+ years of experience in data science or analytics \n 8+ years of experience in leading and mentoring a team of data scientists or analysts \n An advanced degree in computer science data science, information management or a related field, strongly preferred \n Proven expertise in leveraging data analytics tools, techniques, and technologies to extract insights and drive data-informed decision-making   Strong experience working in SQL, Python, and/or R \n Experience working with BI tools such as Looker \n Knowledge and experience working with Google Cloud Platform suite (e.g. BigQuery, Vertex AI) \n Excellent problem-solving skills with the ability to approach complex business challenges from a data-driven perspective \n Demonstrated ability to work in a fast-paced, dynamic environment ", "techs": ["looker", "google cloud platform suite", "bigquery", "vertex ai", "sql", "python", "r"]}, "468c4453025b8c44": {"terms": ["data science"], "salary_min": 800.0, "salary_max": 800.0, "title": "Data Bootcamp Assistant Trainer", "company": "Institute of Data", "desc": "About the Institute of Data \n The Institute of Data is a Professional Network of Data Scientists, Cyber Security Analysts and Software Engineering. In partnership with leading universities in Australia, New Zealand & America, the government of Singapore and hundreds of employers, we transform careers for a data-driven world. \n About the role \n We are looking for Data Bootcamp Assistant Trainers to join a team of trainers to deliver our next cohort. Bootcamps are short intensive course to upskill quickly for a career change. \n Your responsibilities: \n \n Deliver and grade practical labs on data collection, cleaning, analysis and visualisation \n Take attendance, rate engagement, and promote survey completion \n Assisting to create a dynamic and collaborative classroom community \n Inspire students to persevere through the challenges of learning complex subjects. \n \n Next cohort: Every  Monday and Wednesday 6-9pm  and  fortnightly Saturdays 9am-5pm from 6 November 2023 to 4 May 2024.  Note this is Louisiana  Central Time . Run in partnership with  University of Louisiana Layafette and Virginia Commonwealth University . The work is  remote  in virtual classroom and with classes of up to 15 students. \n Culture & Benefits \n \n Remote work \n Further contract opportunities in 2024 \n Work in a fun supportive virtual environment \n Make a life-changing impact by doing what you know and love \n Speaking opportunities at industry events \n \n Job Type: Contract \n Salary: $800.00 per month \n Schedule: \n \n Evening shift \n Weekends as needed \n \n Application Question(s): \n \n Are you able to work Mondays and Wednesdays 6-9pm CST and every second Saturday 9am-5pm CST? \n Are you able to attend every class between the project dates of 6 Nov 2023 and 4 May 2024? \n \n Experience: \n \n Data science: 1 year (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "249bbe9b50a92d99": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Senior Applied Data Scientist", "company": "R1 RCM, Inc.", "desc": "The Senior Data Scientist will be responsible for building predictive models and analytic solutions for business end users to help them make more efficient decisions in their day-to-day work.  \n In this role, the successful candidate must have a demonstrated understanding of machine learning concepts, data engineering techniques, and presentation ready reporting. This position requires good time management skills and the ability to work independently. Having strong critical thinking capabilities with a background in solving solutions with healthcare claims data will be key to being successful in this position.  \n \n Responsibilities:  \n \n Collaborates with development teams to prepare and manipulate structured and unstructured data for data discovery and mining from multiple disparate resources.  \n Builds high-end analytic models, utilizing supervised and unsupervised learning models, to support decision makers with data driven insights that address immediate business problems and objectives.  \n Creates informative visualizations that intuitively display large amounts of data and/or complex relationships, translating data analytics into coherent reports and presentations for internal and external customer with varying degrees of technical knowledge.  \n Utilizes machine learning, artificial intelligence, pattern recognition, and/or advanced statistics to deliver projects.  \n Routinely uses anonymized or encrypted data.  \n Prototypes solutions using varied resources, including both commercial and open-source software.  \n \n \n Required Qualifications:  \n \n 2+ years of experience working in healthcare.  \n 6+ years of experience utilizing machine learning models.  \n History of delivering data science projects including data discovery, modeling, and application integration.  \n Experience leading data science projects, including resource allocation, project estimation and mentoring other staff members.  \n Can facilitate converting business needs into technical projects.  \n Experience using R and Python to program machine learning models.  \n Experience using SQL to extract data from databases.  \n Knowledge of deploying models and reports into cloud-based environments (Azure, AWS, etc.).  \n Ability to visualize data and model results utilizing a modern BI tool (Power BI, Spotfire, Tableau, etc.).  \n Advanced knowledge of machine learning modeling techniques (clustering, decision tree learning, and NLP) and their real-world advantages/drawbacks.  \n Excellent written and verbal communication with the ability to present results to teams of people, including executive stakeholders.  \n Can work independently to resolve complex issues in creative and effective ways.  \n Strong mentoring capabilities.  \n \n \n Desired Qualifications:  \n \n Advanced knowledge working with Azure Machine Learning and notebook coding environments.  \n Understanding of performance improvement techniques for extracting large datasets from SQL-based environments.  \n Experience delivering advanced statistical concepts through Power BI.  \n Experience using Snowflake and Databricks as data sources.  \n \n \n Education:  \n \n Master\u2019s degree (or equivalent training/relevant experience) in fields that include strong coverage of applied mathematics and statistics, computer science, engineering, or related fields.  \n The US base pay range for this position is $63,140.06 - $143,517.00. Individual pay is determined by role, level, location, job-related skills, experience, and relevant education or training. \n  \n Learn more about Benefits at R1  \n \n Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests.   \n  Our associates are given valuable opportunities to contribute, to innovate and create meaningful work that makes an impact in the communities we serve around the world. We also offer a culture of excellence that drives customer success and improves patient care. We believe in giving back to the community and offer a competitive benefits package including:  \n \n Comprehensive Medical, Dental, Vision & RX Coverage  \n Paid Time Off, Volunteer Time & Holidays  \n 401K with Company Match  \n Company-Paid Life Insurance, Short-Term Disability & Long-Term Disability  \n Tuition Reimbursement  \n Parental Leave  \n \n \n R1 RCM Inc. (\u201cthe Company\u201d) is dedicated to the fundamentals of equal employment opportunity. The Company\u2019s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person\u2019s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.  \n \n If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.  \n \n CA PRIVACY NOTICE: California resident job applicants can learn more about their privacy rights California Consent", "cleaned_desc": "The Senior Data Scientist will be responsible for building predictive models and analytic solutions for business end users to help them make more efficient decisions in their day-to-day work.  \n In this role, the successful candidate must have a demonstrated understanding of machine learning concepts, data engineering techniques, and presentation ready reporting. This position requires good time management skills and the ability to work independently. Having strong critical thinking capabilities with a background in solving solutions with healthcare claims data will be key to being successful in this position.  \n \n Responsibilities:  \n \n Collaborates with development teams to prepare and manipulate structured and unstructured data for data discovery and mining from multiple disparate resources.  \n Builds high-end analytic models, utilizing supervised and unsupervised learning models, to support decision makers with data driven insights that address immediate business problems and objectives.  \n Creates informative visualizations that intuitively display large amounts of data and/or complex relationships, translating data analytics into coherent reports and presentations for internal and external customer with varying degrees of technical knowledge.  \n Utilizes machine learning, artificial intelligence, pattern recognition, and/or advanced statistics to deliver projects.  \n Routinely uses anonymized or encrypted data.  \n Prototypes solutions using varied resources, including both commercial and open-source software.  \n   \n Required Qualifications:  \n \n 2+ years of experience working in healthcare.  \n 6+ years of experience utilizing machine learning models.  \n History of delivering data science projects including data discovery, modeling, and application integration.  \n Experience leading data science projects, including resource allocation, project estimation and mentoring other staff members.  \n Can facilitate converting business needs into technical projects.  \n Experience using R and Python to program machine learning models.  \n Experience using SQL to extract data from databases.  \n Knowledge of deploying models and reports into cloud-based environments (Azure, AWS, etc.).  \n Ability to visualize data and model results utilizing a modern BI tool (Power BI, Spotfire, Tableau, etc.).    Advanced knowledge of machine learning modeling techniques (clustering, decision tree learning, and NLP) and their real-world advantages/drawbacks.  \n Excellent written and verbal communication with the ability to present results to teams of people, including executive stakeholders.  \n Can work independently to resolve complex issues in creative and effective ways.  \n Strong mentoring capabilities.  \n \n \n Desired Qualifications:  \n \n Advanced knowledge working with Azure Machine Learning and notebook coding environments.  \n Understanding of performance improvement techniques for extracting large datasets from SQL-based environments.  \n Experience delivering advanced statistical concepts through Power BI.  \n Experience using Snowflake and Databricks as data sources.  ", "techs": ["machine learning models", "r", "python", "sql", "azure", "aws", "power bi", "spotfire", "tableau", "clustering", "decision tree learning", "nlp", "azure machine learning", "notebook coding environments", "performance improvement techniques", "snowflake", "databricks"]}, "89a97b66caf34c96": {"terms": ["data science"], "salary_min": 145000.0, "salary_max": 155000.0, "title": "Sr. Data Scientist", "company": "Perfect Path, LLC, d/b/a Trajector Services", "desc": "Overview:\n  \n \n  One Trajector. One Mission. \n \n \n \n  Trajector is where purpose meets progress. We specialize in developing medical evidence that becomes the compass our clients rely on while navigating the intricate terrain of disability benefits. Our calling is clear: to make a real difference, infuse passion, and enhance the quality of life for the disabled community. As part of our global community, you'll join a team of over 1,500 dedicated individuals, each contributing their unique talents to streamline the path to benefits. Urgency propels us, data empowers us, and every step is tailored to ensure those with disabilities access their rightful compensation. Join us in shaping stories of transformation, one life at a time.\n   Job Overview: \n  \n   As the pioneers in this space, we have developed new and innovative Data Science techniques which have been an important part of our growth in revenue, and EBITDA. We have a data-focused culture, and are eager to expand our team with contributors who share our passion for data and insights. We now seek a Lead Data Scientist for our Product Analytics domain to enrich our team. This remote position will report directly to our VP of Data.\n   About Our Perks, Compensation, & Benefits: \n  \n $145,000 - $155,000 annual salary PLUS quarterly bonuses based on performance \n  Medical, dental, vision, life insurance, flexible spending accounts and an Employee Assistance Program \n  401k program \n  Paid time off, including 7 federal holidays plus 2 flex holidays for DEI \n  Tuition Reimbursement \n  Joining a rapidly growing organization \n  Responsibilities: \n  \n Lead the creation and implementation of product analytics and experimentation frameworks that enhance data-driven decision-making through understanding of growth, retention and engagement \n  Establish key strategic initiatives via statistical models, forecasts, and thorough analyses \n  Foster collaboration with diverse teams to uncover business opportunities and address data analysis-related challenges \n  Pinpoint avenues for process optimization using in-depth data analysis and provide actionable recommendations to stakeholders \n  Champion the continual advancement of our data science technology stack and best practices \n  Engage closely with data engineering and business stakeholders to forge a unified metrics and dimensions repository \n  Leverage insights from data to guide the development of new products, features and user experience enhancements \n  Qualifications: \n  \n Authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future \n  Academic background in a quantitative discipline such as Computer Science, Statistics, Engineering, Econometrics or similar (or equivalent relevant work experience) \n  5+ years of experience in leveraging Data Science to support key business initiatives within a corporate environment \n  Experience in applying statistical methodologies to business problems \n  Proficiency in statistical modeling, scientific computing, and data manipulation using Python tools like statsmodels, numpy, scipy, pandas \n  Proficiency in SQL \n  Ability to narrate data stories using BI platforms like Preset, Tableau, or Looker \n  Exceptional communication skills \n  A keen product mindset, complemented by skills in Product Management, Experimental Design, Statistical Modeling, and Experimentation \n  Prior experience in leading and scaling Data Science teams, especially in a product-focused role, will be a distinct advantage \n  Minimum internet speed of 25 Download/10 Upload to be eligible for hire \n  EEO Statement: \n   Trajector is an EOE/Veterans/Disabled/LGBTQ employer.", "cleaned_desc": "  Pinpoint avenues for process optimization using in-depth data analysis and provide actionable recommendations to stakeholders \n  Champion the continual advancement of our data science technology stack and best practices \n  Engage closely with data engineering and business stakeholders to forge a unified metrics and dimensions repository \n  Leverage insights from data to guide the development of new products, features and user experience enhancements \n  Qualifications: \n  \n Authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future \n  Academic background in a quantitative discipline such as Computer Science, Statistics, Engineering, Econometrics or similar (or equivalent relevant work experience)    5+ years of experience in leveraging Data Science to support key business initiatives within a corporate environment \n  Experience in applying statistical methodologies to business problems \n  Proficiency in statistical modeling, scientific computing, and data manipulation using Python tools like statsmodels, numpy, scipy, pandas \n  Proficiency in SQL \n  Ability to narrate data stories using BI platforms like Preset, Tableau, or Looker \n  Exceptional communication skills \n  A keen product mindset, complemented by skills in Product Management, Experimental Design, Statistical Modeling, and Experimentation \n  Prior experience in leading and scaling Data Science teams, especially in a product-focused role, will be a distinct advantage ", "techs": ["python tools like statsmodels", "numpy", "scipy", "pandas", "sql", "bi platforms like preset", "tableau", "looker"]}, "09d261daf5fad5a8": {"terms": ["data science", "data analyst"], "salary_min": 58300.0, "salary_max": 133000.0, "title": "Data Analytics and Visualization Specialist", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Norfolk,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0181785\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Analytics and Visualization Specialist\n           Key Role: \n  Identify and collect data sources, analyze and extract key data and information, and evaluate and monitor data quality to meet an organization's information needs and requirements. Apply consulting and technical expertise to customer challenges and develop virtual dashboards built upon specialized software fed by multiple databases. Identify, design, and execute visualization approaches and visually articulate cohesive analysis results. Conduct verification and validation of data, visualization models, and resulting visualizations. Work without considerable direction and mentor and supervise team members. \n \n  Basic Qualifications: \n \n  3+ years of experience in a professional work environment \n  3+ years of experience with data analytics and data visualization tools, including Tableau, QlikSense, or Microsoft Power BI \n  Experience with management consulting techniques, including client interviews, data gathering, and problem-solving \n  Experience with scripting languages, including SQL or Python \n  Experience with Microsoft Office \n  Experience with briefing techniques, methods, and findings to senior personnel \n  Knowledge of Extract, Transform, and Load (ETL) processes using tools, including PostgreSQL, Databricks, or NiFi \n  Knowledge of operations research techniques, including probability and statistical methods \n  Secret clearance \n  Bachelor's degree \n \n \n  Additional Qualifications: \n \n  3+ years of experience with capturing user requirements \n  3+ years of experience with the design, development, and visualization of scientific methods and techniques, including mathematical, statistical, or econometric \n  Bachelor\u2019s degree in Economics, Operations Research, Management Science, Mathematics, Statistics, or a Data Science-related field \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": "           Key Role: \n  Identify and collect data sources, analyze and extract key data and information, and evaluate and monitor data quality to meet an organization's information needs and requirements. Apply consulting and technical expertise to customer challenges and develop virtual dashboards built upon specialized software fed by multiple databases. Identify, design, and execute visualization approaches and visually articulate cohesive analysis results. Conduct verification and validation of data, visualization models, and resulting visualizations. Work without considerable direction and mentor and supervise team members. \n \n  Basic Qualifications: \n \n  3+ years of experience in a professional work environment \n  3+ years of experience with data analytics and data visualization tools, including Tableau, QlikSense, or Microsoft Power BI \n  Experience with management consulting techniques, including client interviews, data gathering, and problem-solving \n  Experience with scripting languages, including SQL or Python \n  Experience with Microsoft Office \n  Experience with briefing techniques, methods, and findings to senior personnel \n  Knowledge of Extract, Transform, and Load (ETL) processes using tools, including PostgreSQL, Databricks, or NiFi \n  Knowledge of operations research techniques, including probability and statistical methods \n  Secret clearance \n  Bachelor's degree \n \n ", "techs": ["tableau", "qliksense", "microsoft power bi", "sql", "python", "microsoft office", "postgresql", "databricks", "nifi"]}, "64b511952b7be71f": {"terms": ["data science"], "salary_min": 104731.81, "salary_max": 132613.81, "title": "Software Engineer, AI (All levels)", "company": "Pulley", "desc": "We are searching for a versatile AI Software Engineer with a deep understanding of Emerging LLM App Stack and in-context learning workflow. Your role would be instrumental in building, enhancing and maintaining our AI-driven features, specifically as they relate to OpenAI's GPT-4 API and its functions. \n \n \n  Responsibilities: \n \n \n Develop and maintain AI applications, primarily using GPT-4 API. \n Design, expand and maintain AI tools for a broad set of applications. \n Stay updated on the latest trends in AI, including emerging prompting techniques and AI agent construction. \n Contribute innovative ideas for future where Pulley's agent is interacting with other agents. \n Actively manage data and increase relevancy of vector search through strategic embeddings. \n \n \n \n \n  Requirements: \n \n \n Degree in Computer Science, AI, or a related field. \n Detailed understanding and experience with the in-context learning workflow (Data preprocessing / embedding -> Prompt construction / retrieval -> Prompt execution / inference). \n Familiarity with emerging prompting techniques (CoT, ToT, Zero/Few-shot prompting etc.). Active reading of new papers on prompting is highly desirable. \n Familiarity with building AI agents, particularly with langchain's agents, memory, and chain modules being a plus point. \n Thorough understanding/experience with functions API is required. \n Proficiency in Python, JavaScript, or similar. \n Understanding of AI, ML, and NLP. \n Excellent communication skills. \n \n \n \n \n  Desirables: \n \n \n Experience with Golang and Typescript. \n Experience with customer service platforms. \n Familiarity with legal documentation. \n Knowledge of LLM caching mechanisms. \n Creative problem-solving skills. \n Adaptability in a fast-paced environment. \n Capacity to consume new information directly from the source (papers, documentations etc.) as it's being published. \n \n \n \n \n  We Offer: \n \n \n Competitive salary and benefits. \n Opportunity to work with cutting-edge AI technology. \n Collaboratively innovating within a remote team environment.", "cleaned_desc": " Degree in Computer Science, AI, or a related field. \n Detailed understanding and experience with the in-context learning workflow (Data preprocessing / embedding -> Prompt construction / retrieval -> Prompt execution / inference). \n Familiarity with emerging prompting techniques (CoT, ToT, Zero/Few-shot prompting etc.). Active reading of new papers on prompting is highly desirable. \n Familiarity with building AI agents, particularly with langchain's agents, memory, and chain modules being a plus point. \n Thorough understanding/experience with functions API is required. \n Proficiency in Python, JavaScript, or similar. \n Understanding of AI, ML, and NLP. \n Excellent communication skills. \n   \n \n \n  Desirables: \n \n \n Experience with Golang and Typescript. \n Experience with customer service platforms. \n Familiarity with legal documentation. ", "techs": ["degree in computer science", "ai", "or a related field", "in-context learning workflow", "data preprocessing", "embedding", "prompt construction", "retrieval", "prompt execution", "inference", "emerging prompting techniques", "cot", "tot", "zero/few-shot prompting", "building ai agents", "langchain's agents", "memory", "chain modules", "functions api", "python", "javascript", "ai", "ml", "nlp", "golang", "typescript", "customer service platforms", "legal documentation"]}, "3ccbb3ca1d8da93e": {"terms": ["data science"], "salary_min": 92300.0, "salary_max": 103100.0, "title": "Director - Results Measurement", "company": "Habitat for Humanity", "desc": "Habitat for Humanity International (HFHI) is seeking an experienced professional to serve as the \n   Director, Results Measurment  for our Integrated Programs team. The Director, Results Measurement will \n   provide leadership to organizational wide efforts to measure and report the evidence of impact across all programmes and projects implemented by various entities in HFHI  including the development of the results measurement framework, the development and roll out of the platform and tools that will enable data acquisition and reporting. Reporting to the Sr. Director, MEAL, this position is responsible for \n   effective project management and strong stakeholder engagement in Habitat\u2019s Global Results framework.  \n \n \n This position is eligible to be remote or hybrid, based in countries which include, but are not limited to: Costa Rica; Belgium; Kenya; the Philippines; Slovakia; Switzerland; the United Kingdom; and the USA. There is up to 25% international travel. \n \n \n POSITION RESPONSIBILITIES: \n \n Development of the measurement frame 35 % of the time \n \n \n Provide leadership to and engage with stakeholders and subject matter experts coordinating overall organizational efforts to determine the appropriate indicators to measure as part of the results measurement framework.  \n Lead efforts to develop and maintain the indicator library for use across the programmes and projects in HFHI \n Lead the efforts in the development of tools and resources to guide the measurement of results across the portfolio. \n Collaborate with DART and IT to oversee the data pipeline and ensure that data management and processing including visualization are completed in accordance with industry standards.  \n \n Develop and roll out the platform for data acquisition and reporting on the results framework- 45 % of the time  \n \n \n Lead the efforts to articulate the needs of the business for result management platform in collaboration with the MEAL team and the advisory group. \n Develop with the IT and the vendor the project plans including timeline and resource allocation. Oversee the project\u2019s progress and ensure that business contributions are made on time as per the project roadmap and timeline. Manage project resources responsibly and establish accountability mechanisms that enable visibility and transparency in project management.  \n Prepare the advisory group for testing the platform and organize their feedback and share it with the vendor promptly.  \n Work closely with the IT counterpart to find creative solutions to issues and challenges that may be identified/faced during project implementation.  \n Prepare regular updates for the steering committee, keep track of issues such as progress, backlog, budget, risks and engage in time for problem solving and project adjustments.  \n Lead organizational efforts to scaling the use of the platform across HFHI \n \n  Develop a learning system for scaling up of the result measurement 20 % \n \n \n Lead efforts in developing learning assets and establish a learning system that will be used to educate the network on the results measurement frame, its indicators, tools, and guidance.  \n Develop in collaboration with IT and AOs a learning system that will enable the network to make effective use of the platform for results measurement.  \n Engage externally with other partner organizations to remain abreast of developments in the space of data science and use of technology in MEAL business processes and specifically on best practices related to impact reporting.  \n Develop a learning system for scaling up of the result measurement 20 %\n   \n \n Lead efforts in developing learning assets and establish a learning system that will be used to educate the network on the results measurement frame, its indicators, tools, and guidance.  \n Develop in collaboration with IT and AOs a learning system that will enable the network to make effective use of the platform for results measurement.  \n Engage externally with other partner organizations to remain abreast of developments in the space of data science and use of technology in MEAL business processes and specifically on best practices related to impact reporting.  \n \n \n DEADLINE: Submissions will be reviewing as received. Closing date for applications is October 20th. \n \n \n POSITION REQUIRMENTS: \n \n \n Bachelors degree in social sciences, development studies, data science, monitoring and evaluation \n 10 + years of experience in Monitoring, Evaluation, Accountability & Learning with at least 3 years of experience in shaping measurement tools and reporting platforms.  \n Excellent project management skills and an ability to work efficiently and prioritize effectively. \n Excellent written and verbal communication skills in English. \n Ability to earn trust and provide excellent service to different levels and functions within the organization, including facilitation and influencing skills to drive change. \n Excellent analytical and critical thinking skills. \n Active support of HFHI values and commitments: \n  Humility \u2013 We are part of something bigger than ourselves.\n    Courage \u2013 We do what\u2019s right, even when it is difficult or unpopular.\n    Accountability \u2013 We take personal responsibility for Habitat\u2019s mission.\n   \n \n The actual salary offered for this role will be based on a variety of factors, including location, internal equity and the candidate\u2019s qualifications and professional experience. HFHI offers a competitive, comprehensive benefits package that varies by country and typically includes vacation leave, sick leave, personal days, health insurance options, retirement plan contributions and life insurance. \n \n   \n \n For work locations in the US, the target hiring range for this position is $92,300-$103,100. The salary range for this position is between $87,000-$130,000 per year. \n \n \n Safeguarding - HFHI requires that all employees take seriously their ethical responsibilities to safeguarding our intended beneficiaries, their communities, and all those with whom we work. Managers at all levels have responsibilities to support and develop systems that create and maintain an environment that prevents harassment, sexual exploitation and abuse, safeguards the rights of beneficiaries and community. \n \n \n PREFERRED: \n \n \n Masters degree in Social Sciences, Data Science, Project Management, Monitoring and Evaluation  \n Prior knowledge and experience with measurement of impact and development of tools and platforms to facilitate such processes.  \n Experience with statistical packages and qualitative data analysis software \n Demonstrated ability to work effectively within a multi-cultural network \n Experience working in a federated network", "cleaned_desc": " Lead efforts to develop and maintain the indicator library for use across the programmes and projects in HFHI \n Lead the efforts in the development of tools and resources to guide the measurement of results across the portfolio. \n Collaborate with DART and IT to oversee the data pipeline and ensure that data management and processing including visualization are completed in accordance with industry standards.  \n \n Develop and roll out the platform for data acquisition and reporting on the results framework- 45 % of the time  \n \n \n Lead the efforts to articulate the needs of the business for result management platform in collaboration with the MEAL team and the advisory group. \n Develop with the IT and the vendor the project plans including timeline and resource allocation. Oversee the project\u2019s progress and ensure that business contributions are made on time as per the project roadmap and timeline. Manage project resources responsibly and establish accountability mechanisms that enable visibility and transparency in project management.  \n Prepare the advisory group for testing the platform and organize their feedback and share it with the vendor promptly.  \n Work closely with the IT counterpart to find creative solutions to issues and challenges that may be identified/faced during project implementation.  \n Prepare regular updates for the steering committee, keep track of issues such as progress, backlog, budget, risks and engage in time for problem solving and project adjustments.  \n Lead organizational efforts to scaling the use of the platform across HFHI \n \n  Develop a learning system for scaling up of the result measurement 20 %   \n POSITION REQUIRMENTS: \n \n \n Bachelors degree in social sciences, development studies, data science, monitoring and evaluation \n 10 + years of experience in Monitoring, Evaluation, Accountability & Learning with at least 3 years of experience in shaping measurement tools and reporting platforms.  \n Excellent project management skills and an ability to work efficiently and prioritize effectively. \n Excellent written and verbal communication skills in English. \n Ability to earn trust and provide excellent service to different levels and functions within the organization, including facilitation and influencing skills to drive change. \n Excellent analytical and critical thinking skills. \n Active support of HFHI values and commitments: \n  Humility \u2013 We are part of something bigger than ourselves.\n    Courage \u2013 We do what\u2019s right, even when it is difficult or unpopular.\n    Accountability \u2013 We take personal responsibility for Habitat\u2019s mission.\n   ", "techs": ["indicator library", "tools and resources", "data pipeline", "data management", "data processing", "visualization", "platform for data acquisition and reporting", "result management platform", "project plans", "timeline", "resource allocation", "project resources", "accountability mechanisms", "it counterpart", "steering committee", "learning system", "measurement tools", "reporting platforms", "project management skills", "written and verbal communication skills", "facilitation and influencing skills", "analytical and critical thinking skills"]}, "3a73ca32b337a391": {"terms": ["data science"], "salary_min": 159375.0, "salary_max": 215625.0, "title": "Senior Data Scientist, Product Analytics", "company": "Rec Room", "desc": "Rec Room is the best place to build and play games together. Chat, hang out, explore MILLIONS of rooms, or build something new to share with us all! As a Senior Product Data Scientist at Rec Room, you will be responsible for a large strategic area and will use data to be an advocate for our players. Your insights into what users are doing on the platform will inform broader team strategy and impact their short and long-term roadmap. You'll be equal parts leader, investigator, and storyteller, shaping experiences towards delighting players and building a sustainable business. \n  As we scale, Product Data Scientists will embed within individual teams, and as the Senior Product Data Scientist, you would be expected to drive product thinking at the broader team level and guide other data scientists as needed. You might be helping the econ team think through how to scale the buyer and builder ecosystem, or helping the growth team think through how to give users more reason to return to the app. You might also help the User Generated Content team think through how to enable creators to build the best products, or the Social team how to make a player's experience more meaningful. The questions and potential for impact are huge. \n  WHAT YOU'LL DO: \n \n Work closely with our designers and developers to understand what users are doing on the platform. Broadly communicate those findings to the immediate team and beyond. \n Define top-level business and team KPIs, establish learning agendas, measurement plans, and success metrics in close coordination with the product team. \n Work with teams to build a culture of goal setting and accountability. \n Drive changes to our product roadmap based on quantitative insights. \n Structure thoughtfully designed A/B tests and up-level broader team through rigorous understanding of test results. \n Contribute as needed to improve overall infrastructure - including building pipelines, data documentation, and dashboarding. \n Work with the ML team as needed to develop novel features and understand performance. \n \n WE ARE LOOKING FOR INDIVIDUALS WITH: \n \n 5+ years of product analytics experience, with a proven track record of deriving insights that lead to product changes \n A Bachelor's or Masters in Math, CS, or related field \n Significant expertise in experimentation methodologies \n Very strong knowledge of SQL \n Experience with Python or R is a plus \n Experience with manipulating and analyzing complex, high-volume data \n A constant desire to learn, improve, and help others improve \n Effective communicator with the ability to distill complex concepts into easily digestible insights \n \n \n \n   The base pay range for this position is listed below; please note the base pay may vary depending on location, job-related knowledge, skills, and experience. Stock options and, in some cases, a sign-on bonus may be offered as part of the compensation package. We also offer a full slate of benefits, including flexible vacation, medical, dental vision, life and disability coverage, long-term care insurance, FSA, commuter benefits, a 401(k) plan with company match, and a parental leave program. We also offer some not-so-standard benefits, including equipment, family, and pet care stipends.\n   \n  Base Pay Range \n \n    $159,375\u2014$215,625 USD\n   \n \n \n  COMPANY INFO TO KNOW: \n  Rec Room offers generous medical, dental, and vision plans that cover you, your spouse/domestic partner, and children. We also support your retirement benefits with a company match. Rec Room values work-life balance by providing unlimited paid time off. Our company values are real and drive our culture. We work hard to be a safe and friendly place for people from all walks of life.  \n Rec Room provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  Applicants who are in need of a reasonable accommodation for any part of the application process may contact, in confidence, accessibilityrequest.hr@recroom.com. Rec Room will work with each individual to define their application-related needs and to try to accommodate those needs. \n  Applicants can find our CCPA disclosure notice here.", "cleaned_desc": " 5+ years of product analytics experience, with a proven track record of deriving insights that lead to product changes \n A Bachelor's or Masters in Math, CS, or related field \n Significant expertise in experimentation methodologies \n Very strong knowledge of SQL \n Experience with Python or R is a plus \n Experience with manipulating and analyzing complex, high-volume data \n A constant desire to learn, improve, and help others improve ", "techs": ["sql", "python", "r"]}, "4752ecf0dae9b021": {"terms": ["data science"], "salary_min": 55000.0, "salary_max": 65000.0, "title": "Rule Operations Analyst", "company": "Revecore", "desc": "Job Title:\n      \n \n \n \n      Rule Operations Analyst\n      \n \n \n \n \n \n \n \n      Division:\n      \n \n \n \n      Revenue Integrity\n      \n \n \n \n      FLSA Status:\n      \n \n \n \n      Exempt\n      \n \n \n \n \n \n \n \n      Department:\n      \n \n \n \n      Research and Development\n      \n \n \n \n      Position Type:\n      \n \n \n \n      Full Time\n      \n \n \n \n \n \n \n \n      Reports To:\n      \n \n \n \n      Emily Brophy or Rule Operations Manager\n      \n \n \n \n \n \n \n \n      Reporting to this position:\n      \n \n \n \n      VP Research and Development or Rule Operations Manager\n      \n \n \n \n \n \n \n \n \n \n Position Summary \n \n \n \n  Rule Operation Analysts are rule owners and have responsibility for the accuracy and performance of their rule portfolio. They monitor the performance of rules, research underperforming rules, identify changes to optimize and improve effectiveness, and coordinate the execution of changes. They report results to operational leaders based on projected and realized results and interface with technical consultants to maximize accuracy. They also have the responsibility to identify broader applicability of rules and communicate with the appropriate leaders and other strategic partners. They have specific goals to maintain and improve performance of their rule portfolio.\n  \n \n \n \n \n \n Duties and Responsibilities \n \n \n \n Build strong, lasting relationships with R&D and other cross functional teams supporting Rule Operations. \n Engage with operational leaders to support their business through effective utilization of rules to maximize results. \n Manage portfolio of rules through analysis of EV and other data science outputs to identify improvements which will maximize results. \n Collaborate with other cross functional teams to understand changes to features and attributes that will improve results. \n Document rule improvements for underperforming and inaccurate rules based on EV projected and realized results. \n Communicate changes and recommendations to leaders and demonstrate the value of improvements. \n Execute recommendations through updates to rules and monitor outcomes. \n \n \n Attend and participate in department and other Revecore meetings. \n Comply with federal and state laws, company and department policies and procedures. \n All other duties as assigned \n \n \n \n \n \n Skills and Experience \n \n \n \n Bachelor\u2019s Degree in a Healthcare related field is preferred but not required. \n Advanced computer proficiency with MS Excel and other Microsoft products is preferred. \n Experience with SQL is helpful but not required. \n Ability to research and investigate related information using the internet, payor websites, and other industry related resources and tools. \n Strong problem-solving skills to understand data patterns that help define problems, provide data, establish facts and draw valid conclusions which lead to leading to productive outcomes. \n Strong critical thinking skills to Ability to read and interpret industry related documents contracts, claims, instructions, policies and procedures in written (in English) and diagram form \n Ability to present ideas on complex, detailed issues with ease \n Strong analytical, troubleshooting and problem resolution skills \n Strong communication skills, written and verbal \n Strong customer service orientation \n Excellent interpersonal and communication skills \n Strong team player \n Commitment to company values \n \n \n \n \n \n \n \n Physical Demands and Work Environment \n \n \n \n  The physical demands and work environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.\n  \n \n Physical Demands:  While performing the duties of this job, the employee is occasionally required to walk; sit; use hands to handle or feel objects, tools or controls; reach with hands and arms; balance; stoop; talk or hear. The employee must occasionally lift and/or move up to 15 pounds. Specific vision abilities required by the job include close vision, distance vision, color vision, peripheral vision, depth perception, and the ability to adjust focus. \n Work Environment:  While performing the duties of this job, the employee is exposed to weather conditions prevalent at the time. The noise level in the work environment is usually moderate. \n \n \n \n \n \n  The employee is expected to adhere to all company policies.\n  \n \n \n \n \n  I have read and understand this explanation and job description.\n  \n \n \n \n \n \n \n \n \n \n      Associate Signature", "cleaned_desc": " \n \n Build strong, lasting relationships with R&D and other cross functional teams supporting Rule Operations. \n Engage with operational leaders to support their business through effective utilization of rules to maximize results. \n Manage portfolio of rules through analysis of EV and other data science outputs to identify improvements which will maximize results. \n Collaborate with other cross functional teams to understand changes to features and attributes that will improve results. \n Document rule improvements for underperforming and inaccurate rules based on EV projected and realized results. \n Communicate changes and recommendations to leaders and demonstrate the value of improvements. \n Execute recommendations through updates to rules and monitor outcomes. \n \n \n Attend and participate in department and other Revecore meetings. \n Comply with federal and state laws, company and department policies and procedures. \n All other duties as assigned \n \n \n \n \n \n Skills and Experience \n \n \n \n Bachelor\u2019s Degree in a Healthcare related field is preferred but not required. \n Advanced computer proficiency with MS Excel and other Microsoft products is preferred. \n Experience with SQL is helpful but not required. \n Ability to research and investigate related information using the internet, payor websites, and other industry related resources and tools. \n Strong problem-solving skills to understand data patterns that help define problems, provide data, establish facts and draw valid conclusions which lead to leading to productive outcomes. \n Strong critical thinking skills to Ability to read and interpret industry related documents contracts, claims, instructions, policies and procedures in written (in English) and diagram form \n Ability to present ideas on complex, detailed issues with ease \n Strong analytical, troubleshooting and problem resolution skills \n Strong communication skills, written and verbal \n Strong customer service orientation \n Excellent interpersonal and communication skills \n Strong team player ", "techs": ["r&d", "ev", "data science", "ms excel", "microsoft products", "sql"]}, "0e49b83eaaf6cc00": {"terms": ["data science"], "salary_min": 130000.0, "salary_max": 160000.0, "title": "Senior Data Scientist", "company": "Angi", "desc": "Angi\u00ae is transforming the home services industry, creating an environment for homeowners, service professionals and employees to feel right at \"home.\" For most home maintenance needs, our platform makes it easier than ever to find a qualified service professional for indoor and outdoor jobs, home renovations (or anything in between!). We are on a mission to become the home for everything home by helping small businesses thrive and providing solutions to financing and booking home jobs with just a few clicks. \n  Over the last 25 years we have opened our doors to a network of over 200K service professionals and helped over 150 million homeowners love where they live. We believe home is the most important place on earth and are embarking on a journey to redefine how people care for their homes. Angi is an amazing place to build your dream career, join us\u2014we cannot wait to welcome you home!  \n \n About the team \n  Our Applied Data Science team is tackling challenges such as homeowner-contractor matching, forecasting key business metrics, and using predictive models to optimize consumer experience. This role will give you the opportunity to use state-of-the-art machine learning techniques and open-source big data processing tools. \n  What you'll do \n \n Create mathematical and data driven solutions for difficult problems at scale \n Work with Data Science leadership to develop team roadmaps \n Develop, maintain, and monitor the performance of production quality code \n Become the domain expert for one business segment in the Angi organization \n Communicate project results and insights with stakeholders across Angi \n Provide mentorship to team members \n \n Who you are \n \n 5+ years of experience performing quantitative analysis, predictive analytics, mathematical modeling and/or machine learning \n Master's degree or PhD in Statistics, Applied Mathematics or similar quantitative field is highly preferred \n Demonstrating creative problem solving skills to inform decisions, improve outcomes, and deliver transformation through data \n Developing predictive models and analysis using R and/or Python \n Interacting with data using SQL \n Deep knowledge of machine learning and data mining algorithms \n Experience deploying machine learning models and projects to a production environment at scale \n Bonus points if you've worked with ML frameworks like Sagemaker \n \n We value diversity \n  We know that the best ideas come from teams where diverse points of view uncover new solutions to hard problems. We welcome and value individuals who bring diverse life experiences, educational backgrounds, cultures, and work experiences. \n  Compensation & Benefits \n \n The salary band for this position ranges   $130,000 - $160,000 commensurate with experience and performance. Compensation may vary based on factors such as cost of living. \n This position will be eligible for a competitive year end performance bonus & equity package. \n Full medical, dental, vision package to fit your needs \n Flexible vacation policy; work hard and take time when you need it \n Pet discount plans & retirement plan with company match (401K) \n The rare opportunity to work with sharp, motivated teammates solving some of the most unique challenges and changing the world \n \n #LI-Remote", "cleaned_desc": " Who you are \n \n 5+ years of experience performing quantitative analysis, predictive analytics, mathematical modeling and/or machine learning \n Master's degree or PhD in Statistics, Applied Mathematics or similar quantitative field is highly preferred \n Demonstrating creative problem solving skills to inform decisions, improve outcomes, and deliver transformation through data \n Developing predictive models and analysis using R and/or Python \n Interacting with data using SQL ", "techs": ["r", "python", "sql"]}, "1bef740765e4b61a": {"terms": ["data science", "data analyst"], "salary_min": 92500.0, "salary_max": 99000.0, "title": "Financial Analyst, Supply Chain and Merchandise Finance", "company": "Stitch Fix", "desc": "We\u2019re a team of bright, kind individuals who are motivated by challenge and who care deeply about achieving great things. We know our individual strengths, but believe we only win as a team. We\u2019re transforming the way people find what they love - and we need your big ideas. We just might be the perfect fit. \n \n \n \n  ABOUT THE TEAM\n  \n \n   The Stitch Fix Finance team enables our clients to be their best self. We broadly define our clients as customers, business partners, and shareholders. We drive value through business partner support, innovative and insightful analysis, and financial integrity. We are looking for bright, kind individuals who are motivated by challenge and who succeed in a fast-paced environment and thrive in building and improving processes to scale the business to the next level.\n  \n \n   ABOUT THE ROLE\n  \n \n   The FINANCIAL ANALYST will serve as an integral FP&A business partner to our internal organizations across several verticals. You will build and refresh reports, forecasts and financial models to support a wide range of financial planning and analysis for the Supply Chain Finance team which includes Merchandise Finance & Operations Finance. You will serve as a finance business partner to our merchandise planning and variable labor and expense organizations to support activities related to forecasting cost of goods sold, fulfillment-related costs down to contribution profit, operating expenses and capex. You will be empowered with visibility to the entire organization, which provides a unique opportunity to develop insights that will meaningfully impact our business. The successful candidate will be a team player who possesses strong analytical skills, a well-rounded understanding of financial statements, and enjoys solving complex business problems.\n  \n \n   YOU'RE EXCITED ABOUT THIS OPPORTUNITY BECAUSE YOU WILL\u2026\n  \n \n \n   Develop and work in close partnerships within finance and across the business to develop annual, quarterly and monthly budgets and forecasts including but not limited to merchandise margin, inventory, and opex\n   \n \n   Manage and track financial performance against annual budget, seasonal financial plans, and KPIs\n   \n \n   Analyze variances to plan and forecast, providing insight on current and expected trends, and identifying areas of risk and opportunities\n   \n \n   Participate in cross-functional projects and lead process improvement efforts, including dashboard and reporting enhancements\n   \n \n   Prepare monthly financial review presentations, recapping results vs. plan and forecast for management meetings\n   \n \n   Drive ad-hoc analysis and scenario modeling to aid in decision-making\n   \n \n   Evolve tools, enhance existing reporting, and improve business processes in partnership with Finance and the business\n   \n \n   Identify and quantify risk or upside due to business environment to offer solutions and aid in decision-making\n   \n \n   Assist with conducting ad hoc analysis and scenario modeling at the request of the finance team, management and business partners to aid in decision-making\n   \n \n   Own communications of shared calendars for forecast deadlines/dates for supply chain\n   \n \n \n  WE\u2019RE EXCITED ABOUT YOU BECAUSE\u2026\n  \n \n \n   You have a Bachelor\u2019s degree and 1 to 3 years of financial analysis, retail finance, merchandise planning, inventory planning or accounting experience with exposure to forecasting, budgeting and monthly close activities\n   \n \n   You have superior Excel skills, including basic financial modeling, and have experience creating effective presentation slide decks\n   \n \n   You possess strong analytical, troubleshooting, problem-solving, and project management skills\n   \n \n   You\u2019re able to identify opportunities for business improvement and take initiative to drive necessary changes\n   \n \n   You have exceptional communication and interpersonal skills with proven success partnering and collaborating across a wide spectrum of functions\n   \n \n   You work well in a demanding, fast-paced environment and can manage competing priorities\n   \n \n   You\u2019re highly self-motivated, you have a stellar work ethic and you\u2019re looking for the right company to support your growth potential\n   \n \n   You have experience with Anaplan, Essbase, and/or similar planning and reporting tools\n   \n \n \n  WHY YOU'LL LOVE WORKING AT STITCH FIX...\n  \n \n \n   We are a group of bright, kind people who are motivated by challenge. We value integrity, innovation and trust. You\u2019ll bring these characteristics to life in everything you do at Stitch Fix.\n   \n \n   We cultivate a community of diverse perspectives\u2014 all voices are heard and valued.\n   \n \n   We are an innovative company and leverage our strengths in fashion and tech to disrupt the future of retail.\n   \n \n   We win as a team, commit to our work, and celebrate grit together because we value strong relationships.\n   \n \n   We boldly create the future while keeping equity and sustainability at the center of all that we do.\n   \n \n   We are the owners of our work and are energized by solving problems through a growth mindset lens. We think broadly and creatively through every situation to create meaningful impact.\n   \n \n   We offer comprehensive compensation packages and inclusive health and wellness benefits.\n   \n \n \n  ABOUT STITCH FIX\n  \n \n   We're changing the industry and bringing personal styling to every body. We believe in a service and a workplace where you can show up as your best, most authentic self. The Stitch Fix experience is not merely curated\u2014it\u2019s truly personalized to each client we style. We are changing the way people find what they love. We\u2019re disrupting the future of retail with the precision of data science by combining it with human instinct to find pieces that fit our client\u2019s unique style. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. This results in a simple, yet powerful offering to our customers and a successful, growing business serving millions of men, women and kids throughout the US and UK. We believe we are only scratching the surface and are looking for incredible people like you to help us boldly create our future.\n  \n \n \n \n    COMPENSATION AND BENEFITS\n     \n  Our anticipated compensation reflects the cost of labor across several US geographic markets, and the range below indicates the low end of the lowest-compensated market to the high end of the highest-compensated market. This position is eligible for new hire and ongoing grants of restricted stock units depending on employee and company performance. In addition, the position is eligible for medical, dental, vision, and other benefits. Applicants should apply via our internal or external careers site.\n    \n  Salary Range \n \n     $92,500\u2014$99,000 USD\n    \n \n \n \n \n   This link leads to the machine readable files that are made available in response to the federal Transparency in Coverage Rule and includes negotiated service rates and out-of-network allowed amounts between health plans and healthcare providers. The machine-readable files are formatted to allow researchers, regulators, and application developers to more easily access and analyze data.\n   \n \n    Please review Stitch Fix's US Applicant Privacy Policy and Notice at Collection here: https://stitchfix.com/careers/workforce-applicant-privacy-policy\n   \n \n    RECRUITING FRAUD ALERT:\n   \n \n    To all candidates: your personal information and online safety are top of mind for us. At Stitch Fix, recruiters only direct candidates to apply through our official career pages at https://www.stitchfix.com/careers/jobs or https://web.fountain.com/c/stitch-fix.\n   \n \n    Recruiters will never request payments, ask for financial account information or sensitive information like social security numbers. If you are unsure if a message is from Stitch Fix, please email RecruitingOperations@stitchfix.com.\n   \n \n    You can read more about Recruiting Scam Awareness on our FAQ page here: https://support.stitchfix.com/hc/en-us/articles/1500007169402-Recruiting-Scam-Awareness", "cleaned_desc": "", "techs": ""}, "24b41ba1560125be": {"terms": ["data science"], "salary_min": 130000.0, "salary_max": 160000.0, "title": "Senior Data Scientist", "company": "Angi", "desc": "Angi\u00ae is transforming the home services industry, creating an environment for homeowners, service professionals and employees to feel right at \"home.\" For most home maintenance needs, our platform makes it easier than ever to find a qualified service professional for indoor and outdoor jobs, home renovations (or anything in between!). We are on a mission to become the home for everything home by helping small businesses thrive and providing solutions to financing and booking home jobs with just a few clicks. \n  Over the last 25 years we have opened our doors to a network of over 200K service professionals and helped over 150 million homeowners love where they live. We believe home is the most important place on earth and are embarking on a journey to redefine how people care for their homes. Angi is an amazing place to build your dream career, join us\u2014we cannot wait to welcome you home!  \n \n About the team \n  Our Applied Data Science team is tackling challenges such as homeowner-contractor matching, forecasting key business metrics, and using predictive models to optimize consumer experience. This role will give you the opportunity to use state-of-the-art machine learning techniques and open-source big data processing tools. \n  What you'll do \n \n Create mathematical and data driven solutions for difficult problems at scale \n Work with Data Science leadership to develop team roadmaps \n Develop, maintain, and monitor the performance of production quality code \n Become the domain expert for one business segment in the Angi organization \n Communicate project results and insights with stakeholders across Angi \n Provide mentorship to team members \n \n Who you are \n \n 5+ years of experience performing quantitative analysis, predictive analytics, mathematical modeling and/or machine learning \n Master's degree or PhD in Statistics, Applied Mathematics or similar quantitative field is highly preferred \n Demonstrating creative problem solving skills to inform decisions, improve outcomes, and deliver transformation through data \n Developing predictive models and analysis using R and/or Python \n Interacting with data using SQL \n Deep knowledge of machine learning and data mining algorithms \n Experience deploying machine learning models and projects to a production environment at scale \n Bonus points if you've worked with ML frameworks like Sagemaker \n \n We value diversity \n  We know that the best ideas come from teams where diverse points of view uncover new solutions to hard problems. We welcome and value individuals who bring diverse life experiences, educational backgrounds, cultures, and work experiences. \n  Compensation & Benefits \n \n The salary band for this position ranges   $130,000 - $160,000 commensurate with experience and performance. Compensation may vary based on factors such as cost of living. \n This position will be eligible for a competitive year end performance bonus & equity package. \n Full medical, dental, vision package to fit your needs \n Flexible vacation policy; work hard and take time when you need it \n Pet discount plans & retirement plan with company match (401K) \n The rare opportunity to work with sharp, motivated teammates solving some of the most unique challenges and changing the world \n \n #LI-Remote", "cleaned_desc": " Who you are \n \n 5+ years of experience performing quantitative analysis, predictive analytics, mathematical modeling and/or machine learning \n Master's degree or PhD in Statistics, Applied Mathematics or similar quantitative field is highly preferred \n Demonstrating creative problem solving skills to inform decisions, improve outcomes, and deliver transformation through data \n Developing predictive models and analysis using R and/or Python \n Interacting with data using SQL ", "techs": ["r", "python", "sql"]}, "cdcb42b5fd1cd1d7": {"terms": ["data science"], "salary_min": 120000.0, "salary_max": 130000.0, "title": "ServiceNow Solutions Engineer / Business Solution Analyst", "company": "Kanini Software Solutions", "desc": "About Kanini \n Kanini provides Agile Software Development, Cloud Computing, Data Science, and Location Intelligence services to public and private organizations. We have successfully served our clients in government, finance, transportation, utility, and software industries since 2003. \n Why you should join \n Working at Kanini is flexible and personal. We are a highly motivated, collaborative team experimenting with the latest technologies. We are committed to everyone having a healthy work/life balance, and we provide extensive mentorship and training resources to help you succeed. \n Kanini is looking for a  ServiceNow Solution Service Engineer /    Business Solutions Analyst  who has a deep experience in ServiceNow Solutions Engineering, User Stories. \n Key Responsibilities \n \n ServiceNow Solution Engineering: \n \n \n Design, configure, and customize ServiceNow applications to meet business requirements. \n \n \n Collaborate with stakeholders to gather and document functional and technical requirements. \n \n \n Develop and maintain ServiceNow workflows, scripts, and integrations. \n \n \n Perform system testing and ensure the quality of ServiceNow solutions. \n \n Business Systems Analysis \n \n Analyze existing business processes and systems to identify areas for improvement. \n \n \n Work closely with business stakeholders to understand their needs and translate them into technical solutions. \n \n \n Create detailed documentation, including user stories, process diagrams, and system specifications. \n \n Qualifications \n \n Bachelor\u2019s degree in computer science, Information Technology, or a related field. \n \n \n Proven experience as a ServiceNow Solution Engineer or Business Systems Analyst. \n \n \n ServiceNow certification (e.g., Certified System Administrator, Certified Implementation Specialist) is a plus. \n \n \n Strong analytical and problem-solving skills. \n \n \n Excellent communication and interpersonal skills. \n \n \n Project management experience is desirable. \n \n \n Knowledge of ITIL principles and practices is a plus. \n \n Kanini Software Solutions, Inc. does not discriminate in employment matters based on race, gender, religion, age, national origin, citizenship, veteran status, family status, disability status, or any other protected class. We support workplace diversity. If you have a disability, please let us know if there is anything we can do to improve the interview process for you; we\u2019re happy to accommodate. \n Kanini Software Solutions, Inc., 25 Century Blvd., Ste. 602, Nashville, TN 37214 \n Job Type: Full-time \n Pay: $120,000.00 - $130,000.00 per year \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "28d0c9b733eb941d": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 230000.0, "title": "Data Ecosystem Lead", "company": "Bayer", "desc": "At Climate, our mission is to use technologies to enhance the sustainability and security of our global food value chain. Using field-verified data science models, Climate is shaping the future of sustainable agriculture across 180 million acres worldwide and counting. As the digital farming arm of Bayer Crop Science, we have the benefits and resources of an established organization while offering employees the opportunity to deliver significant individual impact alongside some of the brightest minds in life sciences. \n  Grounded in our vision, \u2018Health for all, Hunger for none\u2019, our diverse team spends their days solving the world's most pressing challenges through sheer curiosity and dedication. In our learning-oriented and flexible environment, you can find us collaborating in a hybrid model that mixes on-site and remote work. \n  Our LIFE values\u2014leadership, integrity, flexibility, and efficiency\u2014and our unique focus on health and nutrition demand that we create value for all stakeholders\u2014today, tomorrow, and for generations to come. If you\u2019re hungry to build a meaningful career helping empower farmers with sustainable digital farming systems, keep reading! \n  The Opportunity:    Climate is modernizing the agriculture industry with a platform and products that help the world\u2019s farmers sustainably increase productivity with digital tools. We collect, process, and analyze vast amounts of agronomic data using our Fieldview Platform and suite of applications and connected devices to help our growers realize the full potential of their farmable land. \n  As the Lead of Data Ecosystem, you will guide the integration and architecture of data within Bayer\u2019s Digital Farming Solutions (DFS) division into a larger Bayer Enterprise data warehouse and support the enablement of data tooling solutions for its customers to leverage the data for R&D purposes. You will be accountable for collaborating with stakeholders in engineering, business, science and across Bayer R&D functions to define a technical roadmap, design, and then assist/oversee the execution and implementation of the technical strategy. \n  What You'll Do: \n \n  Lead the execution of Data Ecosystem strategy within DFS, socialize across the broader Bayer organization, serve as main point of contact for all Data Ecosystem projects within DFS. \n  Partner with technical and science peers across the broader Bayer Enterprise, as well as with 3rd parties, to facilitate the coordinated adoption of a streamlined, consistent data ecosystem from research to production, capitalizing on capabilities of cloud platforms to serve data solutions across multiple business programs. \n  Partner with Engineering and Science stakeholders to guide technical direction and architectural evolution of the integration with Bayer\u2019s data warehouse. \n  Own project management for the unit by collaborating with stakeholders across the organization to understand project requirements and priorities, monitor project progress and performance, and provide regular updates to executive stakeholders. \n  Drive operational excellence and perform governance for the technical execution to ensure that DFS data ecosystem is enabled by high quality, sustainable technology systems and teach others to do the same. \n  Partner closely with Data Governance and Security teams on the implementation of Data ecosystem projects. \n  Represent requirements, resource & budgeting needs and project status for Data Ecosystem platforms and pipelines in executive steering committee meetings and own the communication across of the implementation functions in DFS. \n  Enable DFS data stakeholders to access and leverage tools to interact with data ranging from on farm collected precision agriculture data to remote sensed satellite imagery. \n \n  About You: \n  What You\u2019ll Need: \n \n  Master's degree in science, engineering or related technical field \n  10+ years of experience working as data scientist or software engineer, deriving insights from a wide range of research data \n  Excellent communication skills, the ability to work collaboratively with cross-functional teams, and a proven track record of successful project delivery \n  Solid knowledge of software development methodologies, technical project management and best practices \n  Experience working with AWS and/or GCP and/or Azure cloud platforms \n  Experience designing, building or working with scalable backend services and with relational and non-relational databases and persistence stores \n \n  Nice to Haves: \n \n  PhD in science, engineering or related technical field \n  At least 10 years relevant work experience, with expertise in managing data pipelines, data storage systems, and data processing technologies, preferred in deployment of large cloud-based distributed environments and/or data science modeling platforms \n  Experience with master reference data/management system \n  Experience working with data governance and data quality programs \n \n  What We Offer: \n \n  Base salary estimated range between $160-230k annually, depending on the hiring location. You may also be offered bonuses, RSUs cash equivalent, or commission. \n  Comprehensive health benefits including medical, dental, vision, life, and disability, as well as a Life Solutions Plan covering mental health benefits \n  Industry leading 401K match of up to 10% \n  Discounted access to Employee Share Purchase Plan program \n  Professional growth opportunities including up to $10,000 college tuition reimbursement, access to upskilling platform, leadership training, mentoring and coaching programs, and short-term assignments (domestic and international) \n \n  Belonging and Accommodations: \n  At Climate, we strive to create inclusive experiences for candidates and employees alike in which a diverse set of perspectives and voices are represented. If this role sounds exciting to you but your experience doesn\u2019t perfectly align with the job description, we still encourage you to apply. \n  We\u2019re proud to be an equal opportunity employer. This means we actively pursue ways to celebrate our differences and don\u2019t discriminate based on race, religion, color, national origin, ethnicity, gender, sex (including pregnancy), protected veteran status, age, disability, sexual orientation, gender identity, gender expression, or any unlawful criterion existing under applicable federal, state, or local laws. \n  If you need assistance or an accommodation due to a disability, contact us at accommodations@climate.com. \n  Learn more about our team and mission: https://climate.com/careers    #LI-BD1", "cleaned_desc": "  Partner with Engineering and Science stakeholders to guide technical direction and architectural evolution of the integration with Bayer\u2019s data warehouse. \n  Own project management for the unit by collaborating with stakeholders across the organization to understand project requirements and priorities, monitor project progress and performance, and provide regular updates to executive stakeholders. \n  Drive operational excellence and perform governance for the technical execution to ensure that DFS data ecosystem is enabled by high quality, sustainable technology systems and teach others to do the same. \n  Partner closely with Data Governance and Security teams on the implementation of Data ecosystem projects. \n  Represent requirements, resource & budgeting needs and project status for Data Ecosystem platforms and pipelines in executive steering committee meetings and own the communication across of the implementation functions in DFS. \n  Enable DFS data stakeholders to access and leverage tools to interact with data ranging from on farm collected precision agriculture data to remote sensed satellite imagery. \n \n  About You: \n  What You\u2019ll Need:   \n  Master's degree in science, engineering or related technical field \n  10+ years of experience working as data scientist or software engineer, deriving insights from a wide range of research data \n  Excellent communication skills, the ability to work collaboratively with cross-functional teams, and a proven track record of successful project delivery \n  Solid knowledge of software development methodologies, technical project management and best practices \n  Experience working with AWS and/or GCP and/or Azure cloud platforms \n  Experience designing, building or working with scalable backend services and with relational and non-relational databases and persistence stores \n \n  Nice to Haves:   \n  PhD in science, engineering or related technical field \n  At least 10 years relevant work experience, with expertise in managing data pipelines, data storage systems, and data processing technologies, preferred in deployment of large cloud-based distributed environments and/or data science modeling platforms \n  Experience with master reference data/management system \n  Experience working with data governance and data quality programs \n \n  What We Offer: \n \n  Base salary estimated range between $160-230k annually, depending on the hiring location. You may also be offered bonuses, RSUs cash equivalent, or commission. ", "techs": ["aws", "gcp", "azure", "databases", "persistence stores", "data pipelines", "data storage systems", "data processing technologies", "cloud-based distributed environments", "data science modeling platforms"]}, "0440f4446c17a0eb": {"terms": ["data science"], "salary_min": 80000.0, "salary_max": 90000.0, "title": "Data Scientist", "company": "Praxis Precision Medicines", "desc": "Data Scientist \n  Location:  This position may be performed remotely with travel to the Boston area as needed.  \n Note to Applicants:  Please provide samples of your work, either via link or attachment with your application. \n  Position Summary \n  We are in search of a passionate Data Scientist who excels at transforming raw data into valuable insights. The ideal candidate is proficient in R, Python, PowerBI, SQL, and possesses knowledge of statistical methods and machine learning. You should have a deep understanding of analyzing datasets of various sizes and be skilled at presenting data in a manner that is accessible to diverse audiences. As a part of our agile team, you will not only be diving into multiple domains but will also play a pivotal role in shaping our data-driven strategies. Prior experience in a cross-functional team is a plus. If you are someone who loves challenges, can handle multiple projects, and aims to make a significant impact, then you might be the fit we are looking for! \n \n  Primary Responsibilities \n \n  Analyze, interpret, and visualize data across multiple domains to generate actionable insights. \n  Provide expertise on both small and large dataset analysis, ensuring accuracy and relevance of the findings. \n  Collaborate with different departments to understand their data needs and deliver tailored solutions. \n  Develop and maintain dashboards using PowerBI, ensuring they are user-friendly, updated, and provide real-time insights. \n  Apply statistical methods and machine learning techniques to extract deeper insights from data. \n  Work within multiple small teams, ensuring smooth communication, understanding of project requirements, and timely delivery. \n  Offer recommendations based on data analysis that can drive company strategy and decision-making. \n  Participate in regular team meetings, presenting findings and updates on ongoing projects. \n \n \n  Qualifications and Key Success Factors \n \n  Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics or a related field. \n  Experience in a data science role or related position. \n  Proficiency in R, Python, PowerBI, SQL, and knowledge of statistical methods and machine learning. \n  Demonstrated experience in analyzing and visualizing both small and large datasets. \n  Ability to work in multiple domains and adapt to changing requirements. \n  A proactive approach to problem-solving and a keen eye for details. \n  Prior experience with patient level data is a plus. \n \n  Compensation & Benefits \n  At Praxis, we\u2019re proud to offer an exceptional benefits package that includes: \n \n \n  99% premium cost covered for medical (Blue Cross Blue Shield), dental, and vision plans \n  Bonus program structured to pay on a quarterly basis \n  401k plan with 100% match up to 6% of employee\u2019s contribution (Traditional & Roth) \n  Wellness benefit of $200/month towards incredibly flexible options including travel, fitness equipment & memberships, student loan repayment, sports fees and much more \n  Unlimited PTO, (2) weeklong shutdowns each year, and a generous extended family leave benefit \n  Eligibility for equity awards and Employee Stock Purchase Plan (15% discount) \n \n \n  To round out this world-class total rewards package, we provide base salary compensation in the range of $80,000 to $90,000 annualized. Final salary range may be modified commensurate with job level, education, and experience. \n \n  Company Overview \n  Praxis Precision Medicines is a clinical-stage biopharmaceutical company translating genetic insights into the development of therapies for central nervous system disorders characterized by neuronal imbalance. At Praxis we share a common vision of reshaping the human condition into a more freeing and fulfilled existence by developing high impact medicines for patients and families affected by and living with complex brain disorders. Our core Values of  Trust ,  Ownership ,  Curiosity  and  Results  are foundational to every aspect of our business and are exemplified by each and every one of our team members. \n  Additional Requirement \n  To safeguard the health of our employees and their families, our partners and visitors, and our communities, Praxis requires that all employees be up to date on their COVID-19 vaccinations, including CDC recommended booster shots. Employees must provide proof of such vaccinations before beginning employment, except where prohibited by law. Requests for exemption will be considered and Praxis will provide reasonable accommodations unless doing so would pose an undue hardship. \n \n  Diversity, Equity & Inclusion \n  Guided by our core values, at Praxis Precision Medicines, Inc. we continue to DARE FOR MORE\u2122 to advance, promote, and champion diversity, equity, and inclusion by encouraging individuals to bring their authentic selves and perspectives to work each day. We are an equal opportunity employer and committed to providing opportunities to all qualified applicants without regard to race, religious creed, color, gender identity or expression, age, national origin, sexual orientation, disability, genetics, military service and veteran status, or any other characteristic protected by federal, state, or local laws. \n   \n Attention: Job Scam Alert  Praxis has recently become aware of fraudulent job recruitment postings from individuals claiming to represent Praxis. These postings seek financial information in connection with fraudulent opportunities for employment. If you suspect any fraudulent activity or misrepresentation in connection with a Praxis job opportunity, please report it to careers@praxismedicines.com.", "cleaned_desc": "  Bachelor's or Master's degree in Data Science, Computer Science, Statistics, Mathematics or a related field. \n  Experience in a data science role or related position. \n  Proficiency in R, Python, PowerBI, SQL, and knowledge of statistical methods and machine learning. \n  Demonstrated experience in analyzing and visualizing both small and large datasets. \n  Ability to work in multiple domains and adapt to changing requirements. \n  A proactive approach to problem-solving and a keen eye for details. \n  Prior experience with patient level data is a plus. \n \n  Compensation & Benefits \n  At Praxis, we\u2019re proud to offer an exceptional benefits package that includes: ", "techs": ["r", "python", "powerbi", "sql"]}, "a2d43b43453a6036": {"terms": ["data science"], "salary_min": 130000.0, "salary_max": 160000.0, "title": "Senior Data Scientist", "company": "Angi", "desc": "Angi\u00ae is transforming the home services industry, creating an environment for homeowners, service professionals and employees to feel right at \"home.\" For most home maintenance needs, our platform makes it easier than ever to find a qualified service professional for indoor and outdoor jobs, home renovations (or anything in between!). We are on a mission to become the home for everything home by helping small businesses thrive and providing solutions to financing and booking home jobs with just a few clicks. \n  Over the last 25 years we have opened our doors to a network of over 200K service professionals and helped over 150 million homeowners love where they live. We believe home is the most important place on earth and are embarking on a journey to redefine how people care for their homes. Angi is an amazing place to build your dream career, join us\u2014we cannot wait to welcome you home!  \n \n About the team \n  Our Applied Data Science team is tackling challenges such as homeowner-contractor matching, forecasting key business metrics, and using predictive models to optimize consumer experience. This role will give you the opportunity to use state-of-the-art machine learning techniques and open-source big data processing tools. \n  What you'll do \n \n Create mathematical and data driven solutions for difficult problems at scale \n Work with Data Science leadership to develop team roadmaps \n Develop, maintain, and monitor the performance of production quality code \n Become the domain expert for one business segment in the Angi organization \n Communicate project results and insights with stakeholders across Angi \n Provide mentorship to team members \n \n Who you are \n \n 5+ years of experience performing quantitative analysis, predictive analytics, mathematical modeling and/or machine learning \n Master's degree or PhD in Statistics, Applied Mathematics or similar quantitative field is highly preferred \n Demonstrating creative problem solving skills to inform decisions, improve outcomes, and deliver transformation through data \n Developing predictive models and analysis using R and/or Python \n Interacting with data using SQL \n Deep knowledge of machine learning and data mining algorithms \n Experience deploying machine learning models and projects to a production environment at scale \n Bonus points if you've worked with ML frameworks like Sagemaker \n \n We value diversity \n  We know that the best ideas come from teams where diverse points of view uncover new solutions to hard problems. We welcome and value individuals who bring diverse life experiences, educational backgrounds, cultures, and work experiences. \n  Compensation & Benefits \n \n The salary band for this position ranges   $130,000 - $160,000 commensurate with experience and performance. Compensation may vary based on factors such as cost of living. \n This position will be eligible for a competitive year end performance bonus & equity package. \n Full medical, dental, vision package to fit your needs \n Flexible vacation policy; work hard and take time when you need it \n Pet discount plans & retirement plan with company match (401K) \n The rare opportunity to work with sharp, motivated teammates solving some of the most unique challenges and changing the world \n \n #LI-Remote", "cleaned_desc": " Who you are \n \n 5+ years of experience performing quantitative analysis, predictive analytics, mathematical modeling and/or machine learning \n Master's degree or PhD in Statistics, Applied Mathematics or similar quantitative field is highly preferred \n Demonstrating creative problem solving skills to inform decisions, improve outcomes, and deliver transformation through data \n Developing predictive models and analysis using R and/or Python \n Interacting with data using SQL ", "techs": ["r", "python", "sql"]}, "72db8660a2a145d9": {"terms": ["data science"], "salary_min": 178538.0, "salary_max": 218213.0, "title": "Senior Data Scientist, Machine Learning", "company": "Rec Room", "desc": "Rec Room is the best place to build and play games together. Players can chat, hang out, play in millions of rooms, or build something new to share with the world! We have a vibrant commercial ecosystem within Rec Room, and our goal is to enable creators to be rewarded for their work. Come join us on the ground floor to help optimize the ecosystem for both players and the business. \n  As a Senior Machine Learning Data Scientist, you'll be responsible for designing, developing, and implementing machine learning models to power our in-game store recommendations and serve users content that they'd find valuable. You'll be supporting creators in making a living on the platform, as well as playing a critical role in the success of Rec Room as a business. \n  WHAT YOU'LL DO: \n \n Design, develop and implement production-facing ML models to deliver valuable commerce content to our users. \n Collaborate closely with the ML Infra team to define a roadmap that powers real-time personalized ranking models. \n Design and run A/B tests, analyze model performance, and deep dive into the data to uncover opportunities for improvements. \n Build out pipelines in collaboration with our Analytics Engineering team to enable model building on top of sophisticated features. \n Set best practices, mentor, and provide guidance to the more junior Data Scientists. \n \n WE ARE LOOKING FOR INDIVIDUALS WITH: \n \n Master's or Ph.D. degree in computer science, statistics, mathematics, or a related field \n 7+ years of ML experience in a production setting, with extensive experience working on ranking/recommendations \n Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n \n \n \n   The base pay range for this position is listed below; please note the base pay may vary depending on location, job-related knowledge, skills, and experience. Stock options and, in some cases, a sign-on bonus may be offered as part of the compensation package. We also offer a full slate of benefits, including flexible vacation, medical, dental vision, life and disability coverage, long-term care insurance, FSA, commuter benefits, a 401(k) plan with company match, and a parental leave program. We also offer some not-so-standard benefits, including equipment, family, and pet care stipends.\n   \n  Base Pay Range \n \n    $178,538\u2014$218,213 USD\n   \n \n \n  COMPANY INFO TO KNOW: \n  Rec Room offers generous medical, dental, and vision plans that cover you, your spouse/domestic partner, and children. We also support your retirement benefits with a company match. Rec Room values work-life balance by providing unlimited paid time off. Our company values are real and drive our culture. We work hard to be a safe and friendly place for people from all walks of life.  \n Rec Room provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  Applicants who are in need of a reasonable accommodation for any part of the application process may contact, in confidence, accessibilityrequest.hr@recroom.com. Rec Room will work with each individual to define their application-related needs and to try to accommodate those needs. \n  Applicants can find our CCPA disclosure notice here.", "cleaned_desc": " Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n ", "techs": ["recommendations", "ranking", "personalization", "search", "content discovery", "python", "sql", "ml infrastructure", "experimentation", "dbt", "spark", "databricks"]}, "36e472297271849a": {"terms": ["data science", "machine learning engineer"], "salary_min": 100388.78, "salary_max": 127114.56, "title": "Data Scientist", "company": "KBR", "desc": "Title:  Data Scientist\n  \n \n  KBR is seeking a  Data Scientist ( Junior )   to join The Advanced Analytics and Cloud Program team. The cloud analytics program supports government customers within the Department of Defense (DoD) on various projects to develop solutions incorporating technologies such as machine learning, artificial intelligence (ML/AI), robotic process automation (RPA) and cloud infrastructure. \n \n  Role and Responsibilities:  \n \n \n \n In this role you will be part of a diverse team of developers, data scientists and technology experts to solve complex problems.  \n Works with government stakeholders to understand user requirements, develop technology recommendations, and implement solutions.  \n Works with a dynamic team of Innovators, AI engineers and data scientists that are at the forefront of AI/ML application for the Department of Defense.  \n Research and develops leading-edge analytics enabled solutions, including applying smart algorithms, machine learning, artificial intelligence, and cloud technologies. \n \n \n \n \n \n  Basic Qualifications: \n \n \n \n  B.S. in Computer Science, Statistics, Machine Learning, Data Science, Electrical Engineering or related field plus two years of related experience.  \n Must have technical skills on machine learning/AI with proven track record. These technical skills include, but not limited to, regression techniques, neural networks, decision trees, clustering, pattern recognition, probability theory, stochastic systems, Bayesian inference, statistical techniques, deep learning, supervised learning, unsupervised learning. \n  Technical knowledge on big data technologies, cloud, and opensource software tools is required. \n  Knowledge of AI/ML platforms, technologies, techniques (e.g. TensorFlow, Apache MXnet, Theano, Keras, CNTK, scikit-learn, H2O, Spark MLlib, etc) is required. \n  Must have knowledge of data engineering tasks. \n  Applicants must be able to obtain and maintain a secret level security clearance. Contract requires U.S. citizens. \n  Relocation to the Jacksonville, Florida metro area is desired, although position is remote.  \n Occasional travel may be required. \n \n \n \n \n  Desired Qualification: \n \n  Ph.D. or graduate degree in data science or related field. Candidates currently completing a Ph.D. are strongly encouraged to apply. \n \n \n  Contract requirements regarding education and experience will prevail.  \n \n KBR is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, disability, sex, sexual orientation, gender identity or expression, age, national origin, veteran status, genetic information, union status and/or beliefs, or any other characteristic protected by federal, state, or local law.", "cleaned_desc": " \n In this role you will be part of a diverse team of developers, data scientists and technology experts to solve complex problems.  \n Works with government stakeholders to understand user requirements, develop technology recommendations, and implement solutions.  \n Works with a dynamic team of Innovators, AI engineers and data scientists that are at the forefront of AI/ML application for the Department of Defense.  \n Research and develops leading-edge analytics enabled solutions, including applying smart algorithms, machine learning, artificial intelligence, and cloud technologies. \n \n \n ", "techs": ["developers", "data scientists", "technology experts", "ai engineers", "ai/ml application", "department of defense", "smart algorithms", "machine learning", "artificial intelligence", "cloud technologies"]}, "102e55aa46ee9bda": {"terms": ["data science"], "salary_min": 81000.0, "salary_max": 162000.0, "title": "Sr Data Scientist", "company": "CVS Health", "desc": "Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u2014 with heart at its center \u2014 our purpose sends a personal message that how we deliver our services is just as important as what we deliver.    Our Heart At Work Behaviors\u2122 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. \n \n  Position Summary \n  Develops complex algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes  Performs analyses of structured and unstructured data to solve multiple and complex business problems  Utilizing advanced statistical techniques and mathematical analyses and specialized expertise in the organization and/or industry  Applies analytical rigor and statistical methods to analyze large amounts of data, using advanced statistical techniques  Manages large and complex analytical projects from data exploration, model building, performance evaluation and testing  Behaves as mentor to junior team members to provide technical advice  Collaborates with business partners to develop technical /business approaches and new or enhanced technical tools  Interacts with internal and external peers and management to share highly complex information related to areas of expertise and/or to gain acceptance of new or enhanced technology / business solutions \n  Required Qualifications  6+ years of relevant analytic experience  Experience programming using R or Python  Experience in SAS or SQL  Big Data Technologies  Machine Learning \n  Preferred Qualifications  8+ years of relevant analytic experience  Experience in Cloud  Big Data Technologies  Machine Learning \n  Education \n  Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline.    Master\u2019s degree or PhD preferred \n \n  Pay Range \n  The typical pay range for this role is: \n  $81,000.00 - $162,000.00\n  \n  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.    In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u2019s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201cPTO\u201d) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.    For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits \n \n  CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. \n \n  You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. \n \n  CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.", "cleaned_desc": "  Develops complex algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes  Performs analyses of structured and unstructured data to solve multiple and complex business problems  Utilizing advanced statistical techniques and mathematical analyses and specialized expertise in the organization and/or industry  Applies analytical rigor and statistical methods to analyze large amounts of data, using advanced statistical techniques  Manages large and complex analytical projects from data exploration, model building, performance evaluation and testing  Behaves as mentor to junior team members to provide technical advice  Collaborates with business partners to develop technical /business approaches and new or enhanced technical tools  Interacts with internal and external peers and management to share highly complex information related to areas of expertise and/or to gain acceptance of new or enhanced technology / business solutions \n  Required Qualifications  6+ years of relevant analytic experience  Experience programming using R or Python  Experience in SAS or SQL  Big Data Technologies  Machine Learning \n  Preferred Qualifications  8+ years of relevant analytic experience  Experience in Cloud  Big Data Technologies  Machine Learning ", "techs": ["r", "python", "sas", "sql", "big data technologies", "machine learning", "cloud"]}, "0c3dc626c2294536": {"terms": ["data science", "machine learning engineer"], "salary_min": 114577.305, "salary_max": 145080.4, "title": "Data Scientist-LLM", "company": "Walter P Moore", "desc": "Responsibilities: \n  \n   We are in search of a skilled Data Scientist to join our Technology Team. The role involves developing Large Language Model (LLM) applications, including specialized agents and tools, to assist our employees and clients in answering questions and streamlining daily operations.\n  \n \n  Qualifications: \n  \n Educational Background : Master\u2019s in Computer Science, Data Science, or a related field. \n  Programming Skills : Proficiency in statistical programming languages such as R and Python, as well as database query languages like SQL. \n  Statistical Expertise : Solid understanding of applied statistics, including but not limited to statistical tests, distributions, regression analysis, and maximum likelihood estimators. \n  Machine Learning : Strong grasp of machine learning algorithms including k-Nearest Neighbors, Naive Bayes, SVM, Decision Forests, and Neural Networks. \n  LLM and NLP : Experience in Large Language Models and Natural Language Processing. \n  Model Fine-Tuning : Hands-on experience with in-context learning, domain-specific model fine-tuning, and prompt engineering. \n  Tool Familiarity : Experience with tools and frameworks popular in the LLM and NLP communities, such as LangChain, LlamaIndex, PyTorch, and TensorFlow. \n  Cloud Services : Experience with Azure Cloud Services. \n  Vector Storage Systems : Experience with Vector Storage Systems \n  Operating Systems and Containerization : Familiarity with Linux operating systems and containerization technologies like Docker and Kubernetes. \n  Mathematical Skills : Strong background in Multivariable Calculus and Linear Algebra. \n  Data Manipulation : Strong data wrangling and mining skills. \n  Data Visualization : Experience with visualization tools like matplotlib, ggplot, and Power BI. \n  Soft Skills : Excellent communication and collaboration abilities. \n  Experience : At least 5 years of experience in a Data Scientist role. \n  Software Engineering : Strong background in software engineering with a hands-on approach and a knack for problem-solving. \n \n \n \n  Walter P Moore is an equal employment opportunity employer and provides equal employment opportunities (including offering competitive compensation and benefit packages) to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to any characteristic protected by federal, state or local laws. \n  Overview: \n  \n   Walter P Moore is an international company of engineers, architects, innovators, and creative people who solve some of the world\u2019s most complex structural and infrastructure challenges. Providing structural, diagnostics, civil, traffic, parking, transportation, enclosure, WPM technology and construction engineering services, we design solutions that are cost- and resource-efficient, forward-thinking, and help support and shape communities worldwide. Founded in 1931 and headquartered in Houston, Texas, our 800+ professionals work across 24 U.S. offices and 7 international locations.", "cleaned_desc": "  Qualifications: \n  \n Educational Background : Master\u2019s in Computer Science, Data Science, or a related field. \n  Programming Skills : Proficiency in statistical programming languages such as R and Python, as well as database query languages like SQL. \n  Statistical Expertise : Solid understanding of applied statistics, including but not limited to statistical tests, distributions, regression analysis, and maximum likelihood estimators.    Machine Learning : Strong grasp of machine learning algorithms including k-Nearest Neighbors, Naive Bayes, SVM, Decision Forests, and Neural Networks. \n  LLM and NLP : Experience in Large Language Models and Natural Language Processing. \n  Model Fine-Tuning : Hands-on experience with in-context learning, domain-specific model fine-tuning, and prompt engineering. \n  Tool Familiarity : Experience with tools and frameworks popular in the LLM and NLP communities, such as LangChain, LlamaIndex, PyTorch, and TensorFlow. \n  Cloud Services : Experience with Azure Cloud Services.    Vector Storage Systems : Experience with Vector Storage Systems \n  Operating Systems and Containerization : Familiarity with Linux operating systems and containerization technologies like Docker and Kubernetes. \n  Mathematical Skills : Strong background in Multivariable Calculus and Linear Algebra. \n  Data Manipulation : Strong data wrangling and mining skills. \n  Data Visualization : Experience with visualization tools like matplotlib, ggplot, and Power BI.    Soft Skills : Excellent communication and collaboration abilities. \n  Experience : At least 5 years of experience in a Data Scientist role. \n  Software Engineering : Strong background in software engineering with a hands-on approach and a knack for problem-solving. \n \n ", "techs": ["r", "python", "sql", "k-nearest neighbors", "naive bayes", "svm", "decision forests", "neural networks", "large language models", "natural language processing", "langchain", "llamaindex", "pytorch", "tensorflow", "azure cloud services", "vector storage systems", "linux", "docker", "kubernetes", "multivariable calculus", "linear algebra", "matplotlib", "ggplot", "power bi"]}, "f88eba5eb7ca3e7e": {"terms": ["data science"], "salary_min": 97016.96, "salary_max": 122845.086, "title": "Project Manager", "company": "Infor", "desc": "General information \n       \n \n \n \n \n \n \n        Country \n        \n United States  \n \n \n \n        City \n        \n Remote Location  \n \n \n \n        Department \n        \n IT Business Innovation  \n \n \n \n        Job ID \n        \n 36204  \n \n \n \n \n \n \n \n \n \n       Description & Requirements \n       \n \n \n \n \n \n \n As a Hospitality GPS (Global Professional Services) Project Manager, you will be responsible for implementing Cloud-based solutions used by Hotels, Casinos, and Resorts to manage their day-to-day operations for Hotel Management, Sales and catering, Restaurant Point of Sales and Revenue Management. Projects require industry-specific knowledge to effectively manage resource assignments for configuration, training, support, and technical installations. GPS Project Managers have responsibility for major accounts and multi-site product rollout. You\u2019ll be accountable for managing the client project, ensuring that all targets and requirements are met, on schedule and within budget, while operating with minimal supervision. You\u2019ll report to the Manager of Project Managers who will support you from project assignment to planning & execution, through to project billing and closure. These duties will be performed remotely with some travel to customer\u2019s site and with regular client facing video conferencing expected. Other duties may include supporting the sales teams in a pre-sales capacity and the support team for post-implementation queries as needed. \n     \n A Day in The Life Typically Includes: \n  Responsible for billable projects from initiation through delivery: \n \n Being accountable and ensuring that projects remain on schedule and within budget and confirm projects are completed according to agreed-upon plan. \n Keeping appropriate client and Infor resources informed of project progress, completing weekly Project Status Reports, dashboard reports, participating in weekly PM meetings and communicating appropriately with client project sponsors, client department leadership, and staff. \n Ensuring all project resources are identified, forecasted, and staffed. \n Completing timely and accurate client invoicing and monitors outstanding receivables. \n Provide team leadership including: building a team, motivating staff, aligning project requirements to resource competencies, delegating work assignments and monitoring performance. \n \n \n \n Managing the Infor Consulting business through accurate project accounting: \n \n Maintaining project financial and project profitability, to include resource scheduling, revenue forecasting per project, billing reconciliations, expense report and time approval for project work, etc. \n Providing timely and accurate updates to all internal reporting and tracking systems. \n Ensuring all project resources are identified, forecasted, and staffed. \n Responsible for medium to high value services work orders \n \n \n \n Basic Qualifications: \n \n Project lifecycle Project Management experience within the Hospitality Industry \n Ability to manage small, medium up to large implementation projects. \n Experience building relationships and client communication. \n Experienced with Project Management tools and MS Office products. \n Travel up to 25% \n \n \n \n \n Preferred Qualifications: \n \n PMP or other Project Management certification. \n Hotel software products use or experience. \n Demonstrated business acumen in the Hospitality Industry. \n Bachelor's Degree, or equivalent work experience. \n \n \n \n \n         Remote (Dallas, TX; St. Paul, MN; and Alpharetta, GA)\n         \n \n \n \n \n \n \n \n \n         About Infor\n         \n \n \n  Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.\n         \n \n          For more information visit www.infor.com\n         \n \n \n \n \n \n \n \n         Our Values\n         \n \n \n  At Infor, we strive for an environment that is founded on a business philosophy called Principle Based Management\u2122 (PBM\u2122) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization. Increasing diversity is important to reflect our markets, customers, partners, and communities we serve in now and in the future.\n         \n \n \n  We have a relentless commitment to a culture based on PBM. Informed by the principles that allow a free and open society to flourish, PBM\u2122 prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.\n         \n \n \n  Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law.\n          \n \n \n \n \n         At Infor we value your privacy that\u2019s why we created a policy that you can read here.\n         \n \n \n \n \n \n \n \n \n         This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf", "cleaned_desc": " \n \n \n Managing the Infor Consulting business through accurate project accounting: \n \n Maintaining project financial and project profitability, to include resource scheduling, revenue forecasting per project, billing reconciliations, expense report and time approval for project work, etc. \n Providing timely and accurate updates to all internal reporting and tracking systems. \n Ensuring all project resources are identified, forecasted, and staffed. \n Responsible for medium to high value services work orders \n \n \n \n Basic Qualifications: \n \n Project lifecycle Project Management experience within the Hospitality Industry \n Ability to manage small, medium up to large implementation projects. \n Experience building relationships and client communication. \n Experienced with Project Management tools and MS Office products. \n Travel up to 25% \n \n \n \n \n Preferred Qualifications: \n \n PMP or other Project Management certification. \n Hotel software products use or experience. \n Demonstrated business acumen in the Hospitality Industry. ", "techs": ["project management tools", "ms office products", "pmp", "hotel software products"]}, "39868177deed829b": {"terms": ["data science", "data analyst"], "salary_min": 104398.45, "salary_max": 132191.7, "title": "Data Analyst -Senior", "company": "Dine Development Corporation", "desc": "Job Summary:: \n  \n   DDC ITS is actively searching for a Senior Data Analyst to play a pivotal role in supporting the Air Force Pathfinder initiative. This role involves the in-depth exploration of business processes, data resources, and technological facilitators, all of which are essential components in establishing self-sustaining support for the F-35 within the Air Force Supply Chain. The Senior Data Analyst will work with a team to provide high-quality service to our customer in managing the logistics IT portfolio of systems. This role is responsible for the execution of data management activities within the areas of data quality and data asset management.\n  \n \n   This position is a collaborative role providing support for analysis and research into our data structures, attribution, maintenance, and models to ensure they are compliant with the organization\u2019s strategic data management direction. This position is also responsible for maintaining the visibility and integrity of the portfolio\u2019s data asset inventory by identifying and closing information gaps that may exist.\n  \n \n   The Data Analyst will work within an agile team to provide high-quality service to our customer by applying analysis techniques to determine solutions based on client requirements with an IT services/solutions-based scope. They will analyze and reverse engineer business and technical artifacts such as data models, data catalogs, design documentation and interfaces to capture, store and maintain relevant metadata for the systems within the portfolio. This role may also be expected to develop and maintain data quality assessments and data profiles for the systems within the LogIT portfolio. As such, they will be expected to work closely with functional and technical data stewards to present their findings and provide recommendations for addressing issues which may be identified.\n   Job Duties and Responsibilities: : \n  \n Analyze operational activities to obtain a quantitative, rational basis for decision making and resource allocation \n  Conceptually understand and convey to stakeholders and leadership complex topics related to data management, data governance, and data maturity. \n  Work with subject matter experts (SME) across organizations to collect and update business and technical metadata. \n  Reverse engineer data models and other design or build artifacts to extract relevant business and technical metadata and load into a metadata repository \n  Develop source-to-target (STMs) that document data transformation at the interface level \n  Create project plans to achieve performance-based objectives, enhancing implementation, systems and service \n  Review submitted data to detect data quality problems and anomalies and help organization correct data: both current and historical \n  Provide integral support in mission requirements determination, conceptualization, design, development, testing, verification and validation, documentation, and implementation of system applications \n  Collect and analyze data and associated system artifacts for stakeholders to use in perfecting their business practices \n  Perform analysis to determine how data might best be applied to profit the stakeholders \n  Develop ETL routines to load and curate disparate data sets \n  Job Requirements (Education/Skills/Experience):: \n   You'll need to have: \n \n  Ability to obtain an active DoD Secret Clearance \n  Bachelor's degree in Computer Science or similar and 8+ years of experience \n  Experience with ETL or data movement software such as Informatica, Talend, SSIS, NiFi, StreamSets, DataBricks, Jupyter Notebooks etc\u2026 \n  Expertise using SQL for data analysis, data quality, and data profiling activities \n  Experience in one or more scripting languages \n  Expertise creating data mapping documentation for databases, interfaces and applications \n  Experience with Agile development methodologies and roles \n  Experience leading a team of developers and analysts \n  Excellent written and verbal communications \n \n  Even better if you have: \n \n  Experience with AF Logistics systems and data \n  Experience in requirements elicitation \n  Extensive practical experience in working with and defining data \n  Logical thinker; able to articulate thoughts both verbally and diagrammatically \n  Prior experience of logical data modelling and data normalization \n  Experience with data collection systems and their strategies \n \n \n  Din\u00e9 Development Corporation is an Equal Opportunity Employer subject to the Navajo Preference in Employment Act. In compliance with the Americans with Disabilities Act and/or applicable state regulations, Din\u00e9 Development Corporation will provide reasonable accommodations to qualified individuals with disabilities and encourages prospective employees/incumbents to discuss potential accommodations with the company", "cleaned_desc": "Job Summary:: \n  \n   DDC ITS is actively searching for a Senior Data Analyst to play a pivotal role in supporting the Air Force Pathfinder initiative. This role involves the in-depth exploration of business processes, data resources, and technological facilitators, all of which are essential components in establishing self-sustaining support for the F-35 within the Air Force Supply Chain. The Senior Data Analyst will work with a team to provide high-quality service to our customer in managing the logistics IT portfolio of systems. This role is responsible for the execution of data management activities within the areas of data quality and data asset management.\n  \n \n   This position is a collaborative role providing support for analysis and research into our data structures, attribution, maintenance, and models to ensure they are compliant with the organization\u2019s strategic data management direction. This position is also responsible for maintaining the visibility and integrity of the portfolio\u2019s data asset inventory by identifying and closing information gaps that may exist.\n  \n \n   The Data Analyst will work within an agile team to provide high-quality service to our customer by applying analysis techniques to determine solutions based on client requirements with an IT services/solutions-based scope. They will analyze and reverse engineer business and technical artifacts such as data models, data catalogs, design documentation and interfaces to capture, store and maintain relevant metadata for the systems within the portfolio. This role may also be expected to develop and maintain data quality assessments and data profiles for the systems within the LogIT portfolio. As such, they will be expected to work closely with functional and technical data stewards to present their findings and provide recommendations for addressing issues which may be identified.    Job Duties and Responsibilities: : \n  \n Analyze operational activities to obtain a quantitative, rational basis for decision making and resource allocation \n  Conceptually understand and convey to stakeholders and leadership complex topics related to data management, data governance, and data maturity. \n  Work with subject matter experts (SME) across organizations to collect and update business and technical metadata. \n  Reverse engineer data models and other design or build artifacts to extract relevant business and technical metadata and load into a metadata repository \n  Develop source-to-target (STMs) that document data transformation at the interface level \n  Create project plans to achieve performance-based objectives, enhancing implementation, systems and service \n  Review submitted data to detect data quality problems and anomalies and help organization correct data: both current and historical    Experience with ETL or data movement software such as Informatica, Talend, SSIS, NiFi, StreamSets, DataBricks, Jupyter Notebooks etc\u2026 \n  Expertise using SQL for data analysis, data quality, and data profiling activities \n  Experience in one or more scripting languages \n  Expertise creating data mapping documentation for databases, interfaces and applications \n  Experience with Agile development methodologies and roles \n  Experience leading a team of developers and analysts \n  Excellent written and verbal communications \n \n  Even better if you have:   \n  Experience with AF Logistics systems and data \n  Experience in requirements elicitation \n  Extensive practical experience in working with and defining data \n  Logical thinker; able to articulate thoughts both verbally and diagrammatically \n  Prior experience of logical data modelling and data normalization \n  Experience with data collection systems and their strategies \n \n ", "techs": ["informatica", "talend", "ssis", "nifi", "streamsets", "databricks", "jupyter notebooks", "sql"]}, "60308381e2e7a852": {"terms": ["data science"], "salary_min": 114000.0, "salary_max": 154000.0, "title": "Vice President, Performance Implementation and Impact Services", "company": "Acelero Learning", "desc": "Are you a socially conscious, dedicated individual who is committed to building a better future for children, families, and their communities? If so, join us as we support early childhood education programs across the country to create positive outcomes for the children and families served.  \n Job Title: Vice President of Performance Implementation & Impact Services \n  The Organization: Acelero, Inc.  \n The Current Landscape: The VP of Performance, Implementation & Impact (PII) Services is responsible for building and overseeing performance and implementation for a caseload of community partners across the network. The role involves working with partner/client Head Start Directors, Data Leads, and other key leaders to adopt Acelero / Shine Early Learning's early childhood education, family & community engagement, and management systems & analysis approach. \n  The VP of PII Services is a seasoned data scientist with a proven track record of leadership in driving performance and implementation in complex environments. The VP will manage a system of work streams and reviews, provide direction to stakeholders, coordinate support provided by early childhood education and family & community engagement colleagues, and ensure high-quality Performance, Implementation, and Impact (PII) services are provided to clients. The ideal candidate will have extensive experience in data management and analysis, coaching, facilitation of training, program assessment, and evaluation. This position emphasizes harnessing the power of data analytics, predictive modeling, and machine learning to ensure the best outcomes for children and families. \n  The Purpose of the Role: The VP is a senior member of the Program Services & Innovation, Program and Acelero Shine Leadership teams, and requires leadership skills, ability to multitask in a fast-paced environment, sound judgment, data-driven decision-making, and exceptional interpersonal skills. The VP will provide strategic leadership with a commitment to equity principles to successfully deliver high-quality services and drive business growth and development. \n  Contribute to Acelero, Inc. community of practice by: \n \n  Demonstrating leadership in alignment of work and approach to company vision, mission, core values and the advancement of diversity, equity, inclusion and belonging.Serving as an active member of both the PSI and Acelero Shine leadership teams.Communicating department goals and progress frequently and effectively with the program team, executive leadership, business unit leaders, and other appropriate internal and external stakeholders.Partnering in cross-network communications and development activities to advance Acelero's strategic priorities.Serving as an industry thought leader on program-related topics through conference presentations, articles, and professional or scientific publications. \n \n  A Day in the Life \n \n  Strategy & Innovation \n \n  Oversee data-driven projects aimed at enhancing performance and measuring the impact of interventions.Foster an environment of continuous learning and innovation, leveraging data to drive decisions.Leads the design of the PII Services support framework that is grounded in data-centered methodologies.Establishes systems, policies and procedures that enable the team to support partner programs in comprehending and efficiently utilizing data and analytical tools/products.Facilitate partner strategic planning sessions, using data to develop and assess goal attainment.Co-create and execute an innovative, rigorous, and inclusive partner support model.Facilitate collaboration with other leaders to ensure and enhance partner success.Drive the adoption of advanced data analytics methodologies across teams. \n \n \n \n  Management & Implementation \n \n  Responsible for projects related to data analysis, compliance monitoring, program evaluation, record-keeping and reporting, planning, communication, and project management.Lead the implementation and effective utilization of Shine Insight, a child and family database, including potential support for initial training and certification, ongoing support, and periodic professional development for partner programs using Shine Insight.Create and support a coherent coaching system for data and compliance leads across internal and external partners.Ensure compliance across partners with licensing, HS and other regulatory statutes + quality implementation of PII approaches.Demonstrate an in depth understanding of all data and analytic tools related to partner support.Manage the development, planning, execution, and analysis of a comprehensive self-assessment system partners. \n \n \n \n  Team Development & Leadership \n \n  Build, coach, develop, and lead a team of partner leads on a suite of \"Manage By\" Data Dashboards.Ensure the creation, analysis, and facilitation of self-assessment and strategy workshops in collaboration with PII and SDPM roles.Track record of success in completing assigned tasks in a timely, high-quality manner.Build bridges among other PT teams to provide opportunities for collaboration to increase program quality and innovation to inform strategies to increase child and family outcomes.Navigate the One Inc. transition with positivity while building a team culture of belonging and alignment to core values.Support existing MSA/PDM (Monitoring Systems Analysis/Program Design & Management) team members through the change management process to PSI-PII or to roles in other parts of the organization. \n \n \n  Position Reports To: Senior Vice President of Program Services and Innovation, Maria Begg-Roberson. \n  Position Manages: Supervises one Senior Director of PII Services, may have other leaders under their supervision. \n  Who should apply? (Requirements) \n \n  Master's Degree in data science, data analytics, applied Statistics (MAS), mathematics, business analytics, computational data science, or related field required.At least three (3) years of experience managing data and reporting for a multi-site learning organization required;Early learning or previous Head Start experience is a plus.Progressive track record of management success.At least 1-2 years of experience required in management/administration, 3-5 years preferred.Experience and knowledge in quality rating and improvement systems for childcare.Extensive experience in quantitative analytic methods; basic qualitative experience required.Extensive experience with databases and case management systems, particularly in customizing, no-code build out and managing new systems migration or product development; basic coding experience required.Ability to analyze and communicate complex data. \n \n  When/Where/How Much: \n  Start Date : January/February 2024 \n  Location/Travel: 25% of the time for work-related meetings and functions. \n  Salary: $114,000 - $154,000 \n  INTERESTED AND READY TO TAKE THE NEXT STEPS? \n  Read the  FAQ , an honest deep dive into the role, the organization, and the manager. Copy and paste this link into your browser to access the FAQ.  This position earns up to 154,000.00 Annually\n   Why Acelero Learning or Shine Early Learning? - Ability to make an impact in the lives of the children, families, and partners we serve- Career growth and professional development opportunities- Supportive working environment- Average of 5 weeks of paid time off during 1st year of employment- Comprehensive benefits, including 401K matching and 100% vesting program We are an equal opportunity employer, committed to creating a diverse and healthy work place. \n  Still have questions about this role or our company? Submit an anonymous question by copying and pasting this ,intoyour browser. \n  Or feel free to contact. Thank you for considering employment with us!", "cleaned_desc": " \n  Master's Degree in data science, data analytics, applied Statistics (MAS), mathematics, business analytics, computational data science, or related field required.At least three (3) years of experience managing data and reporting for a multi-site learning organization required;Early learning or previous Head Start experience is a plus.Progressive track record of management success.At least 1-2 years of experience required in management/administration, 3-5 years preferred.Experience and knowledge in quality rating and improvement systems for childcare.Extensive experience in quantitative analytic methods; basic qualitative experience required.Extensive experience with databases and case management systems, particularly in customizing, no-code build out and managing new systems migration or product development; basic coding experience required.Ability to analyze and communicate complex data. \n \n  When/Where/How Much: \n  Start Date : January/February 2024 \n  Location/Travel: 25% of the time for work-related meetings and functions. \n  Salary: $114,000 - $154,000 \n  INTERESTED AND READY TO TAKE THE NEXT STEPS? ", "techs": ["master's degree in data science", "data analytics", "applied statistics (mas)", "mathematics", "business analytics", "computational data science", "related field", "quality rating and improvement systems for childcare", "databases", "case management systems", "customizing", "no-code build out", "managing new systems migration or product development", "coding"]}, "e17a28433290e7f7": {"terms": ["data science"], "salary_min": 28.0, "salary_max": 33.0, "title": "Project Coordinator - Analyst Relations program", "company": "FocusKPI Inc.", "desc": "FocusKPI is looking for a  Project Coordinator  to join our client, a high-tech SaaS company. This is a remote role and you will be part of a global communications team, reporting to the Head of Analyst Relations and partnering with communications, marketing, product, and corporate teams across the business. \n  A typical communications specialist is responsible for helping the team with the execution of strategy and project management of the  analyst relations  program, for creating and maintaining best practices, processes and infrastructure that will enable the analyst relations team to operate as efficiently and effectively as possible. \n  Work Location:  Remote anywhere in the U.S.   Duration:  14 months with the possibility of extension depending on your performance and future situation   Pay Range:  $28/hr to $33/hr \n  Responsibilities: \n \n  Project manage the execution of the analyst relations program, tracking activities and reporting on results. \n  Capture and aggregate insights from analysts and combine them with internal and external sources to help inform and shape program and business strategy. \n  Manage annual and quarterly planning cycles, working with cross-functional stakeholders to gather input and capture feedback. \n  Maintain an analyst knowledge base that tracks the most relevant and influential global analysts, strategic research reports, and their interactions with global media, financial markets, and customers. \n  Monitor analyst research agenda and coverage, and create a forward-looking research and engagement calendar. \n  Catalog research and our responses to serve as a history, learning reference, and reliable source of curated research responses. \n  Project manage analyst report submissions and presentations. \n \n  Qualifications: \n \n  Two years of experience in project management in marketing, ideally on a communications or analyst relations team in a Fortune 500 tech firm. \n  Experience doing research and presentations. \n  An eye for simplifying sophisticated topics and technologies to their essence, and the curiosity and aim to discover share-worthy information. \n  Great communication skills, with a love for collecting and sharing salient content from internal and external sources. \n  High energy and the ability to be scrappy and multi-task to prioritize high-impact projects and juggle urgent inbound requests with ease. \n \n \n  Thank you! \n  FocusKPI Hiring Team \n  Founded in 2010, FocusKPI, Inc. (FocusKPI) is a data science and technology firm specializing in predictive analytics practice and methodologies. FocusKPI is a US company headquartered in Silicon Valley, California, with an East Coast office in Boston, Massachusetts. \n  NOTICE:  Please be aware of fraudulent emails regarding job postings, job offers and fake checks. FocusKPI's recruiting team will strictly reach out via @focuskpi.com email domain. If you have received fraudulent emails now or in the past, please report it to https://reportfraud.ftc.gov/ .  The domain @focuskpijobs.com is fraudulent and not related to FocusKPI. Please do not not reply or communicate to anyone with @focuskpijobs.com. \n   \n GFDsTmrj4C", "cleaned_desc": "  Two years of experience in project management in marketing, ideally on a communications or analyst relations team in a Fortune 500 tech firm. \n  Experience doing research and presentations. \n  An eye for simplifying sophisticated topics and technologies to their essence, and the curiosity and aim to discover share-worthy information. \n  Great communication skills, with a love for collecting and sharing salient content from internal and external sources. \n  High energy and the ability to be scrappy and multi-task to prioritize high-impact projects and juggle urgent inbound requests with ease. ", "techs": ["project management", "marketing", "communications", "analyst relations", "research", "presentations", "simplifying sophisticated topics", "technologies", "curiosity", "aim to discover share-worthy information", "communication skills", "collecting content", "sharing salient content", "high energy", "scrappy", "multi-tasking", "prioritizing high-impact projects", "juggling inbound requests"]}, "54605b1da37e88fd": {"terms": ["data science", "machine learning engineer"], "salary_min": 92432.234, "salary_max": 117039.81, "title": "Senior Data Scientist", "company": "Zepz", "desc": "About Zepz \n  Zepz is the group powering two leading global remittance brands: WorldRemit and Sendwave. Since 2010, we have been disrupting an industry previously dominated by offline legacy players with our relentless focus on reducing the cost of remittances and increasing safety and convenience for our users. Every day, our people work to unlock the prosperity of cross-border communities through finance and technology - driven by our vision of a world that celebrates migrants' impact on prosperity, at home and abroad. \n  Our brands helped cross-border communities send over $15bn from 50 countries to recipients in 130 countries in 2022. We operate over 5,000 money transfer corridors worldwide and employ over 1,000 people globally. Zepz is a remote-first employer, with team members located across six continents. \n    Our vision is to create a world that celebrates migrants' impact on prosperity, at home and abroad. Our purpose is to unlock the prosperity of cross-border communities through finance and technology. \n  Zepz.io \n  Our Commitments: \n \n \n We act like owners  - We are relentlessly delivering for our users and spending money thoughtfully. \n \n \n We embrace embarrassing honesty -  We function best when we're open and honest with one another \u2014 especially about our challenges and doubts. \n \n \n We have a bias to action  - We get to first outcomes quickly, iterate and learn. \n \n \n We strive to be better -  We may make mistakes, but always learn from them. \n \n \n We are inclusive -  to better reflect and serve our users. \n \n \n \n Your key area of focus: \n  The main focus of this role initially will be within the marketing & product teams, looking at ways we can improve our customer understanding and optimize our spending and returns, through modeling like MMM, CLV, retention & loyalty. As the role develops there will be other areas of the business that will also need support ie. optimizing performance in the commercial and operations space and looking for anomalies within our data to help spot issues. \n  You will champion the data science space for these teams, looking for where there are the greatest opportunities to deploy models/algorithms and find the 'low hanging fruit'. \n  What you will own: \n \n Translate commercial requirements into technical solutions, converting real-world problems into solvable data science projects, resulting in insights that further the strategy and enable visibility into key results \n Designing and implementing new models to improve business performance, whether this is in the marketing, product, or commercial space. \n Improving existing models through greater scrutiny of the methodology and improving the input data \n Own our existing CLV/LTV & MMM models \n Develop a new anomaly detection algorithm, helping us spot strange behaviour in certain countries. \n Develop loyalty models to help retention our customers better \n Develop cost optimization models to help the team understand how to truly optimize their spend \n Evaluate and integrate new data sources for our algorithms, aligning with Data Engineering and Analytical Engineers' best practices for dbt \n Develop strategies and tools to help less technical individuals understand and use the models and results. \n Automate the training and deployment of updated models, ensuring the output is tested, automated, scalable and documented and checks are in place to identify drift. \n Help build experiments to evaluate new models, third-party data sources and tooling. \n Champion the use of Data Science within the business \n \n What you bring to the table: \n \n 4+ years of professional experience training and deploying models that deliver measurable value (regression, clustering, decision trees, spend optimization etc). \n You have strong SQL skills, confidently able to pull and manipulate data to get into the desired format for modelling (CTEs, joins, case statements, subqueries, an understanding of data types and how to cast them). \n Possess strong Python or R programming skills, able to automate processes and deploy applications. You can develop production standard scripts and perform relevant analysis. \n You are a problem solver who can identify opportunities for data-driven solutions and prioritize against commercial impact \n You are motivated to deeply understand user behaviour and deliver actionable recommendations to teams alongside a strong technical data solution. \n You can confidently discuss complex business and technical topics with a range of stakeholders and present findings \n Work authorization in the country in which you intend to be based. \n Experience in one or more of the following areas: \n \n Machine Learning (Scikit Learn, Tensorflow, Keras, XGBoost, H2O etc...) \n SQL Analytics (BigQuery, Redshift, Databricks, Athena, etc) \n Visualisation Tools (matlibplot, seaborn, streamlit Looker, Tableau, Periscope, etc) \n \n \n Bonus points if you \n \n You have experience with some of the following: CLV/LTV, MMM, churn, loyalty and attribution models, ARIMA. \n Have experience/are comfortable using dbt \n Have a marketing or product experience \n Have experience with experimentation design and evaluation \n You have experience with GA/Adobe or equivalent data and digital marketing/martech stacks \n Demonstrate tenacity and a willingness to go the distance to get something done. You don't mind doing things manually but automate at every opportunity. \n Are inquisitive, intellectually curious and can make sense of complex systems or information. \n Can work in a structured approach towards goals and pay attention to detail. \n Can easily communicate with non-technical folks and translate their feedback into code. \n Are comfortable defaulting to over-communication and overreaching when it comes to coordination \n Adjust quickly to changing priorities and conditions and cope effectively with complexity and change. \n \n Key details \n \n Team Composition:  The Analytics Team is a combination of Analysts, Data Scientists and Analytics Engineers. \n Team Philosophy:  The team works on a hub and spoke method - with this role sitting in the hub, meaning that you will help support the entire business, rather than being focused on a particular domain, although there will be a heavy focus on Marketing to begin with. \n Location:  Our company is remote first. You can be based anywhere in Africa, Europe, or the Americas \n Length of position:  Permanent. \n \n \n What we offer you: \n Please note that the benefits below will apply to Full-time roles. \n  We have five core benefits for our talent in the US, UK, Philippines, Poland, and South Africa. If you're not in one of those regions, don't worry - the Talent team can let you know what is available for you specifically: \n \n Unlimited Annual Leave:  Most Zepz team members are eligible for unlimited annual leave. Colleagues in customer-facing roles, receive a competitive holiday allowance and four recharge days a year. Feel free to make the most of your time off and maintain a healthy work-life balance!   \n Private Medical Cover:  You can opt-in to a Private Medical Insurance scheme. This provides you with access to thorough medical coverage, so you can feel confident in your health and well-being.   \n Retirement:  We offer pension schemes to help you plan for and secure your future.   \n Life Assurance:  Life assurance is available to give you peace of mind and protect your loved ones in case of the unexpected.   \n Parental Leave:  We offer competitive parental leave schemes to ensure you are spending as much quality time with your new bundle of joy as possible.   \n \n We are also remote-first as an organisation, offering flexibility for you to work where you need to be most productive. In many locations, we have workspaces, which you can use as you desire. Most roles in the Philippines are predominately office-based, with this we offer free meals for those 100% on-site. \n  In addition to the above, you will discover that we have a range of secondary perks (such as the cycle-to-work scheme and employee discounts) depending on your location, to help you thrive at Zepz! \n  Why choose Zepz? \n \n Our team of over 1,000 employees is fully distributed across the world. We are working from coffee shops, homes, and co-working spaces \u2014 making us one of the larger fully distributed growth-stage startups in the world but we also offer workspace in our talent cluster locations - spaces we can meet, collaborate and connect.   \n We are proud parents, community organizers, farmers, band members, yoga teachers, YouTube influencers, former Olympians, and serial entrepreneurs.   \n We collectively speak over twenty languages, including Akuapem, Amharic, Bengali, Ewe, Fante, Ga, Igbo, Kalenjin, Luganda, Oromo, Somali, Swahili, Wolof, Bulgarian, Croatian, Czech, Danish, Dutch, English, Estonian, Finnish, French, German, Greek, Hungarian, Irish, Italian, Latvian, Lithuanian, Maltese, Polish, Portuguese, Romanian, Slovak, Slovenian, Spanish and Swedish.   \n At Zepz, embodying our commitments binds us together. We are collectively passionate about striving to achieve our vision and purpose - to continue to provide the best service to our users.   \n \n Ready to Apply? \n  Applications will be reviewed on a rolling basis. If interested, please submit your resume along with a cover letter (optional), highlighting why your experience demonstrates you meet the requirements of the role. Please also indicate the countries in which you have work authorization. While Zepz supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skills. \n  At Zepz we record interviews using Metaview (https://metaview.ai). It helps us become better interviewers by recording and transcribing our interviews, and ensures we interview candidates in a fair & consistent manner. It is not required. Please let us know if you'd like to opt out of the use of Metaview - this will not affect the outcome of your interview. \n  Confidence can sometimes hold us back from applying for a job. But we'll let you in on a secret: there's no such thing as a 'perfect' candidate. Zepz is a place where everyone can thrive. \n  So however you identify and whatever background you bring with you, and if at all you might need any form of support to make the process as comfortable as possible, please let us know and give us a shot by applying. We want you to be excited to wake up to make an impact every day.", "cleaned_desc": " Champion the use of Data Science within the business \n \n What you bring to the table: \n \n 4+ years of professional experience training and deploying models that deliver measurable value (regression, clustering, decision trees, spend optimization etc). \n You have strong SQL skills, confidently able to pull and manipulate data to get into the desired format for modelling (CTEs, joins, case statements, subqueries, an understanding of data types and how to cast them). \n Possess strong Python or R programming skills, able to automate processes and deploy applications. You can develop production standard scripts and perform relevant analysis. \n You are a problem solver who can identify opportunities for data-driven solutions and prioritize against commercial impact \n You are motivated to deeply understand user behaviour and deliver actionable recommendations to teams alongside a strong technical data solution. \n You can confidently discuss complex business and technical topics with a range of stakeholders and present findings \n Work authorization in the country in which you intend to be based. \n Experience in one or more of the following areas: \n \n Machine Learning (Scikit Learn, Tensorflow, Keras, XGBoost, H2O etc...) \n SQL Analytics (BigQuery, Redshift, Databricks, Athena, etc) \n Visualisation Tools (matlibplot, seaborn, streamlit Looker, Tableau, Periscope, etc) \n \n \n Bonus points if you \n ", "techs": ["scikit learn", "tensorflow", "keras", "xgboost", "h2o", "bigquery", "redshift", "databricks", "athena", "matlibplot", "seaborn", "streamlit looker", "tableau", "periscope"]}, "91c1414d7113b42a": {"terms": ["data science"], "salary_min": 102417.34, "salary_max": 129683.17, "title": "Data Scientist III", "company": "Battelle", "desc": "Battelle delivers when others can\u2019t. We conduct research and development, manage national laboratories, design and manufacture products and deliver critical services for our clients\u2014whether they are a multi-national corporation, a small start-up or a government agency. \n \n  We recognize and appreciate the value and contributions of individuals with diverse backgrounds and experiences and welcome all qualified individuals to apply. \n \n  We are currently seeking a  Data Scientist III . This position may be located in  Columbus, OH or remotely within the US . \n \n \n \n  Job Summary \n \n \n  Battelle's Advanced Analytics supports government, academic and private industry clients in the areas of healthcare, national defense, environmental, transportation, and energy.    An individual in this role fulfills data analysis needs for complex and unusual problems, as well as leadership of other junior staff on small tasks. They will work autonomously but with guidance from other senior technical staff. For this position, there is an emphasis on (i) organizing and documenting data, code, and results, (ii) implementing state-of-the-art data analysis algorithms, evaluating them, and improving on them as needed, (iii) developing reports or presentations to report findings to project leaders and clients, (iv) providing technical expertise to support business development activities, and (v) managing small teams of 1-3 staff on small tasks. \n \n \n \n \n  Responsibilities \n \n \n \n Apply and develop quality measures to evaluate data, focusing on criteria such as completeness, accuracy, and applicability, applying understanding of relevant research area nomenclature. Experience with physiological datasets is a plus. \n  Design, implement, test, and improve methodologies for solving unusual or complex neurotechnology problems with minimal supervision \n  Review literature to identify appropriate methods to solve a neurotechnology problem, implement those methods, and develop approaches to improve on them \n  Communicate technical results in a clear, concise, and effective manner with emphasis on data visualization techniques \n  Create technical reports and presentations, describing results with tables, graphs, and software tools in a manner that the client can understand \n  Present research results to clients and participate in scientific conferences, peer review panels, and increase company visibility through publications \n  Build relationships with contacts across Battelle in different disciplines, as well as external clients \n  Support business development efforts led by others, including contributing technical material to proposals, helping to plan technical budgets and schedule, and conversing with potential clients as part of a team, with guidance \n  Proactively manage expectations and meet deadlines in a fast-moving, agile environment \n  Participate in multiple, assigned research projects with minimal supervision and within time and budget constraints \n  Maintain excellent communication and interact with both co-located and geographically diverse team members daily \n  Occasionally travel domestically to client sites, conferences, etc. \n  Plan and carry out appropriate professional self-development activities \n  Perform other duties as assigned \n \n \n \n \n \n  Key Qualifications \n \n \n \n Expertise in manipulating and analyzing data (e.g., regression, classification, machine learning methods, mixed and generalized linear models, time series analysis, longitudinal methods, Bayesian methods) \n  PhD AND 1+ years of experience OR Master's degree AND 4+ or more years of experience with degree in Statistics, Machine Learning, Mathematics, Data Science, Computer Science, or Electrical Engineering (with a data analysis focus) or relevant related field \n  Applicants for this position must be a U.S. Person, as defined by U.S. export control laws. \n  Strong background in neurotechnology field, demonstrating algorithmic programming and data visualization skills \n  Programming experience in at least one of R, Python, and/or MATLAB \n  Excellent oral and written communication skills \n  Attention to detail and adaptability \n  Strong analytical, multi-tasking, problem solving, organizational, and planning skills \n \n \n \n \n \n  Preferred Qualifications \n \n \n \n Ability to obtain and maintain a government security clearance \n  Experience either as an intern, a research assistant, or an applied project consultant, demonstrating capabilities in data analysis and programming \n  Experience with C, C++, C#, Java, or similar programming languages \n \n \n \n \n \n  Benefits: Live an Extraordinary Life  We care about your well-being, not just on the job. Battelle offers comprehensive and competitive benefits to help you live your best life. \n \n  Balance life through a compressed work schedule : Most of our team follows a flexible, compressed work schedule that allows for every other Friday off\u2014giving you a dedicated day to accomplish things in your personal life without using vacation time. \n  Take time to recharge : You get paid time off to support work-life balance and keep motivated. \n  Prioritize wellness : Stay healthy with medical, dental, and vision coverage with wellness incentives and benefits plus a variety of optional supplemental benefits. \n  Better together : Coverage for partners, gender-affirming care and health support, and family formation support. \n  Build your financial future : Build financial stability with an industry-leading 401(k) retirement savings plan. For most employees, we put in 5 percent whether you contribute or not, and match your contributions on top of that. \n  Advance your education : Tuition assistance is available to pursue higher education. \n  Flexible work arrangements : You have options for where you work and when you work. \n \n     A Work Environment Where You Succeed  For brilliant minds in science, technology, engineering and business operations, Battelle is the place to do the greatest good by solving humanity\u2019s most pressing challenges and creating a safer, healthier and more secure world.    You will have the opportunity to thrive in a culture that inspires you to: \n \n  Apply your talent to challenging and meaningful projects \n  Receive select funding to pursue ideas in scientific and technological discovery \n  Collaborate with world-class experts in an inclusive environment \n  Nurture and develop the next generation of scientific leaders \n  Give back to and improve our communities \n \n \n  Vaccinations & Safety Protocols \n  Battelle may require employees, based on job duties, work location, and/or its clients\u2019 requirements to follow certain safety protocols and to be vaccinated against a variety of viruses, bacteria, and diseases as a condition of employment and continued employment and to provide documentation that they are fully vaccinated. If applicable, Battelle will provide reasonable accommodations based on a qualified disability or medical condition through the Americans with Disabilities Act or the Rehabilitation Act or for a sincerely held religious belief under Title VII of the Civil Rights Act of 1964 (and related state laws). \n \n  Battelle is an equal opportunity employer. We provide employment and opportunities for advancement, compensation, training, and growth according to individual merit, without regard to race, color, religion, sex (including pregnancy), national origin, sexual orientation, gender identity or expression, marital status, age, genetic information, disability, veteran-status veteran or military status, or any other characteristic protected under applicable Federal, state, or local law. Our goal is for each staff member to have the opportunity to grow to the limits of their abilities and to achieve personal and organizational objectives. We will support positive programs for equal treatment of all staff and full utilization of all qualified employees at all levels within Battelle. \n \n  The above statements are intended to describe the nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, activities and skills required of staff members.  No statement herein is intended to imply any authorities to commit Battelle unless special written permission is granted by Battelle's Legal Department. \n \n  For more information about our other openings, please visit www.battelle.org/careers", "cleaned_desc": " \n \n Apply and develop quality measures to evaluate data, focusing on criteria such as completeness, accuracy, and applicability, applying understanding of relevant research area nomenclature. Experience with physiological datasets is a plus. \n  Design, implement, test, and improve methodologies for solving unusual or complex neurotechnology problems with minimal supervision \n  Review literature to identify appropriate methods to solve a neurotechnology problem, implement those methods, and develop approaches to improve on them \n  Communicate technical results in a clear, concise, and effective manner with emphasis on data visualization techniques \n  Create technical reports and presentations, describing results with tables, graphs, and software tools in a manner that the client can understand \n  Present research results to clients and participate in scientific conferences, peer review panels, and increase company visibility through publications \n  Build relationships with contacts across Battelle in different disciplines, as well as external clients \n  Support business development efforts led by others, including contributing technical material to proposals, helping to plan technical budgets and schedule, and conversing with potential clients as part of a team, with guidance \n  Proactively manage expectations and meet deadlines in a fast-moving, agile environment \n  Participate in multiple, assigned research projects with minimal supervision and within time and budget constraints \n  Maintain excellent communication and interact with both co-located and geographically diverse team members daily \n  Occasionally travel domestically to client sites, conferences, etc. \n  Plan and carry out appropriate professional self-development activities \n  Perform other duties as assigned \n \n   \n \n \n  Key Qualifications \n \n \n \n Expertise in manipulating and analyzing data (e.g., regression, classification, machine learning methods, mixed and generalized linear models, time series analysis, longitudinal methods, Bayesian methods) \n  PhD AND 1+ years of experience OR Master's degree AND 4+ or more years of experience with degree in Statistics, Machine Learning, Mathematics, Data Science, Computer Science, or Electrical Engineering (with a data analysis focus) or relevant related field \n  Applicants for this position must be a U.S. Person, as defined by U.S. export control laws. \n  Strong background in neurotechnology field, demonstrating algorithmic programming and data visualization skills \n  Programming experience in at least one of R, Python, and/or MATLAB \n  Excellent oral and written communication skills \n  Attention to detail and adaptability \n  Strong analytical, multi-tasking, problem solving, organizational, and planning skills \n \n \n ", "techs": ["regression", "classification", "machine learning methods", "mixed and generalized linear models", "time series analysis", "longitudinal methods", "bayesian methods", "statistics", "machine learning", "mathematics", "data science", "computer science", "electrical engineering", "r", "python", "matlab"]}, "64e781268877fabe": {"terms": ["data science"], "salary_min": 129471.75, "salary_max": 163940.1, "title": "Principal Data Scientist (HYBRID)", "company": "Inclusively", "desc": "Inclusively is partnering with a multinational financial services company to hire a Principal Data Scientist (HYBRID). \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The Expertise and Skills You Bring \n \n Deep understanding of Machine Learning & Deep Learning algorithms \n Proven experience working with business partners to understand their problem, design and model a solution, and bring a prototype to market efficiently \n Knowledge or experience with embedding models and large language models \u2013 Llama 2, OpenAI products, Langchain, multimodal embeddings \n Knowledge of most of the following quantitative fields: Natural Language Processing, OCR Information Retrieval, Machine Comprehension, Question Answering, Reinforcement Learning, Knowledge Graph, Causal Inference, and Design of Experiment \n Programming skills and experience, such as Python, Scikit Learn, PyTorch etc. \n Expertise in navigating large data sets (structured and unstructured), discovering, cleaning, analyzing, and preparing data for ingestion \n Experience building and hosting data pipelines and RESTful APIs \n Professional experience building scalable applications in AWS \n Familiarity with CI/CD and DevOps standard methodologies and/or ML-Ops \n Additional technical skills that are nice to have: Snowflake, JavaScript, Spark, Serverless, Jenkins, Concourse, NoSQL databases, Tableau, R, Linux \n A creative problem solver, who thrives on working through complex challenges and is fueled by a natural curiosity to keep up with continuous advancements and trends in technology \n Strong technical foundation with an ability to learn new skills and technologies as needed \n Great collaboration and interpersonal skills while also demonstrating the ability to be self-starter and independent thinker \n Strong communication and presentation skills, with a ability to explain complex technical/analytical concepts to audiences at all levels (technical and non-technical) \n Computer science / mathematics / quantitative educational background \n Working knowledge of Investment Management business domain knowledge across some combination of Research, Portfolio Management, Trading, Compliance, and Investment Operations is helpful, but not necessary \n Bachelors or equivalent with 5+ years of experience or Masters with 3+ years of experience \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Deep understanding of Machine Learning & Deep Learning algorithms \n Proven experience working with business partners to understand their problem, design and model a solution, and bring a prototype to market efficiently \n Knowledge or experience with embedding models and large language models \u2013 Llama 2, OpenAI products, Langchain, multimodal embeddings \n Knowledge of most of the following quantitative fields: Natural Language Processing, OCR Information Retrieval, Machine Comprehension, Question Answering, Reinforcement Learning, Knowledge Graph, Causal Inference, and Design of Experiment \n Programming skills and experience, such as Python, Scikit Learn, PyTorch etc.   Expertise in navigating large data sets (structured and unstructured), discovering, cleaning, analyzing, and preparing data for ingestion \n Experience building and hosting data pipelines and RESTful APIs \n Professional experience building scalable applications in AWS \n Familiarity with CI/CD and DevOps standard methodologies and/or ML-Ops \n Additional technical skills that are nice to have: Snowflake, JavaScript, Spark, Serverless, Jenkins, Concourse, NoSQL databases, Tableau, R, Linux   A creative problem solver, who thrives on working through complex challenges and is fueled by a natural curiosity to keep up with continuous advancements and trends in technology \n Strong technical foundation with an ability to learn new skills and technologies as needed \n Great collaboration and interpersonal skills while also demonstrating the ability to be self-starter and independent thinker \n Strong communication and presentation skills, with a ability to explain complex technical/analytical concepts to audiences at all levels (technical and non-technical) \n Computer science / mathematics / quantitative educational background ", "techs": ["machine learning", "deep learning", "llama 2", "openai products", "langchain", "multimodal embeddings", "natural language processing", "ocr information retrieval", "machine comprehension", "question answering", "reinforcement learning", "knowledge graph", "causal inference", "design of experiment", "python", "scikit learn", "pytorch", "aws", "ci/cd", "devops", "ml-ops", "snowflake", "javascript", "spark", "serverless", "jenkins", "concourse", "nosql databases", "tableau", "r", "linux", "snowflake", "javascript", "spark", "serverless", "jenkins", "concourse", "nosql databases", "tableau", "r", "linux"]}, "08e54539cea29376": {"terms": ["data science"], "salary_min": 112000.0, "salary_max": 122000.0, "title": "Senior Data Scientist", "company": "Beckman Coulter Diagnostics", "desc": "Wondering what\u2019s within Beckman Coulter Diagnostics? Take a closer look. \n \n  At first glance, you\u2019ll see that for more than 80 years we\u2019ve been dedicated to advancing and optimizing the laboratory to move science and healthcare forward. Join a team where you can be heard, be supported, and always be yourself. We\u2019re building a culture that celebrates backgrounds, experiences, and perspectives of all our associates. Look again and you\u2019ll see we are invested in you, providing the opportunity to build a meaningful career, be creative, and try new things with the support you need to be successful. \n \n  Beckman Coulter Diagnostics is proud to work alongside a community of six fellow Diagnostics Companies at Danaher. Together, we\u2019re working at the pace of change to improve patient lives with diagnostic tools that address the world\u2019s biggest health challenges. \n \n  This position is part of the Bioinformatics/Biostatistics team located in Miami and will be  remote . At Beckman Coulter, our vision is to relentlessly reimagine healthcare, one diagnosis at a time. \n \n  You will be a part of the Data Automation team and report to the Manager of Data Automation responsible for building applications for managing and analyzing clinical trials data. If you thrive in a dynamic development role and want to work to build a world-class data science organization\u2014please read on. \n \n  In this role, you will have the opportunity to: \n \n \n  Build applications for data capturing and automation \n  Build applications to interface with the existing EDC and instrument data automation systems \n  Collaborate with cross-functional teams to define project objectives and gather data requirement \n  Visualize data, create reports and present findings to stakeholders and non-technical audiences \n  Create data visualization applications using C#, Python and SQL \n \n \n  The essential requirements of the job include: \n \n \n  Bachelor's degree in computer science, statistics, bioinformatics or a related field with 5+ years of experience in data science or software development OR Master's degree in computer science, statistics, bioinformatics or a related field with 3+ years of experience in data science or software development \n  Strong programming skills in Python or C# \n  Experience with SQL \n \n \n  It would be a plus if you also possess previous experience in: \n \n \n  Experience with visualization tools, such as Tableau or Power BI, to convey insights effectively \n  Experience working with medical data \n  Experience working with a global team \n \n \n  At Beckman Coulter Diagnostics we believe in designing a better, more sustainable workforce. We recognize the benefits of flexible, remote working arrangements for eligible roles and are committed to providing enriching careers, no matter the work arrangement. This position is eligible for a remote work arrangement in which you can work remotely from your home. Additional information about this remote work arrangement will be provided by your interview team. Explore the flexibility and challenge that working for Beckman Coulter Diagnostics can provide. \n \n  The salary range for this role is $112,000\u2013$122,000. This is the range that we in good faith believe is the range of possible compensation for this role at the time of this posting. We may ultimately pay more or less than the posted range. This range may be modified in the future. \n \n  This job is also eligible for bonus/incentive pay. \n \n  We offer a comprehensive package of benefits including paid time off, medical/dental/vision insurance and 401(k) to eligible employees. \n \n  Note: No amount of pay is wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company\u2019s sole discretion, consistent with the law. \n \n  #LI-SM1 \n  #LI-Remote \n \n  When you join us, you\u2019ll also be joining Danaher\u2019s global organization, where 80,000 people wake up every day determined to help our customers win. As an associate, you\u2019ll try new things, work hard, and advance your skills with guidance from dedicated leaders, all with the support of powerful  Danaher Business System  tools and the stability of a tested organization.", "cleaned_desc": " \n  In this role, you will have the opportunity to: \n \n \n  Build applications for data capturing and automation \n  Build applications to interface with the existing EDC and instrument data automation systems \n  Collaborate with cross-functional teams to define project objectives and gather data requirement \n  Visualize data, create reports and present findings to stakeholders and non-technical audiences \n  Create data visualization applications using C#, Python and SQL   \n \n  The essential requirements of the job include: \n \n \n  Bachelor's degree in computer science, statistics, bioinformatics or a related field with 5+ years of experience in data science or software development OR Master's degree in computer science, statistics, bioinformatics or a related field with 3+ years of experience in data science or software development \n  Strong programming skills in Python or C# \n  Experience with SQL \n   \n  It would be a plus if you also possess previous experience in: \n \n \n  Experience with visualization tools, such as Tableau or Power BI, to convey insights effectively \n  Experience working with medical data \n  Experience working with a global team \n \n ", "techs": ["tableau", "power bi", "c#", "python", "sql"]}, "6f93e481f60aeffe": {"terms": ["data science"], "salary_min": 101250.0, "salary_max": 155250.0, "title": "Sr. Customer Success Analyst", "company": "6sense", "desc": "Our Mission: \n  6sense is on a mission to revolutionize how B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage anonymous buying teams. 6sense Revenue AI is the only sales and marketing platform to unlock the ability to create, manage and convert high-quality pipeline to revenue. \n  Our People: \n  People are the heart and soul of 6sense. We serve with passion and purpose. We live by our Being 6sense values of Accountability, Growth Mindset, Integrity, Fun and One Team. Every 6sensor plays a part in de\ufb01ning the future of our industry-leading technology. 6sense is a place where difference-makers roll up their sleeves, take risks, act with integrity, and measure success by the value we create for our customers. \n  We want 6sense to be the best chapter of your career. \n \n  6sense Account Based Orchestration Platform helps revenue teams identify and close more opportunities by putting the power of AI, big data and machine learning behind every member of the B2B revenue team, empowering them to uncover anonymous buying behavior, prioritize fragmented data to focus on accounts in market, and engage resistant buying teams with personalized, multi-channel, multi-touch campaigns. 6sense helps revenue teams know everything they need to know about their buyers so they can easily do anything they need to do to generate more opportunities, increase deal size, get into opportunities sooner, compete and win more often. \n  This role reports to the Manager, Pipeline Analytics, and provides support to the Customer Success team. The successful candidate will be responsible for gathering, analyzing, and interpreting customer data to provide valuable insights that drive Customer Success and renewal strategies. You will collaborate closely with cross-functional teams to ensure that our customers receive unparalleled service and maximize their engagement with our products/services. \n  Responsibilities : \n \n Routinely perform analysis and insight into key metrics and provide recommendations for improving performance across the Customer Success management operating rhythm \n \n \n Be the subject matter expert and provide recommendations of best practices related to 6sense Customer Success & Customer Experience initiatives \n \n \n Proactively work with all levels of Customer Success staff to understand and establish goals, determine required data sources and establish Customer Success benchmarks and metrics \n \n \n Development and management of reports and dashboards that provide actionable metrics used to optimize and drive decisions regarding Customer Success coverage across different regional and product segments \n \n \n Be an advocate for data driven everything, evangelize insights on what's working and what's not working to help drive better views into future churn risk and customer experience initiatives. \n \n \n Partner with Customer Success Leadership, Customer Success Operations, Data teams, Finance and IT to ensure Customer data is appropriately captured and organized to enable clean and accurate instrumentation and analysis. \n \n  Qualifications : \n \n Strong understanding of SaaS Metrics like Net/Gross Retention, ARR/MRR and Churn \n \n \n Understanding and/or experience leveraging customer engagement data source via CSM interactions, NPS surveys, and data science orchestration into Gainsight or other Customer Success platforms \n \n \n Strong data evaluation skills - with the ability to extract and interpret data from various sources, and focus on the big picture takeaways of any analysis while owning the underlying details \n \n \n Experience in creating reports and dashboards in Salesforce and/or Gainsight \n \n \n Highly self-motivated, proactive contributor who works well as an individual and within a team environment \n \n \n Strong computer skills, such as MS Excel, MS PowerPoint, MS Power Query, SQL, R Studio, Python or similar applications \n \n \n Proficiency with Tableau, Power BI, or knowledge of other BI tools a plus \n \n \n Ability to understand complex systems and dependencies \n \n \n Strong critical thinking and independent problem solving skills \n \n \n Strong verbal and written communication skills with the ability to translate data findings into actionable recommendations. \n \n \n Attention to detail and a commitment to delivering high-quality work. \n \n \n Experience working in a cross-functional environment \n \n \n 3-4 years working in a professional environment, preferably within an analytics/operations role \n \n  Base Salary Range: $101,250 to $155,250. The base salary range represents the anticipated low and high end of the base salary range for this position. Actual salaries may vary and may be above or below the range based on various factors, including but not limited to work location and experience. The base salary is one component of 6sense's total compensation package for this position. Other compensation may include a bonus program or commission plan, and stock options if approved by 6sense's board. In addition, 6sense provides a variety of benefits, including generous health insurance coverage, life, and disability insurance, a 401K employer matching program, paid holidays, self-care days, and paid time off (PTO). #Li-remote \n  Notice of Collection and Use of Personal Information for California Residents: California Recruitment Privacy Notice and Policy \n \n  Our Benefits: \n  Full-time employees can take advantage of health coverage, paid parental leave, generous paid time-off and holidays, quarterly self-care days off, and stock options. We'll make sure you have the equipment and support you need to work and connect with your teams, at home or in one of our o\ufb03ces. \n  We have a growth mindset culture that is represented in all that we do, from onboarding through to numerous learning and development initiatives including access to our LinkedIn Learning platform. Employee well-being is also top of mind for us. We host quarterly wellness education sessions, and everyone has access to meQuilibrium \u2013 a platform to encourage self care and personal growth. From wellness days to ERG-hosted events, we celebrate and energize all 6sense employees and their backgrounds. \n  Equal Opportunity Employer: \n  6sense is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to  jobs@6sense.com.", "cleaned_desc": " \n Strong understanding of SaaS Metrics like Net/Gross Retention, ARR/MRR and Churn \n \n \n Understanding and/or experience leveraging customer engagement data source via CSM interactions, NPS surveys, and data science orchestration into Gainsight or other Customer Success platforms \n \n \n Strong data evaluation skills - with the ability to extract and interpret data from various sources, and focus on the big picture takeaways of any analysis while owning the underlying details \n \n \n Experience in creating reports and dashboards in Salesforce and/or Gainsight \n \n \n Highly self-motivated, proactive contributor who works well as an individual and within a team environment   \n \n Strong computer skills, such as MS Excel, MS PowerPoint, MS Power Query, SQL, R Studio, Python or similar applications \n \n \n Proficiency with Tableau, Power BI, or knowledge of other BI tools a plus \n \n \n Ability to understand complex systems and dependencies \n \n \n Strong critical thinking and independent problem solving skills \n \n ", "techs": ["net/gross retention", "arr/mrr", "churn", "gainsight", "customer success platforms", "salesforce", "ms excel", "ms powerpoint", "ms power query", "sql", "r studio", "python", "tableau", "power bi"]}, "cf09760870f105d1": {"terms": ["data science", "machine learning engineer"], "salary_min": 180000.0, "salary_max": 250000.0, "title": "Principal Bioinformatics Data Scientist, Liquid Biopsy", "company": "Tempus", "desc": "Passionate about precision medicine and advancing the healthcare industry? \n  Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time for our expanding liquid biopsy portfolio (including diagnostics, therapy selection, molecular residual disease testing and therapeutic response monitoring). \n  We are looking for a highly motivated and capable bioinformatics data scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical/machine learning modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting. \n  Responsibilities: \n \n Develop novel algorithms and statistical/machine learning models using genetic and epigenetic NGS data to detect highly sensitive biomarkers used to gain insight into cancer variation. \n Design and conduct analyses to improve methylation and variant calling, artifact filtering, quality control systems, variant classification and biomarker discovery. \n Design and execute experiments to support various regulatory submissions. \n Translate molecular insights into predictors and classifiers of therapeutic response and prognosis in clinical cancer care. \n Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care. \n Lead an interdisciplinary group of bioinformaticians, data scientists, and engineers to translate research into clinically actionable insights for our clients. \n Communicate with outside scientific teams as well as product and scientific leadership. \n Produce high quality and detailed documentation for all projects. \n \n Preferred Qualifications: \n \n Must have completed a Ph.D. in genetics, biomedical informatics, or related life sciences areas. \n At least 10 years of postdoc or industry experience. \n Computational skills using Python (preferred) and/or R. \n Experience working in cancer genetics, immunology, and/or biomarker discovery. \n \n Ideal candidates will possess: \n \n Experience working with Next-Generation Sequencing Data. \n Experience building NGS pipelines in a clinical setting. \n Experience in implementing and parallelizing pipelines in cloud computing environments. \n Expertise in algorithmic development, statistical models, and machine learning techniques. \n Self-driven and works well in interdisciplinary teams. \n Experience leading project teams of scientists and/or software engineers. \n Experience with communicating insights and presenting concepts to a diverse audience. \n Demonstrated knowledge in best-practice coding processes and data change control. \n Strong background in predictive or prognostic algorithm development. \n \n \n \n  #LI-EH1 \n #LI-Hybrid \n #LI-Remote \n \n \n    The expected salary range below is applicable if the role is performed from [\n    New York ] and may vary for other locations. Actual salary may vary based on qualifications and experience. Tempus offers a full range of benefits, which may include incentive compensation, restricted stock units, medical and other benefits, depending on the position.\n   \n  New York Pay Range \n \n    $180,000\u2014$250,000 USD\n   \n \n \n  We are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.", "cleaned_desc": "Passionate about precision medicine and advancing the healthcare industry? \n  Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time for our expanding liquid biopsy portfolio (including diagnostics, therapy selection, molecular residual disease testing and therapeutic response monitoring). \n  We are looking for a highly motivated and capable bioinformatics data scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical/machine learning modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting. \n  Responsibilities: \n \n Develop novel algorithms and statistical/machine learning models using genetic and epigenetic NGS data to detect highly sensitive biomarkers used to gain insight into cancer variation. \n Design and conduct analyses to improve methylation and variant calling, artifact filtering, quality control systems, variant classification and biomarker discovery. \n Design and execute experiments to support various regulatory submissions. \n Translate molecular insights into predictors and classifiers of therapeutic response and prognosis in clinical cancer care.   Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care. \n Lead an interdisciplinary group of bioinformaticians, data scientists, and engineers to translate research into clinically actionable insights for our clients. \n Communicate with outside scientific teams as well as product and scientific leadership. \n Produce high quality and detailed documentation for all projects. \n \n Preferred Qualifications: \n \n Must have completed a Ph.D. in genetics, biomedical informatics, or related life sciences areas. \n At least 10 years of postdoc or industry experience.   Computational skills using Python (preferred) and/or R. \n Experience working in cancer genetics, immunology, and/or biomarker discovery. \n \n Ideal candidates will possess: \n \n Experience working with Next-Generation Sequencing Data. \n Experience building NGS pipelines in a clinical setting. \n Experience in implementing and parallelizing pipelines in cloud computing environments. \n Expertise in algorithmic development, statistical models, and machine learning techniques.   Self-driven and works well in interdisciplinary teams. \n Experience leading project teams of scientists and/or software engineers. \n Experience with communicating insights and presenting concepts to a diverse audience. \n Demonstrated knowledge in best-practice coding processes and data change control. \n Strong background in predictive or prognostic algorithm development. \n \n \n \n  #LI-EH1 ", "techs": ["tempus' proprietary platform", "genetic and epigenetic ngs data", "methylation and variant calling", "artifact filtering", "quality control systems", "variant classification", "biomarker discovery", "python", "r", "next-generation sequencing data", "ngs pipelines", "cloud computing environments", "algorithmic development", "statistical models", "machine learning techniques", "interdisciplinary teams", "project teams", "communicating insights", "predictive algorithm development."]}, "fec04aced3a0deaa": {"terms": ["data science"], "salary_min": 76000.0, "salary_max": 96000.0, "title": "Data Scientist & AI R&D Consultant and Lead Writer", "company": "REOFTech", "desc": "Software & AI R&D Consultant and Lead Writer SBIR DoD and NSF Grants Phase I and Phase II \n Software & AI R&D Consultant and SBIR Lead Writer  sought with successful experience and expertise in the applied and translational aspects of general software/hardware, artificial intelligence (AI), and machine learning (ML) that are a key part of an actual product to address a relevant unmet need. \n This role writes winning grant applications with rigor, depth, and specifics that convey a compelling story for real-world products and platforms to audiences of both experts and laypersons who review small and medium-size business grant applications. We are not looking for a writer who only focuses on the high-level conceptual approach to theoretical product development. Rather, we are looking for a writer who can deliver sufficient detail that resonates with reviewers as to how a practical product is designed, tested, and validated to demonstrate proof-of-concept. The writer must also understand and communicate how the eventual commercial product will be deployed and further developed for a functional and high-impact use case. Elements of content are likely to include how data is generated, managed, and validated and may include the applied use of natural language processing, distributed computing, and overall software pipeline management, among other domains. \n Specific aspects of written proficiency, supported by technical capability, in the following areas are needed for effective non-dilutive grant and contract submissions: system-level software and hardware architectures; cloud-deployed architectures; ML for clustering, classification, and regression tasks; neural networks / multi-layer perceptron models/ensembles; deep neural networks; Natural Language Processing; and others. \n This role is responsible for working alongside the Program Manager in support of industry-focused clients pursuing funding support. This role will lead the full range of technical activities required to conceptualize, prepare, and deliver grant proposals to NSF, DoD, and other government agencies. \n The Lead Writer is responsible for producing the highest quality written scientific documents for funding applications and publications, including writing, editing, and proofreading grant proposals, as well as supporting end clients as they interface with funding agencies. The lead writer must be deadline-driven and able to handle multiple concurrent projects per cycle, each with varying deadlines for execution. \n REOFTech  is focused on securing funding for leading companies that have a high potential to make a difference in their domain. Our vision is to promote scientific discovery and innovation through technological advancement by supporting our clients. \n In this mission, we selectively work with clients whose technology has the potential to significantly improve upon the current state of innovation through deep tech. \n REOFTech  is a leader in our field and continues to build on our vision. We identify innovation from every corner of our company and we are committed to innovation in every facet of our work. Each of us works to get results by employing, or pioneering, cutting-edge techniques in communication and project management to realize our vision. We know that every detail matters. We are committed to successfully delivering on our goals so that our partners can deliver on theirs. Everyone on our team realizes that when clients win, our mission is accomplished. \n A key tenet of the  REOFTech  team is that we work well together! We trust one another\u2019s judgment and have established an effective team dynamic of delivering on our individual responsibilities to best serve our clients. \n This position is part-time with full-time potential. Individuals with superior skills and a demonstrated track record will be considered for an immediate full-time hire. \n Job Title: Grant Writer Software, AI & Machine Learning \n Status: Part-time, with a full-time opportunity \n Deliverables: \n \u25cf Identify the fit between granting agencies\u2019 research needs and the end-client product roadmap and technical focus. \n \u25cf Perform literature/product searches on new ideas to understand and assess novel advancements as they relate to the end client product roadmap. \n \u25cf Work closely with technical and business staff in developing and transforming ideas into grant proposals. \n \u25cf Maintain comprehensive and up-to-date knowledge of platform technological advances and particular market areas involved in identifying and soliciting grants. \n \u25cf Draft high-quality written grant applications; translate scientific abstracts into lay terms. \n \u25cf Assist with assembling scientific documents as necessary (e.g., large institutional grants, annual/occasional reports, progress reports for grants admin., etc.). \n \u25cf May assist with planning and conducting educational courses and workshops. \n \u25cf All other duties as assigned. \n Necessary Qualifications: \n \u25cf Ph.D. with artificial intelligence, machine learning, and natural language processing background preferred. Postdoctoral fellows with grant writing experience are preferred. In lieu of a Ph.D., Master\u2019s Degree in biomedical engineering, biostatistics, neuroscience, computer science or engineering, or relevant background with direct software or AI/ML experience will be considered. \n \u25cf Subject Matter Expert in the applied and real-world use of software and AI/ML in product development and grant-writing domain. \n \u25cf Minimum 1 year of scientific writing experience, preferably in a healthcare/research/academic environment. \n \u25cf Proven experience writing grants, including DoD, NSF, and/or NIH SBIR proposals, and/or experience with other funding mechanisms preferred. \n \u25cf Technical expertise to include one or more of the following (or similar): system-level software and hardware architectures; cloud-deployed architectures; ML for clustering, classification, and regression tasks; neural networks / multi-layer perceptron models/ensembles; deep neural networks; Natural Language Processing; among others. \n Additional Qualifications and Competencies: \n \u25cf Critical Evaluation: Measurement and assessment skills objectivity, critical thinking, problem-solving, curiosity, inquisitiveness, research methodology, knowledge management, and online search skills. \n \u25cf Communication for Impact: Exceptional verbal and written English language communications skills, presentation skills, diplomacy, perceptual objectivity, and active listening. \n \u25cf Relationship Building: Internal and external customer service, objectivity, credibility, confidentiality, proactivity, responsiveness, teamwork, and mutual respect. \n \u25cf Flexibility: Ability to handle changing priorities and multiple deadlines while maintaining a high quality of workmanship. \n \u25cf Ethical Practice: Rapport building, trust-building, personal and professional integrity, credibility, professional and personal courage. \n Compensation: Competitive salary commensurate with experience. Bonus eligible. \n About REOFTech.  Founded in 2011,  REOFTech  is a consulting firm specializing in securing federal funding for the advanced technology, healthcare, drug development, education, and defense industries. With a strong focus on R&D, technology, and innovation, we are technical and scientific leaders in federal funding and technology consulting. We have obtained more than $90M for our clients. \n We focus on the National Science Foundation, National Institutes of Health, and the US Department of Defense funding, with an emphasis on the Small Business Innovation and Research (SBIR) program. We serve more than 30 clients in 17 states and other countries on a yearly basis. \n Job Types: Contract, Part-time \n Salary: $76,000.00 - $96,000.00 per year \n Benefits: \n \n Flexible schedule \n \n Compensation package: \n \n Bonus opportunities \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 8 hour shift \n Day shift \n Holidays \n Monday to Friday \n Night shift \n On call \n Weekends as needed \n \n Experience: \n \n Scientific and/or technical writing: 1 year (Required) \n Successful grant writing with proven track record of winning: 3 years (Preferred) \n Technology and/or biotechnology product development: 3 years (Preferred) \n Proposal development for NIH: 3 years (Preferred) \n Proposal development for NSF: 3 years (Preferred) \n Proposal development for DoD: 3 years (Preferred) \n Scientific methods research: 3 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " \u25cf Identify the fit between granting agencies\u2019 research needs and the end-client product roadmap and technical focus. \n \u25cf Perform literature/product searches on new ideas to understand and assess novel advancements as they relate to the end client product roadmap. \n \u25cf Work closely with technical and business staff in developing and transforming ideas into grant proposals. \n \u25cf Maintain comprehensive and up-to-date knowledge of platform technological advances and particular market areas involved in identifying and soliciting grants. \n \u25cf Draft high-quality written grant applications; translate scientific abstracts into lay terms. \n \u25cf Assist with assembling scientific documents as necessary (e.g., large institutional grants, annual/occasional reports, progress reports for grants admin., etc.). \n \u25cf May assist with planning and conducting educational courses and workshops. \n \u25cf All other duties as assigned. \n Necessary Qualifications: \n \u25cf Ph.D. with artificial intelligence, machine learning, and natural language processing background preferred. Postdoctoral fellows with grant writing experience are preferred. In lieu of a Ph.D., Master\u2019s Degree in biomedical engineering, biostatistics, neuroscience, computer science or engineering, or relevant background with direct software or AI/ML experience will be considered. \n \u25cf Subject Matter Expert in the applied and real-world use of software and AI/ML in product development and grant-writing domain. \n \u25cf Minimum 1 year of scientific writing experience, preferably in a healthcare/research/academic environment. \n \u25cf Proven experience writing grants, including DoD, NSF, and/or NIH SBIR proposals, and/or experience with other funding mechanisms preferred. \n \u25cf Technical expertise to include one or more of the following (or similar): system-level software and hardware architectures; cloud-deployed architectures; ML for clustering, classification, and regression tasks; neural networks / multi-layer perceptron models/ensembles; deep neural networks; Natural Language Processing; among others. ", "techs": ["artificial intelligence", "machine learning", "natural language processing", "biomedical engineering", "biostatistics", "neuroscience", "computer science", "software", "ai/ml", "scientific writing", "dod", "nsf", "nih sbir", "system-level software", "hardware architectures", "cloud-deployed architectures", "ml", "clustering", "classification", "regression tasks", "neural networks", "multi-layer perceptron models", "ensembles", "deep neural networks", "natural language processing"]}, "a1bc11fb1a2ae926": {"terms": ["data science", "machine learning engineer"], "salary_min": 180000.0, "salary_max": 250000.0, "title": "Principal Bioinformatics Data Scientist, Liquid Biopsy", "company": "Tempus", "desc": "Passionate about precision medicine and advancing the healthcare industry? \n  Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time for our expanding liquid biopsy portfolio (including diagnostics, therapy selection, molecular residual disease testing and therapeutic response monitoring). \n  We are looking for a highly motivated and capable bioinformatics data scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical/machine learning modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting. \n  Responsibilities: \n \n Develop novel algorithms and statistical/machine learning models using genetic and epigenetic NGS data to detect highly sensitive biomarkers used to gain insight into cancer variation. \n Design and conduct analyses to improve methylation and variant calling, artifact filtering, quality control systems, variant classification and biomarker discovery. \n Design and execute experiments to support various regulatory submissions. \n Translate molecular insights into predictors and classifiers of therapeutic response and prognosis in clinical cancer care. \n Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care. \n Lead an interdisciplinary group of bioinformaticians, data scientists, and engineers to translate research into clinically actionable insights for our clients. \n Communicate with outside scientific teams as well as product and scientific leadership. \n Produce high quality and detailed documentation for all projects. \n \n Preferred Qualifications: \n \n Must have completed a Ph.D. in genetics, biomedical informatics, or related life sciences areas. \n At least 10 years of postdoc or industry experience. \n Computational skills using Python (preferred) and/or R. \n Experience working in cancer genetics, immunology, and/or biomarker discovery. \n \n Ideal candidates will possess: \n \n Experience working with Next-Generation Sequencing Data. \n Experience building NGS pipelines in a clinical setting. \n Experience in implementing and parallelizing pipelines in cloud computing environments. \n Expertise in algorithmic development, statistical models, and machine learning techniques. \n Self-driven and works well in interdisciplinary teams. \n Experience leading project teams of scientists and/or software engineers. \n Experience with communicating insights and presenting concepts to a diverse audience. \n Demonstrated knowledge in best-practice coding processes and data change control. \n Strong background in predictive or prognostic algorithm development. \n \n \n \n  #LI-EH1 \n #LI-Hybrid \n #LI-Remote \n \n \n    The expected salary range below is applicable if the role is performed from [\n    California ] and may vary for other locations. Actual salary may vary based on qualifications and experience. Tempus offers a full range of benefits, which may include incentive compensation, restricted stock units, medical and other benefits, depending on the position.\n   \n  California Pay Range \n \n    $180,000\u2014$250,000 USD\n   \n \n \n  We are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.", "cleaned_desc": "Passionate about precision medicine and advancing the healthcare industry? \n  Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time for our expanding liquid biopsy portfolio (including diagnostics, therapy selection, molecular residual disease testing and therapeutic response monitoring). \n  We are looking for a highly motivated and capable bioinformatics data scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical/machine learning modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting. \n  Responsibilities: \n \n Develop novel algorithms and statistical/machine learning models using genetic and epigenetic NGS data to detect highly sensitive biomarkers used to gain insight into cancer variation. \n Design and conduct analyses to improve methylation and variant calling, artifact filtering, quality control systems, variant classification and biomarker discovery. \n Design and execute experiments to support various regulatory submissions. \n Translate molecular insights into predictors and classifiers of therapeutic response and prognosis in clinical cancer care.   Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care. \n Lead an interdisciplinary group of bioinformaticians, data scientists, and engineers to translate research into clinically actionable insights for our clients. \n Communicate with outside scientific teams as well as product and scientific leadership. \n Produce high quality and detailed documentation for all projects. \n \n Preferred Qualifications: \n \n Must have completed a Ph.D. in genetics, biomedical informatics, or related life sciences areas. \n At least 10 years of postdoc or industry experience.   Computational skills using Python (preferred) and/or R. \n Experience working in cancer genetics, immunology, and/or biomarker discovery. \n \n Ideal candidates will possess: \n \n Experience working with Next-Generation Sequencing Data. \n Experience building NGS pipelines in a clinical setting. \n Experience in implementing and parallelizing pipelines in cloud computing environments. \n Expertise in algorithmic development, statistical models, and machine learning techniques.   Self-driven and works well in interdisciplinary teams. \n Experience leading project teams of scientists and/or software engineers. \n Experience with communicating insights and presenting concepts to a diverse audience. \n Demonstrated knowledge in best-practice coding processes and data change control. \n Strong background in predictive or prognostic algorithm development. \n \n \n \n  #LI-EH1 ", "techs": ["ai", "tempus' proprietary platform", "liquid biopsy portfolio", "diagnostics", "therapy selection", "molecular residual disease testing", "therapeutic response monitoring", "bioinformatics data scientist", "translational cancer research", "genomics algorithm development", "scientific programming", "relational data systems", "algorithms development", "statistical/machine learning modeling", "ngs pipeline development", "genetic and epigenetic ngs data", "methylation", "variant calling", "artifact filtering", "quality control systems", "variant classification", "biomarker discovery", "molecular insights", "predictors", "classifiers", "therapeutic response", "prognosis", "cancer clinical sequencing data", "interdisciplinary group", "bioinformaticians", "engineers", "geneticists", "biomedical informatics", "life sciences", "python", "r", "cancer genetics", "immunology", "biomarker discovery", "next-generation sequencing data", "ngs pipelines", "cloud computing environments", "algorithmic development", "statistical models", "machine learning techniques", "self-driven", "interdisciplinary teams", "project teams", "software engineers", "communicating insights", "presenting concepts", "coding processes", "data change control", "predictive algorithm development", "prognostic algorithm development"]}, "ab33c7867dabdd85": {"terms": ["data science"], "salary_min": 94500.0, "salary_max": 196000.0, "title": "Senior Data Scientist, Digital Personalization", "company": "CVS Health", "desc": "Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u2014 with heart at its center \u2014 our purpose sends a personal message that how we deliver our services is just as important as what we deliver.    Our Heart At Work Behaviors\u2122 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. \n \n  Summary : \n  CVS is aiming to inspire customers to consistently choose us as their health and wellness go-to retailer by delivering the most relevant and rewarding personalized experiences through a world-class personalization and loyalty program. \n   \n This is a top initiative within the company, and we have a team dedicated to recruiting the best talent in the world to help propel us to this goal. The company has invested in state-of-the-art technology, scaling of our loyalty program, and deep expertise in analytics and data science to continuously strive for excellence and innovation in this space. As part of the Analytics & Behavior Change function, the Retail, Front Store Growth Analytics team helps lead our mission to be a customer-centric, data-driven organization. This team aggressively tracks and helps grow CVS\u2019 customer journeys through franchise by identifying opportunities and optimizing customer strategies derived by analyzing trends in customer shopping behavior, needs, intents, and responses. The team leverages advanced analytics, machine learning, and a hypothesis-driven approach to quickly transform data into actionable, customer-centric insights in fast-moving and energizing environment. \n   \n \n  We are looking for the best, the brightest and the most passionate analytics visionaries to join our team and help us deliver on this initiative in this end to end applied data science role with emphasis on building solutions from scratch to solve business problems and high-performing ML models that will allow for deep personalized customer experience.\n   \n  Specific job duties typically include:\n   \n \n Experience working with natural language processing (NLP), large language models (LLMs), generative models, or deep learning \n Ability to connect business unit value and practical applications (improve experience, automate tasks, etc.) \n Deep technical depth and experience leveraging statistics, data analysis, data science and visualizations to drive business insights while ensures insights are both actionable and measurable \n Hands on technical lead who can drive analytics projects end-to-end, from conception to release \n Demonstrates strong ability to communicate technical concepts and implications to business partners \n \n \n \n  Required Qualifications: \n \n 3+ years of relevant work experience \n 3+ years of experience in SQL \n 2+ years developing and debugging in Python \n 2+ years of experience with experimental design and supervised/unsupervised machine learning approaches for regression and classification tasks \n 1+ years with deep machine learning frameworks such as TensorFlow, JAX, PyTorch \n \n \n  Preferred Qualifications: \n \n Research and implement statistical models, machine learning algorithms using methods such as NLP or LLM, and other customized solutions that show significant impact solving complex business problems  \n Working with Digital data will be a huge plus \n Write testable and production-level code and ship the code into production \n Process data from multiple sources via big data platforms (such as GCP) \n Enhance existing data pipelines by exploring unstructured data sources and engineering new features \n Work cross functionally to solve problems and identify trends and opportunities \n Provide technical and engineering support and expertise to the broader team \n \n \n  Education : \n  Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline.   \n Master\u2019s degree or PhD preferred. \n \n  Pay Range \n  The typical pay range for this role is: \n  $94,500.00 - $196,000.00\n  \n  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.    In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u2019s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201cPTO\u201d) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.    For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits \n \n  CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. \n \n  You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. \n \n  CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.", "cleaned_desc": "   \n \n Experience working with natural language processing (NLP), large language models (LLMs), generative models, or deep learning \n Ability to connect business unit value and practical applications (improve experience, automate tasks, etc.) \n Deep technical depth and experience leveraging statistics, data analysis, data science and visualizations to drive business insights while ensures insights are both actionable and measurable \n Hands on technical lead who can drive analytics projects end-to-end, from conception to release \n Demonstrates strong ability to communicate technical concepts and implications to business partners \n \n \n \n  Required Qualifications:   \n 3+ years of relevant work experience \n 3+ years of experience in SQL \n 2+ years developing and debugging in Python \n 2+ years of experience with experimental design and supervised/unsupervised machine learning approaches for regression and classification tasks \n 1+ years with deep machine learning frameworks such as TensorFlow, JAX, PyTorch \n \n \n  Preferred Qualifications: \n \n Research and implement statistical models, machine learning algorithms using methods such as NLP or LLM, and other customized solutions that show significant impact solving complex business problems    Working with Digital data will be a huge plus \n Write testable and production-level code and ship the code into production \n Process data from multiple sources via big data platforms (such as GCP) \n Enhance existing data pipelines by exploring unstructured data sources and engineering new features \n Work cross functionally to solve problems and identify trends and opportunities \n Provide technical and engineering support and expertise to the broader team \n \n \n  Education : \n  Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline.   \n Master\u2019s degree or PhD preferred. ", "techs": ["natural language processing (nlp)", "large language models (llms)", "generative models", "deep learning", "sql", "python", "experimental design", "supervised/unsupervised machine learning", "tensorflow", "jax", "pytorch", "big data platforms (such as gcp)"]}, "145f11e4f569ce4c": {"terms": ["data science"], "salary_min": 37.7, "salary_max": 58.1, "title": "Revenue Cycle Analyst - Revenue Integrity", "company": "Valley Children's Healthcare", "desc": "This senior-level analyst position is responsible for decision support and the proactive auditing?, ?trending and analyzing of ?various revenue cycle metrics and functions?, ?including making recommendations to management to ensure the continual ?improvement of the organization's revenue cycle? and payer reimbursement.? Accountable for the coordination and project management of revenue cycle and payor reimbursement related cross-departmental performance and process improvement projects. Serves as the department's primary reporting lead and provides consult, education and decision support on revenue cycle and payor reimbursement reporting best practices, ad hoc decision support and quality control to ensure data integrity, as well as develops sustainable executive dashboards and scorecards to assist in the ongoing analysis of the hospital's initiatives. \n \n  JOB REQUIREMENTS: This position requires a Bachelor's Degree in Business, Accounting, Finance, Math, Statistics, Health Administration, Data Science, Computer Science, or equivalent field. Minimum three years related work experience required. Epic Certification in Epic Resolute Hospital Billing Admin preferred. Epic Certification in Epic Provider Billing Admin preferred.  \n \n Broad based knowledge of hospital operations, including all aspects of the revenue cycle functions.  \n Broad based knowledge of hospital information and financial systems.  \n Maintains working knowledge of applicable Federal, State, and local laws and regulations pertaining to the revenue cycle.  \n Possess strong project management skills including the ability to adapt frequently to changing work priorities.  \n Possess strong written and verbal communication skills.  \n Possess the ability to achieve results in an independent manner.  \n Comfortable operating in a collaborative environment.  \n Possess advanced proficiency in the use of personal computers and experience in the use of software used in a typical office environment (e.g. word processing, spreadsheet, database, presentation, etc.), including the ability to manipulate large amounts of data in an automated and efficient manner.  \n Possess strong conceptual, problem solving and analytical skills. \n \n  POSITION DETAILS: Full-time, Days. Monday-Friday, 8:00am-5:00pm. Remote, California/local preferred.  \n PAY RANGE: $37.70-$58.10 \n  LOCATION: Madera, CA", "cleaned_desc": " Possess the ability to achieve results in an independent manner.  \n Comfortable operating in a collaborative environment.  \n Possess advanced proficiency in the use of personal computers and experience in the use of software used in a typical office environment (e.g. word processing, spreadsheet, database, presentation, etc.), including the ability to manipulate large amounts of data in an automated and efficient manner.  ", "techs": ["word processing", "spreadsheet", "database", "presentation"]}, "3f9d720c8e195edb": {"terms": ["data science"], "salary_min": 112000.0, "salary_max": 179000.0, "title": "Data Scientist Senior Technical Specialist", "company": "Peraton", "desc": "Peraton Overview \n  Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.\n  \n Responsibilities \n \n  We are looking to add a \n  Data Scientist Senior Technical Specialist  to our team. \n  \n \n What you'll do: \n \n \n Involved in the analysis of unstructured and semi-structured data, including latent semantic indexing (LSI), entity identification and tagging, complex event processing (CEP), and the application of analysis algorithms on distributed, clustered, and cloud-based high-performance infrastructures.  \n Exercises creativity in applying non-traditional approaches to large-scale analysis of unstructured data in support of high-value use cases visualized through multi-dimensional interfaces.  \n Handle processing and index requests against high-volume collections of data and high-velocity data streams.  \n Has the ability to make discoveries in the world of big data. Requires strong technical and computational skills - engineering, physics, mathematics, coupled with the ability to code design, develop, and deploy sophisticated applications using advanced unstructured and semi-structured data analysis techniques and utilizing high-performance computing environments.  \n Has the ability to utilize advance tools and computational skills to interpret, connect, predict and make discoveries in complex data and deliver recommendations for business and analytic decisions.  \n \n \n Qualifications \n \n \n Basic Qualifications: \n \n \n Bachelors degree and 12-15 years or Masters degree and 10-13 years or Phd 10+ years of experience  \n Experience with software development, either an open-source enterprise software development stack (Java/Linux/Ruby/Python) or a Windows development stack (.NET, C#, C++).  \n Experience with data transport and transformation APIs and technologies such as JSON, XML, XSLT, JDBC, SOAP and REST.  \n Experience with Cloud-based data analysis tools including Hadoop and Mahout, Acumulo, Hive, Impala, Pig, and similar.  \n Experience with visual analytic tools like Microsoft Pivot, Palantir, or Visual Analytics.  \n Experience with open source textual processing such as Lucene, Sphinx, Nutch or Solr.  \n Experience with entity extraction and conceptual search technologies such as LSI, LDA, etc. Experience with machine learning, algorithm analysis, and data clustering.  \n \n \n Benefits:  \n \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way. \n  \n \n Target Salary Range \n \n  $112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.\n  \n \n SCA / Union / Intern Rate or Range \n \n \n EEO \n  An Equal Opportunity Employer including Disability/Veteran.\n  \n \n Our Values \n \n \n Benefits \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.\n  \n \n  Paid Time-Off and Holidays \n  Retirement \n  Life & Disability Insurance \n  Career Development \n  Tuition Assistance and Student Loan Financing \n  Paid Parental Leave \n  Additional Benefits \n  Medical, Dental, & Vision Care", "cleaned_desc": " Exercises creativity in applying non-traditional approaches to large-scale analysis of unstructured data in support of high-value use cases visualized through multi-dimensional interfaces.  \n Handle processing and index requests against high-volume collections of data and high-velocity data streams.  \n Has the ability to make discoveries in the world of big data. Requires strong technical and computational skills - engineering, physics, mathematics, coupled with the ability to code design, develop, and deploy sophisticated applications using advanced unstructured and semi-structured data analysis techniques and utilizing high-performance computing environments.  \n Has the ability to utilize advance tools and computational skills to interpret, connect, predict and make discoveries in complex data and deliver recommendations for business and analytic decisions.  \n \n \n Qualifications \n \n \n Basic Qualifications: \n \n \n Bachelors degree and 12-15 years or Masters degree and 10-13 years or Phd 10+ years of experience    Experience with software development, either an open-source enterprise software development stack (Java/Linux/Ruby/Python) or a Windows development stack (.NET, C#, C++).  \n Experience with data transport and transformation APIs and technologies such as JSON, XML, XSLT, JDBC, SOAP and REST.  \n Experience with Cloud-based data analysis tools including Hadoop and Mahout, Acumulo, Hive, Impala, Pig, and similar.  \n Experience with visual analytic tools like Microsoft Pivot, Palantir, or Visual Analytics.  \n Experience with open source textual processing such as Lucene, Sphinx, Nutch or Solr.  \n Experience with entity extraction and conceptual search technologies such as LSI, LDA, etc. Experience with machine learning, algorithm analysis, and data clustering.  \n \n \n Benefits:  \n \n  At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way. \n  \n ", "techs": ["java", "linux", "ruby", "python", ".net", "c#", "c++", "json", "xml", "xslt", "jdbc", "soap", "rest", "hadoop", "mahout", "acumulo", "hive", "impala", "pig", "microsoft pivot", "palantir", "visual analytics", "lucene", "sphinx", "nutch", "solr", "lsi", "lda", "machine learning", "algorithm analysis", "data clustering."]}, "a3837b9895c5fddc": {"terms": ["data science", "machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Principal Bioinformatics Data Scientist, Liquid Biopsy", "company": "Tempus", "desc": "Passionate about precision medicine and advancing the healthcare industry? \n  Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time for our expanding liquid biopsy portfolio (including diagnostics, therapy selection, molecular residual disease testing and therapeutic response monitoring). \n  We are looking for a highly motivated and capable bioinformatics data scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical/machine learning modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting. \n  Responsibilities: \n \n Develop novel algorithms and statistical/machine learning models using genetic and epigenetic NGS data to detect highly sensitive biomarkers used to gain insight into cancer variation. \n Design and conduct analyses to improve methylation and variant calling, artifact filtering, quality control systems, variant classification and biomarker discovery. \n Design and execute experiments to support various regulatory submissions. \n Translate molecular insights into predictors and classifiers of therapeutic response and prognosis in clinical cancer care. \n Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care. \n Lead an interdisciplinary group of bioinformaticians, data scientists, and engineers to translate research into clinically actionable insights for our clients. \n Communicate with outside scientific teams as well as product and scientific leadership. \n Produce high quality and detailed documentation for all projects. \n \n Preferred Qualifications: \n \n Must have completed a Ph.D. in genetics, biomedical informatics, or related life sciences areas. \n At least 10 years of postdoc or industry experience. \n Computational skills using Python (preferred) and/or R. \n Experience working in cancer genetics, immunology, and/or biomarker discovery. \n \n Ideal candidates will possess: \n \n Experience working with Next-Generation Sequencing Data. \n Experience building NGS pipelines in a clinical setting. \n Experience in implementing and parallelizing pipelines in cloud computing environments. \n Expertise in algorithmic development, statistical models, and machine learning techniques. \n Self-driven and works well in interdisciplinary teams. \n Experience leading project teams of scientists and/or software engineers. \n Experience with communicating insights and presenting concepts to a diverse audience. \n Demonstrated knowledge in best-practice coding processes and data change control. \n Strong background in predictive or prognostic algorithm development. \n \n \n \n  #LI-EH1 \n #LI-Hybrid \n #LI-Remote \n \n  We are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.", "cleaned_desc": "Passionate about precision medicine and advancing the healthcare industry? \n  Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time for our expanding liquid biopsy portfolio (including diagnostics, therapy selection, molecular residual disease testing and therapeutic response monitoring). \n  We are looking for a highly motivated and capable bioinformatics data scientist with extensive experience and interest in translational cancer research and genomics algorithm development. This position requires experience with scientific programming, relational data systems, algorithms development, and statistical/machine learning modeling. Top candidates will also have leadership experience in NGS pipeline development in a clinical setting. \n  Responsibilities: \n \n Develop novel algorithms and statistical/machine learning models using genetic and epigenetic NGS data to detect highly sensitive biomarkers used to gain insight into cancer variation. \n Design and conduct analyses to improve methylation and variant calling, artifact filtering, quality control systems, variant classification and biomarker discovery.   Design and execute experiments to support various regulatory submissions. \n Translate molecular insights into predictors and classifiers of therapeutic response and prognosis in clinical cancer care. \n Collaborate with scientists, and clinicians to design and perform analyses on cancer clinical sequencing data in order to improve quality of care. \n Lead an interdisciplinary group of bioinformaticians, data scientists, and engineers to translate research into clinically actionable insights for our clients. \n Communicate with outside scientific teams as well as product and scientific leadership. \n Produce high quality and detailed documentation for all projects. \n   Ideal candidates will possess: \n \n Experience working with Next-Generation Sequencing Data. \n Experience building NGS pipelines in a clinical setting. \n Experience in implementing and parallelizing pipelines in cloud computing environments. \n Expertise in algorithmic development, statistical models, and machine learning techniques. \n Self-driven and works well in interdisciplinary teams.   Experience leading project teams of scientists and/or software engineers. \n Experience with communicating insights and presenting concepts to a diverse audience. \n Demonstrated knowledge in best-practice coding processes and data change control. \n Strong background in predictive or prognostic algorithm development. \n \n \n ", "techs": ["tempus' proprietary platform", "ngs pipeline development", "scientific programming", "statistical/machine learning modeling", "genetic and epigenetic ngs data analysis", "methylation and variant calling", "artifact filtering", "quality control systems", "variant classification", "biomarker discovery", "molecular insights", "therapeutic response and prognosis prediction", "clinical cancer care", "interdisciplinary collaboration", "bioinformaticians", "data scientists", "engineers", "ngs pipelines in a clinical setting", "cloud computing environments", "algorithmic development", "statistical models", "machine learning techniques", "project team leadership", "communicating insights", "best-practice coding processes", "data change control", "predictive or prognostic algorithm development."]}, "b9a3d616d8d0fb66": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 93300.0, "salary_max": 212000.0, "title": "MLOps Engineer, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Atlanta,GA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0181934\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         MLOps Engineer, Senior\n           The Opportunity: \n  As an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using Machine Learning (ML) techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support Public Health and Safety and Save citizens life. As a machine learning engineer on our Public Health CDC team, you\u2019ll train, test, deploy, and maintain models that learn from data. \n \n  In this role, you\u2019ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You\u2019ll be part of a large community of machine learning engineers across the firm and collaborate with data engineers, data scientists, solutions architects, Enterprise architects and product owners to deliver world class solutions to design, developed machine Learning Operations framework for entire enterprise and also be part of mentorship, training, and solutions to real world problem, Process data and information at a massive scale, perform A/B testing tasks on statistical models, ML algorithms, and systems. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. \n \n  Work with us to solve real-world challenges and define ML strategy for Public Health and protect America from health, safety, and security threats, both foreign and in the U.S. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience in a Big Data, analytics, data science, machine learning, or artificial intelligence technical delivery role, including data scientist, developer, architect, engineer, or machine learning specialist \n  3+ years of experience with DevOps or software engineering \n  2+ years of experience with programming, including machine learning frameworks, including TensorFlow, Keras, PyTorch, Caffe, Python, or MXNET \n  Knowledge of Agile and Scrum processes \n  Ability to stay abreast of current and emerging technologies to support new concept development, including emerging machine learning, data management, and AI capabilities with the real-time implementation of AI/ML software \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with Azure Machine Learning, Azure OpenAI, or Azure Cognitive \n  Experience in a healthcare or public health domain \n  Knowledge of Data Architecture and Data Integration \n  Azure Cloud Machine Learning , Databricks or Data Architecture, or Data Engineering Certification \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n \n \n         MLOps Engineer, Senior\n           The Opportunity: \n  As an experienced engineer, you know that machine learning is critical to understanding and processing massive datasets. Your ability to conduct statistical analyses on business processes using Machine Learning (ML) techniques makes you an integral part of delivering a customer-focused solution. We need your technical knowledge and desire to problem-solve to support Public Health and Safety and Save citizens life. As a machine learning engineer on our Public Health CDC team, you\u2019ll train, test, deploy, and maintain models that learn from data. \n \n  In this role, you\u2019ll own and define the direction of mission-critical solutions by applying best-fit ML algorithms and technologies. You\u2019ll be part of a large community of machine learning engineers across the firm and collaborate with data engineers, data scientists, solutions architects, Enterprise architects and product owners to deliver world class solutions to design, developed machine Learning Operations framework for entire enterprise and also be part of mentorship, training, and solutions to real world problem, Process data and information at a massive scale, perform A/B testing tasks on statistical models, ML algorithms, and systems. Your advanced consulting skills and extensive technical expertise will guide clients as they navigate the landscape of ML algorithms, tools, and frameworks. \n \n  Work with us to solve real-world challenges and define ML strategy for Public Health and protect America from health, safety, and security threats, both foreign and in the U.S. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience in a Big Data, analytics, data science, machine learning, or artificial intelligence technical delivery role, including data scientist, developer, architect, engineer, or machine learning specialist    3+ years of experience with DevOps or software engineering \n  2+ years of experience with programming, including machine learning frameworks, including TensorFlow, Keras, PyTorch, Caffe, Python, or MXNET \n  Knowledge of Agile and Scrum processes \n  Ability to stay abreast of current and emerging technologies to support new concept development, including emerging machine learning, data management, and AI capabilities with the real-time implementation of AI/ML software \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with Azure Machine Learning, Azure OpenAI, or Azure Cognitive \n  Experience in a healthcare or public health domain \n  Knowledge of Data Architecture and Data Integration \n  Azure Cloud Machine Learning , Databricks or Data Architecture, or Data Engineering Certification \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n ", "techs": ["mlops engineer", "senior", "machine learning", "ml algorithms", "technologies", "data engineers", "data scientists", "solutions architects", "enterprise architects", "product owners", "machine learning operations framework", "mentorship", "training", "a/b testing", "statistical models", "ml algorithms", "systems", "big data", "analytics", "data science", "artificial intelligence", "devops", "software engineering", "programming", "tensorflow", "keras", "pytorch", "caffe", "python", "mxnet", "agile", "scrum", "emerging technologies", "concept development", "data management", "ai capabilities", "ai/ml software", "azure machine learning", "azure openai", "azure cognitive", "healthcare", "public health", "data architecture", "data integration", "azure cloud machine learning", "databricks", "data engineering certification"]}, "219bae3a16c4bc4a": {"terms": ["data science", "mlops"], "salary_min": 109260.09, "salary_max": 138347.62, "title": "Senior Data Scientist (Experienced Level Professional)", "company": "Michelin", "desc": "Senior Data Scientist (Experienced Level Professional)\n  \n \n   Michelin is hiring!\n  \n \n   - - - - - - - - - - - -\n  \n \n  THIS OPEN POSITION IS LOCATED ONLY AT THE FOLLOWING LOCATIONS:Michelin North America HQ \n \n \n \n  THE \u201cADDITIONAL LOCATIONS\u201d SHOWN AT THE RIGHT INDICATE WHERE THIS JOB POSTING IS VISIBLE, NOT WHERE THE POSITION IS LOCATED \n \n \n \n   Michelin is hiring! We are looking for a data scientist to join our company be a key player in our IT Business Intelligence & Analytics team.\n  \n \n \n   Overview:\n  \n \n   The Senior Data Scientist manages and analyses disparate datasets, researches and implements Machine Learning and Advanced Analytics (ARIMA, optimization, etc) solutions to address complex business questions. He/ She will collaborate with Business leaders across the company to accelerate the development and deployment of Artificial Intelligence (AI) / Machine Learning (ML) models, and influence and innovate solutions that impact the business.\n  \n \n   This job opportunity is open to 100% remote work if needed.\n  \n \n \n   What you'll do:\n  \n \n   Partner with the business to scope out opportunities and potential value creation.\n  \n \n   Master the Supply Chain, Logistics, Manufacturing, Marketing and Sales value chains.\n  \n \n   Determine the relevant data among those available and identifying the missing data to acquire to successfully implement the opportunity.\n  \n \n   Explore, select, and create features to build models.\n  \n \n   Fit and evaluates Machine Learning/Advanced Analytics/Advanced Statistics models to solve the business problem and satisfy acceptance criteria.\n  \n \n   Present the results and the model (performances and limits) to business leadership and lead technical discussions for model improvement.\n  \n \n   Design, build, and automate all steps of the Machine Learning (MLOps) industrialization workflow.\n  \n \n   Collaborate with product managers and internal partners to automate integrated AI/ML systems.\n  \n \n   Develop partnerships, standard processes, network and knowledge by :\n  \n \n  Mentoring less experienced people \n  Transmitting knowledge by development and deployment of training modules and various other communication methods \n  Participating in the development of the Data Science Roadmap and Network \n  Accelerating the adoption of Artificial Intelligence across the enterprise through the use of machine learning, modern architecture and software engineering best practices \n \n \n \n   What you\u2019ll bring:\n  \n \n   Bachelor\u2019s Degree or greater in Statistics, Applied Mathematics, Computer Science Information Systems or equivalent.\n  \n \n   Must have experience with data science methodology and techniques: Exploratory Data Analysis, Feature Engineering, Cross Validation, Visualization, Advanced Analytics, Machine Learning, Predictive Modeling\n  \n \n   Relevant software development skills with Python and PySpark; proficiency using Azure Service, Databricks and software repositories.\n  \n \n   Exposure/experience putting into production models with MLOps: CI/CD workflows with a Product approach.\n  \n \n   Collaborate and work within an international team environment.\n  \n \n \n \n    #LI-RG1\n   \n \n    #LI-hiringmichelin\n   \n \n \n \n   Inspire Motion for Life: Apply Today!\n  \n \n \n   As the leading mobility company, we work with tires, around tires and beyond tires to enable Motion for Life. Dedicated to enhancing our clients\u2019 mobility and sustainability, Michelin designs and distributes the most suitable tires, services and solutions for our customers\u2019 needs. Michelin provides digital services, maps and guides to help enrich trips and travels and make them unique experiences. Bringing our expertise to new markets, we invest in high-technology materials, 3D printing and hydrogen, to serve a wide a variety of industries\u2014from aerospace to biotech. Headquartered in Greenville, South Carolina, Michelin North America has approximately 23,000 employees and operates 34 production facilities in the United States and Canada.\n  \n \n \n   MICHELIN\u00ae tires have been ranked the #1 Tire Brand across major categories and segments by industry experts and consumers alike. For nearly three decades we\u2019ve been recognized for our achievements in Customer Satisfaction, Performance, Durability, Technology and Innovation.\n  \n \n \n   Michelin cares for the personal and professional development of its employees. We support career advancement through various options, which include: skill and career development, training, career exploration and work with cross-functional teams. We offer the possibility of a varied and fulfilling career path in an environment where unique contributions are valued.\n  \n \n \n   Michelin offers 10 Business Resource Groups (BRGs) which are all-inclusive groups created and led by employees who have shared life experiences across various diversity dimensions. Each group supports business strategies and initiatives along with meeting the needs of members. The goal of each group is to help employees feel welcome and included, support employee engagement and encourage professional development. BRGs also provide cross-cultural support, career management resources and opportunities for community involvement.\n  \n \n \n   Michelin provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), parental status, national origin, age, disability, genetic information (including family medical history), political affiliation, military service, or other non-merit-based factors. Consistent with these obligations, Michelin also provides reasonable accommodations to employees and applicants with disabilities and for sincerely held religious beliefs. If you need accommodation for any part of the employment process because of a disability, please contact us at \n   \n   accommodations@michelin.com\n   .\n  \n \n \n   This position is not available for immigration sponsorship.\n  \n \n \n  Get in the driver\u2019s seat and be on your way to a meaningful professional journey!", "cleaned_desc": "  \n \n   Design, build, and automate all steps of the Machine Learning (MLOps) industrialization workflow.\n  \n \n   Collaborate with product managers and internal partners to automate integrated AI/ML systems.\n  \n \n   Develop partnerships, standard processes, network and knowledge by :\n  \n \n  Mentoring less experienced people \n  Transmitting knowledge by development and deployment of training modules and various other communication methods \n  Participating in the development of the Data Science Roadmap and Network \n  Accelerating the adoption of Artificial Intelligence across the enterprise through the use of machine learning, modern architecture and software engineering best practices \n \n \n \n   What you\u2019ll bring:\n  \n \n   Bachelor\u2019s Degree or greater in Statistics, Applied Mathematics, Computer Science Information Systems or equivalent.\n  \n \n   Must have experience with data science methodology and techniques: Exploratory Data Analysis, Feature Engineering, Cross Validation, Visualization, Advanced Analytics, Machine Learning, Predictive Modeling", "techs": ["machine learning", "mlops", "ai/ml systems", "data science roadmap", "artificial intelligence", "machine learning", "modern architecture", "software engineering"]}, "6805360b13967ec5": {"terms": ["data science"], "salary_min": 89715.945, "salary_max": 113600.38, "title": "Senior PeopleSoft Business System Analyst", "company": "IQVIA", "desc": "Job Overview( 100% Remote)  Provides expertise and system support in developing and enhancing business systems to provide new or enhanced products to internal clients for effective planning, reporting and analysis. \n \n  Essential Functions \n \n  Working knowledge of PeopleSoft Financial modules to include Projects and Contracts. \n  Under general direction, formulates and defines systems scope and objectives based on both user needs and a good understanding of applicable business systems and requirements. \n  Devises or modifies procedures to solve complex problems considering equipment capacity and limitations, operating time, and form of desired results. \n  Includes analysis of business and user needs, documentation of requirements, and translation into proper system requirement specifications. \n  Guides and advises less-experienced Business Systems Analysts. \n  Competent to work at the highest technical level of most phases of systems analysis while considering the business implications of the application of technology to the current and future business environment. \n  Business analysis planning and monitoring \n  Elicitation and collaboration \n  Requirements life cycle management \n  Strategy analysis \n  Requirements analysis and design definition \n  Solution evaluation \n  Troubleshoots systems issues \n  Develop mitigation strategy for production issues and management of escalations \n  Devises and/or modifies procedures to solve complex problems considering system capacity, limitations, operating time and for formulating desired results. \n \n \n  Qualifications \n \n  Bachelor's Degree Computer Science or Business Administration, or equivalent experience Req \n  Five (5) years PeopleSoft Finance systems analysis experience or equivalent combination of education and experience \n  Knowledge of PeopleSoft Systems \n \n \n  Technical Abilities  \n \n Four or more years of experience in reading and creating SQL (Read and Write Simple Queries) \n  Four or more years of experience utilizing an understanding of PeopleSoft architecture and table structures. \n  Four or more years of experience utilizing PeopleSoft Application Designer as a reference tool for functional design, support, and troubleshooting. \n  Four or more years of experience in supporting integrations (IB) into PeopleSoft \n \n \n  IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible \u2013 to help our customers create a healthier world. Learn more at https://jobs.iqvia.com \n \n  We are committed to providing equal employment opportunities for all, including veterans and candidates with disabilities. https://jobs.iqvia.com/eoe \n \n  IQVIA\u2019s ability to operate and provide certain services to customers and partners necessitates IQVIA and its employees meet specific requirements regarding COVID-19 vaccination status. https://jobs.iqvia.com/covid-19-vaccine-status", "cleaned_desc": "  Five (5) years PeopleSoft Finance systems analysis experience or equivalent combination of education and experience \n  Knowledge of PeopleSoft Systems \n \n \n  Technical Abilities  \n \n Four or more years of experience in reading and creating SQL (Read and Write Simple Queries) \n  Four or more years of experience utilizing an understanding of PeopleSoft architecture and table structures. ", "techs": ["peoplesoft finance systems", "peoplesoft systems", "sql"]}, "d2b62a8714c69a0f": {"terms": ["data science"], "salary_min": 40.0, "salary_max": 60.0, "title": "Contract Statistician", "company": "Hire Minded", "desc": "Job Summary: We are seeking a highly skilled and motivated Statistician with clinical research experience to join our team. The ideal candidate will have a strong background in statistics, a deep understanding of clinical research methodologies, and expertise in using R and creating forest plots. In this role, you will play a crucial part in designing, analyzing, and interpreting data from clinical research studies, contributing to the advancement of medical knowledge and patient care. \n Key Responsibilities: \n Study Design and Planning: \n \n Collaborate with research teams to design and plan clinical studies, including sample size calculations, randomization strategies, and data collection methods. \n Develop statistical analysis plans (SAPs) to guide data analysis and ensure study objectives are met. \n \n Data Analysis: \n \n Perform statistical analyses on clinical research data using R and other relevant software. \n Implement advanced statistical techniques to address research questions and hypotheses. \n Conduct exploratory data analysis to identify patterns and trends in the data. \n \n Forest Plot Creation: \n \n Generate forest plots to visualize and communicate the results of meta-analyses and clinical trials. \n Ensure that forest plots are clear, accurate, and conform to industry standards. \n \n Statistical Modeling: \n \n Apply various statistical models, such as regression analysis, survival analysis, and multivariate analysis, to assess clinical outcomes and treatment effects. \n Conduct sensitivity analyses to test the robustness of findings. \n \n Data Interpretation and Reporting: \n \n Summarize and interpret statistical results in a clear and meaningful way for both technical and non-technical audiences. \n Prepare statistical reports and contribute to research publications. \n \n Quality Assurance: \n \n Ensure data integrity and accuracy throughout the research process. \n Collaborate with cross-functional teams to maintain the highest standards of research quality. \n \n Compliance and Ethics: \n \n Adhere to ethical guidelines and regulations governing clinical research and data analysis. \n \n Continuous Learning: \n \n Stay current with advancements in statistical methodologies and clinical research best practices. \n \n Qualifications: \n \n Master's or Ph.D. in Statistics, Biostatistics, Epidemiology, or a related field. \n Proven experience in clinical research, with a strong understanding of clinical trial design and methodology. \n Proficiency in R for statistical analysis and data visualization, including forest plot creation. \n Strong statistical modeling skills, including familiarity with advanced statistical techniques. \n Excellent problem-solving and critical-thinking abilities. \n Effective communication skills, with the ability to explain complex statistical concepts to non-technical stakeholders. \n Attention to detail and commitment to data accuracy. \n Familiarity with regulatory requirements for clinical research (e.g., FDA guidelines) is a plus. \n \n Job Type: Contract \n Pay: $40.00 - $60.00 per hour \n Expected hours: 1 \u2013 20 per week \n Experience level: \n \n 5 years \n \n Schedule: \n \n Choose your own hours \n \n Work Location: Remote", "cleaned_desc": " \n Continuous Learning: \n \n Stay current with advancements in statistical methodologies and clinical research best practices. \n \n Qualifications: \n \n Master's or Ph.D. in Statistics, Biostatistics, Epidemiology, or a related field. \n Proven experience in clinical research, with a strong understanding of clinical trial design and methodology. \n Proficiency in R for statistical analysis and data visualization, including forest plot creation. \n Strong statistical modeling skills, including familiarity with advanced statistical techniques. \n Excellent problem-solving and critical-thinking abilities. ", "techs": ["r"]}, "960e1732111e2b5b": {"terms": ["data science"], "salary_min": 65883.08, "salary_max": 83422.66, "title": "Supply Chain Analyst", "company": "Elemental Enzymes", "desc": "Supply Chain Analyst \n \n  Elemental Enzymes is seeking a process and data-oriented, highly-collaborative team member to join our organization as a full-time Supply Chain Analyst. This role will be instrumental in establishing critical process and communication methodologies for a growing organization. The Supply Chain Analyst will sit within in our Global Manufacturing Organization and will be responsible for recommending and establishing communication standards, dashboards, and data analysis for best practices/industry standards, including documentation. The successful candidate will be self-motivated, thrive in a changing environment, and leverage both talent and experience in cross-functional communication to drive results through a matrix organization. \n \n  Job Description \n \n Data Analysis \n \n  o Evaluate current data and KPIs for proactive recommendations and leadership decisions \n  o Validate and audit data capture to ensure accuracy in reporting \n \n Communications and Dashboards \n \n  o Recommend and/or establish tracking processes to support operational standards, targets, and long-range planning \n  o Able to develop communications roadmap for growing matrix organization needs with a focus on sustainable, clear, and consistent insights that drive actions/decisions within Leadership \n \n Cross-functional (Matrix) Collaboration \n \n  o Collaborate with and drive results through matrix teams across a majority of the organization to ensure appropriate data capture and communication from Product Pipeline through Sales Targets \n  o Confidence in raising questions, communicating recommendations, and driving results across teams and platforms to ensure data capture and analysis are meeting EE needs \n \n Continuous Improvement and Strategy \n \n  o Focus on establishing appropriate platform, stabilizing, and identifying continuous improvement opportunities for a successful Manufacturing and Supply Chain organization \n  o Documentation and tracking of processes and protocols to ensure practices are being followed and align with strategic objectives \n  o Lead value stream mapping sessions to ensure product and information flow is optimized \n \n Project Management \n \n  o Proven ability to lead cross-functional projects and drive results supporting key strategic initiatives \n \n  Qualifications: \n \n Bachelor's Degree in Business Analytics, Supply Chain, Logistics, Data Science or related field \n \n  o MBA preferred \n  o Supply Chain certification preferred \n \n 3+ years experience in similar role, including Global Operations \n \n \n 3+ years working experience and proficiency in digital data analysis platforms \n \n \n Demonstrated ability to provide descriptive, predictive, and prescriptive data analysis as well as create models and forecasting tools to evaluate scenarios \n \n \n Demonstrated ability to create data visual tools such as dashboards in Excel or other programs (ex: Tableau, Power BI, etc.) \n \n \n Highly-developed attention to detail and problem-solving skills \n \n \n Process improvement and Project Management experience preferred (Six Sigma belt certification, and PMP certification preferred) \n \n \n Experience with Lean, Six Sigma, similar methodologies preferred \n \n  Physical Requirements: \n \n Alternate Sitting or Standing at will \n \n \n Lifting or Carrying - 10 lbs or less, as needed for PC, office materials, etc \n \n \n Keyboarding - entering data by use of a traditional keyboard \n \n \n Gross Manipulation - seizing, holding, grasping, turning, or otherwise working with your hands \n \n \n Fine Manipulation - touching, picking, pinching, or otherwise working with your fingers \n \n \n Speaking - expressing or exchanging ideas by means of the spoken word \n \n \n Hearing Requirements - the ability to hear, understand, and distinguish speech and/or other sounds \n \n \n Near Visual Acuity - clarity of vision at approximately 20 inches or less (including use of computers) \n \n \n  Job Location: St. Louis, MO, United States or Remote \n  Position Type: Full-Time/Regular/Salary/Exempt \n  Salary: Competitive base \n  Benefits: Employee Stock Options, 401K, Healthcare, Dental, Vision, Life, HAS/FSA \n \n  About Elemental Enzymes: \n  Elemental Enzymes was founded upon the simple belief that we must do everything we can to improve agricultural performance in a way that not only enables plants to flourish but enriches and renews the planet with eco-friendly and sustainable agricultural solutions. From products that enable effective enzymes, peptide and protein inputs to foliar treatments that hold the promise to renew entire industries, our focus is to make a positive difference in the world through people \u2013 like you and me. Success is a byproduct of responsible production. That is why Elemental Enzymes works to bring cross-disciplinary scientists and processes together to create novel solutions to practical problems with a shared goal of helping both the plant and the planet. \n \n  Apply: \n  Please complete the application and submit your resume and cover letter to the open job posting on Bamboo HR. References may be required upon request", "cleaned_desc": "  o Collaborate with and drive results through matrix teams across a majority of the organization to ensure appropriate data capture and communication from Product Pipeline through Sales Targets \n  o Confidence in raising questions, communicating recommendations, and driving results across teams and platforms to ensure data capture and analysis are meeting EE needs \n \n Continuous Improvement and Strategy \n \n  o Focus on establishing appropriate platform, stabilizing, and identifying continuous improvement opportunities for a successful Manufacturing and Supply Chain organization \n  o Documentation and tracking of processes and protocols to ensure practices are being followed and align with strategic objectives \n  o Lead value stream mapping sessions to ensure product and information flow is optimized \n \n Project Management \n \n  o Proven ability to lead cross-functional projects and drive results supporting key strategic initiatives \n \n  Qualifications: \n \n Bachelor's Degree in Business Analytics, Supply Chain, Logistics, Data Science or related field \n \n  o MBA preferred    o Supply Chain certification preferred \n \n 3+ years experience in similar role, including Global Operations \n \n \n 3+ years working experience and proficiency in digital data analysis platforms \n \n \n Demonstrated ability to provide descriptive, predictive, and prescriptive data analysis as well as create models and forecasting tools to evaluate scenarios \n \n \n Demonstrated ability to create data visual tools such as dashboards in Excel or other programs (ex: Tableau, Power BI, etc.) \n \n \n Highly-developed attention to detail and problem-solving skills \n \n \n Process improvement and Project Management experience preferred (Six Sigma belt certification, and PMP certification preferred) ", "techs": ["excel", "tableau", "power bi"]}, "535c682194d51080": {"terms": ["data science"], "salary_min": 85000.0, "salary_max": 167300.0, "title": "Reporting and Optimization Sr Specialist-Optum-Remote", "company": "Optum", "desc": "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best.\n     Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale.\n     Join us to start \n   Caring. Connecting. Growing together. \n \n \n \n  Why Optum Financial? \n  Optum Financial is one of UHG\u2019s five strategic pillars. We\u2019re highly profitable and growing fast \u2013 which is a great place to be from a career standpoint. We are leading the charge on customer centricity and we\u2019re a true innovator \u2013 we\u2019re rapidly growing new lending products for providers and hospital systems that\u2019s not been seen before in the market. Our aspirations are big. \n \n \n  We need marketers who are hungry, smart, and conscientious. Functional passion and expertise matter \u2013 we want people who know how to do \u201ctheir thing\u201d really, really well. Experience and the desire to look outside of health care is essential. We want to elevate our industry to a whole new level and that means you know what greatness looks like in your domain. \n \n   \n Optum Financial is passionate about giving people a career path within the business as we grow. We want to see people crush their roles, overdeliver, coach others and step into bigger opportunities over time. \n \n   \n Let\u2019s get exponential \n  The Reporting and Optimization Sr Specialist is someone innately curious, an unrelenting problem solver, and uses XLS and SQL like magic wands. In this role, you will drive the ability for the provider services marketing team to make decisions informed by data to deliver on aggressive revenue targets. This will require you to establish a singular source of marketing performance results, connecting it with relevant data sets, allowing us to strategize, forecast, and track success. You will be responsible for providing actionable analysis to inform marketing strategy and spend decisions. Not just a numbers person, you will also play in the experimentation sandbox by designing sophisticated multivariate tests across multiple lead generation channels that yield more-than-incremental optimizations. As also a people person, you will collaborate cross-functionally with the consumer office, finance, operations, product, technology, account management and legal & compliance teams to contribute to the execution of high-visibility marketing programs that shatter ROI benchmarks. \n \n \n \n   You\u2019ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges.\n  \n \n \n \n  Primary Responsibilities: \n \n \n Build an automated dashboard to track marketing impact across the full customer lifecycle, integrating data sets from marketing, sales, customer service/ops, finance, and product owners \n Compile disparate audience data sets from multiple stakeholders into a consolidated target market dashboard ensuring data integrity and ongoing maintenance for on-demand segment analysis and list pulls for channel activities \n Manage sophisticated manipulation of customer lists in XLS to remove duplicates, randomize data, and cross-reference with other data sets \n Build complex tables to perform analysis of aggregated data, presenting insights to drive marketing decisions \n Design, conduct, and analyze A/B and multivariate tests across high-performance channels including email, digital advertising, and direct mail, aimed at boosting lead generation and sales conversion \n Use a mix of creativity and analytical skills to identify new targeting and channel strategies through experiments informed by market trends and competitive activity \n Audit performance results across the full customer lifecycle to develop hypotheses and the marketing strategy for an optimization and testing plan to improve conversion and customer experience \n Other duties as determined by supervisor \n \n \n \n \n   You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.\n  \n  Required Qualifications: \n \n 5+ years of experience related to this business  \n Proven track record of successfully optimizing performance marketing campaigns across a range of digital marketing channels, including email marketing, in-app promotion, and paid advertising \n Demonstrated analytical approach to acquisition funnel metrics measurement, campaign performance, and optimizations, providing insights and analysis on all campaign key performance indicators (KPIs) and performance metrics \n Demonstrated expert level ability to manipulate data using XLS and SQL \n Demonstrated analysis of large sets of data that identified actionable trends, outliers, or insights \n Proven experience concepting, testing, and optimizing ad creative with demonstrated ability to develop and optimize performance marketing A/B testing and targeting plans across conversion efforts \n Demonstrated outstanding relationship-building and interpersonal skills. Must be able to build relationships across functions and levels with demonstrated ability to solve problems and work effectively in a team environment \n Demonstrated exceptional listening, verbal, and written communication skills with the ability to think quickly on your feet \n Ability to be a motivated, process-oriented self-starter with a high level of organization, efficient time-management, and attention to detail \n Demonstrated ability to work in a fast-paced environment with flexibility to accommodate demanding project schedules \n \n \n \n  Preferred Qualifications: \n \n Related degree \n 8+ years of experience related to this business  \n Demonstrated ability to quickly grasp highly technical, complex, financial concepts and easily articulate them to others \n Proven advanced knowledge of performance marketing tools like Google Analytics, Eloqua, Google AdWords, Facebook Business Manager, Optimizely, or others \n Proficiency with data visualization tools like PowerBI, Sprinklr, Domo, Looker Studio, Tableau, etc. \n Experience with comfort coding in languages like Python, R, ETL, etc. \n Experience with data science and predictive modeling \n \n \n \n \n   *All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy\n  \n \n \n \n  California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only:  The salary range for California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island or Washington residents is $85,000 to $167,300 per year. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives.\n  \n \n \n \n  At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age,  \n location and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission. \n \n \n \n \n  Diversity creates a healthier atmosphere:  \n UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employers and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. \n \n \n \n \n  UnitedHealth Group \n  is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.", "cleaned_desc": " \n \n  Preferred Qualifications: \n \n Related degree \n 8+ years of experience related to this business  \n Demonstrated ability to quickly grasp highly technical, complex, financial concepts and easily articulate them to others \n Proven advanced knowledge of performance marketing tools like Google Analytics, Eloqua, Google AdWords, Facebook Business Manager, Optimizely, or others \n Proficiency with data visualization tools like PowerBI, Sprinklr, Domo, Looker Studio, Tableau, etc. \n Experience with comfort coding in languages like Python, R, ETL, etc. \n Experience with data science and predictive modeling \n \n \n \n \n   *All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy\n  \n \n ", "techs": ["google analytics", "eloqua", "google adwords", "facebook business manager", "optimizely", "powerbi", "sprinklr", "domo", "looker studio", "tableau", "python", "r", "etl."]}, "90a701487524e628": {"terms": ["data science", "machine learning engineer"], "salary_min": 107176.93, "salary_max": 135709.88, "title": "Senior Data Scientist - Research (Remote)", "company": "Mercy", "desc": "We're a Little Different \n \n  Our mission is clear. We bring to life a healing ministry through our compassionate care and exceptional service. \n  \n  At Mercy, we believe in careers that match the unique gifts of unique individuals - careers that not only make the most of your skills and talents, but also your heart. Join us and discover why Modern Healthcare Magazine named us in its \"Top 100 Places to Work.\"\n  \n \n Overview: Senior Data Scientist - Research \n \n \n Position can be Remote (work from home) \n \n \n \n Please note that as of the posting date of this job announcement, Mercy is unable to offer immigration sponsorship or visa assistance for this position. We encourage all eligible candidates, including U.S. citizens, permanent residents, and those with existing work authorization, to apply. \n \n  Mercy is seeking a Senior Data Scientist to work within a team of other advanced professional data scientists, engineers, and application developers in the generation, extraction, and compilation of data to perform creative, high-quality, state-of-the-art analyses and evaluations that produce insights, support decision-making, and drive impact within a leading and transforming healthcare organization. This position will support Mercy's efforts to deliver on the vision of personalized, predictive, and proactive care. The candidate should demonstrate expertise with data extraction, management, analysis with data analytics tools, be able deliver outputs on a timeline, and lead others in the completion of related work. The candidate should be able to effectively document, develop, and communicate project plans and analytic findings with a variety of technical/non-technical stakeholders.\n  \n \n Qualifications: \n \n \n  Experience:  At least 4 years of experience in a similar role in academia or industry or PhD + 2 years in a similar role in academia or industry \n  Required Education:  Graduate degree in Public Health, Health Care Research, Epidemiology, Statistics, Data Science, Health Policy, Economic, Finance, Simulation/Simulation-Based Optimization, or related field. \n  Other:  \n Have a strong knowledge of electronic medical record data, clinical data, claims data, or financial data. \n \n  Technical Expertise: Proficiency in data analysis and programming languages such as Python, R, SQL, or other relevant tools commonly used in medical research. \n  Ability to quickly learn new analytic tools and packages \n  Strong background in statistical methods, including regression analysis, hypothesis testing, survival analysis, and machine learning algorithms. \n  Prior experience in medical or clinical research, working with healthcare-related datasets, and contributing to scientific publications is preferred. \n  Excellent problem-solving skills \n  Strong organizational skills, an orientation toward detail, and collaboration oriented.Present complex data (qualitative and quantitative) in a clear, concise, and compelling manner to both technical and non-technical audiences to inspire action. \n \n \n \n  We Offer Great Benefits: \n \n  Day-one comprehensive health, vision and dental coverage, PTO, tuition reimbursement and employer-matched retirement funds are just a few of the great benefits offered to eligible co-workers, including those working 32 hours or more per pay period!\n  \n \n We're bringing to life a healing ministry through compassionate care. \n \n  At Mercy, our supportive community will be behind you every step of your day, especially the tough ones. You will have opportunities to pioneer new models of care and transform the health care experience through advanced technology and innovative procedures. We're expanding to help our communities grow. Join us and be a part of it all.\n  \n \n What Makes You a Good Match for Mercy?  \n \n  Compassion and professionalism go hand-in-hand with us. Having a positive outlook and a strong sense of advocacy is in perfect step with our mission and vision. We're also collaborative and unafraid to do a little extra to deliver excellent care - that's just part of our commitment. If that sounds like a good fit for you, we encourage you to apply.", "cleaned_desc": " \n Position can be Remote (work from home) \n \n \n \n Please note that as of the posting date of this job announcement, Mercy is unable to offer immigration sponsorship or visa assistance for this position. We encourage all eligible candidates, including U.S. citizens, permanent residents, and those with existing work authorization, to apply. \n \n  Mercy is seeking a Senior Data Scientist to work within a team of other advanced professional data scientists, engineers, and application developers in the generation, extraction, and compilation of data to perform creative, high-quality, state-of-the-art analyses and evaluations that produce insights, support decision-making, and drive impact within a leading and transforming healthcare organization. This position will support Mercy's efforts to deliver on the vision of personalized, predictive, and proactive care. The candidate should demonstrate expertise with data extraction, management, analysis with data analytics tools, be able deliver outputs on a timeline, and lead others in the completion of related work. The candidate should be able to effectively document, develop, and communicate project plans and analytic findings with a variety of technical/non-technical stakeholders.\n     Technical Expertise: Proficiency in data analysis and programming languages such as Python, R, SQL, or other relevant tools commonly used in medical research. \n  Ability to quickly learn new analytic tools and packages \n  Strong background in statistical methods, including regression analysis, hypothesis testing, survival analysis, and machine learning algorithms. \n  Prior experience in medical or clinical research, working with healthcare-related datasets, and contributing to scientific publications is preferred. \n  Excellent problem-solving skills \n  Strong organizational skills, an orientation toward detail, and collaboration oriented.Present complex data (qualitative and quantitative) in a clear, concise, and compelling manner to both technical and non-technical audiences to inspire action. \n \n \n ", "techs": ["python", "r", "sql"]}, "e5a1bfa3b13e558e": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Senior Machine Learning Scientist - Ann Arbor, MI or Marlborough, MA", "company": "Sartorius", "desc": "We are looking for a Senior Machine Learning Scientist. In this role you will have a good understanding and knowledge of cell biology/cell physiology, biochemistry and knowledge of statistics, data science and machine learning concepts. \n \n \n Sartorius is seeking a Senior Machine Learning Applied Scientist to expand our Corporate Research team. \n \n  Location: Hybrid: Two days working in the Ann Arbor, MI or Marlborough, MA lab and three days working remote \n \n  Our passion is to simplify and accelerate progress in life science and bioprocessing research, enabling the faster development of new and better therapies. \n  As an applied machine learning scientist, you will use your expertise in modern computer vision methodology to improve world-leading Sartorius imaging products routinely used by major companies across the life science and biopharmaceutical industry. \n \n  Working with Sartorius you will have unique access to large-scale, annotated and high-quality biological/chemical datasets across many different data domains in bio-analytics and bio-processing, including live-cell imaging, multi-plex cell and protein analysis as examples. \n \n  You will join a world-class talented team of interdisciplinary researchers developing state of the art ML tools where your personal drive and focus make a real difference and significantly contribute to simplify progress for our customers, from molecule developability to production for better health at global scale. We are looking forward to your contribution. \n \n  What you will accomplish together with us \n \n  Design and lead technical/applied research projects to achieve goals laid out in our Research and Technology Roadmaps \n  Evaluate relevant state of the art knowledge for business potential and translate into project and existing product/technology areas \n  Building prototypes using state-of-the-art machine learning tools for the life sciences in the applications of computer vision, sequence analysis and omics analysis \n  Implementing data science-best practices for developing and deploying high-quality reliable machine learning-solutions \n  Global responsibility on respective technology areas \n  Advise project leads and upper management \n  Maintain and build strong relationships with internal and external collaborators \n \n \n  What will convince us \n \n  Ph.D. in Computer Science, Machine Learning, Biotech, Engineering, Physics or related disciplines/equivalent research experience, preferably with a focus on life science or biotechnology applications \n  2+ years of experience in industry using modern deep learning frameworks (such as PyTorch or Tensorflow) and with with modern computer vision methodology (Object Detection/Tracking or 3D reconstruction) \n  2+ years of experience working with real world data is required, experience working with microscopy images is a plus \n  Strong programming knowledge in Python is required, including knowledge of common data science tools such as Numpy, Pandas and Matplotlib, and version control using Git. \n  Working knowledge of either machine learning management systems such as Azure ML, machine learning workflow-engines such as MLFlow/Airflow/Metaflow, or data storage, databases, and structure for large data volumes \n  Conceptual and creative thinker \n  Excellent communication skills (oral and written) and relevant people management experience \n  Identification with our core values: Sustainability, Openness, Enjoyment \n \n \n  What we offer  \n Sartorius\u2019 ambition is to simplify progress in the bio-pharmaceutical industry to help translate scientific findings into new therapeutics faster and more efficiently. Nearly 10,000 employees at more than 60 sites are working together on achieving our goal: Better health for more people. And together, we have grown strongly over the past years. Enjoy the advantages of working with a global player: \n \n  Opportunity for international career development:  a global network offering seminars and training sessions, expert and manager career paths \n  Open and highly collaborative culture: mutual support within teams and working as equals, team spirit and international collaboration \n  Work-life balance: Working from home at many sites \n  Intelligent working environment: working in smart buildings with the latest technology and equipment \n  Ambitious goals: Sartorius plans to double its sales revenue approximately every five years and expects to grow its global team to approximately 15,000 people in 2025. \n  We offer a comprehensive array of benefits which include: Paid Vacation (3 weeks), 7 sick days (eligible to carry over up to 30 days), 11 Corporate Holidays, 2 Floating Holidays, Community Service Day, Medical, Dental, Vision, Company Paid and Supplemental Life Insurance, STD & LTD, 401k (with generous company match), Tuition Assistance, Flexible Spending Accounts, Employee Assistance Program, Health and Wellness Program (in addition to other benefits). \n \n \n  All qualified applicants will be considered for employment without regard to race, color, religion, sex or national origin. We are also an equal opportunity employer of individuals with disabilities and protected veterans. \n \n  Please view equal employment opportunity posters provided by OFCCP here. \n \n  E-Verify Participation Info \n  E-Verify Workers Rights \n \n  For Residents of California please review; \n  CA Privacy Notice for Employees \n \n  #LI-remote \n \n  We look forward to receiving your application. \n  www.sartorius.com/career", "cleaned_desc": " \n  What will convince us \n \n  Ph.D. in Computer Science, Machine Learning, Biotech, Engineering, Physics or related disciplines/equivalent research experience, preferably with a focus on life science or biotechnology applications \n  2+ years of experience in industry using modern deep learning frameworks (such as PyTorch or Tensorflow) and with with modern computer vision methodology (Object Detection/Tracking or 3D reconstruction) \n  2+ years of experience working with real world data is required, experience working with microscopy images is a plus \n  Strong programming knowledge in Python is required, including knowledge of common data science tools such as Numpy, Pandas and Matplotlib, and version control using Git. \n  Working knowledge of either machine learning management systems such as Azure ML, machine learning workflow-engines such as MLFlow/Airflow/Metaflow, or data storage, databases, and structure for large data volumes \n  Conceptual and creative thinker \n  Excellent communication skills (oral and written) and relevant people management experience \n  Identification with our core values: Sustainability, Openness, Enjoyment \n ", "techs": ["pytorch", "tensorflow", "object detection/tracking", "3d reconstruction", "numpy", "pandas", "matplotlib", "git", "azure ml", "mlflow", "airflow", "metaflow"]}, "e6243931b07ddf9f": {"terms": ["data science", "data engineer", "machine learning engineer"], "salary_min": 130000.0, "salary_max": 150000.0, "title": "Data Engineer/Data Scientist", "company": "Compact Information Systems LLC", "desc": "Description: \n   About Deep Sync \n  Our parent company, Compact Information Systems LLC, is considered a pioneer of the data industry and was originally founded in 1988 as a mailing list company for direct marketers and print shops. Thirty-five years later, and combining the strength of our sister brands \u2013 AccuData Integrated Marketing, AlumniFinder, ASL Marketing, College Bound Selection Service (CBSS), Deep Sync Labs and HomeData \u2013 we have grown to become some of the foremost data suppliers in the U.S. \n  Today, we are Deep Sync. A company that powers agencies and brands with unmatched audience insights, unsurpassed reach, and unrivaled expertise by combining the industry\u2019s most comprehensive data with easy-to-activate solutions. We provide billions of privacy-first data connections annually to thousands of customers. Learn more about us here. \n  Position Overview \n  Position Overview: We are looking for a senior level Data Engineer with a strong background in data engineering and a solid understanding of data science principles. The ideal candidate will play a critical role in designing, developing, and maintaining our data infrastructure, while also adding expertise to enable advanced analytics and machine learning initiatives. \n  Key Responsibilities: \n \n  Data Pipeline Development: \n    \n Design, implement, and maintain scalable data pipelines to collect, process, and store data from various sources. \n Ensure data quality, accuracy, and consistency throughout the pipeline. \n \n Data Modeling: \n    \n Design and implement data models for predictive analytics, machine learning, and data exploration. \n Optimize data structures and storage to support efficient querying and analysis. \n \n Data Integration: \n    \n Work closely with cross-functional teams to integrate data from diverse sources, including databases, APIs, and external data providers. \n Develop and maintain ETL processes to transform and enrich raw data into actionable insights. \n \n Performance Tuning: \n    \n Monitor and optimize the performance of data pipelines and databases to meet business requirements. \n Identify and resolve bottlenecks and performance issues. \n \n Continuous Learning and mentoring: \n    \n Stay up-to-date with the latest advancements in data engineering and data science technologies. \n Share knowledge and mentor junior team members. \n \n Requirements: \n   Requirements : \n \n  5+ years experience in SQL Query Design, SQL Performance Tuning and Query Optimization \n  5+ years of relevant experience in Data Warehouse Design,Data Warehouse Technical Architectures, Development and Implementation \n  5+ years of relevant experience in ETL Development, ETL Implementation, Unit Testing, Troubleshooting and Support of ETL Processes \n  2+ years of relevant experience with the application of Data Science principles and data modeling. \n \n  Knowledge and Skills: \n \n  Proficiency in SQL Query Design and Implementation \n  Strong Experience with Relational Data Warehouse Systems \n    \n Data Warehouse Management Systems \n Optimization by Indexing, Partitioning and Denormalization \n \n Strong Ability to build and optimize data sets, \u2018big data\u2019 data pipelines and architecture \n  Knowledge of data science concepts, machine learning algorithms, and statistical analysis. \n  Programming skills in languages such as Python, Java, or C# required. \n  Strong analytical and problem-solving skills \n \n  Location: \n \n  Position may be located in Redmond, Washington, we will consider remote candidates. \n \n  Salary: \n \n  The annualized salary range for this senior role is $130,000 - $150,000, commensurate with experience and expertise.", "cleaned_desc": " \n Data Modeling: \n    \n Design and implement data models for predictive analytics, machine learning, and data exploration. \n Optimize data structures and storage to support efficient querying and analysis. \n \n Data Integration: \n    \n Work closely with cross-functional teams to integrate data from diverse sources, including databases, APIs, and external data providers. \n Develop and maintain ETL processes to transform and enrich raw data into actionable insights. \n \n Performance Tuning:    5+ years experience in SQL Query Design, SQL Performance Tuning and Query Optimization \n  5+ years of relevant experience in Data Warehouse Design,Data Warehouse Technical Architectures, Development and Implementation \n  5+ years of relevant experience in ETL Development, ETL Implementation, Unit Testing, Troubleshooting and Support of ETL Processes \n  2+ years of relevant experience with the application of Data Science principles and data modeling. \n \n  Knowledge and Skills: \n \n  Proficiency in SQL Query Design and Implementation \n  Strong Experience with Relational Data Warehouse Systems \n    \n Data Warehouse Management Systems \n Optimization by Indexing, Partitioning and Denormalization   \n Strong Ability to build and optimize data sets, \u2018big data\u2019 data pipelines and architecture \n  Knowledge of data science concepts, machine learning algorithms, and statistical analysis. \n  Programming skills in languages such as Python, Java, or C# required. \n  Strong analytical and problem-solving skills \n \n  Location: \n \n  Position may be located in Redmond, Washington, we will consider remote candidates. \n \n  Salary: \n ", "techs": ["sql query design", "sql performance tuning", "query optimization", "data warehouse design", "data warehouse technical architectures", "development", "implementation", "etl development", "etl implementation", "unit testing", "troubleshooting", "support", "data science principles", "data modeling", "sql query design and implementation", "relational data warehouse systems", "data warehouse management systems", "optimization by indexing", "partitioning", "denormalization", "ability to build and optimize data sets", "big data data pipelines and architecture", "knowledge of data science concepts", "machine learning algorithms", "statistical analysis", "programming skills in python", "java", "c#."]}, "5aa5575b6fe4c4aa": {"terms": ["data science", "machine learning engineer"], "salary_min": 220000.0, "salary_max": 260000.0, "title": "Engineering Manager, Machine Learning", "company": "Runway AI", "desc": "Runway is a research company pioneering new tools for human imagination. Runway has been at the forefront of multi-modal AI systems ensuring that the future of content creation is accessible, controllable and empowering for creatives. Runway\u2019s mission is to ensure that anyone anywhere can tell their stories. We believe that deep learning techniques applied to audiovisual content will forever change art, creativity, and design tools. \n  Runway is leading a shift to generative media that is unlocking an unprecedented level of creative potential. The invention of the camera 200 years ago forever changed our world \u2013 AI is a new kind of camera that will reshape storytelling forever and lead to full feature films that are entirely generated. \n \n About the role \n  We\u2019re looking for an Engineering Manager to help manage a new team that is focused on productionizing new ML-based features to power Runway\u2019s set of creative tools. You should have experience growing high-performing engineering teams and be deeply interested in the intersection of machine learning and systems design. \n  What you\u2019ll do \n \n Lead a talented ML team and keep pushing the boundaries of AI-based content creation \n Develop and deploy state-of-the-art machine learning systems to production \n Work weekly with leadership and the engineering team as a whole to review and set priority around goals \n Build a team of skilled engineers from diverse backgrounds \n \n What you\u2019ll need \n \n 2+ years of experience in a team lead or engineering manager role \n 4+ years of industry experience in an engineering and/or research role \n Strong background building impactful and novel machine learning projects \n Solid knowledge of at least one machine learning framework (e.g. PyTorch, Tensorflow) \n Empathetic and inclusive leadership style \n Ability to rapidly prototype solutions and iterate on them with tight product deadlines \n Strong communication, collaboration, and documentation skills \n \n Runway strives to recruit and retain exceptional talent from diverse backgrounds while ensuring pay equity for our team. Our salary ranges are based on competitive market rates for our size, stage and industry, and salary is just one part of the overall compensation package we provide. \n  There are many factors that go into salary determinations, including relevant experience, skill level and qualifications assessed during the interview process, and maintaining internal equity with peers on the team. The range shared below is a general expectation for the function as posted, but we are also open to considering candidates who may be more or less experienced than outlined in the job description. In this case, we will communicate any updates in the expected salary range. \n  Lastly, the provided range is the expected salary for candidates in the U.S. Outside of those regions, there may be a change in the range, which again, will be communicated to candidates. \n  Salary range: $220,000-$260,000 \n \n Working at Runway \n  Great things come from great teams.  We\u2019d love to hear from you. \n  We\u2019re committed to creating a space where our employees can bring their full selves to work and have equal opportunity to succeed. So regardless of race, gender identity or expression, sexual orientation, religion, origin, ability, age, veteran status, if joining this mission speaks to you, we encourage you to apply. \n  More about Runway \n \n Runway Research \n Runway's AI Film Festival \n Creative Dialogues Series \n Runway Studios \n Our Behaviors and Company Mission \n We raised a $141 million extension to our Series C \n \n We're excited to be recognized as a best place to work Crain's | InHerSight | BuiltIn NYC | INC", "cleaned_desc": " 2+ years of experience in a team lead or engineering manager role \n 4+ years of industry experience in an engineering and/or research role \n Strong background building impactful and novel machine learning projects \n Solid knowledge of at least one machine learning framework (e.g. PyTorch, Tensorflow) \n Empathetic and inclusive leadership style \n Ability to rapidly prototype solutions and iterate on them with tight product deadlines \n Strong communication, collaboration, and documentation skills ", "techs": ["pytorch", "tensorflow"]}, "ad2834140805b27f": {"terms": ["data science"], "salary_min": null, "salary_max": null, "title": "Senior Research Associate-Quantitative", "company": "JBS International", "desc": "JBS seeks a  Senior Research Associate (SRA)  to join the Labor and Economic Equity Impact Center. The ideal candidate has significant expertise in developing questionnaire in social science research, and strong data analysis skills. As part of a wider team, the SRA supports several projects and provides expertise in implementing state-of-the-art statistical methods and develops innovations to deliver reliable data and rigorous analysis to JBS clients. The SRA collaborates with senior staff to develop and lead projects and manages and mentors junior and mid-level staff in the execution of these projects. The   SRA   may serve as a special advisor to other Impact Centers within JBS. The SRA demonstrates expertise in: \n \n  Develop questionnaire across multiple content areas (e.g., labor, low wage labor market, volunteering, behavioral health, health care). \n  Design and implement rigorous, efficient methods for sampling from populations and weighting resultant survey data. \n  Experience successfully developing and administering complex statistical surveys that are national in scope. \n  Develop and implement cross sectional and longitudinal evaluation designs. \n  Experience in inferential statistics and multivariate modeling. \n  Knowledge of psychometrics. \n  Experience in writing clear research reports and translating research findings and reports into easy-to understand products such as infographics and memos. \n  Proven experience and skilled at establishing trust, rapport, and strong working relationships with multiple partners. \n \n  ***If you are within a 50 mile location of our San Mateo, CA or North Bethesda, MD offices this position would be a hybrid position with possibly 2 days in office. For the ideal candidate will consider other remote locations.*** \n  ESSENTIAL JOB FUNCTIONS: \n  Questionnaire Design \n \n  Conduct background research to inform questionnaire development; \n  Draft and test survey questions. \n \n  Research and Evaluation Activities \n \n  Design and lead policy-based evaluation and research studies, and provide expertise in data science and analytics; \n  Provide analytical expertise in inferential statistics, multivariate statistics, and multilevel statistical modeling; \n  Provide expertise in survey research and sampling methods including statistical matching procedures; \n  Provide expertise for both simple and complex analyses (e.g., Time Series, Growth Curve Models, Propensity Score Matched Designs and/or Regression Discontinuity Design); \n  Write memoranda, e-mail correspondence, project documents, reports or sections of reports, literature reviews, and other written documents, in collaboration with other staff or alone; \n  Lead the preparation and production of reports and presentations (e.g., visual data elements such as graphics and tables for printing and peer-reviewed journal articles). \n \n   Business Development Support \n \n  Develop plans and proposals in response to federal contract requests; \n  Use specialized knowledge of a region or area of expertise (e.g., social, economic health disparities, low wage markets, underserved communities and populations) to develop new business opportunities through review of potential proposal requests, research for networking with other organizations, contacts and recruitment of subject matter experts in the area \n  Define and execute business development strategy, conduct capture planning, new client development, new areas for growth, promoting the outcomes and reach of the Center\u2019s work \n \n  Logistical and Administrative Tasks \n \n  Coach and mentor junior and mid-level staff, provide guidance on career development within JBS; \n  Manage projects or lead key tasks, as directed; \n  Develop materials for presentation at conferences, seminars, and workshops; \n  Handle job tasks independently, completing them in an accurate and timely manner. \n  Provide project/program management, including managing project budgets and contracts, develop and map steps in projects adhering to deadlines and deliverables, execute at a high-level of quality, promote and maintain the JBS reputation. \n \n  MINIMUM JOB REQUIREMENTS: \n  Education:  M.A. in Economics, Sociology, Statistics, Social Sciences, Community Psychology, Public Health, or a similar field. \n  Experience:  Twelve years\u2019 experience, which will consist of 9 years of focus experience managing a diverse pool of technical staff with survey research and social science expertise, and at least 4 years of project development and management. Experience preparing Office of Management and Budget (OMB) Office of Information and Regulatory Affairs (OIRA) Paperwork Reduction Act packages. \n  Soft Skills:  Ability to communicate effectively, ability to work independently or work collaboratively with a team. Ability to work in fast paced environment with multiple deadlines. Must demonstrate initiative. \n  Software Proficiency:  Experience conducting analysis in SAS, Stata, or R. Proficiency in MS Excel, MS Word, and MS Access, PowerPoint, Alchemer or other online survey services. Knowledge of research and evaluation design, statistical analysis techniques and survey methods. Familiarity with SQL or SQLPlus is a plus. \n  Location:  San Mateo, California; North Bethesda, MD, or remote location. \n \n  PREFERRED JOB REQUIREMENTS: \n  Education:  Ph.D. in Economics, Sociology, Social Sciences, Community Psychology, Public Health, or a similar field. \n  Experience:  Ten years\u2019 experience, which will consist of 7 years of focus experience managing a diverse pool of technical staff with survey research and social science expertise, and at least 2 years of project development and management. \n  OTHER DUTIES AS ASSIGNED:  This position description should not be construed to imply that these requirements are the exclusive standards of the position nor will it be the sole basis for any subsequent employee evaluations. Incumbents will follow any other instructions and perform any other related duties as may be required by their supervisor. \n  This position is subject to availability of funds and to any and all restrictions contained in the contract or contracts that provide funding for this position. \n  APPLICATION INFORMATION:  If you meet the minimum requirements for this position, please click on the \"Apply\" link posted below and complete the application. Please include a cover letter, resume, and at least three (3) professional references. \n  Our company is an equal opportunity/affirmative action employer. Applicants can learn more about the company's status as an equal opportunity employer by viewing the federal \"EEO is the Law\" poster at EEOPost.pdf. \n  Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, disability, or protected Veteran status.", "cleaned_desc": "JBS seeks a  Senior Research Associate (SRA)  to join the Labor and Economic Equity Impact Center. The ideal candidate has significant expertise in developing questionnaire in social science research, and strong data analysis skills. As part of a wider team, the SRA supports several projects and provides expertise in implementing state-of-the-art statistical methods and develops innovations to deliver reliable data and rigorous analysis to JBS clients. The SRA collaborates with senior staff to develop and lead projects and manages and mentors junior and mid-level staff in the execution of these projects. The   SRA   may serve as a special advisor to other Impact Centers within JBS. The SRA demonstrates expertise in: \n \n  Develop questionnaire across multiple content areas (e.g., labor, low wage labor market, volunteering, behavioral health, health care). \n  Design and implement rigorous, efficient methods for sampling from populations and weighting resultant survey data. \n  Experience successfully developing and administering complex statistical surveys that are national in scope. \n  Develop and implement cross sectional and longitudinal evaluation designs. \n  Experience in inferential statistics and multivariate modeling. \n  Knowledge of psychometrics. \n  Experience in writing clear research reports and translating research findings and reports into easy-to understand products such as infographics and memos. \n  Proven experience and skilled at establishing trust, rapport, and strong working relationships with multiple partners. \n ", "techs": ["developing questionnaire in social science research", "strong data analysis skills", "implementing state-of-the-art statistical methods", "developing innovations", "reliable data and rigorous analysis", "managing and mentoring junior and mid-level staff", "serving as a special advisor", "develop questionnaire across multiple content areas", "rigorous", "efficient methods for sampling", "experience in inferential statistics and multivariate modeling", "knowledge of psychometrics", "writing clear research reports", "translating research findings into easy-to-understand products", "establishing trust", "rapport", "and strong working relationships with multiple partners."]}, "09c485d140ae7754": {"terms": ["data science"], "salary_min": 121941.71, "salary_max": 154405.38, "title": "Manager, Statistical Programming", "company": "Daiichi Sankyo, Inc.", "desc": "Join a Legacy of Innovation 110 Years and Counting!\n   \n  Daiichi Sankyo Group is dedicated to the creation and supply of innovative pharmaceutical therapies to improve standards of care and address diversified, unmet medical needs of people globally by leveraging our world-class science and technology. With more than 100 years of scientific expertise and a presence in more than 20 countries, Daiichi Sankyo and its 16,000 employees around the world draw upon a rich legacy of innovation and a robust pipeline of promising new medicines to help people. Under the Group\u2019s 2025 Vision to become a \u201cGlobal Pharma Innovator with Competitive Advantage in Oncology,\u201d Daiichi Sankyo is primarily focused on providing novel therapies in oncology, as well as other research areas centered around rare diseases and immune disorders.\n  \n \n \n   Summary\n  \n \n \n   The purpose of this job is to oversee statistical vendor deliverables, perform programmatic review of analysis datasets and Table, Listing, and Figures (TLFs) generated by vendor, ensure deliverable quality, and expedite the preparation of oncology compound regulatory submission. It will also to maintain institutional knowledge across oncology compounds and support building up oncology programming standard on datasets and TFLs to improve efficiency and quality.\n   \n  Responsibilities\n   \n \n \n By leading internal programming contractor or by self, perform programmatic review of analysis datasets and TLFs generated by statistical vendor, ensure deliverable quality for the pivotal studies, Integrated Summary of Efficacy (ISE)/Integrated Summary of Safety (ISS) for oncology submission compounds, and expedite the preparation of regulatory submissions. Responsibilities include: review Case Report Form (CRF) annotation and Study Date Tabulation Model (SDTM) dataset, identify data inconsistencies and support data review, review analysis dataset specifications and ensure correct interpretation of SAP, develop independent programs to validate analysis dataset and TLFs generated by vendor, ensure analysis dataset in compliance with CDISC and submission requirement, review submission data package and ensure its quality and integrity \n Oversee statistical programming vendor on project planning and execution to ensure high quality deliverables and timelines met. Responsibilities include: review and agree on vendor project timelines and resource planning, work in tandem with Biostatistics and Data Management members to ensure best vendor performance, monitor analysis dataset and TLFs transfers for ongoing and complete trials, confirm data use and output quality, proactively ensure the resolution of programming related issues prior to database lock analysis, be accountable and verify completeness of study programming deliverables, maintain all required study programming documentation required for Trial Master File (TMF) \n Maintain institutional knowledge across oncology compounds and support building up oncology programming standard on datasets and TFLs to improve efficiency and quality. Responsibilities include: contribute to CRF and SDTM standard development, support develop, implement, and maintain Analysis Data Model (ADaM) dataset and TLF standard, develop sample programs to generate standard ADaM dataset and TLFs, support training and ensure implementation of ADaM and TLFs standard in clinical trials analysis \n Provide programming support to prepare regulatory requested analyses and help submission team in quick turnaround in response to regulatory agencies. Responsibilities include: create TLFs to support submission QAs in a quick turnaround, support ad-hoc and exploratory analysis requested by clinical team, provide programming supports in agency response or potential Advisory Committee Meeting \n Develop and maintain programming macros to effectively support internal data review and monitoring. Responsibilities include: work with Biostatistics member to define the requirements of efficacy data review, develop macros and support the internal data review and monitoring on an ongoing basis \n \n \n \n  Qualifications: Successful candidates will be able to meet the qualifications below with or without a reasonable accommodation.\n  \n \n \n   Education Qualifications (from an accredited college or university)\n   \n \n \n Bachelor's Degree from an accredited institution in science or in a technical field preferred \n Master's Degree preferred \n \n \n \n \n   Experience Qualifications\n   \n \n \n 7 or More Years proven experience within pharmaceutical industry, or CROs supporting statistical analysis of clinical trials programming with Bachelor's degree preferred \n 4 or More Years proven experience within pharmaceutical industry, or CROs supporting statistical analysis of clinical trials programming with Masters degree preferred \n Advanced working knowledge of all aspects of the SAS programming language used in clinical trials programming. preferred \n Advanced working knowledge of CDISC SDTM and ADaM, and extensive experiences of their implementation in clinical trials analysis preferred \n Advanced understanding of statistical concepts in support of analyses and reporting of clinical trials. preferred \n Having knowledge of all phases of drug development, including early and late phase clinical development and submission preferred \n Having solid background of applied statistics preferred \n Solid knowledge of new advanced statistical methods using SAS preferred \n Knowledge in database structures and set-up preferred \n The candidate should have successfully provided programming expertise at the Project level for at least two global development projects that have been submitted to regulatory agencies preferred \n \n \n \n \n   Daiichi Sankyo, Inc. is an equal opportunity/affirmative action employer. Qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.", "cleaned_desc": "", "techs": ""}, "ed93a6b73370707e": {"terms": ["data science"], "salary_min": 118860.0, "salary_max": 196720.0, "title": "Central Lab Capacity Planning Technical Program Manager", "company": "INTEL", "desc": "Job Description \n  Join SATG as a Central Lab Capacity Planning Technical Program Manager. As a program manager, responsibilities include but not limited to:Own Platform demand forecasting by line of business (LOB) for Xeon, Client, GFX, FPGA, Network/EDGE, IFS, AI, Wireless etc and manage data upload to the Advanced Lab Planning System (ALPS)Partner with CS/CRESD to manage lab supply capacity allocation for on premise labs, estimate off-premise (colo), and ODC lab capacity need to meet product validation requirementsEngage with PXTs, engineering teams, finance and operations to ensure LRP/MRP/POR platform demand based on lab space use case is aligned to roadmap deliverables and program spending targets.Create and present data driven analysis and options/recommendations to stakeholders and management for investment and allocation decisionsDesign, modify, and manage lab supply chain process in support of any centralized lab servicesGuide and influence business and development priorities for the ALPS development teamDrive ALPS adoption and productization across Intel\n  \n  Qualifications \n  You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates.     Minimum Qualifications    The candidate must have a Bachelor's Degree in Electrical/Computer Engineering/Industrial Engineering or other related field and 6+ years of experience in: \n \n  Project/Program management experience with complex and large scope programs in a high-tech Si/platform validation environment \n  Product validation \n  Data science and analysis skills to gather insights from data and the willingness to setup options for decision making \n  Experience creating lab capacity planning methodologies that improved post Si validation efficiency \n \n  Preferred Qualifications \n \n \n  MS preferred \n  Multiple product lines of business including server and client CPU, chipsets, graphics, networking, and ethernet \n  Intel product life cycle processes, milestones, and benchmarks tied to Intel's project efforts \n  Intel's post-silicon validation process \n  Experience generating requirements for Intel's lab capacity planning solution (ALPS) \n  Intel platforms and facility space, power, cooling and related requirements along with utilization that translates to experience to develop planning for lab build outs and expansion \n \n  Inside this Business Group \n  Intel's Information Technology Group (IT) designs, deploys and supports the information technology architecture and hardware/software applications for Intel. This includes the LAN, WAN, telephony, data centers, client PCs, backup and restore, and enterprise applications. IT is also responsible for e-Commerce development, data hosting and delivery of Web content and services.\n  \n  Covid Statement \n  Intel strongly encourages employees to be vaccinated against COVID-19. Intel aligns to federal, state, and local laws and as a contractor to the U.S. Government is subject to government mandates that may be issued. Intel policies for COVID-19 including guidance about testing and vaccination are subject to change over time.\n  \n  Posting Statement \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.\n  \n  Benefits \n  We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html\n  \n  Annual Salary Range for jobs which could be performed in US, Colorado, New York, Washington, California: $118,860.00-$196,720.00\n  \n \n Salary range dependent on a number of factors including location and experience \n \n  Working Model \n  This role is available as a fully home-based and generally would require you to attend Intel sites only occasionally based on business need. This role may also be available as our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. \n  In certain circumstances the work model may change to accommodate business needs. \n  JobType  \n Fully Remote", "cleaned_desc": "Job Description \n  Join SATG as a Central Lab Capacity Planning Technical Program Manager. As a program manager, responsibilities include but not limited to:Own Platform demand forecasting by line of business (LOB) for Xeon, Client, GFX, FPGA, Network/EDGE, IFS, AI, Wireless etc and manage data upload to the Advanced Lab Planning System (ALPS)Partner with CS/CRESD to manage lab supply capacity allocation for on premise labs, estimate off-premise (colo), and ODC lab capacity need to meet product validation requirementsEngage with PXTs, engineering teams, finance and operations to ensure LRP/MRP/POR platform demand based on lab space use case is aligned to roadmap deliverables and program spending targets.Create and present data driven analysis and options/recommendations to stakeholders and management for investment and allocation decisionsDesign, modify, and manage lab supply chain process in support of any centralized lab servicesGuide and influence business and development priorities for the ALPS development teamDrive ALPS adoption and productization across Intel\n  \n  Qualifications \n  You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates.     Minimum Qualifications    The candidate must have a Bachelor's Degree in Electrical/Computer Engineering/Industrial Engineering or other related field and 6+ years of experience in: \n \n  Project/Program management experience with complex and large scope programs in a high-tech Si/platform validation environment \n  Product validation    Intel product life cycle processes, milestones, and benchmarks tied to Intel's project efforts \n  Intel's post-silicon validation process \n  Experience generating requirements for Intel's lab capacity planning solution (ALPS) \n  Intel platforms and facility space, power, cooling and related requirements along with utilization that translates to experience to develop planning for lab build outs and expansion \n \n  Inside this Business Group \n  Intel's Information Technology Group (IT) designs, deploys and supports the information technology architecture and hardware/software applications for Intel. This includes the LAN, WAN, telephony, data centers, client PCs, backup and restore, and enterprise applications. IT is also responsible for e-Commerce development, data hosting and delivery of Web content and services.\n  ", "techs": ["xeon", "client", "gfx", "fpga", "network/edge", "ifs", "ai", "wireless", "advanced lab planning system (alps)", "pxts", "lrp/mrp/por", "alps development team", "alps adoption", "alps productization", "electrical/computer engineering/industrial engineering", "si/platform validation environment", "intel product life cycle processes", "intel's post-silicon validation process", "intel's lab capacity planning solution (alps)", "intel platforms", "lan", "wan", "telephony", "data centers", "client pcs", "backup and restore", "enterprise applications", "e-commerce development."]}, "28cbf520a29d7d45": {"terms": ["data science", "machine learning engineer"], "salary_min": 144000.0, "salary_max": 208000.0, "title": "Senior Product Manager", "company": "Indeed", "desc": "Our Mission \n As the world\u2019s number 1 job site*, our mission is to help people get jobs. We strive to cultivate an inclusive and accessible workplace where all people feel comfortable being themselves. We're looking to grow our teams with more people who share our enthusiasm for innovation and creating the best experience for job seekers. \n (*comScore Total Visits, September 2023) \n Day to Day \n As a Senior Technical Product Manager for Indeed\u2019s machine learning (ML) platform, you will play a pivotal role in shaping the future of our data-driven initiatives. You will lead a cross-functional team, collaborating closely with data scientists, engineers, and interested parties to develop and enhance the product. Your primary focus will be to create a powerful, user-friendly, and scalable platform that enables our data scientists to leverage the full potential of machine learning in solving complex business challenges. \n We\u2019re looking for someone who will work with businesses across Indeed to understand their ML needs, identify product opportunities for internal customers, and build ML infrastructure that meets customer needs. This person will leverage their deep product management expertise to work backwards from customer scenarios, to identify the right product opportunities, and define and execute the product roadmap. If you have a passion for innovation, for taking on ambiguous problems, for solving some of the biggest technical challenges in the industry, and for building elegant products that delight our customers, we need you! \n Responsibilities \n \n Platform Strategy : Develop and articulate a clear, compelling, data-driven product vision, strategy, and roadmap for the machine learning platform, aligned with Indeed's business goals while identifying features that value for customers \n Engagement : Collaborate closely with data scientists, engineers, and interested parties across the company to understand their needs, gather requirements, and prioritize features and enhancements. Represent the product and the team, comfortably communicating with executives as well as with business and technical interested parties. \n User-Centric Design : Promote a user-centric design approach, empathizing with Indeed\u2019s ML users to ensure the platform is intuitive, efficient, and capable of supporting a wide range of machine learning workflows and models. \n Platform Development : Collaborate closely with cross-functional teams, including engineering and data science, to ensure successful platform development and deployment. Head the end-to-end product development lifecycle, including defining requirements, creating user stories, and coordinating with engineering teams to deliver high-quality features and updates on time and within budget. \n Performance Metrics : Define and monitor key performance metrics to assess the platform's effectiveness, making data-driven decisions to continuously improve its performance and usability. \n Compliance and Security : Ensure that the platform adheres to industry best practices for data privacy, security, and compliance. \n \n Skills/Competencies \n \n Proven track record (5+ years) as a Product Manager, with experience in machine learning or data science-related products. \n Experience designing and building products for developers and scientists. \n Familiarity with cloud-based machine learning platforms (e.g., Amazon Web Services (AWS) SageMaker, Google Cloud AI Platform, etc.). \n Experience working with data preparation techniques, and ML modeling frameworks and tooling. \n Prior experience working with cross-functional teams in a fast-paced environment. \n Bachelor\u2019s Degree in Computer Engineering, Computer Science, Electrical Engineering, Electronics, a related field, or equivalent experience. \n \n Salary Range Transparency \n \n US Remote: 144,000 - 208,000 USD per year \n Austin Metro Area: 176,000 - 254,000 USD per year \n New York City Metro Area: 149,000 - 217,000 USD per year \n San Francisco Metro Area: 196,000 - 284,000 USD per year \n Seattle Metro Area: 177,000 - 257,000 USD per year \n \n Salary Range Disclaimer \n The base salary range represents the low and high end of the Indeed salary range for this position in the given work location. Actual salaries will vary depending on factors including but not limited to location, experience, and performance. The range(s) listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Restricted Stock Units (RSUs), a Paid Time Off policy, and many region-specific benefits. \n Benefits - Health, Work/Life Harmony, & Wellbeing \n We care about what you care about. We have a multitude of benefits to support Indeedians, as well as their pets, kids, and partners. Select your country and learn more about our employee benefits, program, & perks at https://benefits.indeed.jobs! \n Equal Opportunity Employer \n Indeed is deeply committed to building a workplace and global community where inclusion is not only valued, but prioritized. We\u2019re proud to be an equal opportunity employer, seeking to create a welcoming and diverse environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, family status, marital status, sexual orientation, national origin, genetics, neuro-diversity, disability, age, or veteran status, or any other non-merit based or legally protected grounds. \n Indeed is committed to providing reasonable accommodations to qualified individuals with disabilities in the employment application process. To request an accommodation, please contact Talent Attraction Accommodations at 1-855-567-7767, or by email at accommodations@indeed.com. If you are requesting accommodation for an interview, please reach out at least one week in advance of your interview. \n Fair Chance Hiring \n We value diverse experiences, including those who have had prior contact with the criminal legal system. We are committed to providing individuals with criminal records, including formerly incarcerated individuals, a fair chance at employment. \n Indeed\u2019s Employee Recruiting Privacy Policy \n Like other employers Indeed uses our own technologies to help us find and attract top talent from around the world. In addition to our site\u2019s user and privacy policy found at https://www.indeed.com/legal, we also want to make you aware of our recruitment specific privacy policy found at https://www.indeed.com/legal/indeed-jobs. \n Req ID:  2023-43295 \n Job Type: Full-time \n Pay: $144,000.00 - $208,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Health savings account \n Paid time off \n Parental leave \n Retirement plan \n Tuition reimbursement \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n Performance bonus \n Quarterly bonus \n RSU \n Signing bonus \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n People with a criminal record are encouraged to apply \n Experience: \n \n Agile: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Our Mission \n As the world\u2019s number 1 job site*, our mission is to help people get jobs. We strive to cultivate an inclusive and accessible workplace where all people feel comfortable being themselves. We're looking to grow our teams with more people who share our enthusiasm for innovation and creating the best experience for job seekers. \n (*comScore Total Visits, September 2023) \n Day to Day \n As a Senior Technical Product Manager for Indeed\u2019s machine learning (ML) platform, you will play a pivotal role in shaping the future of our data-driven initiatives. You will lead a cross-functional team, collaborating closely with data scientists, engineers, and interested parties to develop and enhance the product. Your primary focus will be to create a powerful, user-friendly, and scalable platform that enables our data scientists to leverage the full potential of machine learning in solving complex business challenges. \n We\u2019re looking for someone who will work with businesses across Indeed to understand their ML needs, identify product opportunities for internal customers, and build ML infrastructure that meets customer needs. This person will leverage their deep product management expertise to work backwards from customer scenarios, to identify the right product opportunities, and define and execute the product roadmap. If you have a passion for innovation, for taking on ambiguous problems, for solving some of the biggest technical challenges in the industry, and for building elegant products that delight our customers, we need you! \n Responsibilities \n \n Platform Strategy : Develop and articulate a clear, compelling, data-driven product vision, strategy, and roadmap for the machine learning platform, aligned with Indeed's business goals while identifying features that value for customers \n Engagement : Collaborate closely with data scientists, engineers, and interested parties across the company to understand their needs, gather requirements, and prioritize features and enhancements. Represent the product and the team, comfortably communicating with executives as well as with business and technical interested parties. \n User-Centric Design : Promote a user-centric design approach, empathizing with Indeed\u2019s ML users to ensure the platform is intuitive, efficient, and capable of supporting a wide range of machine learning workflows and models. \n Platform Development : Collaborate closely with cross-functional teams, including engineering and data science, to ensure successful platform development and deployment. Head the end-to-end product development lifecycle, including defining requirements, creating user stories, and coordinating with engineering teams to deliver high-quality features and updates on time and within budget. \n Performance Metrics : Define and monitor key performance metrics to assess the platform's effectiveness, making data-driven decisions to continuously improve its performance and usability. \n Compliance and Security : Ensure that the platform adheres to industry best practices for data privacy, security, and compliance. \n \n Skills/Competencies ", "techs": ["machine learning", "data-driven initiatives", "data scientists", "engineers", "product management expertise", "product roadmap", "ml infrastructure", "product vision", "user-centric design", "machine learning workflows", "platform development", "performance metrics", "data privacy", "security", "compliance"]}, "175898f7b11c0e14": {"terms": ["data science"], "salary_min": 106982.805, "salary_max": 135464.06, "title": "Statistical Programmer", "company": "Katalyst Healthcares & Life Sciences Inc", "desc": "Responsibilities: \n \n Provide statistical programming support to generate SDTM and ADaM datasets, tables, listings, and figures for individual studies and ISS/ISE to FDA, EMA, and other worldwide regulatory agencies. \n Participate in the review of statistical analysis plans and TLF specifications. \n Review or annotate CRFs for SDTM mapping, review/author SDTM/ADaM dataset specifications. \n Review, and comment on CRFs, vendor data transfer specifications (DTS), edit checks and other study data related documents. \n Support in the preparation of study reports, regulatory submissions, and annual safety update reports \n Perform additional analysis and validation for data checking, publication, presentation, poster and ad hoc analysis. \n Work with CRO statistical programmers and perform statistical programming vendor oversight. \n Contribute to Biometrics SOPs and work instructions related to EDC studies, FDA requests, and statistical programming processes. \n Contribute to department process improvement initiatives. \n Support department infrastructure build up by developing, validating and testing the macros, utilities and tools. \n Keep abreast of literature and advancements in SAS. \n \n Requirements: \n \n Bachelor\u2019s or master\u2019s degree in biostatistics, computer science, or related fields, Master\u2019s degree preferred; \n At least 6 years of relevant experience in the biotech or pharmaceutical industry. \n The ideal candidate must be able to communicate effectively within a multi-disciplinary project team to assess priorities and complete assigned tasks on time. \n Proficient of SAS programming in a regulated clinical research environment \n Experience of programming and validation of SDTM and ADaM data sets, tables, figures, and listings. \n \n Job Type: Contract \n Experience level: \n \n 6 years \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Experience: \n \n Informatica: 1 year (Preferred) \n SQL: 1 year (Preferred) \n Data warehouse: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Requirements: \n \n Bachelor\u2019s or master\u2019s degree in biostatistics, computer science, or related fields, Master\u2019s degree preferred; \n At least 6 years of relevant experience in the biotech or pharmaceutical industry. \n The ideal candidate must be able to communicate effectively within a multi-disciplinary project team to assess priorities and complete assigned tasks on time. \n Proficient of SAS programming in a regulated clinical research environment \n Experience of programming and validation of SDTM and ADaM data sets, tables, figures, and listings. ", "techs": ["sas programming", "sdtm", "adam"]}, "80d2c26d80196098": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 144000.0, "salary_max": 270250.0, "title": "AI Solutions Architect", "company": "NVIDIA", "desc": "We are looking for a Machine Learning Engineer/AI Solutions Architect with experience in AI data pipelines and model development. As part of the Solutions Architecture organization, we work with the most exciting computing hardware and software, driving the latest breakthroughs in deep learning and machine learning with NVIDIA\u2019s key customers. This role offers an excellent opportunity to build your career in the rapidly growing field of AI while enabling the world's most successful technology companies. Primary responsibilities will be to lead software customer technical engagements with NVIDIA products and technologies. Join us in this exciting endeavor!\n  \n \n \n   What You\u2019ll Be Doing:\n  \n \n \n \n     Develop and demonstrate software solutions based on NVIDIA\u2019s ground breaking AI, data science software and hardware technologies to customers. Perform in-depth analysis and optimization of data processing pipelines, AI models to ensure the best performance on current- and next-generation GPU architectures\n    \n \n \n     Lead and develop proof-of-concepts (PoCs) for solutions applied to Consumer Internet industry use-cases such as NLP/LLM, recommender, etc. by working closely with customer's data and AI developers. Build collateral (notebook/code) for PoCs\n    \n \n \n     Work closely with business development team through the sales process for GPU/Network hardware/software products. Owning the technical relationship and enabling customer in building innovative solutions based on NVIDIA technologies\n    \n \n \n     Partner with NVIDIA Engineering, Product, Sales teams to secure design wins at customers. Enable development and growth of NVIDIA product features through customer feedback and PoC evaluations\n    \n \n \n \n   What We Need To See:\n  \n \n \n \n     BS, MS, or PhD in Computer Science, Electrical/Computer Engineering, Physics, Mathematics, or other Engineering fields or equivalent experience\n    \n \n \n     5+ years of experience as an ML/Software Engineer with proven track record in writing code in Python and/or C++\n    \n \n \n     Experience with AI applications and data processing with frameworks such as PyTorch, Spark\n    \n \n \n     Ability to communicate your ideas/code clearly through GitHub, documentation\n    \n \n \n     Enjoy collaborating with teams across the organization such as Engineering/Research, Sales, Product, and Marketing\n    \n \n \n     Effective verbal/written communication, and technical presentation skills\n    \n \n \n     Self-starter with passion for growth, enthusiasm for continuous learning and sharing findings across the team\n    \n \n \n \n   Ways To Stand Out From The Crowd:\n  \n \n \n \n     External customer facing skill-set and background\n    \n \n \n     Experience with large-scale production data pipelines and AI model deployment\n    \n \n \n     Development experience with NVIDIA software libraries and GPUs\n    \n \n \n     Knowledge of MLOps technologies such as Kubernetes, data center deployments etc. Experience working with enterprise developers building computer vision, NLP, or data analytics applications\n    \n \n \n     Able to think creatively to debug and solve complex problems\n    \n \n \n \n   We make extensive use of conferencing tools, but occasional travel is required for local on-site visit to customers and data science conferences. We are open to remote work location. We look forward to have you join our team! With highly competitive salaries, a comprehensive benefits package, and an excellent engineering work culture, NVIDIA is widely considered to be one of the technology industry's most desirable employers. NVIDIA has some of the most innovative people working on meaningful problems that are defining the field of ML/DL, data science, robotics, and graphics.\n  \n  The base salary range is $144,000 - $270,250. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.\n  \n \n \n \n \n \n \n \n          You will also be eligible for equity and \n          \n          benefits\n          .\n         \n \n \n \n \n \n \n \n  NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.", "cleaned_desc": "We are looking for a Machine Learning Engineer/AI Solutions Architect with experience in AI data pipelines and model development. As part of the Solutions Architecture organization, we work with the most exciting computing hardware and software, driving the latest breakthroughs in deep learning and machine learning with NVIDIA\u2019s key customers. This role offers an excellent opportunity to build your career in the rapidly growing field of AI while enabling the world's most successful technology companies. Primary responsibilities will be to lead software customer technical engagements with NVIDIA products and technologies. Join us in this exciting endeavor!\n  \n \n \n   What You\u2019ll Be Doing:\n  \n \n \n \n     Develop and demonstrate software solutions based on NVIDIA\u2019s ground breaking AI, data science software and hardware technologies to customers. Perform in-depth analysis and optimization of data processing pipelines, AI models to ensure the best performance on current- and next-generation GPU architectures\n    \n \n \n     Lead and develop proof-of-concepts (PoCs) for solutions applied to Consumer Internet industry use-cases such as NLP/LLM, recommender, etc. by working closely with customer's data and AI developers. Build collateral (notebook/code) for PoCs\n    \n \n \n     Work closely with business development team through the sales process for GPU/Network hardware/software products. Owning the technical relationship and enabling customer in building innovative solutions based on NVIDIA technologies\n    \n \n       Partner with NVIDIA Engineering, Product, Sales teams to secure design wins at customers. Enable development and growth of NVIDIA product features through customer feedback and PoC evaluations\n    \n \n \n \n   What We Need To See:\n  \n \n \n \n     BS, MS, or PhD in Computer Science, Electrical/Computer Engineering, Physics, Mathematics, or other Engineering fields or equivalent experience\n    \n \n \n     5+ years of experience as an ML/Software Engineer with proven track record in writing code in Python and/or C++\n    \n \n \n     Experience with AI applications and data processing with frameworks such as PyTorch, Spark\n    \n   \n \n     External customer facing skill-set and background\n    \n \n \n     Experience with large-scale production data pipelines and AI model deployment\n    \n \n \n     Development experience with NVIDIA software libraries and GPUs\n    \n \n \n     Knowledge of MLOps technologies such as Kubernetes, data center deployments etc. Experience working with enterprise developers building computer vision, NLP, or data analytics applications\n    \n \n \n     Able to think creatively to debug and solve complex problems\n    \n ", "techs": ["machine learning engineer/ai solutions architect", "ai data pipelines", "model development", "deep learning", "machine learning", "nvidia", "software customer technical engagements", "pocs", "nlp/llm", "recommender", "business development", "gpu/network hardware/software products", "nvidia engineering", "design wins", "computer science", "electrical/computer engineering", "physics", "mathematics", "python", "c++", "pytorch", "spark", "large-scale production data pipelines", "ai model deployment", "nvidia software libraries", "gpus", "mlops technologies", "kubernetes", "data center deployments", "computer vision", "nlp", "data analytics applications"]}, "e7b45564c186209b": {"terms": ["data science"], "salary_min": 60.0, "salary_max": 65.0, "title": "Coverage Review Pharmacist", "company": "BuzzClan Private Limited", "desc": "Job title: Coverage Review Pharmacist \n Location: Remote \n Duration:3+ months \n Shift: 8 AM to 5 PM \n Education \n \n Doctor of Pharmacy (PharmD) Degree \n \n Experience \n \n 3 years - Clinical experience required, and preference for coverage review experience. \n \n Skills\\Certifications \n \n Ability to work independently with minimal supervision or function in a team environment sharing responsibility, roles and accountability. \n \n Competency in compendia navigation and research \n \n Proficient in Microsoft Office (Outlook, Word, Excel and PowerPoint) \n \n \n Must be a team player, be organized and have the ability to handle multiple projects. \n \n \n Excellent oral and communication skills \n \n \n Strong interpersonal and organizational skills \n \n \n Solid understanding of regulatory guidelines (FDA, NCQA, EQRO, CMS) required. \n \n \n Knowledge of medical and pharmacy products \n \n License \n \n Licensed in Tennessee to practice Pharmacy, or eligible for licensure in the state of Tennessee to practice Pharmacy. \n \n Responsibilities: \n \n Responsible for various activities associated with coverage reviews and appeals including the review of medication related prior authorizations, pharmacy appeals, and member grievances focused on medications. \n \n \n Performs prospective and retrospective coverage reviews and appeals per State and Federal regulations. \n \n \n Responds to prescriber, pharmacy provider, member appeals, grievances and complaints related to the provision of pharmaceutical services within established time periods. \n \n \n Builds and maintains decision trees in the prior authorization system. \n \n \n Maintains denial rationale associated with clinical criteria and ensures that decision letters meet regulatory compliance. \n \n Education: Doctor of Pharmacy (PharmD) Degree \n Job Type: Contract \n Salary: $60.00 - $65.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Ability to work independently with minimal supervision or function in a team environment sharing responsibility, roles and accountability. \n \n Competency in compendia navigation and research \n \n Proficient in Microsoft Office (Outlook, Word, Excel and PowerPoint) \n \n \n Must be a team player, be organized and have the ability to handle multiple projects. \n \n \n Excellent oral and communication skills \n \n \n Strong interpersonal and organizational skills ", "techs": ["microsoft office (outlook", "word", "excel", "powerpoint)"]}, "cde5c6dfa9ee701d": {"terms": ["data science", "machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Job description: \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n FMCOgxRegP", "cleaned_desc": "", "techs": ""}, "02a61651a0c8fbb6": {"terms": ["data science"], "salary_min": 205000.0, "salary_max": 220000.0, "title": "Director, Statistical Programming", "company": "Praxis Precision Medicines", "desc": "Director, Statistical Programming \n  Reports to:  Vice President, Head of Data Sciences \n  Location:  This position may be performed remotely with travel to the Boston area as needed. \n   \n Position Summary \n  As the Associate Director or Director of Statistical Programming, you will play a pivotal role in our mission to develop life-altering treatments by leading and directing the statistical programming function and strategy for clinical projects across multiple therapeutic areas. The primary objectives are to ensure the delivery of high-quality programming deliverables within project timelines and manage statistical reporting for major Praxis initiatives. \n \n  Primary Responsibilities \n \n  Lead and implement the statistical programming strategy in assigned therapeutic area/s.  \n Manage quality, timeliness, efficiency, and implementation of standards. Ensure implementation of state-of-the-art programming practices and quality guidelines in compliance with regulatory requirements and Praxis quality standards, to ensure programming deliverables of high quality, on time, and within budget.  \n Build and maintain strong partnerships within Praxis Statistical Programming groups and across functions within Biometrics, Regulatory and all development functions.  \n Attend Biometrics leadership meeting and extended leadership meeting to represent programming function on strategic and operational level.  \n Lead all external and internal resource management activities across programming TAs, as well as contribute to the overall resource planning for programming.  \n Manage and build relationships with external partners and service organizations.  \n Engages in effective management of vendors including development, maintenance and monitoring of effective KPIs and KQIs.  \n Anticipates potential problems within and across TAs and develops appropriate contingency plans. Creates escalation plans to ensure resolution of all issues at the therapeutic and project levels.  \n Independently lead improvement initiatives and/or non-clinical projects for programming and Biometrics.  \n Review the planned contents of tables / listings / figures and project level documents to ensure efficient production and usefulness of output. \n \n \n  Qualifications and Key Success Factors \n \n  Masters degree in statistics, math, or computer science.  \n Must have minimum of 8 years in a senior programming/statistical role within the biotechnology or pharmaceutical industry within drug development. \n  Experience on the sponsor side is required, experience within a CRO helpful. \n  Strong leadership, communications, and collaboration skills required.  \n Good knowledge of drug development and commercialization processes. Must have solid Phase 3 readout experience/know how to derive data in CDISC compliant datasets and be able to evidence experience with submissions. \n  Excellence in SAS, SAS/macro, SAS/Graph, Tables, listings and figures production and independent QC. \n  Experience developing TFL shells, annotated CRF, ADaM/SDTM specs, review guidance and programming specs. \n  Proven ability to proactively identify issues, recommend and implement solutions.  \n Good knowledge of statistical programming languages such as SAS, R and R Shiny \n  Experience managing vendors and driving quality and timelines.  \n \n Compensation & Benefits \n  At Praxis, we\u2019re proud to offer an exceptional benefits package that includes: \n \n \n  99% premium cost covered for medical (Blue Cross Blue Shield), dental, and vision plans \n  Bonus program structured to pay on a quarterly basis \n  401k plan with 100% match up to 6% of employee\u2019s contribution (Traditional & Roth) \n  Wellness benefit of $200/month towards incredibly flexible options including travel, fitness equipment & memberships, student loan repayment, sports fees and much more \n  Unlimited PTO, (2) weeklong shutdowns each year, and a generous extended family leave benefit \n  Eligibility for equity awards and Employee Stock Purchase Plan (15% discount) \n \n \n  To round out this world-class total rewards package, we provide base salary compensation in the range of $205,000 to $220,000 annualized. Final salary range may be modified commensurate with job level, education, and experience. \n \n  Company Overview \n  Praxis Precision Medicines is a clinical-stage biopharmaceutical company translating genetic insights into the development of therapies for central nervous system disorders characterized by neuronal imbalance. At Praxis we share a common vision of reshaping the human condition into a more freeing and fulfilled existence by developing high impact medicines for patients and families affected by and living with complex brain disorders. Our core Values of  Trust ,  Ownership ,  Curiosity  and  Results  are foundational to every aspect of our business and are exemplified by each and every one of our team members. \n  Additional Requirement \n  To safeguard the health of our employees and their families, our partners and visitors, and our communities, Praxis requires that all employees be up to date on their COVID-19 vaccinations, including CDC recommended booster shots. Employees must provide proof of such vaccinations before beginning employment, except where prohibited by law. Requests for exemption will be considered and Praxis will provide reasonable accommodations unless doing so would pose an undue hardship. \n \n  Diversity, Equity & Inclusion \n  Guided by our core values, at Praxis Precision Medicines, Inc. we continue to DARE FOR MORE\u2122 to advance, promote, and champion diversity, equity, and inclusion by encouraging individuals to bring their authentic selves and perspectives to work each day. We are an equal opportunity employer and committed to providing opportunities to all qualified applicants without regard to race, religious creed, color, gender identity or expression, age, national origin, sexual orientation, disability, genetics, military service and veteran status, or any other characteristic protected by federal, state, or local laws. \n   \n Attention: Job Scam Alert  Praxis has recently become aware of fraudulent job recruitment postings from individuals claiming to represent Praxis. These postings seek financial information in connection with fraudulent opportunities for employment. If you suspect any fraudulent activity or misrepresentation in connection with a Praxis job opportunity, please report it", "cleaned_desc": " \n  Masters degree in statistics, math, or computer science.  \n Must have minimum of 8 years in a senior programming/statistical role within the biotechnology or pharmaceutical industry within drug development. \n  Experience on the sponsor side is required, experience within a CRO helpful. \n  Strong leadership, communications, and collaboration skills required.  \n Good knowledge of drug development and commercialization processes. Must have solid Phase 3 readout experience/know how to derive data in CDISC compliant datasets and be able to evidence experience with submissions. \n  Excellence in SAS, SAS/macro, SAS/Graph, Tables, listings and figures production and independent QC. \n  Experience developing TFL shells, annotated CRF, ADaM/SDTM specs, review guidance and programming specs. \n  Proven ability to proactively identify issues, recommend and implement solutions.  \n Good knowledge of statistical programming languages such as SAS, R and R Shiny \n  Experience managing vendors and driving quality and timelines.  ", "techs": ["sas", "sas/macro", "sas/graph", "cdisc compliant datasets", "sas/graph", "tables", "listings", "figures", "tfl shells", "annotated crf", "adam/sdtm specs", "review guidance", "programming specs", "sas", "r shiny"]}, "a5d061fe92743ef1": {"terms": ["data science"], "salary_min": 152508.05, "salary_max": 193109.17, "title": "Oracle Fusion Analytics Warehouse Architect", "company": "Argano", "desc": "Description: \n The FAW Architect will become a valuable part of the HCM COE team, he will play a crucial role in configuring, implementing, and supporting functional & Technical activities within an Oracle FAW environment, along working with other team members. The Architect will be responsible for managing & deliver complex projects on-time and on-budget with quality. Independently executes work across all aspects of delivery \u2013 including client management, partner management and execution. Collaborates frequently with COE team members on solutions & decisions on what approach to be done on different engagements. You will be reporting to Director of HCM COE team. \n RESPONSIBILITIES \n \n Translate functional and non-functional requirements into actionable operational insights \n Collaborate with business and technical teams to identify reporting requirements \n Prepare functional specification in collaboration with business and data systems \n Produce mapping of reporting attributes to tables and columns \n Collaborate with FAW development team to deliver business intelligence reports \n Integrate disparate enterprise datasets (TXT, CSV, Avro, etc.) and databases (relational and NoSQL) \n Perform data validation and QA in preparation for UAT \n Assist with the Sales and Service process across entire Enterprise \n Contribute in all phases of the software development lifecycle \n Participate in scrum sessions using Agile development \n Interact with other team members and customers on regular basis \n Assist with provisioning Fusion Analytics Warehouse (FAW), verify FAW prerequisites, configure and activate pipeline data loads \n Assist with FAW data validation. \n Setup SSO to enable Fusion SaaS Apps users to access FAW, enable standard object and data security. \n Architect solution to feed data from external (non-Fusion) sources into FAW and make the data accessible to report in FAW. \n Educate clients on Cloud technologies and facilitate decision making. \n Document all technical specifications and project deliverables. \n \n BUSINESS-UNIT & TECHNOLOGIES REQUIREMENT \n \n Strong grasp of core data warehouse concept and design paradigms \n Solid understanding of Oracle\u2019s analytics offerings including OAC, OBIEE, OBIA, RPD, Machine Learning and Autonomous Data Warehouse (ADW) \n Knowledge of Oracle Cloud HCM modules \u2013 Core HR, Payroll, Absences, Benefits, Time and Labor are also desirable \n Knowledge of Oracle Cloud HCM \n Experience with common web connectivity and integration standards/protocols like XML, SOAP, REST, JSON and JDBC \n Experience integrating with enterprise applications, databases, service layers, and message queues \n Experience with relational (SQL) & NoSQL databases \n Experience with Cloud Platforms like Oracle, AWS, Google, Azure, Salesforce \n Desire & ability to work in a team environment and train on new technologies \n Excellent communication skills, both written and verbal \n \n Experience Requirements: \n \n Bachelor\u2019s degree in a computer science or related field (MS preferred) \n Experience as a data scientist or developer with Fusion Analytics Warehouse (FAW), Autonomous Data Warehouse (ADW), Oracle Analytics Cloud (OAC) or Oracle Data Integrator (ODI) are MUST-have requirement \n Experience with OBIEE, PowerBI, Snowflake, Tableau, etc. also desirable \n Knowledge of business software solutions like CRM, CPQ, ERP, HCM \n Experience working on enterprise-wide projects \n Experience with complex data analysis, data migrations, analytics, and insights \n Good querying skills in Oracle database with the ability to understand and debug \n Implementation of security protocols \n Strong understanding of Data Modelling \n \n The base compensation range for this position is $140,000 - $160,000, commensurate with experience. Argano also offers a performance-based bonus and strong benefits package, including Medical, Dental, Vision, 401K, Paid Parental Leave and Flexible Time Off.", "cleaned_desc": " Integrate disparate enterprise datasets (TXT, CSV, Avro, etc.) and databases (relational and NoSQL) \n Perform data validation and QA in preparation for UAT \n Assist with the Sales and Service process across entire Enterprise \n Contribute in all phases of the software development lifecycle \n Participate in scrum sessions using Agile development \n Interact with other team members and customers on regular basis \n Assist with provisioning Fusion Analytics Warehouse (FAW), verify FAW prerequisites, configure and activate pipeline data loads \n Assist with FAW data validation. \n Setup SSO to enable Fusion SaaS Apps users to access FAW, enable standard object and data security.   Architect solution to feed data from external (non-Fusion) sources into FAW and make the data accessible to report in FAW. \n Educate clients on Cloud technologies and facilitate decision making. \n Document all technical specifications and project deliverables. \n \n BUSINESS-UNIT & TECHNOLOGIES REQUIREMENT \n \n Strong grasp of core data warehouse concept and design paradigms \n Solid understanding of Oracle\u2019s analytics offerings including OAC, OBIEE, OBIA, RPD, Machine Learning and Autonomous Data Warehouse (ADW) \n Knowledge of Oracle Cloud HCM modules \u2013 Core HR, Payroll, Absences, Benefits, Time and Labor are also desirable   Knowledge of Oracle Cloud HCM \n Experience with common web connectivity and integration standards/protocols like XML, SOAP, REST, JSON and JDBC \n Experience integrating with enterprise applications, databases, service layers, and message queues \n Experience with relational (SQL) & NoSQL databases \n Experience with Cloud Platforms like Oracle, AWS, Google, Azure, Salesforce \n Desire & ability to work in a team environment and train on new technologies \n Excellent communication skills, both written and verbal \n \n Experience Requirements:   \n Bachelor\u2019s degree in a computer science or related field (MS preferred) \n Experience as a data scientist or developer with Fusion Analytics Warehouse (FAW), Autonomous Data Warehouse (ADW), Oracle Analytics Cloud (OAC) or Oracle Data Integrator (ODI) are MUST-have requirement \n Experience with OBIEE, PowerBI, Snowflake, Tableau, etc. also desirable \n Knowledge of business software solutions like CRM, CPQ, ERP, HCM \n Experience working on enterprise-wide projects \n Experience with complex data analysis, data migrations, analytics, and insights \n Good querying skills in Oracle database with the ability to understand and debug \n Implementation of security protocols ", "techs": ["txt", "csv", "avro", "relational databases", "nosql databases", "fusion analytics warehouse (faw)", "agile development", "cloud technologies", "oracle analytics cloud (oac)", "obiee", "obia", "rpd", "machine learning", "autonomous data warehouse (adw)", "oracle cloud hcm modules", "xml", "soap", "rest", "json", "jdbc", "enterprise applications", "databases", "service layers", "message queues", "sql", "nosql", "cloud platforms (oracle", "aws", "google", "azure", "salesforce)", "fusion analytics warehouse (faw)", "autonomous data warehouse (adw)", "oracle analytics cloud (oac)", "oracle data integrator (odi)", "obiee", "powerbi", "snowflake", "tableau", "crm", "cpq", "erp", "hcm", "oracle database."]}, "84b6a1e685595b1c": {"terms": ["data science", "machine learning engineer", "mlops"], "salary_min": 93300.0, "salary_max": 212000.0, "title": "Machine Learning Engineer, Senior", "company": "Booz Allen Hamilton", "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Arlington,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0181841\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Machine Learning Engineer, Senior\n           The Opportunity: \n  Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning (ML), and artificial intelligence (AI) advances? In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, you know the answers are in the data. \n \n  We have an opportunity for you to use your analytical skills to improve the government's advanced analytics capabilities. You\u2019ll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You\u2019ll develop algorithms, write scripts, build predictive analytics, apply ML and deep learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help drive innovation, research, and development for our military and government leaders to make informed decisions. You\u2019ll provide your client with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in bringing decision support and innovation to our clients. \n \n  Empower change with us. \n \n  You Have: \n \n  4+ years working within data science, machine learning engineering, or data research, in a professional or academic environment \n  2+ years of experience with developing machine learning models, including supervised, unsupervised, or reinforcement learning \n  Experience with designing, developing, deploying, and testing in AWS and using tools, including Lambda, API Gateway, or S3 \n  Experience with containerization, including Docker or Kubernetes \n  Experience with deploying AI \n  Ability to obtain a security clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with MLOps, GitOps, and string programming skills in Python or Java \n  Experience with distributed computing frameworks, including Spark, RAPIDS, Ray, or Polars \n  Experience with data engineering tools, including Databricks, Spark, Elasticsearch, Airflow, or a data warehouse \n  Experience with Cloud services, including Azure or Google Cloud \n  Possession of excellent oral and written communication skills \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.", "cleaned_desc": " \n \n \n \n \n \n \n \n         Machine Learning Engineer, Senior\n           The Opportunity: \n  Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning (ML), and artificial intelligence (AI) advances? In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors from fraud detection to cancer research, to national intelligence, you know the answers are in the data. \n \n  We have an opportunity for you to use your analytical skills to improve the government's advanced analytics capabilities. You\u2019ll work closely with your client to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You\u2019ll develop algorithms, write scripts, build predictive analytics, apply ML and deep learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help drive innovation, research, and development for our military and government leaders to make informed decisions. You\u2019ll provide your client with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in bringing decision support and innovation to our clients. \n \n  Empower change with us. \n \n  You Have: \n \n  4+ years working within data science, machine learning engineering, or data research, in a professional or academic environment \n  2+ years of experience with developing machine learning models, including supervised, unsupervised, or reinforcement learning \n  Experience with designing, developing, deploying, and testing in AWS and using tools, including Lambda, API Gateway, or S3    Experience with containerization, including Docker or Kubernetes \n  Experience with deploying AI \n  Ability to obtain a security clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with MLOps, GitOps, and string programming skills in Python or Java \n  Experience with distributed computing frameworks, including Spark, RAPIDS, Ray, or Polars \n  Experience with data engineering tools, including Databricks, Spark, Elasticsearch, Airflow, or a data warehouse \n  Experience with Cloud services, including Azure or Google Cloud \n  Possession of excellent oral and written communication skills \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n \n  Grow With Us ", "techs": ["machine learning engineer", "iot", "machine learning (ml)", "artificial intelligence (ai)", "data scientist", "algorithms", "predictive analytics", "ml", "deep learning", "aws", "lambda", "api gateway", "s3", "docker", "kubernetes", "ai", "security clearance", "mlops", "gitops", "python", "java", "spark", "rapids", "ray", "polars", "databricks", "elasticsearch", "airflow", "data warehouse", "azure", "google cloud."]}, "b10f58292ae01cde": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Multiple Locations \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n ffgMrJQNQM", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python", "deep learning", "different language", "tensorflow"]}, "1018b5b05f687f0e": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n gDAHM5GD9L", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python", "deep learning", "tensorflow"]}, "42452058c18334f3": {"terms": ["data science"], "salary_min": 150000.0, "salary_max": 185000.0, "title": "Director of Capture & Business Development", "company": "JANUS Research Group", "desc": "Candidates must have an active Secret clearance and verify, before applying, that you meet the minimum requirements of the position \n JANUS Research is seeking a Director of Capture & Business Development to lead the Mission & Training Solutions\u2019 business unit\u2019s development and capture activities focused on Data Science & Engineering, DevSecOps System / Software Development, Cyber Operations, and Training Systems Solutions. The position is focused on identifying, qualifying, and capturing opportunities within DoD and Civilian customer set, continuing to build the JANUS reputation in Federal market. Responsible for building and maintaining the business pipeline, executing the BD process, maintaining a high win probability, and growing business by winning. \n This position can be remote anywhere in the continental US. \n Primary Responsibilities \n \n Create, grow, and mature the pipeline for MTS\u2019 opportunities \n Identify, Qualify, and Capture opportunities aligned with the Data Science & Engineering, DevSecOps System / Software Development, Cyber Operations, and Training Systems Solutions \n Assist in creating strategies, win themes, and discriminators for implementation into proposals \n Create and execute customer call plans. Coordinate and conduct meetings with customers, competitors, clients, and teammates to develop market insight on requirements, acquisition strategy, acquisition timing, and contract vehicle choices \n Understand priorities, and accordingly Groom & Balance Pipeline with appropriate mix of opportunities, on a continuous basis \n Build winning teams for relevant solicitations \n Have reasonable understanding of priority areas \u2013 to include Data Science & Engineering, DevSecOps System / Software Development, Cyber Operations, and Training Systems Solutions \u2013 such that can provide critical reviews, recovery, and writing support. \n Experience in both the DoD and Federal Civilian IT support BD arena.  \n Participate in the JANUS business development process, including pipeline reviews, opportunity gate reviews, black hat sessions, and proposal reviews. \n Collaborate within management to support cross enterprise objectives and customer engagement. \n Support overall strategic planning and linking pursuits/capture activities which support the business development metrics for awards, submits, and pipeline. \n \n Qualifications \n Candidates must be US Citizens and be eligible to obtain a security clearance. \n \n 15 years of prior relevant experience. \n Demonstrated success in winning opportunities in the full and open arena ranging from $10M to $100M in total contract value. \n Demonstrated ability to understand the ever-evolving IT landscape and priority drivers at various federal departments and agencies \n Demonstrated access to and relationships within DoD and/or FedCiv markets \n Demonstrated teaming relationships with companies of mid & large sizes that operate in federal IT acquisition market \n Excellent written and verbal communication skills. \n Leadership skills to develop, organize and execute significant BD activities, including building industry teams, assessing win probability, and executing customer call plans. \n Ability to gain internal support, operate independently with limited supervision and feedback, and establish a solid working relationship with technical staff, division managers, and peers. \n Self-starter and ability to manage time independently without direct supervision. \n The ability to operate at the senior level and influence, negotiate and close. \n Experience in executing a leading role during formal proposal submissions. \n Military and or Government contracting experience a plus \n \n Education  \n \n Bachelor\u2019s degree  \n \n \n Target salary range:  $150k - 185k . The estimate displayed represents the typical salary range for this position based on experience and other factors. \n \n JANUS strives to provide opportunities for career growth through training and development. We also offer an attractive comprehensive benefit package to include health and welfare plans and financial products. As part of a total rewards program, employees can benefit from our referral bonus program, and other various employee awards. JANUS Research Group takes pride in our benefit package and rewards program which has earned us the certification of a  Great Place to Work \u2122 \n JANUS Research Group provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: Alisha Pollard, Director of Human Resources at alisha.pollard@janusresearch.com or calling (706) 364-9100. Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within JANUS Research Group will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with JANUS Research Group. \n JANUS Research Group participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.     E-Verify    JANUS Research Group is an equal opportunity/ affirmative action employer. It is company policy to provide equal opportunity in all areas of employment practice without regard to race, color, religion, sex, sexual orientation, national origin, age, marital status, veteran status, citizenship, or disability. \n \n This contractor and subcontractor shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibit discrimination against all individuals based on their race, color, religion, sex, or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment qualified individuals without regard to race, color, religion, sex, national origin, protected veteran status or disability.", "cleaned_desc": "", "techs": ""}, "5ad20d0c50fe178d": {"terms": ["data science", "data engineer"], "salary_min": 101000.0, "salary_max": 130000.0, "title": "ML Data Engineer", "company": "Cognizant Technology Solutions", "desc": "This remote position is   open to any qualified applicant in the United States. \n  *Please note, this role is not able to offer visa transfer or sponsorship now or in the future* \n  Practice - AIA - Artificial Intelligence and Analytics \n  About AI & Analytics:  Artificial intelligence (AI) and the data it collects and analyzes will soon sit at the core of all intelligent, human-centric businesses. By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. Within AI & Analytics, we work to design the future\u2014a future in which trial-and-error business decisions have been replaced by informed choices and data-supported strategies! \n  By applying AI and data science, we help leading companies to prototype, refine, validate, and scale their AI and analytics products and delivery models! Cognizant\u2019s AIA practice takes insights that are buried in data and provide businesses with a clear way to transform how they source, interpret, and consume their information. Our clients need flexible data structures and a streamlined data architecture that quickly turns data resources into informative, meaningful intelligence. \n  Job Duties and Responsibilities: \n \n Analyze complex business and functional problems related to the implementation of new business functions customization of existing business process. \n Partner with other technology teams to work with business executives and end users to conceptualize new application projects recommend technologies and implementation strategies. \n Understand the changing business needs of the organization/projects and recommend viable strategies for the future. \n Author and/or Review architecture/design and other technical documents ensuring high quality deliverables and systems development across tech stacks and applications teams. \n Help ensure high quality software delivery by providing guidance on testing strategy providing technical consultation to plan/design performance testing and profiling of application and providing feedback/guidance for tuning performance and other non-functional elements of the application. \n \n Position Qualifications: \n  Required skills: \n \n Bachelor\u2019s degree in Computer Science or related field \n 8+ years experience in BigData Spark/Scala SQL DataBricks AWS Data \n 5+ years experience with Data Management Databricks Amazon Redshift Apache Spark \n Strong experience using AWS OpenSource \n Demonstrated experience in Spark/Scala \n Strong knowlage in Agile scrum methodology \n \n Salary and Other Compensation: \n  The annual salary for this position is between $101,000 - $130,000 depending on experience and other qualifications of the successful candidate. \n  This position is also eligible for Cognizant\u2019s discretionary annual incentive program and stock awards, based on performance and is subject to the terms of Cognizant\u2019s applicable plans. \n  Benefits : Cognizant offers the following benefits for this position, subject to applicable eligibility requirements: \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n Disclaimer:  The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law. \n  #LI-AY1 #CB #Ind123 \n  Employee Status :  Full Time Employee \n  Shift :  Day Job \n  Travel :  No \n  Job Posting :  Oct 10 2023 \n \n \n  About Cognizant \n  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.\n  \n  Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. \n \n  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. \n  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.", "cleaned_desc": " Understand the changing business needs of the organization/projects and recommend viable strategies for the future. \n Author and/or Review architecture/design and other technical documents ensuring high quality deliverables and systems development across tech stacks and applications teams. \n Help ensure high quality software delivery by providing guidance on testing strategy providing technical consultation to plan/design performance testing and profiling of application and providing feedback/guidance for tuning performance and other non-functional elements of the application. \n \n Position Qualifications: \n  Required skills: \n \n Bachelor\u2019s degree in Computer Science or related field \n 8+ years experience in BigData Spark/Scala SQL DataBricks AWS Data ", "techs": ["bigdata", "spark", "scala", "sql", "databricks", "aws data"]}, "9da37c6dfbf54e57": {"terms": ["data science"], "salary_min": 205318.0, "salary_max": 250944.0, "title": "Principal Data Scientist, Machine Learning", "company": "Rec Room", "desc": "Rec Room is the best place to build and play games together. Players can chat, hang out, play in millions of rooms, or build something new to share with the world! We have a vibrant commercial ecosystem within Rec Room, and our goal is to enable creators to be rewarded for their work. Come join us on the ground floor to help optimize the ecosystem for both players and the business. \n  As a Principal Machine Learning Data Scientist, you'll be responsible for designing, developing, and implementing machine learning models to power our in-game store recommendations and serve users content that they'd find valuable. You'll be supporting creators in making a living on the platform, as well as playing a critical role in the success of Rec Room as a business. \n  WHAT YOU'LL DO: \n \n Design, develop and implement production-facing ML models to deliver valuable commerce content to our users. \n Collaborate closely with the ML Infra team to define a roadmap that powers real-time personalized ranking models. \n Design and run A/B tests, analyze model performance, and deep dive into the data to uncover opportunities for improvements. \n Build out pipelines in collaboration with our Analytics Engineering team to enable model building on top of sophisticated features. \n Set best practices, mentor, and provide guidance to the more junior Data Scientists. \n \n WE ARE LOOKING FOR INDIVIDUALS WITH: \n \n Master's or Ph.D. degree in computer science, statistics, mathematics, or a related field \n 10+ years of ML experience in a production setting, with extensive experience working on ranking/recommendations \n Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n \n \n \n   The base pay range for this position is listed below; please note the base pay may vary depending on location, job-related knowledge, skills, and experience. Stock options and, in some cases, a sign-on bonus may be offered as part of the compensation package. We also offer a full slate of benefits, including flexible vacation, medical, dental vision, life and disability coverage, long-term care insurance, FSA, commuter benefits, a 401(k) plan with company match, and a parental leave program. We also offer some not-so-standard benefits, including equipment, family, and pet care stipends.\n   \n  Base Pay Range \n \n    $205,318\u2014$250,944 USD\n   \n \n \n  COMPANY INFO TO KNOW: \n  Rec Room offers generous medical, dental, and vision plans that cover you, your spouse/domestic partner, and children. We also support your retirement benefits with a company match. Rec Room values work-life balance by providing unlimited paid time off. Our company values are real and drive our culture. We work hard to be a safe and friendly place for people from all walks of life.  \n Rec Room provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  Applicants who are in need of a reasonable accommodation for any part of the application process may contact, in confidence, accessibilityrequest.hr@recroom.com. Rec Room will work with each individual to define their application-related needs and to try to accommodate those needs. \n  Applicants can find our CCPA disclosure notice here.", "cleaned_desc": " Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n ", "techs": ["recommendations", "ranking", "personalization", "search", "content discovery", "python", "sql", "ml infrastructure", "experimentation", "dbt", "spark", "databricks"]}, "5020c3966542f4d4": {"terms": ["data science", "machine learning engineer"], "salary_min": 186000.0, "salary_max": 233000.0, "title": "Senior Manager, Software Engineering - AI Observability (Remote)", "company": "New Relic", "desc": "Req ID \n      \n \n      FY24|R&D|#5409 \n      \n \n \n \n      Location(s) \n      \n \n      Atlanta, Georgia, USA; Chicago, Illinois, USA; Portland, Oregon, USA; Vancouver, Washington, USA; \n      \n \n \n \n      Work arrangement(s) \n      \n \n      Fully Remote (works exclusively from home), Hybrid (works from home and New Relic office throughout the week) \n      \n \n \n \n \n \n \n \n \n \n      Your opportunity \n      \n \n \n \n        At New Relic, we help customers understand, optimize, troubleshoot and improve their sophisticated software systems, including AI, machine learning, and large language models.\n        \n \n \n  Our AI Observability team is looking for an experienced manager with a passion for people, and systems, who can lead and mentor engineers as well as collaborate with multiple teams! This position will report directly to a Director and is available to work from home or any New Relic office.\n        \n \n \n \n \n \n \n \n      What you'll do \n      \n \n \n \n Lead and grow teams of software engineers that work on the observability and reliability of our data platform! \n  Ensure the success of software projects through the planning and execution phases within and across teams \n  Partner closely with product management, fellow engineering managers, and key decision-makers to set up team priorities and roadmap \n  Mentor and develop an engineering team by holding regular coaching and career pathing conversations \n  Provide growth opportunities for engineers by assigning projects tailored to skill level and interests \n  Develop and iterate on processes and practices that keep your team focused and executing efficiently \n \n \n \n \n \n \n      This role requires \n      \n \n \n \n 4+ years of experience leading high-performing operationally focused software engineering teams \n  Experience leading cloud-focused teams or back-end development teams \n  Consistent track record of delivering high-quality software in regular, iterative releases \n  Ability to collaborate within your own and across departments \n  Experience mentoring and coaching team members \n \n \n \n \n \n \n      Bonus points if you have \n      \n \n \n \n Familiarity with modern people management practices \n  Experience leading high-complexity projects with cross-team dependencies \n  Familiarity with observability \n  Familiarity with statistics \n \n  Please note that visa sponsorship is not available for this position. \n \n \n \n \n \n \n \n \n \n \n \n We're looking for bold and passionate people to be a part of our mission to help every engineer do their best work, every day, using data, not opinions, at every stage of the software lifecycle. We'd love to have you apply, even if you don't feel you meet every single requirement. What's most important to us is finding authentic and accountable people who feel connected to our mission and values, not just candidates who check off all the boxes.   We believe in empowering all Relics to achieve professional and business success through a workforce model called  Flex First. Flex First  allows us to work in a variety of workplaces that best support our success, including fully office-based, fully remote, or hybrid.  Read more about  Flex First .   Our hiring process      Please note that visa sponsorship is not available for this position. \n  In compliance with applicable law, all persons hired will be required to verify identity and eligibility to work and to complete employment eligibility verification. Note: Our stewardship of the data of thousands of customers\u2019 means that a criminal background check is required to join New Relic.     We will consider qualified applicants with arrest and conviction records based on individual circumstances and in accordance with applicable law including, but not limited to, the San Francisco Fair Chance Ordinance.    Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. New Relic does not accept unsolicited headhunter and agency resumes, and will not pay fees to any third-party agency or company that does not have a signed agreement with New Relic.     New Relic is an equal opportunity employer. We eagerly seek applicants of diverse background and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities (or disability), age, sexual orientation, veteran status, or any other characteristic protected by law. \n \n \n \n \n \n \n \n \n \n \n \n \n       Estimated Base Pay Range: $ 186,000 - $ 233,000\n         The pay range above represents a reasonable estimate of the salary for the listed position. This role is eligible for a corporate bonus plan and may be eligible for a competitive equity package. Pay within this range varies by work location and may also depend on job-related factors such as an applicant\u2019s skills, qualifications, and experience.\n        \n  New Relic provides a variety of benefits for this role, including healthcare, dental, vision, parental leave and planning, mental health benefits, a 401(k) plan and match, flex time-off, 11 paid holidays, volunteer time off, and other competitive benefits designed to improve the lives of our employees.\n        \n \n \n \n \n \n      Wage - midpoint \n      \n \n      233,000 \n      \n \n \n \n      Wage - minimum \n      \n \n      186,000 \n      \n \n \n \n \n \n \n \n \n \n      #LI-JH1 #LI-Remote", "cleaned_desc": " \n      Your opportunity \n      \n \n \n \n        At New Relic, we help customers understand, optimize, troubleshoot and improve their sophisticated software systems, including AI, machine learning, and large language models.\n        \n \n \n  Our AI Observability team is looking for an experienced manager with a passion for people, and systems, who can lead and mentor engineers as well as collaborate with multiple teams! This position will report directly to a Director and is available to work from home or any New Relic office.\n        \n \n \n \n \n \n \n \n      What you'll do \n      \n \n \n \n Lead and grow teams of software engineers that work on the observability and reliability of our data platform! \n  Ensure the success of software projects through the planning and execution phases within and across teams \n  Partner closely with product management, fellow engineering managers, and key decision-makers to set up team priorities and roadmap \n  Mentor and develop an engineering team by holding regular coaching and career pathing conversations \n  Provide growth opportunities for engineers by assigning projects tailored to skill level and interests ", "techs": ["ai", "machine learning"]}, "88af180e3320482e": {"terms": ["data science"], "salary_min": 98496.0, "salary_max": 158432.0, "title": "Interdisciplinary - Biological Scientist or Mathematical Statistician", "company": "US Animal and Plant Health Inspection Service", "desc": "Duties \n \n The duties may include, but are not limited to: \n Designs and implements project plans associated with analytical epidemiological methods that use statistically valid data compiled on indicators of the health of U.S. livestock. \n Works with other analysts to develop and/or enhance quantitative risk analysis methods and models. \n Functions as an expert in risk analysis, emergency response strategies, livestock disease simulation modeling, and analytical epidemiology. \n Provides scientific insight into the development of defensible regulatory analyses. \n Identifies the changing information needs, researches the potential impact of the integration of such advances into VS programs and provides advice on installation of changes. \n Analyzes data resulting from program/projects to assure scientific accessibility and defensibility. \n Initiates and coordinates projects, evaluates results, and recommends program direction and future activities. \n \n \n \n Requirements \n Conditions of Employment \n \n You must be a US Citizen or US National. \n Individuals who were born male after 12/31/1959 must be Selective Service registered or exempt. \n Subject to satisfactory adjudication of background investigation and/or fingerprint check. \n Direct Deposit: Per Public Law 104-134 all Federal employees are required to have federal payments made by direct deposit to their financial institution. \n Successfully pass the E-Verify employment verification check. To learn more about E-Verify, including your rights and responsibilities, visit E-Verify at https://www.e-verify.gov/ \n Successful completion of one-year trial period. \n Most work is performed in a typical office setting with the normal safety precautions while sitting in an office cubicle and using a computer. \n May be required to walk in a variety of weather conditions and on a variety of surfaces, including wet, uneven surfaces. \n Domestic and international travel is required as an essential function of the job and may require obtaining an Official Government Passport. \n Foreign travel may be to remote locations with few amenities. Vaccinations may be required. \n May visit farms and ranches where a zoonotic animal disease is present. Personal protective clothing and equipment may be required as well as a requirement to shower in and out of some facilities. \n Long term assignments for disease investigations may occur and will require work at a temporary duty station from one-to-four weeks or longer. \n \n \n Qualifications \n \n    Applicants must meet all qualifications and eligibility requirements by the closing date of the announcement, including specialized experience and/or education, as defined below.\n     \n \n BASIC REQUIREMENT for 0401 Series: \n \n Degree:  biological sciences, agriculture, natural resource management, chemistry, or related disciplines appropriate to the position.\n     \n OR \n \n Combination of education and experience:  Courses equivalent to a major, as shown above, plus appropriate experience or additional education.\n     \n \n BASIC REQUIREMENT for 1529 Series: \n \n Degree:  that included 24 semester hours of mathematics and statistics, of which at least 12 semester hours were in mathematics and 6 semester hours were in statistics.\n     \n OR \n \n Combination of education and experience:  at least 24 semester hours of mathematics and statistics, including at least 12 hours in mathematics and 6 hours in statistics, as shown above, plus appropriate experience or additional education.\n     \n \n FOR THE GS-13 LEVEL:  Applicants must have one year of specialized experience (equivalent to the GS-12 grade level) that demonstrates: \n     \n Contributing to the development of methods and models with experiential knowledge of risk assessment methodology and principles to accomplish scientifically defensible risk analyses. \n Providing expertise relevant to population medicine including statistical principles, descriptive epidemiology, economic impacts, and disease measurement related to livestock disease modeling. \n Applying and modifying the application of software for qualitative and quantitative analysis including statistical, database, economic modeling, or epidemiological modeling software, compiling the results and developing effective mechanisms for interpreting the significance of results. \n Developing, applying, and modifying epidemiological or economic simulation models to analyze livestock disease outbreak data and information from multiple and varied sources. \n \n  Note: There is no education substitution for this grade level.\n     \n \n TRANSCRIPTS  are required if: \n     \n This position requires specific coursework or a degree in a specific field to be basically qualified. \n You are qualifying for this position based on a combination of experience and education. \n This education must have been successfully completed and obtained from an accredited school, college, or university \n \n \n COMBINATION OF EDUCATION & EXPERIENCE AT THE GS-13 GRADE LEVEL:  Applicants may have combinations of successfully completed education and specialized experience to meet total qualification requirements. The total percentages must equal at least 100 percent to qualify for that grade level.\n      \n  Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional, philanthropic, religious, spiritual, community, student, social). Volunteer work helps build critical competencies and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.\n     \n \n \n \n Education \n Please see above for education qualification requirement information.  \n \n \n Additional information \n \n \n \n Career Transition Assistance Plan (CTAP), Reemployment Priority List (RPL), or Interagency Career Transition Assistance Plan (ICTAP): Visit the OPM website for information on how to apply as a CTAP, RPL, or ICTAP eligible. To exercise selection priority for this vacancy, CTAP/RPL/ICTAP candidates must meet the basic eligibility requirements and all selective factors. CTAP/ICTAP candidates must be rated and determined to be well qualified (or above) based on an evaluation of the competencies listed in the How You Will Be Evaluated section. When assessed through a score-based category rating method, CTAP/ICTAP applicants must receive a rating of at least 85 out of a possible 100. \n First time hires to the federal government normally start at the lowest rate of the salary range for the grade selected. \n Travel, transportation, and relocation expenses will not be paid. Any travel, transportation, and relocation expense associated with reporting for duty will be the responsibility of the selected employee. \n Locality pay will vary based upon the selectee's duty location. A final salary determination will be made upon selection. \n This is a term appointment not to exceed 13 months. (Appointment may be extended up to 4 years without reannouncing). For more details click: Term Appointments \n Worksite Information:  This is a 100% remote position that must be located within the 50 United States, its territories, or possessions. The duty station for a remote designation is the selectee's home and must be established within the defined geographic options prior to start date. The selectee is not required to regularly work from a government facility however, the option may be available. \n \n \n \n \n \n \n \n Benefits \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.  \n \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n \n \n \n \n How You Will Be Evaluated \n \n You will be evaluated for this job based on how well you meet the qualifications above. \n \n \n    This is a Direct-Hire Authority position, all applicants who meet the minimum qualifications, to include any specialized experience and/or selective placement factor(s), if applicable, will be referred to the selecting official. Before a certificate is issued to the selecting official, your application is reviewed to ensure that you meet all the qualification requirements. A rating will not be used; veteran's preference does not apply due to the existence of the Direct Hire authority for this position.\n     Note: If, after reviewing your resume and/or supporting documentation, a determination is made that you have inflated your qualifications and/or experience, you may be found ineligible. Please follow all instructions carefully. Errors or omissions may affect your rating. Providing inaccurate information on Federal documents could be grounds for non-selection or disciplinary action up to including removal from the Federal service.\n    \n  To preview the application questionnaire, please visit: https://apply.usastaffing.gov/ViewQuestionnaire/12155358 \n   \n \n \n \n \n Benefits \n \n A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.  \n \n \n Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered. \n \n \n Required Documents \n \n As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies. \n The following documents are required for your applicant package to be complete. Our office cannot be responsible for incompatible software, your system failure or downtime, etc. Encrypted documents will not be accepted. Failure to submit required, legible documents may result in loss of consideration.  \n \n Resume that includes:   1) personal information such as name, address, contact information; 2) education; 3) detailed work experience related to this position as described in the major duties including work schedule, hours worked per week, dates of employment; title, series, grade (if applicable); 4) other qualifications; and 5) supervisors name and phone number for each work period listed and whether or not they may be contacted for reference checks. \n If education is required or you are using education to qualify, you must submit a copy of your college transcripts. An unofficial copy is sufficient with the application if it includes your name and the necessary course information; however, if you are selected, you will be required to submit official transcripts prior to entering on duty. Education must have been successfully obtained from an accredited school, college or university. If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show that the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs and such education has been deemed equivalent to that gained in an accredited U.S. education program. For further information, visit the following: Foreign Education Evaluation. All transcripts must be in English or include an English translation. \n Although veterans' preference doesn't apply under Direct Hire Authority, applicants are encouraged to provide documentation of their eligibility. If claiming veterans' preference, you must submit a DD214, Certificate of Release from Active Duty, which shows dates of service and discharge under honorable conditions. If currently on active duty you must submit a certification of expected discharge or release from active duty service under honorable conditions within 120 days after the date the certification is submitted. The certification must be on the letterhead of the appropriate military branch and include the dates of military service. \n If claiming 10-point veterans' preference you must provide the DD214 or certification requirements (see above bullet), plus the proof of entitlement of this preference as listed on the SF-15 Application for 10-point Veterans' Preference. The SF-15 should be included but is not required. Failure to submit these documents could result in the determination that there is insufficient documentation to support your claim for 10-point preference. For more information on veterans' preference visit FEDSHIREVETS \n Surplus or displaced employees eligible for CTAP, RPL, or ICTAP priority must provide: proof of eligibility (RIF separation notice, notice of proposed removal for declining a transfer of function or directed reassignment to another commuting area, notice of disability annuity termination), SF-50 documenting separation (as applicable), last performance appraisal that is at least fully successful or its equivalent, and your most recent SF-50 noting position, grade level, and duty location with your application per 5 CFR 330. \n Worker's Compensation Separation: Agency certification of inability to place employee AND Notification of Separation OR Separation SF-50. \n Disability Annuity Termination: Notification from OPM of disability annuity termination AND Separation SF-50 of the last position held. Military Reserve or National Guard Technician Special Disability Retirement Annuity under 5 U.S.C. 8337(h) or 8456: Certification of special disability retirement annuity from a military department or National Guard Bureau AND Separation SF-50 of the last position held. \n \n \n \n How to Apply \n \n \n Please read the entire announcement and all instructions before you begin. You must complete this application process and submit all required documents electronically by 11:59p.m. Eastern Time (ET) on the closing date of this announcement.    Applying online is highly encouraged. We are available to assist you during business hours (normally 8:00a.m. - 4:00p.m., Monday - Friday). If applying online poses a hardship, contact the Agency Contact listed below well before the closing date for an alternate method. All hardship application packages must be complete and submitted no later than noon ET on the closing date of the announcement in order to be entered into the system prior to its closing.    This agency provides reasonable accommodation to applicants with disabilities on a case-by-case basis; contact the Agency Contact to request this.     Step 1:  Create a USAJOBS account (if you do not already have one) at www.usajobs.gov. It is recommended that as part of your profile you set up automatic email notification to be informed when the status of your application changes. If you choose not to set up this automatic notification, then you will have to log into your USAJOBS account to check on the status of your application.     Step 2:  Create a Resume with USAJOBS or upload a Resume into your USAJOBS account. You may want to customize your resume to ensure it documents duties and accomplishments you have gained that are directly related to this position in order to verify that qualifications are met. In addition, your resume must support your responses to the online questionnaire (you may preview the online questionnaire by clicking on the link at the end of the How You Will Be Evaluated section of the job announcement).     Step 3:  Click \"Apply Online\" and follow the prompts to complete the Occupational Questionnaire and attach any additional documents that may be required. You can update your application or documents anytime while the announcement is open. Simply log into your USAJOBS account and click on \"Application Status.\" Click on the position title, and then select \"Update Application\" to continue.     NOTE : Please verify that documents you are uploading from USAJOBs transfer into the Agency's staffing system as there is a limitation to the number of documents that can be transferred. However, once in the Agency's staffing system, you will have the opportunity to upload additional documents. Uploaded documents must be less than 5MB and in one of the following document formats: GIF, JPG, JPEG, PNG, RTF, PDF, TXT or Word (DOC or DOCX). Do not upload Adobe Portfolio documents because they are not viewable. \n \n \n Agency contact information \n MRP Human Resources  \n \n \n Phone \n 612-336-3227  \n Email \n MRP.Application.Help@usda.gov  \n \n \n Address \n \n \n Animal and Plant Health Inspection Service \n \n USDA APHIS MRPBS \n \n 250 Marquette Avenue, Suite 410  \n \n Minneapolis, MN 55401 \n \n US  \n \n \n \n \n Next steps \n \n If you set up your USAJOBS account to send automatic email notifications, your will receive an email acknowledging: 1) the submission of your online Occupational Questionnaire and resume was successful, 2) if you were referred to the selecting official for consideration, and 3) if you were selected or not selected. Your application will be reviewed to verify that you meet the eligibility and qualification requirements for the position prior to issuing referral lists to the selecting official. If further evaluation or interviews are required, you will be contacted. Log in to your USAJOBS account to check your application status. We expect to make a final job offer approximately 40 days after the deadline for applications.    Multiple positions may be filled from this announcement. Once a selection is made for this position, the remaining list of qualified candidates may be shared with other hiring managers in the agency who have similar vacancies. You will have the opportunity to opt-in if you are willing to have your name, application materials, and assessment results shared to be considered with additional hiring managers. There is no guarantee of further consideration, and you can continue to explore job opportunity announcements.  \n \n \n Fair and Transparent \n \n The Federal hiring process is set up to be fair and transparent. Please read the following guidance.  \n \n Equal Employment Opportunity (EEO) Policy  \n Reasonable accommodation policy  \n Financial suitability  \n Selective Service  \n New employee probationary period  \n Signature and false statements  \n Privacy Act  \n Social security number request  \n \n \n \n \n \n Required Documents \n \n The following documents are required for your applicant package to be complete. Our office cannot be responsible for incompatible software, your system failure or downtime, etc. Encrypted documents will not be accepted. Failure to submit required, legible documents may result in loss of consideration.  \n \n Resume that includes:   1) personal information such as name, address, contact information; 2) education; 3) detailed work experience related to this position as described in the major duties including work schedule, hours worked per week, dates of employment; title, series, grade (if applicable); 4) other qualifications; and 5) supervisors name and phone number for each work period listed and whether or not they may be contacted for reference checks. \n If education is required or you are using education to qualify, you must submit a copy of your college transcripts. An unofficial copy is sufficient with the application if it includes your name and the necessary course information; however, if you are selected, you will be required to submit official transcripts prior to entering on duty. Education must have been successfully obtained from an accredited school, college or university. If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show that the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs and such education has been deemed equivalent to that gained in an accredited U.S. education program. For further information, visit the following: Foreign Education Evaluation. All transcripts must be in English or include an English translation. \n Although veterans' preference doesn't apply under Direct Hire Authority, applicants are encouraged to provide documentation of their eligibility. If claiming veterans' preference, you must submit a DD214, Certificate of Release from Active Duty, which shows dates of service and discharge under honorable conditions. If currently on active duty you must submit a certification of expected discharge or release from active duty service under honorable conditions within 120 days after the date the certification is submitted. The certification must be on the letterhead of the appropriate military branch and include the dates of military service. \n If claiming 10-point veterans' preference you must provide the DD214 or certification requirements (see above bullet), plus the proof of entitlement of this preference as listed on the SF-15 Application for 10-point Veterans' Preference. The SF-15 should be included but is not required. Failure to submit these documents could result in the determination that there is insufficient documentation to support your claim for 10-point preference. For more information on veterans' preference visit FEDSHIREVETS \n Surplus or displaced employees eligible for CTAP, RPL, or ICTAP priority must provide: proof of eligibility (RIF separation notice, notice of proposed removal for declining a transfer of function or directed reassignment to another commuting area, notice of disability annuity termination), SF-50 documenting separation (as applicable), last performance appraisal that is at least fully successful or its equivalent, and your most recent SF-50 noting position, grade level, and duty location with your application per 5 CFR 330. \n Worker's Compensation Separation: Agency certification of inability to place employee AND Notification of Separation OR Separation SF-50. \n Disability Annuity Termination: Notification from OPM of disability annuity termination AND Separation SF-50 of the last position held. Military Reserve or National Guard Technician Special Disability Retirement Annuity under 5 U.S.C. 8337(h) or 8456: Certification of special disability retirement annuity from a military department or National Guard Bureau AND Separation SF-50 of the last position held. \n \n \n \n \n \n \n \n Help \n  This job is open to \n \n \n \n \n Career transition (CTAP, ICTAP, RPL) \n Federal employees who meet the definition of a \"surplus\" or \"displaced\" employee. \n \n \n \n \n The public \n U.S. Citizens, Nationals or those who owe allegiance to the U.S. \n \n \n \n Clarification from the agency \n Applications will be accepted from any U.S. citizen. Direct Hire Authority will be used to fill this position. Veterans Preference and traditional rating and ranking of applicants does not apply to this vacancy.", "cleaned_desc": "", "techs": ""}, "dd44fe4c20b7368c": {"terms": ["data science"], "salary_min": 65.0, "salary_max": 70.0, "title": "(remote) data scientist", "company": "Randstad", "desc": "summary \n \n \n \n \n \n       $65 - $70 per hour\n      \n \n \n \n \n         contract\n        \n \n \n \n \n       bachelor degree\n      \n \n \n \n \n \n \n \n \n      category\n      computer and mathematical occupations\n    \n \n \n      reference\n      1029699\n    \n \n \n \n \n \n job summary:\n   Randstad Digital is in search of a Data Scientist with an exciting opportunity with an industry leading employer. In this role the Data Scientist will be processing, cleaning, and analyzing large volumes of data to develop business solutions for a variety of projects. This position utilizes statistics, machine learning programming, and data modeling to discover information, recognize patterns and trends to address business problems.\n  \n \n \n  location: Leawood, Kansas\n   job type: Contract\n   salary: $65 - 70 per hour\n   work hours: 8am to 4pm\n   education: Bachelors\n  \n  responsibilities:\n   Oversee the analysis of data to discover information, business value, patterns and trends in support to guide development of assets business solutions.\n  \n \n   Oversee data gathering, finding patterns and relationships and create prediction models to evaluate client assets.  Conduct research and apply existing data science methods to complex business line problems.  Responsible for monitoring client assets and perform predictive and root cause analysis to identify adverse trends; choose best fit methods, define algorithms, and validate and deploy models to achieve desired results. \n    Oversee the production of reports and visualizations to communicate technical results and interpretation of trends; effectively communicate findings and recommendations to all areas of the business. \n  Requirements\n   Bachelor's degree in Analytics, Computer Science, Information Systems, Statistics, Math, or related field from an accredited program required. Master's degree is preferred.\n  \n \n   5 + years of experience as a Data Scientist in and Enterprise level environment  Related consulting experience preferred.  Experience with machine learning techniques, specifically in python  Experience in leading data mining and advanced analytics.  Experience in machine learning and advanced statistical algorithms.  Experience in data visualization.  Ability to work with team members and clients to assess needs, provide assistance, and resolve problems. \n    Excellent verbal/written communication, and the ability to present and explain technical concepts to business \n \n  qualifications:\n  \n \n Experience level: Experienced  Minimum 5 years of experience \n    Education: Bachelors \n \n  skills: \n  \n Python \n  Snowflake \n  AWS \n  Cloud    Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.    At Randstad Digital, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.    Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).", "cleaned_desc": "  \n \n   5 + years of experience as a Data Scientist in and Enterprise level environment  Related consulting experience preferred.  Experience with machine learning techniques, specifically in python  Experience in leading data mining and advanced analytics.  Experience in machine learning and advanced statistical algorithms.  Experience in data visualization.  Ability to work with team members and clients to assess needs, provide assistance, and resolve problems. \n    Excellent verbal/written communication, and the ability to present and explain technical concepts to business \n \n  qualifications:\n  \n \n Experience level: Experienced  Minimum 5 years of experience \n    Education: Bachelors \n \n  skills: \n  \n Python \n  Snowflake ", "techs": ["python", "snowflake"]}, "336a6184bccd887d": {"terms": ["data science", "mlops"], "salary_min": 108275.65, "salary_max": 137101.1, "title": "Senior Data Scientist (Experienced Level Professional)", "company": "Michelin", "desc": "Senior Data Scientist (Experienced Level Professional)\n  \n \n   Michelin is hiring!\n  \n \n   - - - - - - - - - - - -\n  \n \n  THIS OPEN POSITION IS LOCATED ONLY AT THE FOLLOWING LOCATIONS:Michelin North America HQ \n \n \n \n  THE \u201cADDITIONAL LOCATIONS\u201d SHOWN AT THE RIGHT INDICATE WHERE THIS JOB POSTING IS VISIBLE, NOT WHERE THE POSITION IS LOCATED \n \n \n \n   Michelin is hiring! We are looking for a data scientist to join our company be a key player in our IT Business Intelligence & Analytics team.\n  \n \n \n   Overview:\n  \n \n   The Senior Data Scientist manages and analyses disparate datasets, researches and implements Machine Learning and Advanced Analytics (ARIMA, optimization, etc) solutions to address complex business questions. He/ She will collaborate with Business leaders across the company to accelerate the development and deployment of Artificial Intelligence (AI) / Machine Learning (ML) models, and influence and innovate solutions that impact the business.\n  \n \n   This job opportunity is open to 100% remote work if needed.\n  \n \n \n   What you'll do:\n  \n \n   Partner with the business to scope out opportunities and potential value creation.\n  \n \n   Master the Supply Chain, Logistics, Manufacturing, Marketing and Sales value chains.\n  \n \n   Determine the relevant data among those available and identifying the missing data to acquire to successfully implement the opportunity.\n  \n \n   Explore, select, and create features to build models.\n  \n \n   Fit and evaluates Machine Learning/Advanced Analytics/Advanced Statistics models to solve the business problem and satisfy acceptance criteria.\n  \n \n   Present the results and the model (performances and limits) to business leadership and lead technical discussions for model improvement.\n  \n \n   Design, build, and automate all steps of the Machine Learning (MLOps) industrialization workflow.\n  \n \n   Collaborate with product managers and internal partners to automate integrated AI/ML systems.\n  \n \n   Develop partnerships, standard processes, network and knowledge by :\n  \n \n  Mentoring less experienced people \n  Transmitting knowledge by development and deployment of training modules and various other communication methods \n  Participating in the development of the Data Science Roadmap and Network \n  Accelerating the adoption of Artificial Intelligence across the enterprise through the use of machine learning, modern architecture and software engineering best practices \n \n \n \n   What you\u2019ll bring:\n  \n \n   Bachelor\u2019s Degree or greater in Statistics, Applied Mathematics, Computer Science Information Systems or equivalent.\n  \n \n   Must have experience with data science methodology and techniques: Exploratory Data Analysis, Feature Engineering, Cross Validation, Visualization, Advanced Analytics, Machine Learning, Predictive Modeling\n  \n \n   Relevant software development skills with Python and PySpark; proficiency using Azure Service, Databricks and software repositories.\n  \n \n   Exposure/experience putting into production models with MLOps: CI/CD workflows with a Product approach.\n  \n \n   Collaborate and work within an international team environment.\n  \n \n \n \n    #LI-RG1\n   \n \n    #LI-hiringmichelin\n   \n \n \n \n   Inspire Motion for Life: Apply Today!\n  \n \n \n   As the leading mobility company, we work with tires, around tires and beyond tires to enable Motion for Life. Dedicated to enhancing our clients\u2019 mobility and sustainability, Michelin designs and distributes the most suitable tires, services and solutions for our customers\u2019 needs. Michelin provides digital services, maps and guides to help enrich trips and travels and make them unique experiences. Bringing our expertise to new markets, we invest in high-technology materials, 3D printing and hydrogen, to serve a wide a variety of industries\u2014from aerospace to biotech. Headquartered in Greenville, South Carolina, Michelin North America has approximately 23,000 employees and operates 34 production facilities in the United States and Canada.\n  \n \n \n   MICHELIN\u00ae tires have been ranked the #1 Tire Brand across major categories and segments by industry experts and consumers alike. For nearly three decades we\u2019ve been recognized for our achievements in Customer Satisfaction, Performance, Durability, Technology and Innovation.\n  \n \n \n   Michelin cares for the personal and professional development of its employees. We support career advancement through various options, which include: skill and career development, training, career exploration and work with cross-functional teams. We offer the possibility of a varied and fulfilling career path in an environment where unique contributions are valued.\n  \n \n \n   Michelin offers 10 Business Resource Groups (BRGs) which are all-inclusive groups created and led by employees who have shared life experiences across various diversity dimensions. Each group supports business strategies and initiatives along with meeting the needs of members. The goal of each group is to help employees feel welcome and included, support employee engagement and encourage professional development. BRGs also provide cross-cultural support, career management resources and opportunities for community involvement.\n  \n \n \n   Michelin provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), parental status, national origin, age, disability, genetic information (including family medical history), political affiliation, military service, or other non-merit-based factors. Consistent with these obligations, Michelin also provides reasonable accommodations to employees and applicants with disabilities and for sincerely held religious beliefs. If you need accommodation for any part of the employment process because of a disability, please contact us at \n   \n   accommodations@michelin.com\n   .\n  \n \n \n   This position is not available for immigration sponsorship.\n  \n \n \n  Get in the driver\u2019s seat and be on your way to a meaningful professional journey!", "cleaned_desc": "  \n \n   Design, build, and automate all steps of the Machine Learning (MLOps) industrialization workflow.\n  \n \n   Collaborate with product managers and internal partners to automate integrated AI/ML systems.\n  \n \n   Develop partnerships, standard processes, network and knowledge by :\n  \n \n  Mentoring less experienced people \n  Transmitting knowledge by development and deployment of training modules and various other communication methods \n  Participating in the development of the Data Science Roadmap and Network \n  Accelerating the adoption of Artificial Intelligence across the enterprise through the use of machine learning, modern architecture and software engineering best practices \n \n \n \n   What you\u2019ll bring:\n  \n \n   Bachelor\u2019s Degree or greater in Statistics, Applied Mathematics, Computer Science Information Systems or equivalent.\n  \n \n   Must have experience with data science methodology and techniques: Exploratory Data Analysis, Feature Engineering, Cross Validation, Visualization, Advanced Analytics, Machine Learning, Predictive Modeling", "techs": ["mlops", "ai/ml systems", "data science roadmap", "artificial intelligence", "machine learning", "modern architecture", "software engineering."]}, "fbb9901546670307": {"terms": ["data science"], "salary_min": 55.0, "salary_max": 55.0, "title": "Clinical Trial Manager (Contract) # 3283", "company": "GRAIL", "desc": "GRAIL is a healthcare company whose mission is to detect cancer early, when it can be cured. GRAIL is focused on alleviating the global burden of cancer by developing pioneering technology to detect and identify multiple deadly cancer types early. The company is using the power of next-generation sequencing, population-scale clinical studies, and state-of-the-art computer science and data science to enhance the scientific understanding of cancer biology, and to develop its multi-cancer early detection blood test. GRAIL is headquartered in Menlo Park, CA with locations in Washington, D.C., North Carolina, and the United Kingdom. GRAIL, LLC is a wholly-owned subsidiary of Illumina, Inc. (NASDAQ:ILMN). For more information, please visit www.grail.com.\n  \n \n \n  The Clinical Trial Manager has overall responsibility to support Clinical Operations. This will include supporting day-to-day execution of a clinical trial, building strong internal and external relationships, managing clinical sites, and collaborating with cross functional teams.\n  \n \n \n  This position will require a candidate to have experience with working in a fast paced environment, ability to work in ambiguity, proactive in seeking and utilizing the resources available to effectively problem solve, ability to be flexible and creative yet ensuring the clinical trial is executed within compliance of regulations and of the highest quality, and to be able to identify areas of improvement to drive efficiency within Clinical Operations.\n  \n You will: \n \n  Manage all clinical operational aspects of a clinical trial from site selection, start-up, enrollment, maintenance, and close-out. \n  Prepare and reviews study related plans and documents including protocols, informed consent forms, recruitment plans, monitoring plans, protocol deviation plans, and case report forms with minimal supervision. \n  Participate in identifying, selecting, and monitoring the performance of clinical sites. \n  Ensure proper site training and management, provides ongoing oversight of clinical site compliance with study plans, study protocol, SOPs, FDA regulations, ICH/GCP guidelines, and in accordance with all applicable regulations. \n  Participate in EDC set-up by contributing to case report form design, user acceptance testing, completion guideline development and other related activities. \n  Identify any potential risks to the study timelines and/or conduct, proposes mitigations and implements mitigations with cross-functional team and manager support. \n  Monitor clinical data entry progress and follows up on incomplete data entry and/or outstanding queries. \n  Contribute to the development and management of site budgets and ensures invoice payment according to site payment terms. \n  Work cross functionally with other departments such as Legal, Data Management, Biospecimen Management, and Finance on all aspects of the clinical trial. \n  Provide oversight of regional monitors, vendors or contract research organizations (CRO). \n  Establish and maintains strong relationships and communication with sites and site staff. \n  Ensure Trial Master File (TMF) is current and maintained. \n  Provide guidance and mentorship to CPAs (Clinical Project Assistants). \n \n  Your qualifications and background will include: \n \n  Bachelor\u2019s degree or equivalent in the life sciences or related field required. Additional coursework in clinical trial planning and execution is strongly desired. \n  Ideal candidate will have at least 5 years of relevant experiencein managing clinical trials at a sponsor company (pharma, biotech, or medical device) with a strong track record of successful trial initiation and execution. \n  Industry experience within in vitro diagnostics (IVD) highly preferred; pharmaceutical, biologics or medical device experience also acceptable. \n  Thorough knowledge of GCP, ICH guidelines and other US and international clinical regulatory requirements. \n  Working experience with an electronic data capture system, CTMS system, and eTMF system. \n  Strong interpersonal communication (written and verbal), organizational and prioritization skills. \n  Able to work effectively under a fast-paced and changing environment. \n  Strong work ethic and demonstrated ability to deliver assignments on time. \n  Proficient with office automation tools, such as Microsoft Office and the Google suite of apps. \n \n \n   The expected hourly rate for this position is expected to be $55.00/hour - $75.00 / hr. Actual hourly rate will consider skills, experience, and location.\n  \n \n \n  Based on the role, colleagues may be eligible to participate in an annual bonus plan tied to company and individual performance, or an incentive plan. We also offer a long-term incentive plan to align company and colleague success over time.\n  \n \n \n  In addition, GRAIL offers a progressive benefit package, including flexible time-off, a 401k with a company match, and alongside our medical, dental, vision plans, carefully selected mindfulness offerings.\n  \n \n \n  GRAIL is an Equal Employment Office and Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status. We will reasonably accommodate all individuals with disabilities so that they can participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. GRAIL maintains a drug-free workplace.", "cleaned_desc": "  Industry experience within in vitro diagnostics (IVD) highly preferred; pharmaceutical, biologics or medical device experience also acceptable. \n  Thorough knowledge of GCP, ICH guidelines and other US and international clinical regulatory requirements. \n  Working experience with an electronic data capture system, CTMS system, and eTMF system. \n  Strong interpersonal communication (written and verbal), organizational and prioritization skills. \n  Able to work effectively under a fast-paced and changing environment. \n  Strong work ethic and demonstrated ability to deliver assignments on time. \n  Proficient with office automation tools, such as Microsoft Office and the Google suite of apps. \n \n \n   The expected hourly rate for this position is expected to be $55.00/hour - $75.00 / hr. Actual hourly rate will consider skills, experience, and location.", "techs": ["in vitro diagnostics (ivd)", "pharmaceutical", "biologics", "medical device\n\ngcp", "ich guidelines\n\nelectronic data capture system", "ctms system", "etmf system\n\nmicrosoft office", "google suite"]}, "c1a6c7ffc7ccd96f": {"terms": ["data science"], "salary_min": 126411.0, "salary_max": 144000.0, "title": "Senior Manager of Clinical Analytics", "company": "Inovalon", "desc": "Inovalon was founded in 1998 on the belief that technology, and data specifically, would empower the transformation of the entire healthcare ecosystem for the better, improving both outcomes and economics. At Inovalon, we believe that when our customers are successful in their missions, healthcare improves. Therefore, we focus on empowering them with data-driven solutions. And the momentum is building. \n  Together, as ONE Inovalon, we are a united force delivering solutions that address healthcare's greatest needs. Through our mission-based culture of inclusion and innovation, our organization brings value not just to our customers, but to the millions of patients and members they serve. \n \n  Inovalon's Insights business unit is seeking a Senior Manager, Clinical Analytics to join its Advanced Healthcare Analytics group. The group works with life sciences companies and other healthcare sectors to derive and apply actionable clinical insights to clinical development and to align our clients' clinical and market access strategies with the evidentiary demands of an evolving healthcare marketplace. We are driven by deep subject matter expertise, differentiated and proprietary real-world data assets, and an emphasis on sound business strategy coupled with rigorous research and advanced analytic capabilities. \n  Duties and Responsibilities: \n \n Responsible for supporting clinical analytics projects with life sciences and related clients including but not limited to the development of engagement scopes, research protocols, basic programming and analysis of healthcare claims data, creation of BI dashboards/reports, interpretation of results, and/or development of summary findings and insights (i.e., client deliverables). Project types may include protocol development support, diversity planning support, study operational intelligence, and the delivery of real-world data for regulatory use; \n Manage multiple mid to large-sized projects and teams to ensure the breadth of Inovalon's knowledge and expertise is available to meet client needs; \n Conceptualize the scope of projects for clients, assembling a cross-functional team, and overseeing the team from project initiation through to client delivery; \n Demonstrate advanced subject matter expertise to solve complex client problems, with an emphasis on translating qualitative and quantitative research findings into clients' value-oriented business strategies; \n Engage clients with novel solutions and ideas; deepens client relationships; \n Contribute to project profitability; \n Create both strategic and tactical recommendations for clients; \n Make meaningful business development and sales contributions; \n Write Statements of Work (SOW); \n Solve complex client issues in a timely and appropriate manner with minimal management oversight; \n Mentor, supervise, and train staff members; \n Identify and pursue opportunities to improve internal best practices, collaboration models, and standard operating procedures; \n Maintain compliance with Inovalon's policies, procedures and mission statement; \n Adhere to all confidentiality and HIPAA requirements as outlined within Inovalon's Operating Policies and Procedures in all ways and at all times with respect to any aspect of the data handled or services rendered in the undertaking of the position; and \n Fulfill those responsibilities and/or duties that may be reasonably provided by Inovalon for the purpose of achieving operational and financial success of the Employer. \n \n Job Requirements: \n \n Minimum five (5) years' relevant experience in the real-world data and clinical analytics space; \n Understanding of pharmaceutical product and medical device development cycle, including global clinical R&D systems and the role of real-world data; \n Prior experience with clinical analytics in a healthcare consulting, services, or life sciences company; \n Advanced project management acumen with experience leading large clinical analytics projects; \n Strong technology experience including programming (SQL, Python, R), BI tools (Tableau, Power BI), and/or data science techniques (AI, ML, NLP); \n Strong collaboration skills in working with real-world data scientists, clinical development stakeholders, and other sponsor decision-makers; \n Experience with data governance best practices and real-world data analytics process development; \n Strong verbal and written communication skills including the ability to concisely explain complicated concepts to executives and technical and non-technical audiences within and outside of the firm; \n Intermediate Microsoft Office skills, including PowerPoint, Excel, and Word; \n Exemplary interpersonal skills that translate into positive relationships with colleagues and clients; and \n Commitment to working in a team environment with an emphasis on collaboration and maintaining positive relationships with colleagues and clients. \n \n Education: \n \n Bachelor's or Master's degree in life sciences, data sciences, statistics, epidemiology, health economics/HEOR, or relevant discipline. \n Doctoral degree preferred. \n \n \n   Physical Demands and Work Environment: \n \n Sedentary work (i.e. sitting for long periods of time); \n Exerting up to 10 pounds of force occasionally and/or negligible amount of force; \n Frequently or constantly to lift, carry push, pull or otherwise move objects and repetitive motions; \n Subject to inside environmental conditions; and \n Travel for this position will include less than 5% locally usually for training purposes. \n \n \n \n \n  The actual base pay offered may vary depending on multiple factors including, but not limited to, job-related knowledge/skills, experience, business needs, geographical location, and internal equity. At Inovalon, it is not typical for an individual to be hired at or near the top end of the range for their role, and compensation decisions are dependent upon the facts and circumstances of each position and candidate. \n \n  Base Compensation Range \n \n    $126,411\u2014$144,000 USD\n   \n \n \n  Studies have shown that women and people of color are less likely to apply for jobs unless they believe they meet every one of the qualifications listed in a job description. If you don't meet every qualification listed but are excited about our mission and the work described, we encourage you to apply regardless. Inovalon is most interested in finding the best candidate for the job and you may be just the right person for this or other roles. \n  By embracing diversity, equity and inclusion we enhance our work environment and drive business success. Inovalon strives to reflect the diversity of the communities where we operate and of our clients and everyone whom we serve. We endeavor to create a culture of inclusion in which our associates feel empowered to bring their full, authentic selves to work and pursue their professional goals in an equitable setting. We understand that by fostering this type of culture, and welcoming different perspectives, we generate innovation and growth. \n  Inovalon is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirement. \n  The Company maintains a drug free work environment for all of its associates, which includes employees, contractors and vendors. It is unlawful for associates to manufacture, sell, distribute, dispense, possess or use any controlled substance or marijuana in the workplace and doing so will result in disciplinary action, up to and including termination of employment or the contracted relationship.", "cleaned_desc": " Minimum five (5) years' relevant experience in the real-world data and clinical analytics space; \n Understanding of pharmaceutical product and medical device development cycle, including global clinical R&D systems and the role of real-world data; \n Prior experience with clinical analytics in a healthcare consulting, services, or life sciences company; \n Advanced project management acumen with experience leading large clinical analytics projects; \n Strong technology experience including programming (SQL, Python, R), BI tools (Tableau, Power BI), and/or data science techniques (AI, ML, NLP); \n Strong collaboration skills in working with real-world data scientists, clinical development stakeholders, and other sponsor decision-makers; \n Experience with data governance best practices and real-world data analytics process development; \n Strong verbal and written communication skills including the ability to concisely explain complicated concepts to executives and technical and non-technical audiences within and outside of the firm; \n Intermediate Microsoft Office skills, including PowerPoint, Excel, and Word; \n Exemplary interpersonal skills that translate into positive relationships with colleagues and clients; and \n Commitment to working in a team environment with an emphasis on collaboration and maintaining positive relationships with colleagues and clients. \n ", "techs": ["sql", "python", "r", "tableau", "power bi", "ai", "ml", "nlp", "microsoft office", "powerpoint", "excel", "word"]}, "5084623618d0b0d2": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "888935484ed5599e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b9e1ae2099f60062": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ed71c86006916424": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "3fe4f4c4d2959a43": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "05f8a16c684447dc": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "9a2e7c9f4446c2be": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "21742fb6b275c816": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "88bde87df77c29d3": {"terms": ["data science", "machine learning engineer"], "salary_min": 178538.0, "salary_max": 218213.0, "title": "Senior Machine Learning Engineer", "company": "Rec Room", "desc": "Rec Room is the best place to build and play games together. Players can chat, hang out, play in millions of rooms, or build something new to share with the world! We have a vibrant commercial ecosystem within Rec Room, and our goal is to enable creators to be rewarded for their work. Come join us on the ground floor to help optimize the ecosystem for both players and the business. \n  As a Senior Machine Learning Data Scientist, you'll be responsible for designing, developing, and implementing machine learning models to power our in-game store recommendations and serve users content that they'd find valuable. You'll be supporting creators in making a living on the platform, as well as playing a critical role in the success of Rec Room as a business. \n  WHAT YOU'LL DO: \n \n Design, develop and implement production-facing ML models to deliver valuable commerce content to our users. \n Collaborate closely with the ML Infra team to define a roadmap that powers real-time personalized ranking models. \n Design and run A/B tests, analyze model performance, and deep dive into the data to uncover opportunities for improvements. \n Build out pipelines in collaboration with our Analytics Engineering team to enable model building on top of sophisticated features. \n Set best practices, mentor, and provide guidance to the more junior Data Scientists. \n \n WE ARE LOOKING FOR INDIVIDUALS WITH: \n \n Master's or Ph.D. degree in computer science, statistics, mathematics, or a related field \n 7+ years of ML experience in a production setting, with extensive experience working on ranking/recommendations \n Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n \n \n \n   The base pay range for this position is listed below; please note the base pay may vary depending on location, job-related knowledge, skills, and experience. Stock options and, in some cases, a sign-on bonus may be offered as part of the compensation package. We also offer a full slate of benefits, including flexible vacation, medical, dental vision, life and disability coverage, long-term care insurance, FSA, commuter benefits, a 401(k) plan with company match, and a parental leave program. We also offer some not-so-standard benefits, including equipment, family, and pet care stipends.\n   \n  Base Pay Range \n \n    $178,538\u2014$218,213 USD\n   \n \n \n  COMPANY INFO TO KNOW: \n  Rec Room offers generous medical, dental, and vision plans that cover you, your spouse/domestic partner, and children. We also support your retirement benefits with a company match. Rec Room values work-life balance by providing unlimited paid time off. Our company values are real and drive our culture. We work hard to be a safe and friendly place for people from all walks of life.  \n Rec Room provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  Applicants who are in need of a reasonable accommodation for any part of the application process may contact, in confidence, accessibilityrequest.hr@recroom.com. Rec Room will work with each individual to define their application-related needs and to try to accommodate those needs. \n  Applicants can find our CCPA disclosure notice here.", "cleaned_desc": " Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n ", "techs": ["recommendations", "ranking", "personalization", "search", "content discovery", "python", "sql", "ml infrastructure", "experimentation", "dbt", "spark/databricks"]}, "e01ac0c26751a259": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "a867f4f38e8b4ed3": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "277f88134ea2aeb2": {"terms": ["data science", "machine learning engineer"], "salary_min": 205318.0, "salary_max": 250944.0, "title": "Principal Machine Learning Engineer", "company": "Rec Room", "desc": "Rec Room is the best place to build and play games together. Players can chat, hang out, play in millions of rooms, or build something new to share with the world! We have a vibrant commercial ecosystem within Rec Room, and our goal is to enable creators to be rewarded for their work. Come join us on the ground floor to help optimize the ecosystem for both players and the business. \n  As a Principal Machine Learning Data Scientist, you'll be responsible for designing, developing, and implementing machine learning models to power our in-game store recommendations and serve users content that they'd find valuable. You'll be supporting creators in making a living on the platform, as well as playing a critical role in the success of Rec Room as a business. \n  WHAT YOU'LL DO: \n \n Design, develop and implement production-facing ML models to deliver valuable commerce content to our users. \n Collaborate closely with the ML Infra team to define a roadmap that powers real-time personalized ranking models. \n Design and run A/B tests, analyze model performance, and deep dive into the data to uncover opportunities for improvements. \n Build out pipelines in collaboration with our Analytics Engineering team to enable model building on top of sophisticated features. \n Set best practices, mentor, and provide guidance to the more junior Data Scientists. \n \n WE ARE LOOKING FOR INDIVIDUALS WITH: \n \n Master's or Ph.D. degree in computer science, statistics, mathematics, or a related field \n 10+ years of ML experience in a production setting, with extensive experience working on ranking/recommendations \n Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n \n \n \n   The base pay range for this position is listed below; please note the base pay may vary depending on location, job-related knowledge, skills, and experience. Stock options and, in some cases, a sign-on bonus may be offered as part of the compensation package. We also offer a full slate of benefits, including flexible vacation, medical, dental vision, life and disability coverage, long-term care insurance, FSA, commuter benefits, a 401(k) plan with company match, and a parental leave program. We also offer some not-so-standard benefits, including equipment, family, and pet care stipends.\n   \n  Base Pay Range \n \n    $205,318\u2014$250,944 USD\n   \n \n \n  COMPANY INFO TO KNOW: \n  Rec Room offers generous medical, dental, and vision plans that cover you, your spouse/domestic partner, and children. We also support your retirement benefits with a company match. Rec Room values work-life balance by providing unlimited paid time off. Our company values are real and drive our culture. We work hard to be a safe and friendly place for people from all walks of life.  \n Rec Room provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n  Applicants who are in need of a reasonable accommodation for any part of the application process may contact, in confidence, accessibilityrequest.hr@recroom.com. Rec Room will work with each individual to define their application-related needs and to try to accommodate those needs. \n  Applicants can find our CCPA disclosure notice here.", "cleaned_desc": " Experience with recommendations, ranking, personalization, search, and/or content discovery \n Strong proficiency in Python and SQL \n Deep familiarity with ML infrastructure to collaborate with our infra team \n Extensive experience with experimentation. \n dbt knowledge is a plus \n Spark/Databricks knowledge is a plus \n ", "techs": ["recommendations", "ranking", "personalization", "search", "content discovery", "python", "sql", "ml infrastructure", "experimentation", "dbt", "spark", "databricks"]}, "813e21ab1211c3a1": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "be2ca3ca5a3028c2": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "cef510a61133a5bc": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b0ee7f5b396e019e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ba3eb1779bc9e7a7": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "7672a1b7273e7860": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "214998a333155a01": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "0aaa32d8e0f8b732": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "92e0c53eab354257": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "22299ff7df8979c9": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ec8a9578dfb7b186": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "fd454ae1dc3b7c46": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c9858bc551508741": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "f1389a72abedacab": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "cbf30e646cf87f9f": {"terms": ["data science"], "salary_min": 70.0, "salary_max": 100.0, "title": "Reinforcement Learning (AWS)", "company": "Radiant Systems", "desc": "Job Summary: \n We are seeking an experienced Data Scientist with a specialization in Reinforcement Learning (RL) and its application in quantitative trading or portfolio management. The selected candidate will work on developing a package for RL to apply to many use cases and end their contract training other data scientists in how to utilize the package. \n Key Responsibilities: \n 1. Package Development: Develop a package for us to execute Reinforcement Learning (RL) on AWS Sagemaker. The package should allow for the use of multiple agents and allow for easy implementation of agents across different problems. NRG needs the ability to deploy multiple agents to solve problems mainly for portfolio management purposes. \n - Deploy the building blocks of a reinforcement learning problem to NRG\u2019s data packages. \n - Code should be modular. Strong acumen for OOP preferred. \n - Package should address complex multi-agent problems which are common in portfolio optimization. \n - Package should have functionality for the evaluation of models, hyper-parameter optimization, model/scenario explainability, and the display of results to the trading team. \n - Experience in Quantitative trading or deploying RL for similar optimization problems required. \n 2. Proof of Concept Deployment: Design, implement, and evaluate the RL package on a POC after package deployment. \n 3. Documentation & Training: Train other data scientists on NRG\u2019s team to swap agents, change the environment, rewards, etc... Detailed documentation of the RL package will be required. \n Qualifications: \n 1. Education: Master's or PhD in Computer Science, Machine Learning, Financial Engineering, Operations Research or a related field. \n 2. Experience: At least 5 years of professional experience in reinforcement learning deploying models at scale on AWS required. Experience contributing to building python packages in RL or other ML fields preferred. Prior model deployments with a specific focus on applications in quantitative trading or portfolio management preferred. \n 3. Technical Skills: Proficiency in Python and familiarity with popular RL libraries such as TensorFlow, PyTorch, and OpenAI Gym. Must also have a familiarity with cloud platforms deploying and training RL models (AWS Sagemaker). \n 4. Software Engineering Skills: Solid grasp of software design principles, data structures, and algorithms pertinent to trading environments. \n 5. Communication: Excellent written and verbal communication skills; ability to relay complex trading strategies and outcomes to various stakeholders. \n 6. Teamwork: Demonstrated experience working effectively in cross-functional teams, especially within a high-pressure trading context. \n Nice-to-Have: \n 1. Experience with high-frequency trading environments. \n 2. Publications or notable contributions in the realm of RL for quantitative finance. \n #INDEED_D \n Job Type: Contract \n Salary: $70.00 - $100.00 per hour \n Experience: \n \n Reinforcement Learning: 5 years (Preferred) \n AWS Sagemaker: 5 years (Preferred) \n Machine learning: 10 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " 1. Education: Master's or PhD in Computer Science, Machine Learning, Financial Engineering, Operations Research or a related field. \n 2. Experience: At least 5 years of professional experience in reinforcement learning deploying models at scale on AWS required. Experience contributing to building python packages in RL or other ML fields preferred. Prior model deployments with a specific focus on applications in quantitative trading or portfolio management preferred. \n 3. Technical Skills: Proficiency in Python and familiarity with popular RL libraries such as TensorFlow, PyTorch, and OpenAI Gym. Must also have a familiarity with cloud platforms deploying and training RL models (AWS Sagemaker). \n 4. Software Engineering Skills: Solid grasp of software design principles, data structures, and algorithms pertinent to trading environments. \n 5. Communication: Excellent written and verbal communication skills; ability to relay complex trading strategies and outcomes to various stakeholders. \n 6. Teamwork: Demonstrated experience working effectively in cross-functional teams, especially within a high-pressure trading context. ", "techs": ["master's or phd in computer science", "machine learning", "financial engineering", "operations research", "aws sagemaker", "python", "tensorflow", "pytorch", "openai gym"]}, "7c9c7541ea5d1b1c": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "2ae418edeac25421": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "3748065b9bd4a5a6": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "1ba72658fb247ec5": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "35d62b823fa751e2": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "54912a62c4198665": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "fef8af74e31d810d": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "1cb1be37c0cb6bb7": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d7e34f28295a783a": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "3c84ff7dbeb12e42": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "0bdacd617f43a8ca": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "6939b085b6ef4861": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "624d403525dccec5": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "6487e2ff780054e8": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "2297bdf44c9c2255": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "9a9adf6998a9e78b": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "24e2183da3575b22": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d468826c61a893ff": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ae1449a72d87afd0": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d0ac37b1728601ab": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d875dbad75c0067e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ab38ae4beef1ed34": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "e5a249c668781a1d": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "1affe5d1add60d92": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "6fa3d7e3d712ef4a": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "4b2d7dc8f143e584": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "55fae98057ce3cfc": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "9472d50008d65bbc": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "09e8834adf59af92": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "06efd11986f0f0b5": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "a449b1754b809088": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "595bd6dc24780deb": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "4fe4638e6565b062": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "e263424d29e2c1ed": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "25fa97dae983c97e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "99bd61f103dec2d9": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "37e17d733333f604": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "491b50de6a066bf4": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "a8e3909c12f390af": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "7269d442b96c4bbd": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "387963d9081a9f48": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "8726fd4133e00398": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d8f1c6da513e1bf3": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "cf2e0a4a992656e1": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c509a73837c299aa": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "a5306fde799c4c4a": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "072e75eb2215a273": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b4fb781fb76cce55": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "40c4b1d3f70b7193": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ef36aea465e348cb": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "17c92e7fd314c238": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c82a2be0508600cf": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b8cc97ebd4f873e3": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b696c2fdf1b5bcb6": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "758040eef944b471": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c9159bba301e24da": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d58be1e52f1e0935": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c7b99df71a2c6bd1": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "2320813ff8b2552e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "19d6d70c5a81c735": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "0920c02a375380a9": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "902954ebac321ff7": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "254417a95a7ac997": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "e9290dec692c8c8b": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "43c2636d94a8c7af": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "52c8f2b33bab3b54": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "8a5416dac86b1935": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d35f8dd2a3f70e27": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "2f197bfbead64130": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "4ad342c879d8a490": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "03504e0878da4822": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "08f02f1e73f80743": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ef18782e97428f56": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d176e6e4d2f9e640": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "da294f5facf9fbe9": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c65877c0d60e1be6": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "57f54d3583f41b6a": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "27abd7107aeb335e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "70b6b13e09509e5b": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "cdc1652ceeaffa73": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "35431e2fffd22d23": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "5542e534a68a873e": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "348380c2f497a632": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "d62b88aea9353653": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "bcb79caf6b9e2864": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "48306cfbe95c404a": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "f26a18427ec5d1d5": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b5e4d08c3de63aba": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "e5228bbc0f9997e7": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "7dfe8451ebfb0657": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "43d570c06925dcba": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "83e7e8ce0c04e8b7": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "46f466e443c73026": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "029c550509cba623": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "5d4e3308f17c75a3": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "304956100dd63db5": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b3a89d93e42f2fd8": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "2bcf5cb3275be507": {"terms": ["data science", "machine learning engineer"], "salary_min": 112309.37, "salary_max": 142208.69, "title": "Machine Learning Infra Engineer", "company": "Cyberjin", "desc": "Remote Position \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n UdqL17Du4d", "cleaned_desc": "", "techs": ""}, "b25c2f047ba7c09a": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "5acabe552bf20db0": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "1dae91e5ea2645ba": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "40c046f583deedfb": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "4f677d5e768e5814": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "ec17684a2eb2b47f": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "9bb915a6e5e1ab93": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "5865e6db99e205dd": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "62e4829c3dde3547": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote position \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n twiieVGwhs", "cleaned_desc": "", "techs": ""}, "e8c23ef337d400e8": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "e7fd4ceae9ff9629": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "c8db0c15782d4e4b": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "88e9c34ba7ed0798": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "e61f61676b43efc1": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "01701fc59ff9b90b": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "1e0ec8c6a06d2e66": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "b1352692a58201c3": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "9cbabac33e610d73": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "66341a02353e002c": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "2af9d69b6cbe95db": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "8062cd73adac7c53": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "571f615a71986ce4": {"terms": ["data science"], "salary_min": 160000.0, "salary_max": 160000.0, "title": "Founding Backend Engineer, AI Startup", "company": "Recruiting From Scratch", "desc": "Who is  \n Recruiting from Scratch  \n :  \n \n \n   Recruiting from Scratch is a premier talent firm that focuses on placing the best product managers, software, and hardware talent at innovative companies. Our team is 100% remote and we work with teams across the United States to help them hire. We work with companies funded by the best investors including Sequoia Capital, Lightspeed Ventures, Tiger Global Management, A16Z, Accel, DFJ, and more. \n   \n \n \n   https://www.recruitingfromscratch.com/ \n   \n \n \n Our Client  \n \n \n We are a venture-backed startup building the infrastructure layer for Property & Casualty (P&C) insurance. Integrating technology in the insurance industry today is much like consumer finance pre-Plaid (we could succinctly be described as \"Plaid for Insurance\"), or payments pre-Stripe, and our vision is to unlock a similar wave of innovation for the $2T global P&C industry.  \n Today, walking into an insurance agency is like stepping into a time machine. Filing cabinets, fax machines, piles of incoming and outgoing mail. What you don't see is that even for the parts that have been \"digitized\", needless manual work abounds. Few systems communicate directly, leading to endless copy-pasting from emails to various proprietary web portals/desktop apps and back again.  \n Carrier by carrier, endpoint by endpoint, we will bring each of those manual and error-prone workflows into our simple, modern API layer.  \n The implementation details are subject to change, but this is our north star, and the future we envision isn't possible without it.  \n What we're looking for  \n We are seeking a highly autonomous engineer (employee #2!) excited about owning the design and implementation of a robust, API-driven product and playing a foundational role in the formation of the company.  \n \n \n Responsibilities  \n \n \n \n You'll work closely with the team and early customers to build a world-class, API-driven product.  \n You'll solve hard technical problems from scratch, owning the solution through the entire development lifecycle.  \n You'll help define the tech stack/architecture for a fledgling product \u2014 we're technology agnostic and focus using the right tool for the job.  \n You'll contribute to the creation of the team culture, as well as internal tooling and processes.  \n \n Role requirements  \n \n 4+ years professional backend/full-stack engineering experience. Working on large-scale open-source projects works too. You've played significant roles in either API design, building processing pipelines, or systemic integration of external systems.  \n Early-stage startup experience (or other similar unstructured, fast-paced environment)  \n Live in or willing to relocate to the Bay Area to work full-time in our SF office  \n \n \n \n Nice to haves  \n \n Experience with web scraping, email scraping, RPA \u2014 in general just getting data creatively out of hard-to-reach places  \n 1+ years TypeScript/JavaScript experience in a professional or large-scale OSS setting. If you have a comprehensive side project you think is equivalent, send it our way! Clear, concise, and extensible code is important to us and collaborating with others is often a forcing function to that end.  \n Experience integrating with low tech industries, or other time spent integrating with poorly documented, antiquated APIs (and sometimes even a lack thereof)  \n \n Why you should join us  \n \n Opportunity to be a foundational team member to a well-funded, post-product and -revenue startup in a massive and largely untapped industry.  \n Hard backend engineering problems on day 1. Backend is all we do, and the projects you'll work on will be challenging and interesting.  \n Generous equity comp (90th+ percentile) and competitive cash comp (50th percentile). As we're a startup, we're happy to play with the balance for exceptional candidates.  \n \n \n \n The Founding Team  \n Our CEO is a strong engineer in his own right (Waterloo grad, senior eng at multiple Bay Area startups) but will be focusing on the business/product side. He\u2019s gone super deep on insurance, including getting a Broker License and a stint as an Insurtech EIR at a top VC firm.  \n We\u2019ve raised funding from great investors including top seed funds, ex-Plaid folks, and insurance industry insiders.  \n \n \n \n Salary Range: $160,000-$180,000 base.  \n \n \n \n   https://www.recruitingfromscratch.com/", "cleaned_desc": "", "techs": ""}, "cb0caa9e6cd28ed5": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n bieDUBlEKc", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python expertise", "deep learning experience", "tensorflow familiarity"]}, "c47bf16fe463a734": {"terms": ["data science"], "salary_min": 120363.016, "salary_max": 152406.39, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n l9aMGzMMHc", "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ", "techs": ["python", "deep learning", "tensorflow"]}, "a609b8267363854f": {"terms": ["data science"], "salary_min": 120675.25, "salary_max": 152801.75, "title": "Deep Learning Engineer", "company": "Cyberjin", "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n tvBdeH5EaO", "cleaned_desc": "", "techs": ""}, "9062e9e23ae4a872": {"terms": ["data science"], "salary_min": 110000.0, "salary_max": 150000.0, "title": "Generative AI Engineer", "company": "CyberCoders", "desc": "Generative AI Engineer \n  \n  -THIS POSITION IS 100% REMOTE AND WORK IS CONDUCTED DURING STANDARD PST HOURS-\n   \n  If you are a Generative AI Engineer with TypeScript and/or JavaScript experience, please read on!\n   \n  Since our company was founded in 2017, we have held the view that achieving wellness is simply a matter of doing a little bit better than yesterday. Self-improvement, in our opinion, is a team sport. Our platform offers straightforward, actionable tools and insights for taking control of one's own health. By giving people a specialized and accurate health solution to help them live their best lives, we hope to lower the cost of treating chronic disorders like diabetes.\n  \n  Top Reasons to Work with Us \n \n Backed by founders of some of the biggest tech companies in the world \n Work on a product that helps improve and save lives \n Fully remote work policy! \n \n  What You Will Be Doing \n \n Creating solutions for Gen AI that evaluate user profiles and real-time data from many sources to produce insightful results \n Using Gen AI and similar tools to build interconnected networks \n Using next-generation AI technology to manipulate photos \n Keeping up with new advances and developing trends in the Gen AI ecosystem by always researching and learning about the newest technologies \n \n  What You Need for this Position \n \n   A Bachelors Degree and at least 1 year of AI Engineering experience with a combination of the following\n   \n \n \n Generative AI \n JavaScript/TypeScript \n SQL (PostgreSQL/MySQL preferred) \n Open AI API \n Python (Nice to have) \n \n \n  Benefits \n \n Vacation/PTO \n Medical \n Dental \n Vision \n 401k: Match \n Equity \n \n \n   So, if you are a Generative AI Engineer with TypeScript and/or JavaScript experience, please apply today!\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Kevin Jones\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.", "cleaned_desc": "", "techs": ""}, "eccf0f87c3adc76c": {"terms": ["data science", "machine learning engineer"], "salary_min": 65.0, "salary_max": 80.0, "title": "AI/ML Solutions Architect", "company": "Expert Technical Solutions", "desc": "Enterprise Solutions Architect - Remote \n Expert Technical Solutions has an immediate opening for an Enterprise Solutions Architect with an industry leading client in Stone Mountain, GA. The ideal candidate will be an Execution focused lead for our client\u2019s client facing software/technology platform and innovation responsible for continuing to evolve the technology development to bring additional efficiency, cost savings, speed and marketing value to clients. This person will oversee the information and architecture and provide technical direction to product, software, and digital development including the identification of needs/gaps business case justification, commercialization, and implementation priorities for development teams. \n This is a 6+ Month, REMOTE Contract opportunity that offers competitive pay and strong benefits. Candidates MUST be located in the CST / EST time zones. \n Responsibilities: \n \u00b7 Collaborate closely with customer stakeholders to understand their requirements, goals, and expectations for generative AI solutions. \n \u00b7 Design, develop, and implement generative AI architectures, models, and solutions that meet customer needs and align with industry best practices. \n \u00b7 Envision, design, build, deploy, and operationalize end-to-end machine learning (ML) and AI pipeline build POC/MVP and set direction for enterprise scale up. \n \u00b7 Work cross-functionally with other teams, including data engineers, software developers, and project managers, to ensure the successful delivery of end-to-end AI projects. \n \u00b7 Lead the decision-making process for technical and architectural choices, ensuring that solutions are scalable, maintainable, and cost-effective. \n \u00b7 Communicate effectively with both technical and non-technical stakeholders, translating complex AI concepts into clear, understandable language. \n \u00b7 Provide expert guidance and advice as a consultant to help customers maximize the value of their generative AI investments. \n \u00b7 Monitor and evaluate the performance of generative AI models, identify areas for improvement, and implement strategies to optimize solutions. \n \u00b7 Stay current with the latest advancements in generative AI, machine learning, and related technologies, and incorporate new ideas and techniques into the team's work. \n \u00b7 Participate in daily standups/Scrum. \n \u00b7 Think strategically but execute in a \u201chands-on\u201d environment. \n Required Skills and Experience: \n \n 2+ years\u2019 experience working as AI Architect, AI Engineer, or AI Developer \n Deep experience with .NET technologies (C#, ASP.NET, .NET Core, DI, Web API) \n Proven development background with front-end technologies such as Angular & React \n Understanding of cloud technologies \u2013 MS Azure \n Knowledge of source control and CI/DC processes. \n Knowledge of Agile/Scrum methodologies & project management practices \n Microservices design and programming \n RESTful API design and programming experience \n Strong knowledge of machine-learning algorithms, data analytics, natural language processing & other AI technologies \n Demonstrated client-facing presentation skills. \n Experience with Cosmos DB (graph & document) \n Experience with Databricks & Azure Data Factory \n Experience and Knowledge around Azure ML services applied AI services. \n Experience with Azure DevOps automation and infrastructure as code \n Version control and enterprise branching methodologies experience (especially GIT) \n Ability to work on & manage multiple projects concurrently. \n Flexible and positive attitude, even while working under pressure. \n Communicates wells with offshore geographically dispersed resources. \n \n Job Types: Contract, Full-time \n Pay: $65.00 - $80.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n Vision insurance \n \n Work Location: Remote", "cleaned_desc": " \n 2+ years\u2019 experience working as AI Architect, AI Engineer, or AI Developer \n Deep experience with .NET technologies (C#, ASP.NET, .NET Core, DI, Web API) \n Proven development background with front-end technologies such as Angular & React \n Understanding of cloud technologies \u2013 MS Azure \n Knowledge of source control and CI/DC processes. \n Knowledge of Agile/Scrum methodologies & project management practices \n Microservices design and programming   RESTful API design and programming experience \n Strong knowledge of machine-learning algorithms, data analytics, natural language processing & other AI technologies \n Demonstrated client-facing presentation skills. \n Experience with Cosmos DB (graph & document) \n Experience with Databricks & Azure Data Factory \n Experience and Knowledge around Azure ML services applied AI services. \n Experience with Azure DevOps automation and infrastructure as code \n Version control and enterprise branching methodologies experience (especially GIT) ", "techs": [".net technologies (c#", "asp.net", ".net core", "di", "web api)", "angular", "react", "ms azure", "source control", "ci/cd processes", "agile/scrum methodologies", "project management practices", "microservices design", "restful api design and programming", "machine-learning algorithms", "data analytics", "natural language processing", "cosmos db", "databricks", "azure data factory", "azure ml services", "azure devops", "git"]}, "ef84b1690c8be5d8": {"terms": ["data analyst"], "salary_min": 61108.89, "salary_max": 77377.47, "title": "Master Data Analyst", "company": "Rise Baking Company", "desc": "Rise Baking Company was founded by bakery experts passionate about providing our customers with high quality products and providing a positive, collaborative place to work for our people.  \n We are a company built on elevating expectations. It\u2019s what sets us apart from others in the baking industry. And our people are our finest ingredient.  \n We believe the quality of our people is just as important as the quality of our products. Our environment encourages creativity, and we value an entrepreneurial and industrious approach to work \u2014a place where honesty, respect, and trust are the essential ingredients for how we do business. We take pride in working with creative individuals with a passion for what they do, and we\u2019re always looking to expand our team.  \n We offer a wide variety of professional and management opportunities, including sales, product development, account management, general management, finance, engineering, administration, and information systems management. We also employ a diverse workforce of hourly food production, packaging, quality assurance, warehouse, sanitation personnel, leads, and supervisors.  \n Like our products, our benefits package offers quality that makes a difference.  \n Coverage options may include:  \n \n Medical, dental, life, disability, vision, and supplemental insurance  \n Company paid holidays \n  Paid Time Off (PTO) plans  \n Performance bonus potential  \n 401k plan with company match \n \n  Expectations Deliciously Exceeded. \n  Job Purpose \n  Provide vendor master data setup and analytics, ensuring vendors and customers are set up correctly in SAP and CRM. Standardize customer and product hierarchies and maintain consistency of master data within the company\u2019s ERP systems and external systems. Troubleshoot issues related to master data management and identify opportunities for improving data management processes. \n   \n Essential Functions \n \n Understand structure of data warehouse and integration with ERP system master data \n Resolve customer and product hierarchy inconsistencies \n Develop knowledge and understanding of master data, becoming a system expert \n Understand business processes for all departments, recommending improvements that better utilize the capabilities of the ERP systems \n Coordinate with cross-functional teams on product optimization, new product development, and product moves to ensure that all master data is set up as needed in a timely manner \n Coordinate with all appropriate departments as necessary in the master data management process \n Investigate, research, document, and problem-solve issues encountered with data management processes \n Develop and maintain new procedures for master data processes \n Train system users on master data systems \n EDI Master Data: \n \n  o Create training documentation; update as needed \n  o Perform daily checks for EDI IDOC errors \n  o Troubleshoot EDI issues with orders, invoices, and new EDI setup \n  o Work with EDI IT team on any issues \n \n Reporting: \n \n  o Perform data checks to ensure proper setup and alignment with all systems \n  o Perform KPI checks at least quarterly \n  o Run item information report for category, pricing, finance, production, inventory, demand planning, and sales on demand, usually quarterly \n  o Run customer data report for AR, customer service, and commercial finance on demand, 1-2 times annually \n  o Run miscellaneous reports as requested for specific data needs \n \n Maintain positive approach and accept new accountabilities as the department grows \n Support food safety program, quality standards, and legality of manufactured products \n Perform other job-related duties as assigned \n \n   \n Qualifications (Education, Experience, Competencies) \n \n Bachelor\u2019s degree in business or technology and/or equivalent industry experience preferred \n 2+ years of experience with SAP, SRM, and CRM systems \n Food manufacturing experience preferred \n Proficient in Microsoft Office \n High level of accuracy in the manipulation and entry of data \n Excellent problem-solving and analytical skills \n Ability to effectively communicate with multi-level personnel as well as suppliers, customers, and their representatives \n Ability to collaborate with multiple functional groups as well as work independently with minimal supervision \n Ability to organize and manage multiple priorities efficiently and proactively in a fast-paced environment \n Ability to handle ambiguity, frequent change, and risk \n \n   \n An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disabilities. \n   \n RISE123 \n  MON123 \n \n \n \n \n \n \n PI231470218", "cleaned_desc": " \n Maintain positive approach and accept new accountabilities as the department grows \n Support food safety program, quality standards, and legality of manufactured products \n Perform other job-related duties as assigned \n \n   \n Qualifications (Education, Experience, Competencies) \n \n Bachelor\u2019s degree in business or technology and/or equivalent industry experience preferred \n 2+ years of experience with SAP, SRM, and CRM systems \n Food manufacturing experience preferred \n Proficient in Microsoft Office \n High level of accuracy in the manipulation and entry of data \n Excellent problem-solving and analytical skills ", "techs": ["sap", "srm", "crm systems", "microsoft office"]}, "6759b9d9da2256c8": {"terms": ["data analyst"], "salary_min": 59767.76, "salary_max": 75679.305, "title": "Data Analyst", "company": "Alliant Insurance Services", "desc": "Alliant Insurance Services is one of the nation\u2019s largest and fastest-growing insurance brokerage and consulting firms. We operate through a network of specialized national platforms and local offices to offer our clients a comprehensive portfolio of solutions built on innovative thinking and personal service. Alliant is changing the way our clients approach risk management and benefits, so they can capitalize on new opportunities to grow and protect their organizations. \n \n More information is available on the company's website at:  www.alliant.com. \n \n  SUMMARY \n Responsible for the development of financial reporting to client regarding the value of the client\u2019s property and casualty insurance programs total cost of risk analysis. Provide data analysis support to the brokerage, claims, actuarial, underwriting, and data analytics teams. \n \n  ESSENTIAL DUTIES AND RESPONSIBILITIES \n \n \n Create reports to analyze results of all risk management programs under management for client(s). \n Collect, analyze, and interpret specific data and criteria. \n Support plan design modeling analysis efforts. \n Oversee and coordinate efficient workflow between Account Executives and Program Managers. \n Provide reporting from internal and external Risk Management Information Systems. \n Coordinate a variety of special projects such as benchmarking using data warehouse information. \n Provide support to brokerage and actuarial department. \n Support Account Executives with various cost and data aggregation projects and analysis. \n Comply with agency management system data standards and data integrity (enter and maintain complete and accurate information). \n Other duties as assigned. \n  QUALIFICATIONS \n EDUCATION / EXPERIENCE \n Bachelor\u2019s degree in finance, accounting, business or equivalent combination of education and experience \n One (1) or more year related work experience \n Significant experience with Microsoft Excel and Access required \n Experience with SQL preferred \n Underwriting experience preferred \n \n  SKILLS \n Proficient in Microsoft Office products with a strong emphasis in Excel \n Technical understanding of data structure, data mining, and reporting processes \n Excellent analytical skills \n Excellent interpersonal skills \n Strong verbal and written communication skills \n Ability to perform complex mathematical functions \n Ability to prioritize and multi-task \n Ability to work independently and within a team environment \n \n  We are proud to provide comprehensive, high quality employee programs to meet employees\u2019 needs now and in the future, including a very competitive financial package. We encourage you to explore what we have to offer. \n For immediate consideration for this position, please click on the \u201cApply Now\" button. \n Alliant Insurance Services, Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, age, religion, gender, sexual orientation, gender identity, national origin, disability, protected veteran status or any other protected status. \n If you are applying for a job and need a reasonable accommodation for any part of the employment process, please call our Career Center at 1-877-901-9473 and let us know the nature of your request and contact information. \n \n  For more information on Alliant Insurance Service's benefits, visit the link below. \n \n  https://www.alliant.com/media/p33ldzpp/recruitment_benefits_2022-23.pdf", "cleaned_desc": " Comply with agency management system data standards and data integrity (enter and maintain complete and accurate information). \n Other duties as assigned. \n  QUALIFICATIONS \n EDUCATION / EXPERIENCE \n Bachelor\u2019s degree in finance, accounting, business or equivalent combination of education and experience \n One (1) or more year related work experience \n Significant experience with Microsoft Excel and Access required \n Experience with SQL preferred \n Underwriting experience preferred   \n  SKILLS \n Proficient in Microsoft Office products with a strong emphasis in Excel \n Technical understanding of data structure, data mining, and reporting processes \n Excellent analytical skills \n Excellent interpersonal skills \n Strong verbal and written communication skills \n Ability to perform complex mathematical functions \n Ability to prioritize and multi-task ", "techs": ["microsoft excel", "microsoft access", "sql"]}, "d580b05640aabc54": {"terms": ["data analyst"], "salary_min": 60723.785, "salary_max": 76889.84, "title": "Data Analyst Associate", "company": "Planet Technologies", "desc": "Planet Technologies, the Nation\u2019s leading Microsoft services provider to the public sector, is looking for a highly motivated individual to join our growing team as \n    Data Analyst . In this role, you will be supporting impactful projects that make a difference for our country.\n   \n \n \n  Data Analysts enable businesses to maximize the value of their data assets by using Microsoft Power BI. As a subject matter expert, the Data Analyst Associate will have a minimum of three (3) years of experience building interactive dashboards and reports from enterprise data stores. Microsoft certification is required.\n   \n \n \n \n Responsibilities \n \n \n  Individual with three (3) years\u2019 operational experience designing and building scalable data models, cleaning and transforming data, and enabling advanced analytic capabilities that provide meaningful business value through easy-to-comprehend data visualizations. \n \n \n \n \n \n \n \n \n  Skills Required \n \n \n  Design and build scalable data models \n  Cleaning and transforming data \n  Enabling advances analytic capabilities \n  Provide meaningful business value \n \n \n \n \n \n \n \n \n    Planet Technologies is the leading provider of Microsoft Consulting Services to public sector and commercial organizations. Planet has significant experience in deploying business intelligence, cloud services, unified communications, and systems management with an emphasis building, deploying, and managing custom solutions that transform the business operations of federal government agencies.\n   \n \n \n  Planet Technologies does not discriminate in employment opportunities, terms and conditions of employment, or practices. All qualified applicants will receive consideration for employment without regard to race, age, gender, religious or political beliefs, national origin or heritage, disability, sexual orientation, protected veteran status, or any characteristic protected by law. Federal Agency Clearance Requirements may require up to a 10 year background investigation - US Citizenship (clearable) is required.\n   \n \n \n  Join our highly talented team of Microsoft Certified Masters and MVP\u2019s \u2013 Visit www.go-planet.com to learn more!", "cleaned_desc": "", "techs": ""}, "09ec3b6016ce5bae": {"terms": ["data analyst"], "salary_min": 100000.0, "salary_max": 110000.0, "title": "Data Visualization Specialist (PowerBI)", "company": "Saebo Consulting", "desc": "Summary \n Are you a master of visual storytelling through data? We're seeking a  PowerBI Dashboard Developer  who can transform complex datasets into intuitive and insightful visualizations. This role is not just about creating dashboards; it's about understanding the narrative behind the numbers and presenting it in a way that drives informed decisions. \n If you have a passion for data visualization and are proficient in PowerBI, we invite you to be a part of our dynamic team, where innovation meets excellence. \n Your Central Role \n \n Design, develop, and maintain interactive dashboards using PowerBI to provide actionable insights. \n Collaborate with data analysts and stakeholders to understand data requirements and deliver tailored visualizations. \n Optimize the performance of PowerBI reports, ensuring data accuracy and integrity. \n Stay updated with the latest trends in data visualization and PowerBI functionalities. \n Work closely with data scientists and developers, integrating PowerBI with other platforms and tools. \n \n Required Qualifications \n \n Bachelor's degree with 5 years of experience in data visualization or a high school diploma with 8 years of experience. \n Proven expertise in PowerBI, including DAX, Power Query, and other advanced functionalities. \n \n What Sets You Apart \n \n Exceptional skills in data visualization and storytelling using PowerBI. \n Experience in integrating PowerBI with other platforms like Tableau, ServiceNow, and Medallia. \n Ability to translate complex data insights into user-friendly visualizations. \n Familiarity with geospatial and procurement data contexts. \n \n You Might Also Have \n \n Advanced skills in data modeling and crafting data-driven strategies. \n Knowledge of big data strategies and implementation. \n Experience with other data visualization tools and platforms. \n Proficiency in AI tooling or prompt engineering. \n \n About Saebo \n Saebo is a veteran-owned minority business and a leading digital agency. We specialize in data-driven solutions, product management services, and top-tier web solutions. Our mission is to empower our clients through cutting-edge technology, management consulting, and innovative web design. Join us in pushing the boundaries of data analysis and web development to deliver outstanding results. \n Visit Saebo\u2019s website: http://www.saebo.pro \n Saebo is an Equal Opportunity Employer. \n Benefits \n Saebo offers a comprehensive benefits package tailored to the diverse needs of our employees. Specific offerings may vary by region. \n Pay Range \n The salary range for this role at Saebo is a general guideline and not a guarantee of compensation. Factors such as job responsibilities, education, experience, skills, and internal equity will be considered when determining the final offer. \n Job Type: Full-time \n Pay: $100,000.00 - $110,000.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n Can you share a portfolio or samples of your past PowerBI dashboards that showcase your expertise in data visualization and storytelling? \n \n Education: \n \n High school or equivalent (Required) \n \n Experience: \n \n relevant: 5 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " \n Bachelor's degree with 5 years of experience in data visualization or a high school diploma with 8 years of experience. \n Proven expertise in PowerBI, including DAX, Power Query, and other advanced functionalities. \n \n What Sets You Apart \n \n Exceptional skills in data visualization and storytelling using PowerBI. \n Experience in integrating PowerBI with other platforms like Tableau, ServiceNow, and Medallia. \n Ability to translate complex data insights into user-friendly visualizations. \n Familiarity with geospatial and procurement data contexts. \n \n You Might Also Have ", "techs": ["powerbi", "dax", "power query", "tableau", "servicenow", "medallia"]}, "e6b2dcbbc7f439b3": {"terms": ["data analyst"], "salary_min": 78571.26, "salary_max": 99488.73, "title": "Data Analyst", "company": "Coefficient", "desc": "Who we are \n  Coefficient is a VC-backed SaaS startup based in the SF Bay Area. We are building a remote-first company with a focus on hiring the best talent regardless of location. Our culture is centered around people who are smart, driven, curious and collaborative. We are embarking on a journey to unleash the power and flexibility of spreadsheets across all of the data in company systems. The founders are serial entrepreneurs whose last startup, Shopular, was backed by Y Combinator and Sequoia and acquired by Rakuten Ebates. \n  What we do \n  Coefficient provides a no-code solution that enables business teams to access their company data in real-time directly from their spreadsheets and make it actionable across the organization. Whether their data lives in business applications, databases, data warehouses, or business intelligence solutions, business users can easily work with this data without IT involvement. \n  Using Coefficient, business teams can be more effective with company data that's connected, automated and performant in the most familiar and flexible analytics product - their spreadsheet. By meeting users where they are, companies can now reduce friction between IT and business teams to drive higher efficiency and growth. \n  Overview \n  We're looking for a proactive data analyst to join our team. This person will be naturally curious and proactive, and love solving growth problems with data. This role requires advanced SQL and spreadsheet knowledge, especially with looking at product analytics. We're looking for a partner in this role that can help drive business decisions and uncover opportunities that will help scale our business. If you are a relentless problem solver who loves data and loves working with smart people, this is the role for you. \n \n \n  Responsibilities \n \n Support the building and maintenance of a comprehensive internal analytics system to cover all business departments so stakeholders can quickly and easily access the data, metrics or analysis they need. \n Meet with stakeholders from all departments to gather requirements on their reporting needs and provide solutions to address their questions. \n Provide ad hoc analysis for all departments as needed. \n Bring intellectual curiosity to our business and constantly bring proactive insights and recommendations to the table \n Become a strong and knowledgeable user of Coefficient. Report bugs and suggest product improvements. \n Be a steward for data hygiene across the organization, identifying missing or inaccurate data and suggesting new data that should be captured. \n Maintain awareness of all fundamental business metrics and set up alerts to identify any potential issues as soon as they occur. \n Always seek ways to automate repetitive tasks and perform work more efficiently. \n Other responsibilities as required. \n \n Requirements \n \n 3-7 years experience in data analysis roles, preferably in SaaS or startup environments. \n Extensive familiarity and expertise with SQL. \n Understanding of core principles of business analysis and key metrics for SaaS PLG startups, including experience with Amplitude or a similar product analytics platform. \n Advanced spreadsheet knowledge, including complex formulas, pivot tables and charts. \n Knowledge of data visualization principles and how to make dashboards and reporting easy to view, interact with, and gain insights from. \n Experience with some of the following platforms: HubSpot, Google Analytics, Google Data Studio, Amplitude, Notion, Stripe, Chargebee, Slack, Retool \n Ability to communicate effectively with internal stakeholders, manage project timelines, and deliver on time. \n \n Location \n  We are building a remote-only team and looking for candidates anywhere who can work US time zone hours. Having worked remotely in the past is a plus. \n  Our Benefits: \n \n Medical, Dental and Vision Insurance \n \n \n Unlimited PTO \n \n \n Parental Leave \n \n \n 401K Plan \n \n \n Remote Work \n \n  We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace.", "cleaned_desc": " Always seek ways to automate repetitive tasks and perform work more efficiently. \n Other responsibilities as required. \n \n Requirements \n \n 3-7 years experience in data analysis roles, preferably in SaaS or startup environments. \n Extensive familiarity and expertise with SQL. \n Understanding of core principles of business analysis and key metrics for SaaS PLG startups, including experience with Amplitude or a similar product analytics platform. \n Advanced spreadsheet knowledge, including complex formulas, pivot tables and charts. ", "techs": ["sql", "amplitude"]}, "04e61d33cc072628": {"terms": ["data analyst"], "salary_min": 59190.023, "salary_max": 74947.76, "title": "Data Center Operations Analyst", "company": "Ensono", "desc": "Position Summary \n  A Data Center Operations Analyst is responsible for system monitoring, production batch monitoring, workload throughput as well as batch and system task abend recovery for internal and external client MVS / ZOS / VM/VSE environments. \n \n 12 hour \u201cquad\u201d (3 on 3 off/4 on 4 off) shifts (Nights and/or Days). \n 16 week rotation from front half to back half of week. \n Weekends (Saturday and/or Sunday) and Holidays required as per Shift Schedule. \n Occasional travel (approx 10%) as required to client site for knowledge acquisition of new business. \n \n Position reports to Manager, Mainframe Operations. \n Key Areas of Focus for this Role \n \n Monitor and manage internal and external MVS zSeries and VM/VSE environments to ensure production processing meets internal and external client agreed service levels and requirements. \n High level of interaction with internal and external customers requires effective and professional communication. \n Complete daily shift turnover and customer checklists associated with assigned client environment. Along with written shift turnover, verbal turnover must be facilitated. \n Thoroughly document deviations within company\u2019s designated Incident Management tool, reflecting clear and tangible details surrounding each incident. \n Properly escalate all events or incidents that may impact our ability to meet agreed service levels. \n Ensure system IPL, maintenance and backup processes are successfully performed according to predetermined schedule and per established procedures. \n Ensure all operations related changes are properly documented and approved in company designated Change Management tool prior to implementation. Follow-up and close completed changes with valid and meaningful data. \n Adhere to company documented processing procedures for internal and external clients, as well as suggesting and requesting updates and improvements as needed to internal Operations SharePoint documentation repository. \n Organize tasks to work independently. \n Hands and feet support as required. \n Perform additional duties as assigned or designated by Operations management. \n \n What the Ideal Candidate Brings to this Role \n  Required Qualifications help to assure new Associates are set up for success in their role with Ensono. To be considered for this career opportunity, it is important that you meet all Required Qualifications. Candidates that may meet some, but not all, Other Qualifications are still encouraged to apply. \n  Required Qualifications \n \n Typically requires a Bachelor\u2019s degree and a minimum of 2 years of related experience; or an advanced degree without experience; or equivalent work experience \n 5 years experience in IT and with system monitoring. \n Proficient in MS Office (Excel, Word, and Outlook) \n Strong written / verbal Communication skills \n Designing skills \n Analytical and Critical thinking skills \n Ability to represent Ensono in a professional manner to clients \n Knowledge of mainframe (TSO, SDSF, TMS, QuickRef) and server scripts (read & codeMidrange server knowledge) \n \n Why Ensono? \n  Ensono is a place we unleash Associates to  Do Great Things  \u2013 for our clients and for your career. This could mean achieving a professional goal, collaborating with your team on an innovative idea, learning a new skill, reaching a wellness milestone, or engaging in your community through volunteer programs. Whatever it means to you, we want Ensono to be the place where you can do great things. \n \n We value flexibility and work-life balance. Positions that are not required to be onsite to support a client may offer the ability to work remotely or hybrid at an Ensono office location. \n Unlimited Paid Day Off (PDO) Plan \n Two robust health plan options through Blue Cross Blue Shield \n 401(k) with a generous company match \n Eligibility for dental, vision, short and long-term disability, life and AD&D coverage, and flexible spending accounts \n Depending on location, ability to take advantage of fitness centers \n Wellness program \n Flexible work schedule \n \n Ensono is an Equal Opportunity/Affirmative Action employer. We are committed to providing equal employment to our Associates and building a diverse and inclusive workforce. All qualified applicants will be considered without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, or other legally protected basis, in accordance with applicable law. \n Pay transparency nondiscrimination statement/posting OFCCP\u2019s pay transparency policy can be found on OFCCP\u2019s website. \n If you need accommodation at any point during the application or interview process, please let your recruiter know or email USTalentAcquisition@esnono.com.", "cleaned_desc": "", "techs": ""}, "c785359891e1fdbc": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Data Analyst (Remote in California)", "company": "Molina Healthcare", "desc": "Remote in California \n \n  JOB DESCRIPTION \n \n  Job Summary Designs and implements processes and solutions associated with a wide variety of data sets used for data/text mining, analysis, modeling, and predicting to enable informed business decisions. Gains insight into key business problems and deliverables by applying statistical analysis techniques to examine structured and unstructured data from multiple disparate sources. Collaborates across departments and with customers to define requirements and understand business problems. Uses advanced mathematical, statistical, querying, and reporting methods to develop solutions. Develops information tools, algorithms, dashboards, and queries to monitor and improve business performance. Creates solutions from initial concept to fully tested production, and communicates results to a broad range of audiences. Effectively uses current and emerging technologies. \n \n  KNOWLEDGE/SKILLS/ABILITIES \n \n  Extracts and compiles various sources of information and large data sets from various systems to identify and analyze outliers. \n \n  Sets up process for monitoring, tracking, and trending department data. \n \n  Prepares any state mandated reports and analysis. \n \n  Works with internal, external and enterprise clients as needed to research, develop, and document new standard reports or processes. \n \n  Implements and uses the analytics software and systems to support the departments goals. \n \n  JOB QUALIFICATIONS \n \n  Required Education \n Associate's Degree or equivalent combination of education and experience \n Required Experience \n 1-3 years \n Preferred Education \n Bachelor's Degree or equivalent combination of education and experience \n Preferred Experience \n 3-5 years \n \n \n To all current Molina employees:  If you are interested in applying for this position, please apply through the intranet job listing. \n Molina Healthcare offers a competitive benefits and compensation package. Molina Healthcare is an Equal Opportunity Employer (EOE) M/F/D/V.", "cleaned_desc": "", "techs": ""}, "d16ec048c6bf0891": {"terms": ["data analyst"], "salary_min": 51195.355, "salary_max": 64824.73, "title": "Infrastructure Data Analyst - Part Time", "company": "Holland America Line", "desc": "Job Description \n  Holland America Line has been exploring the world since 1873. Our ships offer innovative features and enriching experiences focused on destination exploration and personalized travel, inviting guests to savor the journey. \n  We\u2019re looking for an amazing Infrastructure Data Analyst to fill this role, which is based in our Seattle. You\u2019ll be responsible for making daily decisions regarding the execution of fleet connectivity strategies that align with established leadership priorities. Decisions are related to team management (hiring, performance, etc.), project executable requirements, technology standards, product selection. Challenges will occur when balancing multiple team and brand priorities, as well as when working with existing technology debt. Often, recommendations will need to be implemented in phases across all ships based on various financial and operational priorities.  This is a part-time role under 20 hours per week. \n  Here\u2019s a summary of what Holland America Line is looking for in its Infrastructure Data Analyst. Is this you? \n  Responsibilities \n \n Computer Science or other technical degree or equivalent experience \n Analyze Network Operations performance data and provide reports for optimization. Build reports that allow content and distribution to encompass total organization and drilldowns to specific entities as needed \n Manage CMDB data models and distributions for review and changes. \n Maintain functionality and relevance of reports and problem solve as issues arise \n Design, publish and maintain data models with many interrelated tables connected \n Ensure report output is aligned with company data governance processes \n Stay up to date around relevant reporting tools and help implement relevant tools where required \n Help translate business requirements into Power BI reporting requirements. Creating KPIs and reporting packages for teams to provide insight into groups that make strategic decisions. \n Work with users and team members at all levels to elevate existing reports and reporting capabilities and report distribution \n Analyze SLA KPI data and provide reports for all providers, including out-sourced Operation providers, circuits and VSAT providers, cloud services providers. \n Analyze SLA KPI data for Network Operations and provide report to business and local cruise brands\u2019 IT and business. \n Analyze application performance data for admin, guest and crew, identify gaps in application performance in comparison to baseline. \n Provide historical trend reports for satellite performance and bandwidth trends \n Ensure department goals, standards and guiding principles are defined and communicated regularly \n Develop dashboards and portals for business to consume performance data and generate ad-hoc reports. \n Understand and share IT and company vision and provide strategic direction to team managers \n Oversee and ensure proper communication protocols are established and upheld \n Maintain strong partnerships with IT sponsors and stakeholders to ensure BI data solutions and services are delivered in-line with expectations and priorities \n Maintain relevant industry knowledge and act as advisor to the business of best practices, strategies and technologies \n Perform all other administrative and organizational duties as required (time keeping, training, travel, collaboration and correspondence, etc.) \n \n Requirements \n \n Minimum 4 years in a corporate technology environment \n Minimum 2 years performing BI related data analysis and reporting \n 1+ years designing and developing reports and dashboards \n Strong Excel skills \n Understand business requirements and convert data into meaningful insights \n Experience analyzing high volumes of data for multiple purposes \n Strong analytical skills, with experience developing financial modeling and analysis. \n Ability to multi-task, which requires strong organizational skills, attention to detail and quality. \n Possess excellent verbal and written communication skills and have a process improvement-oriented mindset. \n Leadership, engagement, collaboration and other necessary skills \n Excellent technical communication and collaboration skills across multiple teams \n Ability to work very collaboratively in a team environment \n Be able to manage your time efficiently and work with little supervision \n Must be legally authorized to work in the United States. Holland America is unable to sponsor or take over sponsorship of employment visas at this time (e.g., H-1B status). \n \n Please note that this position can be 100% fully remote, US Only   (please note that Holland America Line is not setup to hire anyone in the following states: AR, DE, HI, ME, MN, MS, NE, NH, OK, SD, VT, WV, WY) \n  What You Can Expect \n \n Cruise and Travel Privileges for You and Your Family \n Health Benefits \n 401(k) \n Employee Stock Purchase Plan \n Training & Professional Development \n Tuition & Professional Certification Reimbursement \n Rewards & Incentives \n Hourly Range: $37.60 to $50.77. The range is applicable for the labor market where the role is intended to be hired. Final hourly range is directly related to each candidates' qualifications and experience uniquely.  This is a part-time role under 20 hours per week. \n \n Our Culture\u2026 Stronger Together \n  Our highest responsibility and top priority is compliance, environmental protection and the health, safety and well-being of our guests, the people in the communities we touch and serve, and our shipboard and shoreside employees. Please visit our site to learn more about our Culture Essentials, Corporate Vision Statement and our Core Values at:  https://www.hollandamerica.com/en_US/our-company/mission-values.html    Holland America is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. \n \n  Americans with Disabilities Act (ADA) \n  Holland America will provide reasonable accommodations with the application process, upon your request, as required to comply with applicable laws. If you have a disability and require assistance in this application process, please contact recruiting@hollandamericagroup.com \n \n  #HAL", "cleaned_desc": " Maintain relevant industry knowledge and act as advisor to the business of best practices, strategies and technologies \n Perform all other administrative and organizational duties as required (time keeping, training, travel, collaboration and correspondence, etc.) \n \n Requirements \n \n Minimum 4 years in a corporate technology environment \n Minimum 2 years performing BI related data analysis and reporting \n 1+ years designing and developing reports and dashboards \n Strong Excel skills \n Understand business requirements and convert data into meaningful insights \n Experience analyzing high volumes of data for multiple purposes \n Strong analytical skills, with experience developing financial modeling and analysis. ", "techs": ["excel", "bi related data analysis", "reporting", "designing reports", "developing dashboards", "financial modeling and analysis"]}, "293895d593f2d58d": {"terms": ["data analyst"], "salary_min": 51195.355, "salary_max": 64824.73, "title": "Infrastructure Data Analyst - Part Time", "company": "Holland America Line Inc", "desc": "Holland America Line has been exploring the world since 1873. Our ships offer innovative features and enriching experiences focused on destination exploration and personalized travel, inviting guests to savor the journey.  \n We\u2019re looking for an amazing Infrastructure Data Analyst to fill this role, which is based in our Seattle. You\u2019ll be responsible for making daily decisions regarding the execution of fleet connectivity strategies that align with established leadership priorities. Decisions are related to team management (hiring, performance, etc.), project executable requirements, technology standards, product selection. Challenges will occur when balancing multiple team and brand priorities, as well as when working with existing technology debt. Often, recommendations will need to be implemented in phases across all ships based on various financial and operational priorities.  This is a part-time role under 20 hours per week.  \n Here\u2019s a summary of what Holland America Line is looking for in its Infrastructure Data Analyst. Is this you?  \n Responsibilities  \n \n Computer Science or other technical degree or equivalent experience  \n Analyze Network Operations performance data and provide reports for optimization. Build reports that allow content and distribution to encompass total organization and drilldowns to specific entities as needed  \n Manage CMDB data models and distributions for review and changes.  \n Maintain functionality and relevance of reports and problem solve as issues arise  \n Design, publish and maintain data models with many interrelated tables connected  \n Ensure report output is aligned with company data governance processes  \n Stay up to date around relevant reporting tools and help implement relevant tools where required  \n Help translate business requirements into Power BI reporting requirements. Creating KPIs and reporting packages for teams to provide insight into groups that make strategic decisions.  \n Work with users and team members at all levels to elevate existing reports and reporting capabilities and report distribution  \n Analyze SLA KPI data and provide reports for all providers, including out-sourced Operation providers, circuits and VSAT providers, cloud services providers.  \n Analyze SLA KPI data for Network Operations and provide report to business and local cruise brands\u2019 IT and business.  \n Analyze application performance data for admin, guest and crew, identify gaps in application performance in comparison to baseline.  \n Provide historical trend reports for satellite performance and bandwidth trends  \n Ensure department goals, standards and guiding principles are defined and communicated regularly  \n Develop dashboards and portals for business to consume performance data and generate ad-hoc reports.  \n Understand and share IT and company vision and provide strategic direction to team managers  \n Oversee and ensure proper communication protocols are established and upheld  \n Maintain strong partnerships with IT sponsors and stakeholders to ensure BI data solutions and services are delivered in-line with expectations and priorities  \n Maintain relevant industry knowledge and act as advisor to the business of best practices, strategies and technologies  \n Perform all other administrative and organizational duties as required (time keeping, training, travel, collaboration and correspondence, etc.)  \n \n Requirements  \n \n Minimum 4 years in a corporate technology environment  \n Minimum 2 years performing BI related data analysis and reporting  \n 1+ years designing and developing reports and dashboards  \n Strong Excel skills  \n Understand business requirements and convert data into meaningful insights  \n Experience analyzing high volumes of data for multiple purposes  \n Strong analytical skills, with experience developing financial modeling and analysis.  \n Ability to multi-task, which requires strong organizational skills, attention to detail and quality.  \n Possess excellent verbal and written communication skills and have a process improvement-oriented mindset.  \n Leadership, engagement, collaboration and other necessary skills  \n Excellent technical communication and collaboration skills across multiple teams  \n Ability to work very collaboratively in a team environment  \n Be able to manage your time efficiently and work with little supervision  \n Must be legally authorized to work in the United States. Holland America is unable to sponsor or take over sponsorship of employment visas at this time (e.g., H-1B status).  \n \n Please note that this position can be 100% fully remote, US Only  (please note that Holland America Line is not setup to hire anyone in the following states: AR, DE, HI, ME, MN, MS, NE, NH, OK, SD, VT, WV, WY)  \n What You Can Expect  \n \n Cruise and Travel Privileges for You and Your Family  \n Health Benefits  \n 401(k)  \n Employee Stock Purchase Plan  \n Training & Professional Development  \n Tuition & Professional Certification Reimbursement  \n Rewards & Incentives  \n Hourly Range: $37.60 to $50.77. The range is applicable for the labor market where the role is intended to be hired. Final hourly range is directly related to each candidates' qualifications and experience uniquely.  This is a part-time role under 20 hours per week.  \n \n Our Culture\u2026 Stronger Together  \n Our highest responsibility and top priority is compliance, environmental protection and the health, safety and well-being of our guests, the people in the communities we touch and serve, and our shipboard and shoreside employees. Please visit our site to learn more about our Culture Essentials, Corporate Vision Statement and our Core Values at:  https://www.hollandamerica.com/en_US/our-company/mission-values.html     Holland America is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.     \n Americans with Disabilities Act (ADA)  \n Holland America will provide reasonable accommodations with the application process, upon your request, as required to comply with applicable laws. If you have a disability and require assistance in this application process, please contact recruiting@hollandamericagroup.com     \n #HAL", "cleaned_desc": " Maintain strong partnerships with IT sponsors and stakeholders to ensure BI data solutions and services are delivered in-line with expectations and priorities  \n Maintain relevant industry knowledge and act as advisor to the business of best practices, strategies and technologies  \n Perform all other administrative and organizational duties as required (time keeping, training, travel, collaboration and correspondence, etc.)  \n \n Requirements  \n \n Minimum 4 years in a corporate technology environment  \n Minimum 2 years performing BI related data analysis and reporting  \n 1+ years designing and developing reports and dashboards  \n Strong Excel skills  \n Understand business requirements and convert data into meaningful insights    Experience analyzing high volumes of data for multiple purposes  \n Strong analytical skills, with experience developing financial modeling and analysis.  \n Ability to multi-task, which requires strong organizational skills, attention to detail and quality.  \n Possess excellent verbal and written communication skills and have a process improvement-oriented mindset.  \n Leadership, engagement, collaboration and other necessary skills  \n Excellent technical communication and collaboration skills across multiple teams  \n Ability to work very collaboratively in a team environment  \n Be able to manage your time efficiently and work with little supervision  \n Must be legally authorized to work in the United States. Holland America is unable to sponsor or take over sponsorship of employment visas at this time (e.g., H-1B status).  \n \n Please note that this position can be 100% fully remote, US Only  (please note that Holland America Line is not setup to hire anyone in the following states: AR, DE, HI, ME, MN, MS, NE, NH, OK, SD, VT, WV, WY)  ", "techs": ["excel skills"]}, "0b6864d88a9f6dde": {"terms": ["data analyst"], "salary_min": 74453.61, "salary_max": 94274.86, "title": "Data Analyst", "company": "Foundation Finance Company, LLC", "desc": "Description: \n   About Foundation Finance: \n  Foundation Finance Company (FFC) is one of the fastest-growing consumer finance companies in the U.S. We work with home improvement contractors nationwide to help them close more sales through the use of flexible financing plans. FFC's full-spectrum lending approach has driven billions in originations and helped many customers make needed improvements to their homes. We're making big investments in both infrastructure and employee talent to keep up with our growth, so the time is right to join our team! It's a fast-paced environment with room to advance. We offer a competitive salary, medical/dental/vision benefits, 401(k) with company match, a casual dress work environment and much, much, more.  Overview: \n   Data Analyst Description & Duties: \n  The Data Analyst will help drive profitable growth by leveraging data and analytics. The data analyst analyses data sets to find ways to solve problems relating to the business communicating this information to management and other stakeholders. \n \n  Duties may include, but are not limited to:  Responsibilities: \n  \n Dive into data and quickly become an expert on internal and non-traditional data sets. \n  Maintain data and file integrity. \n  Improve existing data query scripts and develop new ones as needed. \n  Create user-friendly reports and Tableau visualizations for staff and management. \n  Enhance existing and build new Tableau dashboards as needed. \n  Track, review, manage and audit software development projects, particularly from database access and usage perspectives. \n  Work with staff, managers and executives on analytic projects and develop data-driven solutions and recommendations. \n  Other duties as assigned by management. Must be able to come to work promptly and regularly. Must be able to take direction and work well with others. Must be able to work under the stress of deadlines. Must be able to concentrate and perform accurately. Must be able to react to change productively. \n \n \n  The Ideal Candidate: \n \n   Applicants must be reliable, dynamic, sociable and enthusiastic team players; while possessing a positive \"can-do\" attitude, excellent judgement and communication skills. Applicants must also have great attention to detail and ability to multi-task under the stress of deadlines with a strong desire to help the organization succeed.\n   Qualifications: \n  \n  Minimum Qualifications: \n \n \n  Bachelor\u2019s degree in Finance, Business, Economics or related field required. Relevant data analyst experience preferred or combination of education and experience. \n  Hands-on familiarity with SQL or Python data querying, coding experience and understanding of basic coding syntax \n  Advanced Excel skills to create/edit pivot tables, understand/create/manipulate database formulas, create/modify macros (VBA knowledge preferred) \n  Adjust formatting to create professional reports; Data visualization skills, preferably with Tableau. \n  Associate Certified Analytics Professional (aCAP\u00ae) is preferred. \n \n  Foundation Finance Company LLC requires that remote employees must reside in one of the following states to be considered for any of our remote positions: WI, AL, AR, AZ, CO, CT, FL,GA, IA, IL, IN, KY, MD, ME, MI, MN, MO, MS, NC, NJ, NV, NY, OH, OK, OR, SC, TN, TX, UT, VA, WA \n \n  Working Conditions: \n \n   Office environment with significant time spent sitting, typing and talking on the telephone.\n  \n \n \n  Foundation Finance Company provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.", "cleaned_desc": " Dive into data and quickly become an expert on internal and non-traditional data sets. \n  Maintain data and file integrity. \n  Improve existing data query scripts and develop new ones as needed. \n  Create user-friendly reports and Tableau visualizations for staff and management. \n  Enhance existing and build new Tableau dashboards as needed. \n  Track, review, manage and audit software development projects, particularly from database access and usage perspectives. \n  Work with staff, managers and executives on analytic projects and develop data-driven solutions and recommendations. \n  Other duties as assigned by management. Must be able to come to work promptly and regularly. Must be able to take direction and work well with others. Must be able to work under the stress of deadlines. Must be able to concentrate and perform accurately. Must be able to react to change productively.   \n \n  Bachelor\u2019s degree in Finance, Business, Economics or related field required. Relevant data analyst experience preferred or combination of education and experience. \n  Hands-on familiarity with SQL or Python data querying, coding experience and understanding of basic coding syntax \n  Advanced Excel skills to create/edit pivot tables, understand/create/manipulate database formulas, create/modify macros (VBA knowledge preferred) \n  Adjust formatting to create professional reports; Data visualization skills, preferably with Tableau. \n  Associate Certified Analytics Professional (aCAP\u00ae) is preferred. \n ", "techs": ["sql", "python", "tableau (data visualization software)", "excel (advanced skills)", "vba (macros)", "associate certified analytics professional (acap\u00ae)"]}, "7278b1eca5aa70c0": {"terms": ["data analyst"], "salary_min": 45000.0, "salary_max": 55000.0, "title": "Junior Data Analyst", "company": "Nuvia Dental Implant Centers", "desc": "Nuvia Dental Implant Center is looking for a Junior Data Analyst to join our team. We provide dental implants and full mouth restorations to our patients, literally changing their lives. It's a unique time to join our organization, we are a rapidly growing company with many opportunities for advancement. Nuvia has an amazing company culture and we are looking for top talent to lay a solid foundation and set our teams up for success. This position will be assisting with our data storage and visualization. \n \n  Nuvia is a great place to work! We pride ourselves in the satisfaction of our teams and believe if they are well taken care of, in turn, they will take great care of our patients. Our benefits package includes the following: \n \n Medical Insurance \n Paid Dental Insurance \n \n \n Paid Life Insurance \n \n \n Paid Short Term Disability \n Paid Training \n Paid Time Off plan \n Paid Bereavement \n Paid Holidays \n Paid Parental Leave \n \n \n 401k match \n Employee Assistance Program \n \n \n Vision (voluntary) \n Long Term Disability (voluntary) \n \n \n \n  Responsibilities \n \n Become a master of data visualization \n Build dashboards and metrics as requested \n Analyze data for any discrepancies or improvements \n Provide insights and recommendations \n \n \n \n  Results \n \n Deliver Reliable accurate data for executive, sales, marketing and other teams to make decisions quickly \n \n \n \n  Requirements \n \n \n \n Available to work Mon-Fri from 8am to 5pm \n Proven track record for prioritizing tasks in a fast paced environment \n Expert competency in excel / google sheets \n SQL knowledge a major plus \n Be attentive to all details with excellent verbal and written communication skills \n Ability to work independently and also under pressure to meet deadlines \n Understand and live by Nuvia company values \n \n \n \n   \n Our team members are as diverse as the patients we serve. Imagine being part of a team that gets to give patients their confidence back through a brand new smile, we get to do it every day! We are eager to invent, find new solutions to problems and develop new processes. At Nuvia, we have a culture of excellence while still collaborating well as a team. We are obsessed with our patients, love what we do and feel honored to be able to provide such an incredible service. \n \n  If you feel like you would be a good fit with our culture and like the idea of changing people's lives, apply today! We look forward to meeting you", "cleaned_desc": "", "techs": ""}, "0aa46984ba5b1a0e": {"terms": ["data analyst"], "salary_min": 71847.0, "salary_max": 121272.0, "title": "Data Governance Analyst (Remote)", "company": "Amica Mutual Insurance Company", "desc": "Data Governance Analyst - Remote    Enterprise Solutions   25 Amica Way, Lincoln, RI 02865 \n  Your future is our business. \n  We\u2019re redefining excellent customer experiences. Data drives that process. \n  As a Data Governance Analyst, you are responsible for executing an enterprise-wide Data Governance strategy by working with business and technology partners to ensure alignment and dedication to objectives. \n  This position is eligible for remote work. \n  Responsibilities: \n \n Execute an enterprise-wide Data Governance strategy by working with business and technology partners to ensure alignment and dedication to objectives.  \n Create and implement best practices in Data Governance.  \n Define and implement an enterprise business glossary, data catalog, data dictionary, and Data Governance best practices.  \n Establish and maintain data standards and data ownership. Actively collaborate with data owners and data stewards to complete various data projects and with compliance team to develop policy and processes for handling sensitive data.  \n Facilitate cross-functional data domain groups to drive data governance activities. Communicate the importance of managing data as an asset in all aspects of the role. \n \n Starting salary range of $71,847 - $121,272 annually based on qualifications and experience. In addition, hired applicants will be eligible for the company\u2019s annual variable incentive paid based on company performance. Additional commission opportunities may apply to customer facing sales and service representatives. \n   Qualifications: \n \n Bachelor\u2019s degree or equivalent from an accredited college or university in Information Management, Computer Science, Computer Systems Engineering, Business Administration, Mathematics, or a related field. \n Three or more years of expertise in metadata management, data privacy, and data security. \n Three or more years of experience with data cataloging tools, including assessing features and functionalities, POC, recommendation, implementation, and maintenance. \n Solid understanding of data governance frameworks, principles, and best practices. \n Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. \n Demonstrated ability to understand business processes and the definition of data requirements to meet complex business needs. \n Deep understanding of data-related regulatory requirements and knowledge of emerging trends and issues. \n Experience working with large data repositories, AWS cloud platform, and/or relational databases. \n Familiarity with data management technologies such as SQL Server, Teradata, Oracle, Postgres, data warehousing, and/or NoSQL DB (e.g., mongo DB). \n Familiarity with frameworks and best practices in data quality management. \n Driven to continuously develop and acquire new skills and learn new tools. \n Strong project management/business analysis knowledge and familiarity with Agile methodology. \n Knowledge of process improvement techniques, risk identification, and mitigation. \n Strong prioritization, organization, time management, and problem-solving skills. \n Strong stakeholder management and interpersonal skills to build productive and positive relationships across organizations. \n Skilled at developing presentations with business/technical details for key stakeholders. \n Ability to quickly adapt to changes in both technology and business environments. \n \n Perks and Benefits \n \n Medical, dental, vision coverage, short- and long-term disability, and life insurance \n Generous leave programs, including paid parental bonding leave \n Student Loan Repayment and Tuition Reimbursement programs \n Paid Vacation \u2013 you will receive at least 10 vacation days in the first 12 months, amounts could be greater depending on the role \n Holidays - 14 paid holidays observed and 2 additional floating paid holidays provided \n Sick time - 6 days sick time at hire, 6 additional days sick time at 90 days of employment \n Generous 401k with company match and immediate vesting \n Family support benefits including back-up care \n Competitive salaries and exceptional benefits \n Fitness and wellness reimbursement \n Employee community involvement \n Strong relationships, lifelong friendships \n Opportunities for advancement in a successful and growing company \n \n About Amica \n  Amica Mutual Insurance Company is America's oldest mutual insurer of automobiles. A direct national writer, Amica also offers home, marine and umbrella insurance. Amica Life Insurance Company, a wholly owned subsidiary, provides life insurance and retirement solutions. Amica was founded on the principles of creating peace of mind and building enduring relationships for and with our exceptionally loyal policyholders, a mission that thousands of employees in offices nationwide share and support. \n  Equal Opportunity Policy: All qualified applicants who are authorized to work in the United States will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, family status, ethnicity, age, national origin, ancestry, physical and/or mental disability, mental condition, military status, genetic information or any other class protected by law. The Age Discrimination in Employment Act prohibits discrimination on the basis of age with respect to individuals who are 40 years of age or older. Employees are subject to the provisions of the Workers' Compensation Act. \n  #Dice \n  #LI-ES1 \n  rp \n  #LI-Remote", "cleaned_desc": " Facilitate cross-functional data domain groups to drive data governance activities. Communicate the importance of managing data as an asset in all aspects of the role. \n \n Starting salary range of $71,847 - $121,272 annually based on qualifications and experience. In addition, hired applicants will be eligible for the company\u2019s annual variable incentive paid based on company performance. Additional commission opportunities may apply to customer facing sales and service representatives. \n   Qualifications: \n \n Bachelor\u2019s degree or equivalent from an accredited college or university in Information Management, Computer Science, Computer Systems Engineering, Business Administration, Mathematics, or a related field. \n Three or more years of expertise in metadata management, data privacy, and data security. \n Three or more years of experience with data cataloging tools, including assessing features and functionalities, POC, recommendation, implementation, and maintenance. \n Solid understanding of data governance frameworks, principles, and best practices. \n Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. \n Demonstrated ability to understand business processes and the definition of data requirements to meet complex business needs.   Deep understanding of data-related regulatory requirements and knowledge of emerging trends and issues. \n Experience working with large data repositories, AWS cloud platform, and/or relational databases. \n Familiarity with data management technologies such as SQL Server, Teradata, Oracle, Postgres, data warehousing, and/or NoSQL DB (e.g., mongo DB). \n Familiarity with frameworks and best practices in data quality management. \n Driven to continuously develop and acquire new skills and learn new tools. \n Strong project management/business analysis knowledge and familiarity with Agile methodology. \n Knowledge of process improvement techniques, risk identification, and mitigation. \n Strong prioritization, organization, time management, and problem-solving skills. \n Strong stakeholder management and interpersonal skills to build productive and positive relationships across organizations. \n Skilled at developing presentations with business/technical details for key stakeholders. \n Ability to quickly adapt to changes in both technology and business environments. ", "techs": ["metadata management", "data privacy", "data security", "data cataloging tools", "data governance frameworks", "data-related regulatory requirements", "aws cloud platform", "relational databases", "sql server", "teradata", "oracle", "postgres", "data warehousing", "nosql db", "mongo db", "data quality management", "agile methodology"]}, "5698a8e35ea0e9a1": {"terms": ["data analyst"], "salary_min": 68133.805, "salary_max": 86272.586, "title": "Analyst, Content Analytics", "company": "Recurrent Ventures", "desc": "About Us \n \n  Recurrent Ventures Inc. is an innovative digital media company that is challenging the media landscape with its proprietary approach. Its best-in-class brands like Popular Science, Domino, Outdoor Life, The Drive, Donut, Dwell, Task & Purpose and more, engage a combined audience of more than 60 million monthly visitors. Initially founded in 2018, the portfolio rapidly expanded and today we have more than 15 publishing brands across automotive, home, outdoors, science, technology, and military verticals. Recurrent Ventures is virtual first, with headquarters in Miami and offices in New York, San Diego, Los Angeles and San Francisco. \n \n  Summary \n The Analyst, Content Analytics will sit between the worlds of content performance data and editorial strategy as they assist in the creation of profitable content across Recurrent Ventures\u2019 portfolio of brands. They will be a primary user of Recurrent\u2019s content performance analytics tools\u2013 translating insights into regular content planning recommendations for content teams. This person will collaborate daily with our business operations, technology, and editorial teams to build world-class content experiences for our audiences and drive measurable results for the business. \n Responsibilities \n \n \n Create and maintain reports that illustrate which characteristics of content drive the best experiences for our audiences and results for the business. Monitor daily and weekly dashboards to understand audience trends and the results of our content strategies. \n Share learnings with key stakeholders, creating data visualizations, sharing findings in group presentations, and surfacing intel on portfolio- and media industry-wide trends. \n Perform data cleaning and aggregation to ensure data accuracy and integrity. \n Identify, analyze, and interpret trends or patterns in complex data sets. \n Distill large data sets into a more easily digestible format that can be translated into actionable insights. \n Study search demand to identify content opportunities. Collaborate across teams to implement identified content opportunities. \n Monitor and analyze competitors. \n Partner with the product and engineering teams to vet and develop new content performance data sources and create ongoing efficiencies within key BI tools, such as Looker and Google Analytics. \n Serve as a data guide and teacher, helping others make better data-driven decisions, read and understand reporting, and build their own bespoke reports. \n  Qualifications \n \n \n A Bachelor\u2019s Degree from an accredited four year college or university in Business Administration, Mathematics, or other related field is preferred. \n At least two (2) years of experience in data analytics with an emphasis on content analytics. \n A general understanding of digital media audiences. \n Experience with SQL and comfortable with sourcing, merging, and working with multiple, disparate data sets. \n Experience with Google Analytics, Wordpress, Looker, and/or PowerBI a plus. \n Ability to analyze, interpret, and visualize data into clean, clear, and digestible dashboards and reports. \n Demonstrated entrepreneurial spirit. \n Strong organizational and communication skills. \n Strong Excel skills. \n Writing or editing background is a plus. \n  Benefits & Perks \n \n \n \n Medical, dental, vision & life insurance \n Fitness Reimbursement \n Unlimited PTO \n Remote - work from anywhere! \n Parental leave \n Matching 401k \n Equity package \n \n Hiring & Equal Opportunity Statement:  Recurrent Ventures provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type with regard to race, ethnicity, national origin, color, religion, age, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic or affiliation protected by federal, state or local laws. With a number of our media brands reporting on the military, veterans\u2019 affairs, and topics facing the active military community, we are very supportive of veterans\u2019 activities and highly encourage this community to apply.", "cleaned_desc": " Partner with the product and engineering teams to vet and develop new content performance data sources and create ongoing efficiencies within key BI tools, such as Looker and Google Analytics. \n Serve as a data guide and teacher, helping others make better data-driven decisions, read and understand reporting, and build their own bespoke reports. \n  Qualifications \n \n \n A Bachelor\u2019s Degree from an accredited four year college or university in Business Administration, Mathematics, or other related field is preferred. \n At least two (2) years of experience in data analytics with an emphasis on content analytics. \n A general understanding of digital media audiences.   Experience with SQL and comfortable with sourcing, merging, and working with multiple, disparate data sets. \n Experience with Google Analytics, Wordpress, Looker, and/or PowerBI a plus. \n Ability to analyze, interpret, and visualize data into clean, clear, and digestible dashboards and reports. \n Demonstrated entrepreneurial spirit. \n Strong organizational and communication skills. \n Strong Excel skills. \n Writing or editing background is a plus. \n  Benefits & Perks ", "techs": ["looker", "google analytics", "sql", "wordpress", "powerbi", "excel"]}, "e1f7e843d2a63843": {"terms": ["data analyst"], "salary_min": 82943.586, "salary_max": 105025.055, "title": "BUSINESS ANALYST", "company": "Transition Technologies PSC Sp. z o. o.", "desc": "_ Business Analyst  \n \n \n \n _ What will you do? \n \n Responsibilities : \n  You will be a member of project team that implements ITSM solutions for external customers. The solution is based on third-party system and aligned with ITIL best practices. During the project you will combine the role of business analyst with ITSM specialist by: \n \n Working closely with external customers: identify needs, gather requirements and analyzing customer\u2019s expectations; \n Modeling business processes with focus on IT Service Management Area; \n Suggesting optimizations and areas for improvement; \n Hosting workshops and meetings with the customer, presenting solutions to stakeholders; \n Creating a concept of final solutions based on third-party vendors\u2019 systems; \n Participation in presales activities like assessing feasibility of the requirements and preparing content of the commercial offer; \n Close cooperation with technical teams; \n Verification whether delivered solution meets business needs; \n Collaboration within a team of business analysts. \n \n \n \n \n _ Who are we looking for? \n \n \n Requirements : \n \n At least 3 years of experience in IT Service Management (Service Manager, Service Delivery Manager, Service Desk Manager, Incident Manager, Asset Manager etc); \n Good knowledge of at least one of ITSM tool: ServiceNow, BMC, Atlassian/Jira, Manage Engine/Service Desk+; \n Very good understanding of ITIL concept, experience in working with ITIL best practices; \n Ability to suggest how to implement an ITIL-compliant processes in the organization; \n Strong communication and presentation skills; \n Ability to share knowledge, focus on learning new skills independently; \n Effective communication skills in English \u2013 at least (B2/C1) level; \n \n Nice to have : \n \n ITIL Certificate; \n Experience in Business Analysis or Project Management area; \n Technical IT background; \n Familiar with Jira and Confluence; \n Readiness to public presentations. \n \n \n \n \n \n \n \n \n _ Why is it worth it? \n \n \n What can we offer : \n \n Flexible forms of employment and working hours (CoE or B2B); \n An interesting, challenging job in the dynamically developing Capital Group company; \n Work on innovative projects using modern technologies; \n Direct impact on shaping the image of the Capital Group\u2019s companies on the market; \n Possibility to develop competences in a wide range; \n Attractive salary; \n Stability of employment and a friendly work atmosphere; \n Cool benefits, among others integration meetings, internal company competitions, fruit Tuesdays, sweet Thursdays and much more;", "cleaned_desc": "", "techs": ""}, "6513216e79582d48": {"terms": ["data analyst"], "salary_min": 71230.97, "salary_max": 90194.28, "title": "Data Governance Analyst", "company": "Capital Blue Cross", "desc": "Position Description: \n   At Capital Blue Cross, we promise to go the extra mile for our team and our community. This promise is at the heart of our culture, and it\u2019s why our employees consistently vote us one of the \u201cBest Places to Work in PA.\u201d \n  The Data Governance Analyst is a position within the Analytics & Reporting department that reports directly to the Data Governance Manager. The Data Governance Analyst supports the Data Governance Manager in implementing a corporate-wide Data Governance strategy that manages enterprise information life cycle needs in an effective manner and in a way that encourages thinking and acting globally about its production and use. This individual is responsible for supporting data governance strategy by working across lines of business and Information Technology to ensure alignment and dedication to the overall objectives. S/he supports on-going attention to the regulatory environment to ensure the organization is meeting regulatory and compliance standards. The Data Governance Analyst's role is to protect, improve, and leverage the value of Capital' data assets by: Promoting a culture which benefits from \u201cgood\u201d data quality resulting in greater accuracy, timeliness and quality of information for decision making. Supports established data quality standards and processes. Furthers Data Governance education throughout the organization. Strong interpersonal skills, time management, written and verbal communication skills are integral to success. Risk identification and mitigation along with issue resolution and advanced knowledge of process flows and change management are critical to success. Proactive, strong interpersonal effectiveness and accountability are key competencies to this position.  Responsibilities and Qualifications: \n  \n 55% - Support of policies, procedures and workflow within the Data Governance Program including Systems Standardization, Data Standards, Data Classification, and data quality efforts. \n  5% - Benefit Management including participation in definition of new projects within program, measuring and tracking of data governance program benefits \n  5% - Program Stakeholder Management including identification of program stakeholders, participation in Executive-level, Data Governance Board, and Data Owner meetings, and the preparation of communications between these groups and with stakeholders \n  5% - Working across organizational boundaries to successfully drive consensus and change. \n  15% - Coordination of Data Governance efforts with the Enterprise Data Stewards \n  5% - Supporting progress towards to key milestones, major deliverables, savings and cost targets \n  10% - Serve as a change agent for data management and data architecture across the enterprise. \n \n  Skills: \n \n  Self-motivator that guides and inspires Data Owners, Data Stewards, & other program stakeholders. \n  Facilitates collaboration among technical and non-technical teams. \n  Fairness, honesty and respect of all stakeholders; strong interpersonal effectiveness in working with various levels within the organization. \n  Strong collaboration and organizational skills with a focus on attention to detail and follow up. \n  Ability to handle multiple job duties in a fast paced environment. \n  Ability to quickly gain knowledge of new business processes and issues. \n  Ability to work independently with minimal supervision including the organization and prioritization of tasks to meet prescribed deadlines and department goals. \n  Ability to prepare and analyze complex data and ability to communicate Data Governance concepts such as Metadata Repositories, Data Dictionary, Business Glossary, and Data Stewardship to technical and non-technical staff. \n  Ability to effectively communicate with various levels within the organization, clearly expressing ideas and concepts both verbally and in writing. \n  Demonstrated strong written communication skills including experience in drafting policies and procedures. \n  Ability to facilitate and lead effective meetings including project status meetings, training and business requirement gathering sessions. \n \n  Knowledge: \n \n  Proficiency in Microsoft Office tools including Visio as well as basic understanding of SAS or SQL code and PowerBI. \n  Basic understanding of Master Data, collection of metadata elements, and its use or potential use within the company. \n  Basic understanding of metrics gathering, tracking and reporting within the company. \n  Project management methodology, requirements gathering and process improvement techniques are highly desired.  \n \n Experience: \n \n  A minimum of five years of healthcare experience including consulting, project management, and/or process reengineering. Additional experience working on cross-functional teams strongly desired. \n \n  Education and Certifications: \n \n  Bachelor\u2019s Degree Required in one of the following: business administration, healthcare informatics, or information systems. \n \n  Work Environment:  \n Remote \n \n  Physical Demands: \n  While performing the duties of the job, the employee is frequently required to sit, use hands to finger, handle and feel, and talk, hear, and see. The employee must occasionally lift and/or move up to 5 pounds. \n  Other: \n \n  Travel@@Amount (less than 1% of time) \n  Potential travel for continuing education requirements/courses. \n \n \n  About Us: We recognize that work is a part of life, not separate from it, and foster a flexible environment where your health and wellbeing are prioritized. At Capital you will work alongside a diverse and caring team of supportive colleagues, and be encouraged to volunteer in your community. We value your professional and personal growth by investing heavily in training and continuing education, so you have the tools to do your best as you develop your career. And by doing your best, you\u2019ll help us live our mission of improving the health and well-being of our members and the communities in which they live.", "cleaned_desc": "  Ability to work independently with minimal supervision including the organization and prioritization of tasks to meet prescribed deadlines and department goals. \n  Ability to prepare and analyze complex data and ability to communicate Data Governance concepts such as Metadata Repositories, Data Dictionary, Business Glossary, and Data Stewardship to technical and non-technical staff. \n  Ability to effectively communicate with various levels within the organization, clearly expressing ideas and concepts both verbally and in writing. \n  Demonstrated strong written communication skills including experience in drafting policies and procedures. \n  Ability to facilitate and lead effective meetings including project status meetings, training and business requirement gathering sessions. \n \n  Knowledge: \n \n  Proficiency in Microsoft Office tools including Visio as well as basic understanding of SAS or SQL code and PowerBI. \n  Basic understanding of Master Data, collection of metadata elements, and its use or potential use within the company. ", "techs": ["microsoft office", "visio", "sas", "sql", "powerbi"]}, "41d3639673a4d246": {"terms": ["data analyst"], "salary_min": 77235.0, "salary_max": 115852.0, "title": "HEALTH CARE DATA CONVERSION ANALYST", "company": "OCHIN", "desc": "Description: \n   MAKE A DIFFERENCE AT OCHIN \n  OCHIN is a rapidly growing national nonprofit health IT organization with two decades of experience transforming health care delivery to drive health equity. We are hiring for a number of new positions to meet increasing demand. When you choose to join OCHIN, you have the opportunity to continuously grow your skills and do meaningful work to help fulfill our mission. \n  OCHIN provides leading-edge technology, data analytics, research, and support services to nearly 1,000 community health care sites, reaching nearly 6 million patients nationally. We believe that every individual, no matter their race, ethnicity, background, or zip code, should have a fair opportunity to achieve their full health potential. Our work addresses differences in health that are systemic, avoidable, and unjust. We, partner, learn, innovate, and advocate, in order to close the gap in health for individuals and communities negatively impacted by racism or other structural inequities. \n  At OCHIN, we value the unique perspectives and experiences of every individual and work hard to maintain a culture of belonging. \n  Founded in Oregon in 2000, OCHIN employs a growing virtual workforce of more than 900 diverse professionals, working remotely across 46 states. We offer a generous compensation package and are committed to supporting our employees\u2019 entire well-being by fostering a healthy work-life balance and equitable opportunity for professional advancement. We are curious, collaborative learners who strive to live our values every day: leadership, collaboration, excellence, innovation, inclusion, and stewardship. OCHIN is excited to support our continued national expansion and the increasing demand for our innovative tools and services by welcoming new talent to our growing team. \n  Position Overview \n  The  Data Conversion Analyst  supports OCHIN\u2019s mission by helping our new members extract data from their previous EHR and ancillary healthcare IT systems, transform the data into new formats, and then import the data into OCHIN\u2019s Epic system. In addition to performing this technical work, the  Data Conversion Analyst  also uses their interpersonal, communication, and organizational skills to work with various internal and external stakeholders and to drive each project toward completion. You'll be part of a team that will travel to some of our clinic membership sites and supports the conversion of the data from their current EHR over to OCHIN's Epic system. \n  ***This is not a general or entry-level data entry position. We are seeking candidates with strong technical knowledge as listed below. \n  Essential Duties \n \n  Participate in shaping and growing OCHIN\u2019s nascent Data Conversion product line \n  Analyzing healthcare data in HL7, CDA, CSV, and SQL formats for extraction, transformation, and import. \n  Facilitate meetings with multiple internal and external stakeholders to gather requirements, identify data conversion needs, provide ongoing updates, and ensure high customer satisfaction. \n  Participate in informal internal training as part of ongoing team improvement. \n  Develop and update technical and business process documentation for data conversions (internal and customer-facing) \n  Performing data conversions including extracting healthcare data from non-Epic EHR systems, performing transformations upon the data, and importing it into OCHIN Epic. \n  Approach the work as a Technical Analyst on data conversion projects and be able to multi-task in a fast-paced environment. \n  Provide quality assurance on data conversion work. \n  Coming up with brilliant solutions to analytical challenges. \n  The ability to travel to Clinic locations across the U.S. on an as-needed basis to meet with clients understand their Data Conversion needs and upport the conversion work. \n  Participate in internal process improvement projects. \n  Assist with additional Interface projects as assigned. \n  Performed other duties as assigned \n  Requirements: \n  \n Bachelor\u2019s degree in Health Informatics, Computer Science, or a similar field required. Equivalent knowledge and skills obtained through a combination of education, training, and experience may meet this requirement. \n  Minimum of 2- years of experience working with healthcare data preferably in Epic \n  Minimum of 2- years of experience working with EHRs/EMRs. \n  Minimum one year Working knowledge of the HL7 standard is required. \n  Minimum of one years Experience with Mirth or another interface engine is required. \n  Strong technical proficiency with JavaScript, SQL, and Epic products \n  Certified in Epic Bridges preferred or ability to obtain in the first 6- months of hire \n \n  Additional Qualifications: \n \n  Knowledge of data transformations from any industry. \n  Experience with Epic conversions and DBA skills are a plus \n  Troubleshooting and documenting skills. \n  Able to learn in a self-directed, fast-paced, rapidly changing environment. \n \n  COVID-19 Vaccination Requirement \n  To keep our colleagues, members, and communities safe, OCHIN requires all employees\u2014including remote employees, contractors, interns, and new hires\u2014to be vaccinated with a COVID-19 vaccine, as supported by state and federal public health officials, as a condition of employment. All new hires are required to provide proof of full vaccination or receive approval for a medical or religious exemption before their hire date. \n  Work Location and Travel Requirements \n \n  OCHIN is 100% remote organization with no physical corporate office location. Employees work remotely from home and many of our positions also support our member organizations on-site for new software installations. Nationwide travel is determined based on OCHIN business needs. Please inquire during the interview process about travel requirements for the position. \n \n  This position is 100% remote. Work from home requirements are: \n    \n Ability to work independently and efficiently from a home office environment \n High-Speed Internet Service \n It is a requirement that employees work in a distraction-free workplace \n \n \n We offer a comprehensive range of benefits. See our website for details: https://ochin.org/employment-openings \n  Equal Opportunity Statement \n  OCHIN is proud to be an equal-opportunity employer. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills for the benefit of our staff, our mission, and the communities we serve. \n  As an Equal Opportunity and Affirmative Action employer, OCHIN, Inc. does not discriminate on the basis of race, ethnicity, sex, gender identity, sexual orientation, religion, marital or civil union status, age, disability status, veteran status, or any other protected characteristics. All aspects of employment are based on merit, performance, and business needs. \n  Base Pay Overview \n  The typical offer range for this role is minimum to midpoint, with the midpoint representing the average pay in a national market scope for this position. Please keep in mind that this range represents the pay range for all positions in the job grade within which this position falls. The actual salary offer will consider a wide range of factors directly relevant to this position, including, but not limited to, skills, knowledge, training, responsibility, and experience, as well as internal equity and alignment with market data. \n  #LI-Remote", "cleaned_desc": "  Analyzing healthcare data in HL7, CDA, CSV, and SQL formats for extraction, transformation, and import. \n  Facilitate meetings with multiple internal and external stakeholders to gather requirements, identify data conversion needs, provide ongoing updates, and ensure high customer satisfaction. \n  Participate in informal internal training as part of ongoing team improvement. \n  Develop and update technical and business process documentation for data conversions (internal and customer-facing) \n  Performing data conversions including extracting healthcare data from non-Epic EHR systems, performing transformations upon the data, and importing it into OCHIN Epic. \n  Approach the work as a Technical Analyst on data conversion projects and be able to multi-task in a fast-paced environment. \n  Provide quality assurance on data conversion work. \n  Coming up with brilliant solutions to analytical challenges. \n  The ability to travel to Clinic locations across the U.S. on an as-needed basis to meet with clients understand their Data Conversion needs and upport the conversion work. \n  Participate in internal process improvement projects. \n  Assist with additional Interface projects as assigned. \n  Performed other duties as assigned ", "techs": ["hl7", "cda", "csv", "sql", "epic ehr systems", "ochin epic", "technical analyst"]}, "bd203b586ac89e05": {"terms": ["data analyst"], "salary_min": 89261.48, "salary_max": 113024.914, "title": "Business Analyst", "company": "Leonardo247", "desc": "We are looking to add a  Business Analyst  to assist the Product Team in coordinating projects through all phases of the requirement development lifecycle. This BA will assist various Product Owners to manage the full life cycle of technical projects and programs to deliver high quality products and services for our customers with predictability. We are looking for people who thrive in a fast-paced environment and can take something from idea to execution with ease. \n On Any Given Day, A Business Analyst Will\u2026 \n \n Lead the business analysis, estimation, and planning of a broad set of business requirements using a structured requirements process (gathering, analyzing, documenting, estimating, validating) and recommending options, risks, and cost vs. benefits. \n Be able to interpret gaps in requirements and business needs, identify possible solutions to those gaps, and suggest those improvements to processes to make them more effective and easier to implement. \n Critically evaluate information gathered from multiple sources, reconcile conflicts, decompose high-level information into details and able to prioritize requirements based on business needs. \n Problem Solving to identify, develop, and initiate innovations and solutions where precedents and procedures may not exist. \n Work cross-functionally to offer alternate solutions and resolve more complex business analysis challenges. \n Serve as a liaison and works collaboratively between business operations and technical teams \n Create/revise/execute: Process maps, Data flow diagrams, Requirement specifications, Use case scenarios, Acceptance testing. \n \n We Will Want You to Join Our Team If You Have\u2026 \n \n 5+ years of business analysis experience. \n Strong understanding of how business requirements are gathered, analyzed, documented, and translated into technical specifications. \n Excellent technical writing skills and ability to document software requirements in a crisp way while relating them to database table and field level information and business system processing rules and logic. \n Outstanding presentation and interpersonal skills with the ability to negotiate business/technical requirements and project schedules with a customer and other project team members. \n Exceptional analytical skills with the ability to learn from customers, analyze past projects and advise top management on how the sales strategy can be improved and how reusable technical solutions can be developed. \n Results-oriented with strong people and time management skills, highly organized, motivated, and driven to succeed. \n \n You Will Want to Join Our Team If You \u2026 \n \n Want to be a part of something that is solving real problems and changing the way an entire industry does business \n Like a competitive base salary in a company with ever expanding opportunities \n Are comfortable working remotely \n Are committed to working additional hours from time to time to ensure deadlines are met \n Have a positive, \u201cget the job done\u201d attitude and think of yourself as someone who is always working smart \n Always want to be the best and strive become an expert at whatever you do", "cleaned_desc": " Excellent technical writing skills and ability to document software requirements in a crisp way while relating them to database table and field level information and business system processing rules and logic. \n Outstanding presentation and interpersonal skills with the ability to negotiate business/technical requirements and project schedules with a customer and other project team members. \n Exceptional analytical skills with the ability to learn from customers, analyze past projects and advise top management on how the sales strategy can be improved and how reusable technical solutions can be developed. \n Results-oriented with strong people and time management skills, highly organized, motivated, and driven to succeed. \n ", "techs": ["none"]}, "240f88ce255498dc": {"terms": ["data analyst"], "salary_min": 70185.56, "salary_max": 88870.56, "title": "IT Operations Data Analyst Lead", "company": "CDMS", "desc": "WE WELCOME YOU INTO A GROWING COMPANY \n Consumer Direct Care Network is all about caring for people. Care is at our core, and we strive to live up to it every single day. We are currently providing services in 14 states across the USA. We specialize in providing home and community-based services that support individuals with disabilities and older adults so they can remain in their homes and communities. \n \n  Culture Vision at Consumer Direct Care Network \n At CDCN, we strive to create a\u202fworkplace where everyone is\u202fsupported and motivated to be\u202ftheir best; we collaborate on\u202fshared goals and celebrate our\u202faccomplishments. \n \n  JOB SUMMARY \n The IT Operations Data Analyst Lead is \n responsible for directing a team of IT Operations Data Analysts that provide \n data analytics, data management, data monitoring, data reporting, and problem \n resolution support for data operations and data exchanges across CDCN \n transaction management platforms. The IT Operations Data Analyst Lead is highly \n knowledgeable of the CDCN transaction lifecycle management framework. \n \n  JOB DUTIES \n \n  Lead and manage a team of data analysts \n providing transaction processing data management and data integration \n services for CDCN \n Prioritize team activities based on input \n and direction from the Manager-Data Management \n Lead daily stand-ups with Team to \n coordinate daily activities \n Train and mentor team on best practices \n and processes related to system monitoring and health \n Responsible for tasking resources based \n on incoming operational requests \n Analyze and become proficient in \n interacting with our data flows and system objects \n Participate in monitoring processes for \n data exchanges \n Design, develop and test exception \n reporting for data exchanges \n Design and develop reporting mechanisms \n to capture key operational statistics for data exchanges \n Design and develop data flow reporting \n mechanisms for operational activities \n Prepare monthly reports on data exchange \n and interface activities \n Prepare monthly reports on data \n characteristics as a result of production operations activities \n Prioritize and multitask effectively \n Present findings and analysis results to \n stakeholders through written summaries and oral presentations \n Problem solve data integration/processing \n results \n Other duties as assigned \n Previous experience managing teams \n \n  QUALIFICATIONS \n \n  Bachelor\u2019s Degree preferred \n Combination of education and experience \n 4 - 5 years\u2019 previous experience in \n analytics preferred \n Expertise using Analytics tools (Azure, \n Microsoft Power BI, Microsoft SQL Server, Microsoft Visual Studios, and \n .NET) \n Ability to work flexible and/or extended \n hours, if needed, to meet the job requirements \n If remote, the employee must have \n sufficient internet access and speed to perform the functions of the job \n \n  The incumbent typically works in an office \n environment and uses a computer, telephone and other office equipment as needed \n to perform duties. The noise level in the work environment is typical of that \n of an office. Incumbent may encounter frequent interruptions throughout the \n workday. The employee is regularly required to sit, talk, or hear; frequently \n required to use repetitive hand motion, handle or feel, and to stand, walk, \n reach, bend or lift up to 20 pounds. Reasonable accommodations may be made to \n enable individuals with disabilities to perform the essential functions. \n \n  WHAT'S IN IT FOR YOU \n When you join Consumer Direct Care Network, you will be exposed to numerous professional development opportunities. We welcome your contributions and value your integrity as we collaborate on work that moves us all toward a compassionate community. We have a long history of helping individuals build their careers in the home-care industry. This is truly a place where there is something for everyone, whether you are looking to support a particular lifestyle, seeking professional growth, or seeking new and challenging work, all in an expanding nationwide company with that small-company feel. Most importantly, you will experience the satisfaction of working in a culture built on caring. Caring for others comes naturally at Consumer Direct Care Network, based on our long history of connecting people and championing change, all geared toward helping others. We are proud of the longevity and loyalty of our employees. Their commitment to doing good work is what makes us a leader in the industry. \n As a Consumer Direct Care Network team member you will receive: \n \n \n A rewarding career helping others \u2022 Fun and engaging work environment built on team unity \u2022 Job satisfaction knowing you make a difference in the work you do and lives we serve \u2022 Professional training to help advance your skills for career development \n  Based on your position and employment status, you may be eligible for: \n \n \n Medical, Dental, and Vision Insurance \n Accrued Vacation with no waiting period \n Two Paid Floating Holidays \n Nine Paid Federal Holidays \n Paid Safe Sick Time with no waiting period \n 401(k) Retirement plan \n Company-Paid Life Insurance \n Supplemental Life, Accident, Critical Illness, and Hospital benefits \n Short and Long-Term Disability \n Paid Parental Leave \n Flexible Spending Account \n Employee Assistance Program \n Pet Insurance \n  WHO WE ARE \n Consumer Direct Care Network specializes in home and community-based services that assist older adults and individuals of all ages with disabilities and impairments to continue to live their lives independently in their own homes and communities. We provide coordinated service delivery in 14 states and the District of Columbia. Our services span from financial management services and support brokerage to traditional agency in-home care and caregiving to behavioral health. We have extensive experience with Medicaid, Medicare, private insurance, and with supporting people who pay for their own care. \n Your opportunities within our network are endless, it\u2019s not just a job, it\u2019s a career\u2026 advance it with the Consumer Direct Care Network! \n The Consumer Direct Care Network and its subsidiaries are an Equal Opportunity Employer and drug-free workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. \n In accordance with the Immigration and Reform Control Act (IRCA), you may only work at Consumer Direct Care Network if you are legally authorized to work in the United States. Consumer Direct Care Network does not provide visa sponsorship or STEM OPT extensions to employees.", "cleaned_desc": " and interface activities \n Prepare monthly reports on data \n characteristics as a result of production operations activities \n Prioritize and multitask effectively \n Present findings and analysis results to \n stakeholders through written summaries and oral presentations \n Problem solve data integration/processing \n results \n Other duties as assigned \n Previous experience managing teams \n \n  QUALIFICATIONS \n \n  Bachelor\u2019s Degree preferred \n Combination of education and experience \n 4 - 5 years\u2019 previous experience in \n analytics preferred \n Expertise using Analytics tools (Azure, \n Microsoft Power BI, Microsoft SQL Server, Microsoft Visual Studios, and ", "techs": ["azure", "microsoft power bi", "microsoft sql server", "microsoft visual studios"]}, "9bcb043891c8c5cd": {"terms": ["data analyst"], "salary_min": 78180.44, "salary_max": 98993.86, "title": "Security Data Analyst", "company": "Jack Henry and Associates, Inc.", "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you. \n \n  The Security Data Analyst plays a critical role in ensuring the security and compliance of financial services software provided by our organization. This position involves analyzing and interpreting data related to security incidents, threats, vulnerabilities, and compliance requirements to safeguard our systems and maintain regulatory compliance. The Security Data Analyst will collaborate with various teams to develop and implement data-driven security strategies and ensure our software and customer data's confidentiality, integrity, and availability. \n \n  What you\u2019ll be responsible for: \n \n Data Analysis:  Collect, analyze, and interpret security-related data from various sources, including logs, network traffic, and security tools, to identify security incidents, threats, and vulnerabilities. \n Incident Response:  Assist in incident response activities by providing data-driven insights to identify the root cause of security incidents, assess their impact, and recommend appropriate remediation measures. \n Threat Intelligence:  Monitor and analyze threat intelligence feeds to stay current on emerging threats and vulnerabilities and incorporate this information into security strategies and policies. \n Compliance Analysis:  Ensure compliance with relevant regulations and standards (e.g., PCI DSS, etc.\u2026) by assessing data, processes, and systems against compliance requirements and assisting in the preparation for audits and assessments. \n Security Reporting:  Create and maintain security reports and dashboards, providing key metrics and insights to senior management, compliance teams, and other stakeholders. \n Data Protection:  Collaborate with the data protection team to ensure the security of sensitive customer data, including encryption, access controls, and data classification. \n Security Policies:  Contribute to developing and enforcing security policies, procedures, and guidelines based on data-driven insights and compliance requirements. \n Security Awareness:  Assist in developing security awareness programs and training materials to educate employees about security best practices and compliance obligations. \n Collaboration:  Work closely with cross-functional teams, including IT, legal, compliance, and development, to align security and compliance efforts with business objectives. \n Continuous Improvement:  Stay current with evolving cybersecurity threats and trends and continuously improve security analytics processes and tools to enhance the organization's security posture. \n May perform other job duties as assigned. \n \n \n  What you\u2019ll need to have: \n \n Bachelor's degree. Relevant certifications (e.g., CISSP, CISA, CompTIA Security+) are a plus. \n Minimum of 4 years experience in data analysis and data-driven decision-making within information security and compliance. \n Familiarity with regulatory requirements and industry standards, especially those relevant to the financial services sector. \n \n \n  What would be nice for you to have: \n \n Familiarity with regulatory requirements and industry standards, especially those relevant to the financial services sector. \n Strong analytical skills and proficiency in data analysis tools and technologies. \n Knowledge of security information and event management (SIEM) systems and security data analytics tools. \n Excellent communication skills to convey complex security concepts and findings to both technical and non-technical stakeholders. \n Ability to work collaboratively in a team environment and adapt to a dynamic and evolving security landscape. \n \n \n  If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways. \n \n  Why Jack Henry? \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being. \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met. \n \n  Culture of Commitment \n \n  Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders. \n \n  Equal Employment Opportunity \n \n  At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law. \n \n  No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations. \n \n  Requests for full corporate job description may be requested through the interview process at any time.", "cleaned_desc": "", "techs": ""}, "e2cc8fb13c233e13": {"terms": ["data analyst"], "salary_min": 0.0, "salary_max": 50.0, "title": "Business Analyst III", "company": "RPO International", "desc": "Looking for a Business Analyst III who will work on a team specializing in fleet maintenance that is building a low complexity one-stop-shop onsite service station at a delivery station covering preventative maintenance, tires, brakes, and bolt-on collision like mirrors, cameras and side steps. This project will help improve our client's infrastructure. The Business Analyst will calculate metrics and automate processes within a fleet service center team. \n Job Responsibilities: \n \n 50% - managing ongoing dashboards and data correlation efforts. \n 50% - fulfilling ad hoc requests, mostly SQL queries. \n Reviews, analyzes, and evaluates business systems and user needs. \n Formulates systems to parallel overall business strategies. \n Writes detailed description of user needs, program functions, and steps required to develop or modify computer programs. \n Relies on extensive experience and judgment to plan and accomplish goals. \n Performs a variety of tasks. \n Leads and directs the work of others. \n A wide degree of creativity and latitude is expected. \n Typically reports to a manager or head of a unit/department. \n \n Basic Requirements: \n \n 3-5 years of experience in the field or in a related area. \n 2+ years of SQL writing SQL queries etc. \n 1+ year of automotive and/or maintenance & repairs experience. \n Quicksight \n Independent thinking \n Excellent written and verbal communication skills \n Only candidates available and ready to work directly as NJAI/Genesis10 employees will be considered for this position. \n \n Compensation : $50.00 per hour \n If you have the described qualifications and are interested in this exciting opportunity, apply today! \n Job Types: Contract, Full-time \n Pay: Up to $50.00 per hour \n Expected hours: No more than 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Business Analysis or related: 5 years (Preferred) \n SQL: 5 years (Preferred) \n automotive and/or maintenance & repairs: 1 year (Preferred) \n Quicksight: 2 years (Preferred) \n \n License/Certification: \n \n US Citizen or Green Card Holder (Preferred) \n \n Work Location: Remote", "cleaned_desc": " A wide degree of creativity and latitude is expected. \n Typically reports to a manager or head of a unit/department. \n \n Basic Requirements: \n \n 3-5 years of experience in the field or in a related area. \n 2+ years of SQL writing SQL queries etc. \n 1+ year of automotive and/or maintenance & repairs experience. \n Quicksight \n Independent thinking \n Excellent written and verbal communication skills ", "techs": ["sql", "quicksight"]}, "415432378dde01ef": {"terms": ["data analyst"], "salary_min": 56467.0, "salary_max": 95993.0, "title": "Data and Reporting Analyst - Remote", "company": "ICF", "desc": "Are you interested and have a passion for Data Analytics and Reporting Solutions? ICF's Disaster Management division is seeking a Data and Reporting Analyst to join us immediately!\n  \n \n \n   In this role, you will work with various internal and external clients and will have the opportunity to help support the mission, business, service, and operational needs of our customers. ICF\u2019s Disaster Management division works with government agencies and communities to design and implement policies and programs to promote increased resilience to disasters. Our functional expertise includes program management and operations, planning and preparedness, technical assistance and training, strategic communications and outreach, compliance and monitoring, and performance measurement and evaluation. Clients include states and localities administering the United States Department of Housing and Urban Development (HUD) and the Federal Emergency Management Agency (FEMA) funded disaster recovery programs.\n  \n \n \n   This is a remote-based position.\n  \n \n \n   Responsibilities:\n  \n \n \n \n     Support requirements gathering on business processes, existing systems/reports, and problem areas\n    \n \n \n     Provide support to developers by gathering and or clarifying data and reporting requirements from business owners\n    \n \n \n     Support the identification of data source systems and perform extensive system analysis and data profiling on these systems\n    \n \n \n     Support the design of end-to-end data visualizations/Reporting solutions, from data extraction to presentation, to address a client\u2019s needs\n    \n \n \n     Perform data validation/quality assurance on the reporting solution to ensure that it meets the technical requirements\n    \n \n \n     Ability to provide technical assistance and troubleshooting by effectively responding to inquiries\n    \n \n \n     Track scope and changes throughout the implementation of reports and application changes, keeping stakeholders notified of anticipated completion dates\n    \n \n \n     Support project delivery on disaster recovery/data analytics projects for external and internal clients, including partnering with ICF subject matter experts on project execution\n    \n \n \n     Create and analyze business reports to provide performance insights, forecast staffing needs, and determine trends\n    \n \n \n     Generate regular and ad hoc reports for both internal and external use\n    \n \n \n     Generate dashboard mockups, charts, use cases, wireframes, process flow diagrams, and other system documentation\n    \n \n \n     Prepare agendas, biweekly status reports, and follow-up actions for meetings with external clients and client vendors\n    \n \n \n \n   Minimum Qualifications:\n  \n \n \n \n     Bachelor\u2019s Degree\n    \n \n \n     1+ years of experience as a business analyst, data analyst, reporting analyst, or similar role\n    \n \n \n     2+ years of experience in MS Excel, including advanced formulas, conditional formatting, advanced charting, and tables and formatting for \u201cclient-ready\u201d deliverables\n    \n \n \n     1+ years of experience in MS PowerPoint, MS Power BI or other BI reporting tools (Tableau), and MS Word\n    \n \n \n \n   Preferred Skills:\n  \n \n \n \n     1+ years of experience in MS Visio\n    \n \n \n     Analytical skills that allow for the development of data-driven reports\n    \n \n \n     Experience with Quickbase, Salesforce, MS Power Apps, or similar low-code platforms\n    \n \n \n     Experience with business process mapping and the use of project management software\n    \n \n \n     Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand\n    \n \n \n \n   Professional Skills:\n  \n \n \n \n     Demonstrated ability to manage time and prioritize projects to meet deadlines\n    \n \n \n     Excellent listening, written, and oral communication skills\n    \n \n \n     Excellent critical thinking skills to help solve business problems and make decisions, paired with a desire to take initiative\n    \n \n \n     Ability to maintain project plans, resourcing schedules, and forecasting activities\n    \n \n \n     Ability to work well under continually changing deadlines and priorities\n    \n \n \n \n   Working at ICF\n  \n  ICF is a global advisory and technology services provider, but we\u2019re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.\n  \n \n   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our \n   \n   EEO & AA policy\n   .\n  \n \n \n   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email \n   \n   icfcareercenter@icf.com\n    and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: \n   \n   Know Your Rights\n    and \n   \n   Pay Transparency Statement.\n   \n \n \n \n  Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:\n   $56,467.00 - $95,993.00\n   Nationwide Remote Office (US99)", "cleaned_desc": "   Minimum Qualifications:\n  \n \n \n \n     Bachelor\u2019s Degree\n    \n \n \n     1+ years of experience as a business analyst, data analyst, reporting analyst, or similar role\n    \n \n \n     2+ years of experience in MS Excel, including advanced formulas, conditional formatting, advanced charting, and tables and formatting for \u201cclient-ready\u201d deliverables\n    \n \n \n     1+ years of experience in MS PowerPoint, MS Power BI or other BI reporting tools (Tableau), and MS Word\n    \n \n \n \n   Preferred Skills:\n  \n \n \n \n     1+ years of experience in MS Visio\n    \n \n \n     Analytical skills that allow for the development of data-driven reports\n      \n \n     Experience with Quickbase, Salesforce, MS Power Apps, or similar low-code platforms\n    \n \n \n     Experience with business process mapping and the use of project management software\n    \n \n \n     Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand\n    \n \n \n \n   Professional Skills:\n  \n \n \n \n     Demonstrated ability to manage time and prioritize projects to meet deadlines\n    \n \n \n     Excellent listening, written, and oral communication skills\n    \n \n \n     Excellent critical thinking skills to help solve business problems and make decisions, paired with a desire to take initiative\n    \n \n \n     Ability to maintain project plans, resourcing schedules, and forecasting activities", "techs": ["ms excel", "ms powerpoint", "ms power bi", "ms word", "ms visio", "quickbase", "salesforce", "ms power apps"]}, "b0ba65e32af91812": {"terms": ["data analyst"], "salary_min": 29.82, "salary_max": 42.95, "title": "Salesforce Business Analyst", "company": "Hanker Systems", "desc": "Description \n Salesforce experience General knowledge of Microsoft Office suite Will primarily be using the SaaS Management system, PODIS Plus Training experience Position training will take up to 4 weeks. \n Responsible for business analysis activities in accordance with Cencora systems development methodology and supporting projects within a specific portfolio area (sales and marketing, supply chain, finance, etc.). This individual may work independently or with other Portfolio associates to deliver small scale projects or deliverables for larger projects. Responsible for collecting, documenting, and confirming business requirements and functional specifications. Works in close collaboration with business partners and developers to ensure consistent understanding of business processes and requirements. Defines, develops, and delivers test plans and associated test case scenarios. Establishes effective relationships with other Cencroa and IBM IT departments; builds and maintains effective business partner relationships. Assists with tasks and deliverables related to System Development Life Cycle phases for package and custom solutions Attends and participates in user and project meetings and teams to expand knowledge, as a participant and not in a lead capacity; facilitates project status meetings; tracks project status. Investigates and documents project issues and detailed requirements Frequently interacts with IT staff including business area management, portfolio managers, vendors, consultants and other contractors. Excellent discovery and active listening skills Good interpersonal skills Good relationship building skills Ability to communicate effectively both orally and in writing. Good group presentation skills. Good analytical and problem solving skills Good mathematical skills. Good organizational skills Good leadership skills. Good staff development skills. Knowledge of computers to operative effectively with computer hardware such as general mainframe, midrange, network and desktop technologies; computer software includes application development lifecycle, MS Office Suite and Outlook. \n Job Type: Contract \n Salary: $29.82 - $42.95 per hour \n Experience: \n \n Salesforce: 1 year (Preferred) \n Business analysis: 1 year (Preferred) \n Microsoft Office suite: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Responsible for business analysis activities in accordance with Cencora systems development methodology and supporting projects within a specific portfolio area (sales and marketing, supply chain, finance, etc.). This individual may work independently or with other Portfolio associates to deliver small scale projects or deliverables for larger projects. Responsible for collecting, documenting, and confirming business requirements and functional specifications. Works in close collaboration with business partners and developers to ensure consistent understanding of business processes and requirements. Defines, develops, and delivers test plans and associated test case scenarios. Establishes effective relationships with other Cencroa and IBM IT departments; builds and maintains effective business partner relationships. Assists with tasks and deliverables related to System Development Life Cycle phases for package and custom solutions Attends and participates in user and project meetings and teams to expand knowledge, as a participant and not in a lead capacity; facilitates project status meetings; tracks project status. Investigates and documents project issues and detailed requirements Frequently interacts with IT staff including business area management, portfolio managers, vendors, consultants and other contractors. Excellent discovery and active listening skills Good interpersonal skills Good relationship building skills Ability to communicate effectively both orally and in writing. Good group presentation skills. Good analytical and problem solving skills Good mathematical skills. Good organizational skills Good leadership skills. Good staff development skills. Knowledge of computers to operative effectively with computer hardware such as general mainframe, midrange, network and desktop technologies; computer software includes application development lifecycle, MS Office Suite and Outlook. \n Job Type: Contract ", "techs": ["cencora systems development methodology", "sales and marketing", "supply chain", "finance", "business analysis", "business requirements", "functional specifications", "test plans", "test case scenarios", "system development life cycle", "package solutions", "custom solutions", "user meetings", "project meetings", "project status", "project issues", "detailed requirements", "it staff", "discovery skills", "active listening skills", "interpersonal skills", "relationship building skills", "communication skills", "group presentation skills", "analytical skills", "problem-solving skills", "mathematical skills", "organizational skills", "leadership skills", "staff development skills", "computer hardware", "mainframe", "midrange", "network technologies", "desktop technologies", "application development lifecycle", "ms office suite", "outlook"]}, "52859d1da9686de2": {"terms": ["data analyst"], "salary_min": 99290.0, "salary_max": 129077.5, "title": "Expert TouchWorks Business Analyst", "company": "Altera Digital Health Inc. United States", "desc": "Altera, a new member of the N. Harris Computer Corporation family, delivers health IT solutions that support caregivers around the world. These include the Sunrise\u2122, Paragon\u00ae, Altera TouchWorks\u00ae, Altera Opal, STAR\u2122, HealthQuest\u2122 and dbMotion\u2122 solutions. At the intersection of technology and the human experience, Altera Digital Health is driving a new era of healthcare, in which innovation and expertise can elevate care delivery and inspire healthier communities across the globe. A new age in healthcare technology has just begun. \n \n  Job Summary    The TouchWorks Business Analyst Specialist is responsible for eliciting and documenting business and functional requirements essential for developing technology solutions that align with customer needs, delivery schedules, and quality benchmarks. This role involves providing support to clients through various communication channels such as telephone and internet, resolving technical issues using advanced problem-solving skills, particularly within the TouchWorks environment.     Essential Functions  \n \n Possesses functional knowledge of assigned application technology including version releases, industry standards and legal & regulatory requirements \n Works under the direction of the Manager to provide application solutions for assigned business areas \n Interacts with the business stakeholders and subject matter experts, internal and external as appropriate, in order to understand their problems and needs \n Follows all Standard Operating Procedures SOP's (i.e. Patient Safety and Compliance) \n Diagnoses and resolves client questions or problems over the telephone/Internet in the areas of system configuration/setup, product functionality and bugs/enhancements \n Interacts with business stakeholders, internal and external as appropriate, to understand new business requirements and enhancement requests \n Communicates effectively with all parties related to assigned process area \n Achieves established goals \n Translates business requirements into product-specific designs and configuration, detailed requirement specifications and use cases, provides accurate and timely information and appropriate notification as required \n Delivers functional specifications, design documents, business process workflow and related documentation for new development projects and/or enhancement and modification requests \n Participates in the software build and/or configuration process and testing process \n Designs and executes functional, integration, and regression test plans for new application functionality, product releases and enhancement and regulatory modifications using business scenarios and user cases, as appropriate \n Ensures programs meet business specifications \n Reviews vendor provided documentation and user manuals needed to support the product, as appropriate \n Escalates any disconnects between client expectations, the contract and Allscripts' interests \n Participates in user focus groups and requirements workshops, vendor training and demonstrations \n Improve solutions by studying current practices; designing modifications; writing specifications, as appropriate \n Conduct and coordinate financial, product, market, operational and related research to support strategic and business planning within the department, as appropriate \n Knowledge transfer and documentations of issue resolution with other team members to improve overall team education level and productivity \n Take complete ownership for the assigned tasks, including escalations, and proactively inform the progress of the project / task to all stakeholders \n Works directly with business stakeholders on highly complex or multifaceted problems, leading the effort through on-going engagement, in some instances, at the client site \n Acts as a lead resource, handling issues that are subject to high-profile escalations for that entire product \n Handles all specific product related functional and technology related issues including work required for system/data recovery, involving other necessary resources at Allscripts \n Identifies opportunities for cost saving through increased efficiency and the development of tools \n Identifies potential revenue generating opportunities and work with their management team to realize these opportunities \n Acts as a single point of contact for client specific engagements in absence of his/her manager \n Participates in new hire process. Interviews potential new hires and participates in selection process \n Work independently to gather and translate business requirements into product-specific designs and configuration, detailed requirement specifications and use cases \n Mentors and encourages individual team members development and improvement through example \n \n Job Requirements \n \n Bachelor's Degree (Preferred) \n 7+ years relevant work experience; 2-3 years at the Senior level or equivalent experience (Preferred) \n Typically 5-10+ years healthcare industry experience (Preferred) \n Must have Business Analyst experience \n Background with FHIR and/or C-CDA a PLUS \n Up to 20% travel may be required \n \n \n \n \n  Altera complies with all local/state regulations in regards to displaying salary ranges. If required, the salary range(s) are displayed below and are specifically for those potential hires who will perform work in or reside in the location(s) listed, if selected for the role. Any offered salary is determined based on internal equity, internal salary ranges, market data, ranges, applicant's skills and prior relevant experience, certain degrees and certifications (e.g. JD, technology), for example. \n \n  Salary Range \n \n    $99,290\u2014$129,077.50 USD\n   \n \n \n   Altera is an Equal Opportunity/Affirmative Action Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state or local law. \n  If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at: \n  HR.Recruiting@AlteraHealth.com \n \n \n  https://www.alterahealth.com/legal/privacy-policy/", "cleaned_desc": "", "techs": ""}, "f4d8b419ad6a0ca7": {"terms": ["data analyst"], "salary_min": 56000.0, "salary_max": 73000.0, "title": "Int Enhanced Underwriting Analyst", "company": "Transamerica", "desc": "Job Family\n   Underwriting\n  \n \n \n    Who We Are\n   \n \n \n \n \n  Transamerica has been helping people feel better about the future for more than 100 years. We provide investment, retirement, and life insurance solutions to more than 11 million customers throughout the U.S. But the way we see it, our responsibility goes beyond our clients\u2019 accounts. We\u2019re in the business of helping people live well and empowering them to create a better tomorrow through the financial and health-related habits they form today. We help people prepare by providing solutions that consider the whole picture.\n   \n \n \n    What We Do\n   \n \n \n    Transamerica is organized by lines of business (Life Insurance, Annuities, Mutual Funds, Retirement Plans, Employee Benefits, and Financial Assets), which are supported by Transamerica Corporate (Corporate Development; Finance; Internal Audit; Legislative, Regulatory & Policy; Office of the CEO; People, Places & Brand; Risk; and Technology).\n   \n \n \n \n   Job Description Summary\n   Responsible for the development, operation and refinement of an enhanced underwriting decision engine.\n  \n   Job Description\n  \n \n   Responsibilities\n  \n \n  Prepare cases for test beds and conduct tests to determine if the decision engine and/or underwriting system is functioning correctly. \n  Analyze data to ensure accuracy and alignment with the traditional underwriting experience; identify gaps for resolution. \n  Collaborate with the enhanced underwriting project team and related stakeholders in New Business, Project Management, Data Analytics, Medical, Actuarial, Sales & Marketing, vendors, etc. \n  Keep abreast of relevant events in the insurance sector. \n \n \n \n   Qualifications\n  \n \n  Bachelor\u2019s degree in a business field or equivalent experience \n  Two years of life or health underwriting experience \n  One year of underwriting experience within Transamerica or one year of experience working on an enhanced underwriting project \n  Basic understanding of enhanced underwriting user interface \n  Knowledge of industry products \n  Communication and interpersonal skills to interact with multiple business groups, including New Business, Project Management, Data Analytics, Medical, Actuaries, Sales & Marketing, etc. \n  Decision-making and problem-solving skills \n  Ability to work in a team environment to deliver a high functioning decision engine \n  Time-management skills to work on multiple priorities simultaneously \n  Willingness to continue education to stay current in the insurance sector \n  Proficiency in MS Office \n \n \n \n   Preferred Qualifications\n  \n \n  Completion of FALU courses or LOMA courses \n  FLMI designation or related coursework \n  Basic understanding of predictive modeling and data mining \n \n \n \n   Working Conditions\n  \n \n  Remote from home \n \n \n   Compensation\n  \n \n  **Please note that the compensation information that follows is a good faith estimate for this position only and is provided pursuant to applicable pay transparency and compensation posting laws. It is estimated based on what a successful candidate might be paid in certain Company locations.** \n \n \n \n  The Salary for this position generally ranges between $56-73K. This range is an estimate, based on potential qualifications and operational needs. Salary may vary above and below the stated amounts, as permitted by applicable law.\n  \n \n \n  Additionally, this position is typically eligible for an Annual Bonus of 7.5% based on the Company Bonus Plan/Individual Performance and is at Company discretion.\n  \n \n \n   What We Offer\n  \n \n \n \n  For eligible employees, we offer a comprehensive benefits package designed to support both the personal and financial well-being of our employees.\n   \n \n \n \n \n  Compensation Benefits\n   \n \n \n \n \n \n \n       Competitive Pay\n      \n \n \n       Bonus for Eligible Employees\n      \n \n \n \n \n \n  Benefits Package\n    \n \n \n \n \n \n       Pension Plan\n      \n \n \n       401k Match\n      \n \n \n       Employee Stock Purchase Plan\n      \n \n \n       Tuition Reimbursement\n      \n \n \n       Disability Insurance\n      \n \n \n       Medical Insurance\n      \n \n \n       Dental Insurance\n      \n \n \n       Vision Insurance\n      \n \n \n       Employee Discounts\n      \n \n \n       Career Training & Development Opportunities\n      \n \n \n \n \n \n \n \n  Health and Work/Life Balance Benefits\n    \n \n \n \n \n \n       Paid Time Off starting at 160 hours annually for employees in their first year of service.\n      \n \n \n       Ten (10) paid holidays per year (typically mirroring the New York Stock Exchange (NYSE) holidays).\n      \n \n \n       Be Well Company holistic wellness program, which includes Wellness Coaching and Reward Dollars\n      \n \n \n       Parental Leave \u2013 fifteen (15) days of paid parental leave per calendar year to eligible employees with at least one year of service at the time of birth, placement of an adopted child, or placement of a foster care child.\n      \n \n \n       Adoption Assistance\n      \n \n \n       Employee Assistance Program\n      \n \n \n       College Coach Program\n      \n \n \n       Back-Up Care Program\n      \n \n \n       PTO for Volunteer Hours\n      \n \n \n       Employee Matching Gifts Program\n      \n \n \n       Employee Resource Groups\n      \n \n \n       Inclusion and Diversity Programs\n      \n \n \n       Employee Recognition Program\n      \n \n \n       Referral Bonus Programs\n      \n \n \n       Peer Recognition Program (BRAVO)\n      \n \n \n \n \n \n \n  Inclusion & Diversity\n   \n \n \n \n \n  Transamerica has made a strong commitment to inclusion and diversity, and we are proud to be an organization where all perspectives are valued. Transamerica has earned recognition for its strong efforts year-over-year, including from the Human Rights Campaign\u2019s Foundation Corporate Equality Index, the Diversity Best Practices Inclusion Index, and Seramount\u2019s \u201c100 Best Companies\u201d list.\n   \n \n \n \n \n  In addition, as part of Transamerica\u2019s commitment to maintaining an inclusive workplace, the company sponsors employee-driven Employee Resource Groups (ERGs), which are formed around a shared interest or a common characteristic of diversity. ERGs are open to all employees and provide a supportive environment for raising diversity awareness and promoting inclusive behavior.\n   \n \n \n \n \n  Giving Back\n   \n \n \n \n \n  Transamerica believes our responsibilities extend beyond our corporate walls. That's why we created the Aegon Transamerica Foundation in 1994. Through a combination of financial grants and the volunteer commitment of our employees, this foundation supports nonprofit organizations focused on the education, health, and well-being of the communities where we live and work.\n   \n \n \n \n \n \n  https://www.transamerica.com/why-transamerica/aegon-transamerica-foundation\n    \n \n \n \n \n \n  Transamerica\u2019s Parent Company\n   \n \n \n \n \n \n     Aegon\n     acquired the Transamerica business in 1999. Aegon\u2019s roots go back more than 175 years to the first half of the nineteenth century. Since then, Aegon has grown into an international company, with businesses in the Americas, Europe, and Asia. Today, Aegon is one of the world\u2019s leading financial services organizations, providing life insurance, pensions, and asset management. As a leading global investor and employer, the company seeks to have a positive impact by addressing critical environmental and societal issues, with a focus on climate change and inclusion and diversity.", "cleaned_desc": "", "techs": ""}, "eaedf7b739324031": {"terms": ["data analyst"], "salary_min": 80000.0, "salary_max": 100000.0, "title": "Business Analyst", "company": "Pacific Advisors", "desc": "Business Analyst \n \n  Take your analytical skills to the next level. We offer customized analysis, insights, and recommended strategies across a range of business and personal financial concerns. We work collaboratively with licensed professionals whose business and personal planning clients want to make smart decisions based on a sophisticated blend of complex software and human expertise. \n \n  To be successful as a Business Analyst, you should have: \n \n  Business-related degree field (business, accounting, mathematics, etc.). \n  3+ years of experience in business analytics and/or consulting. \n  Background and ongoing development of business analytics skills, including reading financial statements, understanding performance ratios, business operations, basic business tax, and value drivers. \n  Experience as an individual contributor, working well with teams, bringing solutions. \n  Ability to resolve conflicting, missing, and confusing data. \n  Knowledge of how to evaluate data for completeness and accuracy. \n  Experience with operating analytics platforms and interpreting results to confirm outcomes, then delivering analysis in professional reports. \n  Ability to support Relationship Managers in responding to advisor/client questions. \n  Capability to demonstrate intermediate/advanced Excel skills, understanding of mathematical concepts, and financial forecasting. \n \n \n  Your responsibilities as the Business Analyst will include: \n \n  Master analytics systems and operate them independently. \n  Oversee data prep team to ensure high quality and accurate data goes into each analysis. \n  Communicate analysis/report highlights, assumptions, unique concerns, and suggested strategies to Engagement Specialist, Lead Advisor, and Client as needed, in writing and/or in video/meetings. \n  Advance our analytics toward improved automation, efficiency, and highest quality. \n  Evaluate, recommend, and implement new analytics processes, features, software, and reports. \n  Prepare and deliver analysis reports for up to 20 clients per month. \n  Complete each client report in 4 hours or less, including meetings. \n  Collaborate with Data Team and junior Analysts to increase capacity and efficiency. \n  Develop analysis/report improvements that improve client and/or advisor experience, as measured in C-Sat scores consistently improving over previous quarters \n \n \n  Benefits: \n  We value our employees\u2019 time and efforts. Our commitment to your success is enhanced by our competitive compensation of $80-100k annually, depending on experience, and an extensive benefits package including paid time off, medical, dental, and vision benefits, and future growth opportunities within the company. Plus, we work to maintain the best possible environment for our employees, where people can learn and grow with the company. We strive to provide a collaborative, creative environment where each person feels encouraged to contribute to our processes, decisions, planning, and culture.", "cleaned_desc": "", "techs": ""}, "bc21a50eb3ca397c": {"terms": ["data analyst"], "salary_min": 56737.87, "salary_max": 71842.79, "title": "IT Business Analyst", "company": "US Anesthesia Partners, Inc.", "desc": "Overview  : \n  \n \n   The Business Analyst (BA) will coordinate, support, and manage activities related to demography software applications. The BA will primarily support and maintain demography systems and provide data analysis across related systems. The BA must work with solution manager to serve as a liaison between IT and assigned stakeholders and to define and prioritize business requirements.\n  \n Job Highlights  : \n  \n Capture business requirements from stakeholders \n  Transform business requirements into work items/requests for vendor(s) \n  Become a subject matter expert and understand the assigned solutions and all related data. \n  Assist in holding vendor development teams accountable for meeting stakeholder needs. \n  Assist in managing communications with stake holders. \n  Develop and maintain a strong understanding of USAP data requirements. \n  Identify communication gaps, manage issue escalations, and provide support to teams that are balancing competing priorities. \n  Assist in change control processes and committees. \n  Identify, validate, manage, and communicate application configuration changes. \n  Aid in software implementation and support for existing and new integrations \n \n Qualifications  : \n  \n Strong working knowledge of anesthesia demography preferred. \n  Revenue cycle experience a plus \n  Strong data analysis skills  \n Proficiency reading and writing SQL queries.  \n Strong verbal and written communication skills \n  Extremely detail oriented, able to analyze large volumes of data. \n  Ability to manage multiple projects simultaneously with dynamic requirements.  \n Must be self-motivating, able to work with little or no guidance. \n  Superb organization, time management, and documentation skills \n \n  EDUCATION/TRAINING/EXPERIENCE: \n \n  Bachelor\u2019s degree in business, Management Information Systems, IT or related filed. Relevant experience will be considered in lieu of education. \n  3+ years in healthcare as a business analyst \n  Proficiency in Microsoft Office including Excel, Word, and PowerPoint \n \n  PHYSICAL REQUIREMENTS: \n \n  Requires prolonged sitting, some bending, stooping, and stretching. \n  Must possess sufficient eye-hand coordination/manual dexterity to operate a keyboard, photocopier, telephone, calculator, and other office equipment. \n  Required normal range of hearing and eyesight to record, prepare, and communicate appropriate reports and evaluations.  \n Requires lifting papers and boxes weighing up to thirty-five pounds occasionally. \n  Requires dexterity to type at least 35 wpm. \n \n \n  WORKING CONDITIONS  (environment and safety):\n  \n \n  Work performed in office and/or home office environment. \n  Involves frequent contact with professional staff and executive level stakeholders. \n  Work may be stressful at times. \n  Interaction with others is frequent and often disruptive. \n \n \n \n  disclaimer:  The above job description has been written to indicate the general nature and level of work performed by employees within this classification. It is not written to be inclusive of all duties, responsibilities and qualifications required of employees assigned to this job.\n  \n \n \n  Anesthesia Partners, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, gender identity, sexual orientation, pregnancy, status as a parent, national origin, age, disability (physical or mental), family medical history or genetic information, political affiliation, military service, or other non-merit based factors.", "cleaned_desc": "  Strong data analysis skills  \n Proficiency reading and writing SQL queries.  \n Strong verbal and written communication skills \n  Extremely detail oriented, able to analyze large volumes of data. \n  Ability to manage multiple projects simultaneously with dynamic requirements.  \n Must be self-motivating, able to work with little or no guidance. \n  Superb organization, time management, and documentation skills \n \n  EDUCATION/TRAINING/EXPERIENCE: \n \n  Bachelor\u2019s degree in business, Management Information Systems, IT or related filed. Relevant experience will be considered in lieu of education. ", "techs": ["strong data analysis skills", "proficiency reading and writing sql queries", "extremely detail oriented", "superb organization", "time management", "and documentation skills", "bachelor\u2019s degree in business", "management information systems", "it or related filed"]}, "ca60a3169cbbec75": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Master Data Project Analyst (Nashville, TN)", "company": "Philips", "desc": "Job Title  Master Data Project Analyst (Nashville, TN)\n  \n  Job Description \n  Master Data Project Analyst (Nashville, TN) \n \n  Your role: \n \n  Collaborates with internal partners and organizations in the design and developments of reporting and analytics. \n  Provides support in outlining the tasks involved in projects and collaborate accordingly. \n  Help identify areas of improvements and create plans. \n  Drive proper usage of customer master data by creating an online portal, documentation, and training guides to educate end-users. \n \n \n  You're the right fit if:  \n \n Bachelor\u2019s degree in business or related field preferred, or equivalent combination of education and experience \n  2+ years in a highly accurate and data-driven environment where data integrity and cleanup are required. \n  Strong familiarity with Master Data management and concepts \n  Advance knowledge of tools like Excel, VBA Macros, SharePoint. \n  Proven working experience as a data analyst or business data analyst tools like Power BI, Tableau, Qliksense. \n  Experience working in SAP (MDM) or SFDC. Informatica Business Partner Data Hub experience is a plus. \n  Advanced analytical and conceptual skills with the ability to analyze complex problems, interpret operational needs, and develop integrated, creative solutions. \n  Excellent verbal/written communication skills and presentation skills \n  Ability to interact effectively with all levels of the organization build consensus and work through others in achieving goals and objectives. \n  You must be able to successfully perform the following minimum Physical, Cognitive, and Environmental job requirements with or without accommodation for this Office/Remote position. \n \n \n  Philips Transparency Details  \n \n The pay target for this position is $65,000 - $75,000 annually. The actual base pay offered may vary depending on multiple factors including job-related knowledge/skills, experience, business needs, geographical location, and internal equity. \n \n  In addition, other compensation, such as an annual incentive bonus may be offered. Employees are eligible to participate in our comprehensive Philips Total Rewards benefits program, which includes a generous PTO, 401k (up to 7% match), HSA (with company contribution), stock purchase plan, education reimbursement and much more. Details about our benefits can be found here.  \n \n Additional Information \n \n  US work authorization is a precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa, now or in the future. \n \n  Company relocation benefits  will not  be provided for this position. For this position, you must reside in  or  within commuting distance of Nashville, TN . \n \n  About Philips \n \n  We are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help improve the lives of others. \n \n \n  Learn more about our business. \n  Discover our rich and exciting history. \n  Learn more about our purpose. \n  Read more about our employee benefits. \n \n \n  If you\u2019re interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our commitment to diversity and inclusion here. \n \n  Philips is an  Equal Employment and Opportunity Employer/Disabled/Veteran and maintains a drug-free workplace.", "cleaned_desc": "  Drive proper usage of customer master data by creating an online portal, documentation, and training guides to educate end-users. \n \n \n  You're the right fit if:  \n \n Bachelor\u2019s degree in business or related field preferred, or equivalent combination of education and experience \n  2+ years in a highly accurate and data-driven environment where data integrity and cleanup are required. \n  Strong familiarity with Master Data management and concepts \n  Advance knowledge of tools like Excel, VBA Macros, SharePoint. \n  Proven working experience as a data analyst or business data analyst tools like Power BI, Tableau, Qliksense. ", "techs": ["excel", "vba macros", "sharepoint", "power bi", "tableau", "qliksense"]}, "4e829e1f279e0437": {"terms": ["data analyst"], "salary_min": 90000.0, "salary_max": 125000.0, "title": "Data Business Analyst, Senior", "company": "Varis - United States", "desc": "This is a 100% fully remote role. Work virtually from anywhere in the Continental U.S. \n  Varis stands as a pioneering force in the realm of digital procurement and commerce, serving as the nexus where buying organizations and suppliers seamlessly unite, forge contracts, transact, and prosper together. As a rapidly ascending technology startup, our core focus lies in digital commerce software-as-a-service and procurement, specifically within the dynamic landscape of B2B e-commerce. \n  At the heart of Varis beats an unwavering commitment to innovation and a customer-centric ethos that is poised to revolutionize business-to-business marketplaces. Joining our team at this juncture is akin to stepping onto the ground floor of an extraordinary opportunity to co-shape our destiny. Here, you'll not only witness but actively participate in the direct impact of your work, surrounded by a cadre of passionate individuals. You'll find yourself at the epicenter of a profoundly dynamic business model teeming with untapped individual and collective potential. \n  Your passion, innovation, and creativity are the very catalysts that will propel us to unprecedented heights. Join us today and be instrumental in propelling Varis into a future brimming with promise and possibility. \n \n  Apply quickly by emailing your resume here: data_business_analyst__8c2d867b5us@iris.greenhouse.io \n  What You'll Do \n \n We are looking for a Senior Business Analyst for our Business Planning and Strategy team. As a Senior Business Analyst, you will work closely with Product Managers, Program Managers, Business Operation Managers, and Software Developers to generate actionable insights that guide operational excellence and product development. \n Your work will have a direct impact on decision-making and strategy for our team. You will support this initiative by developing business metrics and reports, analyzing current processes to provide solutions for improvements, and helping executive leaders make key business decisions. \n The successful candidate will communicate effectively across teams and levels while balancing the needs and requirements of internal and external customers. We seek an individual who is motivated by a fast-paced and highly entrepreneurial environment. \n \n Key Responsibilities: \n \n \n Own the design, development, and maintenance of ongoing and ad-hoc metrics, reports, and analyses, that drive key business decisions \n Gather and analyze data for potential business expansion \n Prepare and present results of analysis and reports along with their relative impact(s) to the business to all levels of management. \n Create reports, dashboards, and visualizations with business intelligence tools (excel, visualization tools, and SQL), to understand business performance \n Participate in strategic & tactical planning discussions \n Coordinate with different departmental teams to produce better business outcomes \n Collaborate with the product manager on roadmap planning and prioritization \n \n What You'll Need \n \n \n Bachelor's degree in Business, Engineering, Statistics, Computer Science, Mathematics, Supply Chain or a related field \n 7+ years in corporate operations. \n 3+ years of relevant experience in a business analyst/data analyst/statistical analyst role. \n 2+ years of experience with business metrics reporting for corporate functions like finance/sales etc. \n Experience in supporting C-level is a big bonus. \n Excel modeling. \n Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools like PowerBI and Tableau. \n SQL proficiency, can write basic SQL queries \n Knowledge of DAX is desirable \n Excellent communication (verbal and written) and interpersonal skills with both technical and business audiences. \n Demonstrated ability to manage multiple projects, prioritization, planning, and task delegation. \n Strong critical thinking and problem-solving. \n Ability to display complex data in a simple, intuitive format and to present findings in a clear and concise manner \n Ability to collaborate and communicate effectively with Sales, Finance and Executive teams \n Domain knowledge of eCommerce/indirect procurement/Saas is desirable \n Proven ability to work independently in a fast-paced environment. \n \n \n \n  At Varis, pay scales are determined by role, level, location, and alignment with market data. Individual pay is determined through interviews and an assessment of several factors that are unique to each candidate, including but not limited to, job-related skills, relevant education and experience, certifications, abilities of the candidate, and pay relative to other team members.    The figures in this range reflect the average annual base salary for the given role, while additional variable incentives based on performance may also be available. Recruiters can share more information about our bonus program, benefits, and equity during the hiring process. \n \n  Pay Range \n \n    $90,000\u2014$125,000 USD\n   \n \n \n \n \n \n The above statements are intended to describe the general nature and level of work being performed by associates assigned to this classification and are not intended to be a complete list of all required responsibilities and skills. Other duties and special projects may be assigned per business needs. Job descriptions are subject to change at any time with or without notice. \n  Benefits and Perks \n \n 100% permanent remote work in the United States \n Medical / dental / vision, AD&D, and Life Insurance \n Paid Time Offer (PTO) and company paid holidays \n Health Saving Account (HSA) \n Long Term Disability and Short-Term Disability \n 401(k) matching program \n Discounted auto, home, and pet insurance \n Retirement savings plan rollovers \n Banking services \n Military leave \n Employee Assistance Program (EAP) \n Regular pay for funeral/memorial service observance \n Discounts on Office Depot/Microsoft/Apple products and services \n Opportunity for professional growth and career advancement \n \n \n Varis, Inc. is an Equal Opportunity Employer.  We are committed to providing equal employment opportunities in all employment practices. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, citizenship status, marital status, age, disability, protected veteran status, sexual orientation, or any other characteristic protected by law. We will consider for employment qualified applicants with arrest and conviction records in alignment with the City & County of San Francisco Fair Chance Ordinance. \n  CCPA disclosure notice  here .", "cleaned_desc": " Experience in supporting C-level is a big bonus. \n Excel modeling. \n Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools like PowerBI and Tableau. \n SQL proficiency, can write basic SQL queries \n Knowledge of DAX is desirable \n Excellent communication (verbal and written) and interpersonal skills with both technical and business audiences. \n Demonstrated ability to manage multiple projects, prioritization, planning, and task delegation. \n Strong critical thinking and problem-solving. \n Ability to display complex data in a simple, intuitive format and to present findings in a clear and concise manner \n Ability to collaborate and communicate effectively with Sales, Finance and Executive teams \n Domain knowledge of eCommerce/indirect procurement/Saas is desirable \n Proven ability to work independently in a fast-paced environment. \n \n \n ", "techs": ["excel", "powerbi", "tableau", "sql", "dax"]}, "901e041ba40bc1f2": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Data Quality Analyst", "company": "West Bend Mutual Insurance Company", "desc": "Company Overview: \n  \n   Voted Journal Sentinels Top Workplaces to work for 3 consecutive years! Join us at West Bend Mutual, where we have been voted top workplaces to work three consecutive years. At West Bend Mutual, we believe that our employees are our greatest asset. We hire talented individuals who are conscientious, dedicated, customer focused, and able to build lasting relationships. We create and maintain an environment where you feel a sense of belonging and appreciation. Your diversity of through, experience and knowledge are valued. Recognized as top workplace, we are committed to fostering a welcoming culture, offering you opportunities for meaningful work and professional growth. More than a workplace, we celebrate our success and take pride in serving our communities.\n   Job Summary: \n  \n   We are seeking a Data Quality Specialist to join our Data Governance team. As a data quality specialist you will play a key role as we mature our data quality practice. We are looking for someone who is passionate about measuring and reporting out on data quality. Your prior experience with data quality tools and process will be leveraged to ensure we continue to monitor and improve our data quality at West Bend. We are in flight with transformational data work.\n   Responsibilities & Qualifications: \n  \n  *There is a remote work option, but we still require you to live within driving distance to one of our Wisconsin office- West Bend, Madison, Appleton, WI* \n \n \n \n  The Data quality analyst monitors all aspects data quality for the organization, with the focus being on enterprise level data sources. Works to create a framework for measuring and reporting on data quality. Engages with data stewards to create necessary corrective plans to improve data quality at an individual data element level. Work with project teams to profile and baseline data quality when new sources of data are created. Communicates with data champions overall data quality themes and solicits input from them on corrective measures.\n  \n \n  6-8 years of insurance experience \n  Proven analytical and mathematical skills \n  Statistical knowledge \n  Advanced knowledge of data profiling techniques \n  Thorough understanding of insurance metrics \n  Ability to manage large complex projects or processes independently \n \n \n  Education \n \n \n   Bachelor's degree in statistics, mathematics, computer science, information management, or similar\n   EEO: \n  \n   West Bend provides equal employment opportunities to all associates and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \n    This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, and promotion.", "cleaned_desc": "  The Data quality analyst monitors all aspects data quality for the organization, with the focus being on enterprise level data sources. Works to create a framework for measuring and reporting on data quality. Engages with data stewards to create necessary corrective plans to improve data quality at an individual data element level. Work with project teams to profile and baseline data quality when new sources of data are created. Communicates with data champions overall data quality themes and solicits input from them on corrective measures.\n  \n \n  6-8 years of insurance experience \n  Proven analytical and mathematical skills \n  Statistical knowledge ", "techs": ["none"]}, "e972ff0ee7fe67a2": {"terms": ["data analyst"], "salary_min": 82000.0, "salary_max": 109000.0, "title": "Customer Success Business Analyst", "company": "Guideline, Inc.", "desc": "Guideline is seeking a  Customer Success Business Analyst  to join its growing Customer Success Team. In this role, you will review, analyze, and present insights on our Customer Success data. You will also be involved in implementing and providing ongoing operational support for Customer Success team's tools and platform (Salesforce). This role is highly collaborative and impactful, working cross functionally with key stakeholders and teams across the organization to directly impact top level business metrics, KPIs, and interpret customer trends. \n  What You Will Work On \n \n Split 70% Data Analytics / 30% Operational Improvements \n Perform in depth reviews of customer trends to define new customer experience and process improvement opportunities \n Build out reporting for interdepartmental transparency on a regular cadence \n Monitor and streamline our client feedback loop (NPS) \n Collaborate with team SMEs to update and maintain team SOPs and workflows \n Collaborate cross functionally with product, operations, compliance, engineering, sales and our CFPs in order to identify areas for improvement of the customer experience \n \n What We're Looking For \n \n 3+ years experience in data analytics, project management, operations \n Strong SQL skills and data visualization tools (Looker) \n Experience administering customer support platforms and CRMs (Salesforce, Zendesk, Desk.com) \n Excellent verbal and written communication skills \n Adaptable, with the ability to pick up new technologies \n Creative, with analytical problem-solving skills \n Flexible - we're moving fast, so the ability to constantly adapt to new conditions is a must \n Bachelor's degree preferred (or equivalent field-related experience) \n \n More About Guideline \n  Everyone should have a simple, affordable way to save for retirement. At Guideline, our plans are low cost and highly automated. This makes it easy for companies to offer a valuable benefit\u2014and easy for people to invest in their financial future with confidence. \n  Offer Package \n  The expected Salary Range for this position is $82000 - $109000 annually. Compensation is determined by numerous factors such as your qualifications, experience, and work location. \n  Additional benefits: \n \n Flexible vacation policy \n Company equity \n 401(k) with matching contributions \n 100% paid employee insurance coverage \n Annual learning and development stipend \n Parental leave \n Sabbatical after 5 years of employment \n \n Guideline provides equal employment opportunities to all employees and applicants for employment without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. \n  Employment open to residents of CO, FL, MA, MD, ME, NC, NY, TX, and WA. Guideline is committed to protecting the privacy and security of the personal information of our applicants. Please refer to Guideline's  Privacy Policy  for information about our privacy and security practices. \n  #LI-Remote \n \n  Expected Salary Range \n \n    $82,000\u2014$109,000 USD", "cleaned_desc": " Collaborate cross functionally with product, operations, compliance, engineering, sales and our CFPs in order to identify areas for improvement of the customer experience \n \n What We're Looking For \n \n 3+ years experience in data analytics, project management, operations \n Strong SQL skills and data visualization tools (Looker) \n Experience administering customer support platforms and CRMs (Salesforce, Zendesk, Desk.com) \n Excellent verbal and written communication skills ", "techs": ["looker", "salesforce", "zendesk", "desk.com"]}, "c567863a355e2ad2": {"terms": ["data analyst"], "salary_min": 66100.0, "salary_max": 87110.0, "title": "Analyst, Marketing Analytics (Remote)", "company": "Vail Resorts", "desc": "As a leading mountain resort operator with over 40 resorts in sixteen states and four countries. We exist to create an  Experience of a Lifetime  for our employees, so they can, in turn, provide and  Experience of a Lifetime  for our guests. We are looking for leaders, innovators, creators, and ambitious professionals to join our talented team. If you\u2019re ready to pursue your fullest potential, we want to get to know you! \n \n  Many of our Corporate function teams can now live and work in any of the states in which Vail Resorts currently operates* \u2013 enabling flexible remote work alongside a commitment to building and maintaining strong culture both in person and virtually. If you\u2019re ready to pursue your fullest potential, we want to get to know you. Find your purpose with us at www.vailresortscareers.com. \n \n  Job Summary \n  As the  Analyst of Season Pass Analytics  you will support   marketing and financial analyses for revenue growth strategies, in-season execution and financial budget planning for the Season Pass business (Epic Pass!). In addition, the role will fully support strategic planning for the Season Pass business. \n \n  This individual should demonstrate ambition, business acumen, and emotional intelligence. The position requires the ability to analyze data and to provide strategic insights with actionable recommendations in a concise and persuasive manner to cross-functional stakeholders. You will also be expected to demonstrate learning agility and the drive to take on new topics or projects. \n \n  Job Specifications \n \n  Outlet: Corporate / Remote \n  Shift & Schedule Availability: Year Round / Full Time \n  The budgeted range starts at $66,100 - $87,110. Actual pay will be adjusted based on experience. \n \n \n  Why this role is special: \n \n  Vail Resorts is an incredibly fast-growing company at the forefront of the Travel and Tourism industry \u2013  redefining the ski industry in the 21st century \n  Leveraging analytics is a core pillar of Vail Resorts\u2019 strategy moving forward \u2013  a critical driver of our success leading to a strong willingness to invest \n  We are a data-driven business with a proprietary guest database unmatched by any other company in the industry \u2013  a great foundation for building out advanced analytics \n  The opportunity to take our capabilities to the next level \u2013  driving key guest insights, supporting our analytical capability development, and having significant impact on the business \n  Direct exposure to leaders of the business \u2013  a unique opportunity to team with our business leadership to reimagine analytics \n  All the free skiing / riding you and your dependents can handle  \u2013 free Epic passes, discounted lodging and retail \n \n \n  Department Purpose: \n  The Analytics & Insights (A&I) team\u2019s purpose is to empower data-driven decision-making and strategic innovation for the Vail Resorts Enterprise. We have a shared passion for problem-solving, innovation, tackling complex enterprise challenges, and positively impacting business results. We approach problem-solving from perspectives that are data-driven as well as grounded in business intuition. \n \n  The A&I team fosters an environment that\u2019s inclusive and diverse, supporting all team members to be themselves. We value everyone\u2019s ideas and perspectives and believe that our team\u2019s diversity is critical to our ability to deliver exceptional work products and experiences. \n \n  Job Responsibilities \n \n  [Performance Analysis & Reporting]  Design and develop reporting for executive and Marketing stakeholders; leverage reporting to generate business performance insights \n  [Strategic Analysis]  Analyze historical data and evolving trends to support strategic planning; this may include, for example, identifying and sizing opportunities to grow and retain guests \n  [Presentation]  Communicate conclusions and recommendations in a clear, concise fashion to stakeholders \n  [Prioritization]   Communicate frequently and effectively with your manager to prioritize projects across a wide range of initiatives and stakeholders \n \n \n  Job Requirements \n  Required: \n \n  Experience with analytic tools/software such as Excel, Tableau, or similar programs \n  Strong quantitative and analytic skills with experience driving actionable recommendations and decisions \n  Demonstrated success working with large data sets, developing tools for streamlined analysis and creating output that succinctly summarizes complex concepts \n  Demonstrated strength in written and verbal communication, adjusting message to audience \n  Excellent interpersonal and relationship management skills, with the ability to communicate effectively  \n \n \n Strong organization and time management skills. Ability to handle multiple projects simultaneously and coordinate across multiple functions within an organization. \n \n \n  Preferred: \n \n  1-2 years previous experience in marketing analytics, consulting, financial analysis or other similar field \n  Experience with advanced analytic tools/software such SQL, Python or similar programs \n \n \n  The expected Total Compensation for this role is $66,100 - $87,110. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... \n \n  Medical, Dental, Vision insurance, and a 401(k) retirement plan \n  Hourly employees are generally eligible for accrued Paid Time Off (PTO) and Sick Time. Salaried employees are generally eligible for Flexible Time Off (FTO) \n  Paid Parental Leave for eligible mothers and fathers \n  Healthcare & Dependent Care Flexible Spending Accounts \n  Life, AD&D, and disability insurance \n \n \n  Reach Your Peak at Vail Resorts.  At Vail Resorts, our team is made whole by the brave, passionate individuals who ambitiously push boundaries and challenge the status quo. Whether you\u2019re looking for seasonal work or the career of a lifetime, join us today to reach your peak. \n \n   Remote work is currently permitted from British Columbia and the 16 U.S. states in which we currently operate. This includes: California, Colorado, Indiana, Michigan, Minnesota, Missouri, New Hampshire, New York, Nevada, Ohio, Pennsylvania, Utah, Vermont, Washington State, Wisconsin, and Wyoming. Please note that the ability to work remotely, and the particulars related to such work, are subject to change at any time; and, accordingly, the Company reserves the right to change its policies and/or require in-person/in-office work at any time in its sole discretion. \n \n \n  Vail Resorts is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other status protected by applicable law. \n \n  Requisition ID 498484   Reference Date: 10/09/2023   Job Code Function: Marketing", "cleaned_desc": "  Demonstrated strength in written and verbal communication, adjusting message to audience \n  Excellent interpersonal and relationship management skills, with the ability to communicate effectively  \n \n \n Strong organization and time management skills. Ability to handle multiple projects simultaneously and coordinate across multiple functions within an organization. \n \n \n  Preferred: \n \n  1-2 years previous experience in marketing analytics, consulting, financial analysis or other similar field \n  Experience with advanced analytic tools/software such SQL, Python or similar programs \n \n \n  The expected Total Compensation for this role is $66,100 - $87,110. Individual compensation decisions are based on a variety of factors. \n  The perks include a free ski pass, and a set of benefits including... ", "techs": ["sql", "python"]}, "f250dfa5da63a876": {"terms": ["data analyst"], "salary_min": 85497.664, "salary_max": 108259.086, "title": "IT Business Analyst", "company": "DRT Strategies, Inc.", "desc": "Business Analyst/Tester  \n DRT Strategies delivers expert management consulting and information technology (IT) solutions to large federal agencies, the U.S. Navy, state and local government and commercial clients in health care, technology, and the financial services industries. The three letters of our name, DRT, stand for Driving Resolutions Together, which is the core philosophy on which the company was founded. That is, we collaborate with our clients to solve their most pressing IT challenges - together. \n  We are problem solvers dedicated to your success, combining Fortune 500 experience with small business responsiveness. We have established a reputation with our clients as a forward-thinking consulting firm with demonstrated success in implementing solutions that lead to meaningful results. Our world-class consultants unite people to work collaboratively to achieve project goals and make your vision a reality. \n  Project Description \n  FDA\u2019s Center for Tobacco Products (CTP) developed a suite of electronic submissions applications (eSubmissions) to ensure the preparation, receipt, review, and data storage of tobacco product submissions. CTP developed targeted systems to address specific scientific and business analyses in support of its regulatory and research mission. To maintain and ensure the quality and reliability of these applications, CTP requires services focused on testing existing systems and systems (e.g., Rhapsody) in the development process and improving testing processes and procedures. CTP IT systems are a mix of custom developed systems and commercial-off-the-shelf integrations.    The CTP Office of Science, Division of Regulatory Science Informatics (DRSI) leads or participates in development and enhancements of CTP systems and uses agile system development processes.    The purpose of this task order is to provide testing support services for FDA CTP Office of Science, Division of Regulatory Science Informatics (DRSI).  \n Job Summary \n  Seeking a dynamic Business Analyst/Tester to support our efforts in ensuring the timely and precise completion of all testing activities and deliverables, fully aligned with the Scope of Work (SOW).    In this pivotal role, the Business Analyst/Tester will review/identify gaps in the business requirements and conduct requirements traceability mapping of the client\u2019s requirements/designs with user stories and acceptance criteria. Furthermore the Business Analyst/Tester will conduct System Integration Testing (SIT), End-to-End Testing (E2E) and Regression Testing of the web-based enterprise applications. This includes documentation of test cases/scripts, maintain test case inventory.    Operating within a high-performing team, the Business Analyst/Tester will exemplify strong deductive reasoning, an unwavering attention to detail, persistence, patience, and a flair for creative problem-solving. Effective communication skills will be pivotal in this role, given the multi-client and contractor environment within which you will operate. \n  Responsibilities \n \n Analyze business/functional requirements, design documents, user stories, change requests, business processes documents and develop test scenarios and scripts to test the application features. \n Identify any gaps in requirements/application features and collaborate with FDA staff and other contractors to address those gaps. \n Analyze and map user stories with test scripts, requirements and acceptance criteria for validity and feasibility. \n Perform testing of applications as assigned by Task Order Lead. \n Document test results and other issues (e.g., usability) found during testing and brief testing results to government task leads; Support troubleshooting and triaging of issues with different teams to drive towards resolution \n Draft Test Plan, Test Summary Reports and other reports on all aspects related to the software testing conducted to include identifying gaps, providing recommendations, identifying anomalies and bugs for each testing cycle. \n Learn how to uses automation testing tools and create/execute automation test scripts. \n Support other activities related to testing as directed by Task Order Lead and/or Portfolio Manager. \n \n  Required Experience \n \n Must have or be able to obtain a Public Trust clearance \n Have 5+ years of demonstrated experience in business analysis and software testing within the Federal Government \n Have 3+ years of demonstrated experience using software testing reporting tools (i.e., JIRA) \n Have working knowledge of Microsoft suite of products (Project, Word, Excel, and PowerPoint) \n Have working knowledge of Software Test Life Cycle \n Must be flexible to be able to adapt to changing customer requirements. \n Ability to recognize and respond to problems, issues, and risks. \n Ability to communicate clearly, concisely, and in a timely manner (verbal and written). \n Ability to garner support and operate with political savvy in a multi-client and contractor environment. \n Ability to deal with ambiguity and frequent changes in priorities. \n Ability to manage multiple tasks and prioritize workload based on needs of the clients. \n Ability to work with clients with minimal supervision. \n \n  Preferred Experience \n \n Experience with test automation tools (e.g., Unified Functional Tool, Selenium) \n Experience with agile framework (e.g., Scrum) \n \n  Education and Training \n \n Bachelor\u2019s degree in IT related field or applicable experience \n Software Tester Accredited Certification (e.g., ISTQB, CMST) (Preferred) \n Business Analyst Accredited Certification (Preferred) \n PMP (Preferred) \n \n \n  More About DRT \n  DRT Strategies, Inc. (DRT) celebrates diversity and is proud to provide Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, genetics, disability, or protected veteran status. In addition to federal law requirements, DRT complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. \n   \n 363y1N4sJk", "cleaned_desc": " Ability to communicate clearly, concisely, and in a timely manner (verbal and written). \n Ability to garner support and operate with political savvy in a multi-client and contractor environment. \n Ability to deal with ambiguity and frequent changes in priorities. \n Ability to manage multiple tasks and prioritize workload based on needs of the clients. \n Ability to work with clients with minimal supervision. \n \n  Preferred Experience \n \n Experience with test automation tools (e.g., Unified Functional Tool, Selenium) ", "techs": ["unified functional tool", "selenium"]}, "98471f43c3c4f29f": {"terms": ["data analyst"], "salary_min": 55440.0, "salary_max": 72000.0, "title": "Risk Analytics Analyst II (Remote)", "company": "Blackhawk Network", "desc": "About Blackhawk Network: \n  \n   Blackhawk Network (BHN) is the leader in global branded payment technologies. We strengthen relationships between brands and their customers, employees, and partners by transforming transactions into connections. BHN\u2019s portfolio includes: Gift Card & eGift products, promotions and distribution that grow revenue faster; Rewards & Incentives that build loyalty and acquisition and are integrated into today\u2019s leading platforms; and Payments that enable businesses and customers to access and disburse funds in convenient and innovative ways. BHN\u2019s network spans across the globe with over 400,000 consumer touchpoints. Learn more at BHN.com.\n  \n \n \n  This position may be performed remotely anywhere within the United States except for the State of Alaska, North Dakota, or South Dakota.\n   Overview: \n  \n   Blackhawk Network is looking for an enthusiastic, team-oriented individual to join our Risk Audit Team.\n  \n \n \n  Blackhawk Network is changing the world of gifting by making it possible to send a personalized eGift Card from any device, anywhere, anytime, with the best customer experience possible. More than 600 brands partner with us including Uber, Starbucks, Nordstrom, Delta, Best Buy, and The Home Depot.\n  \n \n \n  The online gift card space is a high-risk segment that attracts malicious actors, each looking to defraud legitimate consumers. Gift Cards are also a highly desirable option for consumers to buy gifts for friends and family or to capitalize on great promotional offers. BHN Risk Services provides best-in-class fraud prevention. We are committed to approving every good order, while preventing fraud from occurring on our platform. We are team driven and driven to succeed in this essential responsibility.\n   Responsibilities: \n  \n  Primary Duties: \n \n \n  Discover, recognize, and audit for patterns of fraudulent activity on orders that have been decisioned. \n  Analyze data to uncover emergent fraud and provide detailed exposition on fraud methodologies. \n  Provide feedback for constant process improvement and awareness of current trends. \n  Qualifications: \n  \n  Skills and Experience: \n \n \n  Strong analytical and decision-making skills. \n  Exceptional attention to detail and organization skills. \n  Experience in volume driven and time sensitive work environments. \n  Proficiency using the internet search tools and social media platforms. \n  Extensive experience/knowledge with Microsoft Excel, My SQL. \n  Fluency in data analysis and presentation. \n \n \n  Qualifications: \n \n \n  College degree (B.S./B.A.) or work experience equivalent in the financial industries or Risk services, at least 4 years. \n  Investigations / analysis background a plus \n  Very knowledgeable in MS Office applications \n  Familiarity with SQL, ability to generate and provide analysis of reporting. \n  Very strong attention to detail \n  Ability to communicate well in writing and on various internal company chat channels. \n  Ability to work remotely and as a part of a remote team. \n \n \n  Risk Analysts who excel in this role: \n \n \n  Demonstrate the ability to make connections that clarify information and produce insights. \n  Are able to work with and analyze data sets to establish trends. \n  Can recognize patterns and use information to establish fraud trends. \n  Are creative thinkers who can approach each order contingently. \n  Look to learn and teach in every collaboration. \n  Are comfortable running multiple software solutions concurrently. \n  Exhibit\u2019s confidence to make independent decisions based on analytical results. \n  Can work independently, but also thrives in a team-oriented environment. \n \n \n   Employer will conduct background check.\n   Benefits: \n  \n   Salary Range for all U.S. Residents (excluding Alaska, California, North Dakota, South Dakota): $55,440.00 to $72,000.00\n  \n \n \n  Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, Blackhawk Network offers benefits including 401k with employer match, medical, dental, vision, 12 paid holidays in the year 2023, sick pay accrual according to state law, parental leave, life insurance, disability insurance, accident and illness insurance, health and dependent care flexible spending accounts, wellness benefits, and flexible time off for all full-time employees. \n  EEO Statement: \n  \n   Blackhawk Network provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. Blackhawk Network believes that diversity leads to strength. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\n  \n \n \n  Blackhawk Network encourages applicants with previous criminal records to apply to all positions and, pursuant to the San Francisco and Los Angeles Fair Chance Acts (and other \u201cFair Chance\u201d laws), Blackhawk Network will consider for employment qualified applicants with arrest and conviction records. For Philadelphia applicants or jobs, please see a copy of Philadelphia\u2019s ordinance on this topic by clicking this link: https://codelibrary.amlegal.com/codes/philadelphia/latest/philadelphia_pa/0-0-0-280104.", "cleaned_desc": " \n  Strong analytical and decision-making skills. \n  Exceptional attention to detail and organization skills. \n  Experience in volume driven and time sensitive work environments. \n  Proficiency using the internet search tools and social media platforms. \n  Extensive experience/knowledge with Microsoft Excel, My SQL. \n  Fluency in data analysis and presentation. \n \n \n  Qualifications: \n \n \n  College degree (B.S./B.A.) or work experience equivalent in the financial industries or Risk services, at least 4 years. \n  Investigations / analysis background a plus \n  Very knowledgeable in MS Office applications ", "techs": ["microsoft excel", "my sql", "ms office applications"]}, "410e18b34bc1cae1": {"terms": ["data analyst"], "salary_min": 70000.0, "salary_max": 70000.0, "title": "Operations Analyst", "company": "NCX", "desc": "Who is NCX? \n \n A marketplace to help landowners participate in the nature-positive economy  \n A venture-backed company with top investors including Marc Benioff, Union Square Ventures, and Microsoft's Climate Innovation Fund \n Creating climate impact across the US - ten million acres and counting \n \n Our Goal: Create a Massive Positive Environmental Global Impact \n  We're helping landowners participate in emerging markets for carbon, biodiversity, and other types of natural capital. \n  We're building a platform to fully and fairly value every acre of forest in the world. \n  As an early hire at NCX, you will shape our growth, culture, and product as we build the foundation of the nature-positive economy. \n \n  Do the Best Work of Your Life \n  NCX is accelerating the transition to a nature-positive economy by helping landowners discover, evaluate, and compare opportunities to participate in natural capital markets. As an Operations Analyst at NCX, you will help run and hone our landowner onboarding and support processes to enable our landowners to match with climate, conservation, and natural resource projects on the NCX Marketplace. \n  This is a scrappy, generalist, \"figure it out\" kind of role. You'll be immersed in the day-to-day running of our marketplace and constantly jumping in to move things along and figure out how we can do it better next time. You'll have a wide range of responsibilities. One day you'll be preparing and analyzing dashboards. The next you'll be verifying property ownership records and checking a property's eligibility for a new program that just got listed on the marketplace. The week after you'll be answering questions from landowners on the platform. You will work with teams across NCX (including finance, customer support, product, and engineering) to streamline operations and increase the number of landowners matched with the right programs for them and their land. \n  Sound like you? \n  Required \n \n 1-3 years of professional experience, including internships or coursework related to data analysis, operations, or similar \n Strong analytical and problem-solving skills and willingness to jump in where needed \n Detail-oriented with the ability to manage multiple tasks simultaneously \n Excellent written and verbal communication skills \n \n Preferred \n \n Background at a startup \n Familiarity with BI tools (Metabase, PowerBI) \n Experience or coursework in marketing, finance, or GIS \n \n What you'll do \n \n Assist with landowner onboarding by reviewing platform data, requesting and verifying ownership documentation, and escalating cases as needed \n Assist with quality control reviews and use findings to recommend listing and data improvements \n Build, prepare, and present reports to track key performance indicators and business metrics \n Analyze data related to landowner performance and platform usage to identify trends and provide actionable insights \n Collaborate with cross-functional teams to measure the impact and efficiency of processes, and participate in cross-team experiments, implementations, and improvements \n \n We're looking for mission driven candidates with a passion for their craft. We encourage you to apply if you are excited about the role and mission even if you do not have every requirement listed. To be successful in accelerating the transition to a nature positive economy, we seek to build a team of diverse backgrounds, perspectives, and talents. We're excited to hear from you! \n \n  Pay Range \n \n    $70,000\u2014$70,000 USD\n   \n \n \n  Benefits \n Earn an equity stake in an exciting, well-capitalized start-up. \n  Setting You Up for Success \n \n 100% fully remote workforce \n Full technology support \n $1,000 budget for home office set up \n \n Generous Time Off and Perks \n \n 20 vacation days 15 company holidays \n Flexible parental leave \n Annual in-person All Hands meetings \n \n We're looking for mission driven candidates with a passion for their craft. We encourage you to apply if you are excited about the role and mission even if you do not have every requirement listed. To be successful in accelerating the transition to a nature positive economy, we seek to build a team of diverse backgrounds, perspectives, and talents. We're excited to hear from you!", "cleaned_desc": " Preferred \n \n Background at a startup \n Familiarity with BI tools (Metabase, PowerBI) \n Experience or coursework in marketing, finance, or GIS \n \n What you'll do \n \n Assist with landowner onboarding by reviewing platform data, requesting and verifying ownership documentation, and escalating cases as needed \n Assist with quality control reviews and use findings to recommend listing and data improvements \n Build, prepare, and present reports to track key performance indicators and business metrics ", "techs": ["metabase", "powerbi", "gis"]}, "c1c788f98f044ba3": {"terms": ["data analyst"], "salary_min": 82318.55, "salary_max": 99136.32, "title": "Aviation Business Analyst", "company": "Enlightened Inc.", "desc": "A Federal Aviation Division requires a Maintenance, Repair and Overhaul (MRO) IT software solution to support the safe, compliant, reliable, efficient, and sustainable management of its fleet of fixed wing and rotary aircraft (approximately 100 aircraft in total). The primary objective shall be to assure the safe and reliable performance of aircraft management, forecasting, planning, scheduling, training, and record keeping. These objectives are going to be completed by IBM by delivering the IBM Maximo for Aviation application using a Software as a Service (SaaS) cloud based Federal Risk and Authorization Management Program (FedRAMP) Moderate approved service. \n Task Description: \n The Aviation BA will be responsible effective use of data provided by aviation maintenance logs, process, and procedures to create overall cost versus benefit assessment while considering functional benefits, technical performance, risks, and schedule concerns. They can also translate maintenance process and procedures into technical requirements. \n Required skills/Level of Experience : \n \n Bachelor\u2019s degree in Business Administration or a related field \n Familiarity with project and change management and Agile methodologies techniques and processes \n Strong background in aviation maintenance \n Strong knowledge of Microsoft Office (Excel, Word, & PowerPoint) \n Excellent written and verbal communication skills \n Ability to explain issues and resolutions to technical and non-technical staff \n Ability to listen and develop detailed requirements and support technology demonstrations \n Ability to communicate directly with client and lead discussions in constructive ways \n \n Nice to have skills: \n \n Cloud Platform Certifications are a plus: AWS, IBM Cloud \n Prior experience with Federal Aviation \n Familiarity with asset management \n \n OTHER SKILLS/REQUIREMENTS \n \n Microsoft Excel \n Microsoft Word \n \n To be considered for work, A CANDIDATE MUST BE A U.S. CITIZEN \n Job Type: Full-time \n Pay: $82,318.55 - $99,136.32 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid sick time \n Paid time off \n Vision insurance \n Work from home \n \n Compensation package: \n \n Yearly pay \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Ability to explain issues and resolutions to technical and non-technical staff \n Ability to listen and develop detailed requirements and support technology demonstrations \n Ability to communicate directly with client and lead discussions in constructive ways \n \n Nice to have skills: \n \n Cloud Platform Certifications are a plus: AWS, IBM Cloud \n Prior experience with Federal Aviation \n Familiarity with asset management \n ", "techs": ["ability to explain issues and resolutions to technical and non-technical staff", "ability to listen and develop detailed requirements and support technology demonstrations", "ability to communicate directly with client and lead discussions in constructive ways", "aws", "ibm cloud", "federal aviation", "asset management"]}, "a23afb28c2dc1e67": {"terms": ["data analyst"], "salary_min": 117394.305, "salary_max": 148647.34, "title": "Data Analytics Lead", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Locations in multiple States \n  The Data Analytics Lead at Company has/is: \n \n  3 - 8 years experience in a data analytics role , preferably at a high-growth startup, CPG, loyalty, retail, or mobile gaming company \n  Entrepreneurial mindset with a  \u2018self-start\u2019 mentality ; Excels at finding answers. Customer centric. Comfortable with a workday and schedule that isn\u2019t always highly structured or predictable \n  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n \n  Additional: \n \n  Ability to handle multiple tasks simultaneously, maintain focus, and adapt to a variety of challenges in a  fast-paced agile environment \n  5 Location / ability to relocate to: Chicago (highly preferred) or San Diego \n \n   \n hyK5HkEn52", "cleaned_desc": "  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n ", "techs": ["tableau", "powerbi", "sql", "python", "r", "tableau prep", "alteryx", "knime", "snowflake", "aws", "gcp", "azure", "amplitude"]}, "ea1a3e6ed442e683": {"terms": ["data analyst"], "salary_min": 92779.625, "salary_max": 117479.67, "title": "Sr. Business Analyst", "company": "Gallagher", "desc": "About Us: \n  \n   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 45,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.\n  \n \n \n \n \n  As a member of our benefits and HR consulting team, you\u2019ll help our clients - employers of all sizes, across all industries - build workplaces that work better. \n  Overview: \n  \n   The Senior Business analyst will be responsible for collecting and understanding business needs for various platform to provide solutions to upgrade, enhance and continuously improve the platform with a consistent approach that works to enhance our client\u2019s experience.\n  \n \n \n \n \n  Please note additional position details below:\n  \n \n  This is a Temp-To-Hire, W-2 position. We are not able to do 1099 or C2C. \n  It is a fully remote role that will need to be based in the U.S. \n  You must meet our U.S. Eligibility requirements for work authorization as noted under \"Additional Information\" at the bottom of the job description. \n \n \n  Responsibilities: \n  \n Extract solution requirements utilizing interviews, requirements gathering exercises, documented business processes and workflow analysis \n  Document recommendations for process and applications improvements \n  Work closely with business partners to identify and enhance opportunities to use information and technology to improve client services and/or business processes \n  Resolve defects in applications according to defined SLA\u2019s while maintaining product quality  \n Transform functional requirements into technical design at various technology levels \n  Provide job aids to end users and support personnel to enable ease of use and ongoing support \n  Qualifications: \n  \n Business analysis experience in application lifecycles and software development \n  Project management experience  \n Management of stakeholders and client expectations while helping to shape deliverable requirements and timelines \n  Ability to communicate findings and development of plans in an organized, thoughtful and concise manner across various levels of business and project leadership teams  \n Preferred Experience with SiSense and PowerBI \n  Experience with direct/employee benefits and products preferred \n \n \n   #contingent\n  \n \n   #LI-KB3\n   Additional Information: \n  \n   Click Here to review our U.S. Eligibility Requirements\n  \n \n \n  We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more.", "cleaned_desc": "  Resolve defects in applications according to defined SLA\u2019s while maintaining product quality  \n Transform functional requirements into technical design at various technology levels \n  Provide job aids to end users and support personnel to enable ease of use and ongoing support \n  Qualifications: \n  \n Business analysis experience in application lifecycles and software development \n  Project management experience  \n Management of stakeholders and client expectations while helping to shape deliverable requirements and timelines \n  Ability to communicate findings and development of plans in an organized, thoughtful and concise manner across various levels of business and project leadership teams  \n Preferred Experience with SiSense and PowerBI ", "techs": ["sisense", "powerbi"]}, "42742f0e7521de88": {"terms": ["data analyst"], "salary_min": 0.0, "salary_max": 104.27, "title": "SAP BO & Tableau Developer", "company": "Evurge Solutions", "desc": "Year of Experience: 7-10 years of hands-on experience as a SAP BO/Tableau Developer. \n Job Description/ Responsibilities \n \u00b7 Design, develop, and enhance SAP BO and Tableau reports and dashboards to meet business requirements. \n \u00b7 Collaborate with stakeholders to gather reporting and visualization requirements and translate them into technical specifications. \n \u00b7 Utilize SAP BW and Snowflake for data integration, modelling, and extraction. \n \u00b7 Optimize and tune performance of SAP BO and Tableau reports to ensure efficient data retrieval and processing. \n \u00b7 Conduct data analysis and provide insights to support business decision-making. \n \u00b7 Perform troubleshooting and debugging of SAP BO and Tableau applications. \n What are the top 3 skills required for this role? \n 1. SAP BO & Tableau \n 2. Strong understanding of SAP BW and experience in leveraging it for data integration and modelling. \n \u00b7 Familiarity with Snowflake data warehouse and its usage in reporting and analytics. \n \u00b7 Proficient in SQL and data manipulation techniques for data extraction and transformation. \n Strong understanding of SAP BW and experience in leveraging it for data integration and modelling. \n \u00b7 Familiarity with Snowflake data warehouse and its usage in reporting and analytics. \n \u00b7 Proficient in SQL and data manipulation techniques for data extraction and transformation. \n Additional Information: \n Team size, direct reports, key deliverables, unique selling points, additional qualifications, team culture etc. \n 1. Good communication skills \n 2. Take ownership of the deliverables \n 3. Should be able to interact with client business team as needed. \n 4. Good Team Player \n 5. Should be able to work in multi-vendor environment \n Years of Experience: \u2002 7-10 years of hands-on experience as a SAP BO/Tableau Developer. \n \u00b7 In-depth knowledge and proficiency in SAP BO and Tableau, including report and dashboard development. \n Job Types: Contract, Permanent, Full-time \n Salary: Up to $104.27 per hour \n Application Question(s): \n \n Pl. mention your Email ID here for better reach \n \n Experience: \n \n SAP BO: 8 years (Required) \n Tableau: 8 years (Required) \n Snowflake & SQL: 1 year (Required) \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Perform troubleshooting and debugging of SAP BO and Tableau applications. \n What are the top 3 skills required for this role? \n 1. SAP BO & Tableau \n 2. Strong understanding of SAP BW and experience in leveraging it for data integration and modelling. \n \u00b7 Familiarity with Snowflake data warehouse and its usage in reporting and analytics. \n \u00b7 Proficient in SQL and data manipulation techniques for data extraction and transformation. \n Strong understanding of SAP BW and experience in leveraging it for data integration and modelling.   \u00b7 Familiarity with Snowflake data warehouse and its usage in reporting and analytics. \n \u00b7 Proficient in SQL and data manipulation techniques for data extraction and transformation. \n Additional Information: \n Team size, direct reports, key deliverables, unique selling points, additional qualifications, team culture etc. \n 1. Good communication skills \n 2. Take ownership of the deliverables \n 3. Should be able to interact with client business team as needed. ", "techs": ["sap bo", "tableau", "sap bw", "snowflake data warehouse", "sql"]}, "5bdcd7635640682b": {"terms": ["data analyst"], "salary_min": 92948.59, "salary_max": 117693.625, "title": "Business Analyst", "company": "Sprezzatura Management Consulting", "desc": "Position Description: \n  Sprezzatura is seeking an experienced Business Analyst to join our team and play a pivotal role in supporting the Customer Experience Datawarehouse initiative. The ideal candidate should possess a strong problem-solving attitude, with a proven ability to develop precise requirements and user stories that align seamlessly with our business goals and objectives. This individual will exercise sound judgment, uphold discretion, and exhibit exceptional written and verbal communication skills. In addition, strong administrative and organizational capabilities are essential, along with a track record of delivering projects on schedule and achieving desired outcomes. If you're ready to make a meaningful impact on a dynamic project, we invite you to apply and be part of our team's success. \n \n  Roles/Responsibilities: \n \n Requirements Gathering and Analysis: Collaborate with stakeholders, including business users, subject matter experts, and technical teams, to elicit, analyze, and document functional and non-functional requirements for projects and systems. Conduct interviews, workshops, and other techniques to gather comprehensive and accurate requirements. \n Requirements Documentation: Create clear, concise, and comprehensive requirements documents, including user stories, use cases, process flows, and functional specifications. Ensure that requirements are well-defined, unambiguous, and aligned with business goals and objectives. \n Requirements Validation and Verification: Review and validate requirements with stakeholders to ensure accuracy, completeness, and alignment with their needs. Facilitate requirements workshops and meetings to resolve conflicts, clarify ambiguities, and gain consensus on requirements. \n JIRA Experience including the creation and management of JIRA tickets through a development lifecycle.  \n Data Analysis: Collect, organize, synthesize, and analyze data; summarize findings; develop conclusions and recommendations. \n Change Management: Assess and manage requirements changes throughout the project lifecycle, ensuring that changes are properly evaluated, documented, and communicated to stakeholders. Collaborate with project teams to assess the impact of changes on project scope, schedule, and resources. \n Stakeholder Engagement: Engage with stakeholders to understand their needs, gather feedback, and provide regular updates on requirements-related activities. Build and maintain strong relationships with stakeholders to foster collaboration and ensure their requirements are accurately captured and addressed. \n Process Improvement: Continuously assess and improve requirements management processes, frameworks, and tools to enhance efficiency and effectiveness. Identify opportunities for automation, standardization, and best practices implementation to streamline requirements gathering, analysis, and documentation. \n Administrative Support: Coordinate, schedule, and support meetings by providing agendas, and meeting minutes. \n Participates in continuous improvement activities by identifying and analyzing the effectiveness and efficiency of existing processes and developing strategies for improvements. \n Use the knowledge and perspective gained through project work to identify the best path forward. \n Business development and proposal support as required. \n \n \n Qualifications and Skills: \n \n Bachelor's degree in a relevant field, such as Business Analysis, Computer Science, Information Management, Information Technology, or a related discipline. \n Minimum of 5 years of experience as a Requirements Analyst or in a similar role, demonstrating expertise in requirements gathering, analysis, and documentation. \n Strong knowledge and practical experience with requirements elicitation techniques, such as interviews, workshops, and prototyping. \n Proven expertise in cloud computing platforms such as AWS, Azure, or Google Cloud. \n Demonstrated experience working with cloud-based data warehousing solutions (e.g., Amazon Redshift, Snowflake, Azure Synapse Analytics). \n Proficiency in API integration. \n Strong grasp of data extraction, transformation, and loading (ETL) processes in a cloud environment. \n Proficiency in requirements management tools, such as JIRA, Confluence, or similar software. \n Excellent analytical and problem-solving skills, with the ability to interpret and prioritize requirements based on business value and project constraints. \n Strong written and verbal communication skills, with the ability to effectively communicate complex information to technical and non-technical stakeholders. \n Detail-oriented and results-driven, with a commitment to delivering high-quality requirements documentation within deadlines. \n Ability to work independently and collaboratively within a team environment, managing multiple priorities and adapting to changing project needs. \n Professional certifications in business analysis, such as CBAP or CCBA, are desirable. \n Familiarity with agile or iterative development methodologies is a plus. \n \n \n \n  Transitioning military and/or Veterans with relevant experience are invited to apply. Sprezzatura is an equal opportunity employer. Sprezzatura offers benefits including healthcare, 401K, vacation, and paid sick leave. \n \n \n  Company Description \n  Sprezzatura Management Consulting, LLC (www.sprezzmc.com) is a Washington, DC-area Service-Disabled Veteran-Owned Small Business (SDVOSB) that enables government transformation by supplying insight and leadership at the intersection of people, processes, and technology. We apply knowledge, project, and life-cycle management best practices to catalyze change.", "cleaned_desc": " Proven expertise in cloud computing platforms such as AWS, Azure, or Google Cloud. \n Demonstrated experience working with cloud-based data warehousing solutions (e.g., Amazon Redshift, Snowflake, Azure Synapse Analytics). \n Proficiency in API integration. \n Strong grasp of data extraction, transformation, and loading (ETL) processes in a cloud environment. \n Proficiency in requirements management tools, such as JIRA, Confluence, or similar software. \n Excellent analytical and problem-solving skills, with the ability to interpret and prioritize requirements based on business value and project constraints. \n Strong written and verbal communication skills, with the ability to effectively communicate complex information to technical and non-technical stakeholders. \n Detail-oriented and results-driven, with a commitment to delivering high-quality requirements documentation within deadlines. ", "techs": ["aws", "azure", "google cloud", "amazon redshift", "snowflake", "azure synapse analytics", "api integration", "jira", "confluence"]}, "ff2e233108871d83": {"terms": ["data analyst"], "salary_min": 44.69, "salary_max": 49.66, "title": "Business Analyst |", "company": "Aquent Talent", "desc": "Overview \n \n \n Placement Type: \n Temporary \n \n \n Salary (USD): \n $44.69 to $49.66 Hourly \n \n \n Start Date: \n 10.23.2023 \n \n \n Responsibilities: \n \n Assets Project Management & Special Projects \n    \n Managing request intake through ADO, follow up with customers on requirement gathering as needed, and self-assign tasks and to other team members \n Completing customer requests that are delivered through our project management tool (ADO) \n Reviewing dashboard and providing project status updates in tool and in sync meetings \n Managing timeline on special projects and Assets Governance Team assignments \n Upholding DAM strategy by working with customers \n Creation/management of requests submitted to engineering for semester planning in coordination with customers and the Assets Governance team \n \n Assets Education & Documentation \n    \n Leading Office Hours and Feature Training Sessions for tenants \n Support Working Group sessions for Tenant Librarian Leads \n Creating and updating governance documentation, trainings, and the MarTech Portal as identified by the Assets Governance Team. \n Advocate for DAM strategy through training delivery and continuous Assets\u2019 education to customers \n \n Tenant Migration Support \n    \n Discovery calls and onboarding support for assigned white glove \n customers to collect business requirements and customization needs beyond out of the box implementation \n \n Assets Governance Team representative to assigned customers currently on the platform, continuous support provided to large scale implementation customers \n \n Working with engineering and migration PMs (Project Managers) to align on migration timelines and submitted engineering requests, schedule check-ins with tenant teams to provide updates \n Customization of the AEM Assets platform based on customer requirements (folder creation, metadata schema property management, image profile creation and management, search schema modification, etc.) \n For \u201ceasy\u201d sites and customers, availability to answer governance and migration questions \n   \n \n Experience: \n \n 8+ years\u2019 experience required. \n \n The target hiring compensation range for this role is the equivalent of $44.69 to $49.66 an hour. Compensation is based on several factors including, but not limited to education, relevant work experience, relevant certifications, and location. Additional benefits offered may include; medical health insurance and dental insurance, life insurance, and eligibility to participate in 401k plan with company match.", "cleaned_desc": "", "techs": ""}, "31d12d036b4566c1": {"terms": ["data analyst"], "salary_min": 84239.94, "salary_max": 106666.53, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "ootb", "gdpr", "hippa", "spi"]}, "bc0ab551d76c5c62": {"terms": ["data analyst"], "salary_min": 107757.61, "salary_max": 136445.14, "title": "Sr. Business Analyst (Remote) - Temp-To-Hire", "company": "Gallagher", "desc": "About Us: \n  \n   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 45,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.\n  \n \n \n \n \n  As a member of our benefits and HR consulting team, you\u2019ll help our clients - employers of all sizes, across all industries - build workplaces that work better. \n  Overview: \n  \n   The Sr. Business Analyst manages business/IT related projects through the entire life-cycle from strategic scope definition to requirements gathering, analysis, timeline and budget definition, implementation support, user training and status reporting. This role also works with a variety of technical and functional partners within the business to define requirements for process improvement projects, develop required documentation and communicate status in order to ensure business requirements are met. Experience with CRM applications such as Salesforce.\n  \n \n \n  Please note additional position details below: \n \n \n  This is a  Temp-To-Hire , W-2 position. We are not able to do 1099 or C2C. \n  It is a  fully remote  role that will need to be based in the U.S. \n  You must meet our U.S. Eligibility requirements for work authorization as noted under \"Additional Information\" at the bottom of the job description. \n \n \n \n  How you will impact the Business? \n \n \n \n  You will collaborate with IT Leadership, practice area leadership, our merger partners, and external vendors.\n  \n \n \n \n  Ensure all work is executed and detailed to keep projects moving forward. \n  Assist Divisional and Regional leadership with coordination of project plans, action items and communications. \n  Guide and assist in developing documentation for processes, including reference manuals, instructional materials, communication presentations, and support manuals. \n  You will develop an integrated and standardized project plan that includes status reporting, progress reports on project health and risk and issue mitigation, as well as leading project budget and resources \n  You will define and gather detailed functional and technical requirements, analyzes business needs, and validates solutions with our internal/external clients \n  Responsibilities: \n  \n  Subject Matter Expertise \n \n \n  Serves as subject matter expert associated with content, processes, and procedures. \n  Identify best practices that support business performance related to efficiency and customer service to drive improvement. \n \n \n  Requirements Gathering \n \n \n  Drive requirements gathering process by meeting with project stakeholders to define business and functional requirements, prototypes, and training materials. \n  Work collaboratively with internal departments in the planning and analysis of requirements, process changes or enhancements. \n \n \n  Business Analysis \n \n \n  Defines detailed requirements, analyzes business needs, and validates solutions with our internal clients. \n  Devises or modifies procedures to solve complex problems considering technology solutions. \n  Retrieve and analyze data from multiple systems for trends and exceptions and help determine business impact. \n  Recommend solutions to problems based on business-specific facts. \n  Qualifications: \n  \n  QUALIFICATIONS REQUIRED \n \n \n  Exceptional Business Requirements Gathering capabilities \n  Superior presentation skills (in-person and utilization of web conferencing platforms) \n  Preferred 7+ years Business Analyst global enterprise-level experience in employee benefits insurance, financial services or related industries \n  Strong ability to learn, adapt and contribute in challenging environments \n  Self-motivated and able to work independently \n  Flexibility to shift priorities as needed to facilitate business requirements \n  Excellent oral and written communication skills (ability to grasp, breakdown and convey complex concepts and ideas) \n  Comfortable leading team project meetings and debriefing sessions between both C-level business executives and technical audiences \n  Proficient PC skills (Windows, Word, Excel, Outlook, Acrobat, etc.) \n  Working knowledge of financial industry terminology (e.g. retirement plans, executive benefits, investment consulting, life insurance, etc.), as well as regulations from the perspective of the SEC and FINRA organizations \n  Experience managing technology related projects and coordinating/collaborating between technology professionals and business executives \n \n \n \n  Communication, Analytical, and Organization Skills \n \n \n  Strong analytical, organizational, problem-solving, communication, and interpersonal skills  Must be independent, self\n    motivated, and goal and people oriented \n  Proactive approach with attention to detail and proven ability to follow through \n \n \n \n  Work Execution \n \n \n  Change agent with ability to influence others outside of a direct reporting relationship \n  Proven relationship building skills and high energy level \n  Co-operative with colleagues, strong consultative approach working closely with IT and business constituents at all levels \n  Supports execution of business unit goals and Dominant Priorities \n \n \n \n  Standards and Practices \n \n \n  Ability to manage/balance multiple priorities \n  Assigns work and manages projects on a timely basis \n  Excels in a self-service environment and has a \u201cno job is too small\u201d attitude \n \n \n \n  Use of Time \n \n \n  Ability to lead and participate in cross functional team based projects \n  Can manage/balance multiple priorities \n  Can prioritize and manage through constant change \n \n \n \n  Customer Service and Business Strategy \n \n \n  Commitment to and record of strong customer service \n  Excellent interpersonal skills \n  Ability to translate short-term business goals into team and individual performance goals \n  Ability to conduct performance management discussions \n  Excellent customer focus \n  Excels at understanding and articulating strategy, positioning and messaging \n \n \n \n  Requirements \n \n \n  Bachelor's degree in Business, Information Technology, Engineering or related field. \n  Excellent verbal and written communication skills. \n  Intermediate level proficiency with Microsoft Office Suite & Outlook \n  Expertise using common project management and flowchart software (MS Project, Easy Projects, DevOps, MS Visio, Gantt Charts, etc.) \n  Additional Information: \n  \n   Click Here to review our U.S. Eligibility Requirements\n  \n \n \n  We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more.", "cleaned_desc": " \n  Defines detailed requirements, analyzes business needs, and validates solutions with our internal clients. \n  Devises or modifies procedures to solve complex problems considering technology solutions. \n  Retrieve and analyze data from multiple systems for trends and exceptions and help determine business impact. \n  Recommend solutions to problems based on business-specific facts. \n  Qualifications: \n  \n  QUALIFICATIONS REQUIRED \n \n \n  Exceptional Business Requirements Gathering capabilities \n  Superior presentation skills (in-person and utilization of web conferencing platforms) \n  Preferred 7+ years Business Analyst global enterprise-level experience in employee benefits insurance, financial services or related industries \n  Strong ability to learn, adapt and contribute in challenging environments \n  Self-motivated and able to work independently \n  Flexibility to shift priorities as needed to facilitate business requirements \n  Excellent oral and written communication skills (ability to grasp, breakdown and convey complex concepts and ideas) \n  Comfortable leading team project meetings and debriefing sessions between both C-level business executives and technical audiences \n  Proficient PC skills (Windows, Word, Excel, Outlook, Acrobat, etc.) \n  Working knowledge of financial industry terminology (e.g. retirement plans, executive benefits, investment consulting, life insurance, etc.), as well as regulations from the perspective of the SEC and FINRA organizations \n  Experience managing technology related projects and coordinating/collaborating between technology professionals and business executives \n \n \n \n  Communication, Analytical, and Organization Skills \n \n \n  Strong analytical, organizational, problem-solving, communication, and interpersonal skills  Must be independent, self     motivated, and goal and people oriented \n  Proactive approach with attention to detail and proven ability to follow through \n \n \n \n  Work Execution \n \n \n  Change agent with ability to influence others outside of a direct reporting relationship \n  Proven relationship building skills and high energy level \n  Co-operative with colleagues, strong consultative approach working closely with IT and business constituents at all levels \n  Supports execution of business unit goals and Dominant Priorities \n \n \n \n  Standards and Practices \n \n \n  Ability to manage/balance multiple priorities \n  Assigns work and manages projects on a timely basis \n  Excels in a self-service environment and has a \u201cno job is too small\u201d attitude \n \n \n \n  Use of Time \n \n \n  Ability to lead and participate in cross functional team based projects    Can manage/balance multiple priorities \n  Can prioritize and manage through constant change \n \n \n \n  Customer Service and Business Strategy \n \n \n  Commitment to and record of strong customer service \n  Excellent interpersonal skills \n  Ability to translate short-term business goals into team and individual performance goals \n  Ability to conduct performance management discussions \n  Excellent customer focus \n  Excels at understanding and articulating strategy, positioning and messaging \n \n \n \n  Requirements \n \n \n  Bachelor's degree in Business, Information Technology, Engineering or related field. \n  Excellent verbal and written communication skills. \n  Intermediate level proficiency with Microsoft Office Suite & Outlook \n  Expertise using common project management and flowchart software (MS Project, Easy Projects, DevOps, MS Visio, Gantt Charts, etc.) \n  Additional Information: \n  \n   Click Here to review our U.S. Eligibility Requirements\n  ", "techs": ["requirements gathering", "presentation skills", "web conferencing platforms", "business analyst", "employee benefits insurance", "financial services", "adaptability", "independent work", "oral communication skills", "written communication skills", "pc skills", "financial industry terminology", "project management", "relationship building", "prioritization", "customer service", "business strategy", "bachelor's degree", "microsoft office suite", "project management software", "flowchart software"]}, "66a91a5bbcd3349b": {"terms": ["data analyst"], "salary_min": 45.0, "salary_max": 50.0, "title": "Business Analyst(WMS Manhattan)", "company": "Lakarya LLC", "desc": "Lakarya is hiring for one of our clients \n WMS Business Analyst \n Chesapeake ,VA(Remote) \n Long Term Contact \n Understand the scope of the Data-Lake solution and work on identifying the data model \n Participate in the design and architecture of ETL processes for the defined mapping to Data-Lake solution \n Conduct meetings with Client Support teams to gather the data mapping requirements for various WMS \n Conduct meetings with internal stakeholders to understand and perform the analysis between various WMS \n Understand business problems, provide analysis and insights from the client\u2019s data \n Conduct scheduled progress reviews on all workstreams and interact with the teams daily \n Create detailed functional specifications for modifications, defect corrections, and enhancements identifying, and mapping changes impacting the Data-Lake solution \n Perform process and data modeling \n Bachelor\u2019s degree in Engineering or related technical fields \n 4 years of experience in Supply Chain and logistics or related industry \n Expertise and experience in at least one of the following business disciplines: supply chain management, warehousing, transportation or distribution \n Strong project and time management skills with ability to multitask and prioritize workload \n Solid expertise with MS Excel, SQL, any visualization tools like Tableau/PowerBI, any ETL tools for data analysis, extraction, troubleshooting and reporting \n Hands on experience of working with Big data sets (Data sets with millions of records) \n Good to have hands on experience with any reporting tool \n Good to have any working experience in any Cloud ecosystem \n Good to have any knowledge of formal systems development methodologies \n Job Type: Contract \n Salary: $45.00 - $50.00 per hour \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n How many do you worked in Distribution center ? \n Are you a US Citizens? \n \n Experience: \n \n Business analysis: 4 years (Preferred) \n WMS Manhattan: 5 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " Understand business problems, provide analysis and insights from the client\u2019s data \n Conduct scheduled progress reviews on all workstreams and interact with the teams daily \n Create detailed functional specifications for modifications, defect corrections, and enhancements identifying, and mapping changes impacting the Data-Lake solution \n Perform process and data modeling \n Bachelor\u2019s degree in Engineering or related technical fields \n 4 years of experience in Supply Chain and logistics or related industry \n Expertise and experience in at least one of the following business disciplines: supply chain management, warehousing, transportation or distribution \n Strong project and time management skills with ability to multitask and prioritize workload ", "techs": ["none"]}, "5033fd4a8cad2203": {"terms": ["data analyst"], "salary_min": 63000.0, "salary_max": 91400.0, "title": "Senior BI Analyst", "company": "JLL", "desc": "JLL supports the Whole You, personally and professionally. \n  Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you\u2019ve got deep experience in commercial real estate, skilled trades, and technology, or you\u2019re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally. \n \n  Job Summary: \n \n  Our dedicated on-account Business Intelligence (BI) team is seeking a Business Intelligence and Analytics Senior Analyst. The role joins a team of BI professionals supporting a large strategic client with a key focus on producing a growing array of BI solutions (dashboards, reports, apps, trackers, etc.). You will partner with data owners to understand business requirements and common reporting/analysis use cases and work with technical and business teams to define appropriate solutions. In addition, the role will be expected to maintain an analytical mindset that will uncover several perspectives on a problem or opportunity, determining any and all drivers towards or barriers to successful performance, and makes recommendations based on what is discovered.  \n \n To be successful in this role, you should be a confident professional with broad skills in analyzing and solving complex business problems, writing and presenting, facilitating and influencing. This includes being able to extrapolate data and be able to forecast and trend performance data as well as analyze trends of Key Performance Indicator results for performance improvement concepts. You should be familiar working within a data warehouse, as well as be able to provide hands-on support to data from a variety of sources, build reporting and meta-data models to support strategic data initiatives and design complex reports and dashboards based on requirements.  \n \n Areas of Responsibility: \n \n  Business Intelligence Reporting & Analytics: \n \n  Perform data management analysis using SQL, including retrieving data from multiple sources, profiling, processing, validating, and migrating data to centralized data platforms \n  Regularly work in SQL and be able to create views, tables, and develop queries to answer questions \n  Design, develop and deploy BI solutions, including interactive dashboards in Tableau, sourcing data from internal SQL Server databases, Tableau published data sources, external sources, and leveraging ETL tools when needed. \n  Devise and promote creative data visualizations, reports, tools and dashboards to derive actionable real-time insights to business data pertinent to the audience (SSRS, Tableau, ect.) \n  Validate the calculations and results against known figures, other reports, peer reviews, etc. \n  Develops, executes and monitors simple to moderately complex data management / analytic processes to support ad hoc data and information delivery for assigned projects. \n  Proactively identify opportunities to optimize the performance and efficiency of existing processes/procedures \n  Translate the business questions and hypothesis into a data analysis plan. Execute the analysis either autonomously or in collaboration with others, depending on what the task calls for. Translate the results of the analysis into actionable recommendations and concrete answers to the business questions. \n  Independently develop, execute, and monitor complex data management/analytic processes to ensure deadlines are met for all assigned deliverables. \n  Financial modeling, analysis and compilation of quantitative data \n  Forecast/trending of performance data. \n  Process mapping and efficiency analysis \n  Provide subject matter expertise for all data related processes and analysis. \n \n \n  Data Validation & Governance Assistance: \n \n  Leverage industry tools (i.e. Alteryx/SSMS) to assess data quality and assist to resolve data quality problems. \n  Assist the BI and Analytics team and Work Dynamic data governance leads to define and document data remediation activities, processes and quality rules. \n  Work with business line data stewards and other stakeholders to identify remediation actions when Critical data quality falls below the accepted threshold. \n  Validate and cleanup input data, ensure assumptions are correct, manage outliers appropriately, raise any questions or issues with the input data if any exists, and help find the root cause of those issues \n \n \n  Interpersonal/Communication: \n \n  Present in front of management groups as the subject matter expert on specific reports or modeling. \n  Excellent presentation skills (verbal and written), Strong understanding of analytic/statistical concepts with the ability to explain them to others. \n  Collaborate with other analysts, data scientists and leaders to get to the best solution for complex questions. \n  Lead problem solving teams to develop recommendations based on data interpretation and analysis to transform behaviors and techniques \n  Work closely with business stakeholders to understand business questions/requirements/opportunities, and to support the accurate business usage and interpretation of JLL data as well as provide insight/answers to meet the needs of the business. \n  Engage with colleagues and internal customers to reverse engineer existing business processes and identify core business requirements for new information deliverables and data infrastructure \n  Distribute reports on a regular cadence as defined by the specific task \n \n \n  Skills & Qualifications: \n \n  Bachelor\u2019s degree in Business Administration, Information Systems, Data Analytics, Information Technology, Construction or Project Management, or related field \n  2+ years of BI, business or data analyst experience required ideally in an enterprise environment across multiple application systems and business functions. \n  2+ years of business experience in Corporate Real Estate, Construction Management, Transaction Management and Lease Brokerage, Property Management or related field \n  High level of technical skills with demonstrated ability to manage, manipulate, analyze raw data, research data issues, draw conclusions, provide resolution, and develop actionable recommendations. \n  Business analysis, consulting/advisory and/or project or client management experience will be a strong plus. \n  Strong SQL skills with experience developing complex queries and stored procedures \n  Proficient user of Microsoft Office applications (Excel, Word, PPT) \n  Experience with data visualization tools, Tableau preferred \n  Proficiency in ETL processes/tools - Alteryx Preferred \n  Exposure to SharePoint Power Applications and SSRS (Report Builder) a plus \n  Comfortable with senior managers and clients; can present without undue tension and nervousness \n  Excellent interpersonal skills - Ability to collaborate across many levels \n  Excellent oral, written, and presentation communication skills. \n  Knowledge of data lifecycle and maintenance processes \n  Experience with Agile methodologies and framework a plus. \n  Must have demonstrated experience in building and analyzing reports and dashboards along with summarizing the data for business users - Able to take abstract ideas or requirements and work independently towards development of a report/dashboard. \n  Reliable, self-motivated, and self-disciplined individual capable of planning and executing multiple projects simultaneously within a fast-paced environment \u2013 works well in a remote environment. \n  Impeccable attention to details and never compromising attitude for data accuracy. \n \n \n  Location \n \n  West Coast or Southwest USA ideal but anywhere in continental US is acceptable. \n  Virtual position optional. \n \n \n  Estimated compensation for this position is: \n  63,000.00 \u2013 91,400.00 USD\n  \n  The pay range listed is a total compensation range including bonus, if applicable. The provided range is an estimate and not guaranteed. An employment offer is based on applicant\u2019s education, experience, skills, abilities, geographic location, internal equity and alignment with market data. \n \n  Location: \n  Remote \u2013Chicago, IL\n  \n  If this job description resonates with you, we encourage you to apply, even if you don\u2019t meet all the requirements. We\u2019re interested in getting to know you and what you bring to the table! \n  Personalized benefits that support personal well-being and growth: \n \n  JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health. Some of these benefits may include: \n \n  401(k) plan with matching company contributions \n  Comprehensive Medical, Dental & Vision Care \n  Paid parental leave at 100% of salary \n  Paid Time Off and Company Holidays \n  Flexible and Remote Work Arrangements may be available \n \n \n  About JLL  \u2013 \n \n  For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500\u00ae company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com. \n \n  JLL Privacy Notice \n  Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL\u2019s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely. \n \n  For more information about how JLL processes your personal data, please view our Candidate Privacy Statement. \n \n  For additional details please see our career site pages for each country. \n \n  For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here. \n \n  This position may require you to be fully vaccinated against COVID-19. If required, you\u2019ll be asked to provide proof that you\u2019re fully vaccinated upon your start date. You\u2019re considered fully vaccinated two weeks after you receive the second dose of a two-dose vaccine series (e.g., Pfizer or Moderna) or two weeks after a single-dose vaccine (e.g., Johnson & Johnson/Janssen). Failure to provide proof of vaccination may result in termination. \n \n  Jones Lang LaSalle (\u201cJLL\u201d) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process \u2013 including the online application and/or overall selection process \u2013 you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL. \n \n  Pursuant to the Arizona Civil Rights Act, criminal convictions are not an absolute bar to employment. \n \n  Pursuant to Illinois Law, applicants are not obligated to disclose sealed or expunged records of conviction or arrest. \n \n  Pursuant to Columbia, SC ordinance, this position is subject to a background check for any convictions directly related to its duties and responsibilities. Only job-related convictions will be considered and will not automatically disqualify the candidate. \n \n  California Residents only \n  If you are a California resident as defined in the California Consumer Privacy Act (CCPA) please view our  Supplemental Privacy Statement  which describes your rights and disclosures about your personal information. If you are viewing this on a mobile device you may want to view the CCPA version on a larger device. \n \n  Pursuant to the Los Angeles Fair Chance Initiative for Hiring Ordinance, JLL will consider for employment all qualified Applicants, including those with Criminal Histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles\u2019 Fair Chance Initiative for Hiring Ordinance. \n \n  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.", "cleaned_desc": "JLL supports the Whole You, personally and professionally. \n  Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you\u2019ve got deep experience in commercial real estate, skilled trades, and technology, or you\u2019re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally. \n \n  Job Summary: \n \n  Our dedicated on-account Business Intelligence (BI) team is seeking a Business Intelligence and Analytics Senior Analyst. The role joins a team of BI professionals supporting a large strategic client with a key focus on producing a growing array of BI solutions (dashboards, reports, apps, trackers, etc.). You will partner with data owners to understand business requirements and common reporting/analysis use cases and work with technical and business teams to define appropriate solutions. In addition, the role will be expected to maintain an analytical mindset that will uncover several perspectives on a problem or opportunity, determining any and all drivers towards or barriers to successful performance, and makes recommendations based on what is discovered.  \n \n To be successful in this role, you should be a confident professional with broad skills in analyzing and solving complex business problems, writing and presenting, facilitating and influencing. This includes being able to extrapolate data and be able to forecast and trend performance data as well as analyze trends of Key Performance Indicator results for performance improvement concepts. You should be familiar working within a data warehouse, as well as be able to provide hands-on support to data from a variety of sources, build reporting and meta-data models to support strategic data initiatives and design complex reports and dashboards based on requirements.  \n \n Areas of Responsibility: \n \n  Business Intelligence Reporting & Analytics: \n \n  Perform data management analysis using SQL, including retrieving data from multiple sources, profiling, processing, validating, and migrating data to centralized data platforms \n  Regularly work in SQL and be able to create views, tables, and develop queries to answer questions \n  Design, develop and deploy BI solutions, including interactive dashboards in Tableau, sourcing data from internal SQL Server databases, Tableau published data sources, external sources, and leveraging ETL tools when needed. \n  Devise and promote creative data visualizations, reports, tools and dashboards to derive actionable real-time insights to business data pertinent to the audience (SSRS, Tableau, ect.) \n  Validate the calculations and results against known figures, other reports, peer reviews, etc. \n  Develops, executes and monitors simple to moderately complex data management / analytic processes to support ad hoc data and information delivery for assigned projects. \n  Proactively identify opportunities to optimize the performance and efficiency of existing processes/procedures \n  Translate the business questions and hypothesis into a data analysis plan. Execute the analysis either autonomously or in collaboration with others, depending on what the task calls for. Translate the results of the analysis into actionable recommendations and concrete answers to the business questions. \n  Independently develop, execute, and monitor complex data management/analytic processes to ensure deadlines are met for all assigned deliverables. \n  Financial modeling, analysis and compilation of quantitative data \n  Forecast/trending of performance data.    Process mapping and efficiency analysis \n  Provide subject matter expertise for all data related processes and analysis. \n \n \n  Data Validation & Governance Assistance: \n \n  Leverage industry tools (i.e. Alteryx/SSMS) to assess data quality and assist to resolve data quality problems. \n  Assist the BI and Analytics team and Work Dynamic data governance leads to define and document data remediation activities, processes and quality rules. \n  Work with business line data stewards and other stakeholders to identify remediation actions when Critical data quality falls below the accepted threshold. \n  Validate and cleanup input data, ensure assumptions are correct, manage outliers appropriately, raise any questions or issues with the input data if any exists, and help find the root cause of those issues \n \n \n  Interpersonal/Communication: \n \n  Present in front of management groups as the subject matter expert on specific reports or modeling. \n  Excellent presentation skills (verbal and written), Strong understanding of analytic/statistical concepts with the ability to explain them to others. \n  Collaborate with other analysts, data scientists and leaders to get to the best solution for complex questions. \n  Lead problem solving teams to develop recommendations based on data interpretation and analysis to transform behaviors and techniques \n  Work closely with business stakeholders to understand business questions/requirements/opportunities, and to support the accurate business usage and interpretation of JLL data as well as provide insight/answers to meet the needs of the business. \n  Engage with colleagues and internal customers to reverse engineer existing business processes and identify core business requirements for new information deliverables and data infrastructure \n  Distribute reports on a regular cadence as defined by the specific task \n \n \n  Skills & Qualifications:   \n  Bachelor\u2019s degree in Business Administration, Information Systems, Data Analytics, Information Technology, Construction or Project Management, or related field \n  2+ years of BI, business or data analyst experience required ideally in an enterprise environment across multiple application systems and business functions. \n  2+ years of business experience in Corporate Real Estate, Construction Management, Transaction Management and Lease Brokerage, Property Management or related field \n  High level of technical skills with demonstrated ability to manage, manipulate, analyze raw data, research data issues, draw conclusions, provide resolution, and develop actionable recommendations. \n  Business analysis, consulting/advisory and/or project or client management experience will be a strong plus. \n  Strong SQL skills with experience developing complex queries and stored procedures \n  Proficient user of Microsoft Office applications (Excel, Word, PPT) \n  Experience with data visualization tools, Tableau preferred \n  Proficiency in ETL processes/tools - Alteryx Preferred \n  Exposure to SharePoint Power Applications and SSRS (Report Builder) a plus \n  Comfortable with senior managers and clients; can present without undue tension and nervousness \n  Excellent interpersonal skills - Ability to collaborate across many levels \n  Excellent oral, written, and presentation communication skills. \n  Knowledge of data lifecycle and maintenance processes \n  Experience with Agile methodologies and framework a plus. \n  Must have demonstrated experience in building and analyzing reports and dashboards along with summarizing the data for business users - Able to take abstract ideas or requirements and work independently towards development of a report/dashboard. \n  Reliable, self-motivated, and self-disciplined individual capable of planning and executing multiple projects simultaneously within a fast-paced environment \u2013 works well in a remote environment. \n  Impeccable attention to details and never compromising attitude for data accuracy. \n \n \n  Location \n \n  West Coast or Southwest USA ideal but anywhere in continental US is acceptable. ", "techs": ["tableau", "sql server", "etl tools", "ssrs", "alteryx", "ssms", "sharepoint power applications", "excel", "word", "ppt"]}, "e52647d51fab5bb4": {"terms": ["data analyst"], "salary_min": 68009.375, "salary_max": 86115.03, "title": "Analyst, Content Analytics", "company": "Recurrent Ventures", "desc": "About Us \n \n  Recurrent Ventures Inc. is an innovative digital media company that is challenging the media landscape with its proprietary approach. Its best-in-class brands like Popular Science, Domino, Outdoor Life, The Drive, Donut, Dwell, Task & Purpose and more, engage a combined audience of more than 60 million monthly visitors. Initially founded in 2018, the portfolio rapidly expanded and today we have more than 15 publishing brands across automotive, home, outdoors, science, technology, and military verticals. Recurrent Ventures is virtual first, with headquarters in Miami and offices in New York, San Diego, Los Angeles and San Francisco. \n \n  Summary \n The Analyst, Content Analytics will sit between the worlds of content performance data and editorial strategy as they assist in the creation of profitable content across Recurrent Ventures\u2019 portfolio of brands. They will be a primary user of Recurrent\u2019s content performance analytics tools\u2013 translating insights into regular content planning recommendations for content teams. This person will collaborate daily with our business operations, technology, and editorial teams to build world-class content experiences for our audiences and drive measurable results for the business. \n Responsibilities \n \n \n Create and maintain reports that illustrate which characteristics of content drive the best experiences for our audiences and results for the business. Monitor daily and weekly dashboards to understand audience trends and the results of our content strategies. \n Share learnings with key stakeholders, creating data visualizations, sharing findings in group presentations, and surfacing intel on portfolio- and media industry-wide trends. \n Perform data cleaning and aggregation to ensure data accuracy and integrity. \n Identify, analyze, and interpret trends or patterns in complex data sets. \n Distill large data sets into a more easily digestible format that can be translated into actionable insights. \n Study search demand to identify content opportunities. Collaborate across teams to implement identified content opportunities. \n Monitor and analyze competitors. \n Partner with the product and engineering teams to vet and develop new content performance data sources and create ongoing efficiencies within key BI tools, such as Looker and Google Analytics. \n Serve as a data guide and teacher, helping others make better data-driven decisions, read and understand reporting, and build their own bespoke reports. \n  Qualifications \n \n \n A Bachelor\u2019s Degree from an accredited four year college or university in Business Administration, Mathematics, or other related field is preferred. \n At least two (2) years of experience in data analytics with an emphasis on content analytics. \n A general understanding of digital media audiences. \n Experience with SQL and comfortable with sourcing, merging, and working with multiple, disparate data sets. \n Experience with Google Analytics, Wordpress, Looker, and/or PowerBI a plus. \n Ability to analyze, interpret, and visualize data into clean, clear, and digestible dashboards and reports. \n Demonstrated entrepreneurial spirit. \n Strong organizational and communication skills. \n Strong Excel skills. \n Writing or editing background is a plus. \n  Benefits & Perks \n \n \n \n Medical, dental, vision & life insurance \n Fitness Reimbursement \n Unlimited PTO \n Remote - work from anywhere! \n Parental leave \n Matching 401k \n Equity package \n \n Hiring & Equal Opportunity Statement:  Recurrent Ventures provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type with regard to race, ethnicity, national origin, color, religion, age, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic or affiliation protected by federal, state or local laws. With a number of our media brands reporting on the military, veterans\u2019 affairs, and topics facing the active military community, we are very supportive of veterans\u2019 activities and highly encourage this community to apply.", "cleaned_desc": " Partner with the product and engineering teams to vet and develop new content performance data sources and create ongoing efficiencies within key BI tools, such as Looker and Google Analytics. \n Serve as a data guide and teacher, helping others make better data-driven decisions, read and understand reporting, and build their own bespoke reports. \n  Qualifications \n \n \n A Bachelor\u2019s Degree from an accredited four year college or university in Business Administration, Mathematics, or other related field is preferred. \n At least two (2) years of experience in data analytics with an emphasis on content analytics. \n A general understanding of digital media audiences.   Experience with SQL and comfortable with sourcing, merging, and working with multiple, disparate data sets. \n Experience with Google Analytics, Wordpress, Looker, and/or PowerBI a plus. \n Ability to analyze, interpret, and visualize data into clean, clear, and digestible dashboards and reports. \n Demonstrated entrepreneurial spirit. \n Strong organizational and communication skills. \n Strong Excel skills. \n Writing or editing background is a plus. \n  Benefits & Perks ", "techs": ["looker", "google analytics", "sql", "wordpress", "powerbi", "excel"]}, "c4bde1d750baa0e4": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Marketing Campaign Analyst", "company": "PSCU", "desc": "Join the people helping people.\n  \n \n \n   For people drawn to serving others through their work, PSCU is a place to thrive, as we serve our credit union members best by taking care of each other first.\n  \n \n \n   PSCU is a proud recipient of the \n   \n   2023 Gallup Exceptional Workplace Award\n    and has been named to the \n   \n   Forbes list of America\u2019s Best Midsize Employers 2023\n   ! These recognitions reflect the strength of our culture and core values, which help PSCU grow, evolve and foster a highly engaged workforce.\n  \n \n \n   If you want to help shape an industry, challenge yourself, and invest in your own future, this is the place for you. PSCU is a highly accessible environment where you\u2019re empowered to think on your feet, work from your heart, and discover the very best version of your professional and personal self. \u201cOur Momentum. Your Moment.\u201d\n  \n \n \n   This application is the first step in seizing your moment.\n  \n \n \n   This position has a marketing focus on reducing the risks related to a marketing initiative or campaign project. In this regard, the analyst will track campaigns and segment the customer base, as well as identify market trends and monitor competitors. Likewise, they consider aspects such as response rates, return on investment (ROI), and consumer dropout rates. The position is responsible for redefining data-driven findings and conclusions into meaningful consultative recommendations and related planning and execution of marketing campaigns for our financial institutions.\n  \n \n \n \n    Essential Functions & Responsibilities\n   \n \n \n  Consult with key personnel at assigned client credit unions on a regular basis to identify, develop, and implement strategies that demonstrate the effective use of PSCU solutions and campaigns to drive the growth and success of the client\u2019s card portfolios. \n  Deliver on requests for data and reports from the Advisors Plus Consulting team and find, prioritize and design meaningful information patterns from various sources of data, including deep dive investigations using data analytics tools, and provide insight and to trends. \n  Participate and provide industry marketing expertise to align with competitive market. \n  Document and maintain driven matrices relative to competition \u2013 for both our Advisors Plus Consulting services as well as Owner credit union products and services. \n  Assist leadership team in developing and deploying new Advisors Plus campaign and automation. \n  Execute financial performance models (cost/benefit, present value, P&L\u2019s and other financial modeling techniques) to develop and understand projected performance of member/owner portfolios and PSCU combined portfolios. \n  Maintain and run risk performance models, including Vintage Analysis. \n  Track and reconcile billing of Advisors Plus consulting services as well as the management and audit of client discounts provided for through a processing contract. \n  Maintain work papers, data, plans, methods and results in a way that can be recreated and leveraged as intellectual capital. \n  Create written and verbal communication materials that optimally summarize findings, supports fact-based recommendations and provides appropriate detail to substantiate conclusions. \n  Identify the data, and data sources required to investigate, evaluate and discover insight about credit union portfolios and campaigns. \n  Develop, solidify and maintain strong member/owner relationships by learning more about their organization, culture and goals. \n  Maintain effective communication with other corporate functional areas to attain common goals. \n  Remain current with Visa, MasterCard, FDR and industry products and services and keep abreast of the competitive, economic and regulatory environment. \n  Perform market research, as needed. \n  Perform other duties as assigned. \n \n \n \n \n    Physical Demands\n   \n \n \n  While performing the duties of this Job, the employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear \n  Specific vision abilities required by this job include close vision \n  Ability to occasionally lift/move up to 25 pounds \n  Individuals with a disability who are otherwise able to perform the essential functions of the job may request a reasonable accommodation through the Human Resources department. \n \n \n \n \n    Supervisory Responsibility\n   \n \n \n  No \n \n \n \n  Position Specifications \n \n \n  Bachelor\u2019s Degree in Business, Marketing, Mathematics, Accounting, Finance, Statistics other related field or combination of education and experience required. \n  Four (4) years of marketing quantitative analysis experience and/or direct credit card, debit, and digital marketing required. \n  Client service experience and experience using SAS and Teradata tools preferred. \n  Knowledge of underwriting practices, collection practices, credit unions service models, credit and debit processing, fees, interchange, and pricing. \n \n \n \n \n    Knowledge, Skills, & Abilities\n   \n \n \n  Demonstrate behaviors based on PSCU values: Excellence, Innovation, Leadership, Passion, Trust and Diversity, Equity, & Inclusion \n  Ability to communicate effectively in both verbal and written formats and give presentations utilizing various audiovisual support aids \n  Ability to manage multiple projects, work in fast-paced environment, and meet deadlines \n  Proven analytical and quantitative skills; use of statistical and other quantitative tools to analyze data, identify trends and opportunities \n  Ability to exercise discretion and good judgment in making decisions \n  Proficiency in spreadsheet computer software applications, Power Point, SAS and SAP, Oracle, Access; exposure to third party software systems \n  Minimal travel may be required \n  Ability to maintain confidentiality of materials handled \n  Ability to be flexible and work under high pressure in a complex environment \n \n \n \n  Pay Equity\n  \n \n   PSCU is committed to pay equity and a competitive benefits package. The hiring amount for this position based on relevant experience and internal equity; the pay range is:\n   $56,600.00\n  \n   to\n   $93,400.00\n  \n Note: T he amount shown is based on full time annual salary and would be prorated based on role. \n \n \n \n   In addition this position is eligible for an incentive plan, based on performance.\n  \n \n \n   Benefits\n  \n \n   At PSCU, everything we do recognizes the fact that our employees are our most important asset. That\u2019s why we are committed to a work/life integration that goes above and beyond to ensure that you have quality time at home with your family and/or to pursue outside interests and aspirations. We back this up with generous PTO, the opportunity to work remotely, flexible scheduling, and a management team that understands how to adjust when the unexpected curveballs of life happen.\n  \n \n   Check out the comprehensive benefits PSCU has to offer that further solidifies our reputation as a company that just \u201cgets it\u201d when it comes to balancing life\u2019s planned and unplanned events while equipping you with all the tools for growth.\n  \n \n \n   PSCU offers:\n  \n \n \n \n     Beautiful, state-of-the-art campus\n    \n \n \n     Endless opportunities for advancement\n    \n \n \n     Competitive wages\n    \n \n \n     Generous paid time off and paid holidays\n    \n \n \n \n   Our benefits package includes:\n  \n \n \n \n     Medical with telemedicine, no-cost diabetes supply program, and expert medical opinion services\n    \n \n \n     Dental and Vision\n    \n \n \n     Basic and Optional Life Insurance\n    \n \n \n     Company Paid Disability Insurance\n    \n \n \n     401k (with employer match)\n    \n \n \n     Health Savings Accounts (HSA) with company provided contributions\n    \n \n \n     Flexible Spending Accounts (FSA)\n    \n \n \n     Supplemental Insurance\n    \n \n \n     Legal Plan\n    \n \n \n     Pet Insurance\n    \n \n \n     Adoption Assistance Plan\n    \n \n \n     Mental Health and Well-being: Employee Assistance Program (EAP)\n    \n \n \n     Mental health and Well-being: Virtual mental health support and resources\n    \n \n \n     Tuition Reimbursement\n    \n \n \n     Wellness program\n    \n \n \n     Back-up child care program\n    \n \n \n     Benefits are subject to generally applicable eligibility, waiting period, contribution, and other requirements and conditions.\n    \n \n \n \n   PSCU is committed to health and safety of all who enter our workplace. If this position requires you to report onsite at a PSCU location, employee attentiveness and cooperation with PSCU Employee Safety Workplace Protocols is critical.\n  \n \n \n   Please Note: For roles with certain levels of travel and/or company car usage, PSCU will require a completed Motor Vehicle Record Check, valid driver's license, and proof of insurance at time of hire and annually.\n  \n \n \n   All applications are reviewed by an AIRS Certified Diversity and Inclusion Recruiter.\n  \n \n \n  PSCU is an Equal Opportunity Employer. We consider applicants without regard to race, color, religion, age, national origin, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, marital status, veteran status, disability, genetic information, citizenship status, or membership in any other group protected by federal, state or local law. \n \n \n \n  PSCU is an Equal Opportunity Employer that complies with the laws and regulations set forth in the following  \n \n \"EEO is the Law\" Poster \n \n  and the  \n \n \"EEO is the Law\" Poster Supplement \n \n . PSCU will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the legal duty to furnish information. \n \n \n \n  PSCU is an E-Verify Employer. Review the E-Verify Poster  \n \n   here\n    (English and Spanish).\n    For information regarding your Right To Work, please click  \n \n here \n \n  (English and Spanish poster). \n \n \n \n  As an ongoing commitment to reasonably accommodate individuals with disabilities \n  please contact a recruiter at  \n \n recruiters@pscu.com \n \n   \n for assistance.", "cleaned_desc": "", "techs": ""}, "e7f81476eeff3b30": {"terms": ["data analyst"], "salary_min": 113959.586, "salary_max": 144298.23, "title": "Sr. Business Analyst - Information Security", "company": "Gallagher", "desc": "About Us: \n  \n   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 45,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.\n  \n \n \n \n \n  At Gallagher, you can build a career whether it\u2019s with our brokerage division, our benefits and HR consulting division, or our corporate team. \n  Overview: \n  \n   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 30,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.\n  \n \n \n  The \n   Information Security Sr. Business Analyst  is responsible for supporting the successful delivery of projects for the Global Cyber and Information Security Team which meet the defined business and technical requirements.\n  \n \n \n  This position reports to the Global Cyber & Information Security Program Leader. A key focus of this position is to participate in supporting a wide range of projects across the Cyber & Information Security team.\n  \n \n \n  Project Team members are critical resources, providing the necessary skills and experience to complete the project successfully. Members are responsible for: establishing priorities and completing deliverables as scheduled; identifying and escalating issues and barriers; participating in communication and change management plans, and providing input in support of reporting progress.\n  \n \n \n  Please note additional position details below:\n  \n \n  This is a Temp-To-Hire, W-2 position. We are not able to do 1099 or C2C. \n  It is a fully remote role that will need to be based in the U.S. \n  You must meet our U.S. Eligibility requirements for work authorization as noted under \"Additional Information\" at the bottom of the job description. \n  Responsibilities: \n  \n   Essential Duties and Responsibilities:\n  \n \n  Under the leadership of a Project Manager, participate in multiple projects by completing and updating project documentation; managing project scope; adjusting schedules when necessary; determining daily priorities; ensuring efficient and on-time delivery of project tasks and milestones; following proper escalation paths; and managing customer and supplier relationships \n  Provide leadership to team members and peers by collaborating with others; articulating ideas and viewpoints to Project Manager, peers and others; driving the resolution of issues; and taking personal responsibility for results \n  Identify, create and facilitate process design changes by conducting business and systems process analysis and design at a complex level; focusing on quality improvement and data management; ensuring data is reliable and valid; developing process improvements or re-engineering and recommending elimination; integrating new systems and processes with existing ones; and partnering with internal and external customers to ensure systems provided meet the long-term business strategies \n  Support the implementation of solutions by building relationships and partnerships with key stakeholders; understanding business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes and new responsibilities \n  Provide project level analysis \u2013 producing required project analysis documentation (business requirements, scope matrix, use cases, sequence diagrams, future state proposals, UAT plan) \n  Collaborate closely with project stakeholders to implement the requirements, provide necessary guidance to testers during QA process \n  Identify improvement opportunities (proactive and reactive) \n  Elicit and clearly document business, functional, and technical requirements \n  Assess business process and system inefficiencies \n  Identify ways to increase adoption and customer satisfaction \n  Demonstrated fluency in business processes and process differentiation \n  Ability to analyze and synthesize business requirements, including recognizing patterns and conceptualizing processes \n  Understand and negotiate needs and expectations of multiple stakeholders \n  Serve as a liaison between Cyber & Information Security and other teams to assist or gather business requirements needed for system modifications, enhancement and implementations \n  Assist with test planning, development, and execution to ensure the successful delivery of cyber and information security solutions, while minimizing negative impacts to the customer \n  Create and maintain issue logs, meeting minutes, meeting schedules, project summaries and updates. \n  Meet with Project Team regularly to review project deliverables and deadlines \n  Support new solution implementations, system conversions, upgrades, and enhancements \n  Responsible for creating or coordinating the creation of required project artifacts \n  Manages project repository in Microsoft Teams / SharePoint \n  Interacts closely with project stakeholders \n  Operationally troubleshoots complex issues \n  Highly self-motivated - functions under broad supervision \n  Other project and support activities as appropriate \n  Qualifications: \n  \n   Qualifications:\n  \n \n   Required:\n  \n \n  Bachelor's degree in Business, Information Technology, Cybersecurity or related field \n  Minimum of 10 years of Business Analysis experience  \n Technology acumen (working knowledge) and awareness of key infrastructure, networking, IT operations and cyber & information security processes \n  Experience working with third party vendors to implement SaaS solutions.  \n Working \"hands-on\" knowledge of Software Development Life Cycle and project management methodologies \n \n \n \n  Preferred:\n  \n \n  Certified Business Analysis Professional (CBAP) certification (highly preferred) \n  Experience working on information security initiatives \n  Experience working with off-shore or remote teams \n \n \n \n  Behaviors:\n  \n \n  Ability to work on information security initiatives and to collaborate effectively with stakeholders at many levels \n  Must have strong team orientation and seek team and colleague success as the priority \n  Ability to drive consensus among various stakeholders, including technology stakeholders and third parties \n  Excellent written and verbal communication skills  \n Excellent organization skills  \n Strong attention to detail  \n Demonstrated ability to prioritize and manage multiple initiatives simultaneously \n  Ability to work at a fast pace and cope with conflicting deadlines \n  Proven ability to deliver excellent customer service \n  Good analytical and problem solving skills \n  Dependable, hardworking, professional, self-starter, able to work well with cross functional teams \n \n \n \n  Work Traits:\n  \n \n  Ability to work independently and prioritize work load \n \n \n \n  #contingent\n  \n \n   #LI-KB3\n   Additional Information: \n  \n   Click Here to review our U.S. Eligibility Requirements\n  \n \n \n  We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more.", "cleaned_desc": "  Minimum of 10 years of Business Analysis experience  \n Technology acumen (working knowledge) and awareness of key infrastructure, networking, IT operations and cyber & information security processes \n  Experience working with third party vendors to implement SaaS solutions.  \n Working \"hands-on\" knowledge of Software Development Life Cycle and project management methodologies \n \n \n \n  Preferred:\n  \n \n  Certified Business Analysis Professional (CBAP) certification (highly preferred) \n  Experience working on information security initiatives \n  Experience working with off-shore or remote teams \n \n \n \n  Behaviors:\n  \n \n  Ability to work on information security initiatives and to collaborate effectively with stakeholders at many levels \n  Must have strong team orientation and seek team and colleague success as the priority \n  Ability to drive consensus among various stakeholders, including technology stakeholders and third parties \n  Excellent written and verbal communication skills  \n Excellent organization skills  ", "techs": ["certified business analysis professional (cbap) certification", "software development life cycle", "project management methodologies", "saas solutions", "information security initiatives", "off-shore or remote teams"]}, "f88ddc55aa9f5146": {"terms": ["data analyst"], "salary_min": 102000.0, "salary_max": 120000.0, "title": "Lead Business Intelligence Developer/Analyst - CAESAR (Work from Home)", "company": "Transamerica", "desc": "Job Family\n   Business Intelligence\n  \n \n \n    Who We Are\n   \n \n \n \n \n  Transamerica has been helping people feel better about the future for more than 100 years. We provide investment, retirement, and life insurance solutions to more than 11 million customers throughout the U.S. But the way we see it, our responsibility goes beyond our clients\u2019 accounts. We\u2019re in the business of helping people live well and empowering them to create a better tomorrow through the financial and health-related habits they form today. We help people prepare by providing solutions that consider the whole picture.\n   \n \n \n    What We Do\n   \n \n \n    Transamerica is organized by lines of business (Life Insurance, Annuities, Mutual Funds, Retirement Plans, Employee Benefits, and Financial Assets), which are supported by Transamerica Corporate (Corporate Development; Finance; Internal Audit; Legislative, Regulatory & Policy; Office of the CEO; People, Places & Brand; Risk; and Technology).\n   \n \n \n \n   Job Description Summary\n   Responsible for leading the development of the Business Intelligence and Analytics products and platforms, including but not limited to data warehouse, data visualizations and interactive reports from a technical perspective. Applies Business Intelligence and Analytics subject matter expertise (data modeling, data discovery, BI product offering development and conceptual insurance acumen) to provide the business support departments with the tools and data representations which allow increasing organizational profit and meeting strategic goals.\n  \n  For more than 20 years, World Financial Group, a Transamerica company, has helped countless individuals and families find financial security through our life insurance, retirement, and wealth-building strategies.\n  \n   Job Description\n  \n \n \n   Responsibilities\n  \n \n  Lead the development of database or data presentation solutions to deliver information to end-users accurately and efficiently \n  Extensive knowledge/experience with SQL & relational databases (ideally Informix). If they are going to investigate problems and make changes/create new programs for Caesar, they need experience with Informix 4GL and/or 4Js Genero BDL. They also need experience with AIX or equivalent operating system and shell scripting \n  Analyze, understand and document user needs to ensure accurate fulfillment of user story request for internal business customers \n  Continuously develop and maintain an understanding of Business Intelligence technology and architecture, including data warehousing, dimensional modeling, OLAP functionality, reporting tools and other methods of information delivery \n  Extract, transform and load data using data management tools in T-SQL/4GL \n  Contribute to and lead project teams that are developing or modifying highly complex information solutions \n  Continuously develop expertise in the data and data models within the data warehouse, as well as an understanding of supported business domains \n  Administer and maintain the data warehouse \n  May construct data models, data dictionaries and report glossaries \n  May conduct user interview and training sessions \n  Conduct and may facilitate internal testing and user acceptance testing \n \n \n \n   Qualifications\n  \n \n  Bachelor\u2019s degree in a relevant field or equivalent experience \n  Seven years of experience in business intelligence or data management \n  Strong understanding of data management concepts and tools \n  Experience with Informix databases \n  Experience with 4Js or similar low code application development framework \n  Significant experience developing physical dimensional models or data visualizations \n  Significant experience in data modeling, data discovery and the application of data to resolve business problems \n  Problem-solving ability and a willingness to think \u201coutside-the-box\u201d \n \n \n \n   Compensation\n  \n \n \n  **Please note that the compensation information that follows is a good faith estimate for this position only and is provided pursuant to applicable pay transparency and compensation posting laws. It is estimated based on what a successful candidate might be paid in certain Company locations.** \n \n \n \n   The Salary for this position generally ranges between $102,000 - $120,000 annually. This range is an estimate, based on potential qualifications and operational needs. Salary may vary above and below the stated amounts, as permitted by applicable law.\n  \n \n \n   Additionally, this position is typically eligible for an Annual Bonus based on the Company Bonus Plan/Individual Performance and is at the Company\u2019s discretion.\n  \n \n \n   Working Conditions\n  \n \n  Office environment \n  Work from home \n  Occasional travel may be required \n \n \n \n   #LI-Remote\n  \n \n \n   What We Offer\n  \n \n \n \n  For eligible employees, we offer a comprehensive benefits package designed to support both the personal and financial well-being of our employees.\n   \n \n \n \n \n  Compensation Benefits\n   \n \n \n \n \n \n \n       Competitive Pay\n      \n \n \n       Bonus for Eligible Employees\n      \n \n \n \n \n \n  Benefits Package\n    \n \n \n \n \n \n       Pension Plan\n      \n \n \n       401k Match\n      \n \n \n       Employee Stock Purchase Plan\n      \n \n \n       Tuition Reimbursement\n      \n \n \n       Disability Insurance\n      \n \n \n       Medical Insurance\n      \n \n \n       Dental Insurance\n      \n \n \n       Vision Insurance\n      \n \n \n       Employee Discounts\n      \n \n \n       Career Training & Development Opportunities\n      \n \n \n \n \n \n \n \n  Health and Work/Life Balance Benefits\n    \n \n \n \n \n \n       Paid Time Off starting at 160 hours annually for employees in their first year of service.\n      \n \n \n       Ten (10) paid holidays per year (typically mirroring the New York Stock Exchange (NYSE) holidays).\n      \n \n \n       Be Well Company holistic wellness program, which includes Wellness Coaching and Reward Dollars\n      \n \n \n       Parental Leave \u2013 fifteen (15) days of paid parental leave per calendar year to eligible employees with at least one year of service at the time of birth, placement of an adopted child, or placement of a foster care child.\n      \n \n \n       Adoption Assistance\n      \n \n \n       Employee Assistance Program\n      \n \n \n       College Coach Program\n      \n \n \n       Back-Up Care Program\n      \n \n \n       PTO for Volunteer Hours\n      \n \n \n       Employee Matching Gifts Program\n      \n \n \n       Employee Resource Groups\n      \n \n \n       Inclusion and Diversity Programs\n      \n \n \n       Employee Recognition Program\n      \n \n \n       Referral Bonus Programs\n      \n \n \n       Peer Recognition Program (BRAVO)\n      \n \n \n \n \n \n \n  Inclusion & Diversity\n   \n \n \n \n \n  Transamerica has made a strong commitment to inclusion and diversity, and we are proud to be an organization where all perspectives are valued. Transamerica has earned recognition for its strong efforts year-over-year, including from the Human Rights Campaign\u2019s Foundation Corporate Equality Index, the Diversity Best Practices Inclusion Index, and Seramount\u2019s \u201c100 Best Companies\u201d list.\n   \n \n \n \n \n  In addition, as part of Transamerica\u2019s commitment to maintaining an inclusive workplace, the company sponsors employee-driven Employee Resource Groups (ERGs), which are formed around a shared interest or a common characteristic of diversity. ERGs are open to all employees and provide a supportive environment for raising diversity awareness and promoting inclusive behavior.\n   \n \n \n \n \n  Giving Back\n   \n \n \n \n \n  Transamerica believes our responsibilities extend beyond our corporate walls. That's why we created the Aegon Transamerica Foundation in 1994. Through a combination of financial grants and the volunteer commitment of our employees, this foundation supports nonprofit organizations focused on the education, health, and well-being of the communities where we live and work.\n   \n \n \n \n \n \n  https://www.transamerica.com/why-transamerica/aegon-transamerica-foundation\n    \n \n \n \n \n \n  Transamerica\u2019s Parent Company\n   \n \n \n \n \n \n     Aegon\n     acquired the Transamerica business in 1999. Aegon\u2019s roots go back more than 175 years to the first half of the nineteenth century. Since then, Aegon has grown into an international company, with businesses in the Americas, Europe, and Asia. Today, Aegon is one of the world\u2019s leading financial services organizations, providing life insurance, pensions, and asset management. As a leading global investor and employer, the company seeks to have a positive impact by addressing critical environmental and societal issues, with a focus on climate change and inclusion and diversity.", "cleaned_desc": "Job Family\n   Business Intelligence\n  \n \n \n    Who We Are\n   \n \n \n \n \n  Transamerica has been helping people feel better about the future for more than 100 years. We provide investment, retirement, and life insurance solutions to more than 11 million customers throughout the U.S. But the way we see it, our responsibility goes beyond our clients\u2019 accounts. We\u2019re in the business of helping people live well and empowering them to create a better tomorrow through the financial and health-related habits they form today. We help people prepare by providing solutions that consider the whole picture.\n   \n \n \n    What We Do\n   \n \n \n    Transamerica is organized by lines of business (Life Insurance, Annuities, Mutual Funds, Retirement Plans, Employee Benefits, and Financial Assets), which are supported by Transamerica Corporate (Corporate Development; Finance; Internal Audit; Legislative, Regulatory & Policy; Office of the CEO; People, Places & Brand; Risk; and Technology).\n   \n \n \n \n   Job Description Summary\n   Responsible for leading the development of the Business Intelligence and Analytics products and platforms, including but not limited to data warehouse, data visualizations and interactive reports from a technical perspective. Applies Business Intelligence and Analytics subject matter expertise (data modeling, data discovery, BI product offering development and conceptual insurance acumen) to provide the business support departments with the tools and data representations which allow increasing organizational profit and meeting strategic goals.\n  \n  For more than 20 years, World Financial Group, a Transamerica company, has helped countless individuals and families find financial security through our life insurance, retirement, and wealth-building strategies.\n  \n   Job Description\n  \n \n \n   Responsibilities\n  \n \n  Lead the development of database or data presentation solutions to deliver information to end-users accurately and efficiently \n  Extensive knowledge/experience with SQL & relational databases (ideally Informix). If they are going to investigate problems and make changes/create new programs for Caesar, they need experience with Informix 4GL and/or 4Js Genero BDL. They also need experience with AIX or equivalent operating system and shell scripting \n  Analyze, understand and document user needs to ensure accurate fulfillment of user story request for internal business customers \n  Continuously develop and maintain an understanding of Business Intelligence technology and architecture, including data warehousing, dimensional modeling, OLAP functionality, reporting tools and other methods of information delivery \n  Extract, transform and load data using data management tools in T-SQL/4GL \n  Contribute to and lead project teams that are developing or modifying highly complex information solutions \n  Continuously develop expertise in the data and data models within the data warehouse, as well as an understanding of supported business domains \n  Administer and maintain the data warehouse \n  May construct data models, data dictionaries and report glossaries \n  May conduct user interview and training sessions \n  Conduct and may facilitate internal testing and user acceptance testing \n \n \n \n   Qualifications\n  \n \n  Bachelor\u2019s degree in a relevant field or equivalent experience \n  Seven years of experience in business intelligence or data management \n  Strong understanding of data management concepts and tools \n  Experience with Informix databases \n  Experience with 4Js or similar low code application development framework ", "techs": ["business intelligence", "data warehouse", "data visualizations", "interactive reports", "sql", "relational databases", "informix", "informix 4gl", "4js genero bdl", "aix", "shell scripting", "t-sql/4gl", "dimensional modeling", "olap functionality", "reporting tools", "data management tools"]}, "6bbac020066f0892": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Cybersecurity Analyst - Solution Security Validation Team (Remote)", "company": "Home Depot / THD", "desc": "Position Purpose: \n  The Cybersecurity Analyst - Solution Security Validation Team collaborates with technology stakeholders to validate the implementation of technology controls prescribed by Cybersecurity standards for PSRB-approved production solutions prior to or shortly after go-live \n  The Cybersecurity Analyst - Solution Security Validation Analyst supports efforts to validate, identify, and analyze risk and controls prescribed by Cybersecurity standards for PSRB-approved production solutions prior to or shortly after go-live. The Cybersecurity Analyst is responsible for collaborating with key stakeholders to scope in key controls, assess architecture diagrams submitted by IT teams for new and existing products to ensure proper security controls are being used, and analyze data to identify and report on any issues discovered. The Cybersecurity Analyst is expected to be able to work independently as well as supporting other team members to complete deliverables and/or adhoc request or projects. \n  Protecting what matters most to our associates and consumers by securing our sensitive data and critical assets from current and emerging threats. At The Home Depot Cybersecurity consists of Architecture, Governance, Identity & Access Management, Internal Threat Operations, Issue and Compliance Management, Risk Assessment/Advisory, Security Consulting, Security Operations, Service Optimization and Strategic Planning. \n  Analysts perform data gathering, analysis, synthesis and develop solutions to support THD Cybersecurity practices. \n  Key Responsibilities: \n \n  30% Analysis - Perform data gathering, synthesis, and develop solutions; Leverage department standards to achieve results \n  30% Collaborate - Partner with teams to identify trends and resolve problems \n  40% Drive Execution - Evaluate information and provide recommendations based on findings \n \n  Direct Manager/Direct Reports: \n \n  This Position typically reports to Manager or Sr. Manager \n  This Position has 0 Direct Reports \n \n  Travel Requirements: \n \n  Typically requires overnight travel less than 10% of the time. \n \n  Physical Requirements: \n \n  Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles. \n \n  Working Conditions: \n \n  Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable. \n \n \n \n  Minimum Qualifications: \n \n  Must be eighteen years of age or older. \n  Must be legally permitted to work in the United States. \n \n  Minimum Education: \n \n  The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job. \n \n  Competencies: \n \n  Action Oriented \n  Collaborates \n  Communicates Effectively \n  Customer Focus \n  Drives Results", "cleaned_desc": "", "techs": ""}, "c7e6fd3e58fed70e": {"terms": ["data analyst"], "salary_min": 105297.09, "salary_max": 133329.58, "title": "Senior PowerBI Analyst / Remote Mexico Position", "company": "Argano", "desc": "REQUIRED QUALIFICATIONS, EXPERIENCE & SKILLS \n \n 3+ years of experience with Azure SQL DB and SQL Server / T-SQL \n 3+ years of experience developing reporting solutions using Power BI \n PowerBI Data Analyst Associate Certified (PL-300) \n Candidate should be familiar with developing analytics in support of Demand Planning and Supply Chain business processes. \n Experience in developing data marts or data warehouse solutions utilizing star schema. \n Experience with Data Lakehouse architecture \n Experience in gathering reporting requirements directly from business stakeholders. \n Experience developing solutions with Azure Data Lake \n Experience with Git version control and Azure Dev Ops \n Familiarity with security configuration and security policies within Power BI and SQL Server \n \n \n ADDITIONAL QUALIFICATIONS & SKILLS \n \n Azure Enterprise Data Analyst Associate Certified (DP-500) \n Experience with AX2012/Dynamics 365 Finance & Supply Chain data model. \n Exposure to technologies such as Azure Data Lake, Azure Synapse Analytics, Microsoft Fabric \n Bachelor\u2019s Degree in Information Systems Management, Computer Science, or related field. \n Experience working with a multicultural and/or multilingual team across several time zones.", "cleaned_desc": "REQUIRED QUALIFICATIONS, EXPERIENCE & SKILLS \n \n 3+ years of experience with Azure SQL DB and SQL Server / T-SQL \n 3+ years of experience developing reporting solutions using Power BI   PowerBI Data Analyst Associate Certified (PL-300) \n Candidate should be familiar with developing analytics in support of Demand Planning and Supply Chain business processes. \n Experience in developing data marts or data warehouse solutions utilizing star schema. \n Experience with Data Lakehouse architecture   Experience in gathering reporting requirements directly from business stakeholders. \n Experience developing solutions with Azure Data Lake \n Experience with Git version control and Azure Dev Ops \n Familiarity with security configuration and security policies within Power BI and SQL Server   Azure Enterprise Data Analyst Associate Certified (DP-500) \n Experience with AX2012/Dynamics 365 Finance & Supply Chain data model. \n Exposure to technologies such as Azure Data Lake, Azure Synapse Analytics, Microsoft Fabric \n Bachelor\u2019s Degree in Information Systems Management, Computer Science, or related field. ", "techs": ["azure sql db", "sql server / t-sql", "power bi", "powerbi data analyst associate certified (pl-300)", "demand planning", "supply chain", "data marts", "data warehouse solutions", "star schema", "data lakehouse architecture", "gathering reporting requirements", "azure data lake", "git version control", "azure dev ops", "security configuration", "security policies", "azure enterprise data analyst associate certified (dp-500)", "ax2012/dynamics 365 finance & supply chain", "azure data lake", "azure synapse analytics", "microsoft fabric", "bachelor's degree in information systems management", "computer science."]}, "3bdad62c773dd043": {"terms": ["data analyst"], "salary_min": 107110.664, "salary_max": 135625.97, "title": "Business Analyst-DHS public trust or Top Secret", "company": "N4 Information Systems", "desc": "Requirement: \n Understanding of Retirement Services Domain Demonstrated experience as a business analyst in RS domain Omni product knowledge (preferrable) Standard Business Analyst competencies and expertise: ability to elicit requirements, document required capabilities and product features, document and prioritize product roadmap backlog, document user stories, support design, testing and go-live processes. Retirement Services (RC) specific knowledge: At least 7 years experience working on Retirement and specifically Recordkeeping business and technologies. Specifically, ability to document requirements for new product features to enable recordkeeping sales and service. Experience with building capabilities for the full or most of Recordkeeping lifecycle or business process including client onboarding, client service and operations and client retention. Understands regulatory requirements and has experience with projects enabling regulatory compliance. \n Job Types: Contract, Full-time \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 1 year \n \n Schedule: \n \n Monday to Friday \n \n Security clearance: \n \n Top Secret (Required) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "ebb9538e41b32e0d": {"terms": ["data analyst"], "salary_min": 79754.05, "salary_max": 100986.39, "title": "Senior Technical Business Analyst - Core Processing and Reporting", "company": "Jack Henry and Associates, Inc.", "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you. \n \n  Credit Union Solutions is looking for a talented Technical Business Analyst to join our Core Processing and Reporting team. This team is focused on the business processes and back office functionality of the Symitar Core platform. This position will work closely with our efforts to transform our platform into a system that opens accounts, processes transactions, creates reports and in general works how our clients want it to work \u2026 which is 24x7. We are committed to modernizing our processes to make our system more available and resilient. If you are prepared to do what it takes to make this vision a reality, let\u2019s get to work building the future. \n \n  What you\u2019ll be responsible for: \n \n Interacts with internal and external stakeholders to gather requirements. \n Works with Subject Matter Experts to identify functional and non-functional requirements as well as assist in refining those items into testable users stories and acceptance criteria. \n Interacts with technical teams to convey business requirements. \n Defines the system and functional requirements of the product. \n Responsible for creating business requirements and system documentation, as well as contributing to end-user and project management documentation. \n Assists development and QA teams in researching topics, gathering/manipulating/preparing data. \n May write, perform and document application, system and regression test steps and descriptions.  \n Works with our customer facing support teams to help research issues and inquiries from clients. \n May perform other job duties as assigned. \n \n  What you\u2019ll need to have: \n \n Minimum of 6 years of experience in business analysis, systems analysis, or technical position. \n Experience with CU back office software/processes. \n Experience in developing (or assisting the development of) functional and non-functional requirements and translating them into acceptance criteria, testing plans/approaches and test cases. \n Data driven, experienced gathering data, manipulating and analyzing data, presenting result and making recommendations. \n \n \n  What would be nice for you to have: \n \n Prior technical development experience (e.g coding, scripting, testing) \n Experienced in CU back office operations and system administration and CU reporting \n Experience with SCRUM or other Agile discipline. \n Excellent communication and customer interaction skills. \n Experience with Azure DevOps. \n Able to bridge communication gap between technical and business stakeholders. \n Previous experience either directly or indirectly with the financial services industry. \n General project management skills. \n Bachelors Degree in Computer Science or related field. \n \n \n  If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways. \n \n  Why Jack Henry? \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being. \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met. \n \n  Culture of Commitment \n \n  Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders. \n \n  Equal Employment Opportunity \n \n  At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law. \n \n  No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations. \n \n  Requests for full corporate job description may be requested through the interview process at any time.", "cleaned_desc": " Assists development and QA teams in researching topics, gathering/manipulating/preparing data. \n May write, perform and document application, system and regression test steps and descriptions.  \n Works with our customer facing support teams to help research issues and inquiries from clients. \n May perform other job duties as assigned. \n \n  What you\u2019ll need to have: \n \n Minimum of 6 years of experience in business analysis, systems analysis, or technical position. \n Experience with CU back office software/processes. \n Experience in developing (or assisting the development of) functional and non-functional requirements and translating them into acceptance criteria, testing plans/approaches and test cases. \n Data driven, experienced gathering data, manipulating and analyzing data, presenting result and making recommendations.   \n \n  What would be nice for you to have: \n \n Prior technical development experience (e.g coding, scripting, testing) \n Experienced in CU back office operations and system administration and CU reporting \n Experience with SCRUM or other Agile discipline. \n Excellent communication and customer interaction skills. \n Experience with Azure DevOps. \n Able to bridge communication gap between technical and business stakeholders. \n Previous experience either directly or indirectly with the financial services industry. ", "techs": ["cu back office software", "gathering/manipulating/preparing data", "functional and non-functional requirements", "acceptance criteria", "testing plans/approaches", "test cases", "scrum", "agile discipline", "azure devops", "financial services industry"]}, "3f7cde3b1d60c09e": {"terms": ["data analyst"], "salary_min": 100000.0, "salary_max": 117000.0, "title": "SAS Informaticist", "company": "Positive Psyche", "desc": "Skills highlighted (not in order of importance): \n 3+ years of experience in Base & Advanced SAS, preferably with one or more SAS certifications and preferably with extensive macro utilization \n Proven track record in SAS usage of designing, developing, and maintaining data extract/transformation jobs, analytical reporting, and automated programming with reusable and SAS macro driven components \n 3+ years of experience in SQL, preferably with multiple Data Base Management systems and understanding of indexed and efficient table joins \n 3+ years of Tableau dashboard development experience \n Experience with both Clinical and Claims data reporting is required \n Experience with Finance and other health plan reporting is required \n Flexibility \u2013 the ideal candidate can serve in both problem research/resolution and then switch hats to building sustainable process to solve that problem in an efficient manner ongoing \n Project examples \n \u2022Telehealth KPI \u2013 extracting data from multiple Tableau dashboards, to summarize, and give the big picture view. \n 360 view of the data \n \u2022Health Plan finance system projects. \n \u2022 \n \u2022Work directly with the business users, understanding of their requirements , plan and design on your own. \n \u2022 \n \u2022A lot of areas to grow and learn \n \u2022 \n \u2022New tools and technologies in the future. \n Job Type: Full-time \n Pay: $100,000.00 - $117,000.00 per year \n Benefits: \n \n 401(k) \n 403(b) \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid holidays \n Paid sick time \n Paid time off \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n SAS: 3 years (Required) \n SQL: 3 years (Required) \n \n License/Certification: \n \n COVID-19 Vaccination (Required) \n \n Work Location: Remote", "cleaned_desc": "Skills highlighted (not in order of importance): \n 3+ years of experience in Base & Advanced SAS, preferably with one or more SAS certifications and preferably with extensive macro utilization \n Proven track record in SAS usage of designing, developing, and maintaining data extract/transformation jobs, analytical reporting, and automated programming with reusable and SAS macro driven components \n 3+ years of experience in SQL, preferably with multiple Data Base Management systems and understanding of indexed and efficient table joins \n 3+ years of Tableau dashboard development experience \n Experience with both Clinical and Claims data reporting is required \n Experience with Finance and other health plan reporting is required \n Flexibility \u2013 the ideal candidate can serve in both problem research/resolution and then switch hats to building sustainable process to solve that problem in an efficient manner ongoing \n Project examples \n \u2022Telehealth KPI \u2013 extracting data from multiple Tableau dashboards, to summarize, and give the big picture view. \n 360 view of the data ", "techs": ["base sas", "advanced sas", "sas certifications", "macro utilization", "sql", "data base management systems", "tableau", "clinical data reporting", "claims data reporting", "finance reporting", "health plan reporting", "telehealth kpi"]}, "17157813e21293dc": {"terms": ["data analyst"], "salary_min": 65000.0, "salary_max": 80000.0, "title": "Business Analyst I", "company": "University of Nebraska at Omaha", "desc": "GENERAL REQUISITION INFORMATION \n   \n \n \n \n \n \n EEO Statement: \n \n \n      The University of Nebraska does not discriminate based on race, color, ethnicity, national origin, sex, pregnancy, sexual orientation, gender identity, religion, disability, age, genetic information, veteran status, marital status, and/or political affiliation in its education programs or activities, including admissions and employment. The University prohibits any form of retaliation taken against anyone for reporting discrimination, harassment, or retaliation for otherwise engaging in protected activity. \n       Read the full statement. \n \n \n \n \n \n Job Title \n \n \n      Business Analyst I\n      \n \n \n \n \n Job Grade \n \n \n      IT22-S\n      \n \n \n \n \n Division \n \n \n      Institutional Effectiveness and Student Success\n      \n \n \n \n \n College/Dept \n \n \n      Systems Intelligence and Data Analytics\n      \n \n \n \n \n Department \n \n \n      SIDA\n      \n \n \n \n \n Requisition Number \n \n \n      2023-00300\n      \n \n \n \n \n FTE (full-time equivalency) \n \n \n      100\n      \n \n \n \n \n Work Schedule \n \n \n      8-5 M-F\n      \n \n \n \n \n Does the position provide the opportunity to work Remotely/Telecommuting? \n \n \n      Yes \u2013 partial remote/telecommute opportunity\n      \n \n \n \n \n Appointment Term \n \n \n      12- 12/12 months\n      \n \n \n \n \n Pay Information \n \n \n      65,000-80,000\n      \n \n \n \n \n Pay Schedule \n \n \n      Annually\n      \n \n \n \n \n FLSA Designation \n \n \n      Exempt\n      \n \n \n \n \n Position Summary \n \n \n      This position\u2019s primary responsibility is to develop new reporting tools and document the business definitions and data of the university. The position acts as a liaison between project stakeholders, Information Technology Services (ITS), end users, university leadership, and external stakeholders. Work requires frequent data analysis, requirements management, documenting and recommending solutions, and project management. This individual will also be involved in the implementation, administration and maintenance of various infrastructure applications used by the university.\n      \n \n \n \n \n \n \n \n   Job Duties \n   \n \n \n \n \n \n Responsibility Area: \n \n \n      Project Management\n      \n \n \n \n \n Duties: \n \n \n      Participate in the selection and prioritization of projects. Assist with strategic projects from initiation through close, ensuring a standard methodology is followed.\n      \n \n \n \n \n Percentage Of Time \n \n \n      15\n      \n \n \n \n \n Essential Function: \n \n \n      Yes\n      \n \n \n \n \n \n \n \n \n Responsibility Area: \n \n \n      Business Analysis\n      \n \n \n \n \n Duties: \n \n \n      Establish relationships with project stakeholders. Creates data analysis tools for end users. Elicit requirements. Document requirements. Manage requirements. Conduct stakeholder analysis and readiness assessments. Performs data analyses using common business intelligence methods and tools.\n      \n \n \n \n \n Percentage Of Time \n \n \n      30\n      \n \n \n \n \n Essential Function: \n \n \n      Yes\n      \n \n \n \n \n \n \n \n \n Responsibility Area: \n \n \n      Documentation\n      \n \n \n \n \n Duties: \n \n \n      Document data usage methodologies and sources. Facilitate standardization and documentation of reporting terminology to expedite adoption of solutions.\n      \n \n \n \n \n Percentage Of Time \n \n \n      25\n      \n \n \n \n \n Essential Function: \n \n \n      Yes\n      \n \n \n \n \n \n \n \n \n Responsibility Area: \n \n \n      Mentoring\n      \n \n \n \n \n Duties: \n \n \n      Act as a department resource for matters of business analysis, project management and change management by providing consulting support and developing department standards, templates, and strategies. Provides functional support and training to UNO staff members.\n      \n \n \n \n \n Percentage Of Time \n \n \n      10\n      \n \n \n \n \n Essential Function: \n \n \n      Yes\n      \n \n \n \n \n \n \n \n \n Responsibility Area: \n \n \n      Learning\n      \n \n \n \n \n Duties: \n \n \n      Continually learn by researching trends and best practices on campus, in the higher education industry, and in client relationship management and data analytics tools to be a resident expert.\n      \n \n \n \n \n Percentage Of Time \n \n \n      15\n      \n \n \n \n \n Essential Function: \n \n \n      Yes\n      \n \n \n \n \n \n \n \n \n Responsibility Area: \n \n \n      Other\n      \n \n \n \n \n Duties: \n \n \n      Additional duties as assigned.\n      \n \n \n \n \n Percentage Of Time \n \n \n      5\n      \n \n \n \n \n Essential Function: \n \n \n      Yes\n      \n \n \n \n \n \n \n \n   Required and Preferred Qualifications \n   \n \n \n \n \n \n Required Education \n \n \n      Bachelor\u2019s degree preferably in business/management information systems/other technology-related field, or equivalent work experience\n      \n \n \n \n \n Required Experience \n \n \n      NA\n      \n \n \n \n \n Required License/Certification \n \n \n      NA\n      \n \n \n \n \n Required Additional Qualifications: \n \n \n      NA\n      \n \n \n \n \n Preferred Education \n \n \n      NA\n      \n \n \n \n \n Preferred Experience \n \n \n      Experience utilizing SalesForce CRM, PeopleSoft Campus Solutions, and data visualization tools (Tableau, PowerBI, or similar). Experience with data modeling and SQL. Experience in higher education.\n      \n \n \n \n \n Preferred License/Certification \n \n \n      NA\n      \n \n \n \n \n Preferred Additional Qualifications: \n \n \n      NA\n      \n \n \n \n \n \n \n \n   Compliance Requirements \n   \n \n \n \n \n \n Credit Check \n \n \n      Yes\n      \n \n \n \n \n Motor Vehicle Licensing Validity Check \n \n \n      Yes\n      \n \n \n \n \n Pre-employment Physical Request and Assessment \n \n \n      No\n      \n \n \n \n \n Drug Screen \n \n \n      No", "cleaned_desc": "", "techs": ""}, "66306d731f084ccd": {"terms": ["data analyst"], "salary_min": 79800.0, "salary_max": 131700.0, "title": "Lead Utility Business Analyst", "company": "Ericsson", "desc": "Company:  PSEG\n  \n \n  Requisition : 75445\n  \n \n  PSEG Company:  PSEG Long Island\n  \n \n  Salary Range : $ 79,800 - $ 131,700\n  \n \n  Incentive : PIP 10%\n  \n \n  Work Location Category : Remote Local\n  \n \n \n  Job Summary \n \n \n   The PSEG-LI Utility Business Analyst position will ensure SAP and Hyperion financial and management reporting is accurate and timely as per Long Island Power Authority (LIPA) Operating Service Agreement \u201cOSA\u201d. This includes working with business partners and finance technology subject matter experts to ensure the proper processing of the monthly accounting close and the annual budgeting process. This position will play a lead role in the coordination and implementation of a new budgeting system and liaise with LIPA regarding PSEGLI Hyperion reporting.\n   \n \n \n  Job Responsibilities: \n \n \n  Provide guidance, review and analyses of Hyperion reporting to internal and external customers. This includes supplying detailed process analytics and reconciliations when requested. Work collaboratively with the PSEGLI Planning and Reporting team, as well as LIPA, to coordinate and facilitate any required system upgrades or maintenance. \n  Obtain a great knowledge of the PSEGLI organization in order to provide reporting solutions. This includes detailed analyses of all or any overhead costs or processes. Ensure uniformity with business rules, assessment calculations, and organizational structures in SAP and new budgeting system. \n  Utilizing current Hyperion Reporting experience to suggest improvements as well as be able to train individuals and groups to generate reports and analyses. Must be able to generate and present documentation and related material to train internal and/or external partners. \n  Provide documentation, support, and guidance on implementation, upgrade, and maintenance of fixed asset system. \n  Update PSEGLI Utility Business team on any upgrades or change request made by internal or external customer to ensure proper data flow and approvals. \n \n \n \n  Job Specific Qualifications: \n \n \n \n  Required: \n \n \n \n  Bachelor's Degree or Advanced Degree preferably in Accounting, Finance or Business Management and a minimum of 7 years of financial planning and analysis experience \n  Demonstrated knowledge in financial analysis and budgeting in SAP and Hyperion Reporting \n  Expert skills in Microsoft Office, proficiency in Word, PowerPoint, expertize in Excel and other database software \n  Excellent written and verbal communication skills, ability to interact with internal and external providers/users of financial information \n  Successful candidate must be able to find solutions strategically and logically \n  Ability to create and present financial and systems information to senior personnel \n \n \n  Desired: \n \n \n \n  Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy \n  Proficient in Hyperion Reporting \n  Supervisory or Managerial experience \n  SAP Experience \n  Powerplan Experience \n  Experience in a Utility Financial and Management Reporting \n \n \n  Minimum Years of Experience: \n \n \n  7 years of experience", "cleaned_desc": " \n \n  Required: \n \n \n \n  Bachelor's Degree or Advanced Degree preferably in Accounting, Finance or Business Management and a minimum of 7 years of financial planning and analysis experience \n  Demonstrated knowledge in financial analysis and budgeting in SAP and Hyperion Reporting \n  Expert skills in Microsoft Office, proficiency in Word, PowerPoint, expertize in Excel and other database software \n  Excellent written and verbal communication skills, ability to interact with internal and external providers/users of financial information \n  Successful candidate must be able to find solutions strategically and logically \n  Ability to create and present financial and systems information to senior personnel \n   \n  Desired: \n \n \n \n  Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy \n  Proficient in Hyperion Reporting \n  Supervisory or Managerial experience \n  SAP Experience \n  Powerplan Experience \n  Experience in a Utility Financial and Management Reporting \n \n ", "techs": ["sap", "hyperion reporting", "microsoft office", "word", "powerpoint", "excel", "database software", "hyperion reporting", "powerplan", "utility financial and management reporting"]}, "f970905fcab5b42b": {"terms": ["data analyst"], "salary_min": 77182.85, "salary_max": 97730.68, "title": "Business Analyst II (S04866P)", "company": "University of Texas at Arlington", "desc": "Posting Details \n \n \n \n     Position Information \n     \n \n \n \n \n \n Posting Number \n \n \n        S04866P\n        \n \n \n \n \n Position Title \n \n \n        Business Analyst II (S04866P)\n        \n \n \n \n \n Department \n \n \n        OIT Business Analysis\n        \n \n \n \n \n Location \n \n \n        Arlington\n        \n \n \n \n \n Job Family \n \n \n        Information Technology\n        \n \n \n \n \n Position Status \n \n \n        Full-time\n        \n \n \n \n \n Work Hours \n \n \n        Standard\n        \n \n \n \n \n Work Schedule \n \n \n        Monday \u2013 Friday\n          8:00 AM \u2013 5:00 PM\n          In-Office and Remote Work as determined by department manager.\n        \n \n \n \n \n Open to \n \n \n        External and Internal\n        \n \n \n \n \n Salary \n \n \n        Salary is commensurate based on qualifications and relevant experience.\n        \n \n \n \n \n Duration \n \n \n        Funding expected to continue\n        \n \n \n \n \n Pay Basis \n \n \n        Monthly\n        \n \n \n \n \n Benefits Eligible \n \n \n        Yes\n        \n \n \n \n \n Benefits at UTA \n \n \n        We are proud to offer a comprehensive benefits package to all our employees at the University.\n         \n  To help you understand the full value of these benefits, we have created a tool that calculates the total worth of your compensation package. This tool takes into account all of the benefits that you are eligible for, including health insurance, retirement plans, and paid time off. To access this tool and learn more about the total value of your benefits, please click on the following link:\n         \n https://resources.uta.edu/hr/services/records/compensation-tools.php \n \n \n \n \n \n University Information \n \n \n        The University of Texas at Arlington is located in the heart of the Dallas-Fort Worth-Arlington metroplex, a vibrant and diverse metropolitan area that is home to over 7 million people, one of the fastest-growing tech economies in the United States, and a wide array of arts, entertainment, and cultural activities. UTA is a comprehensive teaching, research, and public service institution dedicated to the advancement of knowledge through scholarship and creative work. The University is committed to providing access and ensuring student success, and to a culture of innovation, entrepreneurship, and commercialization of discoveries by our community of scholars. With an enrollment of more than 40,000 students, UTA is the second largest in the University of Texas System. As a result of its combination of rigorous academics and innovative research, UTA is designated as a Carnegie R-1 \u201cVery High Research Activity\u201d institution. UTA ranks No. 4 nationally in Military Times\u2019 annual \u201cBest for Vets: Colleges\u201d list and is among the top 30 performers nationwide for promoting social mobility of its graduates (U.S. News & World Report, 2023). UTA is designated by the U.S. Department of Education as both a Hispanic-Serving Institution (HSI) and an Asian American and Native American Pacific Islander-Serving Institution (AANAPISI), and it has one of the top 5 most ethnically diverse undergraduate student bodies in the United States (U.S. News & World Report, 2023). Its approximately 270,000 alumni, including some who occupy leadership positions at many of the 24 Fortune 500 companies headquartered in North Texas, contribute to UTA\u2019s $22.2 billion annual economic impact on Texas.\n        \n \n \n \n \n Job Summary \n \n \n        The Office of Information Technology at UT Arlington provides premier support and solutions to our Maverick Community. We are a team of highly skilled professionals who approach our work with pride, respect, and a shared purpose.\n          The Business Analyst II in the Office of Information Technology (OIT) provides procedural guidance, process improvement recommendations, business requirements planning, system configuration management, application testing, quality control, and advanced reporting to user departments for specific application software used by departments. The Business Analyst II will also perform advanced analysis of exception conditions, error processing, workflow efficiencies, for all software applications used by departments that they support.\n         \n \n \n \n \n \n Essential Duties and Responsibilities \n \n \n Work with associated business areas to resolve exceptions preventing normal business operations as they relate to software applications and business procedures. \n Perform advanced problem/root cause analysis of business processes, work- flow processes, and advanced troubleshooting for user departments. \n Develop business process documentation and configuration guides. \n Develop reports using database queries and associated reporting software. \n Train/Mentor less experienced business analysts with business process designs, testing, quality control and reporting requests from users. \n Act as a liaison on behalf of Office of Information (OIT) and departments for technology related communications and meetings with technical staff/vendors as needed. \n Identify and develop practices and business processes as requested by business areas. \n Perform other duties as assigned. \n \n \n \n \n \n Required Qualifications \n \n \n Bachelor\u2019s degree in Information Systems, Computer Science, Business Administration, Economics, Math, or equivalent experience. \n Three (3) \u2013 Four (4) years experience or the equivalent. \n Experience working with a combination of software related to PeopleSoft Software Applications: Admissions, Student Records, Financial Aid, Student Financials, Advising, Enrollment, HR, Finance, Grants, GL, Commitment Control, Purchasing, CRM, Data Warehousing software, or equivalent software. \n Comfortable using Microsoft Office Suite (Word, Excel, Outlook, PowerPoint, Visio, etc.) \n Exposure using Sql statements, Oracle/Sql databases, and using 4th generation reporting software. \n Excellent communication skills, attention to detail, and documentation skills would be most helpful for this position. \n Microsoft Office Suite, Visio, Teams, and SharePoint would be a plus. \n Knowledge working with Agile Scrum Methodology for projects would be helpful. \n Any experience working with document imaging software like Highland Perceptive \n Content (ImageNow) or Hyland (OnBase) Software would be helpful. \n \n \n \n \n \n Preferred Qualifications \n \n \n Bachelor\u2019s degree in Information Systems, Computer Science, Business Administration, Math, Economics, or equivalent experience. \n Four (4) \u2013 Five (5) years\u2019 experience or the equivalent \n \n \n \n \n \n Working Conditions \n \n \n        Specific job requirements or physical location of positions allocated to this classification render the position security sensitive and thereby subject to the provisions of Section 51.215 Texas Education Code.\n        \n \n \n \n \n Special Conditions for Eligibility \n \n \n \n \n \n \n Working Title \n \n \n \n \n \n \n CBC Requirement \n \n \n        It is the policy of The University of Texas at Arlington to conduct a criminal background check on any applicant who is under final consideration for employment with the University.\n        \n \n \n \n \n EEO Statement \n \n \n        It is the policy of The University of Texas at Arlington (UTA or The University) to provide an educational and working environment that provides equal opportunity to all members of the University community. In accordance with federal and state law, the University prohibits unlawful discrimination, including harassment, on the basis of race, color, national origin, religion, age, sex, sexual orientation, pregnancy, disability, genetic information, and/or veteran status. The University also prohibits discrimination on the basis of gender identity, and gender expression. Retaliation against persons who oppose a discriminatory practice, file a charge of discrimination, or testify for, assist in, or participate in an investigative proceeding relating to discrimination is prohibited. Constitutionally-protected expression will not be considered discrimination or harassment under this policy. It is the responsibility of all departments, employees, and students to ensure the University\u2019s compliance with this policy.\n        \n \n \n \n \n ADA Accommodations \n \n \n        The University of Texas at Arlington is committed to providing reasonable accommodation to individuals with disabilities. If you require reasonable accommodation in completing this application, interviewing or otherwise participating in the employee selection process, please direct your inquiries to 817-272-5554 or email \n         ADADocs@uta.edu .\n        \n \n \n \n \n \n \n \n     Posting Detail Information \n     \n \n \n \n \n \n Number of Vacancies \n \n \n        1\n        \n \n \n \n \n Desired Start Date \n \n \n \n \n \n \n Open Date \n \n \n \n \n \n \n Review Start Date \n \n \n \n \n \n \n Open Until Filled \n \n \n \n \n \n \n Minimum Number of References Required \n \n \n        3\n        \n \n \n \n \n Maximum Number of References Accepted \n \n \n \n \n \n \n Special Instructions to Applicants \n \n \n        Applicants must include in their online resume the following information: 1) Employment history: name of company, period employed (from month/year to month/year), job title, summary of job duties and 2) Education: school name, degree type, and major.\n        \n \n \n \n \n \n \n \n Requirement Questions \n \n Required fields are indicated with an asterisk (*). \n \n \n * Please indicate years of experience working in Higher Education. \n      \n 1 year \n 2-3 years \n More than 3 years \n No experience \n \n \n \n * What is the highest degree you have attained? \n      \n Associate's degree \n Bachelor's degree \n Master's degree or higher \n None of the above \n \n \n \n * What is your skill level using Microsoft Office Suite (Word, Excel, Outlook, etc.)? (Proficient is the highest skill level) \n      \n No skills/Basic \n Intermediate \n Advanced \n Proficient \n \n \n \n * What is your skill level using Reporting Software? (Proficient is the highest skill level) \n      \n No skills/Basic \n Intermediate \n Advanced \n Proficient \n \n \n \n * Please indicate what ERP Software do have experience working with. \n      \n Financials \n HR \n Student Applications \n Purchasing \n None of the above \n \n \n \n \n Documents Needed To Apply \n \n Required Documents \n \n \n Resume or CV \n \n \n Cover/Interest Letter \n \n \n Optional Documents", "cleaned_desc": " \n \n \n \n \n Essential Duties and Responsibilities \n \n \n Work with associated business areas to resolve exceptions preventing normal business operations as they relate to software applications and business procedures. \n Perform advanced problem/root cause analysis of business processes, work- flow processes, and advanced troubleshooting for user departments. \n Develop business process documentation and configuration guides. \n Develop reports using database queries and associated reporting software. \n Train/Mentor less experienced business analysts with business process designs, testing, quality control and reporting requests from users. \n Act as a liaison on behalf of Office of Information (OIT) and departments for technology related communications and meetings with technical staff/vendors as needed. \n Identify and develop practices and business processes as requested by business areas. \n Perform other duties as assigned. \n \n \n \n \n \n Required Qualifications \n \n \n Bachelor\u2019s degree in Information Systems, Computer Science, Business Administration, Economics, Math, or equivalent experience. \n Three (3) \u2013 Four (4) years experience or the equivalent. \n Experience working with a combination of software related to PeopleSoft Software Applications: Admissions, Student Records, Financial Aid, Student Financials, Advising, Enrollment, HR, Finance, Grants, GL, Commitment Control, Purchasing, CRM, Data Warehousing software, or equivalent software. \n Comfortable using Microsoft Office Suite (Word, Excel, Outlook, PowerPoint, Visio, etc.) \n Exposure using Sql statements, Oracle/Sql databases, and using 4th generation reporting software. \n Excellent communication skills, attention to detail, and documentation skills would be most helpful for this position. \n Microsoft Office Suite, Visio, Teams, and SharePoint would be a plus. \n Knowledge working with Agile Scrum Methodology for projects would be helpful. \n Any experience working with document imaging software like Highland Perceptive \n Content (ImageNow) or Hyland (OnBase) Software would be helpful. \n \n \n \n \n \n Preferred Qualifications \n \n \n Bachelor\u2019s degree in Information Systems, Computer Science, Business Administration, Math, Economics, or equivalent experience. \n Four (4) \u2013 Five (5) years\u2019 experience or the equivalent \n \n \n \n \n \n Working Conditions \n \n \n        Specific job requirements or physical location of positions allocated to this classification render the position security sensitive and thereby subject to the provisions of Section 51.215 Texas Education Code.\n        \n \n \n \n \n Special Conditions for Eligibility \n \n \n \n \n \n \n Working Title \n \n \n \n \n \n \n CBC Requirement \n \n \n        It is the policy of The University of Texas at Arlington to conduct a criminal background check on any applicant who is under final consideration for employment with the University.\n        \n \n ", "techs": ["microsoft office suite", "visio", "teams", "sharepoint", "sql statements", "oracle/sql databases", "4th generation reporting software", "highland perceptive content (imagenow) software", "hyland (onbase) software", "agile scrum methodology"]}, "257e7fa9b95464eb": {"terms": ["data analyst"], "salary_min": 67272.89, "salary_max": 85182.47, "title": "Asset Management Analyst", "company": "Pine Gate Renewables", "desc": "Pine Gate Renewables is a leading renewable energy company focused on project development and strategic financing of solar and storage projects throughout the United States. The company's Pine Gate Impact initiative contributes to multiple non-profit organizations aimed at improving the environment and local communities. Headquartered in Asheville, NC, Pine Gate Renewables made the Inc. 5000 list in 2021, placing at #37 and named to Fast Company's Most Innovative Companies list in 2021. Pine Gate Renewables works every day to achieve its mission to \"Get Solar Done.\" For more information, visit pinegaterenewables.com. \n \n  Within Pine Gate Renewables, the operational asset team is accountable for delivering the optimal results from each asset currently operating. Pine Gate Renewables' 100 operating assets have a 2 GW capacity and are across 36 states. This team is critical to ensuring profitable, sustainable assets for the company. As an Asset Management Analyst, you will be an integral part of our Asset Management team, supporting the management of our solar and storage assets. Your role will involve closely monitoring the performance of our renewable energy projects, analyzing data, managing contracts, ensuring compliance, and collaborating with cross-functional teams to optimize asset performance and profitability. \n  What You'll Do \n  Asset Performance Analysis: \n \n Monitor key performance indicators (KPIs) and financial metrics of assigned assets. \n Analyze data to identify opportunities for increasing profitability and propose strategies to achieve financial targets. \n Collaborate with operations and performance engineers to address challenges impacting asset performance. \n \n Contract Management: \n \n Assist in managing power purchase agreements (PPAs) and other contractual agreements. \n Ensure compliance with partner, investor, and lender obligations. \n Work closely with legal and finance teams to manage contracts effectively. \n Assist in maintaining files, file structure, and naming conventions. \n \n Reporting and Compliance: \n \n Prepare regular reports and presentations for partner, investor, and lender compliance. \n Ensure department reporting adheres to internal and external standards. \n Assist in managing warranty and insurance claims. \n \n Market Analysis and Risk Management: \n \n Stay updated with market trends, ISO market rules, regulations, and pricing mechanisms. \n Assist in devising market entry strategies and optimizing revenue generation. \n Assist in maintaining risk registers for assets in operational phase. \n \n Cross-Functional Collaboration: \n \n Collaborate with internal teams (development, operations, finance, legal) to optimize asset performance and mitigate risks. \n Participate in handover sessions to ensure smooth asset transitions between teams. \n Work with regulatory and compliance teams to ensure adherence to relevant laws and regulations. \n \n Stakeholder Management: \n \n Build and maintain relationships with internal and external stakeholders, including O&M providers, PPA counterparties, utilities, regulatory agencies, landowners, and communities. \n \n Must-Haves \n \n Bachelor's degree in engineering, finance, business administration, or related field. \n Minimum of 2 years of experience in the solar industry or a related field. \n Knowledge of solar industry contracts, including PPAs, service agreements, and landowner leases. \n Strong analytical skills with the ability to interpret complex data sets. \n Excellent communication and interpersonal skills. \n Detail-oriented with strong organizational skills. \n Ability to work independently and in a team, thriving in a fast-paced environment. \n Proficiency in Microsoft Office Suite, especially Excel and PowerPoint. \n \n Education and Certifications  \n \n Bachelor's degree in engineering, finance, business administration, or a related field. \n \n Working Environment and Physical Demand  \n \n Location Remote \n \n \n  Pine Gate Renewables believes in taking care of our employees by offering benefits that support their physical, mental, and financial well-being. Our comprehensive benefits package includes medical, dental, vision, matching 401k, Paid Time Off, paid holidays, training, and development, giving back to the community, remote work options, dog-friendly offices, and much more. Pine Gate Renewables is committed to diversity, equity, and inclusion in the workplace. \n  Pine Gate Renewables does not accept any unsolicited resumes or referrals from any third-party recruiting firms or agencies.", "cleaned_desc": " \n Build and maintain relationships with internal and external stakeholders, including O&M providers, PPA counterparties, utilities, regulatory agencies, landowners, and communities. \n \n Must-Haves \n \n Bachelor's degree in engineering, finance, business administration, or related field. \n Minimum of 2 years of experience in the solar industry or a related field. \n Knowledge of solar industry contracts, including PPAs, service agreements, and landowner leases. \n Strong analytical skills with the ability to interpret complex data sets. \n Excellent communication and interpersonal skills. \n Detail-oriented with strong organizational skills. \n Ability to work independently and in a team, thriving in a fast-paced environment. ", "techs": ["none"]}, "35ab07f6e562a0a1": {"terms": ["data analyst"], "salary_min": null, "salary_max": null, "title": "Premium Audit -Senior Quality Analyst", "company": "The Hartford", "desc": "You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.\n  \n \n \n   This position will perform quality evaluations of Premium Audit Operations employees. Responsibilities include conducting baseline sampling, focused audits, establishing and maintaining relationships with the teams the position supports. Quality results, top trends and recommendations are identified and shared with others for continuous improvement, which are typically performed in Microsoft Excel and Verint. This position will work closely with business partners to provide meaningful insight to help develop and refine best practices and standard work within the organization.\n  \n \n \n   Hybrid & Remote:\n  \n \n   Sustaining The Hartford\u2019s unique workplace culture is vital to delivering on our purpose \u2013 underwriting human achievement \u2013 and continuously producing outstanding results. Our enterprise work model, which reflects a mix of in-office, hybrid and fully remote roles, helps us attract, retain and develop the talent we need to achieve the company\u2019s strategic goals. This role can be performed in either a hybrid or remote work arrangement.\n  \n \n \n   The accountabilities of this position are:\n  \n \n \n \n     Provide consistent, independent and objective assessments for Premium Audit teams.\n    \n \n \n     Have a thorough understanding of, and exposure to, supported business groups and processes\n    \n \n \n     Identify and report on quality trends and performance issues, and conduct root cause analysis\n    \n \n \n     Provide leadership with feedback and recommendations related to process effectiveness and execution\n    \n \n \n     Develop skills among supported individuals through consistent and continuous feedback\n    \n \n \n     Conduct focused audits and targeted reviews, document findings and make recommendations to improve results\n    \n \n \n     Perform quality review of work performed within the Premium Audit teams.\n    \n \n \n     Complete quality reviews in conjunction with best practice and quality playbooks to ensure accuracy, compliance, and the identification of opportunities.\n    \n \n \n     Record and report results using quality tools (Verint and Excel)\n    \n \n \n     Partner with operations leaders to determine and recommend areas of concentration and advance the value of the quality program.\n    \n \n \n     Create quality playbooks that support the purpose and intent of the quality program.\n    \n \n \n     Participate in and/or conduct calibration activities with peers, customers, and partners (training/underwriting) to assure alignment across the organization.\n    \n \n \n     Analyze data and results with the purpose of identifying quality trends, characterize opportunities, and quantify business impact.\n    \n \n \n     Lead quality audit calibration sessions and debrief on learning\u2019s with quality team.\n    \n \n \n     Finalize quality audit reports and review the results with vendor and key stakeholders.\n    \n \n \n     Actively participate in cross functional teams established to create and improve Premium Audit processes.\n    \n \n \n \n   Minimum experience, education and skills required:\n  \n \n \n \n     Bachelor\u2019s Degree preferred or equivalent experience, on-going education a plus.\n    \n \n \n     Subject Matter Expertise in Premium Audit is preferred.\n    \n \n \n     Proven performer. Strong business process knowledge required, service operations experience, or equivalent.\n    \n \n \n     Working knowledge of system applications including but not limited to: Verint, Nexus, PARIS, Policy Center, Spurs, IDARS, TRIO, Quart, LAPS, IKE, ASPIR, Etc.\n    \n \n \n     Proficient in Microsoft Office tools; Excel, Power Point, Word, and One Note\n    \n \n \n     Meet/exceed department standards for quality and productivity.\n    \n \n \n     Excellent analytical and decision-making skills\n    \n \n \n     Strong interpersonal skills and responsiveness to internal/external business partners.\n    \n \n \n     Superior attention to detail and strong critical thinking skills.\n    \n \n \n     Ability to identify opportunities, recommend change and drive solutions\n    \n \n \n     Can effectively mentor and coach others to support continuous learning\n    \n \n \n     Excellent communication skills \u2013 written and verbal.\n    \n \n \n     Strong verbal and written communication skills. Demonstrates the ability to effectively deliver messages and results to achieve desired outcome\n    \n \n \n     Strong time management, planning, and organizational skills. Demonstrates initiative and the ability to work independently.\n    \n \n \n     Change advocate with strong influencing and negotiating skills\n    \n \n \n \n   Compensation\n  \n \n   The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford\u2019s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:\n  \n  $51,760 - $77,640\n  \n \n   Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age", "cleaned_desc": "", "techs": ""}, "fe8430fe1590e5b5": {"terms": ["data analyst"], "salary_min": 63700.0, "salary_max": 86000.0, "title": "Maritime Business Intelligence Analyst - Remote US", "company": "Holland America Line Inc", "desc": "Holland America Line has been exploring the world since 1873. Our ships offer innovative features and enriching experiences focused on destination exploration and personalized travel, inviting guests to savor the journey.  \n We\u2019re looking for an amazing Maritime Business Intelligence Analyst to fill this role. You\u2019ll be responsible for utilizing native SQL as well as data connectors like Snowflake and TIBCO to provide analytical support to the team, constantly working to drive vessel performance improvement and inspire change initiatives across work streams utilized, including SeaEvent, NAPA, Global HESS, RiskConsole, and others. Track, report and provide recommendations to relevant teams on incidents, audits, claims, HR and shipboard operations systems.  \n Here\u2019s a summary of what Holland America Line is looking for in its Maritime Business Intelligence Analyst. Is this you?  \n Responsibilities  \n \n BI Analyst will be responsible for taking data and mining it to achieve valuable insights.  \n Meeting with cross-functional stakeholders and recording data requirements into a Story format  \n Writing data collection and processing procedures, including data definitions, to support data requirements.  \n Ensuring data integrity of new queries and requirements meets specifications and that data is being correctly gathered, stored, and analyzed.  \n Report findings to ships, management and/or Senior Leadership as required.  Continually monitor data refreshes and data collection to support legacy projects. \n  \n   Requirements  \n \n Bachelor\u2019s degree in Reliability Engineering, Business, Management, Economics, Accounting, Finance, or Computer and Information Science required, or the equivalent combination of education and experience  \n Postgraduate degree in Industrial/Engineering Management, Operations Research, Decision Science or Reliability Engineering preferred  \n 3 years of experience with business intelligence.  \n 2 years of experience in an analytics role.  \n 1 year of work experience in Maritime or Safety industry (preferred).  \n Advanced Excel and Tableau/Power BI required.  \n Superior attention to detail skills.  \n Python, Stata/R and MATLAB experience preferred.  \n Must be proficient in the use of computer business applications; internet technology, project planning, and management tools.  \n Must be a self-starter capable of working under their own initiative and as part of a larger team with regular reporting and feedback communication.  \n Excellent leadership, interpersonal and communication skills to interact with external agencies, shipboard and shore side management & employees.  \n Must be legally authorized to work in the United States. Holland America is unable to sponsor or take over sponsorship of employment visas at this time (e.g., H-1B status).  \n \n Please note that this position can be 100% fully remote, US Only  (please note that Holland America Line is not setup to hire anyone in the following states: AR, DE, HI, ME, MN, MS, NE, NH, OK, SD, VT, WV, WY)  \n What You Can Expect  \n \n Cruise and Travel Privileges for You and Your Family  \n Health Benefits  \n 401(k)  \n Employee Stock Purchase Plan  \n Training & Professional Development  \n Tuition & Professional Certification Reimbursement  \n Rewards & Incentives  \n Base Salary Range: $ 63,700.00 to $ 86,000.00. The range is applicable for the labor market where the role is intended to be hired. Final base salary is directly related to each candidates' qualifications and experience uniquely.  \n \n Our Culture\u2026 Stronger Together  \n Our highest responsibility and top priority is compliance, environmental protection and the health, safety and well-being of our guests, the people in the communities we touch and serve, and our shipboard and shoreside employees. Please visit our site to learn more about our Culture Essentials, Corporate Vision Statement and our Core Values at:  https://www.hollandamerica.com/en_US/our-company/mission-values.html     Holland America is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.   \n   Americans with Disabilities Act (ADA)  \n Holland America will provide reasonable accommodations with the application process, upon your request, as required to comply with applicable laws. If you have a disability and require assistance in this application process, please contact recruiting@hollandamericagroup.com  \n #HAL", "cleaned_desc": "Holland America Line has been exploring the world since 1873. Our ships offer innovative features and enriching experiences focused on destination exploration and personalized travel, inviting guests to savor the journey.  \n We\u2019re looking for an amazing Maritime Business Intelligence Analyst to fill this role. You\u2019ll be responsible for utilizing native SQL as well as data connectors like Snowflake and TIBCO to provide analytical support to the team, constantly working to drive vessel performance improvement and inspire change initiatives across work streams utilized, including SeaEvent, NAPA, Global HESS, RiskConsole, and others. Track, report and provide recommendations to relevant teams on incidents, audits, claims, HR and shipboard operations systems.  \n Here\u2019s a summary of what Holland America Line is looking for in its Maritime Business Intelligence Analyst. Is this you?  \n Responsibilities  \n \n BI Analyst will be responsible for taking data and mining it to achieve valuable insights.  \n Meeting with cross-functional stakeholders and recording data requirements into a Story format  \n Writing data collection and processing procedures, including data definitions, to support data requirements.    2 years of experience in an analytics role.  \n 1 year of work experience in Maritime or Safety industry (preferred).  \n Advanced Excel and Tableau/Power BI required.  \n Superior attention to detail skills.  \n Python, Stata/R and MATLAB experience preferred.  \n Must be proficient in the use of computer business applications; internet technology, project planning, and management tools.  \n Must be a self-starter capable of working under their own initiative and as part of a larger team with regular reporting and feedback communication.  \n Excellent leadership, interpersonal and communication skills to interact with external agencies, shipboard and shore side management & employees.  ", "techs": ["native sql", "snowflake", "tibco", "seaevent", "napa", "global hess", "riskconsole", "tableau/power bi", "python", "stata/r", "matlab"]}, "d2753c2c0c75aa1b": {"terms": ["data analyst"], "salary_min": 43700.0, "salary_max": 105100.0, "title": "Senior Analyst, Business Analytics", "company": "CVS Health", "desc": "Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u2014 with heart at its center \u2014 our purpose sends a personal message that how we deliver our services is just as important as what we deliver.    Our Heart At Work Behaviors\u2122 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. \n \n  Position Summary \n  Proactively defines, identifies, develops and creates data responsive to regulatory requirements and provides oversight, coaching and mentoring of team member work. This includes, but is not limited to the following: \n \n  Perform analytical work requiring ability to capture, analyze and interpret claims data \n  Manage translation of business needs into business requirements \n  Ensure project documentation is accurate and complete \n  Create queries; perform technical programming \n  Present data in a clear organized format \n  Creatively translate information using business knowledge and identify additional information needed to support analytical objectives \n  Review team member work for accuracy and completeness \n  Mentor and train team members \n  Run 1 - 2 projects simultaneously and independently while providing team guidance with minimal oversight \n \n \n  The successful candidate will be a detail-oriented individual with strong data analysis and analytical skills who is capable of providing leadership and guidance, while also working independently. Responsibilities include review of state regulations, review of compliance interpretation, writing business specifications, data quality review, data preparation, compliance to regulatory requirements, reviewing team member work, providing mentoring/training, running multiple projects simultaneously and independently while providing team guidance with little, or no oversight. Proficiency in all Microsoft Office applications (Excel, Word, Teams) is required. \n \n  Candidates should know SQL; or SAS; and/or technical capabilities relative to data mining & report generation. Knowledge of claims processing, claims quality audit programs, patient management, and/or a working understanding of Aetna products is highly preferred. The candidate will have excellent project management, communication and coaching/training skills and will meet deadlines, balance multiple priorities and demonstrate flexibility. The candidate should exhibit the ability to quickly and positively adapt to a changing environment. It is essential that the candidate builds and maintains effective working relationships with peers, management and others within and across organizational lines. Also desired is demonstrated critical thinking and the ability to articulate ideas clearly and concisely, both orally and in writing. We value a desire and willingness to learn. Some overtime will be required.     Required Qualifications \n \n  3+ years of data interpretation, data management, and analysis experience. \n  At least 2+ years of experience working with advanced SQL queries or SAS. \n  3+ years of Demonstrated leadership. \n  3+ years of project management experience. \n  Excellent verbal and written communication skills. \n  Demonstrated ability to effectively coordinate multiple projects simultaneously. \n  Experience working within the Healthcare analytics space. \n \n  Preferred Qualifications \n \n  Preference for candidate's to have experience with member or provider experience in Healthcare. \n \n  Education  Bachelor's degree or equivalent experience \n \n  Pay Range \n  The typical pay range for this role is: \n  $43,700.00 - $105,100.00\n  \n  This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.    In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u2019s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201cPTO\u201d) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.    For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits \n \n  CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. \n \n  You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. \n \n  CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.", "cleaned_desc": "  The successful candidate will be a detail-oriented individual with strong data analysis and analytical skills who is capable of providing leadership and guidance, while also working independently. Responsibilities include review of state regulations, review of compliance interpretation, writing business specifications, data quality review, data preparation, compliance to regulatory requirements, reviewing team member work, providing mentoring/training, running multiple projects simultaneously and independently while providing team guidance with little, or no oversight. Proficiency in all Microsoft Office applications (Excel, Word, Teams) is required. \n \n  Candidates should know SQL; or SAS; and/or technical capabilities relative to data mining & report generation. Knowledge of claims processing, claims quality audit programs, patient management, and/or a working understanding of Aetna products is highly preferred. The candidate will have excellent project management, communication and coaching/training skills and will meet deadlines, balance multiple priorities and demonstrate flexibility. The candidate should exhibit the ability to quickly and positively adapt to a changing environment. It is essential that the candidate builds and maintains effective working relationships with peers, management and others within and across organizational lines. Also desired is demonstrated critical thinking and the ability to articulate ideas clearly and concisely, both orally and in writing. We value a desire and willingness to learn. Some overtime will be required.     Required Qualifications \n \n  3+ years of data interpretation, data management, and analysis experience. \n  At least 2+ years of experience working with advanced SQL queries or SAS. \n  3+ years of Demonstrated leadership. \n  3+ years of project management experience.    Excellent verbal and written communication skills. \n  Demonstrated ability to effectively coordinate multiple projects simultaneously. \n  Experience working within the Healthcare analytics space. \n \n  Preferred Qualifications \n \n  Preference for candidate's to have experience with member or provider experience in Healthcare. \n ", "techs": ["sql", "sas", "microsoft office applications (excel", "word", "teams)"]}, "f2ac4d40073cf7f7": {"terms": ["data analyst"], "salary_min": 90000.0, "salary_max": 125000.0, "title": "Data Business Analyst, Senior", "company": "Varis - United States", "desc": "This is a 100% fully remote role. Work virtually from anywhere in the Continental U.S. \n  Varis stands as a pioneering force in the realm of digital procurement and commerce, serving as the nexus where buying organizations and suppliers seamlessly unite, forge contracts, transact, and prosper together. As a rapidly ascending technology startup, our core focus lies in digital commerce software-as-a-service and procurement, specifically within the dynamic landscape of B2B e-commerce. \n  At the heart of Varis beats an unwavering commitment to innovation and a customer-centric ethos that is poised to revolutionize business-to-business marketplaces. Joining our team at this juncture is akin to stepping onto the ground floor of an extraordinary opportunity to co-shape our destiny. Here, you'll not only witness but actively participate in the direct impact of your work, surrounded by a cadre of passionate individuals. You'll find yourself at the epicenter of a profoundly dynamic business model teeming with untapped individual and collective potential. \n  Your passion, innovation, and creativity are the very catalysts that will propel us to unprecedented heights. Join us today and be instrumental in propelling Varis into a future brimming with promise and possibility. \n \n  Apply quickly by emailing your resume here: data_business_analyst__8c2d867b5us@iris.greenhouse.io \n  What You'll Do \n \n We are looking for a Senior Business Analyst for our Business Planning and Strategy team. As a Senior Business Analyst, you will work closely with Product Managers, Program Managers, Business Operation Managers, and Software Developers to generate actionable insights that guide operational excellence and product development. \n Your work will have a direct impact on decision-making and strategy for our team. You will support this initiative by developing business metrics and reports, analyzing current processes to provide solutions for improvements, and helping executive leaders make key business decisions. \n The successful candidate will communicate effectively across teams and levels while balancing the needs and requirements of internal and external customers. We seek an individual who is motivated by a fast-paced and highly entrepreneurial environment. \n \n Key Responsibilities: \n \n \n Own the design, development, and maintenance of ongoing and ad-hoc metrics, reports, and analyses, that drive key business decisions \n Gather and analyze data for potential business expansion \n Prepare and present results of analysis and reports along with their relative impact(s) to the business to all levels of management. \n Create reports, dashboards, and visualizations with business intelligence tools (excel, visualization tools, and SQL), to understand business performance \n Participate in strategic & tactical planning discussions \n Coordinate with different departmental teams to produce better business outcomes \n Collaborate with the product manager on roadmap planning and prioritization \n \n What You'll Need \n \n \n Bachelor's degree in Business, Engineering, Statistics, Computer Science, Mathematics, Supply Chain or a related field \n 7+ years in corporate operations. \n 3+ years of relevant experience in a business analyst/data analyst/statistical analyst role. \n 2+ years of experience with business metrics reporting for corporate functions like finance/sales etc. \n Experience in supporting C-level is a big bonus. \n Excel modeling. \n Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools like PowerBI and Tableau. \n SQL proficiency, can write basic SQL queries \n Knowledge of DAX is desirable \n Excellent communication (verbal and written) and interpersonal skills with both technical and business audiences. \n Demonstrated ability to manage multiple projects, prioritization, planning, and task delegation. \n Strong critical thinking and problem-solving. \n Ability to display complex data in a simple, intuitive format and to present findings in a clear and concise manner \n Ability to collaborate and communicate effectively with Sales, Finance and Executive teams \n Domain knowledge of eCommerce/indirect procurement/Saas is desirable \n Proven ability to work independently in a fast-paced environment. \n \n \n \n  At Varis, pay scales are determined by role, level, location, and alignment with market data. Individual pay is determined through interviews and an assessment of several factors that are unique to each candidate, including but not limited to, job-related skills, relevant education and experience, certifications, abilities of the candidate, and pay relative to other team members.    The figures in this range reflect the average annual base salary for the given role, while additional variable incentives based on performance may also be available. Recruiters can share more information about our bonus program, benefits, and equity during the hiring process. \n \n  Pay Range \n \n    $90,000\u2014$125,000 USD\n   \n \n \n \n \n \n The above statements are intended to describe the general nature and level of work being performed by associates assigned to this classification and are not intended to be a complete list of all required responsibilities and skills. Other duties and special projects may be assigned per business needs. Job descriptions are subject to change at any time with or without notice. \n  Benefits and Perks \n \n 100% permanent remote work in the United States \n Medical / dental / vision, AD&D, and Life Insurance \n Paid Time Offer (PTO) and company paid holidays \n Health Saving Account (HSA) \n Long Term Disability and Short-Term Disability \n 401(k) matching program \n Discounted auto, home, and pet insurance \n Retirement savings plan rollovers \n Banking services \n Military leave \n Employee Assistance Program (EAP) \n Regular pay for funeral/memorial service observance \n Discounts on Office Depot/Microsoft/Apple products and services \n Opportunity for professional growth and career advancement \n \n \n Varis, Inc. is an Equal Opportunity Employer.  We are committed to providing equal employment opportunities in all employment practices. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, citizenship status, marital status, age, disability, protected veteran status, sexual orientation, or any other characteristic protected by law. We will consider for employment qualified applicants with arrest and conviction records in alignment with the City & County of San Francisco Fair Chance Ordinance. \n  CCPA disclosure notice  here .", "cleaned_desc": " Experience in supporting C-level is a big bonus. \n Excel modeling. \n Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools like PowerBI and Tableau. \n SQL proficiency, can write basic SQL queries \n Knowledge of DAX is desirable \n Excellent communication (verbal and written) and interpersonal skills with both technical and business audiences. \n Demonstrated ability to manage multiple projects, prioritization, planning, and task delegation. \n Strong critical thinking and problem-solving. \n Ability to display complex data in a simple, intuitive format and to present findings in a clear and concise manner \n Ability to collaborate and communicate effectively with Sales, Finance and Executive teams \n Domain knowledge of eCommerce/indirect procurement/Saas is desirable \n Proven ability to work independently in a fast-paced environment. \n \n \n ", "techs": ["excel modeling", "powerbi", "tableau", "sql", "dax", "excel", "powerbi", "tableau", "sql", "dax", "sales", "finance", "executive teams", "ecommerce", "indirect procurement", "saas."]}, "10c0e55cf66e914d": {"terms": ["data analyst"], "salary_min": 85984.23, "salary_max": 108875.195, "title": "Data Analyst with SQL Experience - Remote - USA", "company": "FullStack Labs", "desc": "FullStack is the fastest-growing software consultancy in the Americas. We help organizations like Uber, GoDaddy, MGM, Siemens, Stanford University, and the State of California, build distributed software development teams, and deliver transformational digital solutions. As an employee-first company, we focus on hiring the most talented software designers and developers in the western hemisphere, by creating a positive, respectful, and supportive work environment where they can achieve their greatest potential.\n  \n \n \n  We\u2019re most proud of:\n  \n \n Offering life-changing career opportunities to talented software professionals across the Americas. \n Building highly-skilled software development teams for hundreds of the world\u2019s greatest companies. \n Having delivered hundreds of successful custom software solutions, which have positively impacted the lives and careers of millions of users. \n Our 4.5-star rating on GlassDoor. \n Our client Net Promoter Score of 68, twice the industry average. \n \n The Position: \n \n   We're looking to hire a Data Analyst with SQL Experience to join our team. You'll work with our incredible clients in one of two ways: \n  \n \n Team Augmentation:  You will integrate yourself directly into our client's team and work alongside their existing designers and engineers on a daily basis. \n  Design & Build:  You will work on a FullStack product team to build and deliver a product to our clients. \n \n  What We're Looking For: \n \n  4+ years of professional Data Analytics experience. \n  Meaningful experience working with SQL. \n  Meaningful experience working with Python. \n  Advanced English is required. \n  Successful completion of a four-year college degree is required. \n  Experience working with JSON. \n  Experience working with JavaScript. \n  Experience working on Agile / Scrum teams. \n  Ability to take extreme ownership over your work. Every day is a challenge to ensure you are performing to the expectations you and your team have agreed upon. \n  Ability to identify with the goals of FullStack's clients, and dedicate yourself to delivering on the commitments you and your team make to them. \n  Ability to work through new and difficult issues and contribute to libraries as needed. \n  A positive mindset and can-do attitude. \n  Forensic attention to detail. \n  Ability to consistently work 40 hours per week. \n \n  Benefits: \n \n  Competitive Salary. \n  Paid Time Off (vacation, sick leave, maternity and paternity leave, holidays). \n  100% remote work. \n  The ability to work with leading startups and Fortune 500 companies. \n  Health, dental, and vision insurance. \n  401(k) w/ 4% match. \n  Virtual company events each month. \n  Ample opportunity for career advancement. \n  Continuing education opportunities. \n \n \n   FullStack is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form, which can be provided upon request during our hiring and interview process.\n  \n \n \n  Learn more about our Applicants Privacy Notice.", "cleaned_desc": "", "techs": ""}, "8b5d7ef494c789ca": {"terms": ["data analyst"], "salary_min": 83650.234, "salary_max": 105919.84, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "df4ea65eedd06b57": {"terms": ["data analyst"], "salary_min": 40.0, "salary_max": 55.0, "title": "BI Specialist", "company": "Info Origin Inc.", "desc": "Looking for BI Specialist (Subject Matter Expert) || 100% Remote Position || Indianapolis, IN!!! \n \n Position Title: BI Specialist \n Location: Indianapolis, IN, Remote \n Position Type: Contract \n Interview Process: Webcam/Skype \n \n The BI Specialist position, cleans and analyzes a variety of agency data sources in order to build compelling visualizations that display public health insights. This role serves a subject matter expert for data visualization and dashboard design, especially related to the use of Tableau. \n Required Skills: \n \n Experience designing and developing Tableau dashboards to build effective visualizations \n Experience using Tableau Prep cleaning, validating, and analyzing data prior to visualization \n Candidate must have at least 2 years work experience after last reported academic degree \n Experience using Outlook, Word, PowerPoint, and Excel in a professional setting \n Experience using one of the following: SAS, R, Python, ArcGIS \n \n Desired Skills: \n \n Experience with Public Health \n \n Educational Qualifications: \n \n Bachelor\u2019s degree from an accredited university in biostatistics, mathematics, epidemiology, analytics, programming, or related field \n \n Job Types: Contract, Full-time \n Salary: $40.00 - $55.00 per hour \n Expected hours: 40 per week \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Data visualization: 4 years (Required) \n Tableau: 4 years (Required) \n \n Work Location: Remote", "cleaned_desc": " \n Experience designing and developing Tableau dashboards to build effective visualizations \n Experience using Tableau Prep cleaning, validating, and analyzing data prior to visualization \n Candidate must have at least 2 years work experience after last reported academic degree \n Experience using Outlook, Word, PowerPoint, and Excel in a professional setting \n Experience using one of the following: SAS, R, Python, ArcGIS \n \n Desired Skills: \n ", "techs": ["tableau", "tableau prep", "outlook", "word", "powerpoint", "excel", "sas", "r", "python", "arcgis"]}, "377ae8dca1b1cd06": {"terms": ["data analyst"], "salary_min": 55440.0, "salary_max": 72000.0, "title": "Risk Analytics Analyst II (Remote)", "company": "Blackhawk Network", "desc": "About Blackhawk Network: \n  \n   Blackhawk Network (BHN) is the leader in global branded payment technologies. We strengthen relationships between brands and their customers, employees, and partners by transforming transactions into connections. BHN\u2019s portfolio includes: Gift Card & eGift products, promotions and distribution that grow revenue faster; Rewards & Incentives that build loyalty and acquisition and are integrated into today\u2019s leading platforms; and Payments that enable businesses and customers to access and disburse funds in convenient and innovative ways. BHN\u2019s network spans across the globe with over 400,000 consumer touchpoints. Learn more at BHN.com.\n  \n \n \n  This position may be performed remotely anywhere within the United States except for the State of Alaska, North Dakota, or South Dakota.\n   Overview: \n  \n   Blackhawk Network is looking for an enthusiastic, team-oriented individual to join our Risk Audit Team.\n  \n \n \n  Blackhawk Network is changing the world of gifting by making it possible to send a personalized eGift Card from any device, anywhere, anytime, with the best customer experience possible. More than 600 brands partner with us including Uber, Starbucks, Nordstrom, Delta, Best Buy, and The Home Depot.\n  \n \n \n  The online gift card space is a high-risk segment that attracts malicious actors, each looking to defraud legitimate consumers. Gift Cards are also a highly desirable option for consumers to buy gifts for friends and family or to capitalize on great promotional offers. BHN Risk Services provides best-in-class fraud prevention. We are committed to approving every good order, while preventing fraud from occurring on our platform. We are team driven and driven to succeed in this essential responsibility.\n   Responsibilities: \n  \n  Primary Duties: \n \n \n  Discover, recognize, and audit for patterns of fraudulent activity on orders that have been decisioned. \n  Analyze data to uncover emergent fraud and provide detailed exposition on fraud methodologies. \n  Provide feedback for constant process improvement and awareness of current trends. \n  Qualifications: \n  \n  Skills and Experience: \n \n \n  Strong analytical and decision-making skills. \n  Exceptional attention to detail and organization skills. \n  Experience in volume driven and time sensitive work environments. \n  Proficiency using the internet search tools and social media platforms. \n  Extensive experience/knowledge with Microsoft Excel, My SQL. \n  Fluency in data analysis and presentation. \n \n \n  Qualifications: \n \n \n  College degree (B.S./B.A.) or work experience equivalent in the financial industries or Risk services, at least 4 years. \n  Investigations / analysis background a plus \n  Very knowledgeable in MS Office applications \n  Familiarity with SQL, ability to generate and provide analysis of reporting. \n  Very strong attention to detail \n  Ability to communicate well in writing and on various internal company chat channels. \n  Ability to work remotely and as a part of a remote team. \n \n \n  Risk Analysts who excel in this role: \n \n \n  Demonstrate the ability to make connections that clarify information and produce insights. \n  Are able to work with and analyze data sets to establish trends. \n  Can recognize patterns and use information to establish fraud trends. \n  Are creative thinkers who can approach each order contingently. \n  Look to learn and teach in every collaboration. \n  Are comfortable running multiple software solutions concurrently. \n  Exhibit\u2019s confidence to make independent decisions based on analytical results. \n  Can work independently, but also thrives in a team-oriented environment. \n \n \n   Employer will conduct background check.\n   Benefits: \n  \n   Salary Range for all U.S. Residents (excluding Alaska, California, North Dakota, South Dakota): $55,440.00 to $72,000.00\n  \n \n \n  Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, Blackhawk Network offers benefits including 401k with employer match, medical, dental, vision, 12 paid holidays in the year 2023, sick pay accrual according to state law, parental leave, life insurance, disability insurance, accident and illness insurance, health and dependent care flexible spending accounts, wellness benefits, and flexible time off for all full-time employees. \n  EEO Statement: \n  \n   Blackhawk Network provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. Blackhawk Network believes that diversity leads to strength. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\n  \n \n \n  Blackhawk Network encourages applicants with previous criminal records to apply to all positions and, pursuant to the San Francisco and Los Angeles Fair Chance Acts (and other \u201cFair Chance\u201d laws), Blackhawk Network will consider for employment qualified applicants with arrest and conviction records. For Philadelphia applicants or jobs, please see a copy of Philadelphia\u2019s ordinance on this topic by clicking this link: https://codelibrary.amlegal.com/codes/philadelphia/latest/philadelphia_pa/0-0-0-280104.", "cleaned_desc": " \n  Strong analytical and decision-making skills. \n  Exceptional attention to detail and organization skills. \n  Experience in volume driven and time sensitive work environments. \n  Proficiency using the internet search tools and social media platforms. \n  Extensive experience/knowledge with Microsoft Excel, My SQL. \n  Fluency in data analysis and presentation. \n \n \n  Qualifications: \n \n \n  College degree (B.S./B.A.) or work experience equivalent in the financial industries or Risk services, at least 4 years. \n  Investigations / analysis background a plus \n  Very knowledgeable in MS Office applications ", "techs": ["microsoft excel", "mysql", "ms office applications"]}, "4313f70137ff841e": {"terms": ["data analyst"], "salary_min": 102281.16, "salary_max": 123280.8, "title": "FT Sr. Applications Analyst (Programmer) - Remote assignment may be considered", "company": "Cerritos College", "desc": "FT Sr. Applications Analyst (Programmer) - Remote assignment may be considered \n \n \n  Salary:  $102,281.16 - $123,280.80 Annually\n  \n Job Type:  Full Time\n  \n Job Number:  Sr. App-Analyst-2023-IT\n  \n Closing:  11/6/2023 11:59 PM Pacific\n  \n Location:  Norwalk, CA\n  \n Department:  Sr. App-Analyst-2023-IT\n  \n Division:  Information Technology\n  \n \n Description \n \n Equity and Diversity \n \n The District is strongly committed to achieving staff diversity and the principles of equal opportunity employment. The District encourages a diverse pool of applicants and does not discriminate on the basis of race, color, national origin, ancestry, sex, age, religion, marital status, disability, or sexual orientation in any of its policies, procedures or practices. In fact, the college encourages applications from all segments of qualified people. \n \n \n Closing Date \n \n This position will close on November 6, 2023 at 11:59 PM (or when 150 applications are received, whichever occurs sooner).   \n \n \n \n College Profile \n \n  Cerritos College is ranked 14th among the top 100 schools with the highest Hispanic enrollment in the United States by the United States Department of Education. Cerritos College serves as a comprehensive community college for southeastern Los Angeles County. Communities within the College's district include Artesia, Bellflower, Cerritos, Downey, Hawaiian Gardens, La Mirada, Norwalk, and portions of Bell Gardens, Lakewood, Long Beach, Santa Fe Springs and South Gate. Cerritos College offers degrees and certificates in more than 180 areas of study in nine divisions. Enrollment currently averages 20,000 students. Visit Cerritos College online at www.cerritos.edu.\n  \n \n \n \n \n Department Profile \n  The Information Technology Department includes four managers and 22 full-time staff members. Of Which, there are currently six Senior Applications Analysts positions supporting our PeopleSoft ERP system under the supervision and direction of the Director of Information Technology.\n  \n  The Information Technology Department at Cerritos College supports and maintains both instructional and non-instructional functions for the entire campus community on a 140-acre campus.\n  \n \n Distinguishing Career Features \n \n  The position requires expanded capability to consult with users from multiple functions, and for original multi-faceted, multiple platform applications, lead complex projects involving multiple departments/committees, work independently on multiple platforms, and write complete standalone systems in several languages. Incumbents are expected to maintain expertise in one of the College's major systems such as business/finance packages or student information systems, and will demonstrate the ability to install, test, customize and maintain standardized applications.\n  \n \n Summary \n \n  Performs advanced analysis, development, coding, testing, and documentation of computer systems and purchased integrated applications on multiple platforms for academic and/or business purposes, following systems development and project management procedures. Consults with staff and coordinates projects for the design and modification of complex and multi-faceted applications. Provides technical support, troubleshooting and problem resolution for staff on computer applications. Develops interfaces to external system.\n  \n \n Job Duties \n \n Essential Duties and Responsibilities \n \n \n  Serves as a leader for projects by coordinating and otherwise involving staff members from multiple organizational units. Follows systems development life-cycle techniques and utilizes joint application development processes and project management techniques and specialized software packages/applications. \n  Defines the scope and objectives for applications, along with constraints and system requirements. Analyzes and defines current organizational functions, processes, sources and uses of information, and other data to determine application needs and requirements. \n  Conceptualizes, analyzes, designs, and programs highly diverse and complex programs for administrative and academic users. An example of the programs includes integrating unrelated database fields and sources of data to common access on a desktop computer. Delegates, reviews, and writes the code and completes the documentation to include specifications and miscellaneous notes for all programs. \n  Documents workflow using organization and data flow charts and other related materials. Produces application design specifications and documentation on inputs, outputs, and data structures. \n  Identifies and documents business processes and workflow that contribute to enhanced information flow by interviewing users, generating process documentation, and proposing process solutions. Identifies information and software to support processes. \n  Prepares system design specifications and documentation for all data input, output, and structures. \n  Provides support to operating system applications encompassing data integration. Creates utilities and tools, and troubleshoots database problems to enhance applications. \n  Coordinates, defines, prepares, and modifies original applications, involving staff members of multiple organizational units, usually in one or more committee formats. \n  Organizes the features included in applications by determining the sequence of detailed operations, determining program outcomes, and designing internal program processes. \n  Designs inputs, including data entry screens, scanner forms and files. Designs outputs, including reports, files, and display screens. Designs, develops, and implements logical and physical database structures and relationships for microcomputers and network systems. \n  Develops, codes, tests, and maintains application software on various platforms. Performs initial testing to application specifications using testing environments, before releasing versions for use. \n  Coordinates and implements data conversions and transitions from old to new systems using extract, transform, and load processes. Develops user and system documentation. \n  Provides advanced technical support, problem resolution, and data research for assigned end users. \n  Troubleshoots application errors. In conjunction with users, isolates problems from symptoms, determines alternatives and develops and implements solutions. If problem is user error, works with staff to improve user instructions or train for better understanding. \n  Works with external agencies, independent contractors, vendors, and organizations on technology services, applications, and/or data requirements. \n  Maintains up-to-date knowledge of evolving computer technologies, including hardware, software, languages, problem solving techniques, and development tools. Prepares periodic briefings on technologies that would have relevance to the College. \n  May perform network and server administration duties. \n  Maintains currency of knowledge and skills related to the duties and responsibilities.  Performs other related duties as assigned. \n  \n \n \n Minimum Qualifications \n \n \n Education and Experience \n  The position requires a Bachelor's degree, plus four years of progressive experience in applications development and support. Additional experience in applications development may substitute for some higher education. Computer science or related discipline degree is preferable.\n  \n \n Supplemental Information \n \n \n Knowledge and Skills \n \n  The position requires in-depth knowledge of program development techniques, procedures, tools, and documentation requirements as well as software systems development life cycles. Requires in-depth knowledge of complex principles and procedures of computer systems, including analysis, and design. Requires in-depth knowledge of relational database concepts, design techniques, and tools. Requires in-depth knowledge of computer file methods, structured testing techniques, and programming languages used by the District to support ERP, or others currently in industry use. Requires in-depth knowledge of object-oriented software development techniques and tools. Requires problem solving and analytical skills. Requires well-developed human relations skills to facilitate small group processes, conduct training, provide technical support, and apply understandable lines of questioning when trying to understand department needs or problems. \n  \n \n Abilities \n \n  Must be able to operate a variety of computers, printers, and peripheral equipment. Requires the ability to analyze technical problems and to develop and apply appropriate solutions. Requires the ability to conduct information interviews through individual conferences and group processes, and then translate user requirements into computer programs and systems. Must be able to coordinate systems development functions and steps and follow logical progressions for programming systems. Must be able to design, program, install, and maintain programs for original and purchased applications and systems, including databases. Requires the ability to design host computer logical and physical database structure and relationships, including those for microcomputer and network systems. Requires the ability to write basic to complex programs using ERP tools or other languages. Requires the ability to analyze data and develop logical solutions. Requires the ability to translate the English language into computer languages and debug program code. Requires the ability to discuss technical information with users, discern their needs and develop programs, systems, screens, etc., which meet those needs. Must be able to communicate technical and complex information to nontechnical users. Requires the ability to provide training to on-line users in use of computer equipment and operating procedures. Must be able to read, understand and apply information from technical manuals and education code regulations. Must be able to prioritize work in order to meet deadlines and maintain schedules. Requires the ability to work cooperatively and productively with others.\n  \n \n Physical Abilities \n  Incumbent must be able to function effectively indoors engaged in work of primarily a sedentary nature. Ability to sit for extended periods of time to accomplish data input and desk work. Requires sufficient hand, arm, speech recognition, and finger dexterity to use a personal computer keyboard, multimedia presentation, and other office equipment. Requires normal hearing and speaking skills to communicate with staff in one-on-one and small group settings, and distinguish sound prompts from equipment. Visual acuity to read printed materials and computer screens. Requires the ability to occasionally push, pull or lift a maximum of 50 lbs. from overhead, waist and floor levels with assistance from co-workers as necessary.\n  \n \n Licenses and Certificates \n  May require a valid driver's license.\n  \n \n Working Conditions \n  Work is performed indoors where minimal safety considerations exist. Remote assignment may be considered. \n  \n \n Salary/Fringe Benefits \n \n  Grade 52 on District Classified Salary Schedule ($8,523.43 - $10,273.40 /month).\n  \n  Health and welfare benefits include District contribution for medical/dental/vision benefits and employee life insurance ($50,000). (Cash in lieu option available on medical insurance.)\n  \n  Participation in the Public Employee's Retirement System that is also integrated with Social Security.\n  \n \n Conditions of Employment \n \n  This is a full-time, 12-calendar month classified position. \n  \n  Hours of employment are:\n  \n  Monday thru Friday 8:00 am to 4:30 pm\n  \n  Initial placement of employees on Classified Salary schedule is at Step 1. After six months of successful probationary employment, employee is placed at Step 2.\n  \n  Employment is to be effective as soon as possible following completion of the selection process.\n  \n  Individual who is offered employment shall be required to obtain fingerprints for a criminal history clearance through the State Department of Justice and remit the required fee for processing the fingerprints, Federal Bureau of Investigation (no fee if obtained at Cerritos College Campus Police Station), produce an original social security card, and submit negative TB test results (must be within the past four years or within the last 60 days if not previously employed in a school district in California) before employment.\n  \n  Proof of eligibility to work in the United States and signing of loyalty oath per Government Codes 3100-3109.\n  \n \n **Please note - the District does not provide for immigration sponsorships such as H1B Visas \n \n  Board Policy 2905 requires mandatory COVID-19 vaccinations as a condition of employment. The District requires all employees to submit proof of full vaccination against COVID-19, as defined by the CDC. Full policy details can be found on the website; Cerritos College - Chapter 2 - Board of Trustees. Employees may submit requests for medical or religious exemptions to the vaccine mandate for consideration. Details are available on the District's COVID-19 webpage.\n  \n \n Application Procedures \n \n  Application materials must be submitted by the closing date. Applicants who need special services or facilities due to disability in order to apply or interview for this position must notify Human Resources at the time of application or at least 72 hours prior to the closing date or date of a scheduled interview.\n   It is the applicant's responsibility to provide copies of all transcript(s) verifying all educational degree(s) and/or coursework required for the position. Transcripts must be from regionally accredited institutions. A foreign transcript must be evaluated by a NACES certified agency. The website address is www.naces.org.\n  \n \n \n \n Required Documents needed to apply \n \n \n  Resume/Curriculum Vitae   \n  Cover letter / Letter of Interest   \n  Transcripts (Must show all coursework completed and the conferral date of the degree) \n \n \n  To apply, visit  \n https://www.schooljobs.com/careers/cerritosedu/jobs/4236252/ft-sr-applications-analyst-programmer-remote-assignment-may-be-considered \n \n \n The District ensures that all qualified applicants for employment and employees have full and equal access to employment opportunity, and are not subjected to discrimination in any program or activity of the District on the basis of national origin, religion, age, sex or gender, race, color, medical condition, ancestry, sexual orientation, marital status, veteran status, physical or mental disability, or because he or she is perceived to have one or more of the foregoing characteristics, or based on association with a person or group with one or more of these actual or perceived characteristics. . jeid-92681b5260013643884005d2abc9c577", "cleaned_desc": " \n  Cerritos College is ranked 14th among the top 100 schools with the highest Hispanic enrollment in the United States by the United States Department of Education. Cerritos College serves as a comprehensive community college for southeastern Los Angeles County. Communities within the College's district include Artesia, Bellflower, Cerritos, Downey, Hawaiian Gardens, La Mirada, Norwalk, and portions of Bell Gardens, Lakewood, Long Beach, Santa Fe Springs and South Gate. Cerritos College offers degrees and certificates in more than 180 areas of study in nine divisions. Enrollment currently averages 20,000 students. Visit Cerritos College online at www.cerritos.edu.\n  \n \n \n \n \n Department Profile \n  The Information Technology Department includes four managers and 22 full-time staff members. Of Which, there are currently six Senior Applications Analysts positions supporting our PeopleSoft ERP system under the supervision and direction of the Director of Information Technology.\n  \n  The Information Technology Department at Cerritos College supports and maintains both instructional and non-instructional functions for the entire campus community on a 140-acre campus.\n  \n \n Distinguishing Career Features \n \n  The position requires expanded capability to consult with users from multiple functions, and for original multi-faceted, multiple platform applications, lead complex projects involving multiple departments/committees, work independently on multiple platforms, and write complete standalone systems in several languages. Incumbents are expected to maintain expertise in one of the College's major systems such as business/finance packages or student information systems, and will demonstrate the ability to install, test, customize and maintain standardized applications.\n  \n \n Summary \n \n  Performs advanced analysis, development, coding, testing, and documentation of computer systems and purchased integrated applications on multiple platforms for academic and/or business purposes, following systems development and project management procedures. Consults with staff and coordinates projects for the design and modification of complex and multi-faceted applications. Provides technical support, troubleshooting and problem resolution for staff on computer applications. Develops interfaces to external system.\n  \n \n Job Duties \n \n Essential Duties and Responsibilities \n \n \n  Serves as a leader for projects by coordinating and otherwise involving staff members from multiple organizational units. Follows systems development life-cycle techniques and utilizes joint application development processes and project management techniques and specialized software packages/applications. \n  Defines the scope and objectives for applications, along with constraints and system requirements. Analyzes and defines current organizational functions, processes, sources and uses of information, and other data to determine application needs and requirements. \n  Conceptualizes, analyzes, designs, and programs highly diverse and complex programs for administrative and academic users. An example of the programs includes integrating unrelated database fields and sources of data to common access on a desktop computer. Delegates, reviews, and writes the code and completes the documentation to include specifications and miscellaneous notes for all programs. \n  Documents workflow using organization and data flow charts and other related materials. Produces application design specifications and documentation on inputs, outputs, and data structures.    Identifies and documents business processes and workflow that contribute to enhanced information flow by interviewing users, generating process documentation, and proposing process solutions. Identifies information and software to support processes. \n  Prepares system design specifications and documentation for all data input, output, and structures. \n  Provides support to operating system applications encompassing data integration. Creates utilities and tools, and troubleshoots database problems to enhance applications. \n  Coordinates, defines, prepares, and modifies original applications, involving staff members of multiple organizational units, usually in one or more committee formats. \n  Organizes the features included in applications by determining the sequence of detailed operations, determining program outcomes, and designing internal program processes. \n  Designs inputs, including data entry screens, scanner forms and files. Designs outputs, including reports, files, and display screens. Designs, develops, and implements logical and physical database structures and relationships for microcomputers and network systems. \n  Develops, codes, tests, and maintains application software on various platforms. Performs initial testing to application specifications using testing environments, before releasing versions for use. \n  Coordinates and implements data conversions and transitions from old to new systems using extract, transform, and load processes. Develops user and system documentation. \n  Provides advanced technical support, problem resolution, and data research for assigned end users. \n  Troubleshoots application errors. In conjunction with users, isolates problems from symptoms, determines alternatives and develops and implements solutions. If problem is user error, works with staff to improve user instructions or train for better understanding. \n  Works with external agencies, independent contractors, vendors, and organizations on technology services, applications, and/or data requirements. \n  Maintains up-to-date knowledge of evolving computer technologies, including hardware, software, languages, problem solving techniques, and development tools. Prepares periodic briefings on technologies that would have relevance to the College. \n  May perform network and server administration duties. \n  Maintains currency of knowledge and skills related to the duties and responsibilities.  Performs other related duties as assigned. \n  \n \n \n Minimum Qualifications \n \n \n Education and Experience \n  The position requires a Bachelor's degree, plus four years of progressive experience in applications development and support. Additional experience in applications development may substitute for some higher education. Computer science or related discipline degree is preferable.\n  \n \n Supplemental Information \n \n \n Knowledge and Skills \n \n  The position requires in-depth knowledge of program development techniques, procedures, tools, and documentation requirements as well as software systems development life cycles. Requires in-depth knowledge of complex principles and procedures of computer systems, including analysis, and design. Requires in-depth knowledge of relational database concepts, design techniques, and tools. Requires in-depth knowledge of computer file methods, structured testing techniques, and programming languages used by the District to support ERP, or others currently in industry use. Requires in-depth knowledge of object-oriented software development techniques and tools. Requires problem solving and analytical skills. Requires well-developed human relations skills to facilitate small group processes, conduct training, provide technical support, and apply understandable lines of questioning when trying to understand department needs or problems. \n  \n ", "techs": ["peoplesoft erp system", "multiple platforms", "business/finance packages", "student information systems", "systems development life-cycle techniques", "joint application development processes", "project management techniques", "specialized software packages/applications", "data flow charts", "data integration", "utilities and tools", "database problems", "logical and physical database structures", "microcomputers and network systems", "application software", "testing environments", "extract", "transform", "and load processes", "advanced technical support", "troubleshooting", "evolving computer technologies", "hardware", "software", "languages", "problem solving techniques", "development tools", "network and server administration", "program development techniques", "software systems development life cycles", "relational database concepts", "structured testing techniques", "programming languages", "object-oriented software development techniques"]}, "078d36d92ae3493e": {"terms": ["data analyst"], "salary_min": 86641.6, "salary_max": 109707.57, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "8b19cc4bcd9c86cf": {"terms": ["data analyst"], "salary_min": 55.0, "salary_max": 60.0, "title": "SAS Developer/Analyst_ W2 Position", "company": "hire IT people", "desc": "Position: SAS Developer \n Location: McLean, VA or Plano, TX \n Duration : 3 month contract to hire \n Rate : $60/hr \n Visa : USC or GC holder or EAD \n Required Experience : hands-on experience with the following technologies... \n \n SAS (3+ years of experience) \n SQL & Unix \n Shell scripting \n DB2 systems database \n Control M or Autosys \u2013 or any other scheduling tool \n \n Nice to have: \n \n Python \n Java \n Datastage \n AWS \n \n Job Types: Contract, Full-time \n Salary: $55.00 - $60.00 per hour \n Experience level: \n \n 10 years \n 11+ years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Experience: \n \n SAS Developer: 10 years (Preferred) \n SQL & Unix: 7 years (Preferred) \n Shell Scripting: 7 years (Preferred) \n DB2 systems database: 7 years (Preferred) \n Control M or Autosys: 7 years (Preferred) \n USC or GC holder or EAD: 1 year (Preferred) \n $60/hr on w2 AL: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "8767d77c3f26e6df": {"terms": ["data analyst"], "salary_min": 97750.0, "salary_max": 115000.0, "title": "Smart Buildings Analyst", "company": "JLL", "desc": "JLL supports the Whole You, personally and professionally. \n  Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you\u2019ve got deep experience in commercial real estate, skilled trades, and technology, or you\u2019re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally. \n \n  In this role, you will work with one of our high-profile clients, acting as an embedded extension of their in-house sustainability team. As a member of the JLL Sustainability Data & Reporting Team, this position will report to the on-account Sustainability Data Optimization Lead while working closely with the Technical Innovations Director to manage smart building metering system performance, data management and modeling. \n \n  The position is required to work collaboratively across internal global business lines including JLL\u2019s Client Account, Technology and Operations teams to help manage stakeholder expectations and maintain high quality service delivery. \n \n  The ideal candidate will be located in the California Bay Area, however the position can be remote for the right candidate (can be located anywhere in the U.S.) with travel to the Bay area as needed. \n \n  What this job involves \n  The Smart Buildings Analyst role will join JLL\u2019s Sustainability Data and Reporting team to support our client's data management in regards to smart building technologies, metering and building system performance and modeling. This role will primarily focus on the review and tracking of the Fault Detection and Diagnostics (FDD) platform outputs to validate opportunities, while investigating opportunities and quantifying the building operational impacts of correcting faults. Engagement with the Building Performance engineering team will be required for implementation of the FDD findings.  \n \n The position is required to work collaboratively across internal global business lines including JLL\u2019s Client Account, Technology and Operations teams to help manage stakeholder expectations and maintain high quality service delivery. \n \n  Key responsibilities include: \n \n  Working with other team members across the practice to develop, maintain, and improve upon the smart buildings program components, such as Fault Detection and Diagnostics (FDD), and performance targets for regional operations implementation. \n  Develop a detailed understanding of JLL\u2019s sustainability reporting application, Canopy, and how we support our clients in measuring their sustainability performance. \n  Work with client delivery and development teams to ensure program smart building system milestones are being met. \n  Develop a detailed understanding of data structures within client\u2019s data. \n  Work closely with the Building Performance team to implement measures that improve energy efficiency, reduce carbon footprint and enhance building sustainability and performance. \n  Collaborate with internal teams and external consultants to identify and resolve technical issues that arise during the implementation of smart building solutions. \n  Document technical issues and solutions to create a shared knowledge base that facilitates effective problem-solving and decision-making. \n  Analyze data on building systems to identify patterns that may indicate larger issues and guide efforts to develop, maintain, and improve the smart buildings program components. \n  Develop a deep understanding of the sustainability reporting application and work with clients to measure their sustainability performance. \n  Work closely with client delivery and development teams to ensure that program milestones are being met. \n \n \n  Performance objectives \n \n  Drive tangible impacts from the correction of faults identified by the FDD platform. \n  The role requires the ability to actively manage concurrent projects and a strong talent for project coordination. \n  Regularly communicate in a clear and non-technical way to internal JLL and client users. \n  Be an integral part of the data and reporting team, contributing to the efficient monitoring and management of building performance and systems improvement, following internal processes and ongoing performance improvement of the team. \n  Identify areas for improvement for data strategy across the technology and process surrounding smart building and metering systems. \n  Manage data strategy for smart metering systems across the portfolio. \n \n \n  Key skills \n \n  The ability to manage multiple deliverables with inter-related dependencies \n  Strong organizational skills and process-driven, with an orientation toward continuous process improvement \n  Strong emotional intelligence and capacity to deliver an excellent client experience. \n  Strong ability to clearly identify issues with data and raise them to the appropriate JLL team member. \n  Ability to work to a defined milestone date and raise any concerns early and often. \n  Knowledge and comfort with building smart systems and metering applications. \n \n \n  Candidate specification \n \n  3-5 years\u2019 experience in a similar technical analyst role. \n  Knowledge and working experience in the built environment, facilities management, building operations, MEP, and building automation systems.  \n High proficiency in Microsoft Excel and data management. \n  Excellent communication skills including the ability to identify and describe data anomalies and provide solutions accordingly. \n  Lateral thinking and problem-solving skills. \n  Ability to multi-task and manage priorities to meet deadlines. \n  A strong desire to deliver a quality outcome for the client and end users. \n  Experience and understanding of sustainability and carbon emissions reporting will be a strong advantage. \n  Project management experience would be an advantage. \n  This role requires a high attention to detail and a strong process-driven approach. \n \n \n  Estimated compensation for this position is: \n  97,750.00 \u2013 115,000.00 USD\n  \n  The pay range listed is a total compensation range including bonus, if applicable. The provided range is an estimate and not guaranteed. An employment offer is based on applicant\u2019s education, experience, skills, abilities, geographic location, internal equity and alignment with market data. \n \n  Location: \n  Remote \u2013Mountain View, CA, Sunnyvale, CA\n  \n  If this job description resonates with you, we encourage you to apply, even if you don\u2019t meet all the requirements. We\u2019re interested in getting to know you and what you bring to the table! \n  Personalized benefits that support personal well-being and growth: \n \n  JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health. Some of these benefits may include: \n \n  401(k) plan with matching company contributions \n  Comprehensive Medical, Dental & Vision Care \n  Paid parental leave at 100% of salary \n  Paid Time Off and Company Holidays \n  Flexible and Remote Work Arrangements may be available \n \n \n  About JLL  \u2013 \n \n  For over 200 years, JLL (NYSE: JLL), a leading global commercial real estate and investment management company, has helped clients buy, build, occupy, manage and invest in a variety of commercial, industrial, hotel, residential and retail properties. A Fortune 500 company with annual revenue of $20.9 billion and operations in over 80 countries around the world, our more than 103,000 employees bring the power of a global platform combined with local expertise. Driven by our purpose to shape the future of real estate for a better world, we help our clients, people and communities SEE A BRIGHTER WAY. JLL is the brand name, and a registered trademark, of Jones Lang LaSalle Incorporated. For further information, visit jll.com. \n \n  JLL Privacy Notice \n  Jones Lang LaSalle (JLL), together with its subsidiaries and affiliates, is a leading global provider of real estate and investment management services. We take our responsibility to protect the personal information provided to us seriously. Generally the personal information we collect from you are for the purposes of processing in connection with JLL\u2019s recruitment process. We endeavour to keep your personal information secure with appropriate level of security and keep for as long as we need it for legitimate business or legal reasons. We will then delete it safely and securely. \n \n  For more information about how JLL processes your personal data, please view our Candidate Privacy Statement. \n \n  For additional details please see our career site pages for each country. \n \n  For candidates in the United States, please see a full copy of our Equal Employment Opportunity and Affirmative Action policy here. \n \n  This position may require you to be fully vaccinated against COVID-19. If required, you\u2019ll be asked to provide proof that you\u2019re fully vaccinated upon your start date. You\u2019re considered fully vaccinated two weeks after you receive the second dose of a two-dose vaccine series (e.g., Pfizer or Moderna) or two weeks after a single-dose vaccine (e.g., Johnson & Johnson/Janssen). Failure to provide proof of vaccination may result in termination. \n \n  Jones Lang LaSalle (\u201cJLL\u201d) is an Equal Opportunity Employer and is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process \u2013 including the online application and/or overall selection process \u2013 you may contact us at Accommodation Requests. This email is only to request an accommodation. Please direct any other general recruiting inquiries to our Contact Us page > I want to work for JLL. \n \n  Pursuant to the Arizona Civil Rights Act, criminal convictions are not an absolute bar to employment. \n \n  Pursuant to Illinois Law, applicants are not obligated to disclose sealed or expunged records of conviction or arrest. \n \n  Pursuant to Columbia, SC ordinance, this position is subject to a background check for any convictions directly related to its duties and responsibilities. Only job-related convictions will be considered and will not automatically disqualify the candidate. \n \n  California Residents only \n  If you are a California resident as defined in the California Consumer Privacy Act (CCPA) please view our  Supplemental Privacy Statement  which describes your rights and disclosures about your personal information. If you are viewing this on a mobile device you may want to view the CCPA version on a larger device. \n \n  Pursuant to the Los Angeles Fair Chance Initiative for Hiring Ordinance, JLL will consider for employment all qualified Applicants, including those with Criminal Histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles\u2019 Fair Chance Initiative for Hiring Ordinance. \n \n  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.", "cleaned_desc": "  Document technical issues and solutions to create a shared knowledge base that facilitates effective problem-solving and decision-making. \n  Analyze data on building systems to identify patterns that may indicate larger issues and guide efforts to develop, maintain, and improve the smart buildings program components. \n  Develop a deep understanding of the sustainability reporting application and work with clients to measure their sustainability performance. \n  Work closely with client delivery and development teams to ensure that program milestones are being met. \n \n \n  Performance objectives \n \n  Drive tangible impacts from the correction of faults identified by the FDD platform. \n  The role requires the ability to actively manage concurrent projects and a strong talent for project coordination. \n  Regularly communicate in a clear and non-technical way to internal JLL and client users. \n  Be an integral part of the data and reporting team, contributing to the efficient monitoring and management of building performance and systems improvement, following internal processes and ongoing performance improvement of the team. \n  Identify areas for improvement for data strategy across the technology and process surrounding smart building and metering systems. \n  Manage data strategy for smart metering systems across the portfolio. \n \n \n  Key skills \n \n  The ability to manage multiple deliverables with inter-related dependencies \n  Strong organizational skills and process-driven, with an orientation toward continuous process improvement \n  Strong emotional intelligence and capacity to deliver an excellent client experience. \n  Strong ability to clearly identify issues with data and raise them to the appropriate JLL team member.    Ability to work to a defined milestone date and raise any concerns early and often. \n  Knowledge and comfort with building smart systems and metering applications. \n \n \n  Candidate specification \n \n  3-5 years\u2019 experience in a similar technical analyst role. \n  Knowledge and working experience in the built environment, facilities management, building operations, MEP, and building automation systems.  \n High proficiency in Microsoft Excel and data management. \n  Excellent communication skills including the ability to identify and describe data anomalies and provide solutions accordingly. \n  Lateral thinking and problem-solving skills. \n  Ability to multi-task and manage priorities to meet deadlines. \n  A strong desire to deliver a quality outcome for the client and end users. \n  Experience and understanding of sustainability and carbon emissions reporting will be a strong advantage. \n  Project management experience would be an advantage. \n  This role requires a high attention to detail and a strong process-driven approach. \n \n \n  Estimated compensation for this position is: \n  97,750.00 \u2013 115,000.00 USD\n  \n  The pay range listed is a total compensation range including bonus, if applicable. The provided range is an estimate and not guaranteed. An employment offer is based on applicant\u2019s education, experience, skills, abilities, geographic location, internal equity and alignment with market data. ", "techs": ["technical issues and solutions", "knowledge base", "problem-solving", "decision-making", "data analysis", "building systems", "smart buildings program", "sustainability reporting application", "project coordination", "communication skills", "data strategy", "smart metering systems", "deliverables management", "organizational skills", "continuous process improvement", "emotional intelligence", "client experience", "data anomaly identification", "microsoft excel", "lateral thinking", "problem-solving", "multitasking", "deadline management", "quality outcome", "sustainability reporting", "carbon emissions reporting", "project management", "attention to detail", "compensation", "bonus"]}, "9acdb5ef63379ce9": {"terms": ["data analyst"], "salary_min": 85700.09, "salary_max": 108515.41, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "b0c43c5033dbcee3": {"terms": ["data analyst"], "salary_min": 85929.125, "salary_max": 108805.42, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "92ead780d23bee3d": {"terms": ["data analyst"], "salary_min": 84628.95, "salary_max": 107159.11, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "7d960bde6cc6ed45": {"terms": ["data analyst"], "salary_min": 83185.9, "salary_max": 105331.88, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "9729bbad7cf4802e": {"terms": ["data analyst"], "salary_min": 83658.52, "salary_max": 105930.336, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "c722ec426ad6905e": {"terms": ["data analyst"], "salary_min": 83658.52, "salary_max": 105930.336, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "unisense search", "gdpr", "hippa", "spi"]}, "d85e5a3748653c02": {"terms": ["data analyst"], "salary_min": 86215.9, "salary_max": 109168.54, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "76102ad8dd75d13c": {"terms": ["data analyst"], "salary_min": 84272.01, "salary_max": 106707.13, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "ootb (out of the box) connectors", "metadata owner and driver", "data lineage", "data catalog", "business glossary", "technical metadata harvesting", "data domains", "data elements", "metadata model design", "data catalog architecture", "data asset identification", "data asset ownership", "data asset usage", "data access control policies", "data classification", "taxonomy", "hierarchies", "data dictionary", "data lineage tracking", "intermediate transformations", "curations layers", "point of data element creation", "point of data consumption", "automated workflows", "sensitive data management", "data-related controls", "data steward", "data owner operating model", "training programs"]}, "37723ddf6ddf57de": {"terms": ["data analyst"], "salary_min": 87571.89, "salary_max": 110885.53, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "14f4e08b69110dfe": {"terms": ["data analyst"], "salary_min": 84239.94, "salary_max": 106666.53, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "data domain discovery", "data classification", "taxonomy", "hierarchies", "data catalog architecture", "business glossaries", "data dictionary", "data lineage", "metadata", "technical metadata harvesting", "data asset identification", "data asset ownership", "data asset usage", "data asset access control policies", "data catalog", "data stewardship", "data governance", "data management", "gdpr", "hippa", "spi", "sensitive data", "data-related controls"]}, "79c3ad9dd927e16d": {"terms": ["data analyst"], "salary_min": 79200.0, "salary_max": 88000.0, "title": "Sr Analyst, Retail Ops", "company": "Constellation", "desc": "Location: , Hybrid Remote, United States  Organization: Constellation New Energy, Inc.  Job ID: 247676  Date Posted: Oct 11, 2023 \n \n \n \n \n \n \n \n \n \n \n \n \n \n Job Description \n Description   \n COMPANY OVERVIEW \n  As the nation's largest producer of clean, carbon-free energy, Constellation is a company purposely-built to meet the challenges of the climate crisis. Constellation has been the leader in clean energy production for more than a decade and we are growing our company and capabilities. Now, we're accelerating, speeding our low-carbon or no-carbon power to more people in more places, day and night, providing our customers and communities with options to buy, manage and use energy as part of their decarbonization mission. The race is on to confront the climate crisis and Constellation is ready to meet the challenge. Come join us as we lead energy, together. \n  TOTAL REWARDS \n  Constellation offers a wide range of benefits and rewards, designed to help our employees thrive professionally and personally. In addition to highly competitive salaries, we offer a bonus program, 401(k) with company match, employee stock purchase program; comprehensive medical, dental and vision benefits, including a robust wellness program; paid time off for vacation, holidays and sick days; and much more.    Expected salary range of $79,200 to $88,000, varies based on experience, along with comprehensive benefits package that includes bonus and 401(k).     PRIMARY PURPOSE OF POSITION \n  Constellation is seeking a qualified professional with proven experience and results to join our Retail Operations team as a Senior Analyst. The Senior Analyst is responsible for leveraging subject matter expertise in the daily execution of their team's work processes, for handling complex issues and escalations, and for exceptional communication and change management both within their work group and with internal and external stakeholders. The Senior Analyst is also responsible for driving process improvement and system enhancements, often collaborating with project groups, Information Technology and cross-functional teams.  \n PRIMARY DUTIES AND ACCOUNTABILITIES \n \n  Ensure Effortless Customer Experience Performing Operational Duties (Operational Excellence): Responsible for one or more of the following functions of the order to cash process: managing data used to ensure competitive pricing and accurate billing for customers while minimizing risk to Constellation; enrolling customers with the utility to ensure they have power or gas when needed; processing contracts and/or confirms to ensure SOX compliance; managing customer payments to ensure accurate posting of cash to customer accounts and accurate revenue recognition; timely 3rd party payments; address internal/external customer inquiries timely and accurately; vendor and system support. \n  Cross Functional Communications(Operational Excellence): Review and communicate issues to team members, leads, management and stakeholders with emphasis on customer information and system and process improvement opportunities. Initiate and foster collaboration with team members to ensure seamless customer support and knowledge transfer. Proactively communicate workflow system or process concerns to avoid or fully remediate issues that cross multiple groups. Adopt, support and promote change management activities. Interface with internal and/or external customers in handling and resolving inquiries as needed.  \n Projects, Improvements, and Innovation(Process Improvements/Projects): Proactively challenge the status quo to automate and improve processes through innovation by creating and/or leveraging new technologies or work processes, with focus and intent on implementing their sustainable solutions. Leverage subject matter expertise in working with project groups, Information Technology and cross-functional teams for key deliverables. Identify and create business requirements for enhancements to systems and existing processes, based on understanding and evaluating business needs. Develop test scripts for business processes, system enhancements and bug fixes as needed.  \n Problem Solving and Issue Resolution (Problem Solving/Analytics): Exercise independent judgment, analytical abilities, and leverage subject matter expertise to investigate discrepancies in work processes. Take necessary actions to resolve issues, including working with other functional teams as needed. Compare and evaluate alternatives, using discretion to select and execute appropriate course of action to fully resolve customer issues (such as courtesy credits), working with other functional teams and leveraging alternate technologies as needed. \n  Comprehension/Adherence of Policies and Controls (Operational Excellence): Maintain an understanding of business, contractual, regulatory, and market policies/tariff and ensure assigned workflow processes are aligned. Ensure that all Sarbanes-Oxley (\"SOX\") Key Controls and other company policies are followed. \n \n  Qualifications   \n MINIMUM QUALIFICATIONS - Sr. Analyst, Retail Pricing \n \n Bachelor's degree with 3+ work experience required; or 6+ years combination of education and relevant work experience. \n Advanced skills with Microsoft Office applications (Word, Excel, PowerPoint and Access). \n Ability to communicate effectively and professionally with internal and external parties as required. \n Can obtain and analyze data independently and can reason through complex scenarios to suggest course of action or remediation. \n Effectively communicate with, develop and maintain professional relationships with internal and external customers. \n Excellent attention to detail knowing others will depend on it being correct. \n Works independently and as a team member. \n Strong organizational and time management skills - ability to organize and prioritize a fast-paced, heavy workload. \n Adapts to changing markets, systems, and processes. \n Works in tight deadlines and shifting priorities but continues to be organized and methodical. \n Proactively seeks out and identifies root causes and facilitates issue resolution. \n \n \n   PREFERRED QUALIFICATIONS \n \n Bachelor's degree in Business Administration, Management, Accounting, Finance, Management Information Technology or Supply Chain Management. \n Prior experience in the retail energy industry and/or regulated energy industry. \n Prior experience in using CRM and/or Order-to-Cash workflow systems. \n Working knowledge of UDC/ISO market EDI transactions. \n Advanced technical acumen in SQL, business applications and/or new technologies. \n Experience leading cross-functional initiative. \n Lean Six Sigma certification. \n \n Minimum Qualification  \u2013  Analyst III, Retail Ops \n \n Bachelor\u2019s Degree + 2 years work experience required; or 6+ years combination of education and relevant work experience \n  Minimum: Advanced computer background/experience, including Microsoft Office Applications (Word, Excel and PowerPoint) \n  Ability to communicate effectively and professionally, with internal and external parties as required. \n  Established analytical and problem-solving skills. \n  Customer service orientation, serving internal and external clients. \n  Excellent attention to detail. \n  Capable of working independently and as a team member. \n  Strong organizational and time management skills - ability to organize and prioritize a fast-paced, heavy workload. \n  Ability to adapt to changing markets, systems, and processes. \n  Ability to obtain and analyze data with general supervision and can reason through scenarios to suggest course of action or remediation. \n  Has acquired a high-level understanding of the group's overall processes, with process improvement in mind. \n \n Preferred Qualification \n \n  Bachelor\u2019s Degree in Business Administration, Accounting, Finance, Management, Management Information Technology or Supply Chain management. \n  Prior experience in the retail energy industry using CRM and/or Order-to-Cash workflow systems. \n  Working knowledge of UDC/ISO/LDC market EDI transactions. \n Advanced skills in Microsoft Access and/or SQL database query development. \n \n Minimum Qualification  -  Analyst II, Retail Ops \n \n  Bachelor\u2019s Degree with 2+ years work experience required; or 5+ years combination of education and relevant work experience. \n \n \n  Strong computer background/experience, including Microsoft Office Applications (Word, Excel and PowerPoint). \n \n \n  Ability to communicate effectively and professionally, with internal and external parties as required. \n \n \n  Established analytical and problem-solving skills. \n \n \n  Customer service orientation, serving internal and external clients. \n \n \n  Excellent attention to detail. \n \n \n  Capable of working independently and as a team member. \n \n \n  Strong organizational and time management skills - ability to organize and prioritize a fast-paced, heavy workload. \n \n \n  Ability to adapt to changing markets, systems, and processes. \n \n \n  Ability to obtain and analyze data with general supervision and can reason through scenarios to suggest course of action or remediation. \n \n \n  Has acquired a high-level understanding of the group's overall processes, with process improvement in mind. \n \n     Preferred Qualification s:  \n \n  Bachelor\u2019s Degree in Business Administration, Management, Accounting, Finance, Management Information Technology or Supply Chain Management. \n \n \n  Prior experience in the retail energy industry and/or regulated energy industry. \n \n \n  Prior experience in the retail energy industry using CRM and/or Order-to-Cash workflow systems. \n \n \n  Working knowledge of UDC/ISO/LDC market EDI transactions. \n \n \n  Intermediate skills in Microsoft Access and/or SQL database query development. \n \n  EEO \n  At Constellation, we are proud to be an equal opportunity employer. Whether you are an employee or applicant, you will receive consideration for employment without regard to: age, color, disability, gender, national origin, race, religion, sexual orientation, gender identity, protected veteran status, or any other classification protected by federal, state, or local law. \n  We are committed to advancing diversity, equity and inclusion and believe in attracting, retaining, and advancing employees who will best serve and represent our customers, partners, and communities. We support a workplace that ensures mutual respect, where everyone has the opportunity to grow and contribute at their greatest potential. Constellation will provide you the tools and resources to build and power a successful career. \n  GOVERNMENT \n  VEVRAA Federal Contractor", "cleaned_desc": " Problem Solving and Issue Resolution (Problem Solving/Analytics): Exercise independent judgment, analytical abilities, and leverage subject matter expertise to investigate discrepancies in work processes. Take necessary actions to resolve issues, including working with other functional teams as needed. Compare and evaluate alternatives, using discretion to select and execute appropriate course of action to fully resolve customer issues (such as courtesy credits), working with other functional teams and leveraging alternate technologies as needed. \n  Comprehension/Adherence of Policies and Controls (Operational Excellence): Maintain an understanding of business, contractual, regulatory, and market policies/tariff and ensure assigned workflow processes are aligned. Ensure that all Sarbanes-Oxley (\"SOX\") Key Controls and other company policies are followed. \n \n  Qualifications   \n MINIMUM QUALIFICATIONS - Sr. Analyst, Retail Pricing \n \n Bachelor's degree with 3+ work experience required; or 6+ years combination of education and relevant work experience. \n Advanced skills with Microsoft Office applications (Word, Excel, PowerPoint and Access). \n Ability to communicate effectively and professionally with internal and external parties as required. \n Can obtain and analyze data independently and can reason through complex scenarios to suggest course of action or remediation. \n Effectively communicate with, develop and maintain professional relationships with internal and external customers. \n Excellent attention to detail knowing others will depend on it being correct. \n Works independently and as a team member. \n Strong organizational and time management skills - ability to organize and prioritize a fast-paced, heavy workload. \n Adapts to changing markets, systems, and processes. \n Works in tight deadlines and shifting priorities but continues to be organized and methodical. \n Proactively seeks out and identifies root causes and facilitates issue resolution. \n \n \n   PREFERRED QUALIFICATIONS \n \n Bachelor's degree in Business Administration, Management, Accounting, Finance, Management Information Technology or Supply Chain Management. \n Prior experience in the retail energy industry and/or regulated energy industry. \n Prior experience in using CRM and/or Order-to-Cash workflow systems. \n Working knowledge of UDC/ISO market EDI transactions. \n Advanced technical acumen in SQL, business applications and/or new technologies.   Experience leading cross-functional initiative. \n Lean Six Sigma certification. \n \n Minimum Qualification  \u2013  Analyst III, Retail Ops \n \n Bachelor\u2019s Degree + 2 years work experience required; or 6+ years combination of education and relevant work experience \n  Minimum: Advanced computer background/experience, including Microsoft Office Applications (Word, Excel and PowerPoint) \n  Ability to communicate effectively and professionally, with internal and external parties as required. \n  Established analytical and problem-solving skills. \n  Customer service orientation, serving internal and external clients. \n  Excellent attention to detail. \n  Capable of working independently and as a team member. \n  Strong organizational and time management skills - ability to organize and prioritize a fast-paced, heavy workload. \n  Ability to adapt to changing markets, systems, and processes. \n  Ability to obtain and analyze data with general supervision and can reason through scenarios to suggest course of action or remediation. \n  Has acquired a high-level understanding of the group's overall processes, with process improvement in mind. \n \n Preferred Qualification \n \n  Bachelor\u2019s Degree in Business Administration, Accounting, Finance, Management, Management Information Technology or Supply Chain management. \n  Prior experience in the retail energy industry using CRM and/or Order-to-Cash workflow systems. \n  Working knowledge of UDC/ISO/LDC market EDI transactions. \n Advanced skills in Microsoft Access and/or SQL database query development. \n \n Minimum Qualification  -  Analyst II, Retail Ops \n    Bachelor\u2019s Degree with 2+ years work experience required; or 5+ years combination of education and relevant work experience. \n \n \n  Strong computer background/experience, including Microsoft Office Applications (Word, Excel and PowerPoint). \n \n \n  Ability to communicate effectively and professionally, with internal and external parties as required. \n \n \n  Established analytical and problem-solving skills. \n \n \n  Customer service orientation, serving internal and external clients. \n \n \n  Excellent attention to detail. \n \n \n  Capable of working independently and as a team member. \n \n \n  Strong organizational and time management skills - ability to organize and prioritize a fast-paced, heavy workload. \n \n \n  Ability to adapt to changing markets, systems, and processes. \n ", "techs": ["microsoft office applications (word", "excel", "powerpoint", "access)", "sql", "crm", "order-to-cash workflow systems", "udc/iso market edi transactions", "lean six sigma certification"]}, "3f7b7c2b74561a63": {"terms": ["data analyst"], "salary_min": 82516.375, "salary_max": 104484.125, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "42d33e9c94948114": {"terms": ["data analyst"], "salary_min": 85966.98, "salary_max": 108853.35, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "03eaa5b47a61b9ab": {"terms": ["data analyst"], "salary_min": 80946.64, "salary_max": 102496.484, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "d551201edb557a0e": {"terms": ["data analyst"], "salary_min": 82834.21, "salary_max": 104886.57, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "1d672448f2f54a1d": {"terms": ["data analyst"], "salary_min": 84113.19, "salary_max": 106506.03, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "df3d3a6a7ab7b35f": {"terms": ["data analyst"], "salary_min": 82001.65, "salary_max": 103832.35, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "5752455b63dba005": {"terms": ["data analyst"], "salary_min": 82298.12, "salary_max": 104207.76, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "e0defbb574065209": {"terms": ["data analyst"], "salary_min": 83690.41, "salary_max": 105970.7, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "01fc65ebc395e90e": {"terms": ["data analyst"], "salary_min": 83702.22, "salary_max": 105985.66, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "a687b52adbce23ce": {"terms": ["data analyst"], "salary_min": 85622.9, "salary_max": 108417.664, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "600ecaeb4b2bf027": {"terms": ["data analyst"], "salary_min": 85101.266, "salary_max": 107757.17, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "f4c255cc6aeda981": {"terms": ["data analyst"], "salary_min": 82684.25, "salary_max": 104696.69, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "9b2dbe5146d19a25": {"terms": ["data analyst"], "salary_min": 84122.14, "salary_max": 106517.375, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "f83b931f6b1a484e": {"terms": ["data analyst"], "salary_min": 88293.125, "salary_max": 111798.766, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "e164f69fed0c86ec": {"terms": ["data analyst"], "salary_min": 83034.73, "salary_max": 105140.46, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "6afe8adc0980743d": {"terms": ["data analyst"], "salary_min": 84815.62, "salary_max": 107395.48, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "95358cd84737c513": {"terms": ["data analyst"], "salary_min": 84655.35, "salary_max": 107192.54, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "149ec3388c02ab65": {"terms": ["data analyst"], "salary_min": 86252.85, "salary_max": 109215.336, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "8e268fb69ef13362": {"terms": ["data analyst"], "salary_min": 83658.39, "salary_max": 105930.16, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "4f5c2a04622b3612": {"terms": ["data analyst"], "salary_min": 83260.05, "salary_max": 105425.766, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "unisense search"]}, "efbac74febbb0e68": {"terms": ["data analyst"], "salary_min": 83346.62, "salary_max": 105535.38, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "ootb", "custom connectors", "data dictionary", "business glossary", "data catalog", "metadata", "data lineage", "data asset identification", "data asset ownership", "data domain discovery", "data classification", "taxonomy", "data catalog architecture", "data catalog inventory", "unisense search", "stitching", "data dictionary", "data governance", "metadata management", "data steward", "data owner", "sensitive data", "gdpr", "hipaa", "spi", "data-related controls", "training programs"]}, "99fdb65c702314b9": {"terms": ["data analyst"], "salary_min": 83658.52, "salary_max": 105930.336, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "06dde691f980899d": {"terms": ["data analyst"], "salary_min": 84428.78, "salary_max": 106905.66, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "33230a423c0bea34": {"terms": ["data analyst"], "salary_min": 83615.94, "salary_max": 105876.41, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "data catalog", "business glossary", "data lineage", "metadata harvesting", "technical metadata", "data management tool"]}, "7e9e06d872471438": {"terms": ["data analyst"], "salary_min": 83658.52, "salary_max": 105930.336, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "data management tool"]}, "2ee423d43ae1fe33": {"terms": ["data analyst"], "salary_min": 84239.94, "salary_max": 106666.53, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "0955504a4028235c": {"terms": ["data analyst"], "salary_min": 84093.35, "salary_max": 106480.93, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "unisense search", "gdpr", "hippa", "spi"]}, "657dae9e2d303c74": {"terms": ["data analyst"], "salary_min": 83086.43, "salary_max": 105205.93, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "1dc352769f1082af": {"terms": ["data analyst"], "salary_min": 84761.85, "salary_max": 107327.4, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "cdca57cb13446733": {"terms": ["data analyst"], "salary_min": 84093.35, "salary_max": 106480.93, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "d7767d562172a95e": {"terms": ["data analyst"], "salary_min": 84239.94, "salary_max": 106666.53, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "58a9cb93c0985418": {"terms": ["data analyst"], "salary_min": 84321.74, "salary_max": 106770.12, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "047d0565ba290399": {"terms": ["data analyst"], "salary_min": 83658.52, "salary_max": 105930.336, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "unisense search", "ootb connectors", "custom connectors", "data catalog", "metadata", "data lineage", "data dictionary", "business glossary", "data management tool", "metadata owner", "technical metadata", "data domains", "data elements", "data lineage", "data asset identification", "data asset ownerships", "data domain discovery", "data classification", "taxonomy", "hierarchies", "dg standards", "technical metadata harvesting", "purview", "solution designers", "automated workflows", "sensitive data", "data management standards", "data steward", "data owner", "training programs"]}, "2b3df3cad0bc5798": {"terms": ["data analyst"], "salary_min": 83834.96, "salary_max": 106153.74, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "6199a6074b2cefa9": {"terms": ["data analyst"], "salary_min": 82409.87, "salary_max": 104349.26, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "data catalog", "data lineage", "metadata management", "data governance", "taxonomy", "data classification", "business glossary", "data dictionary", "technical metadata harvesting", "data asset identification", "data asset ownership", "data domain discovery", "data catalog architecture", "unisense search", "data steward", "data owner", "sensitive data management", "gdpr", "hipaa", "spi", "data-related controls."]}, "ff86690b02512c5a": {"terms": ["data analyst"], "salary_min": 84195.39, "salary_max": 106610.125, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "be43a74069cc1891": {"terms": ["data analyst"], "salary_min": 82834.21, "salary_max": 104886.57, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview"]}, "7942c061e2e2b8a8": {"terms": ["data analyst"], "salary_min": 84195.39, "salary_max": 106610.125, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "04d82f879d95e612": {"terms": ["data analyst"], "salary_min": 84761.85, "salary_max": 107327.4, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview", "ootb", "gdpr", "hippa"]}, "f262cf28976947cd": {"terms": ["data analyst"], "salary_min": 45.0, "salary_max": 50.0, "title": "Senior Business Analyst - 166704", "company": "Raise", "desc": "We\u2019re Hiring! \n Our key client in the Legal industry is growing like crazy and adding to their team. We have a  Senior Business Analyst  role on the team. \n Pay Rate:  $45-$50/hr. on W2 \n Work Type:  Remote - 50 miles within Beaverton \n Work Hours:  8:00 AM-5:00 PM PDT \n Duration:  12-month contract (with possible extension and conversion) \n Key Responsibilities: \n \n Understand the entire lifecycle of a class action or similar matter, with emphasis on complex or significant cases. \n Determine what data is required based on functional requirements and define how that data and business rules will translate to internal applications. \n Develop and publish technical specifications, technical requirements, and other documentation, as required. \n Design data mappings and transformations which will be used to drive ETL procedures. \n Using tools such as Excel, SQL Server, Oracle, and others, directly query, assess and analyze data to ensure requirements are being met. \n Serve as liaison between Client Services (business) and Software Development (technical) to keep production work flowing smoothly. \n Help guide and mentor less experienced BAs in this capacity. \n Work with Technical Project Managers to ensure all required steps and actions are captured in project plans, and that project timelines seem reasonable. \n Lead, conduct, or consult in user acceptance test exercises to ensure results are acceptable and meet requirements. \n Participate in creating and observing software development standards, processes, procedures, methodologies, etc., according to departmental policies and conventions. \n Interact and correspond professionally with team members, project management, clients, and other stakeholders. \n Account for and accurately log time against project work. \n \n Qualifications: \n \n Four-year college degree or equivalent industry experience. \n 5+ years\u2019 of experience as a Business Analyst, Data Analyst, Process Specialist, or other roles where business functional requirements are captured and decomposed. \n Proficient in MS Office tools, particularly Excel. \n Experience with relational databases and the ability to read and write moderately complex SQL. \n Understanding of data modeling and data organization. \n Ability to analyze data sets from external sources and map to an established relational data model. \n Understanding of and experience with extract, transform load (ETL) concepts, tools, and practices. \n Ability to work in an environment with deadlines and shifting priorities. \n Ability to communicate effectively, both verbally and in writing; ability to adjust for the intended audience. \n Fluent in English. \n \n Required Skills: \n \n Must have worked on Agile teams. \n Experience writing user stories, creating wireframes, and requirements artifacts like mapping documents. \n \n Raise PBC is committed to a policy of nondiscrimination and equal opportunity for all employees and qualified applicants without regard to race, color, religious creed, national origin, ancestry, age, disability, genetics, gender identity, veterans' status, sexual orientation, or any other characteristic protected by law. Raise PBC is an equal-opportunity employer encouraging diversity in the workplace. \n #HOTJOB \n Job Type: Contract \n Salary: $45.00 - $50.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " Develop and publish technical specifications, technical requirements, and other documentation, as required. \n Design data mappings and transformations which will be used to drive ETL procedures. \n Using tools such as Excel, SQL Server, Oracle, and others, directly query, assess and analyze data to ensure requirements are being met. \n Serve as liaison between Client Services (business) and Software Development (technical) to keep production work flowing smoothly. \n Help guide and mentor less experienced BAs in this capacity. \n Work with Technical Project Managers to ensure all required steps and actions are captured in project plans, and that project timelines seem reasonable. \n Lead, conduct, or consult in user acceptance test exercises to ensure results are acceptable and meet requirements. \n Participate in creating and observing software development standards, processes, procedures, methodologies, etc., according to departmental policies and conventions. \n Interact and correspond professionally with team members, project management, clients, and other stakeholders. \n Account for and accurately log time against project work.   \n Qualifications: \n \n Four-year college degree or equivalent industry experience. \n 5+ years\u2019 of experience as a Business Analyst, Data Analyst, Process Specialist, or other roles where business functional requirements are captured and decomposed. \n Proficient in MS Office tools, particularly Excel. \n Experience with relational databases and the ability to read and write moderately complex SQL. \n Understanding of data modeling and data organization. \n Ability to analyze data sets from external sources and map to an established relational data model. \n Understanding of and experience with extract, transform load (ETL) concepts, tools, and practices. ", "techs": ["excel", "sql server", "oracle"]}, "eb4b3a243451a60d": {"terms": ["data analyst"], "salary_min": 84093.35, "salary_max": 106480.93, "title": "Data Catalog and Lineage Central Governance Analyst", "company": "PRICE WATERHOUSE COOPERS", "desc": "A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.\n   To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future. \n \n  As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to: \n \n \n  Use feedback and reflection to develop self awareness, personal strengths and address development areas. \n  Delegate to others to provide stretch opportunities, coaching them to deliver results. \n  Demonstrate critical thinking and the ability to bring order to unstructured problems. \n  Use a broad range of tools and techniques to extract insights from current industry or sector trends. \n  Review your work and that of others for quality, accuracy and relevance. \n  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered. \n  Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search; \n  Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; \n  Being a collaborative team player; and, \n  Having a business outcome focused problem-solving mindset. \n \n  Learn more about how we work: https://pwc.to/how-we-work\n  \n  PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n  \n  All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\n  \n  For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\n  \n  For positions in California, Colorado, Nevada, New York State, or Washington State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate\n  \n  #LI-Remote", "cleaned_desc": "  Know how and when to use tools available for a given situation and can explain the reasons for this choice. \n  Seek and embrace opportunities which give exposure to different situations, environments and perspectives. \n  Use straightforward communication, in a structured way, when influencing and connecting with others. \n  Able to read situations and modify behavior to build quality relationships. \n  Uphold the firm's code of ethics and business conduct. \n \n \n  Additional Responsibilities :  \n Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture. \n  Custom Orgs :     Global LoS :   Internal Firm Services     Job Requirements and Preferences :      Basic Qualifications :      Minimum Degree Required :   High School Diploma     Minimum Years of Experience :   2 year(s)      Preferred Qualifications :      Degree Preferred :   Bachelor Degree     Preferred Fields of Study :   Computer and Information Science, Data Processing/Analytics/Science     Additional Educational Preferences :  \n Other related fields of study with relevant experience may be considered.    Preferred Knowledge/Skills :  \n Demonstrates thorough abilities and/or a proven record of success as a team leader: \n \n  Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects; \n  Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes; \n  Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers; \n  Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies; \n  Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture; \n  Exhibiting proven knowledge and working experience in Microsoft Purview; \n  Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers; \n  Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;    Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog; \n  Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards; \n  Facilitating the capture of metadata as core change and operational deliverables; \n  Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers; \n  Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview; \n  Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports; \n  Possessing ability to create and maintain automated workflows for periodic metadata refresh; \n  Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable); \n  Helping manage the inventory of data-related controls on systems that support segment processes and customers; \n  Showcasing thorough understanding of data steward/data owner operating model; \n  Ability in designing and rolling out training programs to train the trainer/end-users; ", "techs": ["azure purview", "microsoft purview"]}, "4ca69e65a903fcc2": {"terms": ["data analyst"], "salary_min": 33.37, "salary_max": 33.37, "title": "Environmental Health and Safety Analyst", "company": "Yoh, A Day & Zimmermann Company", "desc": "Environmental Health and Safety Analyst needed for a REMOTE contract opportunity with Yoh\u2019s client located in Texas \n \n  Do you have a passion for making workplaces safer and more environmentally friendly? Are you ready to take your EHS expertise to the next level? Join our dynamic team as an Environmental Health and Safety Analyst and be a driving force in our mission to revolutionize the world of EHS! \n \n About Us:  We\\'re a technology and innovation leader, specializing in defense, homeland security, and government markets worldwide. With a rich history of innovation spanning 90 years, we provide state-of-the-art electronics, mission systems integration, and more. Our EHS team plays a crucial role in ensuring the safety and well-being of our workforce, and we\\'re seeking a talented individual to join our mission. \n \n \n What You\\'ll Do: \n \n \n Be the Enablon Expert: You'll take the lead in managing our online EHS Management system, making sure it runs like a well-oiled machine. \n Problem-Solver Extraordinaire: Dive into the details, identify system bugs, and find innovative solutions to keep our EHS processes running smoothly. \n Data Dynamo: Crunch numbers, analyze data, and build dazzling dashboards to drive our EHS initiatives forward. \n Training Guru: Share your knowledge and conduct creative EHS training sessions that empower our teams to excel. \n Collaboration Maestro: Work closely with our EHS teams, leadership, and management, ensuring effective communication and alignment. \n Tech-Savvy Superstar: Utilize advanced Excel skills and harness the power of Microsoft Office to create reports and presentations that captivate. \n Continuous Learning: Embrace opportunities to expand your expertise in data management systems, SharePoint, and more. \n Flexibility is Key: Be ready to tackle new challenges and accept additional assignments with a can-do attitude. \n \n What You Bring: \n \n \n Passion for EHS: You're dedicated to making workplaces safer and more sustainable. \n Detail-Oriented: Your attention to detail is second to none, and you thrive in a multitasking environment. \n Communication Pro: You're a master communicator, able to convey your ideas to a wide audience effectively. \n Tech Whiz: You're proficient in Microsoft Office, with advanced Excel skills that shine. \n EHS Enthusiasm: You may have experience in EHS or a related field, but your passion for it is what truly sets you apart. \n Problem-Solving Prowess: You're a natural problem solver, unafraid to ask for help when needed. \n Self-Motivated: You take initiative and thrive in a fast-paced, collaborative team environment. \n \n Why Join Us: \n \n \n Remote Work: Work from anywhere and enjoy a flexible, remote work environment. \n Impact: Be part of a large and impactful Environment, Health & Safety organization with both domestic and international reach. \n Professional Growth: Expand your skills and knowledge in a supportive and collaborative team setting. \n Exciting Challenges: Every day brings new opportunities and challenges to keep you engaged. \n \n How Your Success is Measured: \n \n \n Achieving goals and milestones. \n Delivering high-quality work. \n Collaborating effectively with a diverse team. \n Maintaining a positive attitude and boosting team morale. \n  Ready to Ignite Your EHS Career? Join Us Today! \n If you\\'re ready to make a difference, be a part of a dynamic team, and take your EHS expertise to new heights, we want to hear from you! Apply now and become a crucial part of our mission to shape the future of EHS. \n \n \n Location:  Richardson, TX REMOTE \n \n \n Pay Rate:  $33.37 per hour \n \n \n Hours:  8:00am \u2013 5:00pm \n \n  Opportunity is Calling, Apply Now! \n \n \n Recruiter:  Heather Naso \n \n  We value diverse skills and experience, so don't hold back. Your qualifications could add tremendous value to our team. Our customers come from all different backgrounds, and so do our employees. If you're passionate about what you could accomplish, we'd love to hear from you. \n \n  Yoh makes finding and applying for jobs simple. Partner with Yoh to find the right opportunities across multiple industries in the US and UK. Find out more here! \n #Zip-SA \n #Mon-SA \n #CB-SA \n #IND-SA \n \n \n Note:  Any pay ranges displayed are estimations. Actual pay is determined by an applicant's experience, technical expertise, and other qualifications as listed in the job description. All qualified applicants are welcome to apply. \n \n  Yoh, a Day & Zimmermann company, is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n \n  Visit https://www.yoh.com/applicants-with-disabilities [1]to contact us if you are an individual with a disability and require accommodation in the application process. \n \n \n Links: \n  ------ \n [1] https://www.yoh.com/applicants-with-disabilities \n #IND-SA", "cleaned_desc": "", "techs": ""}, "281b2eedac45da65": {"terms": ["data analyst"], "salary_min": 90000.0, "salary_max": 115000.0, "title": "Clinical Applications Analyst", "company": "Find Great People", "desc": "Day to Day: \n \n Analyze data utilized by enterprise organization. \n Support and maintain analytics tools and applications. \n Create and maintain reports. \n Work closely with analytics development team. \n \n Required Skill Set: \n \n 3+ years IT Application Analyst experience \n Must have clinical healthcare background \n SQL experience \n EHR experience strongly preferred \n Strong communications skills \n \n The Application Analyst will play a critical role in optimizing the use of applications within an acute care setting. They will be responsible for analyzing existing applications, gathering requirements, and implementing data mining strategies to extract valuable insights. The successful candidate will have a strong background in application analysis, data mining, and acute care operations. They must also possess excellent communication skills and the ability to work collaboratively with end-users. If you are passionate about leveraging technology to improve patient care and outcomes, we encourage you to apply. \n Job Types: Contract, Full-time \n Pay: $90,000.00 - $115,000.00 per year \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n HEDIS: 1 year (Preferred) \n Application support: 3 years (Preferred) \n Clinical: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "a5bb20b7ec1bfccd": {"terms": ["data engineer"], "salary_min": 83499.79, "salary_max": 190750.84, "title": "Azure Data Engineer", "company": "GTECH LLC", "desc": "Sr. No \n Mandatory Skills \n Expected Skill Level out 5 \n 1 \n Azure Data Engg services \n 3 \n 2 \n RDBMS \n 4 \n 3 \n Airflow \n 4 \n 4 \n Azure Data Factory \n 3 \n 5 \n API \n 3 \n 6 \n Python for application development \n 3 \n 7 \n L1 Operations \n 5 \n 8 \n Communications & trouble shooting \n 5 \n 9 \n ETL process \n 5 \n Sr. No \n Nice To have Skills \n Expected Skill Level \n 1 \n Spark Scala \n 3 \n 2 \n Snow flakes \n 3 \n 3 \n Grafana \n 3 \n 4 \n Oracle \n Job Type: Full-time \n Salary: $83,499.79 - $190,750.85 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible schedule \n Health insurance \n Paid time off \n Tuition reimbursement \n Vision insurance \n \n Experience: \n \n Informatica: 1 year (Preferred) \n SQL: 1 year (Preferred) \n Data warehouse: 1 year (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "6ca598d4286ea230": {"terms": ["data engineer"], "salary_min": 83521.75, "salary_max": 130759.23, "title": "Sr. Data Engineer", "company": "GTECH LLC", "desc": "Role- Data Engineer Location- Remote Job Description: \n Undergraduate degree or equivalent work experience \n 8+ years\u2019 experience in Development, design, test and implementation of complex database programs using Oracle and third-party tools. within a distributed, service-based enterprise environment \n 4+ years Hands-on development using Oracle PL/SQL. \n Demonstrates expertise in a variety of data warehousing and business intelligence concepts, practices, and procedures. \n Strong experience with oracle functions, procedures, triggers, packages & performance tuning, \n Significant experience and comfortable with production support (and willing to take on slots within our 24/7 support rotation).Providing technical assistance, problem resolution and troubleshooting support issues. \n Analytical approach to problem solving \n At least 2+ year practical experience of developing solutions hosting within key major cloud providers such as OpenShift, Kubernetes, AWS, Google Cloud and Azure \n Experience in using modern software engineering and product development tools including Agile / SAFE, Continuous Integration, Continuous Delivery, DevOps etc. \n Demonstrate being an avid supporter of the Open-Source software community \n Excellent time management, communication, decision making, and presentation skills \n Display a strong desire to achieve and attain high levels of both internal and external customer satisfaction \n Strong experience of operating in a quickly changing environment and driving technological innovation to meet business requirement \n Proven track record of building relationships across cross-functional teams \n Positive attitude and easy to work with \n Initiative-taker. Has grit and can solve problems without management oversight. \n Takes ownership for work. When something goes wrong, stance is introspective rather than blaming. \n Engineering mindset(automate manual process) when it comes to ETL processes. \n Accustomed to developing code in Git and using CI/CD practices. \n Preferred: development experience using Java or open-source technologies, developing Restful APIs \n Job Type: Full-time \n Salary: $83,521.75 - $130,759.23 per year \n Benefits: \n \n Health insurance \n \n Experience level: \n \n 8 years \n 9 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": "Role- Data Engineer Location- Remote Job Description: \n Undergraduate degree or equivalent work experience \n 8+ years\u2019 experience in Development, design, test and implementation of complex database programs using Oracle and third-party tools. within a distributed, service-based enterprise environment \n 4+ years Hands-on development using Oracle PL/SQL. \n Demonstrates expertise in a variety of data warehousing and business intelligence concepts, practices, and procedures. \n Strong experience with oracle functions, procedures, triggers, packages & performance tuning, \n Significant experience and comfortable with production support (and willing to take on slots within our 24/7 support rotation).Providing technical assistance, problem resolution and troubleshooting support issues.   Analytical approach to problem solving \n At least 2+ year practical experience of developing solutions hosting within key major cloud providers such as OpenShift, Kubernetes, AWS, Google Cloud and Azure \n Experience in using modern software engineering and product development tools including Agile / SAFE, Continuous Integration, Continuous Delivery, DevOps etc. \n Demonstrate being an avid supporter of the Open-Source software community \n Excellent time management, communication, decision making, and presentation skills \n Display a strong desire to achieve and attain high levels of both internal and external customer satisfaction \n Strong experience of operating in a quickly changing environment and driving technological innovation to meet business requirement ", "techs": ["oracle pl/sql", "oracle functions", "procedures", "triggers", "packages", "performance tuning", "openshift", "kubernetes", "aws", "google cloud", "azure", "agile/safe", "continuous integration", "continuous delivery", "devops"]}, "558d8c4d36307008": {"terms": ["data engineer"], "salary_min": 112879.07, "salary_max": 142930.06, "title": "Data Engineer", "company": "Connexiz Inc", "desc": "Data Engineer \n Responsibilities include: \n \n Design and implement reliable data pipelines to integrate disparate data sources into a single Data Lakehouse \n Design and implement data quality pipelines to ensure data correctness and building trusted datasets. \n Design and implement a Data Lakehouse solution which accurately reflects business operations. \n Assist with data platform performance tuning and physical data model support including partitioning and compaction. \n Provide guidance in data visualizations and reporting efforts to ensure solutions are aligned to business objectives. \n \n The successful candidate will meet the following qualifications: \n \n 5+ years of experience as a Data Engineer designing and maintaining data pipeline architectures. \n 5+ years of programming experience in Python, ANSI SQL, PLSQL, and TSQL \n Experience in various data integration patterns including ETL, ELT, Pub/Sub, and Change Data Capture \n Experience with common Python Data Engineering packages including pandas, Numpy, Pyarrow Pytest, Scikit-Learn, and Boto3 \n Experience in software development practices such as Design Principles and Patterns, Testing, Refactoring, CI/CD, and version control \n Experience in implementing a Data Lakehouse using Apache Iceberg or Delta Lake \n Knowledgeable of modern data platform technologies including Apache Airflow, Kubernetes, and S3 Object Storage \n \n Job Type: Contract \n Benefits: \n \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n Will you now, or will you in the future, require sponsorship for employment visa status (e.g., H-1B visa status; Transfer of Sponsorship, etc.) to work legally in the country where this job is located? \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Data Engineer: 5 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Data Engineer \n Responsibilities include: \n \n Design and implement reliable data pipelines to integrate disparate data sources into a single Data Lakehouse \n Design and implement data quality pipelines to ensure data correctness and building trusted datasets. \n Design and implement a Data Lakehouse solution which accurately reflects business operations. \n Assist with data platform performance tuning and physical data model support including partitioning and compaction. \n Provide guidance in data visualizations and reporting efforts to ensure solutions are aligned to business objectives.   \n The successful candidate will meet the following qualifications: \n \n 5+ years of experience as a Data Engineer designing and maintaining data pipeline architectures. \n 5+ years of programming experience in Python, ANSI SQL, PLSQL, and TSQL \n Experience in various data integration patterns including ETL, ELT, Pub/Sub, and Change Data Capture \n Experience with common Python Data Engineering packages including pandas, Numpy, Pyarrow Pytest, Scikit-Learn, and Boto3 \n Experience in software development practices such as Design Principles and Patterns, Testing, Refactoring, CI/CD, and version control ", "techs": ["data engineer", "data lakehouse", "data pipelines", "data quality pipelines", "data lakehouse solution", "data platform performance tuning", "physical data model support", "data visualizations", "reporting efforts", "data engineer", "data pipeline architectures", "programming experience", "python", "ansi sql", "plsql", "tsql", "data integration patterns", "etl", "elt", "pub/sub", "change data capture", "python data engineering packages", "pandas", "numpy", "pyarrow", "pytest", "scikit-learn", "boto3", "software development practices", "design principles and patterns", "testing", "refactoring", "ci/cd", "version control"]}, "3de95c359a870cea": {"terms": ["data engineer"], "salary_min": 95001.11, "salary_max": 120292.58, "title": "Data Engineer", "company": "AccuLynx", "desc": "We are seeking a highly skilled and motivated Data Engineer with expertise in creating and managing data lakes and data warehouses. In this role, you will be responsible for designing and implementing efficient data storage and processing solutions using Microsoft SQL Server, Azure Data Factory, and Azure Synapse Analytics. You will collaborate closely with financial planning analysts and other stakeholders to understand their data requirements and build scalable solutions to support their analytical needs. \n \n \n  Responsibilities: \n \n Develop and optimize SQL queries to extract insights from large datasets, leveraging the capabilities of SQL Server. \n Design and develop data lakes and data warehouses using industry best practices, ensuring high performance, scalability, and data quality. \n Collaborate with FP&A Analysts to understand their data requirements and translate them into technical specifications for data models and schemas. \n Extract, transform, and load (ETL) data from various sources into the data lake and data warehouse, ensuring data integrity and consistency. \n Monitor and maintain the performance and health of the data lake and data warehouse, implementing necessary optimizations and troubleshooting any issues that arise. \n Implement data governance and security measures to ensure compliance with regulatory requirements and protect sensitive information. \n Collaborate with cross-functional teams to integrate data from different systems and sources, ensuring data consistency and accuracy across the organization. \n Stay up-to-date with emerging technologies, tools, and trends in data engineering and analytics, and evaluate their potential application to improve existing systems and processes. \n \n \n \n  Requirements: \n \n Bachelor's degree in Computer Science, Engineering, or a related field. \n Proven experience designing and implementing data lakes and data warehouses, preferably using Microsoft SQL Server and Azure Synapse. \n Strong proficiency in SQL and database management systems. \n Experience with data integration, ETL processes, and data modeling concepts. \n Familiarity with cloud platforms (e.g., Microsoft Azure, AWS, Google Cloud) and their data-related services. \n Knowledge of data governance, data security, and regulatory compliance practices. \n Strong analytical and problem-solving skills, with the ability to analyze complex datasets and derive meaningful insights. \n Excellent communication and collaboration skills to work effectively with FP&A Analysts and cross-functional teams. \n Self-motivated and able to work independently as well as in a team environment. \n \n \n \n  Join our dynamic team and contribute to the development of a robust data infrastructure that empowers our FP&A Analysts to derive valuable insights and drive informed decision-making.", "cleaned_desc": "We are seeking a highly skilled and motivated Data Engineer with expertise in creating and managing data lakes and data warehouses. In this role, you will be responsible for designing and implementing efficient data storage and processing solutions using Microsoft SQL Server, Azure Data Factory, and Azure Synapse Analytics. You will collaborate closely with financial planning analysts and other stakeholders to understand their data requirements and build scalable solutions to support their analytical needs. \n \n \n  Responsibilities: \n \n Develop and optimize SQL queries to extract insights from large datasets, leveraging the capabilities of SQL Server.   Design and develop data lakes and data warehouses using industry best practices, ensuring high performance, scalability, and data quality. \n Collaborate with FP&A Analysts to understand their data requirements and translate them into technical specifications for data models and schemas. \n Extract, transform, and load (ETL) data from various sources into the data lake and data warehouse, ensuring data integrity and consistency. \n Monitor and maintain the performance and health of the data lake and data warehouse, implementing necessary optimizations and troubleshooting any issues that arise. \n Implement data governance and security measures to ensure compliance with regulatory requirements and protect sensitive information. \n Collaborate with cross-functional teams to integrate data from different systems and sources, ensuring data consistency and accuracy across the organization.   Bachelor's degree in Computer Science, Engineering, or a related field. \n Proven experience designing and implementing data lakes and data warehouses, preferably using Microsoft SQL Server and Azure Synapse. \n Strong proficiency in SQL and database management systems. \n Experience with data integration, ETL processes, and data modeling concepts. \n Familiarity with cloud platforms (e.g., Microsoft Azure, AWS, Google Cloud) and their data-related services. \n Knowledge of data governance, data security, and regulatory compliance practices.   Strong analytical and problem-solving skills, with the ability to analyze complex datasets and derive meaningful insights. \n Excellent communication and collaboration skills to work effectively with FP&A Analysts and cross-functional teams. \n Self-motivated and able to work independently as well as in a team environment. \n \n \n ", "techs": ["microsoft sql server", "azure data factory", "azure synapse analytics"]}, "215c14549a2398d7": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 137950.31, "salary_max": 174675.84, "title": "Data Engineer", "company": "Royce Geo", "desc": "Why Choose Royce Geo \n  We're not your typical government contracting company, nor do we want to be. At Royce Geo, we live for building durable and long-lasting relationships with our clients, providing exceptional service with a CAN'T QUIT / WON'T QUIT attitude. We are creating a culture of winning, optimism, FUN, and caring for the person next to you. If you want to work in a real team environment and share the wealth and satisfaction of providing real value to your customer, then this company may be just for you. \n  Royce Geo prides ourselves in our values-first approach. Our values of Accountability, Attitude, Communication, Innovation, and Leadership are integrated into how we approach problems, guide our interactions with others, and create the framework for our culture. We recognize and reward our team members that champion these attributes. \n  We offer a competitive benefit package that is designed to attract and retain exceptional talent. We take care of our team members from multiple facets including health, financial, and well-being programs: \n \n  Robust health plan including medical, dental, and vision \n  Health Savings Account with company contribution \n  Annual Paid Time Off and Paid Holidays \n  Paid Parental Leave \n  401k with generous company match \n  Training and Development Opportunities \n  Award Programs \n  Variety of Company Sponsored Events \n \n  Summary: \n  We are seeking an experienced  Data Engineer  to join our team. As a Data Engineer, you will be responsible for collecting data, interpretation of data for business analysis. Candidates for this position will be able to sift through data, apply statistics, compare data points, and create reports outlining business predictions. The data engineer will provide extensive technical expertise, help businesses make decisions and develop innovative solutions to complex problems. We want innovative problem solvers that are passionate about data and enjoy a challenge.  This is a fully remote position . \n \n  Responsibilities: \n \n  Creates database models and components that meet product specification and development schedules for customer/customers \n  Participates in large system and subsystem planning \n  Designs data pipelines, data models, profiling/cleansing the data, and performance tuning. \n  Develops and maintains data pipelines, data workflows, ETL/ELT scripts or packages. \n  Prepares comprehensive test plans. \n  Collaborates and provides influence to team on project deliverables \n  Acts as a technical resource for lower-level engineers \n  Researches and integrates design strategies, product specifications, development schedules, and user expectations into product capabilities. \n  Develops technical designs and specifications for complex data pipelines/data flows for customer/customers. \n  Uses ETL tools or languages to build, test, and maintain product modules, components, and subsystems. \n  Creates quality deliverables for customers \n  Drives full life-cycle of services/solution delivery for project(s) \n  Oversees technical design, development, and implementation of large projects and/or major data pipelines/data flows and solutions for customer/customers. \n  Factors emerging technologies and product supportability into design and implementation. \n  Identifies data quality issues and potential remediations for consideration by PM and/or customer \n  Identifies data gaps and potential remediation or integration activity for consideration by PM and/or customer \n  Responsible for services/solution delivery and customer satisfaction of program(s) \n  Sets strategy and enforces quality assurance program for program and project deliverables \n  Provides leadership to team members on program and project deliverables \n  Serves as primary technical resource to development team. \n  May act as team leader in prioritizing group tasks, determining individual assignments, and reviewing work of lower-level data engineers or other team members. \n \n   Required Qualifications: \n \n  Active TS clearance is required \n  Bachelors degree in a relevant field \n  Minimum 8+ years of experience in the technical field and data solutions \n  Ability to understand requirements and map them into the existing data environment or create new structures needed \n  Background developing data solutions and can operate in a fast paced, highly collaborative environment \n  Experience with SQL, Python, PySpark, leading ETL technologies and approaches \n  Independent, creative, and determined \n  Strong SQL and data management experience \n  Experience with machine learning and statistical analysis \n  Experience with modern programming languages such as Python \n  Strong analytical skills with the ability to organize, analyze and prioritize \n  Experience or exposure to one or more: Redshift, Teradata, Snowflake \n  Familiarity with Metadata management tools like Immuta / Alation / Collibra is a plus \n \n \n   EEO Statement \n  Royce Geo. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability. Anyone requiring reasonable accommodations should email recruiting@roycegeo.com or call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days. \n  Know Your Rights: Workplace Discrimination is Illegal (eeoc.gov) \n  Please review our current job openings and apply for the positions you believe may be a fit. If you are not an immediate fit, we will also keep your resume in our database for future opportunities.", "cleaned_desc": "  Variety of Company Sponsored Events \n \n  Summary: \n  We are seeking an experienced  Data Engineer  to join our team. As a Data Engineer, you will be responsible for collecting data, interpretation of data for business analysis. Candidates for this position will be able to sift through data, apply statistics, compare data points, and create reports outlining business predictions. The data engineer will provide extensive technical expertise, help businesses make decisions and develop innovative solutions to complex problems. We want innovative problem solvers that are passionate about data and enjoy a challenge.  This is a fully remote position . \n \n  Responsibilities: \n \n  Creates database models and components that meet product specification and development schedules for customer/customers \n  Participates in large system and subsystem planning \n  Designs data pipelines, data models, profiling/cleansing the data, and performance tuning. \n  Develops and maintains data pipelines, data workflows, ETL/ELT scripts or packages. \n  Prepares comprehensive test plans.    Collaborates and provides influence to team on project deliverables \n  Acts as a technical resource for lower-level engineers \n  Researches and integrates design strategies, product specifications, development schedules, and user expectations into product capabilities. \n  Develops technical designs and specifications for complex data pipelines/data flows for customer/customers. \n  Uses ETL tools or languages to build, test, and maintain product modules, components, and subsystems. \n  Creates quality deliverables for customers \n  Drives full life-cycle of services/solution delivery for project(s) \n  Oversees technical design, development, and implementation of large projects and/or major data pipelines/data flows and solutions for customer/customers. \n  Factors emerging technologies and product supportability into design and implementation. \n  Identifies data quality issues and potential remediations for consideration by PM and/or customer \n  Identifies data gaps and potential remediation or integration activity for consideration by PM and/or customer \n  Responsible for services/solution delivery and customer satisfaction of program(s)    Experience with SQL, Python, PySpark, leading ETL technologies and approaches \n  Independent, creative, and determined \n  Strong SQL and data management experience \n  Experience with machine learning and statistical analysis \n  Experience with modern programming languages such as Python \n  Strong analytical skills with the ability to organize, analyze and prioritize \n  Experience or exposure to one or more: Redshift, Teradata, Snowflake \n  Familiarity with Metadata management tools like Immuta / Alation / Collibra is a plus \n \n \n   EEO Statement \n  Royce Geo. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran and will not be discriminated against on the basis of disability. Anyone requiring reasonable accommodations should email recruiting@roycegeo.com or call 703-544-7930 with requested details. A member of the HR team will respond to your request within 2 business days. ", "techs": ["sql", "python", "pyspark", "redshift", "teradata", "snowflake", "immuta", "alation", "collibra"]}, "7e20ecf6555919bd": {"terms": ["data engineer"], "salary_min": 110000.0, "salary_max": -1.0, "title": "Data Engineer with healthcare experience", "company": "innoVet Health, LLC", "desc": "Job Summary \n InnoVet Health, a small and growing business that provides health IT professional services to the Department of Veterans Affairs (VA) is looking for a talented and experienced  Data Engineer with Healthcare IT experience  who can turn analytics project requirements into automated data sets processing and modeling. The ideal candidate will support our customers with data ingestion, quality check, transformation and analytics processes applied to a variety of data sources (EHR, wearable devices, mobile apps, etc.). The position offers stimulating advanced data analysis activities, in a rich healthcare environment, interacting with senior staff. It is flexible, full-time and does not require relocating (work from home). The pay, benefits, and growth potential are competitive. \n Responsibilities \n \n Gather and manage business and technical requirements \n Conduct systems and data analysis, and design, implement and maintain data integration processes \n Develop automated data processes for extracting, assessing quality, cleansing, transforming, loading and structuring data sets for downstream processing by data analysts and scientists. This will include ETL pipelines to convert FHIR JSON data into relational database structures. \n Develop and maintain data models and architecture that support efficient storage, retrieval, and analysis of healthcare data \n Collaborate with data analysts and data scientists to ensure data flows efficiently and continuously to other databases and analytics tools \n Stay up to date with emerging technologies and trends in data engineering and healthcare data management \n Present and discuss results with IT and business stakeholders \n Participate in company growth and other responsibilities, as assigned \n \n Qualifications \n \n Bachelor\u2019s or master\u2019s degree in computer science, data analytics or related field \n 5+ years of experience as a Data Engineer, preferably in the healthcare field. \n Proficiency in ETL, database architecture, data warehousing, data modeling, data mining, and SQL queries (e.g., MS SQL BI Stack/SSIS) \n Experience with healthcare standards (e.g., HL7, FHIR, SNOMED, ICD) \n Hands-on experience with scripting languages, R, Python, in on-prem and/or cloud-based platforms (AWS, Azure, GCP) \n Excellent problem-solving, collaboration and communication skills \n Green card or US citizen required because government contract work \n No 1099 or corp-to-corp or international outsourcing or staffing agencies \n \n Job Type: Full-time \n Pay: From $110,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n Referral program \n Vision insurance \n \n Compensation package: \n \n Bonus opportunities \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Application Question(s): \n \n What is the highest level of education you have completed? Please enter 0 for a high school diploma, 1 for a bachelor's degree, 2 for a master's degree, and 3 for a PhD. \n This position requires US citizenship or permanent resident card. Please answer 2 if you are a US citizen, 1 if you have a permanent resident card, 0 if have neither. \n This position requires that work be conducted within the U.S. Applicants MUST provide their U.S. State of Residence. All applications without a U.S. address will be excluded from consideration. \n \n Experience: \n \n Data warehouse: 2 years (Required) \n healthcare data engineering: 2 years (Required) \n Extract, Transform, Load (ELT): 2 years (Required) \n data modeling: 2 years (Required) \n \n Work Location: Remote", "cleaned_desc": "Job Summary \n InnoVet Health, a small and growing business that provides health IT professional services to the Department of Veterans Affairs (VA) is looking for a talented and experienced  Data Engineer with Healthcare IT experience  who can turn analytics project requirements into automated data sets processing and modeling. The ideal candidate will support our customers with data ingestion, quality check, transformation and analytics processes applied to a variety of data sources (EHR, wearable devices, mobile apps, etc.). The position offers stimulating advanced data analysis activities, in a rich healthcare environment, interacting with senior staff. It is flexible, full-time and does not require relocating (work from home). The pay, benefits, and growth potential are competitive. \n Responsibilities \n \n Gather and manage business and technical requirements \n Conduct systems and data analysis, and design, implement and maintain data integration processes \n Develop automated data processes for extracting, assessing quality, cleansing, transforming, loading and structuring data sets for downstream processing by data analysts and scientists. This will include ETL pipelines to convert FHIR JSON data into relational database structures. \n Develop and maintain data models and architecture that support efficient storage, retrieval, and analysis of healthcare data \n Collaborate with data analysts and data scientists to ensure data flows efficiently and continuously to other databases and analytics tools \n Stay up to date with emerging technologies and trends in data engineering and healthcare data management \n Present and discuss results with IT and business stakeholders \n Participate in company growth and other responsibilities, as assigned   \n Qualifications \n \n Bachelor\u2019s or master\u2019s degree in computer science, data analytics or related field \n 5+ years of experience as a Data Engineer, preferably in the healthcare field. \n Proficiency in ETL, database architecture, data warehousing, data modeling, data mining, and SQL queries (e.g., MS SQL BI Stack/SSIS) \n Experience with healthcare standards (e.g., HL7, FHIR, SNOMED, ICD) \n Hands-on experience with scripting languages, R, Python, in on-prem and/or cloud-based platforms (AWS, Azure, GCP) \n Excellent problem-solving, collaboration and communication skills \n Green card or US citizen required because government contract work \n No 1099 or corp-to-corp or international outsourcing or staffing agencies \n ", "techs": ["data engineering", "healthcare it", "etl", "database architecture", "data warehousing", "data modeling", "data mining", "sql queries", "ms sql bi stack/ssis", "healthcare standards", "hl7", "fhir", "snomed", "icd", "scripting languages", "r", "python", "aws", "azure", "gcp"]}, "ac9d0e6b6cbbbed1": {"terms": ["data engineer"], "salary_min": 110453.72, "salary_max": 139859.02, "title": "Azure Data Engineer", "company": "Hire IT People Inc", "desc": "Position: Azure Date Engineer \n Location: [Remote] / Customer is located in Washington DC. \n Duration:12Month(s) \n JOB DESCRIPTION \n \u00b7 Provide support for Azure cloud-based applications and infrastructure. \n \u00b7 Diagnose and troubleshoot technical issues related to Azure cloud services. \n \u00b7 Collaborate with cross-functional teams to implement best practices and ensure service optimization. \n \u00b7 Continuously monitor and manage cloud environment to prevent and mitigate risks. \n \u00b7 Assist client in designing and implementing Azure cloud solutions based on their unique needs by moving forward siting applications into Cloud environment. \n \u00b7 Keep up to date with the latest Azure updates and features, ensuring optimal utilization and implementation. \n \u00b7 Offer guidance and recommendations on cost-management strategies within Azure. \n \u00b7 Contribute to the development of internal tools and processes to enhance Azure cloud management and support. \n Requirements: \n \u00b7 Proven experience as a Cloud Support Engineer, preferably with a focus on Azure. \n \u00b7 Strong knowledge of Azure services, including but not limited to Azure Active Directory, Azure DevOps, Azure Kubernetes Service, and more. \n \u00b7 Excellent problem-solving skills and the ability to diagnose complex cloud-based issues. \n \u00b7 Strong verbal and written communication skills. \n \u00b7 Must successfully pass Level 4 Public Trust verification. \n \u00b7 Relevant certifications in Azure, such as AZ-104 or AZ-303/304, are a plus. \n Regards, \n Anamika Verma \n Technical Recruiter \n Hire IT People, Inc \n Tel: (202)-719-0200 Ext: 122 \n Direct \u2013 (202) 3504277 \n Email:  anamika@hireitpeople.com \n Job Types: Full-time, Permanent \n Salary: Up to $120.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n \n Compensation package: \n \n Yearly pay \n \n Experience level: \n \n 11+ years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n ETL: 10 years (Preferred) \n SQL: 10 years (Preferred) \n Azure: 10 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": " \u00b7 Offer guidance and recommendations on cost-management strategies within Azure. \n \u00b7 Contribute to the development of internal tools and processes to enhance Azure cloud management and support. \n Requirements: \n \u00b7 Proven experience as a Cloud Support Engineer, preferably with a focus on Azure. \n \u00b7 Strong knowledge of Azure services, including but not limited to Azure Active Directory, Azure DevOps, Azure Kubernetes Service, and more. \n \u00b7 Excellent problem-solving skills and the ability to diagnose complex cloud-based issues. \n \u00b7 Strong verbal and written communication skills. \n \u00b7 Must successfully pass Level 4 Public Trust verification. \n \u00b7 Relevant certifications in Azure, such as AZ-104 or AZ-303/304, are a plus. \n Regards, ", "techs": ["azure", "azure active directory", "azure devops", "azure kubernetes service", "az-104", "az-303/304"]}, "2ca88fbc827420a3": {"terms": ["data engineer"], "salary_min": 98100.0, "salary_max": 135000.0, "title": "Senior Data Integration Engineer - Remote", "company": "Healthesystems", "desc": "Healthesystems offers workplace flexibility with our Work-From-Home model, and a competitive compensation and benefits package including healthcare coverage, PTO, paid holidays, 401(k), company-provided life insurance/disability coverage, wellness options, and more. \n \n \n  Note: we are unable to hire in every state \n \n \n \n \n Summary:  Responsible for the analysis, design, documentation, development, unit testing, and support of Data Integration and database objects development for software applications. Provides support and guidance regarding Data Integration and T-SQL best practices and development standards. Promotes approved agile methodologies, leading the design and development efforts for the agile team. Actively coaches, guides, and mentors team members in providing valuable solutions to our customer. \n   Key Responsibilities: \"To simplify complexities for each customer.\" \n \n \n Collaborates with stakeholders and development team members to achieve business results. \n \n \n Work closely with other engineers to integrate databases with other applications. \n \n \n Leads the design, development, and implementation of database applications and solutions for managing and integrating data between operational systems, data repositories, and reporting and analytical applications. This includes but is not limited to ETL, stored procedures, views, and functions. \n \n \n Recommends and provide guidance regarding Data Integration and database development, T-SQL best practices, and standards to the development team members as needed. \n \n \n Create and propose technical design documentation which includes current and future functionality, database objects affected, specifications, and flows/diagrams to detail the proposed database and/or Data Integration implementation. \n \n \n Has a deep understanding of the business processes and the technology platform that enables it. \n \n \n Translates stakeholder's requirements into common language that can be adopted for the use with Behavior Driven Development (BDD) or Test Driven Development (TDD). \n \n \n Participates in industry and other professional networks to ensure awareness of industry standards, trends and best practices in order to strengthen organizational and technical knowledge. \n \n \n Provides support for investigating and troubleshooting production issues. \n \n \n Promotes the establishment of group standards and processes. Participates in the Communities of Practice. \n \n \n Works continually on improving performance of source code using industry standard methodologies. \n \n \n Helps drive technology direction and choices of technologies by making recommendations based on experience and research. \n \n \n \n \n  Qualifications/Education/Certifications: \n  Bachelor's degree from four-year college or university (in Information Technology or Computer Science preferred), plus five to eight years related experience and/or training; or equivalent combination of education and experience. \n  Knowledge, Skills and Abilities: \n  Prefer experience in Healthcare, PBM and/or ABM, workers' compensation and/or insurance industry. \n \n Required experience: \n        \n 5+ years SQL Server 2008/2014 \n \n \n 5+ years Data Integration technologies and principles \n Advanced knowledge of T-SQL including complex SQL queries (ex: using various joins and sub-queries) and best practices \n Advanced knowledge of index design and T-SQL performance tuning techniques \n Advanced experience integrating data from structured and unstructured formats: flat files, XML, EDI, JSON, EXCEL \n Advanced knowledge and experience in online transactional (OLTP) processing and analytical processing (OLAP) databases and schemas \n Advanced knowledge of Data Warehousing methodologies and concepts \n Experience with TDD / BDD \n \n The following knowledge is not required, but is preferred: \n \n Experience with BI Tools is a plus \n Basic understanding of object oriented programming \n Experience in distributed architectures such as Microservices, SOA, and RESTful APIs \n Continuous Integration \n Cucumber, Gherkin \n Jira \n \n Agile Competency Requirements: \n \n Requires an understanding of the application of Agile development methodology. \n Must be comfortable with change, close collaboration, and have conflict resolution skills. \n Knowledge of or willingness to learn Agile / DevOps values. \n Takes initiative and are passionate about what they do. \n Adaption, Ability & Desire to Learn, Team Oriented - tolerance & helpful, and Quality Focus \n \n \n Physical Demands/Working Conditions: \n  Duties are performed primarily in a home office setting utilizing computer equipment. Travel to attend meetings and visit locations throughout the country may be required. While performing the duties of this job, the employee is regularly required to sit and talk or hear. The employee is frequently required to use hands. The employee is occasionally required to stand and walk. *** Job descriptions will be reviewed and are subject to changes of business necessity. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n \n \n \n \n Pay is based on several factors including but not limited to education, work experience, certifications, geographical cost of labor, etc. In addition to base pay, Healthesystems offers a comprehensive benefits package including, health, dental, vision, disability and life insurance, wellness resources, recognition programs, 401k contribution, and PTO & Holiday pay (all subject to eligibility requirements). Applicable statutory benefits also provided. https://healthesystems.com/careers/ \n \n  Anticipated Starting Pay Range \n \n    $98,100\u2014$135,000 USD\n   \n \n \n  To facilitate working from home, and as a requirement for this role, candidates must provide their own reliable, high speed internet access with sufficient bandwidth to execute all job functions. Company laptop will be provided.", "cleaned_desc": " \n Recommends and provide guidance regarding Data Integration and database development, T-SQL best practices, and standards to the development team members as needed. \n \n \n Create and propose technical design documentation which includes current and future functionality, database objects affected, specifications, and flows/diagrams to detail the proposed database and/or Data Integration implementation. \n \n \n Has a deep understanding of the business processes and the technology platform that enables it. \n \n \n Translates stakeholder's requirements into common language that can be adopted for the use with Behavior Driven Development (BDD) or Test Driven Development (TDD). \n \n \n Participates in industry and other professional networks to ensure awareness of industry standards, trends and best practices in order to strengthen organizational and technical knowledge. \n \n \n Provides support for investigating and troubleshooting production issues. \n \n \n Promotes the establishment of group standards and processes. Participates in the Communities of Practice.   5+ years Data Integration technologies and principles \n Advanced knowledge of T-SQL including complex SQL queries (ex: using various joins and sub-queries) and best practices \n Advanced knowledge of index design and T-SQL performance tuning techniques \n Advanced experience integrating data from structured and unstructured formats: flat files, XML, EDI, JSON, EXCEL \n Advanced knowledge and experience in online transactional (OLTP) processing and analytical processing (OLAP) databases and schemas \n Advanced knowledge of Data Warehousing methodologies and concepts \n Experience with TDD / BDD \n \n The following knowledge is not required, but is preferred: \n \n Experience with BI Tools is a plus \n Basic understanding of object oriented programming \n Experience in distributed architectures such as Microservices, SOA, and RESTful APIs \n Continuous Integration \n Cucumber, Gherkin \n Jira \n \n Agile Competency Requirements: \n \n Requires an understanding of the application of Agile development methodology. ", "techs": ["data integration", "database development", "t-sql", "database objects", "flows/diagrams", "behavior driven development (bdd)", "test driven development (tdd)", "industry standards", "trends", "best practices", "investigating", "troubleshooting", "production issues", "group standards", "processes", "communities of practice", "data integration technologies", "t-sql queries", "index design", "t-sql performance tuning", "integrating data", "structured formats", "unstructured formats", "flat files", "xml", "edi", "json", "excel", "online transactional processing (oltp)", "analytical processing (olap)", "data warehousing methodologies", "bi tools", "object oriented programming", "distributed architectures", "microservices", "soa", "restful apis", "continuous integration", "cucumber", "gherkin", "jira", "agile development methodology."]}, "502637fdf8fd4c35": {"terms": ["data engineer"], "salary_min": 109956.66, "salary_max": 139229.62, "title": "Senior Data Engineer / Remote Mexico Position", "company": "Argano", "desc": "REQUIRED QUALIFICATIONS, EXPERIENCE & SKILLS \n \n \n 5 years' experience consulting in Data or Dynamics business application domain \n \n \n Expert experience with T-SQL language \n \n \n Experience in creating Data Factory pipelines to orchestrate ingestion and transformation data for use in analytics and system integration \n \n \n Experience with the Dynamics 365 data model \n \n \n Experience using modern Azure data services such as Azure Synapse, Azure SQL Database, Azure Data Lake Storage Gen 2, Microsoft Fabric \n \n \n Familiarity with security configuration and security policies, and best practices within Azure \n \n \n Curious and tenacious when it comes to leveraging new Azure technology to deliver novel solutions for clients \n \n \n \n ADDITIONAL QUALIFICATIONS & SKILLS \n \n \n Azure Data Engineer Associate Certification preferred (DP-203) \n \n \n Familiar with data lakehouse patterns and practices preferred \n \n \n Bachelor\u2019s Degree in Information Systems Management, Computer Science, or related field \n \n \n Demonstrated ability to lead project workstream including interfacing in a client facing role \n \n \n Familiar with Agile implementation methodology \n \n \n Experience working with a multicultural and/or multilingual team across several time zones remotely", "cleaned_desc": " \n Experience in creating Data Factory pipelines to orchestrate ingestion and transformation data for use in analytics and system integration \n \n \n Experience with the Dynamics 365 data model \n \n \n Experience using modern Azure data services such as Azure Synapse, Azure SQL Database, Azure Data Lake Storage Gen 2, Microsoft Fabric ", "techs": ["data factory", "dynamics 365", "azure synapse", "azure sql database", "azure data lake storage gen 2", "microsoft fabric"]}, "54b4e3c8dc6973fe": {"terms": ["data engineer"], "salary_min": 133742.28, "salary_max": 169347.53, "title": "Data Engineer TS/SCI", "company": "Cyberjin", "desc": "Hybrid/Remote position \n  Looking for a talented Data Engineer to support the acquisition of mission critical and mission support data sets. The preferred candidate will have a background in supporting cyber and/or network related missions within the military spaces, as either a developer, analyst or engineer. Work is mostly on customer site in San Antonio, TX with some hybrid support. \n \n  Essential Job Responsibilities \n  The ideal candidate will have worked with big data systems, complex structured and unstructured data sets, and have supported government data acquisition, analysis, and/or sharing efforts in the past.  \n To excel in the position, the candidate shall have a strong attention to detail, be able to understand technical complexities, and have the willingness to learn and adapt to the situation.  \n The candidate will work both independently and as part of a large team to accomplish client objectives.  \n Minimum Qualifications \n  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata. \n  Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). \n  Ability to decompose technical problems and troubleshoot system and dataflow issues. \n  Must be able to work on customer site most of the time. \n  Preferred Requirements \n  Experience with NOSQL databases such as Accumulo desired \n  Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer. \n   \n ejTw3HSN5g", "cleaned_desc": "  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata.    Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). ", "techs": ["security clearance", "ts/sci level security clearance", "u.s. citizen", "python", "java", "acquisition", "network data", "metadata", "data extraction", "translation", "loading", "data prep", "labeling", "data analytics", "kibana", "elasticsearch", "log formats", "json", "xml", "data flow", "management", "storage solutions", "kafka", "nifi", "aws s3", "aws sqs"]}, "d7f1ccad64214f40": {"terms": ["data engineer"], "salary_min": 110291.03, "salary_max": 139653.02, "title": "Sr Engineer, Data", "company": "Rite Aid", "desc": "Company \n         \n \n \n         Rite Aid\n         \n \n \n \n \n \n \n \n         Shift \n         \n \n         Day \n         \n \n \n \n \n \n \n \n \n \n         Job Type \n         \n \n         Full time\n         \n \n \n \n \n \n \n \n         Requisition \n         \n \n         JR020134\n         \n \n \n \n \n \n \n \n         Last Updated \n         \n \n         2023-10-09\n         \n \n \n \n \n \n \n \n         Department \n         \n \n         TS Business Intelligence\n         \n \n \n \n \n \n \n Job Locations  \n \n \n        Valley Green - Corporate - 200 Newberry Commons, Etters, PA, 17319 \n        \n \n        Remote- United States \n        \n \n \n \n \n \n \n \n \n         Job Summary \n         \n \n         The Sr Google Data Engineer will define and deliver solutions that leverage data to enable the company to scale and accelerate its growth within the cloud. The role will take the lead and build data pipelines, data models and data integrations and other business systems into the Google data platform that will empower the business and analysts to make data-driven decisions. This person will Setup Google infrastructure, automation and visualization platforms and setup and manage data platform including Enterprise Data Warehouse. The Google Cloud Lead Engineer will be a key member of the Riteaid Enterprise Data Services group. They will provide best practices on secure foundational cloud implementations, automated provisioning of infrastructure and applications, cloud-ready application architectures, and more. Through the cloud engineer's guidance, we will ensure our teams have an excellent experience in building, modernizing, migrating, and maintaining applications in our hybrid multi cloud environment. The cloud engineer also serves as a guide and subject matter expert elevating the overall cloud capabilities within Riteaid. \n         \n \n \n \n \n \n \n \n \n \n         Job Responsibilities \n         \n \n         \u2022Refine, evangelize, and deliver on Rite Aid\u2019s Modernization vision and strategy \u2022Partner in the delivery of cloud-based technical architectures, migration approaches, and application optimizations that enable business objectives \u2022Collaborate with Product Owners, Scrum Masters, Developers, Product Architects to implement technical solutions \u2022Evolve and drive our automation capabilities by enabling a DevOps and SRE culture \u2022Support the adoption of Cloud practices and drive the institutionalization of the practices \u2022Identify risk and mitigation plans associated with security, legal, data, compliance, and regulatory requirements \u2022Contribute to the development of internal best practices as well as new innovative capabilities \u2022Hands on-Technical lead to guide, mentor, and coach \n         \n \n \n \n \n \n \n \n \n \n         qualifications \n         \n \n EDUCATION REQUIREMENTS  Education Level GED Bachelor Degree Area of Specialization Information Services or related field \n          LICENCES/CERTIFICATIONS  Not Applicable \n          WORK EXPERIENCE  Experience combined roles of cloud engineer, infrastructure engineer, DevOps engineering, SRE or application development designing, building, and deploying scalable cloud-based solutions in GCP with automating infrastructure provisioning and/or continuous integration/delivery Experience with containerization and container orchestration technologies with cloud architecture and implementation features (OS, multi-tenancy, virtualization, orchestration, elastic scalability) Experience in supporting and troubleshooting large-scale applications deployed in a hybrid multi-cloud Familiarity with standard IT security practices such as identity and access management, data protection, encryption, certificate, and key management Experience one or more languages, such as Java, Python, Go, JavaScript, C++, or similar Experience with \u201con-premises to cloud\u201d migrations or IT transformations Experience leading by example in a large, highly complex, and ever-changing organization; preferably in a hybrid cloud environment. Hand on experience using Cloud data platforms. Setup automation and visualization platforms. Experience building data platforms and data warehouse from ground up Experience with visualization platforms (Tableau, Excel) Expertise in ETL design, implementation and maintenance Expert in schema design and dimensional OLTP data modeling Building data design and modeling from ground up Expert usage of SQL and python (must be able to code in python) Practical application of basic statistical methods: Regression and other techniques to be used for statistical models \n         \n \n \n \n \n \n \n \n \n \n Fair Chance Act \n  Fair Chance Act Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Pursuant to the California Fair Chance Act, we will consider qualified applicants with a criminal history. You do not need to disclose your criminal history or participate in a background check until a conditional job offer is made to you. After making a conditional offer and running a background check, if we identify a conviction that is directly related to the job, you will be given the chance to explain the circumstances surrounding the conviction, provide mitigating evidence, or challenge the accuracy of the background report. Find out more about the Fair Chance Act by visiting the Civil Right\u2019s Department Fair Chance Act webpage. \n  For more detailed information around city/state required notices, click here to access a list of disclosures. \n  New Jersey Law Against Discrimination (LAD) \n  The New Jersey Law Against Discrimination (LAD) prohibits unlawful employment discrimination based on an individual's race, creed, color, national origin, nationality, ancestry, age, sex (including pregnancy), familial status, marital/civil union status, religion, domestic partnership status, affectional or sexual orientation, gender identity and expression, atypical hereditary cellular or blood trait, genetic information, liability for military service, and mental or physical disability (including perceived disability, and AIDS and HIV status).", "cleaned_desc": " \n \n \n \n \n \n         Job Summary \n         \n \n         The Sr Google Data Engineer will define and deliver solutions that leverage data to enable the company to scale and accelerate its growth within the cloud. The role will take the lead and build data pipelines, data models and data integrations and other business systems into the Google data platform that will empower the business and analysts to make data-driven decisions. This person will Setup Google infrastructure, automation and visualization platforms and setup and manage data platform including Enterprise Data Warehouse. The Google Cloud Lead Engineer will be a key member of the Riteaid Enterprise Data Services group. They will provide best practices on secure foundational cloud implementations, automated provisioning of infrastructure and applications, cloud-ready application architectures, and more. Through the cloud engineer's guidance, we will ensure our teams have an excellent experience in building, modernizing, migrating, and maintaining applications in our hybrid multi cloud environment. The cloud engineer also serves as a guide and subject matter expert elevating the overall cloud capabilities within Riteaid. \n         \n \n \n \n \n \n \n \n \n \n         Job Responsibilities \n         \n \n         \u2022Refine, evangelize, and deliver on Rite Aid\u2019s Modernization vision and strategy \u2022Partner in the delivery of cloud-based technical architectures, migration approaches, and application optimizations that enable business objectives \u2022Collaborate with Product Owners, Scrum Masters, Developers, Product Architects to implement technical solutions \u2022Evolve and drive our automation capabilities by enabling a DevOps and SRE culture \u2022Support the adoption of Cloud practices and drive the institutionalization of the practices \u2022Identify risk and mitigation plans associated with security, legal, data, compliance, and regulatory requirements \u2022Contribute to the development of internal best practices as well as new innovative capabilities \u2022Hands on-Technical lead to guide, mentor, and coach \n         \n \n \n   \n \n \n \n \n \n         qualifications \n         \n \n EDUCATION REQUIREMENTS  Education Level GED Bachelor Degree Area of Specialization Information Services or related field \n          LICENCES/CERTIFICATIONS  Not Applicable \n          WORK EXPERIENCE  Experience combined roles of cloud engineer, infrastructure engineer, DevOps engineering, SRE or application development designing, building, and deploying scalable cloud-based solutions in GCP with automating infrastructure provisioning and/or continuous integration/delivery Experience with containerization and container orchestration technologies with cloud architecture and implementation features (OS, multi-tenancy, virtualization, orchestration, elastic scalability) Experience in supporting and troubleshooting large-scale applications deployed in a hybrid multi-cloud Familiarity with standard IT security practices such as identity and access management, data protection, encryption, certificate, and key management Experience one or more languages, such as Java, Python, Go, JavaScript, C++, or similar Experience with \u201con-premises to cloud\u201d migrations or IT transformations Experience leading by example in a large, highly complex, and ever-changing organization; preferably in a hybrid cloud environment. Hand on experience using Cloud data platforms. Setup automation and visualization platforms. Experience building data platforms and data warehouse from ground up Experience with visualization platforms (Tableau, Excel) Expertise in ETL design, implementation and maintenance Expert in schema design and dimensional OLTP data modeling Building data design and modeling from ground up Expert usage of SQL and python (must be able to code in python) Practical application of basic statistical methods: Regression and other techniques to be used for statistical models \n         \n \n \n \n \n \n \n \n \n \n Fair Chance Act \n  Fair Chance Act Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Pursuant to the Los Angeles Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. \n  Pursuant to the California Fair Chance Act, we will consider qualified applicants with a criminal history. You do not need to disclose your criminal history or participate in a background check until a conditional job offer is made to you. After making a conditional offer and running a background check, if we identify a conviction that is directly related to the job, you will be given the chance to explain the circumstances surrounding the conviction, provide mitigating evidence, or challenge the accuracy of the background report. Find out more about the Fair Chance Act by visiting the Civil Right\u2019s Department Fair Chance Act webpage. \n  For more detailed information around city/state required notices, click here to access a list of disclosures. \n  New Jersey Law Against Discrimination (LAD) ", "techs": ["google data engineer", "data pipelines", "data models", "data integrations", "google data platform", "google infrastructure", "automation platforms", "visualization platforms", "enterprise data warehouse", "riteaid enterprise data services", "secure foundational cloud implementations", "automated provisioning", "cloud-ready application architectures", "cloud engineer", "hybrid multi cloud environment", "modernization vision and strategy", "cloud-based technical architectures", "migration approaches", "application optimizations", "devops and sre culture", "cloud practices", "risk mitigation plans", "internal best practices", "innovative capabilities", "technical lead", "ged bachelor degree", "information services", "cloud engineer", "infrastructure engineer", "devops engineering", "sre", "application development", "gcp", "automating infrastructure provisioning", "continuous integration/delivery", "containerization", "container orchestration", "cloud architecture", "implementation features", "os", "multi-tenancy", "virtualization", "orchestration", "elastic scalability", "supporting and troubleshooting large-scale applications", "hybrid multi-cloud", "it security practices", "identity and access management", "data protection", "encryption", "certificate and key management", "java", "python", "go", "javascript", "c++", "on-premises to cloud migrations", "it transformations", "hybrid cloud environment", "cloud data platforms", "automation platforms", "tableau", "excel visualization platforms", "etl design", "implementation and maintenance", "sql", "python", "statistical methods", "regression", "fair chance act"]}, "987d38c95ffcf11f": {"terms": ["data engineer"], "salary_min": 114180.37, "salary_max": 144577.78, "title": "Lead Big Data Engineer", "company": "e-Hireo", "desc": "Experience :  6 - 10 Yrs \n Location :  Pune (Aundh) \n Position :  Senior / Lead Big Data Engineer \n To be successful in this role, you should possess : \n \n Collaborate closely with Product Management and Engineering leadership to devise and build the right solution. \n Participate in Design discussions and brainstorming sessions to select, integrate, and maintain Big Data tools and frameworks required to solve Big Data problems at scale. \n Design and implement systems to cleanse, process, and analyze large data sets using distributed processing tools like Akka and Spark. \n Understanding and critically reviewing existing data pipelines, and coming up with ideas in collaboration with Technical Leaders and Architects to improve upon current bottlenecks \n Take initiatives and show the drive to pick up new stuff proactively, and work as a Senior Individual contributor on the multiple products and features we have. \n 7+ years of experience in developing highly scalable Big Data pipelines. \n In-depth understanding of the Big Data ecosystem including processing frameworks like Spark, Akka, Storm, and Hadoop, and the file types they deal with. \n Experience with ETL and Data pipeline tools like Apache NiFi, Airflow etc. \n Excellent coding skills in Java or Scala, including the understanding to apply appropriate Design Patterns when required. \n Experience with Git and build tools like Gradle/Maven/SBT. \n Strong understanding of object-oriented design, data structures, algorithms, profiling, and optimization. \n Have elegant, readable, maintainable, and extensible code style. \n \n You are someone who would easily be able to : \n \n Work closely with the US and India engineering teams to help build the Java/Scala based data pipelines. \n Lead the India engineering team in technical excellence and ownership of critical modules; own the development of new modules and features. \n Troubleshoot live production server issues. \n Handle client coordination and be able to work as a part of a team, be able to contribute independently and drive the team to exceptional contributions with minimal team supervision. \n Follow Agile methodology, JIRA for work planning, issue management/tracking. \n \n Additional Project/Soft Skills : \n \n Should be able to work independently with India & US based team members. \n Strong verbal and written communication with ability to articulate problems and solutions over phone and emails. \n Strong sense of urgency, with a passion for accuracy and timeliness. \n Ability to work calmly in high pressure situations and manage multiple projects/tasks. \n Ability to work independently and possess superior skills in issue resolution. \n Should have the passion to learn and implement, analyze, and troubleshoot issues. \n \n Job Type: Full-time \n Salary: $2,500,000.00 - $3,000,000.00 per year \n Benefits: \n \n Flexible schedule \n Health insurance \n \n Experience level: \n \n 10 years \n 6 years \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Experience: \n \n Scala: 4 years (Required) \n Spark: 4 years (Preferred) \n Apache Hive: 4 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "Experience :  6 - 10 Yrs \n Location :  Pune (Aundh) \n Position :  Senior / Lead Big Data Engineer \n To be successful in this role, you should possess : \n \n Collaborate closely with Product Management and Engineering leadership to devise and build the right solution. \n Participate in Design discussions and brainstorming sessions to select, integrate, and maintain Big Data tools and frameworks required to solve Big Data problems at scale. \n Design and implement systems to cleanse, process, and analyze large data sets using distributed processing tools like Akka and Spark. \n Understanding and critically reviewing existing data pipelines, and coming up with ideas in collaboration with Technical Leaders and Architects to improve upon current bottlenecks \n Take initiatives and show the drive to pick up new stuff proactively, and work as a Senior Individual contributor on the multiple products and features we have. \n 7+ years of experience in developing highly scalable Big Data pipelines.   In-depth understanding of the Big Data ecosystem including processing frameworks like Spark, Akka, Storm, and Hadoop, and the file types they deal with. \n Experience with ETL and Data pipeline tools like Apache NiFi, Airflow etc. \n Excellent coding skills in Java or Scala, including the understanding to apply appropriate Design Patterns when required. \n Experience with Git and build tools like Gradle/Maven/SBT. \n Strong understanding of object-oriented design, data structures, algorithms, profiling, and optimization. \n Have elegant, readable, maintainable, and extensible code style. \n \n You are someone who would easily be able to : \n \n Work closely with the US and India engineering teams to help build the Java/Scala based data pipelines. \n Lead the India engineering team in technical excellence and ownership of critical modules; own the development of new modules and features.   Troubleshoot live production server issues. \n Handle client coordination and be able to work as a part of a team, be able to contribute independently and drive the team to exceptional contributions with minimal team supervision. \n Follow Agile methodology, JIRA for work planning, issue management/tracking. \n \n Additional Project/Soft Skills : \n \n Should be able to work independently with India & US based team members. \n Strong verbal and written communication with ability to articulate problems and solutions over phone and emails. \n Strong sense of urgency, with a passion for accuracy and timeliness. \n Ability to work calmly in high pressure situations and manage multiple projects/tasks. \n Ability to work independently and possess superior skills in issue resolution. ", "techs": ["akka", "spark", "hadoop", "apache nifi", "airflow", "java", "scala", "git", "gradle/maven/sbt", "jira"]}, "30b006781edd63e6": {"terms": ["data engineer"], "salary_min": 105000.0, "salary_max": 125000.0, "title": "Senior Data Engineer - Health Plan Financial Reporting - 100% Remote", "company": "BlueSky Technology Solutions", "desc": "We have an immediate need for a Senior Data Engineer with experience supporting Health Plan Financial Data Reporting. This permanent position is 100% remote and offers competitive compensation (that will depend on level of experience). Excellent benefits package. \n Target Skills and Experience: \n \n 4+ years of SAS programming experience with extensive macro utilization. One or more SAS certifications desired. \n Strong Data Engineering experience with proven track record in SAS usage of designing, developing, and maintaining data extract/transformation jobs, analytical reporting, and automated programming with reusable and SAS macro driven components \n Strong experience as Data Analyst or Data Engineer within a Health Plan/Payor environment supporting Financial reporting. \n Prior Clinical and Claims data reporting experience. \n 4+ years of SQL technical experience preferably with multiple Data Base Management systems. Strong understanding of indexed and efficient table joins. \n 3+ years of Tableau dashboard development experience. \n \n Job Type: Full-time \n Pay: $105,000.00 - $125,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Retirement plan \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n SQL: 4 years (Preferred) \n Data Analytics/Data Engineering: 4 years (Preferred) \n SAS programming: 4 years (Preferred) \n Health Plan Financial Reporting: 3 years (Preferred) \n SAS Macro utilization: 3 years (Preferred) \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "651209e06d4f7358": {"terms": ["data engineer"], "salary_min": 110000.0, "salary_max": 136000.0, "title": "Senior Engineer, Data Insights (Remote)", "company": "Abercrombie and Fitch Co.", "desc": "Company Description\n   Job Description \n  The primary responsibility of the  Senior Engineer, Global Data & Insights - Data Management  is to build data pipelines, model and prepare data, perform complex data analysis to answer Business questions, build and automate data pipeline and quality framework to enable and promote self service data pipelines, assist in operationalizing the AI / ML Engineering solutions. This role is expected to lead and guide other team members and evangelize the design patterns as well as coding standards. \n  This role plays an active part in our Data Modernization project to migrate the from on-prem platforms such as IBM Netezza to cloud project \n  What Will You Be Doing? \n \n  Team up with the engineering teams and enterprise architecture (EA) to define standards, design patterns, accelerators, development practices, DevOps and CI/CD automation \n  Create and maintain the data ingestion, quality testing and audit framework \n  Conduct complex data analysis to answer the queries from Business Users or Technology team partners either directly from Analysts or stemmed from one of the Reporting tools suchs PowerBI, Tableau, OBIEE. \n  Build and automate the data ingestion, transformation and aggregation pipelines using Azure Data Factory, Databricks / Spark, Snowflake, Kafka as well as Enterprise Scheduler tools such as CA Workload automation or Control M \n  Setup and evangelize the metadata driven approach to data pipelines to promote self service \n  Setup and continuously improve the data quality and audit monitoring as well as alerting \n  Constantly evaluate the process automation options and collaborate with engineering as well as architecture to review the proposed design. \n  Demonstrate mastery of build and release engineering principles and methodologies including source control, branch management, build and smoke testing, archiving and retention practices \n  Adhere to and enhance and document the design principles, best practices by collaborating with Solution and in some cases Enterprise Architects \n  Participate in and support the Data Academy and Data Literacy program to train the Business Users and Technology teams on Data \n  Respond SLA driven production data quality or pipeline issues \n  Work in a fast-paced Agile/Scrum environment \n  Identify and assist with implementation of DevOps practices in support of fully automated deployments \n  Document the Data Flow Diagrams, Data Models, Technical Data Mapping and Production Support Information for Data Pipelines \n  Follow the Industry standard data security practices and evangelize the same across the team. \n \n  What Do You Need To Bring? \n \n  Bachelor\u2019s degree in Computer Science or Engineering or Mathematics or related field and 5+ years of experience in various cloud technologies within a large-scale organization \n  Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, highly motivated, Team oriented \n  Experience designing and building complex data pipelines in an agile environment \n  Expertise on data analysis and wrangling using sql, python, databricks \n  Experience with modern cloud development and design concepts; software development lifecycle; multi-developer code versioning and conflict resolution; planning, design, and problem resolution enterprise data applications / solutions \n  Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms \n  5+ years of experience in an Enterprise Data Management or Data Engineering role \n  3+ of hands on experience in building metadata driven data pipelines using Azure Data Factory, Databricks / Spark for Cloud Datalake \n  5+ years hands on experience with using one or more of the following for data analysis and wrangling Databricks, Python / PySpark, Jupyter Notebooks \n  Expert level SQL knowledge on databases such as but not limited to Snowflake, Netezza, Oracle, Sql Server, MySQL, Teradata \n  3+ years of hands on experience on one or more of big data technologies such as Cloudera Hadoop, Pivotal, Vertica, MapR is a plus \n  Experience working in a multi developer environment and hands on experience in using either azure devops or gitlab \n  Preferably experienced in SLA driven Production Data Pipeline or Quality support \n  Experience or strong understanding of the traditional enterprise ETL platforms such as IBM Datastage, Informatica, Pentaho, Ab Initio etc. \n  Functional knowledge of some of the following technologies - Terraform, Azure CLI, PowerShell, Containerization (Kubernetes, Docker) \n  Functional knowledge of one or more Reporting tools such as PowerBI, Tableau, OBIEE \n  Team player with excellent communication skills, ability to communicate with the customer directly and able to explain the status of the deliverables in scrum calls \n  Ability to implement Agile methodologies and work in an Agile DevOps environment \n \n  Our Company \n  Abercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we\u2019re here for our associates, customers and communities on the journey to being and becoming who they are \u2013 and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas. \n  Our Values \n  We lead with purpose and always put our people first, which is evidenced by our Great Place to Work\u2122 Certification, as well as being a 2021 recipient of Fortune\u2019s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We\u2019re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities. \n  What You'll Get \n  As an Abercrombie & Fitch Co. (A&F Co.) associate, you\u2019ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company\u2019s culture and values, but most importantly \u2013 with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward: \n \n  Incentive Bonus Program \n  Paid Time Off and Work From Anywhere Flexibility \n  Paid Volunteer Day per Year, allowing you to give back to your community \n  Merchandise Discount \n  Medical, Dental and Vision Insurance Available \n  Life and Disability Insurance \n  Associate Assistance Program \n  Paid Parental and Adoption Leave \n  Access to Carrot to support your unique parenthood journey \n  Access to Headspace dedicated to creating healthier, happier lives from the inside out \n  401(K) Savings Plan with Company Match \n  Opportunities for Career Advancement, we believe in promoting from within \n  A Global Team of People Who'll Celebrate you for Being YOU \n \n \n \n \n Additional Information\n   ABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER \n  Notice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $110,000 - $136,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future.", "cleaned_desc": "Company Description\n   Job Description \n  The primary responsibility of the  Senior Engineer, Global Data & Insights - Data Management  is to build data pipelines, model and prepare data, perform complex data analysis to answer Business questions, build and automate data pipeline and quality framework to enable and promote self service data pipelines, assist in operationalizing the AI / ML Engineering solutions. This role is expected to lead and guide other team members and evangelize the design patterns as well as coding standards. \n  This role plays an active part in our Data Modernization project to migrate the from on-prem platforms such as IBM Netezza to cloud project \n  What Will You Be Doing? \n \n  Team up with the engineering teams and enterprise architecture (EA) to define standards, design patterns, accelerators, development practices, DevOps and CI/CD automation \n  Create and maintain the data ingestion, quality testing and audit framework \n  Conduct complex data analysis to answer the queries from Business Users or Technology team partners either directly from Analysts or stemmed from one of the Reporting tools suchs PowerBI, Tableau, OBIEE. \n  Build and automate the data ingestion, transformation and aggregation pipelines using Azure Data Factory, Databricks / Spark, Snowflake, Kafka as well as Enterprise Scheduler tools such as CA Workload automation or Control M \n  Setup and evangelize the metadata driven approach to data pipelines to promote self service \n  Setup and continuously improve the data quality and audit monitoring as well as alerting \n  Constantly evaluate the process automation options and collaborate with engineering as well as architecture to review the proposed design.    Demonstrate mastery of build and release engineering principles and methodologies including source control, branch management, build and smoke testing, archiving and retention practices \n  Adhere to and enhance and document the design principles, best practices by collaborating with Solution and in some cases Enterprise Architects \n  Participate in and support the Data Academy and Data Literacy program to train the Business Users and Technology teams on Data \n  Respond SLA driven production data quality or pipeline issues \n  Work in a fast-paced Agile/Scrum environment \n  Identify and assist with implementation of DevOps practices in support of fully automated deployments \n  Document the Data Flow Diagrams, Data Models, Technical Data Mapping and Production Support Information for Data Pipelines \n  Follow the Industry standard data security practices and evangelize the same across the team. \n \n  What Do You Need To Bring? \n \n  Bachelor\u2019s degree in Computer Science or Engineering or Mathematics or related field and 5+ years of experience in various cloud technologies within a large-scale organization \n  Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, highly motivated, Team oriented    Experience designing and building complex data pipelines in an agile environment \n  Expertise on data analysis and wrangling using sql, python, databricks \n  Experience with modern cloud development and design concepts; software development lifecycle; multi-developer code versioning and conflict resolution; planning, design, and problem resolution enterprise data applications / solutions \n  Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms \n  5+ years of experience in an Enterprise Data Management or Data Engineering role \n  3+ of hands on experience in building metadata driven data pipelines using Azure Data Factory, Databricks / Spark for Cloud Datalake \n  5+ years hands on experience with using one or more of the following for data analysis and wrangling Databricks, Python / PySpark, Jupyter Notebooks \n  Expert level SQL knowledge on databases such as but not limited to Snowflake, Netezza, Oracle, Sql Server, MySQL, Teradata \n  3+ years of hands on experience on one or more of big data technologies such as Cloudera Hadoop, Pivotal, Vertica, MapR is a plus \n  Experience working in a multi developer environment and hands on experience in using either azure devops or gitlab \n  Preferably experienced in SLA driven Production Data Pipeline or Quality support \n  Experience or strong understanding of the traditional enterprise ETL platforms such as IBM Datastage, Informatica, Pentaho, Ab Initio etc. \n  Functional knowledge of some of the following technologies - Terraform, Azure CLI, PowerShell, Containerization (Kubernetes, Docker) ", "techs": ["azure data factory", "databricks", "snowflake", "kafka", "ca workload automation", "control m", "powerbi", "tableau", "obiee", "python", "jupyter notebooks", "sql", "snowflake", "netezza", "oracle", "sql server", "mysql", "teradata", "cloudera hadoop", "pivotal", "vertica", "mapr", "azure devops", "gitlab", "ibm datastage", "informatica", "pentaho", "ab initio", "terraform", "azure cli", "powershell", "kubernetes", "docker."]}, "a6b1080314ce4859": {"terms": ["data engineer"], "salary_min": 114308.68, "salary_max": 144740.27, "title": "Senior Snowflake Data Engineer", "company": "Cardamom Health", "desc": "Remote  \n Your Role:   \n As part of the Delivery Team in Data Services at Cardamom, you will design and develop cloud-based data lakehouse, warehouse, and platform solutions to support the data, analysis, and reporting needs of our clients. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate disparate data from multiple sources.  \n As a Senior Snowflake Data Engineer at Cardamom, you will:   \n \n Provide outstanding customer service through listening to make sure customer needs are understood, building relationships with customers up to director level, and providing timely updates with the right level of detail to each audience  \n Build relationships and communicate engagement accomplishments, plan, and challenges to manager and director-level client counterparts  \n Develop ETL/ELT data pipelines to load data from various data sources to the staging database and apply complex business logic to populate normalized and denormalized data structures  \n Develop data pipelines to handle integration of disparate data types such as flat files, XML/JSON, API, unstructured data into Snowflake cloud services  \n Seek business and technical requirements from enterprise data architect and business stakeholders to accurately build required data pipelines, data definitions, and analytical data models  \n Build reusable components for a scalable data integration methodology such as error handling, logging, and recoverability  \n Review end-to-end pipelines for performance and cost efficiency of the overall data services  Travel occasionally dependent on client requirements (up to 10%) \n  \n \n Our ideal Senior Snowflake Data Engineer will have:   \n \n 3+ years of required Snowflake experience  \n SnoPro Core or SnoPro Advanced required certification  \n Strong SQL skills for complex queries  \n Familiarity with the software development lifecycle  \n Proficiency in database development (OLTP and Data Warehouse/Dimensional)  \n ETL/ELT process experience  \n Competence in complex, distributed, and massively parallel systems  \n Excellent analytical and problem-solving abilities, including algorithm representation in software  \n Deep understanding of data structures and algorithms  Expertise in integrating and modeling healthcare data such as clinical, claims, genomics datasets \n  \n \n Bonus points for experience with the following:   \n \n Snowflake Cloud Data Warehouse ELT tools  \n ML frameworks and libraries including TensorFlow, Spark, PyTorch, and MLPACK  \n BI tools  Amazon Web Services, Microsoft Azure, or Google Cloud \n  \n \n What do we offer to ideal candidates?   \n To learn more about Cardamom's culture and the benefits and overall work experience we provide, visit our Careers page.", "cleaned_desc": "Remote  \n Your Role:   \n As part of the Delivery Team in Data Services at Cardamom, you will design and develop cloud-based data lakehouse, warehouse, and platform solutions to support the data, analysis, and reporting needs of our clients. To succeed in this data engineering position, you should have strong analytical skills and the ability to integrate disparate data from multiple sources.  \n As a Senior Snowflake Data Engineer at Cardamom, you will:   \n \n Provide outstanding customer service through listening to make sure customer needs are understood, building relationships with customers up to director level, and providing timely updates with the right level of detail to each audience  \n Build relationships and communicate engagement accomplishments, plan, and challenges to manager and director-level client counterparts    Develop ETL/ELT data pipelines to load data from various data sources to the staging database and apply complex business logic to populate normalized and denormalized data structures  \n Develop data pipelines to handle integration of disparate data types such as flat files, XML/JSON, API, unstructured data into Snowflake cloud services  \n Seek business and technical requirements from enterprise data architect and business stakeholders to accurately build required data pipelines, data definitions, and analytical data models  \n Build reusable components for a scalable data integration methodology such as error handling, logging, and recoverability  \n Review end-to-end pipelines for performance and cost efficiency of the overall data services  Travel occasionally dependent on client requirements (up to 10%) \n  \n   Our ideal Senior Snowflake Data Engineer will have:   \n \n 3+ years of required Snowflake experience  \n SnoPro Core or SnoPro Advanced required certification  \n Strong SQL skills for complex queries  \n Familiarity with the software development lifecycle  \n Proficiency in database development (OLTP and Data Warehouse/Dimensional)    ETL/ELT process experience  \n Competence in complex, distributed, and massively parallel systems  \n Excellent analytical and problem-solving abilities, including algorithm representation in software  \n Deep understanding of data structures and algorithms  Expertise in integrating and modeling healthcare data such as clinical, claims, genomics datasets \n  \n \n Bonus points for experience with the following:   ", "techs": ["snowflake", "sql", "etl/elt", "database development", "oltp", "data warehouse/dimensional", "complex distributed systems", "algorithm representation", "data structures", "healthcare data integration", "clinical data", "claims data", "genomics datasets"]}, "d4ed26d290fe9912": {"terms": ["data engineer"], "salary_min": 98100.0, "salary_max": 135000.0, "title": "Senior Data Integration Engineer - Remote", "company": "Healthe systems", "desc": "Healthesystems offers workplace flexibility with our Work-From-Home model, and a competitive compensation and benefits package including healthcare coverage, PTO, paid holidays, 401(k), company-provided life insurance/disability coverage, wellness options, and more. \n \n \n Note: we are unable to hire in every state \n \n \n \n \n Summary:  Responsible for the analysis, design, documentation, development, unit testing, and support of Data Integration and database objects development for software applications. Provides support and guidance regarding Data Integration and T-SQL best practices and development standards. Promotes approved agile methodologies, leading the design and development efforts for the agile team. Actively coaches, guides, and mentors team members in providing valuable solutions to our customer. \n   Key Responsibilities: \u201cTo simplify complexities for each customer.\u201d \n \n \n Collaborates with stakeholders and development team members to achieve business results. \n \n \n Work closely with other engineers to integrate databases with other applications. \n \n \n Leads the design, development, and implementation of database applications and solutions for managing and integrating data between operational systems, data repositories, and reporting and analytical applications. This includes but is not limited to ETL, stored procedures, views, and functions. \n \n \n Recommends and provide guidance regarding Data Integration and database development, T-SQL best practices, and standards to the development team members as needed. \n \n \n Create and propose technical design documentation which includes current and future functionality, database objects affected, specifications, and flows/diagrams to detail the proposed database and/or Data Integration implementation. \n \n \n Has a deep understanding of the business processes and the technology platform that enables it. \n \n \n Translates stakeholder\u2019s requirements into common language that can be adopted for the use with Behavior Driven Development (BDD) or Test Driven Development (TDD). \n \n \n Participates in industry and other professional networks to ensure awareness of industry standards, trends and best practices in order to strengthen organizational and technical knowledge. \n \n \n Provides support for investigating and troubleshooting production issues. \n \n \n Promotes the establishment of group standards and processes. Participates in the Communities of Practice. \n \n \n Works continually on improving performance of source code using industry standard methodologies. \n \n \n Helps drive technology direction and choices of technologies by making recommendations based on experience and research. \n \n \n \n \n  Qualifications/Education/Certifications: \n  Bachelor's degree from four-year college or university (in Information Technology or Computer Science preferred), plus five to eight years related experience and/or training; or equivalent combination of education and experience. \n  Knowledge, Skills and Abilities: \n  Prefer experience in Healthcare, PBM and/or ABM, workers\u2019 compensation and/or insurance industry. \n \n Required experience: \n         \n 5+ years SQL Server 2008/2014 \n \n \n 5+ years Data Integration technologies and principles \n Advanced knowledge of T-SQL including complex SQL queries (ex: using various joins and sub-queries) and best practices \n Advanced knowledge of index design and T-SQL performance tuning techniques \n Advanced experience integrating data from structured and unstructured formats: flat files, XML, EDI, JSON, EXCEL \n Advanced knowledge and experience in online transactional (OLTP) processing and analytical processing (OLAP) databases and schemas \n Advanced knowledge of Data Warehousing methodologies and concepts \n Experience with TDD / BDD \n \n The following knowledge is not required, but is preferred: \n \n Experience with BI Tools is a plus \n Basic understanding of object oriented programming \n Experience in distributed architectures such as Microservices, SOA, and RESTful APIs \n Continuous Integration \n Cucumber, Gherkin \n Jira \n \n Agile Competency Requirements: \n \n Requires an understanding of the application of Agile development methodology. \n Must be comfortable with change, close collaboration, and have conflict resolution skills. \n Knowledge of or willingness to learn Agile / DevOps values. \n Takes initiative and are passionate about what they do. \n Adaption, Ability & Desire to Learn, Team Oriented - tolerance & helpful, and Quality Focus \n \n \n Physical Demands/Working Conditions: \n  Duties are performed primarily in a home office setting utilizing computer equipment. Travel to attend meetings and visit locations throughout the country may be required. While performing the duties of this job, the employee is regularly required to sit and talk or hear. The employee is frequently required to use hands. The employee is occasionally required to stand and walk. *** Job descriptions will be reviewed and are subject to changes of business necessity. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n \n \n \n \n \n Pay is based on several factors including but not limited to education, work experience, certifications, geographical cost of labor, etc. In addition to base pay, Healthesystems offers a comprehensive benefits package including, health, dental, vision, disability and life insurance, wellness resources, recognition programs, 401k contribution, and PTO & Holiday pay (all subject to eligibility requirements). Applicable statutory benefits also provided. https://healthesystems.com/careers/ \n \n \n      Anticipated Starting Pay Range\n     \n \n      $98,100\u2014$135,000 USD\n     \n \n \n \n To facilitate working from home, and as a requirement for this role, candidates must provide their own reliable, high speed internet access with sufficient bandwidth to execute all job functions. Company laptop will be provided.", "cleaned_desc": " Recommends and provide guidance regarding Data Integration and database development, T-SQL best practices, and standards to the development team members as needed. \n \n \n Create and propose technical design documentation which includes current and future functionality, database objects affected, specifications, and flows/diagrams to detail the proposed database and/or Data Integration implementation. \n \n \n Has a deep understanding of the business processes and the technology platform that enables it. \n \n \n Translates stakeholder\u2019s requirements into common language that can be adopted for the use with Behavior Driven Development (BDD) or Test Driven Development (TDD). \n \n \n Participates in industry and other professional networks to ensure awareness of industry standards, trends and best practices in order to strengthen organizational and technical knowledge. \n \n \n Provides support for investigating and troubleshooting production issues. \n \n \n Promotes the establishment of group standards and processes. Participates in the Communities of Practice. \n \n   Works continually on improving performance of source code using industry standard methodologies. \n \n \n Helps drive technology direction and choices of technologies by making recommendations based on experience and research. \n \n \n \n \n  Qualifications/Education/Certifications: \n  Bachelor's degree from four-year college or university (in Information Technology or Computer Science preferred), plus five to eight years related experience and/or training; or equivalent combination of education and experience. \n  Knowledge, Skills and Abilities: \n  Prefer experience in Healthcare, PBM and/or ABM, workers\u2019 compensation and/or insurance industry. \n \n Required experience: \n         \n 5+ years SQL Server 2008/2014 \n \n \n 5+ years Data Integration technologies and principles \n Advanced knowledge of T-SQL including complex SQL queries (ex: using various joins and sub-queries) and best practices \n Advanced knowledge of index design and T-SQL performance tuning techniques   Advanced experience integrating data from structured and unstructured formats: flat files, XML, EDI, JSON, EXCEL \n Advanced knowledge and experience in online transactional (OLTP) processing and analytical processing (OLAP) databases and schemas \n Advanced knowledge of Data Warehousing methodologies and concepts \n Experience with TDD / BDD \n \n The following knowledge is not required, but is preferred: \n \n Experience with BI Tools is a plus \n Basic understanding of object oriented programming \n Experience in distributed architectures such as Microservices, SOA, and RESTful APIs \n Continuous Integration \n Cucumber, Gherkin \n Jira \n \n Agile Competency Requirements: \n \n Requires an understanding of the application of Agile development methodology. \n Must be comfortable with change, close collaboration, and have conflict resolution skills. \n Knowledge of or willingness to learn Agile / DevOps values. \n Takes initiative and are passionate about what they do. \n Adaption, Ability & Desire to Learn, Team Oriented - tolerance & helpful, and Quality Focus ", "techs": ["data integration", "database development", "t-sql", "technical design documentation", "flows/diagrams", "behavior driven development (bdd)", "test driven development (tdd)", "industry standards", "troubleshooting", "group standards", "communities of practice", "performance optimization", "healthcare industry", "pbm", "abm", "workers' compensation", "insurance industry", "sql server 2008/2014", "data integration technologies and principles", "index design", "t-sql performance tuning", "structured and unstructured data integration", "flat files", "xml", "edi", "json", "excel", "online transactional processing (oltp)", "analytical processing (olap)", "data warehousing methodologies", "bi tools", "object-oriented programming", "distributed architectures", "microservices", "soa", "restful apis", "continuous integration", "cucumber", "gherkin", "jira", "agile development methodology", "conflict resolution", "agile/devops values."]}, "9ce6a4ba17758148": {"terms": ["data engineer", "machine learning engineer"], "salary_min": 111674.625, "salary_max": 141404.95, "title": "Sr. Data Analytics Engineer", "company": "CoreTrust Purchasing Group", "desc": "At CoreTrust, our mission is to redefine procurement by maximizing value through an efficient on-demand marketplace and community. We envision a prosperous world connected by seamless digital trade and we value building connections, acting nimbly, pioneering exploration, demonstrating fortitude, and driving impact. \n  To support our rapid growth, we're seeking a passionate data analytics professional for our data solutions team. \n  Reporting to the Director of Data you will build our data platform, including developing data models, maintaining a data lake and analytics environment, prepping data integration and analysis. In addition, you will oversee the Analytics Center of Excellence to enable CoreTrust business users to get the most value from our data. \n  The ideal candidate has a great understanding of various data / tech solutions (e.g., data modeling tools, data pipeline, data catalogs, cloud databases) and a record of using them to bring tangible dollar impact. The candidate should be excited to seek out and capitalize on a wide variety of opportunities to use data to create value across the organization. \n \n \n  Responsibilities \n \n Leads data analytics projects to build innovate and highly available solutions while ensuring adherence to budget, schedule, and scope of project \n Mentor other members in the Analytics Center of Excellence (ACE) \n Develop and assist with oversight on the data catalog and data visualization software \n Drive data & analytics solutions from conception to deployment / delivery with clear ROI impact \n Develop and maintain relationships with all relevant business and tech stakeholders and business functions \n Provides input to proposals for assigned projects including project objectives, technologies, systems, information specifications, timelines, and staffing \n Providing timely status updates to affected internal or external customers and stakeholders \n Collects, analyzes, and summarizes information and trends as needed to prepare project status reports \n Assist in developing a culture of data-driven decision-making, including adoption of business intelligence, analysis, and advanced analytics globally \n Performs other related duties as assigned \n \n Qualifications \n \n Bachelor's degree in computer or information science or relevant experience \n 5+ years of relevant experience in a data-driven professional setting \n Thorough understanding of project management principles and planning \n Proficient with, or able to quickly become proficient with, a range of general and specialized applications, software, and hardware used in the organization and the industry \n Proficient with Microsoft Office Suite or related software \n Ability to motivate groups of people to complete a project in a timely manner \n Strong command of databases and SQL \n Proficiency with Python or R, especially for data manipulation and analysis, and ability to build, maintain and deploy sequences of automated processes with these tools \n Ability to assist with the vision of the team (e.g., mission, priorities, engagement model, tooling) \n A record of accomplishment of successfully managing complex cross-functional projects under tight deadlines \n Strong data analytics background \u2013 familiarity with SQL, cloud technologies like Azure and AWS, statistics / machine learning, Snowflake, DBT, Data Visualization Software \n Exceptional communication and presentation skills, particularly in the context of engaging senior management teams \n A successful history of manipulating, processing, and creating value by performing analysis on a variety of datasets \n Build processes supporting data visualizations, data security, data dictionary, data structures, metadata, dependency, and workload management \n \n Benefits \n \n Competitive compensation package \n Free individual employee medical coverage \n Company subsidized dental and vision coverage \n Dollar for dollar 401(k) match up to 6% of your salary with immediate vesting \n Company-paid Short-Term and Long-Term Disability coverage \n Employee Assistance Program to support your wellbeing and mental health \n $1500 annual stipend for undergraduate/graduate college courses; $500 annual stipend for continuing education courses/certifications \n Free snacks and beverages on-site \n Brand new, state-of-the-art, tech-enabled work environment in downtown Nashville \n Flexible/hybrid work culture", "cleaned_desc": "At CoreTrust, our mission is to redefine procurement by maximizing value through an efficient on-demand marketplace and community. We envision a prosperous world connected by seamless digital trade and we value building connections, acting nimbly, pioneering exploration, demonstrating fortitude, and driving impact. \n  To support our rapid growth, we're seeking a passionate data analytics professional for our data solutions team. \n  Reporting to the Director of Data you will build our data platform, including developing data models, maintaining a data lake and analytics environment, prepping data integration and analysis. In addition, you will oversee the Analytics Center of Excellence to enable CoreTrust business users to get the most value from our data. \n  The ideal candidate has a great understanding of various data / tech solutions (e.g., data modeling tools, data pipeline, data catalogs, cloud databases) and a record of using them to bring tangible dollar impact. The candidate should be excited to seek out and capitalize on a wide variety of opportunities to use data to create value across the organization. \n \n \n  Responsibilities \n \n Leads data analytics projects to build innovate and highly available solutions while ensuring adherence to budget, schedule, and scope of project   \n Qualifications \n \n Bachelor's degree in computer or information science or relevant experience \n 5+ years of relevant experience in a data-driven professional setting \n Thorough understanding of project management principles and planning \n Proficient with, or able to quickly become proficient with, a range of general and specialized applications, software, and hardware used in the organization and the industry \n Proficient with Microsoft Office Suite or related software \n Ability to motivate groups of people to complete a project in a timely manner   Strong command of databases and SQL \n Proficiency with Python or R, especially for data manipulation and analysis, and ability to build, maintain and deploy sequences of automated processes with these tools \n Ability to assist with the vision of the team (e.g., mission, priorities, engagement model, tooling) \n A record of accomplishment of successfully managing complex cross-functional projects under tight deadlines \n Strong data analytics background \u2013 familiarity with SQL, cloud technologies like Azure and AWS, statistics / machine learning, Snowflake, DBT, Data Visualization Software \n Exceptional communication and presentation skills, particularly in the context of engaging senior management teams \n A successful history of manipulating, processing, and creating value by performing analysis on a variety of datasets \n Build processes supporting data visualizations, data security, data dictionary, data structures, metadata, dependency, and workload management \n ", "techs": ["data modeling tools", "data pipeline", "data catalogs", "cloud databases", "databases", "sql", "microsoft office suite", "python", "r", "statistics", "machine learning", "snowflake", "dbt", "data visualization software"]}, "6b623a7d96d0b886": {"terms": ["data engineer"], "salary_min": 129731.945, "salary_max": 164269.55, "title": "STAFF SOFTWARE ENGINEER, DATA", "company": "UniGroup", "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com", "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ", "techs": ["data modeling", "data mining techniques", "programming languages (python", "javascript/typescript)", "relational sql databases (postgres)", "nosql databases (mongodb)", "cloud environments (microservices", "aws", "docker", "kubernetes)", "git", "gitlab", "github", "sql database design", "big data tools (kafka)", "data pipeline and workflow management tools", "numerical skills", "analytical skills"]}, "d1f93054c6711053": {"terms": ["data engineer"], "salary_min": 133742.28, "salary_max": 169347.53, "title": "Data Engineer TS/SCI", "company": "Cyberjin", "desc": "Hybrid/Remote role \n  Looking for a talented Data Engineer to support the acquisition of mission critical and mission support data sets. The preferred candidate will have a background in supporting cyber and/or network related missions within the military spaces, as either a developer, analyst or engineer. Work is mostly on customer site in San Antonio, TX with some hybrid support. \n \n  Essential Job Responsibilities \n  The ideal candidate will have worked with big data systems, complex structured and unstructured data sets, and have supported government data acquisition, analysis, and/or sharing efforts in the past.  \n To excel in the position, the candidate shall have a strong attention to detail, be able to understand technical complexities, and have the willingness to learn and adapt to the situation.  \n The candidate will work both independently and as part of a large team to accomplish client objectives.  \n Minimum Qualifications \n  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata. \n  Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). \n  Ability to decompose technical problems and troubleshoot system and dataflow issues. \n  Must be able to work on customer site most of the time. \n  Preferred Requirements \n  Experience with NOSQL databases such as Accumulo desired \n  Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer. \n   \n EeR9txiKzg", "cleaned_desc": "  Security Clearance - Must have a current TS/SCI level security clearance and therefore all candidates must be a U.S. Citizen.  \n 5 years experience as a developer, analyst, or engineer with a Bachelors in related field; OR 3 years relevant experience with Masters in related field; OR High School Diploma or equivalent and 9 years relevant experience. \n  Experience with programming languages such as Python and Java. \n  Proficiency with acquisition and understanding of network data and the associated metadata.    Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics. \n  Experience with Kibana and Elasticsearch. \n  Familiarity with various log formats such as JSON, XML, and others. \n  Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions). ", "techs": ["security clearance", "ts/sci level security clearance", "u.s. citizen", "python", "java", "acquisition", "network data", "metadata", "data extraction", "translation", "loading", "data prep", "data labeling", "data analytics", "kibana", "elasticsearch", "log formats", "json", "xml", "data flow", "management", "storage solutions", "kafka", "nifi", "aws s3", "sqs solutions"]}, "572740213d573088": {"terms": ["data engineer"], "salary_min": 130456.03, "salary_max": 165186.4, "title": "STAFF SOFTWARE ENGINEER, DATA", "company": "UniGroup", "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com", "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ", "techs": ["data modelling", "data mining techniques", "python", "javascript/typescript", "relational sql", "nosql databases", "postgres", "mongodb", "cloud environments", "microservices", "aws", "docker", "kubernetes", "git", "gitlab", "github", "sql database design", "big data tools", "kafka", "data pipeline", "workflow management tools", "numerical skills", "analytical skills"]}, "db610c07e527b1a0": {"terms": ["data engineer"], "salary_min": 110707.19, "salary_max": 140179.97, "title": "Senior AWS Data Engineer", "company": "Cognitive Medical Systems", "desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift. \n  Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing. \n  Troubleshooting and maintenance of the data warehouse. \n  Performs design and implementation of IT systems that require the integration of diverse and complex components. Activities include defining operational requirements including integration with other systems or components, researching and modeling the system architecture and configuration, investigating alternatives and decision analysis. \n  Provides specific, detailed information for selection, implementation techniques, and tools for the most efficient solution to meet business needs, including present and future capacity requirements, identity management, access management, and automation. \n  Exercises judgment in selecting methods and techniques for obtaining results. \n \n  Requirements \n \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems. \n  Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n \n  Strong communication skills \n  Experience in design, development and deployment of dashboards, visualization and reporting using Power BI or Tableau reporting platforms. \n  AWS certified.", "cleaned_desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift.    Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing.   \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems.    Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n ", "techs": ["glue", "lambda", "redshift", "s3", "python", "scala", "spark", "oracle rds", "pl/sql"]}, "79cd8286f4bdc268": {"terms": ["data engineer"], "salary_min": 114812.83, "salary_max": 145378.62, "title": "Senior AWS Data Engineer", "company": "Cognitive Medical Systems", "desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift. \n  Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing. \n  Troubleshooting and maintenance of the data warehouse. \n  Performs design and implementation of IT systems that require the integration of diverse and complex components. Activities include defining operational requirements including integration with other systems or components, researching and modeling the system architecture and configuration, investigating alternatives and decision analysis. \n  Provides specific, detailed information for selection, implementation techniques, and tools for the most efficient solution to meet business needs, including present and future capacity requirements, identity management, access management, and automation. \n  Exercises judgment in selecting methods and techniques for obtaining results. \n \n  Requirements \n \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems. \n  Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n \n  Strong communication skills \n  Experience in design, development and deployment of dashboards, visualization and reporting using Power BI or Tableau reporting platforms. \n  AWS certified.", "cleaned_desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift.    Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing.   \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems.    Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n ", "techs": ["glue", "lambda", "redshift", "s3", "python", "scala", "spark", "json", "oracle rds", "data flow diagrams", "bi applications", "analytical reporting tools", "etl/elt", "oracle pl/sql"]}, "b237a302263bf703": {"terms": ["data engineer"], "salary_min": 45.0, "salary_max": 55.0, "title": "data engineer (ssis, sql, teradata - talend/snowflake) | remote", "company": "Randstad", "desc": "summary \n \n \n \n \n \n       $45 - $55 per hour\n      \n \n \n \n \n         temp to perm\n        \n \n \n \n \n       bachelor degree\n      \n \n \n \n \n \n \n \n \n      category\n      computer and mathematical occupations\n    \n \n \n      reference\n      1029678\n    \n \n \n \n \n \n job summary:\n   Summary:\n   Develops and operationalizes data pipelines to make data available for consumption (reports and advanced analytics), including data ingestion, data transformation, data validation / quality, data pipeline optimization, and orchestration. Engages with the DevSecOps Engineer during continuous integration and continuous deployment.\n  \n \n       \n Education and Experience:\n   A Bachelor's degree in a quantitative or business field (e.g., statistics, mathematics, engineering, computer science).. Requires 2 - 4 years of related experience.\n  \n \n       \n Essential Functions:\n   Designs and implements standardized data management procedures around data staging, data ingestion, data preparation, data provisioning, and data destruction (scripts, programs, automation, assisted by automation, etc.). Designs, develops, implements, tests, documents, and operates large-scale, high-volume, high-performance data structures for business intelligence analytics. Designs, develops, and maintains real-time processing applications and real-time data pipelines. Ensure quality of technical solutions as data moves across Client's environments\n  \n \n       Provides insight into the changing data environment, data processing, data storage, and utilization requirements for the company and offers suggestions for solutions. Develops, constructs, tests, and maintains architectures using programming language and tools. Identifies ways to improve data reliability, efficiency, and quality; use data to discover tasks that can be automated \n  \n  location: Detroit, Michigan\n   job type: Contract\n   salary: $45 - 55 per hour\n   work hours: 8am to 5pm\n   education: Bachelors\n  \n  responsibilities:\n   Develops and operationalizes data pipelines to make data available for consumption (reports and advanced analytics), including data ingestion, data transformation, data validation / quality, data pipeline optimization, and orchestration. Engages with the DevSecOps Engineer during continuous integration and continuous deployment.\n  \n \n       \n \n  qualifications:\n  \n \n Experience level: Experienced  Minimum 4 years of experience \n    Education: Bachelors \n \n  skills: \n  \n SQL \n  SSIS    Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.    At Randstad Digital, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.    Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).", "cleaned_desc": "    \n \n \n      reference\n      1029678\n    \n \n \n \n \n \n job summary:\n   Summary:\n   Develops and operationalizes data pipelines to make data available for consumption (reports and advanced analytics), including data ingestion, data transformation, data validation / quality, data pipeline optimization, and orchestration. Engages with the DevSecOps Engineer during continuous integration and continuous deployment.\n    \n       \n Education and Experience:\n   A Bachelor's degree in a quantitative or business field (e.g., statistics, mathematics, engineering, computer science).. Requires 2 - 4 years of related experience.\n  \n \n       \n Essential Functions:\n   Designs and implements standardized data management procedures around data staging, data ingestion, data preparation, data provisioning, and data destruction (scripts, programs, automation, assisted by automation, etc.). Designs, develops, implements, tests, documents, and operates large-scale, high-volume, high-performance data structures for business intelligence analytics. Designs, develops, and maintains real-time processing applications and real-time data pipelines. Ensure quality of technical solutions as data moves across Client's environments\n  \n \n       Provides insight into the changing data environment, data processing, data storage, and utilization requirements for the company and offers suggestions for solutions. Develops, constructs, tests, and maintains architectures using programming language and tools. Identifies ways to improve data reliability, efficiency, and quality; use data to discover tasks that can be automated \n  \n  location: Detroit, Michigan\n   job type: Contract", "techs": ["data pipelines", "data ingestion", "data transformation", "data validation", "data quality", "data pipeline optimization", "orchestration", "devsecops engineer", "data management procedures", "data staging", "data preparation", "data provisioning", "data destruction", "large-scale", "high-volume", "high-performance data structures", "business intelligence analytics", "real-time processing applications", "real-time data pipelines", "programming language", "data reliability", "data efficiency", "data quality", "automation"]}, "0315cabfeff7ad5d": {"terms": ["data engineer"], "salary_min": 112025.37, "salary_max": 141849.08, "title": "Senior AWS Data Engineer", "company": "Cognitive Medical Systems", "desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift. \n  Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing. \n  Troubleshooting and maintenance of the data warehouse. \n  Performs design and implementation of IT systems that require the integration of diverse and complex components. Activities include defining operational requirements including integration with other systems or components, researching and modeling the system architecture and configuration, investigating alternatives and decision analysis. \n  Provides specific, detailed information for selection, implementation techniques, and tools for the most efficient solution to meet business needs, including present and future capacity requirements, identity management, access management, and automation. \n  Exercises judgment in selecting methods and techniques for obtaining results. \n \n  Requirements \n \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems. \n  Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n \n  Strong communication skills \n  Experience in design, development and deployment of dashboards, visualization and reporting using Power BI or Tableau reporting platforms. \n  AWS certified.", "cleaned_desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift.    Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing.   \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems.    Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n ", "techs": ["glue", "lambda", "redshift", "s3", "python", "scala", "spark", "oracle rds", "data flow diagrams", "bi applications", "analytical reporting tools", "etl/elt solutions", "oracle pl/sql", "agile methodology"]}, "ff845e5c07d0ce47": {"terms": ["data engineer"], "salary_min": 127986.02, "salary_max": 162058.83, "title": "STAFF SOFTWARE ENGINEER, DATA", "company": "UniGroup", "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com", "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ", "techs": ["data modelling", "data mining techniques", "python", "javascript", "typescript", "relational sql databases", "nosql databases", "postgres", "mongodb", "cloud environments", "microservices", "aws", "docker", "kubernetes", "git", "gitlab", "github", "sql database design", "big data tools", "kafka", "data pipeline management tools", "workflow management tools", "numerical skills", "analytical skills"]}, "1c7fde811ae29dd0": {"terms": ["data engineer"], "salary_min": 112025.37, "salary_max": 141849.08, "title": "Senior AWS Data Engineer", "company": "Cognitive Medical Systems", "desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift. \n  Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing. \n  Troubleshooting and maintenance of the data warehouse. \n  Performs design and implementation of IT systems that require the integration of diverse and complex components. Activities include defining operational requirements including integration with other systems or components, researching and modeling the system architecture and configuration, investigating alternatives and decision analysis. \n  Provides specific, detailed information for selection, implementation techniques, and tools for the most efficient solution to meet business needs, including present and future capacity requirements, identity management, access management, and automation. \n  Exercises judgment in selecting methods and techniques for obtaining results. \n \n  Requirements \n \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems. \n  Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n \n  Strong communication skills \n  Experience in design, development and deployment of dashboards, visualization and reporting using Power BI or Tableau reporting platforms. \n  AWS certified.", "cleaned_desc": "Cognitive Medical Systems is seeking a Senior AWS Data Engineer to fill a role on its Human Capital Management (HCM) Product Line\u2019s (PL) Data Warehouse Delivery Team on the VA T4NG Consolidated Corporate Support Services (CCSS) program serving our Department of Veterans Affairs Corporate Portfolio clients across the entire U.S. CCSS. \n  Position Summary \n  Strong AWS hands-on experience in data warehousing using services like Glue, Lambda, Redshift, S3, Python, Scala, and Spark. Familiar with ETL and data warehouse concepts and techniques. \n  Duties: \n \n  Work on AWS Data pipeline to configure data loads from S3 to Redshift.    Will use JSON schema to define tables and column mapping from S3 to Redshift. \n  Extract data from multiple data sources into AWS Redshift. \n  Transform data using Python, Lambda, and Glue. \n  Load data into staging and data warehouse, and fact and dimension tables. \n  Write stored procedures for loading data and orchestration. \n  Perform unit testing, integration testing, and performance testing.   \n  5+ years of hands-on experience working with Redshift. \n  Extensive experience developing solutions using Spark/PySpark, Scala, Python, and AWS services such as Lambda, Redshift, Glue, Oracle RDS and S3. \n  Strong experience developing data warehouse solutions in the AWS cloud. \n  Hands-on experience in data modeling and design, data flow diagrams, data warehousing and BI applications and analytical reporting tools and technique. \n  Strong experience developing ETL/ELT solutions in support of data warehouse systems.    Proven experience using Oracle PL/SQL. \n  Experience performance tuning of data warehouse and reporting. \n  Experience with AGILE methodology. \n \n  Preferred Skills: \n ", "techs": ["glue", "lambda", "redshift", "s3", "python", "scala", "spark", "oracle rds", "agile"]}, "7bd6877cd31531f2": {"terms": ["data engineer"], "salary_min": 0.0, "salary_max": 60.0, "title": "Data integration Engineer (.Net)", "company": "Source Select Group, LLC", "desc": "We are seeking someone who has experience in creating and maintaining system data migration tools, is self-starter and quick learner . \n The focus will be enhancing and maintaining tools used to migrate our client\u2019s data to our new products. This tool is based on C# , .net , SQL and SSIS. \n Skills/Competencies: (List specific skills/specialties in order of importance) \n \u00b7 Experience in Tools to support Data Migration from one or more Source(s) to Destination with application of transformation rules \n \u00b7 Experience in System Data Migrations \n \u00b7 Advanced to Expert skills, using a variety of software development technologies including, but not limited to SQL (T-SQL, SSIS, SSRS, SSAS) \n \u00b7 Desired Skills C#, .NET \n \u00b7 Effective Communication skills, both written and verbal \n Education, prior work experience: \n \u00b7 Bachelor's degree \n \u00b7 8+ years Working experience in data related development field or Technology Consulting \n Job Types: Contract, Full-time \n Pay: Up to $60.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n We are unable to work with candidates that work thru a Vendor or 3rd Party.  \n \n All ELIGIBLE candidates must work on our W2 and must be authorized to work in the USA without sponsorship now or in the future. \n Do you meet this requirement? \n Work Location: Remote", "cleaned_desc": "We are seeking someone who has experience in creating and maintaining system data migration tools, is self-starter and quick learner . \n The focus will be enhancing and maintaining tools used to migrate our client\u2019s data to our new products. This tool is based on C# , .net , SQL and SSIS. \n Skills/Competencies: (List specific skills/specialties in order of importance) \n \u00b7 Experience in Tools to support Data Migration from one or more Source(s) to Destination with application of transformation rules \n \u00b7 Experience in System Data Migrations \n \u00b7 Advanced to Expert skills, using a variety of software development technologies including, but not limited to SQL (T-SQL, SSIS, SSRS, SSAS) ", "techs": ["c#", ".net", "sql", "ssis", "t-sql", "ssrs", "ssas"]}, "8b13ea51f9449952": {"terms": ["machine learning engineer"], "salary_min": 86611.0, "salary_max": 133682.0, "title": "Software Engineer - Remote", "company": "Mayo Clinic", "desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  This is a full time remote position within the United States. \n  The Cardiology department requires a Software Engineer to work closely with the business on cloud computing platform development, modern technology solutions and frameworks. This role will work with the business to support the critical in house developed systems including EIMS and will help advance several Cardiology projects and initiatives. The Software Engineer will develop and provide support for a portfolio of in-house developed applications that will develop scalable, data centric solutions, resolve problems, produce appropriate documentation, and source code for the Cardiology Systems unit. \n  Mayo Clinic is seeking a Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients.  Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction. \n  Mayo Clinic will not sponsor or transfer visas for this position including F1 OPT STEM. \n  Qualifications \n \n \n   Bachelor's Degree in Computer Science/Engineering or related field; Or an Associates\u2019 degree in Computer Science/Engineering or related field with an additional 2 years of experience as described below.\n   \n \n \n Have working knowledge and experience of Software Engineering with a minimum of internships and a minimum of 1 yr. of experience, or 2yrs of experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.). \n Demonstrated problem solving and time management skills. \n Possesses strong technical aptitude for designing and implementing software solutions. \n Experience with modern application development frameworks \n Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. \n Deep hands-on technical expertise, excellent verbal and written communication skills. \n Experience with Agile software development techniques. \n  Preferred qualifications for this position include:\n   \n \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience with Google and Azure cloud environments \n Experience in databases, analytics, big data systems or business intelligence products \n Experience with building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n \n \n  Exemption Status \n \n  Exempt\n  \n \n Compensation Detail \n \n  $86,611 - $133,682 / year\n  \n \n Schedule \n \n  Full Time\n  \n \n Hours/Pay Period \n \n  80\n  \n \n Schedule Details \n \n  Monday - Friday, 8am - 5pm\n  \n \n Weekend Schedule \n \n  As needed\n  \n \n International Assignment \n \n  No\n  \n \n Site Description \n \n \n  Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.\n   \n \n \n \n \n Affirmative Action and Equal Opportunity Employer \n \n \n  As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.\n    \n \n \n \n \n Recruiter \n \n  Ted Keefe", "cleaned_desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  This is a full time remote position within the United States. \n  The Cardiology department requires a Software Engineer to work closely with the business on cloud computing platform development, modern technology solutions and frameworks. This role will work with the business to support the critical in house developed systems including EIMS and will help advance several Cardiology projects and initiatives. The Software Engineer will develop and provide support for a portfolio of in-house developed applications that will develop scalable, data centric solutions, resolve problems, produce appropriate documentation, and source code for the Cardiology Systems unit. \n  Mayo Clinic is seeking a Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients.  Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction. \n  Mayo Clinic will not sponsor or transfer visas for this position including F1 OPT STEM. \n  Qualifications \n \n \n   Bachelor's Degree in Computer Science/Engineering or related field; Or an Associates\u2019 degree in Computer Science/Engineering or related field with an additional 2 years of experience as described below.\n     \n \n Have working knowledge and experience of Software Engineering with a minimum of internships and a minimum of 1 yr. of experience, or 2yrs of experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.). \n Demonstrated problem solving and time management skills. \n Possesses strong technical aptitude for designing and implementing software solutions. \n Experience with modern application development frameworks \n Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. \n Deep hands-on technical expertise, excellent verbal and written communication skills. \n Experience with Agile software development techniques. \n  Preferred qualifications for this position include:\n   \n \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience with Google and Azure cloud environments \n Experience in databases, analytics, big data systems or business intelligence products \n Experience with building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n ", "techs": ["mayo clinic", "u.s. news & world report", "cloud computing", "eims", "software engineer", "data-centric applications", "big data", "mobile", "data science", "data warehousing", "machine learning", "software development applications", "micro-services", "uptime", "accuracy", "resilience", "data engineering", "platform", "solutions teams", "product owners", "product managers", "architects", "requirements", "code", "data warehousing", "business intelligence", "analytics", "machine learning", "devops", "agile", "continuous development", "integration frameworks", "go", "python", "java", "deployment automation", "configuration management", "ado", "puppet", "chef", "ansible", "azure pipelines", "cloudformation", "terraform", "root cause analysis", "organization", "processes", "customers", "f1 opt stem", "bachelor's degree in computer science/engineering", "associates\u2019 degree in computer science/engineering", "working knowledge", "experience", "internships", "problem solving", "time management", "technical aptitude", "application development frameworks", "professional software engineering practices", "coding standards", "code reviews", "source control management", "build processes", "testing", "operations", "open-source technologies", "google cloud", "azure cloud", "databases", "analytics", "big data systems", "business intelligence products", "high-performance systems", "healthcare related industries"]}, "5704fe70eb6f1872": {"terms": ["machine learning engineer"], "salary_min": 106889.875, "salary_max": 135346.4, "title": "Software Engineer - Full Stack", "company": "Sun Automation", "desc": "Software Engineer - Full Stack \n \n \n \n \n SUN Automation is looking for a seasoned full-stack engineer to join our collaborative, agile team to assist with building our industry changing IIOT machine learning platform for the corrugated industry. You should be a team-oriented, creative coder with excellent written and verbal communication skills. Experience with both UI and backend coding required, although equal strength in each is not as important as strong skills on one side and willingness to learn and contribute on the other. \n RESPONSIBILITIES \n \n Implementation of user interface \n Construction of RESTful API(s) and Elixir components \n Participate in the pull request/feedback process as well as technical discussions and other team meetings such as estimation and planning sessions \n Pair with other team members \n Write meaningful unit and integration tests \n Ensure applications are built for speed and scalability \n Demonstrate initiative in improving the quality of our code and your own skills \n \n QUALIFICATIONS \n \n Bachelor's degree in Computer Science or related discipline \n Three or more years as an engineer, with outstanding technical ability \n Experience in a wide range of technologies including Elixir, React JS, AWS Services particularly as they relate to IIOT and machine learning, Terraform \n Strong operational experience, ideally in a 34x7 SaaS environment \n Strong communication and collaboration skills \n Self-directed and self-managed work style \n Comfortable with a range of work from fast proof of concept to careful contributions in risk averse problem domains \n \n \n  In business for 38 years, SUN is a recognized leader within the corrugated industry, is 100% employee owned and has an outstanding culture. Be sure to visit our website for more information.", "cleaned_desc": " SUN Automation is looking for a seasoned full-stack engineer to join our collaborative, agile team to assist with building our industry changing IIOT machine learning platform for the corrugated industry. You should be a team-oriented, creative coder with excellent written and verbal communication skills. Experience with both UI and backend coding required, although equal strength in each is not as important as strong skills on one side and willingness to learn and contribute on the other. \n RESPONSIBILITIES \n \n Implementation of user interface \n Construction of RESTful API(s) and Elixir components ", "techs": ["elixir"]}, "e1c489ad45a58bb0": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "UBA Engineer- SIEM", "company": "Thrivent", "desc": "As an Engineer you will create and/or modify solutions to complex software problems. This includes coding, testing, debugging, documenting, and maintaining those solutions. You will participate in leading smaller engineering efforts as well as contributing to larger, enterprise-wide initiatives. The Engineering teams are challenged to partner across departments and divisions to achieve the best outcomes for our customers. \n  \n  At Thrivent, we are focused on a digital transformation that will deliver modern, innovative experiences for our clients, financial advisors, and employees. We are investing in data and technology, using DevOps practices, and building an engineering culture of empowered technical experts. Our technologists are involved in work that includes cloud native development, digital architecture and integration, automation, cloud data platforms, artificial intelligence, and machine learning as well as maximizing platforms such as Salesforce, AWS and Microsoft. \n  \n \n SPECIFIC DUTIES & RESPONSIBILITIES:   \n \n \n \n Monitor and maintain health of SIEM (Sentinel) infrastructure  \n \n \n \n \n \n \n Assist in data parsing and normalization, leveraging advanced knowledge of regular expressions  \n Upgrade assigned applications and operating systems (Windows, Linux)  \n Troubleshoot errors and/or performance issues with Windows and Linux systems  \n Develop scripts (Python, bash, PowerShell, etc) to assist in accomplishing assigned tasks  \n \n \n \n \n GENERAL DUTIES & RESPONSIBILITIES:   \n \n \n \n Designing Solutions   \n \n \n \n Apply technical knowledge to drive outcomes for customers  \n Ability to work and problem solve independently on initiatives that align to the broader software engineering strategy  \n Proficient at designing solutions within core framework of software products within this team  \n Ability to set up and configure Sentinel environments, create custom detection rules, and work with incident management.  \n \n \n \n \n \n Designing Software   \n \n \n \n Use independent, critical thinking to solve complex problems which are significant to the customer.  \n Consistent and dependable in delivering core software that delivers outcomes and meets/exceeds the teams expectations for stability, scalability, resilience, etc.  \n \n \n \n Learning and Applying New Techniques   \n \n \n \n \n \n Seek out opportunities to learn new technologies that improve the product and its lifecycle.  \n \n \n \n Collaborating within the Team   \n \n \n \n Participate in team\u2019s collaboration sessions to provide technical expertise to solve a problem/remove technical roadblocks for the team  \n Participate in product planning and implementation. Helps team to understand and decompose work \"  \n \n \n \n DevOps   \n \n \n \n \n \n Participates in the team support rotation and builds knowledge on focus subsystems.\"  \n \n \n \n Recruiting/Building Talent   \n \n \n \n \n \n Participate in the interview process or be part of the panel to recruit the right talent to the team  \n Models Thrivent\u2019s leadership competencies \u2013 courage, collaboration, and commitment by demonstrating resiliency, working together to make the best decisions, and holding yourself and others accountable.  \n Supports and/or develops an environment in which Thrivent employees and colleagues are focused on continuous improvement, exceptional employee engagement, and an unwavering commitment to our clients. Shapes and/or supports a culture that represents the Thrivent purpose, promise and values, ensuring that Thrivent\u2019s trust and reputation remain strong with its clients.  \n Perform other related duties as required.  \n \n \n \n QUALIFICATIONS & SKILLS:   \n \n \n \n \n Required:   \n \n \n \n Bachelor's degree in Computer Science or other technical field or equivalent work experience  \n 1 to 2 years of Engineering experience  \n Knowledge of industry standard Software Development Life Cycle (SDLC) practices  \n \n \n \n \n \n Knowledge of systems design concepts that provide security and stability  \n Ability to debug code and/or complex log files for troubleshooting and analysis of product defects  \n Sound understanding of application engineering concepts  \n Knowledge/experience with querying databases for data lookup/update  \n \n \n \n \n \n A strong understanding of Microsoft Azure services,networking, and security features  \n In-depth knowledge of Microsoft Sentinel, including its architecture, data connectors, query language (KQL - Kusto Query Language), and alerting capabilities  \n Proficiency in MS Log Analytics  \n Understanding of user behavior analytics concepts, such as anomaly detection, baselining, and behavioral profiling  \n Scripting skills in PowerShell and familiarity with Azure CLI  \n \n \n \n \n \n \n Proficiency in programming languages like Python, JavaScript, or C#   \n \n \n \n \n Preferred:   \n \n \n \n Understanding Azure AD and its integration with Microsoft Sentinel  \n A strong foundation in cybersecurity principles, threat detection, incident response, and security best practice  \n \n \n \n \n \n Familiarity with data integration techniques, such as using Azure Data Factory or Azure Logic Apps  \n Knowledge of machine learning concepts and tools  \n Microsoft Certified: Azure Security Engineer Associate  \n Certified Information Systems Security Professional (CISSP)  \n \n We exist to help people achieve financial clarity. At Thrivent, we believe money is a tool, not a goal. Driven by a higher purpose at our core, we are committed to providing financial advice, investments, insurance, banking and generosity programs to help people make the most of all they\u2019ve been given.  \n At our heart, we are a membership-owned fraternal organization, as well as a holistic financial services organization, dedicated to serving the unique needs of our clients. We focus on their goals and priorities, guiding them toward financial choices that will help them live the life they want today\u2014and tomorrow.  \n \n \n \n Thrivent provides Equal Employment Opportunity (EEO) without regard to race, religion, color,  sex, gender identity, sexual orientation, pregnancy, national origin, age, disability, marital status, citizenship status, military or veteran status, genetic information, or any other status protected by applicable local, state, or federal law. This policy applies to all employees and job applicants.  \n Thrivent is committed to providing reasonable accommodation to individuals with disabilities. If you need a reasonable accommodation, please let us know by sending an email to  human.resources@thrivent.com  or call 800-847-4836 and request Human Resources.", "cleaned_desc": "As an Engineer you will create and/or modify solutions to complex software problems. This includes coding, testing, debugging, documenting, and maintaining those solutions. You will participate in leading smaller engineering efforts as well as contributing to larger, enterprise-wide initiatives. The Engineering teams are challenged to partner across departments and divisions to achieve the best outcomes for our customers. \n  \n  At Thrivent, we are focused on a digital transformation that will deliver modern, innovative experiences for our clients, financial advisors, and employees. We are investing in data and technology, using DevOps practices, and building an engineering culture of empowered technical experts. Our technologists are involved in work that includes cloud native development, digital architecture and integration, automation, cloud data platforms, artificial intelligence, and machine learning as well as maximizing platforms such as Salesforce, AWS and Microsoft. \n  \n \n SPECIFIC DUTIES & RESPONSIBILITIES:   \n \n \n \n Monitor and maintain health of SIEM (Sentinel) infrastructure  \n \n \n \n \n \n \n Assist in data parsing and normalization, leveraging advanced knowledge of regular expressions  \n Upgrade assigned applications and operating systems (Windows, Linux)  \n Troubleshoot errors and/or performance issues with Windows and Linux systems  \n Develop scripts (Python, bash, PowerShell, etc) to assist in accomplishing assigned tasks  \n \n \n \n \n GENERAL DUTIES & RESPONSIBILITIES:   \n \n \n \n Designing Solutions   \n \n   \n \n \n \n Required:   \n \n \n \n Bachelor's degree in Computer Science or other technical field or equivalent work experience  \n 1 to 2 years of Engineering experience  \n Knowledge of industry standard Software Development Life Cycle (SDLC) practices  \n \n \n \n \n \n Knowledge of systems design concepts that provide security and stability  \n Ability to debug code and/or complex log files for troubleshooting and analysis of product defects  \n Sound understanding of application engineering concepts  \n Knowledge/experience with querying databases for data lookup/update  \n \n \n \n \n \n A strong understanding of Microsoft Azure services,networking, and security features  \n In-depth knowledge of Microsoft Sentinel, including its architecture, data connectors, query language (KQL - Kusto Query Language), and alerting capabilities  \n Proficiency in MS Log Analytics  \n Understanding of user behavior analytics concepts, such as anomaly detection, baselining, and behavioral profiling  \n Scripting skills in PowerShell and familiarity with Azure CLI  \n ", "techs": ["siem (sentinel)", "regular expressions", "python", "bash", "powershell", "windows", "linux", "microsoft azure", "microsoft sentinel", "kql (kusto query language)", "ms log analytics", "powershell", "azure cli"]}, "20e26cde82b1af99": {"terms": ["machine learning engineer"], "salary_min": 89338.77, "salary_max": 113122.79, "title": "Senior Firmware Engineer - Bare Metal Development - Remote Option", "company": "Milwaukee Electric Tool Corporation", "desc": "Sr Firmware Engineer\n  \n   Job Description:\n  \n \n \n   INNOVATE WITHOUT BOUNDARIES! At Milwaukee Tool we firmly believe that our People and our Culture are the secrets to our success \u2013 so we give you unlimited access to everything you need to create disruptive new technologies and solutions on our electrical engineering teams. Our Engineering Team is responsible for giving life to the batteries, motors, and electronics that power solutions changing the lives of our users. Every developmental phase of these critical components happens in-house under the watch of this team. We continue to invest in electrical engineering resources to design and develop leadership in electronic capabilities; something unique within the industry. And we\u2019re pushing the limits in firmware engineering, power electronics, embedded systems, machine learning, and the use of artificial intelligence.\n  \n \n \n   Behind our doors you\u2019ll be empowered every day to own it, drive it, and do what it takes to design and develop the biggest breakthroughs in the industry. Meanwhile, you\u2019ll have the support and resources of the fastest-growing brand in the construction industry to make it happen.\n  \n \n \n   Year after year, our team continues to make significant breakthroughs in the industry. We\u2019re just getting started. To learn more about our story click \n   \n   HERE\n   .\n  \n \n \n   The Sr. Firmware Engineer will be a technical lead the design of new firmware architectures, applications, components, and libraries to ensure on-time delivery and requirements are met. You will interface with cross-functional teams to understand system design requirements and translate them into embedded requirements.\n  \n \n \n   You\u2019ll also be DISRUPTIVE through these duties and responsibilities:\n  \n \n  Leading the design, development, testing, and troubleshooting of real-time, bare-metal firmware and embedded systems. \n  Develop and refine engineering requirements based on marketing and user needs. \n  Lead design and implementation of embedded software systems using modern software engineering processes. \n  Peer-review software designs and source code. \n  Establish and execute test procedures for software applications and subsystems. \n  Analyze and enhance efficiency, stability, and scalability of system resources. \n  Lead agile project teams through the new product development process. \n  Provide candid and effective communications up, down and across the organization on progress, barrier removal and escalation of business risks/opportunities. \n  Demonstrate Milwaukee Tools Culture of high performance and agility by independently creating Work Breakdown Structure for your work and driving to critical milestones. \n  Drive urgency in project schedules and accountability for establishing and achieving key project metrics that meet the organization\u2019s needs. \n  Serve as a role model Milwaukee Tool\u2019s culture while mentoring, guiding, and coaching junior Engineers. \n  Use laboratory equipment such as oscilloscopes, power supplies, e-loads, and data acquisition systems. \n  Independently track projects to ensure adherence to schedule and the Milwaukee process. \n \n \n \n   What TOOLS you\u2019ll bring with you:\n  \n \n  Bachelor of Science degree in Computer Engineering, Computer Science, Electrical Engineering, or related field. \n  5+ years of experience with embedded C/C++. \n  Experience developing bare-metal firmware designs. \n  Experience with DevOps, automated testing, continuous integration/continuous deployment (CI/CD). \n  Knowledge and practical experience in all software development lifecycle phases. \n  Experience with a microcontroller RTOS. \n  Familiarity with software configuration management tools, defect tracking tools, and peer reviews. \n  Ability to read schematics and component data sheets, basic understanding of digital circuits and interaction between firmware and electronics. \n  Demonstrated ability using laboratory equipment such as oscilloscopes, logic analyzers, power supplies, e-loads, and data acquisition systems. \n  Excellent problem-solving skills, exercises independent judgement and works well under pressure in a dynamic environment. \n  Ability to travel 10% of the time (domestic and international). \n \n \n \n   Other TOOLS we prefer you to have:\n  \n \n  Master\u2019s degree in computer engineering, Computer Science, Electrical Engineering, or related field. \n  Leadership or project management experience. \n \n \n \n   We provide these great perks and benefits:\n  \n \n  Robust health, dental and vision insurance plans. \n  Generous 401 (K) savings plan. \n  Education assistance. \n  On-site wellness, fitness center, food, and coffee service. \n  And many more, check out our benefits site \n    \n    HERE\n    .", "cleaned_desc": "  Lead design and implementation of embedded software systems using modern software engineering processes. \n  Peer-review software designs and source code. \n  Establish and execute test procedures for software applications and subsystems. \n  Analyze and enhance efficiency, stability, and scalability of system resources. \n  Lead agile project teams through the new product development process. \n  Provide candid and effective communications up, down and across the organization on progress, barrier removal and escalation of business risks/opportunities. \n  Demonstrate Milwaukee Tools Culture of high performance and agility by independently creating Work Breakdown Structure for your work and driving to critical milestones. \n  Drive urgency in project schedules and accountability for establishing and achieving key project metrics that meet the organization\u2019s needs. \n  Serve as a role model Milwaukee Tool\u2019s culture while mentoring, guiding, and coaching junior Engineers. \n  Use laboratory equipment such as oscilloscopes, power supplies, e-loads, and data acquisition systems. \n  Independently track projects to ensure adherence to schedule and the Milwaukee process. \n \n \n \n   What TOOLS you\u2019ll bring with you:   \n \n  Bachelor of Science degree in Computer Engineering, Computer Science, Electrical Engineering, or related field. \n  5+ years of experience with embedded C/C++. \n  Experience developing bare-metal firmware designs. \n  Experience with DevOps, automated testing, continuous integration/continuous deployment (CI/CD). \n  Knowledge and practical experience in all software development lifecycle phases. \n  Experience with a microcontroller RTOS. \n  Familiarity with software configuration management tools, defect tracking tools, and peer reviews. \n  Ability to read schematics and component data sheets, basic understanding of digital circuits and interaction between firmware and electronics. \n  Demonstrated ability using laboratory equipment such as oscilloscopes, logic analyzers, power supplies, e-loads, and data acquisition systems. \n  Excellent problem-solving skills, exercises independent judgement and works well under pressure in a dynamic environment. \n  Ability to travel 10% of the time (domestic and international). \n \n ", "techs": ["embedded c/c++", "devops", "automated testing", "continuous integration/continuous deployment (ci/cd)", "microcontroller rtos", "software configuration management tools", "defect tracking tools", "peer reviews", "oscilloscopes", "logic analyzers", "power supplies", "e-loads", "data acquisition systems"]}, "c25db32281ad538f": {"terms": ["machine learning engineer"], "salary_min": 99172.11, "salary_max": 125573.984, "title": "Design Engineer (Remote)", "company": "OPALFORCE.COM", "desc": "Opalforce Inc. is looking for Sr. Design engineer consultant in Las vegas, NV \n \n \n Requirements: \n \n \n \n  Bachelor\u2019s degree in Mechanical/Production engineering. \n  4 to 8 years of industrial work experience in relevant Engine or ancillary industry. \n  Must be Proficient in UG NX software with a relevant industry experience on the engine components design, drafting and 3D modeling. \n  Good knowledge and experience in PLM, preferably PTC Windchil. \n  Preferred to have experience in designing Casting, sheet metal & plastic parts. \n  Knowledge of GD&T and able to do tolerance stack ups. \n \n \n \n About OPALFORCE.COM: \n \n \n OpalForce Inc is a renowned Google cloud partner. A global leader with more than 20 years of experience in providing enterprise-level solutions to industries sectors like Healthcare, Entertainment, Retail, Government, Education, and Manufacturing. OpalForce has proven expertise in Google Cloud Platform, Infrastructure Modernization, Cloud Migration, Scaling Production Workloads, Kubernetes on GCP, Production Machine Learning, Gsuite Licenses. OpalForce has started its journey in Santa Clara, California in the year 2000, and associated with Fortune 1000 companies to transform and innovate them with Data and machine intelligence, & Cloud consulting, and engineering.", "cleaned_desc": "  Must be Proficient in UG NX software with a relevant industry experience on the engine components design, drafting and 3D modeling. \n  Good knowledge and experience in PLM, preferably PTC Windchil. \n  Preferred to have experience in designing Casting, sheet metal & plastic parts. ", "techs": ["ug nx software", "plm", "ptc windchill"]}, "7b771442a4f20cae": {"terms": ["machine learning engineer", "mlops"], "salary_min": 156000.0, "salary_max": 196000.0, "title": "Principal DevOps Engineer", "company": "Lilt", "desc": "Lilt is the leading AI solution for enterprise translations. Our stack made up of our Contextual AI Engine, Connector APIs, and Human Adaptive Feedback enable global organizations to adopt a true AI translation strategy, focusing on business outcomes instead of outputs. With Lilt, innovative, category-defining organizations like Intel, ASICS, WalkMe, and Canva are using AI technology to deliver multilingual, digital customer experiences at scale. \n  As a result, Lilt\u2019s AI technology foundation is similar to ChatGPT and Google Translate, before our patented Contextual AI Engine, connector-first approach, and human-adapted feedback. \n  Our team is located globally in San Francisco, Indianapolis, London, and Berlin with hubs located in Washington D.C., New York City, and Boston. You can learn more about us and what it\u2019s like to work here on our Careers page! \n  Authorization to work in the U.S. is a precondition of employment. \n \n  The Engineering Team at Lilt \n  Lilt is a high-performance, large-scale language translation system. We invest in and prioritize workflow (i.e., usability and interface design) and backend AI systems. Since the translation workforce is distributed worldwide, there are interesting cloud engineering problems to solve. We have a strong preference for building our own backend technology, so you\u2019ll be implementing and working with the latest natural language processing (NLP) techniques and ideas. \n \n  What You\u2019ll Do \n  Lilt is seeking a world-class devops engineer to build highly reliable software systems at Lilt. Your job will be to apply your software talents to our infrastructure and operations needs, including bare-metal Linux deployments and commercial deployments in GCP and AWS. Our system requires low latency worldwide, so you\u2019ll continuously improve our multi-region configuration, and help us expand into new regions. You will collaborate with the rest of the engineering team to support new and on-going products. The person in this role may have technical leadership responsibility depending of experience and will collaborate to build the roadmap of the DevOps organization. \n  This position can be based out of our Indianapolis, IN office and will be expected to work in the office in a hybrid capacity. The other locations include the Boston metropolitan area where you will start as fully remote and then transition to hybrid once offices are opened in those locations. Fully remote applicants will also be considered. \n \n  Key Responsibilities \n \n  Support technical operations in our development and production systems \n  Deliver infrastructure engineering projects to support company initiatives \n  Collaborate with our research and development teams to deliver software fast and reliably \n  Secure our platform infrastructure and harden our on-premise builds \n  Ensure high uptime and fast, multi-regional server and DB performance for the lilt.com production system \n  Work with engineering teams to set, measure, and reach SLIs and SLOs for SLAs \n  Contribute to infrastructure and engineering roadmap planning, set and attain quarterly OKRs \n  Execute on the roadmap in sprints, and adhere to SCRUM best practices \n  Introduce and implement new technologies and best practices in InfoSec, DevOps and Site Reliability \n  Support our self-managed customers on-site \n  Technically lead a group of subject-matter experts \n \n  Skills and Experience \n \n  Minimum 6 years experience as Linux System Administrator, DevOps Engineer or similar position. \n  Strong knowledge of at least one scripting language (e.g. Python, Bash). \n  High proficiency with at least one configuration management/infrastructure as code (IaC) tool, preferably Terraform. \n  Experience with GCP services such as Compute Engine, shared VPC, and data analytics or equivalents from other vendors. \n  Solid understanding of Docker and hands-on experience with orchestration frameworks like Kubernetes or Swarm. \n  Expertise in monitoring/alerting and maintaining high production availability \n  Experience with CI/CD tools and concepts, such as Jenkins \n  Preferred, but not required: Experience in DevSecOps best practices, MLOps, GCP Landzone and/or DB administration \n \n \n  Our Story \n  Our founders, Spence and John met at Google working on Google Translate. As researchers at Stanford and Berkeley, they both worked on language technology to make information accessible to everyone. They were amazed to learn that Google Translate wasn\u2019t used for enterprise products and services inside the company and left to start a new company to address this need \u2013 Lilt. \n  At its core, Lilt has always been a machine learning company since its incorporation on March 6, 2015. At the time, machine translation didn\u2019t meet the quality standard for enterprise translations, so Lilt assembled a cutting-edge research team tasked with closing that gap. While meeting customer demand for translation services, Lilt has prioritized investments in Large Language Models, believing that this foundation was imperative to the future of enterprise translation. \n \n  Benefits \n \n  Compensation: Competitive salary with the opportunity to earn on-target earnings (OTE), meaningful equity, 401(k) matching, and flexible time off plus company holidays. \n  Medical Benefits: Employees receive coverage of medical, dental, and vision insurance, plus FSA/DFSA, HSA, and Commuter benefits. In addition, Lilt pays for basic life insurance, short-term disability, and long-term disability. \n  Paid parental leave is provided after 6 months. \n  Monthly lifestyle benefit stipend via the Fringe platform to allow employees to customize benefits to their lifestyle. \n \n  Lilt is an equal opportunity employer. We extend equal opportunity to all individuals without regard to an individual\u2019s race, religion, color, national origin, ancestry, sex, sexual orientation, gender identity, age, physical or mental disability, medical condition, genetic characteristics, veteran or marital status, pregnancy, or any other classification protected by applicable local, state or federal laws. We are committed to the principles of fair employment and the elimination of all discriminatory practices. \n  Compensation Range: $156K - $196K", "cleaned_desc": "  High proficiency with at least one configuration management/infrastructure as code (IaC) tool, preferably Terraform. \n  Experience with GCP services such as Compute Engine, shared VPC, and data analytics or equivalents from other vendors. \n  Solid understanding of Docker and hands-on experience with orchestration frameworks like Kubernetes or Swarm. \n  Expertise in monitoring/alerting and maintaining high production availability \n  Experience with CI/CD tools and concepts, such as Jenkins \n  Preferred, but not required: Experience in DevSecOps best practices, MLOps, GCP Landzone and/or DB administration \n \n \n  Our Story \n  Our founders, Spence and John met at Google working on Google Translate. As researchers at Stanford and Berkeley, they both worked on language technology to make information accessible to everyone. They were amazed to learn that Google Translate wasn\u2019t used for enterprise products and services inside the company and left to start a new company to address this need \u2013 Lilt. ", "techs": ["terraform", "gcp (compute engine", "shared vpc", "data analytics)", "docker", "kubernetes", "swarm", "jenkins", "devsecops", "mlops", "gcp landzone", "db administration"]}, "e386f5e63248c684": {"terms": ["machine learning engineer"], "salary_min": 41319.4, "salary_max": 52319.562, "title": "Lead Software Engineer, Back End (Remote)", "company": "Velocity Black", "desc": "Category \n \n      Engineering\n      \n \n \n \n \n \n Experience \n \n      Manager\n      \n \n \n \n \n \n Primary Address \n \n \n       Remote, USA\n       \n \n \n \n \n \n \n Overview  Locations: US Remote, United States of America\n    Lead Software Engineer, Back End (Remote)\n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  Capital One has taken a bold journey to build a technology company, while operating in a complex, highly regulated business. We have built out a large engineering organization, moved to the cloud, re-architected our applications and data platforms, and embraced machine learning at scale. Our AI/ML capabilities are now at the forefront of what\u2019s possible in banking (e.g., Eno). \n \n  As we uncovered new challenges along the way, we built and battle tested new capabilities to meet those needs. We\u2019ve open sourced several of the software tools we built (e.g., Cloud Custodian, Hygieia) and forged new partnerships with other digital leaders (e.g., Microsoft). \n \n  We've developed a suite of internal solutions uniquely designed to meet the challenges of a digital-first, cloud-first business at scale. Today, the Capital One Software team is exploring how these internal solutions across cloud, data, security, governance, and applications could serve the needs of other companies born or built in the cloud. \n  Capital One Software is a new enterprise B2B software business focused on providing cloud and data management solutions to companies operating in the cloud. This is Capital One\u2019s first foray into the enterprise software market and comes after years spent building our own in-house cloud and data management tools that enable us to operate at scale in the cloud. As a Capital One Software Engineer, you\u2019ll have the opportunity to be on the forefront of driving a major transformation within Capital One. \n \n  We\u2019re looking for a Lead - Back End Software Engineer to join the Capital One Software Incubation Technology team! \n \n \n  What You\u2019ll Do: \n \n \n  Lead technical initiatives and guide developers with deep experience in distributed microservices, and full stack systems to create robust, cloud native, resilient, and highly scalable solutions in data management and security domains \n  Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community, and from time to time, be asked to code or evaluate code \n  Has a strong engineering and technology background with the ability to learn quickly and go deep into our product and engineering solutions \n  Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible. Lead the craftsmanship, availability, resilience, and scalability of your solutions \n  Be the guiding force for stakeholders in design and architecture discussions, helping the engineering teams make key technology choices, and staying associated with the use case through its development lifecycle \n  Collaborate with architects and product managers, and deliver robust cloud-based solutions that drive powerful experiences for our customers \n \n \n  Basic Qualifications: \n \n \n  Bachelor\u2019s Degree \n  At least 6 years of experience in software engineering (Internship experience does not apply) \n  At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud) \n  At least 1 year of experience with Big Data, Data Security, Governance and Controls \n  At least 1 year of experience with containerization technologies \n \n \n \n  Preferred Qualifications: \n \n \n  Master\u2019s Degree \n  7+ years of experience in software engineering, specifically in at least one of the following technologies: GoLang, Java, Python, Lua, Nginx, Rust, or C++ \n  3+ years of experience with AWS, GCP, Azure, or another cloud service \n  2+ years of experience with containerization technologies such as Kubernetes \n  2+ years of experience in open source frameworks \n  2+ years of experience in Big Data, Data Security, Governance and Controls \n  2+ years of experience in Agile practices \n  2+ years of experience building Multi-cloud COTS products \n  2+ years of DevOps or Site Reliability Engineering experience \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  Remote (Regardless of Location): $167,400 - $191,000 for Lead Software Engineer\n   \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n   \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n   \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Capital One Software is a new enterprise B2B software business focused on providing cloud and data management solutions to companies operating in the cloud. This is Capital One\u2019s first foray into the enterprise software market and comes after years spent building our own in-house cloud and data management tools that enable us to operate at scale in the cloud. As a Capital One Software Engineer, you\u2019ll have the opportunity to be on the forefront of driving a major transformation within Capital One. \n \n  We\u2019re looking for a Lead - Back End Software Engineer to join the Capital One Software Incubation Technology team! \n \n \n  What You\u2019ll Do: \n \n \n  Lead technical initiatives and guide developers with deep experience in distributed microservices, and full stack systems to create robust, cloud native, resilient, and highly scalable solutions in data management and security domains \n  Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community, and from time to time, be asked to code or evaluate code \n  Has a strong engineering and technology background with the ability to learn quickly and go deep into our product and engineering solutions \n  Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible. Lead the craftsmanship, availability, resilience, and scalability of your solutions \n  Be the guiding force for stakeholders in design and architecture discussions, helping the engineering teams make key technology choices, and staying associated with the use case through its development lifecycle \n  Collaborate with architects and product managers, and deliver robust cloud-based solutions that drive powerful experiences for our customers \n \n \n  Basic Qualifications: \n \n \n  Bachelor\u2019s Degree \n  At least 6 years of experience in software engineering (Internship experience does not apply) \n  At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud) \n  At least 1 year of experience with Big Data, Data Security, Governance and Controls \n  At least 1 year of experience with containerization technologies \n \n \n \n  Preferred Qualifications:   \n \n  Master\u2019s Degree \n  7+ years of experience in software engineering, specifically in at least one of the following technologies: GoLang, Java, Python, Lua, Nginx, Rust, or C++ \n  3+ years of experience with AWS, GCP, Azure, or another cloud service \n  2+ years of experience with containerization technologies such as Kubernetes \n  2+ years of experience in open source frameworks \n  2+ years of experience in Big Data, Data Security, Governance and Controls \n  2+ years of experience in Agile practices \n  2+ years of experience building Multi-cloud COTS products \n  2+ years of DevOps or Site Reliability Engineering experience \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n \n \n \n \n \n \n \n \n \n \n \n \n ", "techs": ["distributed microservices", "full stack systems", "data management", "security domains", "software engineering", "cloud computing (aws", "microsoft azure", "google cloud)", "big data", "containerization technologies", "golang", "java", "python", "lua", "nginx", "rust", "c++", "open source frameworks", "agile practices", "multi-cloud cots products", "devops", "site reliability engineering"]}, "b490f8078492c838": {"terms": ["machine learning engineer"], "salary_min": 116918.18, "salary_max": 148044.47, "title": "Back-End Engineer - Ruby and Ruby on Rails (RoR)", "company": "Mozilla", "desc": "Why Mozilla? \n  Mozilla Corporation is the non-profit-backed technology company behind pioneering brands like Firefox, the privacy-minded web browser, and Pocket,  a service for keeping up with the best articles online . More than  225  million people around the world use its products each month. \n  Along with  60,000 + volunteer contributors and collaborators all over the world, Mozilla Corporation's staff are driven by our mission  to ensure the Internet is a global public resource, open and accessible to all . We design, build and distribute  open-source  software that enables people to enjoy the internet on their terms. \n  About this team and role: \n  Fakespot is now part of Mozilla, where our mission to bring trust and transparency back to the eCommerce space is now aligned with ensuring the Internet is a global resource, open and accessible to all. Fakespot leverages machine learning and other state-of-the-art technologies to automatically filter out spurious reviews of products and vendors so consumers can make informed purchasing decisions based on real feedback by real people. We are looking for a mid-level engineer to join the Fakespot team within Mozilla. \n  What you'll do: \n \n Creating robust, scalable, highly loaded applications \n Maintaining and troubleshooting existing applications \n Identifying and fixing bottlenecks and bugs \n Maintaining and expanding APIs \n \n What you'll bring: \n \n Minimum 2 years of professional work experience with Ruby and Ruby on Rails \n Excellent learning ability \n Ability to write efficient algorithms, and clean code \n Knowledge of relational databases such as PostgreSQL and MySQL \n Experience working with Sidekiq, RSpec and other common RoR libraries \n Working knowledge of Git, Docker \n Good knowledge of full stack web development \n Commitment to our values: \n \n Welcoming differences \n Being relationship-minded \n Practicing responsible participation \n Having grit \n \n \n Bonus Points for\u2026 \n \n Golang, Python, Kubernetes deployments \n Working with high traffic systems \n Background processing experience \n \n What you'll get: \n \n Generous performance-based bonus plans to all regular employees - we share in our success as one team \n Rich medical, dental, and vision coverage \n Generous retirement contributions with 100% immediate vesting (regardless of whether you contribute) \n Quarterly all-company wellness days where everyone takes a pause together \n Country specific holidays plus a day off for your birthday \n One-time home office stipend \n Annual professional development budget \n Quarterly well-being stipend \n Considerable paid parental leave \n Employee referral bonus program \n Other benefits (life/AD&D, disability, EAP, etc. - varies by country) \n \n About Mozilla \n  Mozilla exists to build the Internet as a public resource accessible to all because we believe that open and free is better than closed and controlled. When you work at Mozilla, you give yourself a chance to make a difference in the lives of Web users everywhere. And you give us a chance to make a difference in your life every single day. Join us to work on the Web as the platform and help create more opportunity and innovation for everyone online. \n  Commitment to diversity, equity, inclusion, and belonging \n  Mozilla understands that valuing diverse creative practices and forms of knowledge are crucial to and enrich the company's core mission. We encourage applications from everyone, including members of all equity-seeking communities, such as (but certainly not limited to) women, racialized and Indigenous persons, persons with disabilities, persons of all sexual orientations, gender identities, and expressions. \n  We will ensure that qualified individuals with disabilities are provided reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment, as appropriate. Please contact us at hiringaccommodation@mozilla.com to request accommodation. \n  We are an equal opportunity employer. We do not discriminate on the basis of race (including hairstyle and texture), religion (including religious grooming and dress practices), gender, gender identity, gender expression, color, national origin, pregnancy, ancestry, domestic partner status, disability, sexual orientation, age, genetic predisposition, medical condition, marital status, citizenship status, military or veteran status, or any other basis covered by applicable laws. Mozilla will not tolerate discrimination or harassment based on any of these characteristics or any other unlawful behavior, conduct, or purpose. \n  Group: E \n  #LI-REMOTE \n  Req ID: R2295 \n \n \n  To learn more about our Hiring Range System, please click this  link. \n  Hiring Ranges: \n \n  US Tier 1 Locations \n \n    $113,000\u2014$165,000 USD\n   \n  US Tier 2 Locations \n \n    $103,000\u2014$151,000 USD\n   \n  US Tier 3 Locations \n \n    $95,000\u2014$139,000 USD", "cleaned_desc": " Minimum 2 years of professional work experience with Ruby and Ruby on Rails \n Excellent learning ability \n Ability to write efficient algorithms, and clean code \n Knowledge of relational databases such as PostgreSQL and MySQL \n Experience working with Sidekiq, RSpec and other common RoR libraries \n Working knowledge of Git, Docker \n Good knowledge of full stack web development \n Commitment to our values: \n \n Welcoming differences \n Being relationship-minded \n Practicing responsible participation \n Having grit \n ", "techs": ["ruby", "ruby on rails", "postgresql", "mysql", "sidekiq", "rspec", "git", "docker"]}, "3379b1ebf3336a92": {"terms": ["machine learning engineer"], "salary_min": 42444.26, "salary_max": 53743.895, "title": "Senior Lead Software Engineer, Back End (Remote)", "company": "Velocity Black", "desc": "Category \n \n      Engineering\n      \n \n \n \n \n \n Experience \n \n      Sr. Manager\n      \n \n \n \n \n \n Primary Address \n \n \n       Remote, USA\n       \n \n \n \n \n \n \n Overview  Locations: US Remote, United States of America\n    Senior Lead Software Engineer, Back End (Remote)\n   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  Capital One has taken a bold journey to build a technology company, while operating in a complex, highly regulated business. We have built out a large engineering organization, moved to the cloud, re-architected our applications and data platforms, and embraced machine learning at scale. Our AI/ML capabilities are now at the forefront of what\u2019s possible in banking (e.g., Eno). \n \n  As we uncovered new challenges along the way, we built and battle tested new capabilities to meet those needs. We\u2019ve open sourced several of the software tools we built (e.g., Cloud Custodian, Hygieia) and forged new partnerships with other digital leaders (e.g., Microsoft). \n \n  We've developed a suite of internal solutions uniquely designed to meet the challenges of a digital-first, cloud-first business at scale. Today, the Capital One Software team is exploring how these internal solutions across cloud, data, security, governance, and applications could serve the needs of other companies born or built in the cloud. \n  Capital One Software is a new enterprise B2B software business focused on providing cloud and data management solutions to companies operating in the cloud. This is Capital One\u2019s first foray into the enterprise software market and comes after years spent building our own in-house cloud and data management tools that enable us to operate at scale in the cloud. As a Capital One Software Engineer, you\u2019ll have the opportunity to be on the forefront of driving a major transformation within Capital One. \n \n  We\u2019re looking for a Senior Lead, Back End Software Engineer to join the Capital One Software team! \n \n \n  What You\u2019ll Do: \n \n \n  Has a strong engineering and technology background with the ability to learn quickly and go deep into our product and engineering solutions \n  Help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices to curate a continual stream of incubated projects and create rapid product prototypes \n  Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible. Lead the craftsmanship, availability, resilience, and scalability of your solutions \n  Be the guiding force for stakeholders in design and architecture discussions, helping the engineering teams make key technology choices, and staying associated with the use case through its development lifecycle \n  Effectively communicate with and influence key stakeholders across the enterprise at all levels of the organization. Proven collaborator and have the ability to build very strong partnerships with others to gain the trust and confidence of those around them, from hands on engineers to executives \n \n \n \n  Basic Qualifications: \n \n \n  Bachelor\u2019s Degree \n  At least 8 years of experience in software engineering (Internship experience does not apply) \n  At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud) \n  At least 1 year of experience with Big Data, Data Security, Governance, Controls \n  At least 1 year of experience with containerization technologies \n \n \n \n  Preferred Qualifications: \n \n \n  Master\u2019s Degree \n  9+ years of experience in software engineering, in at least one of the following technologies: GoLang, Java, Python, Rust, or C++ \n  5+ years of experience with AWS, GCP, Azure, or another cloud service \n  2+ years of experience with containerization technologies such as Kubernetes \n  4+ years of experience in open source frameworks \n  2+ years of experience in Big Data, Data Security, Governance and Controls \n  2+ years of experience in Agile practices \n  2+ years of experience working at a startup or in a startup environment \n  2+ years of experience building Multi-cloud COTS products \n  2+ years of DevOps or Site Reliability Engineering experience \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Software Engineer\n   \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n   \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at theCapital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n   \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).", "cleaned_desc": "  Capital One Software is a new enterprise B2B software business focused on providing cloud and data management solutions to companies operating in the cloud. This is Capital One\u2019s first foray into the enterprise software market and comes after years spent building our own in-house cloud and data management tools that enable us to operate at scale in the cloud. As a Capital One Software Engineer, you\u2019ll have the opportunity to be on the forefront of driving a major transformation within Capital One. \n \n  We\u2019re looking for a Senior Lead, Back End Software Engineer to join the Capital One Software team! \n \n \n  What You\u2019ll Do: \n \n \n  Has a strong engineering and technology background with the ability to learn quickly and go deep into our product and engineering solutions \n  Help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices to curate a continual stream of incubated projects and create rapid product prototypes \n  Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible. Lead the craftsmanship, availability, resilience, and scalability of your solutions \n  Be the guiding force for stakeholders in design and architecture discussions, helping the engineering teams make key technology choices, and staying associated with the use case through its development lifecycle \n  Effectively communicate with and influence key stakeholders across the enterprise at all levels of the organization. Proven collaborator and have the ability to build very strong partnerships with others to gain the trust and confidence of those around them, from hands on engineers to executives \n \n \n \n  Basic Qualifications: \n \n \n  Bachelor\u2019s Degree \n  At least 8 years of experience in software engineering (Internship experience does not apply) \n  At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud) \n  At least 1 year of experience with Big Data, Data Security, Governance, Controls \n  At least 1 year of experience with containerization technologies \n \n \n \n  Preferred Qualifications:   \n \n  Master\u2019s Degree \n  9+ years of experience in software engineering, in at least one of the following technologies: GoLang, Java, Python, Rust, or C++ \n  5+ years of experience with AWS, GCP, Azure, or another cloud service \n  2+ years of experience with containerization technologies such as Kubernetes \n  4+ years of experience in open source frameworks \n  2+ years of experience in Big Data, Data Security, Governance and Controls \n  2+ years of experience in Agile practices \n  2+ years of experience working at a startup or in a startup environment \n  2+ years of experience building Multi-cloud COTS products \n  2+ years of DevOps or Site Reliability Engineering experience \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n \n \n \n \n \n \n \n \n \n \n \n \n ", "techs": ["aws", "microsoft azure", "google cloud", "big data", "data security", "governance", "controls", "containerization technologies", "golang", "java", "python", "rust", "c++", "kubernetes", "open source frameworks", "agile practices", "startup environment", "multi-cloud cots products", "devops", "site reliability engineering"]}, "b871ed2298630d07": {"terms": ["machine learning engineer"], "salary_min": 92095.695, "salary_max": 116613.68, "title": "Technical Support Engineer", "company": "TigerGraph", "desc": "TigerGraph is a platform for advanced analytics and machine learning on connected data. TigerGraph's core technology is the only scalable graph database for the enterprise. Its proven technology supports fraud detection, customer 360, MDM, IoT, AI, and machine learning.\n    Fortune 500 organizations and the most innovative mid-size and startup companies choose TigerGraph to accelerate their analytics, AI, and machine learning:\n  \n \n Seven out of the top ten global banks use TigerGraph for real-time fraud detection. \n Over 50 million patients receive care path recommendations to assist them on their wellness journey. \n 300 million consumers receive personalized offers with recommendation engines powered by TigerGraph. \n TigerGraph reduces power outages by optimizing the energy infrastructure for 1 billion people. \n \n \n We are looking for a highly motivated and experienced Technical Support Engineer to join our US team to support rapidly growing demand from enterprise customers (Global 1000) to deploy TigerGraph's award-winning graph database platform and solutions. The ideal candidate should have experience with Graph Databases or NoSQL databases, distributed systems, cloud platforms (such as Azure, AWS, GCP), scripting skills, Kubernetes and advanced debugging and troubleshooting skills. \n  Responsibilities: \n \n Responding to Customers' inquiries and providing in-depth technical and high-quality support via phone, email, or chat. \n Troubleshooting and resolving technical issues that span from the product itself to the Customer environment. \n Collaborate with other teams (core engineering and solution engineering) to diagnose and resolve complex customer issues. \n Partner with the Customer Success, Sales, and Product teams to drive business to success \n Participate in on-call rotation shift \n Educate customers on best practices for adopting and using TigerGraph \n Create and maintain public documentation, knowledge articles (internal and Customer facing), and FAQs. Keep improving product knowledge and keeping up with business trends. \n Support/Operations Experience \n Oncall rotation, documentation creation, meeting/monitoring SLAs \n \n Requirements: \n \n Bachelor's degree required. \n At least 3+ years of experience in technical support or related work. ( No service desk ) \n \n Skills & Knowledge: \n \n Big data/data ecosystem experience \n \n Technologies: Hadoop, MapReduce, Spark, Airflow, Beam, Kafka, Zookeeper \n Concepts: Data warehousing, data analytics, ETL \n \n Distributed systems experience \n \n Kubernetes, above listed big data technology \n \n Database experience \n \n Any familiarity or experience with databases, preferably distributed ones such as Hive, BigQuery, AWS KMS, Cassandra, BigTable \n \n Programming/scripting skills \n \n Bash, Go, Java, C++, Python preferred \n Terraform, Ansible \n \n Customer facing technical experience \n \n Any of support, consulting, tech writing, solutions architecture, anything where candidate is communicating technical info to customers \n Customer-focus mindset \n Strong problem-solving and troubleshooting skills \n \n Technical skills: \n \n Prior experience working with graph technology is a big plus \n Linux fundamentals knowledge (processes, filesystem, memory management, networking, configuration, security), network troubleshooting (ex. TCP/IP, load balancing), web troubleshooting (HTTP, SSL, REST APIs) \n \n \n Additional skills as a big bonus: \n \n Familiar with HW/SW stacks for large-scale enterprise graph databases or NoSQL databases on-prem and/or on the cloud. \n Experience with LDAP, OAuth \n Experience with a Graph Database is a big plus \n Experience with SaaS solutions \n Understanding of how database systems work under the hood \n \n The anticipated salary range for candidates who will work in Redwood City, CA is $70,000 - $110,000. The final salary offered to a successful candidate will be dependent on several factors that may include, but are not limited to, the type and length of experience within the job, type and length of experience within the industry, education, etc. TigerGraph is a multi-state employer and this salary range may not reflect positions that work in other states.", "cleaned_desc": "TigerGraph is a platform for advanced analytics and machine learning on connected data. TigerGraph's core technology is the only scalable graph database for the enterprise. Its proven technology supports fraud detection, customer 360, MDM, IoT, AI, and machine learning.\n    Fortune 500 organizations and the most innovative mid-size and startup companies choose TigerGraph to accelerate their analytics, AI, and machine learning:\n  \n \n Seven out of the top ten global banks use TigerGraph for real-time fraud detection. \n Over 50 million patients receive care path recommendations to assist them on their wellness journey. \n 300 million consumers receive personalized offers with recommendation engines powered by TigerGraph. \n TigerGraph reduces power outages by optimizing the energy infrastructure for 1 billion people. \n \n \n We are looking for a highly motivated and experienced Technical Support Engineer to join our US team to support rapidly growing demand from enterprise customers (Global 1000) to deploy TigerGraph's award-winning graph database platform and solutions. The ideal candidate should have experience with Graph Databases or NoSQL databases, distributed systems, cloud platforms (such as Azure, AWS, GCP), scripting skills, Kubernetes and advanced debugging and troubleshooting skills. \n  Responsibilities: \n   At least 3+ years of experience in technical support or related work. ( No service desk ) \n \n Skills & Knowledge: \n \n Big data/data ecosystem experience \n \n Technologies: Hadoop, MapReduce, Spark, Airflow, Beam, Kafka, Zookeeper \n Concepts: Data warehousing, data analytics, ETL \n \n Distributed systems experience \n \n Kubernetes, above listed big data technology \n ", "techs": ["tigergraph", "graph database", "fortune 500", "fraud detection", "customer 360", "mdm", "iot", "ai", "machine learning", "global banks", "real-time", "care path recommendations", "personalized offers", "power outages", "technical support engineer", "graph databases", "nosql databases", "distributed systems", "cloud platforms", "azure", "aws", "gcp", "scripting skills", "kubernetes", "debugging", "troubleshooting", "hadoop", "mapreduce", "spark", "airflow", "beam", "kafka", "zookeeper", "data warehousing", "etl"]}, "4b503b1f64796d88": {"terms": ["machine learning engineer"], "salary_min": 102000.0, "salary_max": 190000.0, "title": "Senior DevSecOps Engineer", "company": "IBM", "desc": "Introduction \n  As an IBM Application Architect, you directly help clients transform their business and solve complex problems. You will define the scope and vision for projects that deliver customized solutions using your knowledge of IBM platforms. You are a technical leader, serving as a liaison among business partners, technical resources, and project stakeholders.\n   \n \n Your Role and Responsibilities \n  Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes. \n  Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region\u2019s best places to work multiple times, Octo is an employer of choice! \n  You...  \n As a  DevSecOps Engineer  at Octo, you will be responsible for supporting multiple delivery projects for the Department of Veterans Affairs. This role will be responsible for supporting and providing continuous integration and delivery, with code, of cloud resources used by data engineering teams. You will also be supporting the infrastructure and implementation of various software applications and cloud services. You will proactively participate in the infrastructure code lifecycle including version control, implementation, test design, test implementation, optimization, and delivery utilizing the latest technologies. Along with every aspect of this job is an emphasis on security and demonstrated knowledge of how to deploy and configure infrastructure following secure best practices. Strongly prefer those with knowledge of infrastructure as code to configure and deploy Azure resources. \n  Us... \n  We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client\u2019s missions.  \n Program Mission... \n  This program supports Veterans Affairs' strategic mission of furthering efforts to modernize its data analytics platform and enhance accessibility to enterprise data and reporting tools. \n  Responsibilities... \n \n  Support the design and implementation of infrastructure as code using git technologies with version control systems. \n  Design and optimize code and infrastructure with a focus on security. \n  Proactively participate in every aspect of the software development lifecycle including design, implementation, test design, test implementation, optimization, and delivery utilizing the latest technologies.  \n Partner with data engineering teams to ensure agile infrastructure delivery configuration following DevSecOps best practices. \n  Deploy code changes in different environments for testing and production environments. \n  Collaboration in code reviews, agile ceremonies like retrospectives, daily standups, and sprint planning, pair programming. \n  Coordinate with program and project leaders to analyze technologies being utilized on the projects. \n  Maintain the integrity of services integrated with our cloud environments, including proprietary in-house systems and external integrations. \n \n  Years of Experience:  5+ years of related experience in software engineering and development, including at least 3+ years of experience with overseeing and managing the DevOps lifecycle. \n  Education:  Bachelor\u2019s Degree in Computer Science, Engineering or other technical discipline required, OR a minimum of 8 years equivalent work experience. \n  Location:  Remote within the United States. \n  Clearance:  Ability to obtain public trust clearance. \n  Required Technical and Professional Expertise \n \n  5+ years working with DevOps/release management with an understanding of CI/CD processes and integration concepts. \n  4+ years of infrastructure as code experience primarily in Terraform. \n  4+ years of experience in git technology and version control (GitHub). \n  3+ years of experience with overseeing and managing the DevOps lifecycle. \n  3+ years of experience in managing infrastructure. \n  Must have experience with some Azure resources, i.e. Databricks, Datalake, Data Factory, Function Apps Machine Learning, Virtual Machines, SQL Databases, Roll Base Access Control, etc.   \n Must understand Microsoft Azure Active Directory for authentication and access management.   \n Expertise in modern technologies such as RESTful Services, Git, Microservice Architectures.   \n Experience working with PowerShell and Shell scripting or others.   \n Strong troubleshooting experience.   \n Strong communication skills, attention to detail, and drive to deliver best-in-class software and cloud infrastructure. \n \n \n  Preferred Technical and Professional Expertise \n \n \n  Experience in OS Administration Linux and Windows. \n  Experience with Collibra and/or Trifacta software. \n  Experience in networking; Azure Vnets, Peering, Security Groups, Routing. \n  Experience in TLS Certificate Management. \n  Experience supporting the Department of Veterans Affairs or other federal organizations. \n  Working knowledge of Azure Databricks. \n  Strong technical presentation skills. \n \n \n \n \n \n  About Business Unit \n  IBM Consulting is IBM\u2019s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients\u2019 businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.\n  \n \n \n \n  Your Life @ IBM \n  In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.\n    Being an IBMer means you\u2019ll be able to learn and develop yourself and your career, you\u2019ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background. \n  Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do. \n  Are you ready to be an IBMer? \n \n \n \n  About IBM \n  IBM\u2019s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.\n   \n  Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we\u2019re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. \n   \n  At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it\u2019s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.\n  \n \n \n \n  Location Statement \n  IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:\n   \n \n \n Healthcare benefits including medical & prescription drug coverage, dental, vision, and mental health & well being \n  - Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short & long- term disability coverage, and opportunities for performance based salary incentive programs\n   \n \n Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law \n Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals \n Diverse and inclusive employee resource groups, giving & volunteer opportunities, and discounts on retail products, services & experiences \n \n  The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year. \n   \n  We consider qualified applicants with criminal histories, consistent with applicable law.\n  \n \n \n \n  Being You @ IBM \n  IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.", "cleaned_desc": "Introduction \n  As an IBM Application Architect, you directly help clients transform their business and solve complex problems. You will define the scope and vision for projects that deliver customized solutions using your knowledge of IBM platforms. You are a technical leader, serving as a liaison among business partners, technical resources, and project stakeholders.\n   \n \n Your Role and Responsibilities \n  Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes. \n  Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region\u2019s best places to work multiple times, Octo is an employer of choice! \n  You...  \n As a  DevSecOps Engineer  at Octo, you will be responsible for supporting multiple delivery projects for the Department of Veterans Affairs. This role will be responsible for supporting and providing continuous integration and delivery, with code, of cloud resources used by data engineering teams. You will also be supporting the infrastructure and implementation of various software applications and cloud services. You will proactively participate in the infrastructure code lifecycle including version control, implementation, test design, test implementation, optimization, and delivery utilizing the latest technologies. Along with every aspect of this job is an emphasis on security and demonstrated knowledge of how to deploy and configure infrastructure following secure best practices. Strongly prefer those with knowledge of infrastructure as code to configure and deploy Azure resources. \n  Us... \n  We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client\u2019s missions.  \n Program Mission... \n  This program supports Veterans Affairs' strategic mission of furthering efforts to modernize its data analytics platform and enhance accessibility to enterprise data and reporting tools. \n  Responsibilities... \n \n  Support the design and implementation of infrastructure as code using git technologies with version control systems. \n  Design and optimize code and infrastructure with a focus on security. \n  Proactively participate in every aspect of the software development lifecycle including design, implementation, test design, test implementation, optimization, and delivery utilizing the latest technologies.  \n Partner with data engineering teams to ensure agile infrastructure delivery configuration following DevSecOps best practices. \n  Deploy code changes in different environments for testing and production environments.    Collaboration in code reviews, agile ceremonies like retrospectives, daily standups, and sprint planning, pair programming. \n  Coordinate with program and project leaders to analyze technologies being utilized on the projects. \n  Maintain the integrity of services integrated with our cloud environments, including proprietary in-house systems and external integrations. \n \n  Years of Experience:  5+ years of related experience in software engineering and development, including at least 3+ years of experience with overseeing and managing the DevOps lifecycle. \n  Education:  Bachelor\u2019s Degree in Computer Science, Engineering or other technical discipline required, OR a minimum of 8 years equivalent work experience. \n  Location:  Remote within the United States. \n  Clearance:  Ability to obtain public trust clearance. \n  Required Technical and Professional Expertise \n \n  5+ years working with DevOps/release management with an understanding of CI/CD processes and integration concepts. \n  4+ years of infrastructure as code experience primarily in Terraform. \n  4+ years of experience in git technology and version control (GitHub). \n  3+ years of experience with overseeing and managing the DevOps lifecycle. \n  3+ years of experience in managing infrastructure. \n  Must have experience with some Azure resources, i.e. Databricks, Datalake, Data Factory, Function Apps Machine Learning, Virtual Machines, SQL Databases, Roll Base Access Control, etc.   \n Must understand Microsoft Azure Active Directory for authentication and access management.   \n Expertise in modern technologies such as RESTful Services, Git, Microservice Architectures.   \n Experience working with PowerShell and Shell scripting or others.   \n Strong troubleshooting experience.     Strong communication skills, attention to detail, and drive to deliver best-in-class software and cloud infrastructure. \n \n \n  Preferred Technical and Professional Expertise \n \n \n  Experience in OS Administration Linux and Windows. \n  Experience with Collibra and/or Trifacta software. \n  Experience in networking; Azure Vnets, Peering, Security Groups, Routing. \n  Experience in TLS Certificate Management. \n  Experience supporting the Department of Veterans Affairs or other federal organizations. \n  Working knowledge of Azure Databricks. \n  Strong technical presentation skills. \n \n \n \n \n \n  About Business Unit \n  IBM Consulting is IBM\u2019s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients\u2019 businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.", "techs": ["ibm application architect", "ibm platforms", "agile software engineering", "user experience design", "cloud services", "digital strategy services", "devsecops engineer", "department of veterans affairs", "code integration and delivery", "infrastructure and software implementation", "infrastructure code lifecycle", "secure best practices", "infrastructure as code", "azure resources", "government consulting community", "modernize data analytics platform", "infrastructure as code using git technologies", "security optimization", "devsecops best practices", "code deployment", "code reviews", "agile ceremonies", "pair programming", "technologies analysis", "cloud environments integrity", "software engineering", "devops lifecycle", "ci/cd processes", "infrastructure management", "azure resources (databricks", "datalake", "data factory", "function apps", "machine learning", "virtual machines", "sql databases", "roll base access control)", "microsoft azure active directory", "restful services", "git", "microservice architectures", "powershell", "shell scripting", "troubleshooting", "communication skills", "os administration", "collibra", "trifacta", "networking", "azure vnets", "peering", "security groups", "routing", "tls certificate management", "department of veterans affairs support", "azure databricks", "technical presentation skills"]}, "e4ab743b6d6a82d8": {"terms": ["machine learning engineer"], "salary_min": 130856.2, "salary_max": 165693.11, "title": "Solution Engineer", "company": "TigerGraph", "desc": "TigerGraph is a platform for advanced analytics and machine learning on connected data. TigerGraph's core technology is the only scalable graph database for the enterprise. Its proven technology supports fraud detection, customer 360, MDM, IoT, AI, and machine learning. \n  Fortune 500 organizations and the most innovative mid-size and startup companies choose TigerGraph to accelerate their analytics, AI, and machine learning: \n \n Seven out of the top ten global banks use TigerGraph for real-time fraud detection. \n Over 50 million patients receive care path recommendations to assist them on their wellness journey. \n 300 million consumers receive personalized offers with recommendation engines powered by TigerGraph. \n TigerGraph reduces power outages by optimizing the energy infrastructure for 1 billion people. \n \n TigerGraph is leading the graph industry with its modern, graph database, analytics and ML platform and with its expansion is looking for someone to build and develop its new Customer Success team. \n  The Solutions Team at TigerGraph strives to continuously develop and improve the world's fastest real-time Graph Analytics platform. One key aspect of this continuous improvement is to push this high-performance engine to its limits. Members of the Solutions Team are tasked with developing cutting edge data products for real-world applications and customers using the core TigerGraph platform tools. An ideal candidate is a passionate problem solver who fearlessly approaches a customer's \"impossible\" problems and designs exceptional, high-performance solutions that instantly become the cutting edge in real-time data analytics applications. \n \n \n  Responsibilities \n \n Lead architecture initiatives from inception to completion \n Collaborate with business users to create solutions aligned with business needs \n Write schema design, data ingestion pipeline, and Cypher or GSQL queries for customers application needs \n Write or customize graph algorithms using GSQL \n Help drive and create reusable assets to improve the efficiency \n Work on mid-range to large projects \n Documentation to aid in the understanding of the solution offerings \n Customer health checks \n Engage with pre-sales PoC/PoV to help achieve the technical win \n Contribute to a growing body of graph design and graph algorithm methodology \n \n Key Requirements \n \n B.S. in Computer science with 7 years' experience or M.S. in Computer Science with 5 year's experience \n \n Bonus Points \n \n Industry experience in software development (C++ and/or big data engineering a plus) \n Linux OS and command-line experience \n Talent for algorithm design and problem solving. \n Enthusiasm for graph algorithms and graph data structure design \n Ability to work independently, manage deadlines and set priorities \n Innovative entrepreneurial spirit to develop new business opportunities \n Passion for the start-up environment", "cleaned_desc": "", "techs": ""}, "f557b612e1ec0920": {"terms": ["machine learning engineer"], "salary_min": 137000.0, "salary_max": 163000.0, "title": "Lead SCADA & Automation Engineer -- Remote", "company": "Sargent & Lundy", "desc": "Overview:\n  \n \n  Sargent & Lundy is one of the most experienced full-service architect-engineering firms in the world. Founded in 1891, the firm is a global leader in power and energy with expertise in grid modernization, renewable energy, energy storage, nuclear power, and fossil fuels. Sargent & Lundy delivers comprehensive project services\u2014from consulting, design and implementation to construction management, commissioning and operations/maintenance\u2014with an emphasis on quality and safety. The firm serves public and private sector clients in the power and energy, gas distribution, industrial, and government sectors.\n  \n \n \n  Our Core Values \n \n \n   Every decision we make is guided by our core values. By upholding these six principles, we support our clients, employees, and community. They are the compass we follow as we continue to grow our business and lead the industry.\n  \n \n \n  Quality  \n \u2013  We provide high-quality deliverables and services through an uncompromising focus on peer review, safety, and continuous improvement.\n  \n \n \n  Accountability  \n \u2013  Our actions demonstrate the highest levels of professionalism, integrity, and respect.\n  \n \n \n  Our People  \n \u2013  We value diverse perspectives, encourage professional growth, and are committed to providing a work community where people thrive. Our work is challenging but rewarding.\n  \n \n \n  Our Clients \n  \u2013  We deliver value and exceed our clients\u2019 expectations through outstanding customer service, personal accessibility, and clear communication.\n  \n \n \n  Innovation  \n \u2013  Since 1891, we have invested in the people, training, tools, and technology needed to quickly adapt in a constantly changing world.\n  \n \n \n  Meaningful Impact  \n \u2013  We make a positive impact in the communities where we work and live.\n   Responsibilities: \n  \n  This position allows for a hybrid work schedule with a mix of work spent in office and working remote from home \n . \n \n \n \n  Automation Engineers design SCADA systems to address operational requirements & emerging trends including Smart Grid, Substation & Distribution Automation applications, Battery Energy Storage, and Microgrid controllers. As an Automation Engineer in our Electric Grid Infrastructure Services business unit you will:\n  \n \n  Engage in fast-paced client projects to plan, engineer, & design SCADA and communications systems. \n  Develop communication block diagrams, panel layout/bill of material drawings, SCADA AC & DC schematics, fiber detail drawings, & network drawings. \n  Provide reviews/design input of P&C drawings for SCADA system requirements. \n  Develop points lists for data transferred between RTUs, IEDs, and master station connections. \n  Develop configurations for Remote Terminal Units (RTUs) - (SEL RTAC, Novatech OrionLX, SMP Gateway, GE-D20, etc.) \n  Develop configurations for programmable automation controllers (PACs) \u2013 (SEL-2440/2411, etc.) \n  Program Human Machine Interface (HMI) applications (SEL Diagram Builder, Inkscape, Wonderware, etc.) \n  Coordinate with relay settings engineers to develop/review communication port settings for protection relays, meters, & other IEDs. \n  Develop network device configurations for switches, routers, & firewalls. (Cisco, Siemens Ruggedcomm, SEL, etc.) \n  Perform troubleshooting of SCADA system network & communication systems (DNP, Modbus, SEL Protocol, IEC 61850, TCP/IP, UDP) remotely and onsite (if required). \n  Develop SCADA system and Network documentation for projects. \n  Develop automation tools to improve project efficiency (python, etc.) \n  Stage, configure & test integrated systems designs, for interoperability & performance consistent with predictive models in our Protection, Automation & Telecommunication Laboratory. \n  Ensure strict adherence to NERC standards for Critical Infrastructure Protection (CIP). \n  Coordinate and provide guidance to other engineers, project managers, client personnel, and suppliers to ensure a complete and timely design. \n  Develop your career via peer-learning through sharing of knowledge with other experienced engineers by way of Sargent & Lundy\u2019s systems of process and associated \u201cCommunities of Practice.\u201d \n  Provide guidance as a mentor in the development of less experienced engineers. \n  There is the potential for you to travel to client and vendor offices as needed. \n \n \n   Dependent upon your location, this opportunity offers a generous relocation package.\n   Qualifications: \n  \n  We do not sponsor employees for work authorization in the U.S. for this position. \n \n \n \n  Essential skills and experience:\n  \n \n \n \n  Bachelor\u2019s degree in Electrical, Electronic, Telecommunications, or Computer Systems Engineering. \n  7 years of experience in design, configuration, implementation, and troubleshooting of substation SCADA and communication systems. \n  Experience with SEL, Novatech, & GE RTUs and software. \n  Basic understanding of LAN/WAN devices and topology. \n  Knowledge of DNP, Modbus, SEL, IEC-61850 (MMS/Goose) protocols \u2013 serial & IP based. \n  Proficiency with MS Office applications. \n  Ability & willingness to travel up to 30%. \n \n \n   Valued but not required skills and experience:\n  \n \n \n \n  Professional Engineering (P.E.) License. \n  Master of Science degree in Electrical, Electronic, Telecommunications, or Computer Systems Engineering. \n  Experience with communication troubleshooting software/hardware (ASE Test Set, Wireshark, etc.) \n  Protective relay settings experience (SEL, GE, ABB etc.) \n  Radio communications experience. \n  Network design credentials, applied knowledge of IP / MPLS. \n  Well versed in use of MS Project & Visio. \n  Project Management Professional (PMP). \n  Familiar with NERC Critical Infrastructure Protection (CIP) standards & Cyber-Security. \n  CISSP certification. \n \n \n  Salary Range \n \n \n \n  $137,000 - $163,000\n  \n \n \n  Benefits \n \n \n  Medical Insurance \n  Dental Insurance \n  Vision Insurance \n  Life Insurance \n  Short- & Long-Term Disability \n  Voluntary Insurance \u2013 Accident, Critical Illness, and Hospital Indemnity \n  Business Travel Insurance \n  Savings Investment Plan (401k) \n  Paid Time Off \n  Paid Holidays \n  Tuition Reimbursement \n  First Professional Licensure Monetary Award \n  Employee Assistance Program \n  Parental Benefits \n  Back-Up Care for Children & Adults \n  Merit Scholarship Program \n \n \n   Sargent & Lundy is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any protected status as defined by law.", "cleaned_desc": " \n \n  Bachelor\u2019s degree in Electrical, Electronic, Telecommunications, or Computer Systems Engineering. \n  7 years of experience in design, configuration, implementation, and troubleshooting of substation SCADA and communication systems. \n  Experience with SEL, Novatech, & GE RTUs and software. \n  Basic understanding of LAN/WAN devices and topology. \n  Knowledge of DNP, Modbus, SEL, IEC-61850 (MMS/Goose) protocols \u2013 serial & IP based. \n  Proficiency with MS Office applications. \n  Ability & willingness to travel up to 30%. \n \n \n   Valued but not required skills and experience:\n  \n \n \n \n  Professional Engineering (P.E.) License. \n  Master of Science degree in Electrical, Electronic, Telecommunications, or Computer Systems Engineering. \n  Experience with communication troubleshooting software/hardware (ASE Test Set, Wireshark, etc.) \n  Protective relay settings experience (SEL, GE, ABB etc.) \n  Radio communications experience. \n  Network design credentials, applied knowledge of IP / MPLS. \n  Well versed in use of MS Project & Visio. \n  Project Management Professional (PMP). \n  Familiar with NERC Critical Infrastructure Protection (CIP) standards & Cyber-Security. \n  CISSP certification. \n ", "techs": ["sel", "novatech", "ge rtus", "dnp", "modbus", "iec-61850", "ms office", "ase test set", "wireshark", "sel", "ge", "abb", "ip", "mpls", "ms project", "visio", "pmp", "nerc", "cissp."]}, "2d12e07dd46d8612": {"terms": ["machine learning engineer"], "salary_min": 108950.95, "salary_max": 137956.19, "title": "Cloud Security Senior Engineer - AWS/Azure/GCP (Remote - Delivery Center)", "company": "Deloitte", "desc": "Position Summary  \n \n \n \n \n \n \n \n        Are you looking to elevate your cyber career? Your technical skills? Your opportunity for growth? Deloitte\u2019s Government and Public Services Cyber Practice (GPS Cyber Practice) is the place for you! Our GPS Cyber Practice helps organizations create a cyber minded culture and become stronger, faster, and more innovative. You will become part of a team that advises, implements, and manages solutions across five verticals: Strategy, Defense and Response; Identity; Infrastructure; Data; and Application Security. Our dynamic team offers opportunities to work with cutting-edge cyber security tools and grow both vertically and horizontally at an accelerated rate. Join our cyber team and elevate your career.\n        \n \n \n  Work you\u2019ll do \n \n \n  Responsible for deploying, configuring, and maintaining security baselines within the Azure and/or AWS cloud environment. \n  Set up and manage access to cloud resources using accounts, users, and groups. He/she should be knowledgeable about potential vulnerabilities of virtual machines and container deployment systems. \n  Will drive adherence to federal and state compliance requirements by overseeing continuous monitoring activities and incident response. \n  Provides oversight over the implementation of approved security architecture/policies/procedures for a portfolio clients and engagements Initiate and conduct project security reviews to identify cloud infrastructure security risks \n  Reviews and oversee the implementation of approved recommendations on cloud security design and implementation \n  Support clients with data protection, IoT, and overarching cloud capabilities. \n  Implement core and cloud infrastructure security to manage risks and exposure. \n  Perform cyber reconnaissance to illuminate a potential attack surface area. \n  Provide threat and vulnerability management to federal clients and teams. \n  Analyze tactical network architectures and topologies to assess security risks. \n \n \n \n  The team \n \n \n         Deloitte\u2019s Government and Public Services (GPS) practice \u2013 our people, ideas, technology and outcomes\u2014is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of more than 15,000 professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise\n        \n \n         At Deloitte, we believe cyber is about starting things\u2014not stopping them\u2014and enabling the freedom to create a more secure future. Cyber Infrastructure is focused on rethinking how security is integrated across modernized infrastructure as cyber threats become more complex. If you\u2019re seeking a career implementing, architecting, and\u2014in select cases\u2014handling next generation controls to manage security risks and exposure, then the Cyber Infrastructure team at Deloitte is for you.\n        \n \n  Qualifications \n  Required: \n \n \n \n A minimum of a Bachelor\u2019s degree is required \n Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future. \n Must be able to obtain and maintain the required clearance for this role. \n Travel up to 15% \n \n Experience Requirements: \n \n  The ideal candidate must have a minimum of 3 years of experience in:\n          \n  Developing and updating cloud templates, standards, and best practices to be used by multiple cloud projects. \n  Strong foundational knowledge across Microsoft Azure, Google Cloud, and/or Amazon AWS technology stack. \n  Standardizing Azure/GCP and/or AWS Security Best practices, processes, and procedures. \n  Providing strategic and technical leadership for client teams establishing a cloud infrastructure design, migrating data centers to cloud platforms, developing infrastructure as code, or deploying cloud solutions. \n  Designing and integrating marketplace leading vulnerability management, threat management, monitoring and data protection processes and platform tools. \n  Building and operating automated security operations \n  Experience implementing Azure, GCP, and/or AWS \n  Designing and advising against security requirements to support cloud migration efforts. \n  Strong knowledge of industry trends in security technology. \n \n \n \n  Preferred: \n \n Prior professional services or federal consulting experience \n Experience with CI/CD - Deployment pipelines, and automated build and configuration tools such as Jenkins, Ansible, and terraform \n Excellent communication skills and the ability to partner and collaborate with both engineers and business users on architecture vision and security model \n A comprehensive understanding of writing KQLs, and the use of PowerShell to write queries in all cloud platform \n \n #LI-MC4 \n \n \n \n Recruiting tips \n \n  From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters. \n       \n \n \n \n Benefits \n \n  At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.\n        \n \n \n \n \n Our people and culture \n \n  Our diverse, equitable, and inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our client most complex challenges. This makes Deloitte one of the most rewarding places to work. Learn more about our inclusive culture. \n       \n \n \n \n Our purpose \n \n \n \n  Deloitte\u2019s purpose is to make an impact that matters for our clients, our people, and in our communities. We are creating trust and confidence in a more equitable society. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. We are focusing our collective efforts to advance sustainability, equity, and trust that come to life through our core commitments. Learn more about Deloitte's purpose, commitments, and impact.\n        \n \n \n \n Professional development \n \n  From entry-level employees to senior leaders, we believe there\u2019s always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career. \n       \n \n \n \n \n \n \n \n \n \n As used in this posting, \"Deloitte Advisory\" means Deloitte & Touche LLP, which provides audit and enterprise risk services; Deloitte Financial Advisory Services LLP, which provides forensic, dispute, and other consulting services; and its affiliate, Deloitte Transactions and Business Analytics LLP, which provides a wide range of advisory and analytics services. Deloitte Transactions and Business Analytics LLP is not a certified public accounting firm. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries. These entities are separate subsidiaries of Deloitte LLP. \n All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law. \n \n \n \n \n \n \n \n Requisition code: 161971", "cleaned_desc": "          \n  Developing and updating cloud templates, standards, and best practices to be used by multiple cloud projects. \n  Strong foundational knowledge across Microsoft Azure, Google Cloud, and/or Amazon AWS technology stack. \n  Standardizing Azure/GCP and/or AWS Security Best practices, processes, and procedures. \n  Providing strategic and technical leadership for client teams establishing a cloud infrastructure design, migrating data centers to cloud platforms, developing infrastructure as code, or deploying cloud solutions. \n  Designing and integrating marketplace leading vulnerability management, threat management, monitoring and data protection processes and platform tools. \n  Building and operating automated security operations \n  Experience implementing Azure, GCP, and/or AWS \n  Designing and advising against security requirements to support cloud migration efforts. \n  Strong knowledge of industry trends in security technology. \n \n \n \n  Preferred: \n \n Prior professional services or federal consulting experience \n Experience with CI/CD - Deployment pipelines, and automated build and configuration tools such as Jenkins, Ansible, and terraform \n Excellent communication skills and the ability to partner and collaborate with both engineers and business users on architecture vision and security model \n A comprehensive understanding of writing KQLs, and the use of PowerShell to write queries in all cloud platform \n \n #LI-MC4 \n \n \n \n Recruiting tips ", "techs": ["cloud templates", "standards", "best practices", "microsoft azure", "google cloud", "amazon aws", "azure/gcp", "aws security best practices", "azure", "gcp", "aws", "vulnerability management", "threat management", "monitoring", "data protection processes", "platform tools", "automated security operations", "ci/cd", "deployment pipelines", "jenkins", "ansible", "terraform", "communication skills", "engineers", "business users", "architecture vision", "security model", "kqls", "powershell"]}, "ca56105760a40b3a": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Product Manager - Geospatial", "company": "Near Space Labs", "desc": "Near Space Labs is leading the next generation of Earth imaging. We design, build and operate a fleet of proprietary, stratospheric balloons called Swiftys. Our Swiftys fly to the edge of space to deliver high quality, highly updated imagery of our planet at down to earth prices. \n  Our innovations don't stop at image capture. Customers need us to process and serve data in a format that is easily accessible for their data scientists, product managers, geographers, and remote sensing specialists. We make it easy for them to quickly and seamlessly evaluate the dynamics of our planet, climate, and urban environments. \n \n  We are looking for an intrepid, hands-on Senior Product Manager to build and execute a winning product strategy. In a startup like ours, this is one of the positions with the most impact on the company's success. This position reports directly to the COO and works closely with CTO and the Sales and Customer Success teams to build remote sensing and geospatial products that customers love. \n   Your responsibilities will be: \n \n Solidify Product-Market-Fit and establish market leadership for our imagery product; \n Project and scrum management for internal software development teams; \n Interact closely with customers, the sales team, and perform research to distill the key features and products that will drive market adoption and success; \n Provide and maintain an articulate and cohesive vision for our imagery products, APIs, machine learning and computer vision research. \n Build and own the product roadmap. \n Work closely with our data and software engineering team to prioritize features and meet deadlines; \n Provide UX/UI guidance. \n Implement test schemes to validate business and market assumptions. \n Discern the nice-to-have for the core make-or-break features and see them through no matter what; \n \n Your Skills & background \n \n 6+ years of experience in a similar product role. \n Willingness to be disruptive and do things differently. \n Experience with API products. \n Experience with Earth observation, remote sensing and geospatial industry technologies. \n Experience working with users and customers of imagery, machine learning, or GIS products. \n Experience interacting with engineers, sales, and speaking their languages. \n Excellent organizational, communication and project management skills. For real, you'll have to coordinate a lot of moving pieces. \n BA or BS degree. \n \n Location \n \n This is a remote position with preference given to NYC based candidates \n \n \n  What we offer: \n \n An exciting startup culture where you will have the opportunity to play a critical role in building and scaling a one-of-a-kind technology and organization. \n You will be part of an enthusiastic, international and motivated team of professionals who are committed to building unique technologies, being rigorous, and finding novel solutions to interesting problems. \n A diverse and inclusive workplace where we welcome people of different backgrounds, experiences and perspectives. \n A commitment that you will never be bored. \n \n Equal employment opportunity: \n  Near Space Labs is committed to diversity in our organization and building an equitable and inclusive environment for people of all backgrounds and experiences. We provide equal employment opportunities to all employees and applicants without regard to race, color, religion, gender, national origin, age, disability or genetics. \n  We especially encourage members of traditionally underrepresented communities to apply, including women, people of color, LGBTQ people, veterans, and people with disabilities.", "cleaned_desc": " Your Skills & background \n \n 6+ years of experience in a similar product role. \n Willingness to be disruptive and do things differently. \n Experience with API products. \n Experience with Earth observation, remote sensing and geospatial industry technologies. \n Experience working with users and customers of imagery, machine learning, or GIS products. \n Experience interacting with engineers, sales, and speaking their languages. ", "techs": ["api products", "earth observation", "remote sensing", "geospatial industry technologies", "imagery", "machine learning", "gis products"]}, "bfe8c3bde257ed63": {"terms": ["machine learning engineer"], "salary_min": 119000.0, "salary_max": 171000.0, "title": "IT Engineering & Technology Lead", "company": "Zoetis", "desc": "Position Summary:\n  \n \n   Zoetis, the world leader in animal health, is seeking a highly skilled and experienced IT Engineering & Technology Team Lead to join our team. In this role, you will maintain oversight of existing platform upgrades and support as well as evaluation/approval of new IT technologies for implementation within our organization. You will be responsible for managing a team of IT Engineers who focus on COTS Applications, Custom Coding, Data, and Emerging Technologies (AI, ML, IoT, VR, AR, etc.) that implement digital solutions for global research and development. The ideal candidate will possess a strong technical background, exceptional leadership abilities, an awareness of corporate finances, and excellent communication skills.\n  \n \n \n   Responsibilities:\n  \n \n   Management:\n  \n \n  Manage and mentor a team of engineers, providing guidance, support, and performance feedback. \n  Collaborate with senior management to define and manage IT budgets, resource capacity, and investment plans as well as prioritize workload to deliver on time/within budget for all approved demand. \n  Maintain IT technology roadmaps aligned with goals, strategies, and technology initiatives with global R&D long-term goals. \n \n \n   Technical:\n  \n \n  Collaborate with IT teams to implement technology solutions using existing technologies and new emerging technologies. \n  Stay abreast of emerging technologies and evaluate their potential impact on our business. \n  Ensure legacy systems stay updated to support ongoing business operations. \n \n \n   I\n  \n \n \n   The following base pay range reflects the anticipated base pay for this position if a selected candidate were to\n    be located in Colorado. Base pay may vary based on location and other factors.\n  \n \n \n   Base Pay Range: $119,000 - $171,000\n  \n \n \n   The following base pay range reflects the anticipated base pay for this position if a selected candidate were to be located in California, NJ Remote, NY Remote, or Washington. Base pay may vary based on location and\n    other factors.\n  \n \n \n   Base Pay Range: $134,000 - $193,000\n  \n \n \n   This position is eligible for short-term incentive compensation. The position is also eligible for long-term\n  \n \n   incentive.\n  \n \n \n   We offer a competitive and comprehensive benefits package, which includes healthcare, dental coverage, and\n  \n \n   retirement savings benefits along with paid holidays, vacation and disability insurance.\n  \n \n \n   Education & Experience:\n  \n \n  Bachelor\u2019s degree in Business, Computer Science, Information Systems, or related technology field \n  Advanced degrees or certifications in technology are a plus. \n  Minimum 8+ years of experience in a closely related field and role \n  Experience with emerging technologies such as AI, ML, IoT, VR, AR, etc. \n  Experience with agile development methodologies \n  Experience with cloud platforms, data analytics, and software development \n \n \n \n   Knowledge, Skills, Ability Requirements:\n  \n \n  Ability to communicate and work closely with cross-functional teams, including data scientists, developers, engineers, designers, business stakeholders, and project managers, to foster a culture of innovation, continuous learning, and delivery ownership. \n  Ability to lead and influence teams to ensure a proper balance of time and money is allocated to new and existing technologies. \n  Ability to analyze complex problems, identify suitable emerging technology solutions, and translate them into actionable plans. \n  Ability to mentor teams to grow future leaders. \n \n \n \n   Travel: Minimal, <5%\n  \n  Full time\n   Regular\n   Colleague\n  \n \n   Any unsolicited resumes sent to Zoetis from a third party, such as an Agency recruiter, including unsolicited resumes sent to a Zoetis mailing address, fax machine or email address, directly to Zoetis employees, or to Zoetis resume database will be considered Zoetis property. Zoetis will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\n  \n \n \n   Zoetis will consider any candidate for whom an Agency has submitted an unsolicited resume to have been referred by the Agency free of any charges or fees. This includes any Agency that is an approved/engaged vendor but does not have the appropriate approvals to be engaged on a search.\n  \n  Zoetis is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race, color, religion, sex, sexual orientation, age, gender identity or gender expression, national origin, disability or veteran status or any other protected classification. Disabled individuals are given an equal opportunity to use our online application system. We offer reasonable accommodations as an alternative if requested by an individual with a disability. Please contact Zoetis Colleague Services at zoetiscolleagueservices@zoetis.com to request an accommodation. Zoetis also complies with all applicable national, state and local laws governing nondiscrimination in employment as well as employment eligibility verification requirements of the Immigration and Nationality Act. All applicants must possess or obtain authorization to work in the US for Zoetis. Zoetis retains sole and exclusive discretion to pursue sponsorship for the acquisition or maintenance of nonimmigrant status and employment eligibility, considering factors such as availability of qualified US workers. Individuals requiring sponsorship must disclose this fact. Please note that Zoetis seeks information related to job applications from candidates for jobs in the U.S. solely via the following: (1) our company website at www.Zoetis.com/careers site, or (2) via email to/from addresses using only the Zoetis domain of \u201c@zoetis.com\u201d. In addition, Zoetis does not use Google Hangout for any recruitment related activities. Any solicitation or request for information related to job applications with Zoetis via any other means and/or utilizing email addresses with any other domain should be disregarded. In addition, Zoetis will never ask candidates to make any type of personal financial investment related to gaining employment with Zoetis.", "cleaned_desc": " \n   retirement savings benefits along with paid holidays, vacation and disability insurance.\n  \n \n \n   Education & Experience:\n  \n \n  Bachelor\u2019s degree in Business, Computer Science, Information Systems, or related technology field \n  Advanced degrees or certifications in technology are a plus. \n  Minimum 8+ years of experience in a closely related field and role \n  Experience with emerging technologies such as AI, ML, IoT, VR, AR, etc. \n  Experience with agile development methodologies \n  Experience with cloud platforms, data analytics, and software development \n \n \n \n   Knowledge, Skills, Ability Requirements:\n  ", "techs": ["ai", "ml", "iot", "vr", "ar", "agile development methodologies", "cloud platforms", "data analytics", "software development"]}, "788168a9295b3ecd": {"terms": ["machine learning engineer"], "salary_min": 76198.766, "salary_max": 96484.625, "title": "Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  ***This is a remote-based field position. Candidates should be located in one of the following states: Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, or Texas*** \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n Dallas \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "447b15eab8675920": {"terms": ["machine learning engineer"], "salary_min": 0.0, "salary_max": 220000.0, "title": "Solution Architect", "company": "The Wolf Works LLC", "desc": "We're looking for full-time, fully cleared Solutions Architects to help meet the rapidly growing demand for our product suite. A very competitive salary, signing bonus and retention bonus is offered with this position. \n What You'll Get To Do \n \n Conceptualize and architect the details of the delivery to customers, including: \n use-case architecture \n queries \n data schema \n documentation \n other requirements \n Engage with strategic partners to architect integrated product solutions and features \n Lead and develop lightweight customer validation exercises to include deploying ZeroReveal using Ansible. \n Provide an authoritative voice to represent company engineering thought process and domain expertise for delivery and sales motions \n Decompose customer requirements into necessary engineering tasks and work with engineering to plan tickets to implement meet those tasks \n Be a customer advocate: drive customer feedback into support and engineering \n Help transition products and features from Engineering to Sales \n Help field technical customer questions with the Sales team. \n Be a technical voice of the company, representing company to customers and customers to the engineering team \n \n What You Need To Be Successful \n \n Must be a US Citizen \n An active TS//SCI security clearance with a full scope polygraph \n 5+ years experience as a solutions architect, engineer, and/or devops engineer \n B.S. or higher degree in Computer Science or otherEngineering fields \n Willingness to travel - 25% of the time (Local travel in the Washington Metro area, CONUS, and OCONUS) \n Willingness to work in a SCIF as needed to meet with customers and satisfy delivery requirements (25 - 50%) \n Strong communication skills, both written and verbal. Willingness to work on a highly collaborative team, think on your feet, and handle live customer calls. \n Desire and ability to learn new technical skills, quickly and constantly \n Familiarity or experience with diverse technical topics including: \n Query languages \n Data storage technologies/ database design \n Cloud DevOps and Cloud services (for example: Ansible, Terraform, CloudFormation; AWS, GCP, Azure, etc.) \n Designing system architecture \n Linux system administration \n Software languages such as Java and/or Python \n Machine learning \n Security architecture and Security-oriented software development (especially on Linux) \n ETL on distributed systems (Spark, Hadoop, etc.) \n \n Benefits of working at company: \n \n A family-friendly environment that emphasizes work-life balance \n Flexible working hours; Hybrid \n Unlimited vacation time \n Monthly Wellness Days (company-wide days off) \n Generous paid parental leave policy \n Competitive compensation, including stock options \n Top-quality medical, dental, and vision insurance \n 401(k) with matching contributions and FSAs \n \n Job Type: Full-time \n Salary: Up to $220,000.00 per year \n Experience level: \n \n 5 years \n \n Application Question(s): \n \n Are you a U.S. Citizen? \n Do you have an active TS//SCI clearance with full scope polygraph? \n This position requires at least a B.S. or higher degree in Computer Science, Engineering or equivalent military experience. Do you meet this requirement? \n How many years of technical experience do you have? \n This position requires experience in the following. Please describe your experience in order of strength: \u2022 Query languages \u2022 Data storage technologies/ database design \u2022 Cloud DevOps and Cloud services (for example: Ansible, Terraform, CloudFormation; AWS, GCP, Azure, etc.) \u2022 Designing system architecture \n \n Work Location: Remote", "cleaned_desc": " Willingness to travel - 25% of the time (Local travel in the Washington Metro area, CONUS, and OCONUS) \n Willingness to work in a SCIF as needed to meet with customers and satisfy delivery requirements (25 - 50%) \n Strong communication skills, both written and verbal. Willingness to work on a highly collaborative team, think on your feet, and handle live customer calls. \n Desire and ability to learn new technical skills, quickly and constantly \n Familiarity or experience with diverse technical topics including: \n Query languages \n Data storage technologies/ database design \n Cloud DevOps and Cloud services (for example: Ansible, Terraform, CloudFormation; AWS, GCP, Azure, etc.) \n Designing system architecture \n Linux system administration \n Software languages such as Java and/or Python \n Machine learning ", "techs": ["query languages", "data storage technologies/ database design", "cloud devops and cloud services (ansible", "terraform", "cloudformation; aws", "gcp", "azure)", "designing system architecture", "linux system administration", "software languages (java", "python)", "machine learning"]}, "ba12074f15e6ad92": {"terms": ["machine learning engineer"], "salary_min": 116937.53, "salary_max": 148068.97, "title": "Cybersecurity Engineer - Splunk", "company": "Xcelerate Solutions", "desc": "Xcelerate Solutions is seeking a Cybersecurity Engineer \u2013 Splunk that can correlate threat data from various sources to establish the identity and modus operandi of hackers active in client\u2019s networks and posing a potential threat. Provides the customer with assessments and reports facilitating situational awareness and understanding of current cyber threats and adversaries. Develops cyber threat profiles based on geographic region, country, group, or individual actors. Produces cyber threat assessments based on entity threat analysis. May provide computer forensic and intrusion support to high technology investigations in the form of computer evidence seizure, computer forensic analysis, data recovery, and network assessments. Researches and maintains proficiency in tools, techniques, countermeasures, and trends in computer network vulnerabilities, data hiding and network security and encryption. Come join our award-winning organization and work with some of the most talented and brightest minds in the GovCon industry. \n  Location:  Quantico, VA (telework flexibility at customer discretion) \n  Security Clearance:  Secret \n  Responsibilities: \n \n  Collaborates with intrusion analysts to identify, report on, and coordinate remediation of cyberthreats to the client \n  Provides timely and actionable sanitized intelligence to cyber incident response professionals \n  Leverages technical knowledge of computer systems and networks with cyber threat information to assess the client\u2019s security posture \n  Conducts intelligence analysis to assess intrusion signatures, tactics, techniques, and procedures associated with preparation for and execution of cyber-attacks \n  Research hackers, hacker techniques, vulnerabilities, exploits, and provides detailed briefings and intelligence reports to leadership \n  Coordinates with the Cyber Security and Operations teams to build dashboards and queries to assist with threat detection and incident response \n  Participates in developing security-focused content for Splunk implementations across multiple network classifications on Department of Defense (DoD) networks \n  Assists with designing log management and data ingest solutions while ensure efficiency and scalability \n  Supports the development of automation and scripting directly supporting data/threat analysis \n  Implements and manages Splunk add-ons to enhance capabilities to include advanced threat detection and machine learning \n  Supports the A&A authorization of the Splunk environment \n  Monitors system recovery processes to ensure security features and functions are properly restored and functioning correctly following outages \n  Supports implementation efforts for response/actions addressing operational and communication orders from governing organizations \n  Provides expert analysis of logs/alerts/records to prevent or detect anomalies or adverse events \n  Supports the Government in the enforcement of suspected malicious activity \n  Participates in the change management process, including reviewing Change Requests and assisting in the assessment of security impact of proposed changes \n  Works on project teams responsible for engineering and packaging releases to integrate within the customer\u2019s production IT environment \n  Guides and advises government customer with Splunk best practice solutions and configurations \n  Supports a growing Cybersecurity team with occasional training evolutions \n  Supports RMF compliance requirements by analyzing processes and recommending solutions \n  Communicates well, both written and verbally \n  Other duties as assigned; associated with and/or in support of your primary role or program mission \n \n  Minimum Requirements: \n \n  Active Secret clearance: TS/SCI is highly preferred \n  DoD 8570 (IAT II Level) certification \n  Position requires on-site support at Quantico, VA with telework flexibility at customer\u2019s discretion \n  High School with 10+ years (or commensurate experience) \n  5+ years of managing Splunk and SIEM systems \n  2+years of security engineering experience working with DoD IT systems and solutions \n  1+ years of experience with application and OS logging \n  Experienced with Splunk Enterprise operations to include:\n    \n  Configuration and system tuning \n  Alert and report creation \n  Deployment scaling \n  User Based Analytics implementation and review \n \n \n  Preferred Qualifications: \n \n  Active Splunk certification highly preferred (Architect/Developer level) \n  Familiar with Splunk Enterprise operations to include:\n    \n  Overall enterprise deployment and implementation \n  Endpoint troubleshooting \n  Splunk account management \n  Deployment scaling \n  DoD STIG dashboard creation \n \n  ATO of Splunk systems in DoD packages \n \n  About   Xcelerate   Solutions :  Founded in 2009 and headquartered in McLean, VA, Xcelerate Solutions (www.xceleratesolutions.com) is one of America's fastest-growing companies. Xcelerate\u2019s culture is defined by our diversified workforce of dynamic and versatile professionals, supported with growth and development opportunities that contribute to individual and company growth. This strong commitment to our employees has been recognized by our inclusion on the Washington Business Journal\u2019s \u201c50 Best Places to Work\u201d list as well as being a \u201cGreat Place to Work\u201d certified company with a 4.6 star, and a 99% CEO approval Glassdoor rating. Come find out why Xcelerate Solutions is one of the DC Metro top employers! \n  Xcelerate Solutions is an Equal Employment Opportunity/Affirmative Action Employer. We evaluate qualified applicants without regard to race, color, national origin, religion, age, equal pay, disability, veteran status, sex, sexual orientation, gender identity, genetic information, or expression of another protected characteristic. As part of this commitment to the full inclusion of all qualified individuals, Xcelerate provides reasonable accommodations if needed because of an applicant's or an employee's disability. \n  Pay Transparency Notice: Xcelerate Solutions will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant.", "cleaned_desc": "  Assists with designing log management and data ingest solutions while ensure efficiency and scalability \n  Supports the development of automation and scripting directly supporting data/threat analysis \n  Implements and manages Splunk add-ons to enhance capabilities to include advanced threat detection and machine learning \n  Supports the A&A authorization of the Splunk environment \n  Monitors system recovery processes to ensure security features and functions are properly restored and functioning correctly following outages \n  Supports implementation efforts for response/actions addressing operational and communication orders from governing organizations \n  Provides expert analysis of logs/alerts/records to prevent or detect anomalies or adverse events \n  Supports the Government in the enforcement of suspected malicious activity \n  Participates in the change management process, including reviewing Change Requests and assisting in the assessment of security impact of proposed changes \n  Works on project teams responsible for engineering and packaging releases to integrate within the customer\u2019s production IT environment \n  Guides and advises government customer with Splunk best practice solutions and configurations \n  Supports a growing Cybersecurity team with occasional training evolutions ", "techs": ["splunk", "machine learning"]}, "3d46ffe26bcf8e07": {"terms": ["machine learning engineer"], "salary_min": null, "salary_max": null, "title": "Senior Product Manager, AI Incubation - Remote", "company": "Sorenson Communications, LLC", "desc": "Job Summary \n  Sorenson is seeking a seasoned and entrepreneurial product creator to drive rapid value creation to defend and grow the company\u2019s existing businesses in accessibility and language services, as well as grow into new markets, customers, and categories. The Incubation team consists of specialized Product Managers, UX Designers and Researchers, and Engineers who excel at zero-to-one, early-stage work. The mandate is fast learning and fast failure, as opposed to painstakingly crafting optimized experiences \u2014 although job rotation may be available to support professional development. \n \n \n  You will own opportunity analysis, product vision, competitive strategy, customer discovery, concept definition, GTM design, and oversight of customer or user testing. You will collaborate with UX Research on customer and user research and solution validation, and UX Design and Engineering on delivering and deploying a working Proof of Concept for each project. The capstone of each incubation cycle is bringing all the team has learned together into a business case and recommendation to leadership. Your focus will be on Generative AI (Artificial Intelligence), and building products that incorporate Large Language Models, Machine Learning, and Natural Language Processing. \n \n \n  Essential Duties and Responsibilities \n \n Product Vision: define the vision and strategy based on a deep understanding of customer and user needs, user research, the competitive landscape, and the company\u2019s business goals. \n Continuous Discovery: collect and use customer and user signals and research to identify knowledge gaps, define product capabilities, and market justification. \n Definition: create and communicate a clear, coherent, data-driven set of requirements for the Proof of Concept that enable the team to learn what it needs to learn from customers or users. \n Co-creation: collaborate with your Core Team (Product, Design, Engineering), as well as AI Labs (R&D), Marketing, Sales, Business Development, Legal, and external partners. \n Crosspollination: collaborate with teams across Sorenson to leverage best-in-class technology from across the company, and share what we\u2019ve pioneered with other product teams in need \n Schedule Accountability: negotiate and influence tradeoffs impacting schedule, and share good news fast; bad news faster. \n Performance Management: develop and set metrics, analytics, and hurdle rates to help the team and company achieve desired outcomes. \n Other duties as assigned. \n \n \n \n  Supervisory Responsibility \n  This position has no supervisory responsibilities. \n \n \n  Travel Requirements \n  Travel Requirements: Less than 25% \n \n \n  Education \n  Minimum: 4 Year / Bachelors Degree in business, engineering, marketing, or equivalent professional experience \n  Preferred: Graduate Degree MBA or similar Masters degree \n \n \n  Experience \n  Minimum Years of Experience: 6 years software product management experience with LLM, ML or NLP strongly preferred \n \n \n  Knowledge, Skills, and Abilities \n \n Ability to take a project from scratch to delivery while navigating ambiguity \n Curious, with a desire to learn and grow, and able to quickly adapt to new technologies and tasks \n Performance mindset with ability to self-measure goals and progress \n Experience moving fast with an entrepreneurial mindset \n Excellent verbal and written communication skills, ability to communicate to audiences at all levels, and ability to build relationships with a distributed team \n Positive attitude, team player, and able to work across company departments. \n Experience with Agile, Scrum, and Lean Startup methodologies \n Prior startup or early-stage experience a plus \n Familiarity with software architecture, interfaces, and engineering principles a plus \n \n \n \n  Working Conditions and Physical Requirements \n \n Ability to sit and/or stand at a desk and work with a computer for extended periods of time. \n Dexterity of hands and fingers to operate a computer keyboard, mouse, tools, and to handle other computer components. \n Regular and predictable attendance required. \n \n \n \n  Disclaimer \n  This position has access to highly confidential, sensitive information relating to the employees, customers, and technologies of Sorenson Communications and CaptionCall. It is essential that applicant possess the requisite integrity to maintain the information in strictest confidence. \n \n \n  Apply at www.captioncall.com/careers \n  Apply today! www.sorensonvrs.com/svrs_careers \n \n \n  Equal Employment Opportunity: \n  CaptionCall and Sorenson Communications are an EOE, Disability/Age Employer. \n \n \n  Company Summary \n  Our Mission\u2026Harnessing the power of language, we connect diverse people and enrich the human experience. \n  Our Vision\u2026To provide global language services that expand opportunities, nurture belonging, and empower the world to connect beyond words. \n  As one of the world\u2019s leading language services providers, Sorenson combines patented technology with human-centric solutions. We strive to increase diversity, equity, inclusion, and accessibility for underrepresented people through communication solutions for all: call captioning and video relay services, over-video and in-person sign language and spoken language interpreting, translation, real-time captioning, and post-production language services. \n  Sorenson\u2019s impact vision and plan extends to supporting employment opportunities for diverse employees, customers, and communities. As a minority-owned company, we are committed to expanding opportunities for underserved communities while promoting an inclusive workplace for our own employees. \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities \n  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor\u2019s legal duty to furnish information. 41 CFR 60-1.35(c)", "cleaned_desc": "  Preferred: Graduate Degree MBA or similar Masters degree \n \n \n  Experience \n  Minimum Years of Experience: 6 years software product management experience with LLM, ML or NLP strongly preferred \n \n \n  Knowledge, Skills, and Abilities \n \n Ability to take a project from scratch to delivery while navigating ambiguity \n Curious, with a desire to learn and grow, and able to quickly adapt to new technologies and tasks \n Performance mindset with ability to self-measure goals and progress \n Experience moving fast with an entrepreneurial mindset \n Excellent verbal and written communication skills, ability to communicate to audiences at all levels, and ability to build relationships with a distributed team \n Positive attitude, team player, and able to work across company departments.   Experience with Agile, Scrum, and Lean Startup methodologies \n Prior startup or early-stage experience a plus \n Familiarity with software architecture, interfaces, and engineering principles a plus \n \n \n \n  Working Conditions and Physical Requirements \n \n Ability to sit and/or stand at a desk and work with a computer for extended periods of time. \n Dexterity of hands and fingers to operate a computer keyboard, mouse, tools, and to handle other computer components. \n Regular and predictable attendance required. \n \n \n \n  Disclaimer ", "techs": ["mba", "llm", "ml", "nlp", "agile", "scrum", "lean startup methodologies"]}, "7ae7984955f2b4a5": {"terms": ["machine learning engineer"], "salary_min": 200000.0, "salary_max": 225000.0, "title": "Senior Team Lead - Controls Embedded Software - Autonomous Vehicles (Remote)", "company": "Motional", "desc": "The Embedded Software Controls team delivers robust high performance software on real-time embedded compute platform. Supporting different vehicle platforms provided by OEMs, embedded controller hardware bring up, and safety features. Including system health monitoring, backup strategy when failure happens, redundant system design to meet ASIL-D standards for autonomous driving at scale. Motional builds state-of-the-art fully autonomous vehicles, encompassing software, hardware, vehicle, and cloud solutions for cars. We specialize in robo-taxis for passenger rides and goods delivery, currently operating in Las Vegas. \n  Role responsibilities: \n \n Leads and grows an Embedded Software team to deliver autonomous driving vehicle control systems from design, prototyping, testing, deployment, to production. \n Provide technical leadership to make consequential decisions on architectural direction, strategic investments, tactical execution, and technical debt reduction. \n Oversees the development and optimization of critical platform control components such as body control, sensor cleaning, temperature control, and vehicle monitoring. \n Identifies and reviews technical requirements in collaboration with partnering teams, such as Systems Engineering and Safety, to drive completion of features and projects. \n Leads from a strong technical background in embedded software engineering best practices. \n Coordinate with Motional partners and suppliers for the purpose of vehicle platform bring up and next generation platform design. \n Mentors, provides feedback (technical and professional) to team members, and collaborates with project managers to roadmap and execute plans on schedule. \n Understands and explains trade-offs and complex concepts to peers and leaders to drive decision-making. \n Self-motivation to generate new ideas, and provide a vision for the team and our system. \n \n What we're looking for: \n \n Experience leading a team of 5+ Engineers in a value-driven organization \n 5+ years of experience implementing vehicle controllers utilizing both classical and modern control theory. \n Masters or PhD in Robotics, Computer Science, Electrical Engineering, Computer Engineering, Mechanical Engineering, or related field.. \n Expertise in Embedded C development and C++ within a large codebase. \n Experience successfully launching a new product into the commercial market. \n Preference for candidates with an understanding of linear and nonlinear control theory (MPC, LQR, PID, etc.), kinematics, and mechanical system dynamics. \n Experience in the designing, implementing, and tuning real-time trajectory tracking controllers for vehicle control. \n Experience with vehicle control algorithms in autonomous vehicles, including both on-road and simulation testing. \n Experience in implementing, using, and debugging high-fidelity dynamical simulators \n Experience in system identification and model development using machine learning methods. \n Familiarity with the AUTOSAR development environment \n Familiarity with Vector tools such as CANalyzer, CANape, CANoe. \n Familiarity with Automotive SPICE, MISRA C, ASIL-B & D and ISO 26262 requirements. \n \n \n \n \n  The salary range for this role is an estimate based on a wide range of compensation factors including but not limited to specific skills, experience and expertise, role location, certifications, licenses, and business needs. The estimated compensation range listed in this job posting reflects base salary only. This role may include additional forms of compensation such as a bonus or company equity. The recruiter assigned to this role can share more information about the specific compensation and benefit details associated with this role during the hiring process. \n  Candidates for certain positions are eligible to participate in Motional\u2019s benefits program. Motional\u2019s benefits include but are not limited to medical, dental, vision, 401k with a company match, health saving accounts, life insurance, pet insurance, and more. \n \n  Salary Range \n \n    $200,000\u2014$225,000 USD\n   \n \n \n  Motional is a driverless technology company making autonomous vehicles a safe, reliable, and accessible reality. We're driven by something more. \n  Our journey is always people first. \n  We aren't just developing driverless cars; we're creating safer roadways, more equitable transportation options, and making our communities better places to live, work, and connect. Our team is made up of engineers, researchers, innovators, dreamers and doers, who are creating a technology with the potential to transform the way we move. \n  Higher purpose, greater impact. \n  We're creating first-of-its-kind technology that will transform transportation. To do so successfully, we must design for everyone in our cities and on our roads. We believe in building a great place to work through a progressive, global culture that is diverse, inclusive, and ensures people feel valued at every level of the organization. Diversity helps us to see the world differently; it's not only good for our business, it's the right thing to do. \n  Scale up, not starting up. \n  Our team is behind some of the industry's largest leaps forward, including the first fully-autonomous cross-country drive in the U.S, the launch of the world's first robotaxi pilot, and operation of the world's longest-standing public robotaxi fleet. We're driven to scale; we're moving towards commercialization of our technology, and we need team members who are ready to embrace change and challenges. \n  Formed as a joint venture between Hyundai Motor Group and Aptiv, Motional is fundamentally changing how people move through their lives. Headquartered in Boston, Motional has operations in the U.S and Asia. For more information, visit www.Motional.com and follow us on Twitter, LinkedIn, Facebook, Instagram and YouTube. \n \n \n  Motional AD Inc. is an EOE. We celebrate diversity and are committed to creating an inclusive environment for all employees. To comply with Federal Law, we participate in E-Verify. All newly-hired employees are queried through this electronic system established by the DHS and the SSA to verify their identity and employment eligibility.", "cleaned_desc": "The Embedded Software Controls team delivers robust high performance software on real-time embedded compute platform. Supporting different vehicle platforms provided by OEMs, embedded controller hardware bring up, and safety features. Including system health monitoring, backup strategy when failure happens, redundant system design to meet ASIL-D standards for autonomous driving at scale. Motional builds state-of-the-art fully autonomous vehicles, encompassing software, hardware, vehicle, and cloud solutions for cars. We specialize in robo-taxis for passenger rides and goods delivery, currently operating in Las Vegas. \n  Role responsibilities: \n \n Leads and grows an Embedded Software team to deliver autonomous driving vehicle control systems from design, prototyping, testing, deployment, to production. \n Provide technical leadership to make consequential decisions on architectural direction, strategic investments, tactical execution, and technical debt reduction. \n Oversees the development and optimization of critical platform control components such as body control, sensor cleaning, temperature control, and vehicle monitoring. \n Identifies and reviews technical requirements in collaboration with partnering teams, such as Systems Engineering and Safety, to drive completion of features and projects. \n Leads from a strong technical background in embedded software engineering best practices. \n Coordinate with Motional partners and suppliers for the purpose of vehicle platform bring up and next generation platform design. \n Mentors, provides feedback (technical and professional) to team members, and collaborates with project managers to roadmap and execute plans on schedule.   Preference for candidates with an understanding of linear and nonlinear control theory (MPC, LQR, PID, etc.), kinematics, and mechanical system dynamics. \n Experience in the designing, implementing, and tuning real-time trajectory tracking controllers for vehicle control. \n Experience with vehicle control algorithms in autonomous vehicles, including both on-road and simulation testing. \n Experience in implementing, using, and debugging high-fidelity dynamical simulators \n Experience in system identification and model development using machine learning methods. \n Familiarity with the AUTOSAR development environment \n Familiarity with Vector tools such as CANalyzer, CANape, CANoe. \n Familiarity with Automotive SPICE, MISRA C, ASIL-B & D and ISO 26262 requirements. \n \n ", "techs": ["embedded software controls", "oems", "asil-d standards", "robo-taxis", "las vegas", "autonomous driving", "design", "prototyping", "testing", "deployment", "production", "architectural direction", "strategic investments", "tactical execution", "technical debt reduction", "platform control components", "systems engineering", "safety", "embedded software engineering best practices", "motional partners", "vehicle platform bring up", "linear control theory", "nonlinear control theory", "mpc", "lqr", "pid", "kinematics", "mechanical system dynamics", "real-time trajectory tracking controllers", "vehicle control algorithms", "on-road testing", "simulation testing", "high-fidelity dynamical simulators", "system identification", "model development", "machine learning methods", "autosar development environment", "vector tools", "canalyzer", "canape", "canoe", "automotive spice", "misra c", "iso 26262 requirements."]}, "b9a8d12a67b7fff0": {"terms": ["machine learning engineer"], "salary_min": 116014.57, "salary_max": 146900.3, "title": "Cloud Identity Engineer", "company": "Genworth", "desc": "At Genworth, we empower families to navigate the aging journey with confidence. We are compassionate, experienced allies for those navigating care with guidance, products, and services that meet families where they are. Further, we are the spouses, children, siblings, friends, and neighbors of those that need care\u2014and we bring those experiences with us to work in serving our millions of policyholders each day. \n  We apply that same compassion and empathy as we work with each other and our local communities.  Genworth values all perspectives, characteristics, and experiences so that employees  can bring their full, authentic selves to work to help each other and our company succeed.  We celebrate our diversity and understand that being intentional about inclusion is the only way to create a sense of belonging for all associates. We also invest in the vitality of our local communities through  grants from the Genworth Foundation, event sponsorships, and employee volunteerism. \n  Our four values guide our strategy, our decisions, and our interactions: \n \n  Make it human.  We care about the people that make up our customers, colleagues, and communities. \n  Make it about others.  We do what's best for our customers and collaborate to drive progress. \n  Make it happen.  We work with intention toward a common purpose and forge ways forward together. \n  Make it better.  We create fulfilling purpose-driven careers by learning from the world and each other. \n \n   \n  POSITION TITLE \n  Cloud Identity Management Engineer     LOCATION   Remote     YOUR ROLE   Genworth is embarking on an ambitious cloud transformation journey and are looking to hire a Cloud Identity Engineer to play an important role in the Cloud Center of Excellence (CCoE) and the overall success of the transformation.     The Engineer is responsible for designing the overall IAM strategy for the organization both \u2018of\u2019 the cloud and \u2018in\u2019 the cloud. They work with various teams to ensure that the IAM system is appropriately integrated and meets all security and compliance requirements.  \n   The candidate for this role should be a big picture thinker and a highly skilled engineering leader, who is a problem-solver and has a deep passion for creating and building integrated solutions that combine technology with automation and governance to deliver value. \n    What you will be doing \n \n Act as the subject matter expert for all cloud IAM related queries, challenges, and architectural decisions \n Develop strategy for migrating both customer and workforce user stores and management tools to cloud native solutions \n Design and implement authN/authZ controls for all cloud assets including web applications, databases, API\u2019s, and cloud control planes  \n Develop and maintain \u2018Break Glass\u2019 access procedures \n Assist in migrating secrets management and PAM capabilities to cloud \n Create a strategy for and build mechanisms for Just-In-Time access controls for both human and machine identities Provide Identity and access management advisory, solution architecture, and consulting to internal projects of varying size \n Provide architecture to integrate IAM systems with in-house and third-party applications for provisioning, identity authentication, developing connectors between IAM tools and systems resources, and system resource authorization \n Advocate secure computing practices and procedures and communicate Information Security and IAM best practices throughout the company \n Address uncommon and complex IAM challenges to meet unique organizational requirements. \n \n  What you bring \n \n Bachelor\u2019s degree and minimum 5+ years\u2019 experience or significant equivalent work experience \n In-depth experience with Amazon Web Services solution, architecture, related technologies, and their interdependencies \n Strong understanding of IAM concepts and best practices in Cloud \n Excellent knowledge of IAM software, such as Azure Active Directory, PingFederate, Okta \n Understand the various IAM tools and technologies available and be able to recommend solutions that will meet the company\u2019s needs \n Experience with Infrastructure as Code such as Terraform \n Work effectively with other IT team members to ensure that IAM solutions are integrated seamlessly into the overall IT infrastructure. \n Knowledge of Information Security principles and ability to adhere to SSAE16 and SOX audit requirements pertaining to Identity & Access Management job requirements \n Understands the long-term (\"big picture\") and short-term perspectives of situations. \n Deep understanding of cloud security aspects and tools and their integration with applications. \n Exceptional interpersonal skills and leadership skills \n Excellent planning and organizational skills \n Ability to apply multiple technical solutions to business problems \n Ability to quickly comprehend the functions and capabilities of new technologies \n \n  Employee Benefits & Well-Being \n  Genworth employees make a difference in people\u2019s lives every day. We\u2019re committed to making a difference in our employees\u2019 lives. \n \n  Competitive Compensation & Total Rewards Incentives \n  Comprehensive Healthcare Coverage \n  Multiple 401(k) Savings Plan Options \n  Auto Enrollment in Employer-Directed Retirement Account Feature (100% employer-funded!) \n  Generous Paid Time Off \u2013 Including 12 Paid Holidays, Volunteer Time Off and Paid Family Leave \n  Disability, Life, and Long Term Care Insurance \n  Tuition Reimbursement, Student Loan Repayment and Training & Certification Support \n  Wellness support including gym membership reimbursement and Employee Assistance Program resources (work/life support, financial & legal management) \n  Caregiver and Mental Health Support Services", "cleaned_desc": " Excellent knowledge of IAM software, such as Azure Active Directory, PingFederate, Okta \n Understand the various IAM tools and technologies available and be able to recommend solutions that will meet the company\u2019s needs \n Experience with Infrastructure as Code such as Terraform \n Work effectively with other IT team members to ensure that IAM solutions are integrated seamlessly into the overall IT infrastructure. \n Knowledge of Information Security principles and ability to adhere to SSAE16 and SOX audit requirements pertaining to Identity & Access Management job requirements \n Understands the long-term (\"big picture\") and short-term perspectives of situations. \n Deep understanding of cloud security aspects and tools and their integration with applications. \n Exceptional interpersonal skills and leadership skills \n Excellent planning and organizational skills \n Ability to apply multiple technical solutions to business problems ", "techs": ["azure active directory", "pingfederate", "okta", "terraform", "ssae16", "sox"]}, "9efc9a9448692a85": {"terms": ["machine learning engineer"], "salary_min": 76610.5, "salary_max": 97005.97, "title": "Copy of Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  ***This is a remote-based field position. Candidates should be located in one of the following states: Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, or Texas*** \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n Miami \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "6c6da9c63f9733d3": {"terms": ["machine learning engineer"], "salary_min": 75515.96, "salary_max": 95620.04, "title": "Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  ***This is a remote-based field position. Candidates should be located in one of the following states: Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, or Texas*** \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n Tampa \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "8656382692c85dd0": {"terms": ["machine learning engineer"], "salary_min": 116918.18, "salary_max": 148044.47, "title": "Back-End Engineer - Ruby and Ruby on Rails (RoR)", "company": "Mozilla", "desc": "To learn the Hiring Ranges for this position, please select your location from the  Apply Now  dropdown menu. \n  To learn more about our Hiring Range System, please click this  link. \n  Why Mozilla? \n  Mozilla Corporation is the non-profit-backed technology company behind pioneering brands like Firefox, the privacy-minded web browser, and Pocket,  a service for keeping up with the best articles online . More than  225  million people around the world use its products each month. \n  Along with  60,000 + volunteer contributors and collaborators all over the world, Mozilla Corporation's staff are driven by our mission  to ensure the Internet is a global public resource, open and accessible to all . We design, build and distribute  open-source  software that enables people to enjoy the internet on their terms. \n  About this team and role: \n  Fakespot is now part of Mozilla, where our mission to bring trust and transparency back to the eCommerce space is now aligned with ensuring the Internet is a global resource, open and accessible to all. Fakespot leverages machine learning and other state-of-the-art technologies to automatically filter out spurious reviews of products and vendors so consumers can make informed purchasing decisions based on real feedback by real people. We are looking for a mid-level engineer to join the Fakespot team within Mozilla. \n  What you'll do: \n \n Creating robust, scalable, highly loaded applications \n Maintaining and troubleshooting existing applications \n Identifying and fixing bottlenecks and bugs \n Maintaining and expanding APIs \n \n What you'll bring: \n \n Minimum 2 years of professional work experience with Ruby and Ruby on Rails \n Excellent learning ability \n Ability to write efficient algorithms, and clean code \n Knowledge of relational databases such as PostgreSQL and MySQL \n Experience working with Sidekiq, RSpec and other common RoR libraries \n Working knowledge of Git, Docker \n Good knowledge of full stack web development \n Commitment to our values: \n \n Welcoming differences \n Being relationship-minded \n Practicing responsible participation \n Having grit \n \n \n Bonus Points for\u2026 \n \n Golang, Python, Kubernetes deployments \n Working with high traffic systems \n Background processing experience \n \n What you'll get: \n \n Generous performance-based bonus plans to all regular employees - we share in our success as one team \n Rich medical, dental, and vision coverage \n Generous retirement contributions with 100% immediate vesting (regardless of whether you contribute) \n Quarterly all-company wellness days where everyone takes a pause together \n Country specific holidays plus a day off for your birthday \n One-time home office stipend \n Annual professional development budget \n Quarterly well-being stipend \n Considerable paid parental leave \n Employee referral bonus program \n Other benefits (life/AD&D, disability, EAP, etc. - varies by country) \n \n About Mozilla \n  Mozilla exists to build the Internet as a public resource accessible to all because we believe that open and free is better than closed and controlled. When you work at Mozilla, you give yourself a chance to make a difference in the lives of Web users everywhere. And you give us a chance to make a difference in your life every single day. Join us to work on the Web as the platform and help create more opportunity and innovation for everyone online. \n  Commitment to diversity, equity, inclusion, and belonging \n  Mozilla understands that valuing diverse creative practices and forms of knowledge are crucial to and enrich the company's core mission. We encourage applications from everyone, including members of all equity-seeking communities, such as (but certainly not limited to) women, racialized and Indigenous persons, persons with disabilities, persons of all sexual orientations, gender identities, and expressions. \n  We will ensure that qualified individuals with disabilities are provided reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment, as appropriate. Please contact us at hiringaccommodation@mozilla.com to request accommodation. \n  We are an equal opportunity employer. We do not discriminate on the basis of race (including hairstyle and texture), religion (including religious grooming and dress practices), gender, gender identity, gender expression, color, national origin, pregnancy, ancestry, domestic partner status, disability, sexual orientation, age, genetic predisposition, medical condition, marital status, citizenship status, military or veteran status, or any other basis covered by applicable laws. Mozilla will not tolerate discrimination or harassment based on any of these characteristics or any other unlawful behavior, conduct, or purpose. \n  Group: E \n  #LI-DNI \n  Req ID: R2295", "cleaned_desc": " Identifying and fixing bottlenecks and bugs \n Maintaining and expanding APIs \n \n What you'll bring: \n \n Minimum 2 years of professional work experience with Ruby and Ruby on Rails \n Excellent learning ability \n Ability to write efficient algorithms, and clean code \n Knowledge of relational databases such as PostgreSQL and MySQL \n Experience working with Sidekiq, RSpec and other common RoR libraries \n Working knowledge of Git, Docker ", "techs": ["identifying and fixing bottlenecks and bugs", "maintaining and expanding apis", "ruby", "ruby on rails", "learning ability", "efficient algorithms", "clean code", "relational databases", "postgresql", "mysql", "sidekiq", "rspec", "ror libraries", "git", "docker"]}, "4543dccd9b13eee5": {"terms": ["machine learning engineer"], "salary_min": 75558.8, "salary_max": 95674.266, "title": "Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n Atlanta \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "1cf25a9eed72b53b": {"terms": ["machine learning engineer"], "salary_min": 92095.695, "salary_max": 116613.68, "title": "Technical Support Engineer", "company": "TigerGraph", "desc": "TigerGraph is a platform for advanced analytics and machine learning on connected data. TigerGraph's core technology is the only scalable graph database for the enterprise. Its proven technology supports fraud detection, customer 360, MDM, IoT, AI, and machine learning.\n    Fortune 500 organizations and the most innovative mid-size and startup companies choose TigerGraph to accelerate their analytics, AI, and machine learning:\n  \n \n Seven out of the top ten global banks use TigerGraph for real-time fraud detection. \n Over 50 million patients receive care path recommendations to assist them on their wellness journey. \n 300 million consumers receive personalized offers with recommendation engines powered by TigerGraph. \n TigerGraph reduces power outages by optimizing the energy infrastructure for 1 billion people. \n \n We are looking for a highly motivated and experienced Technical Support Engineer to join our US team to support rapidly growing demand from enterprise customers (Global 1000) to deploy TigerGraph's award-winning graph database platform and solutions. The ideal candidate should have experience with Graph Databases or NoSQL databases, distributed systems, cloud platforms (such as Azure, AWS, GCP), scripting skills, Kubernetes and advanced debugging and troubleshooting skills.     Responsibilities \n \n \n Responding to Customers' inquiries and providing in-depth technical and high-quality support via phone, email, or chat. \n Troubleshooting and resolving technical issues that span from the product itself to the Customer environment. \n Collaborate with other teams (core engineering and solution engineering) to diagnose and resolve complex customer issues. \n Partner with the Customer Success, Sales, and Product teams to drive business to success \n Participate in on-call rotation shift \n Educate customers on best practices for adopting and using TigerGraph \n Create and maintain public documentation, knowledge articles (internal and Customer facing), and FAQs. Keep improving product knowledge and keeping up with business trends. \n Support/Operations Experience \n Oncall rotation, documentation creation, meeting/monitoring SLAs \n \n Requirements \n \n \n Bachelor's degree required. \n At least 3+ years of experience in technical support or related work. (No service desk) \n \n Skills & Knowledge \n \n \n Big data/data ecosystem experience \n \n Technologies: Hadoop, MapReduce, Spark, Airflow, Beam, Kafka, Zookeeper \n Concepts: Data warehousing, data analytics, ETL \n \n Distributed systems experience \n \n Kubernetes, above listed big data technology \n \n Database experience \n \n Any familiarity or experience with databases, preferably distributed ones such as Hive, BigQuery, AWS KMS, Cassandra, BigTable \n \n Programming/scripting skills \n \n Bash, Go, Java, C++, Python preferred \n Terraform, Ansible \n \n Customer facing technical experience \n \n Any of support, consulting, tech writing, solutions architecture, anything where candidate is communicating technical info to customers \n Customer-focus mindset \n Strong problem-solving and troubleshooting skills \n \n Technical skills: \n \n Prior experience working with graph technology is a big plus \n Linux fundamentals knowledge (processes, filesystem, memory management, networking, configuration, security), network troubleshooting (ex. TCP/IP, load balancing), web troubleshooting (HTTP, SSL, REST APIs)  \n \n \n Additional Skills As a Big Bonus \n \n \n Familiar with HW/SW stacks for large-scale enterprise graph databases or NoSQL databases on-prem and/or on the cloud. \n Experience with LDAP, OAuth \n Experience with a Graph Database is a big plus \n Experience with SaaS solutions \n Understanding of how database systems work under the hood \n \n The anticipated salary range for candidates who will work in Redwood City, CA is $70,000 - $110,000. The final salary offered to a successful candidate will be dependent on several factors that may include, but are not limited to, the type and length of experience within the job, type and length of experience within the industry, education, etc. TigerGraph is a multi-state employer and this salary range may not reflect positions that work in other states.", "cleaned_desc": "TigerGraph is a platform for advanced analytics and machine learning on connected data. TigerGraph's core technology is the only scalable graph database for the enterprise. Its proven technology supports fraud detection, customer 360, MDM, IoT, AI, and machine learning.\n    Fortune 500 organizations and the most innovative mid-size and startup companies choose TigerGraph to accelerate their analytics, AI, and machine learning:\n  \n \n Seven out of the top ten global banks use TigerGraph for real-time fraud detection. \n Over 50 million patients receive care path recommendations to assist them on their wellness journey. \n 300 million consumers receive personalized offers with recommendation engines powered by TigerGraph. \n TigerGraph reduces power outages by optimizing the energy infrastructure for 1 billion people. \n \n We are looking for a highly motivated and experienced Technical Support Engineer to join our US team to support rapidly growing demand from enterprise customers (Global 1000) to deploy TigerGraph's award-winning graph database platform and solutions. The ideal candidate should have experience with Graph Databases or NoSQL databases, distributed systems, cloud platforms (such as Azure, AWS, GCP), scripting skills, Kubernetes and advanced debugging and troubleshooting skills.     Responsibilities \n \n \n Responding to Customers' inquiries and providing in-depth technical and high-quality support via phone, email, or chat. \n Troubleshooting and resolving technical issues that span from the product itself to the Customer environment.   Skills & Knowledge \n \n \n Big data/data ecosystem experience \n \n Technologies: Hadoop, MapReduce, Spark, Airflow, Beam, Kafka, Zookeeper \n Concepts: Data warehousing, data analytics, ETL \n \n Distributed systems experience \n \n Kubernetes, above listed big data technology \n \n Database experience \n ", "techs": ["tigergraph", "graph database", "fraud detection", "customer 360", "mdm", "iot", "ai", "machine learning", "fortune 500", "tigergraph platform", "technical support engineer", "graph databases", "nosql databases", "distributed systems", "cloud platforms", "azure", "aws", "gcp", "scripting skills", "kubernetes", "debugging", "troubleshooting", "hadoop", "mapreduce", "spark", "airflow", "beam", "kafka", "zookeeper", "data warehousing", "etl."]}, "89b65c11dc3c37c7": {"terms": ["machine learning engineer"], "salary_min": 77182.05, "salary_max": 97729.67, "title": "Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  ***This is a remote-based field position. Candidates should be located in one of the following states: Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, or Texas*** \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n San Antonio \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "14be21bbfe692312": {"terms": ["machine learning engineer"], "salary_min": 77098.04, "salary_max": 97623.29, "title": "Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  ***This is a remote-based field position. Candidates should be located in one of the following states: Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, or Texas*** \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n Little Rock \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "c5448eb7ed313f8a": {"terms": ["machine learning engineer"], "salary_min": 79139.67, "salary_max": 100208.45, "title": "Field Engineer - Technical Customer Services - Truck Tire", "company": "Continental", "desc": "Your tasks \n \n  ***This is a remote-based field position. Candidates should be located in one of the following states: Georgia, Florida, Alabama, Mississippi, Arkansas, Louisiana, Oklahoma, or Texas*** \n \n  The field engineer will be responsible for supporting Sales by addressing complaints on Continental commercial tires as well as other products offered. The field engineer will support customers with warranty determination on complaints, provide topical training to both dealers and users, and report on product performance in the US. \n \n \n \n Adjudicate warranty on commercial tires and other products that are offered by Continental and provide feedback to customers on findings \n Assist and direct Sales with product complaints \n Enter all complaints into the Global Complaint Handling system, track these complaints and report trends \n Escalate topics of interest into continuous process improvement platform and participate in monthly meetings. \n Track product performance on targeted products \n Provide training to Sales, Fleets and Dealers on failure modes and other technical topics \n  Your profile \n \n  BASIC QUALIFICATIONS \n \n  Bachelor\u2019s degree \n \n 2+ years of industry related experience to include:  truck tire sales/engineering, retreading, and/or customer service \n Strong Microsoft Office Suite experience \n Travel up to 75% domestically \n Ability to handle commercial tires to include moving, stacking, inspecting. \n Legal authorization to work in the US is required. We will not sponsor individuals for employment visas now or in the future, for this job opening \n \n  PREFERRED QUALIFICATIONS \n \n  Engineering related degree \n 5+ years of related experience \n Experience in a retread shop or in retread failure analysis \n \n  Our offer \n \n  All your information will be kept confidential according to EEO guidelines. \n \n \n EEO-Statement: \n  EEO / AA / Disabled / Protected Veteran Employer. Continental offers equal employment opportunities to all qualified individuals, without regard to unlawful consideration to race, color, sex, sexual orientation, gender identity, age, religion, national origin, disability, veteran status, or any other status protected by applicable law. In addition, as a federal contractor, Continental complies with government regulations, including affirmative action responsibilities, where they apply. To be considered, you must apply for a specific position for which Continental has a current posted job opening. Qualifying applications will be considered only for the specific opening(s) to which you apply. If you would like to be considered for additional or future job openings, we encourage you to reapply for other opportunities as they become available. Further, Continental provides reasonable accommodations to qualified individuals with a disability. If you need assistance in the application process, please reply to Careers@conti-na.com or contact US Recruiting at 248.393.5566. This telephone line and email address are reserved solely for job seekers with disabilities requesting accessibility assistance or an accommodation in the job application process. Please do not call about the status of your job application, if you do not require accessibility assistance or an accommodation. Messages left for other purposes, such as following up on an application or non-disability related technical issues, will not receive a call back. \n \n  Ready to drive with Continental? Take the first step and fill in the online application. \n \n  About us \n \n  Continental develops pioneering technologies and services for sustainable and connected mobility of people and their goods. Founded in 1871, the technology company offers safe, efficient, intelligent and affordable solutions for vehicles, machines, traffic and transportation. In 2022, Continental generated sales of \u20ac39.4 billion and currently employs around 200,000 people in 57 countries and markets. \n \n  With its premium portfolio in the car, truck, bus, two-wheel and specialty tire segment, the Tires group sector stands for innovative solutions in tire technology. Intelligent products and services related to tires and the promotion of sustainability complete the product portfolio. For specialist dealers and fleet management, Tires offers digital tire monitoring and tire management systems, in addition to other services, with the aim of keeping fleets mobile and increasing their efficiency. With its tires, Continental makes a significant contribution to safe, efficient and environmentally friendly mobility. \n \n  Keyfacts \n Job ID \n REF40263L \n Field of work \n Quality \n Location \n Houston \n Leadership level \n Leading Self \n Job flexibility \n Remote Job \n Legal Entity \n Continental Tire the Americas, LLC \n \n  What challenge have you learned the most from that you faced at Continental? \n \n Video length:  58 seconds \n 0:58 \n There's been plenty of challenges that have created unique learning \u2026 \n Zack \n Innovation Manager", "cleaned_desc": "", "techs": ""}, "eb95b19eb5a92466": {"terms": ["mlops"], "salary_min": 102284.36, "salary_max": 129514.8, "title": "Expert Level DevOps", "company": "Nagarro", "desc": "Full-time \n  Service Region: Eastern Europe \n \n \n \n \n \n  Company Description \n \n \n  We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale \u2014 across all devices and digital mediums, and our people exist everywhere in the world (19,000+ experts across 35 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in! \n  By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us \n \n \n \n \n \n  Job Description \n \n \n \n  Delivering custom developed products for a top diagnostics company in Switzerland. \n  Managing the CI/CD processes for over 200 medical devices projects. \n  Developing new features for the build solution (C# wrapper over Nuke). \n  Full autonomy when it comes to developing and maintaining the build system. \n  Using the client methodology complemented by the Nagarro software delivery process and best practices. \n  Providing general guidance related to development teams and resolving support tickets around building, testing, and deploying existing and new applications. \n  Implementing solutions which aim for a full automation of manual tasks, delivery processes and monitoring. \n \n \n \n \n \n \n  Qualifications \n \n \n  Must have skills: \n \n  Azure DevOps \n  Gitlab CI/CD \n  Docker \n  PowerShell \n  Bash \n  Windows and Linux Server Administration \n  GitOps \n \n \n \n \n \n \n  Nice to have: \n \n  C# \n  Experience in highly regulated industries (e.g. Life Sciences). \n  AWS Knowledge \n  Experience with Jenkins. \n  Exposure to monitoring tools (Prometheus, Grafana). \n  Familiarity with Docker Compose. \n  Server administration. \n  Client-facing role, directly interacting with Nagarro and customer project stakeholders. \n  Organized, structured. Problem-solving and effective communication skills.", "cleaned_desc": "", "techs": ""}, "ec1b8ff6a8164a72": {"terms": ["mlops"], "salary_min": 115658.336, "salary_max": 146449.22, "title": "Senior Level DevOps", "company": "Nagarro", "desc": "Full-time \n  Service Region: Eastern Europe \n \n \n \n \n \n  Company Description \n \n \n  We are a digital product engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale \u2014 across all devices and digital mediums, and our people exist everywhere in the world (19,000+ experts across 35 countries, to be exact). Our work culture is dynamic and non-hierarchical. We're looking for great new colleagues. That's where you come in! \n  By this point in your career, it is not just about the tech you know or how well you can code. It is about what more you want to do with that knowledge. Can you help your teammates proceed in the right direction? Can you tackle the challenges our clients face while always looking to take our solutions one step further to succeed at an even higher level? Yes? You may be ready to join us \n \n \n \n \n \n  Job Description \n \n \n  We are looking for a Senior Level DevOps Engineer having 4-6 years\u2019 experience with Docker, Gitlab, and Gitlab CI. \n  WHAT ARE YOUR RESPONSIBILITIES: \n \n  Collaborate with clients to understand their needs and tailor our DevOps solutions accordingly. \n  Manage and enhance  Gitlab-based CI/CD  pipelines to streamline development and deployment processes. \n  Maintain and optimize  Docker  containers for various applications and services. \n  Oversee and monitor  AWS Cloud Infrastructure , including EC2 instances, S3 buckets, RDS databases, and networking components. \n  Work closely with development teams to ensure code integration and deployment align with project goals. \n  Create and maintain automation scripts (e.g., Bash) to streamline routine tasks and deployment processes. \n  Swiftly troubleshoot and resolve infrastructure and deployment issues to minimize disruptions. \n  Implement robust security practices to safeguard infrastructure and applications. \n  Configure Nginx to serve as a reliable reverse proxy for applications. \n  Utilize  Terraform  or equivalent technologies to define and manage infrastructure as code for Cloud resources. \n \n \n \n \n \n \n  Qualifications \n \n \n \n  Strong problem-solving skills and attention to detail. \n  Expertise in Docker, Gitlab, and Gitlab CI. \n  Ability to work independently and collaboratively in a fast-paced environment. \n  Excellent communication and teamwork skills.", "cleaned_desc": "", "techs": ""}, "6228ce122bce3073": {"terms": ["mlops"], "salary_min": 129255.99, "salary_max": 163666.89, "title": "Senior Azure DevOps Engineer", "company": "GE Healthcare", "desc": "Job Description Summary  The Senior Azure DevOps Engineer is responsible for designing and managing the cloud infrastructure needed to support all Caption Health products. Duties include deploying infrastructure and product updates, identifying production issues, and implementing integrations that meet our customers' needs. This role has a large impact on team productivity and as such requires an understanding of the software development lifecycle and various automation tools for developing digital pipelines (CI/CD pipelines).\n  \n  Job Description \n  *Not Supporting Sponsorship for this Role* \n  Caption Health\u2019s mission is to detect disease early \u2013 when there is the highest potential for impact \u2013 by leveraging artificial intelligence and ultrasound. Our breakthrough AI platform enables any healthcare professional to perform high-quality ultrasound exams for early disease detection, in convenient and lower-cost outpatient settings including patients\u2019 homes. It was recognized as one of TIME\u2019s 100 Best Inventions of 2021 and one of Fast Company\u2019s Next Big Things in Health Tech. Through our work with health plans, providers, patients, and industry partners, we are transforming care, expanding access, and reducing costs.     Duties/Responsibilities: \n \n  Primary responsibility to manage the Azure cloud infrastructure tools and data with a bias towards automation and scaling. \n  Secondary responsibility to manage the GCP cloud infrastructure environment. \n  Maintain, improve, and monitor data ingestion and processing pipelines. \n  Manage and improve container orchestration and deployment strategies. \n  Develop tools to manage continuous integration, software stack support, code quality, and coverage. \n  Ensure and develop tools for monitoring security, privacy, and integrity of data and other resources. \n  Consult with application teams on architecture, performance, and access control design. \n  Strong skills in Terraform, Ansible, and Jenkins. \n  Perform other duties as assigned. \n \n \n \n  Required Knowledge/Skills/Abilities: \n  Experience with scripting languages. \n  Experience with continuous integration tools (e.g. Github Actions, Jenkins, GitLab CI/CD) and best practices for codebase management. \n  Experience with Docker and Kubernetes container strategies and orchestration. \n  Experience with FaaS/serverless environments. \n  Good verbal and written communication skills. \n  Proactive and assertive in driving solutions/solving issues. \n  Bonus: Experience with Google Cloud (GCP). \n  Bonus: Experience with network security and management of sensitive data. \n  Bonus: Experience working in startups. \n  Bonus: Experience working in healthcare or regulated environments. \n  Proficient with Microsoft 365 or similar software. \n \n \n \n  Education and Experience: \n  Bachelor's degree in software engineering, computer science, information technology, information systems, or similar. \n  7-10 years of experience with Azure cloud infrastructure design, development, and administration. \n \n \n \n  Physical Requirements:  Prolonged periods of sitting at a desk and working on a computer. \n \n \n  We expect all employees to live and breathe our behaviors: to act with humility and build trust; lead with transparency; deliver with focus, and drive ownership \u2013always with unyielding integrity. \n \n  Our total rewards are designed to unlock your ambition by giving you the boost and flexibility you need to turn your ideas into world-changing realities. Our salary and benefits are everything you\u2019d expect from an organization with global strength and scale, and you\u2019ll be surrounded by career opportunities in a culture that fosters care, collaboration and support. \n \n  While GE Healthcare does not currently require U.S. employees to be vaccinated against COVID-19, some GE Healthcare customers have vaccination mandates that may apply to certain GE Healthcare employees. \n \n  Additional Information \n \n \n \n \n \n \n \n  GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Relocation Assistance Provided:  No", "cleaned_desc": "Job Description Summary  The Senior Azure DevOps Engineer is responsible for designing and managing the cloud infrastructure needed to support all Caption Health products. Duties include deploying infrastructure and product updates, identifying production issues, and implementing integrations that meet our customers' needs. This role has a large impact on team productivity and as such requires an understanding of the software development lifecycle and various automation tools for developing digital pipelines (CI/CD pipelines).\n  \n  Job Description \n  *Not Supporting Sponsorship for this Role* \n  Caption Health\u2019s mission is to detect disease early \u2013 when there is the highest potential for impact \u2013 by leveraging artificial intelligence and ultrasound. Our breakthrough AI platform enables any healthcare professional to perform high-quality ultrasound exams for early disease detection, in convenient and lower-cost outpatient settings including patients\u2019 homes. It was recognized as one of TIME\u2019s 100 Best Inventions of 2021 and one of Fast Company\u2019s Next Big Things in Health Tech. Through our work with health plans, providers, patients, and industry partners, we are transforming care, expanding access, and reducing costs.     Duties/Responsibilities: \n \n  Primary responsibility to manage the Azure cloud infrastructure tools and data with a bias towards automation and scaling. \n  Secondary responsibility to manage the GCP cloud infrastructure environment. \n  Maintain, improve, and monitor data ingestion and processing pipelines. \n  Manage and improve container orchestration and deployment strategies. \n  Develop tools to manage continuous integration, software stack support, code quality, and coverage. \n  Ensure and develop tools for monitoring security, privacy, and integrity of data and other resources. \n  Consult with application teams on architecture, performance, and access control design. \n  Strong skills in Terraform, Ansible, and Jenkins. \n  Perform other duties as assigned. \n \n   \n  Required Knowledge/Skills/Abilities: \n  Experience with scripting languages. \n  Experience with continuous integration tools (e.g. Github Actions, Jenkins, GitLab CI/CD) and best practices for codebase management. \n  Experience with Docker and Kubernetes container strategies and orchestration. \n  Experience with FaaS/serverless environments. \n  Good verbal and written communication skills. \n  Proactive and assertive in driving solutions/solving issues. \n  Bonus: Experience with Google Cloud (GCP). \n  Bonus: Experience with network security and management of sensitive data. \n  Bonus: Experience working in startups. \n  Bonus: Experience working in healthcare or regulated environments. \n  Proficient with Microsoft 365 or similar software. \n \n \n \n  Education and Experience: ", "techs": ["terraform", "ansible", "jenkins", "scripting languages", "continuous integration tools (github actions", "jenkins", "gitlab ci/cd)", "docker", "kubernetes", "faas/serverless environments", "google cloud (gcp)", "network security", "microsoft 365"]}, "78b7c72b8813dc32": {"terms": ["mlops"], "salary_min": 89235.58, "salary_max": 112992.125, "title": "SysOPS/DevOPS Engineer", "company": "G5 Entertainment", "desc": "G5 Games is a game developer and publisher headquartered in Stockholm, Sweden. We have over 900+ talented professionals worldwide who work remotely in one of our 10 locations. More than 20 years ago, the company became one of the first mobile game developers in the world. \n You may know us from hit projects like Sherlock, Hidden City\u00ae, Mahjong Journey\u00ae, The Secret Society\u00ae, the Jewels series, and many others. \n We are currently looking for SysOPS/DevOPS Engineer to join our team. Do you have what it takes? Apply now! \n What you will work on: \n \n Maintenance and management of infrastructure resources (including user management, creation and configuration bare metal/cloud machines, data storages, and other services); \n Installation, configuration and software update (including operating systems, databases, applications, etc.); \n Organizing and maintaining the data backup process and disaster recovery; \n Ensuring infrastructure security in accordance with security policies; \n Ensuring the reliability and efficiency of infrastructure operations, troubleshooting, optimizing system performance, analysis of logs and monitoring metrics; \n Automation of routine processes and infrastructure deployment; \n Set and distribute tasks among the members of the project team; \n Close collaboration with all company departments and resolving tasks assigned by them; \n Documentation of technical information for the department. \n \n It\u2019s important to us: \n \n Over 3 years of experience with Linux distributions; \n Over 1 year of experience with AWS (EC2, S3, RDS, DynamoDB, Backup, IAM, VPC); \n Strong experience with LEMP and PostgreSQL; \n Strong experience with best practices/processes of data backup and disaster recovery; \n Experience with service maintaining TeamCity/Bamboo; \n Experience with bare metal servers; \n Experience with containerization and virtualization (Docker/Proxmox); \n Experience with Ansible; \n Experience GitLab CI/CD; \n Experience with programming/scripting languages Bash, Python; \n Experience with version control systems GIT, SVN; \n Knowledge of performance analysis tools, troubleshooting; \n Knowledge of network security (TCP/IP, SSH, SSL, VPN, etc.). \n \n Would be a great bonus: \n \n Experience with service maintaining Jira/Confluence; \n Experience with Windows Server OS; \n Experience with AWS such as EMR, Redshift, Lambda; \n Experience with databases such as Elasticsearch, Redis, MongoDB; \n Experience with IaC tools such as Terraform. \n \n \n Working at G5 is about: \n \n The opportunity to bring your ideas to life in an international company with a multimillion audience: G5 games are played by 250 million users worldwide. \n Official employment in one of our locations or under a contract. \n Assistance with relocation that helps move to one of the countries where the company has offices: Armenia, Georgia, Kazakhstan or Montenegro. \n Maintaining a work-life balance of employees: remote work and flexible hours, sports reimbursement, and health insurance payment. \n Charitable activities: you can initiate your own project with the company's support or participate in G5 Charity events. \n Opportunities for professional development: access to resources for creating your own projects within R&D, an internal educational platform, and training webinars covering various specialties. \n Bonus system: project profit bonus for project teams and a performance share program for key employees. \n Language courses: free English lessons, speaking clubs for all proficiency levels, and free study language of the country of relocation. \n Entertainment: corporate events and team buildings, master classes for adults and children, webinars with guest speakers, coffee talks, quizzes, and contests. \n \n Please be aware that the email correspondence with G5 Games representatives is conducted via g5e.com only.", "cleaned_desc": " Strong experience with best practices/processes of data backup and disaster recovery; \n Experience with service maintaining TeamCity/Bamboo; \n Experience with bare metal servers; \n Experience with containerization and virtualization (Docker/Proxmox); \n Experience with Ansible; \n Experience GitLab CI/CD; \n Experience with programming/scripting languages Bash, Python; \n Experience with version control systems GIT, SVN; \n Knowledge of performance analysis tools, troubleshooting; \n Knowledge of network security (TCP/IP, SSH, SSL, VPN, etc.).   \n Would be a great bonus: \n \n Experience with service maintaining Jira/Confluence; \n Experience with Windows Server OS; \n Experience with AWS such as EMR, Redshift, Lambda; \n Experience with databases such as Elasticsearch, Redis, MongoDB; \n Experience with IaC tools such as Terraform. \n \n ", "techs": ["teamcity/bamboo", "docker/proxmox", "ansible", "gitlab ci/cd", "bash", "python", "git", "svn", "jira/confluence", "windows server os", "aws (emr", "redshift", "lambda)", "elasticsearch", "redis", "mongodb", "terraform"]}, "a58c89c9abf25220": {"terms": ["mlops"], "salary_min": 113404.99, "salary_max": 143595.98, "title": "SENIOR DEVOPS ENGINEER", "company": "Transition Technologies PSC Sp. z o. o.", "desc": "_ Senior DevOps Engineer  \n \n \n \n _ What will you do? \n \n Responsibilities : \n \n Working in DevOps teams to continuously deliver high-quality systems \n Develop and maintain AWS infrastructure using IaaC best practice and Terraform \n Develop and mantain DevOps tools in Python \n Develop and mainatin DevOps pipelines \n Deploy applications to Kubernetes \n Involvement in SDLC process (from development to production) \n \n \n \n \n _ Who are we looking for? \n \n \n Requirements : \n \n Place of work: Poland \n 5+ years of IT Engineering experience \n Strong AWS experience 3+ years (AWS certified preferred) \n Strong Python experience \n Strong Continous Integration and Continous Deployment experience \n Relevant experience in Iaac (Terraform preffered) \n Relevant Kubernetes experience \n Familiarity with incident response, incident management \n Language: Fluent English and Polish \n \n Nice to have : \n \n Experience with Helm \n Familiarity with deploying Java applications \n Other Iaac tools \n On-call, incident response and incident management \n SRE experience \n \n \n \n \n \n \n \n \n _ Why is it worth it? \n \n \n What can we offer : \n \n Flexible forms of employment and working hours (CoE or B2B) \n An interesting, challenging job in the dynamically developing Capital Group company; \n Work on innovative projects using modern technologies; \n Direct impact on shaping the image of the Capital Group\u2019s companies on the market; \n Possibility to develop competences in a wide range; \n Attractive salary; \n Stability of employment and a friendly work atmosphere; \n Cool benefits, among others integration meetings, internal company competitions, fruit Tuesdays, sweet Thursdays and much more;", "cleaned_desc": "_ Senior DevOps Engineer  \n \n \n \n _ What will you do? \n \n Responsibilities : \n \n Working in DevOps teams to continuously deliver high-quality systems \n Develop and maintain AWS infrastructure using IaaC best practice and Terraform \n Develop and mantain DevOps tools in Python \n Develop and mainatin DevOps pipelines   5+ years of IT Engineering experience \n Strong AWS experience 3+ years (AWS certified preferred) \n Strong Python experience \n Strong Continous Integration and Continous Deployment experience \n Relevant experience in Iaac (Terraform preffered) \n Relevant Kubernetes experience \n Familiarity with incident response, incident management \n Language: Fluent English and Polish \n \n Nice to have : \n \n Experience with Helm ", "techs": ["terraform", "python", "aws", "kubernetes", "helm"]}, "05a904687abbe89f": {"terms": ["mlops"], "salary_min": 112500.0, "salary_max": 152000.0, "title": "DevOps Engineer", "company": "Bloomerang", "desc": "Bloomerang combines the best tools, resources, and people to provide a world-class experience for tens of thousands of nonprofits, allowing them to raise more money and do more good in the world. Our powerful software and stellar customer service have made us one of the highest rated fundraising/donor CRM on the market. \n  In addition to creating thriving nonprofits, we're also in the business of creating thriving employees .  At Bloomerang, you'll be a part of a mission-driven culture built on the core values of Empathy, Unity, and Transparency. We know the key to our success is our people, and we're proud to be home to some of the most innovative and skilled employees in the workforce today. \n \n \n  The Role \n  As a DevOps Engineer at Bloomerang, you will be working with our team to modernize both our platform infrastructure and our internal tooling. You will need to demonstrate technical skills for both project based tasks and strong troubleshooting acumen. You will be tasked with multiple projects at any given time and you will need to be able to prioritize them based on urgency. \n \n \n  What You Will Do \n \n You will be responsible for infrastructure related projects \n You will be responding to incidents and other issues as part of an on-call rotation \n You will be setting up monitoring/alerting as needed, to ensure the uptime and reliability of the application infrastructure \n You will assist with building and enhancing CI/CD pipelines \n You will assist in a migration from Windows servers to Linux for .NET Core \n You will help Implement a new VPN system \n You will streamline and enhance deployment strategies \n \n \n \n  What You Need to Succeed \n \n Cloud expertise (AWS) \n Linux or Windows server OS administration \n Scripting language proficiency \n Bash, PowerShell, Python, Ruby \n IaC expertise, e.g. Terraform \n Project management ticketing systems for task delegation, e.g. Jira \n Git proficiency and version/source control tools, e.g. Github, Bitbucket \n \n \n \n  Nice to Have But Not Required \n \n Cloud Experience (GCP) \n Familiarity with CI/CD practices and automation tools \n Jenkins, Circle CI, Travis CI \n Experience with monitoring and alerting system configurations \n Grafana, Graylog, Stackdriver, Datadog, etc \n Containerization and orchestration \n Docker \n Kubernetes \n \n \n \n  Benefits \n  Health + Wellness  You'll have access to generous health, vision, and dental insurance options, as well as a free subscription to Bright, a wellness platform that offers live and on-demand fitness, meditation, mindfulness, and nutrition classes. \n  Time Off \n  You'll get a competitive PTO package that includes 20 PTO days, 3 flex days, 4 optional volunteer Days, 12 paid holidays, as well as paid parental leave. \n  401k \n  You'll receive a 401k match to help invest in your future. \n \n \n  Equipment  Everything you need to be successful, shipped right to your door. \n \n \n  Compensation \n  The salary range for this position is: $112,500 - $152,000. You may also be eligible for a discretionary bonus. Actual compensation within the range will be dependent on your skills, experience, qualifications, and location, as well as applicable employment laws. \n \n \n  Location \n  This is a permanent, full-time, fully remote position. Employees living in Indianapolis, IN are welcome to work from our company headquarters. We do not offer Visa sponsorship or relocation assistance at this time. \n \n \n  Accommodations \n  Applicants who require accommodations may contact careers@bloomerang.com to request an accommodation in completing an application. \n  Bloomerang is an Equal Opportunity Employer. Individuals seeking employment at Bloomerang are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation.", "cleaned_desc": "", "techs": ""}, "e3634a417f0c77a3": {"terms": ["mlops"], "salary_min": 160000.0, "salary_max": 180000.0, "title": "Principal DevOps Engineer (Remote)", "company": "Patterson Technology Center", "desc": "JOB SUMMARY  The Principal DevSecOps Engineer supports web-based Cloud software applications, shared services, and hosting platforms for the Dental Software Organization. We are looking for a DevSecOps Engineer who has a keen eye toward automation and continually improving the security, availability, and scalability of our applications. This engineer will work with the latest Azure technologies. The DevSecOps Engineer focuses all aspects of security during the application life cycle, processes and sets direction with process workflows and improvements with system engineers, software engineers, and technical architects. This position advocates for security-first principles, constantly assess the threat landscape and adapting quickly to manage enterprise risk, as well as integration, configuration and deployment requirements. \n \n \n  ESSENTIAL FUNCTIONS \n  To perform this job successfully, an employee must be able to perform each essential function satisfactorily, with or without reasonable accommodation. To request a reasonable accommodation, notify Human Resources or the manager who oversees the position.\n   \n \n Builds relationships with developers, stakeholders, and technical leaders to incorporate security principles into engineering design and deployments. \n Oversee implementation of defensive configurations and countermeasures across cloud infrastructure and applications. \n Drafts and uphold Secure SDLC strategy and practices in tandem with other technical team leads. \n Partners with the Application Security team in implementing services and tools to enable developers and engineers to easily use security components produced by application security team members. \n Simplify automation that applies security inter-workings with CI/CD pipelines. \n Support the ability to \u201cshift left\u201d and incorporate security early on and throughout the development lifecycle including threat modeling and developer IDE security features. \n Assist prioritization of vulnerabilities identified in code through automated and manual assessments and promote quick remediation. \n Communicate vulnerability results in a manner understood by technical and non-technical business units based on risk tolerance and threat to the business, and gain support through influential messaging. \n Partner with architects to define security principles in architecture, infrastructure and code. \n Enrich application architecture with security standards, best practices and define baseline configuration. \n Partner with teams to define key performance indicators (KPIs), key risk indicators (KRIs) and distribute useful security related metrics to key stakeholders. \n Assist in documentation of application systems, process flows, and support processes. \n Participate in meetings to review processes and identify requirements and/or needs. \n Define needs by documenting processes; includes research, planning and writing supporting documentation. \n Communicate effectively with management to enhance their understanding of the opportunities and limitations of information systems. \n Research application security best practices and recommend solutions to solve problems or alleviate pain points. \n \n \n \n \n  REQUIRED QUALIFICATIONS \n \n \n Bachelor\u2019s or associate degree in Computer Science, Management Information Sciences or area of functional responsibility preferred, or equivalent years of industry work experience \n At least 7 years of DevSecOps or similar work experience. \n Possess a solid understand of information security and cloud application security \n Knowledge of all aspects of application development and project life cycles Design and development experience with engineering software design tools \n Proficient in securing Windows and Linux Operating Systems, applications, and networking \n Experience with operations and security across Microsoft Azure \n Strong experience in deployment and configuration of Azure Services such as: \n  o App Services and App Service Environment\n    o Azure Functions\n    o SQL Server\n    o API Manager\n    o Web Application Firewall (WAF)\n    o Azure Sentinel\n    o Azure NSG\n    o Vnets, Subnets, and DNS zones\n    o KeyVault\n    o App Insights\n    o Azure policies\n    o Azure Identity Management\n    o Azure RBAC and AAD services\n   \n \n Knowledge of DevSecOps concepts like SAST, DAST and SCA \n Experience in the application security and OWASP principles \n Automation experience using Terraform to ensure cloud services / infrastructure meet security guidelines \n Scripting experience required with strong focus on PowerShell and Azure CLI \n Proficiency with version control systems e.g., git, SVN, CVS \n Working knowledge of SQL and databases \n Experience in designing and implementing a continuous integration pipeline (CICD) \n Ability to troubleshoot issues in Stage and Production environments \n Consistent, positive attitude and respect for high quality standards \n Strong verbal and written communication skills with ability to effectively communicate \n Strong analytical and problem-solving abilities \n \n \n  EXPERIENCE WORKING IN A TEAM-ORIENTED, COLLABORATIVE ENVIRONMENT \n \n  PREFERRED QUALIFICATIONS \n \n \n Experience working in an agile development environment \n Experience working with APM and Incident Management tools \n Familiar with Cloud based web application \n Microsoft Azure experience \n Ability to read and comprehend code in C/C++ C# and scripting languages \n Familiarity with Azure DevOps and ServiceNow and project tracking systems \n \n \n \n \n  PHYSICAL DEMANDS \n \n \n None \n \n \n  The duties of this role may be performed remotely in the following states: AK,AZ,CA,CO,CT,DC,HI,ID,IL,KS,KY,ME,MA,MI,MN,MO,NE,NV,NH,NM,NY,OR,RI,SD,TN,TX,UT,VT,WV,WI  The potential compensation range for this role is $160,000-$180,000. The final offer amount would be based on various factors such as candidate location (geographical labor market), experience, and skills.  Periodic on call rotations and available outside of normal business hours on evenings and weekends during critical production release or issue escalation periods", "cleaned_desc": " Partner with teams to define key performance indicators (KPIs), key risk indicators (KRIs) and distribute useful security related metrics to key stakeholders. \n Assist in documentation of application systems, process flows, and support processes. \n Participate in meetings to review processes and identify requirements and/or needs. \n Define needs by documenting processes; includes research, planning and writing supporting documentation. \n Communicate effectively with management to enhance their understanding of the opportunities and limitations of information systems. \n Research application security best practices and recommend solutions to solve problems or alleviate pain points. \n \n \n \n \n  REQUIRED QUALIFICATIONS \n \n \n Bachelor\u2019s or associate degree in Computer Science, Management Information Sciences or area of functional responsibility preferred, or equivalent years of industry work experience \n At least 7 years of DevSecOps or similar work experience. \n Possess a solid understand of information security and cloud application security \n Knowledge of all aspects of application development and project life cycles Design and development experience with engineering software design tools   \n Knowledge of DevSecOps concepts like SAST, DAST and SCA \n Experience in the application security and OWASP principles \n Automation experience using Terraform to ensure cloud services / infrastructure meet security guidelines \n Scripting experience required with strong focus on PowerShell and Azure CLI \n Proficiency with version control systems e.g., git, SVN, CVS \n Working knowledge of SQL and databases \n Experience in designing and implementing a continuous integration pipeline (CICD) \n Ability to troubleshoot issues in Stage and Production environments \n Consistent, positive attitude and respect for high quality standards \n Strong verbal and written communication skills with ability to effectively communicate \n Strong analytical and problem-solving abilities \n \n \n  EXPERIENCE WORKING IN A TEAM-ORIENTED, COLLABORATIVE ENVIRONMENT \n \n  PREFERRED QUALIFICATIONS   \n \n Experience working in an agile development environment \n Experience working with APM and Incident Management tools \n Familiar with Cloud based web application \n Microsoft Azure experience \n Ability to read and comprehend code in C/C++ C# and scripting languages \n Familiarity with Azure DevOps and ServiceNow and project tracking systems \n \n \n \n \n  PHYSICAL DEMANDS \n \n \n None \n ", "techs": ["terraform", "powershell", "azure cli", "git", "svn", "cvs", "sql", "cicd", "apm", "incident management", "microsoft azure", "c/c++", "c#", "azure devops", "servicenow"]}, "2427b03209887ae5": {"terms": ["mlops"], "salary_min": 105000.0, "salary_max": 140000.0, "title": "Senior DevOps Engineer", "company": "Jahnel Group", "desc": "Jahnel Group\u2019s mission is to provide the absolute best environment for software creators to pursue their passion by connecting them with great clients doing meaningful work. We get to build some of the most complex and compelling applications for our clients located across the country. \n  We\u2019re a fast-growing INC 5000 recognized company, yet we still work as a very close-knit team (100+ employees). We\u2019re growing like crazy, and if you\u2019re looking for the next place to call home, hit us up for a beer or coffee. \n   \n WHO WE'RE LOOKING FOR \n  We are looking to hire a Senior Development and Operations Engineer. The ideal candidate will have a strong background in software engineering and will employ DevOps tools and best practices to improve our development team\u2019s production. \n  Problem-solving is key to the ability to utilize creative and innovative thinking. Rather than include the same old boring job description, here is a list of tasks the prospective employee may be asked to accomplish and/or attributes the candidate should possess. \n  Primary Responsibilities: \n \n Work with multiple cloud platforms (Azure, AWS, GCP) \n Implement architectural designs and diagrams \n Automate processes and systems configuration/deployment \n Be able to solve problems and engineer solutions (infrastructure as code) \n Troubleshoot production issues and coordinate with the development team to streamline code deployment \n Implement automation tools and frameworks (CI/CD) \n Analyze code and communicate detailed reviews to development teams \n Automate systems tests for security, performance, and availability \n Collaborate with team members to improve the company\u2019s engineering tools, policy and procedures, and data security \n Ability to gather and aggregate metrics and logs into structured applications \n Working knowledge of known tools like Git and GitHub \n \n Some Must-Haves: \n \n 5+ Years of Professional Software Development Experience \n Expert in continuous code deployment and integration tools (Jenkins, Circle CI, Travis CI, Drone \u2013 not all are required, experience with one flavor or another is an absolute must-have) \n Expertise with Azure cloud infrastructure and proficient in server administration \n Experience scripting with Python, Bash, and/or GOlang. \n Deep understanding of containers \n \n Where We're Looking For It \n \n Schenectady, New York \n Argentina \n 100% Remote available for the right candidate \n \n Compensation Package (Salary Transparency for US Based Employees) \n \n Salary Range: $105,000 - $140,000+ \n    \n Salary is negotiable and the range can be increased based on qualifications, certifications and experience \n \n Free Health Insurance Option for all (Single, 2 - Party and Family) \n 401k Safe Harbor Plan \n Profit Sharing Program \n Generous PTO - Maternity / Paternity Leave \n Side Hustle Opportunities \n Certification Reimbursement and Bounty Programs \n \n Other Information \n  The work hours will be approximately 9:00 am to 5:00 pm EST, depending on workload, with the occasional late night when a tight deadline calls for it. We work for security-conscious clients, thus background checks will be required. \n  Position available immediately.", "cleaned_desc": " Implement architectural designs and diagrams \n Automate processes and systems configuration/deployment \n Be able to solve problems and engineer solutions (infrastructure as code) \n Troubleshoot production issues and coordinate with the development team to streamline code deployment \n Implement automation tools and frameworks (CI/CD) \n Analyze code and communicate detailed reviews to development teams \n Automate systems tests for security, performance, and availability \n Collaborate with team members to improve the company\u2019s engineering tools, policy and procedures, and data security \n Ability to gather and aggregate metrics and logs into structured applications   Working knowledge of known tools like Git and GitHub \n \n Some Must-Haves: \n \n 5+ Years of Professional Software Development Experience \n Expert in continuous code deployment and integration tools (Jenkins, Circle CI, Travis CI, Drone \u2013 not all are required, experience with one flavor or another is an absolute must-have) \n Expertise with Azure cloud infrastructure and proficient in server administration \n Experience scripting with Python, Bash, and/or GOlang. \n Deep understanding of containers ", "techs": ["implement architectural designs and diagrams", "automate processes and systems configuration/deployment", "troubleshoot production issues and coordinate with the development team to streamline code deployment", "implement automation tools and frameworks (ci/cd)", "analyze code and communicate detailed reviews to development teams", "automate systems tests for security", "performance", "and availability", "collaborate with team members to improve the company's engineering tools", "policy and procedures", "and data security", "ability to gather and aggregate metrics and logs into structured applications", "working knowledge of known tools like git and github", "expert in continuous code deployment and integration tools (jenkins", "circle ci", "travis ci", "drone)", "expertise with azure cloud infrastructure and proficient in server administration", "experience scripting with python", "bash", "and/or golang", "deep understanding of containers"]}, "419ed4fdd51720d6": {"terms": ["mlops"], "salary_min": 55.0, "salary_max": 60.0, "title": "Azure DevOps Platform Engineer", "company": "Finezi", "desc": "Platform Engineer \n 6 month+ Contract \n REMOTE with some travel \n PST work hours \n \n SKILLS & FUNCTIONS: \n System & Cloud Administration: \n Windows Management, Linux Management, Privilege Management, Compute Services, DB & Storage Services, Networking & Load balancing Services, ETL & Analytical Services \n Packaging and Installation: \n Configuration Management, SW Inventory Management, Package Management \n Database Administration \n Database pooling, Debugging, Database encryption, Performance tuening, SQL Optimization, Data Modelling (ERD), Backup and Restoration, Data Masking, DML release management, DB partitioning, Database DDL/DML environment comparison reports \n Application Monitoring \n Session log monitoring, Application log monitoring, Batch job monitoring, Filesystem and Infra threshold monitoring, Certificate monitoring \n Platform Monitoring & Maintenance \n Firewall rules , Traffic policies, File system, Service Ids, AD groups, Certificates \n Scripting & Automation \n Scripting, Workflow, RPA, Jobs, Robo copy and Synchronization techniques \n Devops Engineering: \n Release Administration and build dashboard, Deployment support, Repos and Branching policies, CD/CI Pipelines development, SAST, DAST, Code Packaging \n L2 Production Support \n Operations and Manual procedures support, Runbook updates based on incidents and RCAs, Vendors, Upstream, Downstream coordination, Minor code fixes, Failure jobs reprocessing, DDL, DML adhoc updates \n L1 Coordination \n Knowledge books updates, Coordinate with helpdesk for transferred tickets, End user satisfaction management \n Job Types: Contract, Full-time \n Pay: $55.00 - $60.00 per hour \n Expected hours: 40 per week \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": "", "techs": ""}, "a2bc022af081bd3a": {"terms": ["mlops"], "salary_min": 100000.0, "salary_max": 100000.0, "title": "DevOps Engineer - Eastern Time Zone, Virtual, United States", "company": "WorkForce Software", "desc": "Candidates for this role must reside in the Eastern Time zone. Sponsorship is not available at this time. \n \n \n  About Us \n  WorkForce Software is the first global provider of workforce management solutions with integrated employee experience capabilities. The company\u2019s WorkForce Suite adapts to each organization\u2019s needs\u2014no matter how unique their pay rules, labor regulations, and schedules\u2014while delivering a breakthrough employee experience at the time and place work happens. Enterprise-grade and future-ready, WorkForce Software is helping some of the world\u2019s most innovative organizations optimize their workforce, protect against compliance risks, and increase employee engagement to unlock new potential for resiliency and optimal performance. Whether your employees are deskless or office workers, unionized, full-time, part-time, or seasonal, WorkForce Software makes managing your global workforce easy, less costly, and more rewarding for everyone. \n \n  Over one thousand organizations with more than 4 million users in over 80 countries rely on WorkForce Software solutions to streamline compliance, reduce labor costs, provide more intuitive tools to their employees, and achieve strategic HR on a global basis. \n  WorkForce Software is looking for an experienced DevOps Software Engineer to join our collaborative Agile engineering team. This role will involve working amongst teams to develop, deliver and operate enterprise-level services in our suite of workforce management software. As an experienced DevOps Software Engineer, you will be an advocate for DevOps culture, keen to share that experience and drive best practices amongst our teams. You will have experience working in a similar DevOps or site reliability role and have a passion for building products with great automation, optimization, and improvement to help deliver the best experience for our customers. \n \n \n  WorkForce Software is looking for an experienced DevOps Software Engineer to join our collaborative Agile engineering team. This role will involve working amongst teams to develop, deliver and operate enterprise-level services in our suite of workforce management software. As an experienced DevOps Software Engineer, you will be an advocate for DevOps culture, keen to share that experience and drive best practices amongst our teams. You will have experience working in a similar DevOps or site reliability role and have a passion for building products with great automation, optimization, and improvement to help deliver the best experience for our customers. \n \n \n  As a DevOps engineer, you will work across our cross-functional engineering teams that deliver working software at a regular cadence. You\u2019ll be helping to drive a DevOps culture sharing your experience and knowledge with experienced, highly technical engineers at the beginning of a DevOps journey. We aim to leverage modern technologies to continually improve our products to meet our customers\u2019 needs. \n \n \n  Requirements \n  The ideal candidate will have previous experience in a DevOps or site reliability role and will have a background as a Software Engineer who has developed more Operator skills, becoming a DevOps Engineer. \n \n \n  On your first day, we\u2019ll expect you to have: \n \n 3+ years\u2019 experience with scripting languages: Bash, Python, Powershell \n 2+ years\u2019 experience with Infrastructure as code using technologies like Chef, Terraform, Docker or similar technologies \n Experience operating and developing CI/CD tooling like Jenkins, Rundeck \n Experience with log aggregation tools like ELK \n Strong experience building enterprise-level software \n A natural comfort in a Unix/Linux environment with command line \n Experience with container technologies & ecosystem like Docker, Kubernetes \n Experience operating software in cloud environments \n Experience identifying and monitoring application metric \n Experience with monitoring software like Dynatrace, New Relic, Prometheus \n Experience designing, developing, deploying, and operating large scale SaaS application \n Experience identifying and remediating common security issues \n Knowledge of common security controls and best practices \n Experience working within version control technologies like GIT \n Experience reviewing and giving feedback on code developed by peers \n A passion for learning and sharing knowledge and experience \n Passion to learn how individuals do their job and how software can Make Work Easy \n Excellent problem-solving skills \n Good teamworking skills and ability to work as part of a cross-functional team \n Good organizational skills and ability to manage own workload \n Excellent written and verbal communication skills \n \n \n \n  Desired Skills \n \n Experience developing enterprise software with technologies like Java, PHP, JavaScript \n Experience working in a collaborative Agile engineering team \n Experience working with a microservices architecture \n Experience with incident response \n \n \n \n  Education: \n \n Bachelor's or advanced degree in Software Engineering preferred or equivalent \n \n \n \n  Why You Should Join the WorkForce Team? \n \n Unlimited PTO \n Flexible Hours / Work from Home Policy \n 401k with Company Match \n Performance Bonus \n Career Development and Training \u2013 Be the CEO of your career! \n    \n Company paid LinkedIn Learning subscription. \n \n Diversity, Equity, and Inclusion Initiatives including committees such as: \n    \n Women for Inclusion \n Age: Unity Beyond Years \n Racial Equality/Discrimination \n Mental and Physical Ability \n WorkForce Pride Network \n Global Perspectives \n Band of Veterans \n \n Health and Wellness / Gym Reimbursement \n Full Comprehensive Health Benefit Package \n Parental Leave \n Community Outreach Programs and Charitable Support \n \n \n \n  This job description is not intended to be all inclusive, and employee will perform other reasonably related business duties as assigned by the immediate supervisor and other management as required. \n \n \n  To maintain our goal of remaining a diverse and inclusive company, WorkForce Software advocates for and promotes a diverse, equitable, safe, and professional workplace where all people feel welcomed and empowered. We are committed to creating an environment that supports and celebrates the full range of our individual and collective differences, so that everyone can do their best and most innovative work, on the job and in our communities. \n \n \n  WorkForce Software is committed to the full inclusion of all qualified individuals. As part of this commitment, WorkForce Software will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact our Talent Acquisition Department at  careers@workforcesoftware.com , 1-833-987-3831. \n \n \n  WorkForce Software is an Equal Opportunity Employer.", "cleaned_desc": " \n  On your first day, we\u2019ll expect you to have: \n \n 3+ years\u2019 experience with scripting languages: Bash, Python, Powershell \n 2+ years\u2019 experience with Infrastructure as code using technologies like Chef, Terraform, Docker or similar technologies \n Experience operating and developing CI/CD tooling like Jenkins, Rundeck \n Experience with log aggregation tools like ELK \n Strong experience building enterprise-level software \n A natural comfort in a Unix/Linux environment with command line \n Experience with container technologies & ecosystem like Docker, Kubernetes \n Experience operating software in cloud environments \n Experience identifying and monitoring application metric \n Experience with monitoring software like Dynatrace, New Relic, Prometheus \n Experience designing, developing, deploying, and operating large scale SaaS application \n Experience identifying and remediating common security issues \n Knowledge of common security controls and best practices \n Experience working within version control technologies like GIT \n Experience reviewing and giving feedback on code developed by peers \n A passion for learning and sharing knowledge and experience   Passion to learn how individuals do their job and how software can Make Work Easy \n Excellent problem-solving skills \n Good teamworking skills and ability to work as part of a cross-functional team \n Good organizational skills and ability to manage own workload \n Excellent written and verbal communication skills \n \n \n \n  Desired Skills \n \n Experience developing enterprise software with technologies like Java, PHP, JavaScript \n Experience working in a collaborative Agile engineering team \n Experience working with a microservices architecture \n Experience with incident response \n \n \n \n  Education: \n ", "techs": ["bash", "python", "powershell", "chef", "terraform", "docker", "jenkins", "rundeck", "elk", "docker", "kubernetes", "dynatrace", "new relic", "prometheus", "git", "java", "php", "javascript"]}, "606e8bde816706f0": {"terms": ["mlops"], "salary_min": 65.0, "salary_max": 70.0, "title": "Senior DevOps Engineer", "company": "Innovecture", "desc": "We at \n   Innovecture  are hiring for a \n   \"Senior DevOps Engineer\"  to expand our team, this is a Remote position in \n   United States . You will work across various Innovecture and client teams and apply your technical expertise to some of the most complex and challenging technology problems.\n  \n \n \n  About \n   Innovecture :\n  \n \n  Founded in 2007 under the leadership of CEO Shreyas Kamat, Innovecture LLC, began as a U.S.-based Information Technology and Management Consulting Company focusing on technology consulting and services. With international development centers located in Salt Lake City, USA, and Pune, India, Innovecture leverages its Global Agile Delivery Model to effectively deliver client projects within budget scope and project deadline. The primary focus of Innovecture is to provide a unique wealth of expertise and experience to the IT and Management Consulting realm by utilizing various technologies across multiple industry domains. Innovecture uses best-in-class design processes and top-quality talent to ensure the highest quality deliverables. With innovation embedded in its consulting and services approach, Innovecture will continue to deliver outstanding results for its Fortune 500 clients and employees.\n  \n \n \n Senior DevOps Engineer \n \n \n Long Term \n \n \n Remote Role \n \n \n \n Job Description \n \n \n  As a Senior DevOps Engineer you will be responsible for implementing the company\u2019s DevOps roadmap by using guidelines, blueprints, training plan, references etc.\n  \n \n What are we looking for: \n \n \n  5 years\u2019 experience as a Dev Ops professional\n  \n \n  Build, collaborate and support relationships between teams\n  \n \n  Understand the business strategy for infrastructure capabilities and connect it to technical solutions\n  \n \n  Experienced in Docker, Kubernetes, Azure and Dev Ops Coaching", "cleaned_desc": "", "techs": ""}, "b1268b592a95a357": {"terms": ["mlops"], "salary_min": null, "salary_max": null, "title": "Software Engineer (Backend & DevOps)", "company": "West Bend Mutual Insurance Company", "desc": "Company Overview: \n  \n   Voted Journal Sentinels Top Workplaces to work for 3 consecutive years! Join us at West Bend Mutual, where we have been voted top workplaces to work three consecutive years. At West Bend Mutual, we believe that our employees are our greatest asset. We hire talented individuals who are conscientious, dedicated, customer focused, and able to build lasting relationships. We create and maintain an environment where you feel a sense of belonging and appreciation. Your diversity of through, experience and knowledge are valued. Recognized as top workplace, we are committed to fostering a welcoming culture, offering you opportunities for meaningful work and professional growth. More than a workplace, we celebrate our success and take pride in serving our communities.\n   Job Summary: \n  \n  We are building high-visibility, enterprise capabilities to underpin our diverse software landscape. In this role, you will be a key contributor to our enterprise technology platform. Further, you will embrace craftsmanship and innovation to develop a best-of-breed experience for our engineering community.\n  \n \n \n \n   Come join us and be part of a growing team!\n   Responsibilities & Qualifications: \n  \n C#/.NET backend API and services development, with a keen emphasis on reuse and scalability. \n  Building, enhancing, and documenting the enterprise DevOps practice and toolchain. \n  Automated unit, integration, and regression testing to ensure system stability. \n  Azure CI/CD pipelines to build, test and release code. \n  Continuous advocacy for technical craftsmanship and preferred/best practices. \n  Collaboration with engineering squads, to foster enterprise capability adoption. \n  Review and oversight of peer proposals and solutions. \n \n \n  Qualifications and Preferred Experience: \n \n \n  Excellent written and spoken communication skills. \n  Proactive and collaborative attitude. \n  Analytical and systematic approach to solving/solutioning problems. \n  A willingness to continually learn and grow. \n  Substantial direct knowledge and experience with:\n    \n  Dev: C#, .NET, Web API. \n  API: OpenAPI, REST, SOAP \n  Data: SQL, Microsoft SQL Server. \n  Azure Cloud: Serverless Computing, API Management. \n  Source Control: Azure Repos. \n  Branching: Git Flow, Trunk-based Development. \n  Azure DevOps: Repos, Pipelines, Artifacts. \n  Static Code Analysis: SAST, SCA. \n  Automation: YAML, PowerShell. \n  Release-on-Demand: Dark Launches, Feature Flags, Semantic Versioning. \n  Infrastructure-as-Code (IaC): Bicep. \n  Observability: DORA Metrics, Splunk. \n  Test Automation: Linting, Unit Tests, Code Coverage. \n  Architecture: Microservices, CI/CD. \n  Design: OOP, MVC, IoC, Dependency Injection \n \n  4+ years of professional experience with backend software development and DevOps. \n \n \n  Differentiators and preferred Education: \n \n \n  Proficiency with Agile development methodology. Scrum preferred. \n  Integration with multiple SaaS solutions. P&C insurance space preferred. \n  Practical experience with: \n \n  Dev: NUnit, NServiceBus. \n  API: OData, SwaggerHub. \n  Data: NoSQL, Azure Cosmos DB. \n  Azure Cloud: Service Bus, Key Vault. \n  Source Control: GitHub. \n  Branching: GitHub Flow, GitLab Flow. \n  Azure DevOps: Boards, Test Plans. \n  Static Code Analysis: GitHub CoPilot. \n  Automation: Python. \n  Release-on-Demand: Canary Releases. \n  Infrastructure-as-Code (IaC): Terraform. \n  Observability: OpenTelemetry. \n  Test Automation: Code Smells, Performance Engineering. \n  Architecture: Message Broker, Publish/Subscribe. \n  Design: MVVM, Sagas, BFF, Sidecar, Anti-corruption Layer, Fa\u00e7ade, Strangler Fig, CQRS. \n \n \n \n  Preferred Education: \n \n \n  Bachelor\u2019s degree in Computer Science or related field. \n  EEO: \n  \n   West Bend provides equal employment opportunities to all associates and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.", "cleaned_desc": "  Azure CI/CD pipelines to build, test and release code. \n  Continuous advocacy for technical craftsmanship and preferred/best practices. \n  Collaboration with engineering squads, to foster enterprise capability adoption. \n  Review and oversight of peer proposals and solutions. \n \n \n  Qualifications and Preferred Experience: \n \n \n  Excellent written and spoken communication skills. \n  Proactive and collaborative attitude. \n  Analytical and systematic approach to solving/solutioning problems. \n  A willingness to continually learn and grow. \n  Substantial direct knowledge and experience with:\n    \n  Dev: C#, .NET, Web API.    API: OpenAPI, REST, SOAP \n  Data: SQL, Microsoft SQL Server. \n  Azure Cloud: Serverless Computing, API Management. \n  Source Control: Azure Repos. \n  Branching: Git Flow, Trunk-based Development. \n  Azure DevOps: Repos, Pipelines, Artifacts. \n  Static Code Analysis: SAST, SCA. \n  Automation: YAML, PowerShell. \n  Release-on-Demand: Dark Launches, Feature Flags, Semantic Versioning. \n  Infrastructure-as-Code (IaC): Bicep. \n  Observability: DORA Metrics, Splunk. \n  Test Automation: Linting, Unit Tests, Code Coverage. \n  Architecture: Microservices, CI/CD. \n  Design: OOP, MVC, IoC, Dependency Injection \n \n  4+ years of professional experience with backend software development and DevOps. ", "techs": ["azure ci/cd pipelines", "c#", ".net", "web api", "openapi", "rest", "soap", "sql", "microsoft sql server", "serverless computing", "api management", "azure repos", "git flow", "trunk-based development", "azure devops", "yaml", "powershell", "dark launches", "feature flags", "semantic versioning", "bicep", "dora metrics", "splunk", "linting", "unit tests", "code coverage", "microservices", "oop", "mvc", "ioc", "dependency injection"]}, "298f2f59065c05b0": {"terms": ["mlops"], "salary_min": 117000.0, "salary_max": 141000.0, "title": "Lead DevOps Engineer- Confluent Kafka/Microsoft Azure (Remote)", "company": "Abercrombie and Fitch Co.", "desc": "Company Description\n   Job Description \n  Information Technology at Abercrombie & Fitch is fundamental to designing, sourcing, developing, and delivering fashion forward merchandise to our customers. We are committed to implementing new strategic and systematic approaches to generate dynamic technology solutions for our growing business. This position will be responsible for supporting our Global Data and Integrations Team. We\u2019re seeking a candidate that is constantly challenging the status quo and seeking out innovation in an ever-evolving retail environment. \n \n  What Will You Be Doing? \n \n  Leading a team of DevOps Engineers and building a Cloud Centric Roadmap for Integrations Platform utilizing Confluent Kafka and Microsoft Azure \n  Managing (Confluent) Kafka infrastructure, administration, and configuration ( \n  Working with and managing distributed messaging systems, like multiple Kafka clusters. \n  Microsoft Azure cloud management & administration including environment provisioning, configuration, performance monitoring, policy governance, and security that is global in scale. \n  Design, develop, and implement highly available, multi-region solutions within Microsoft Azure. \n  Analyze existing operational standards, processes, and/or governance, present recommendations to modernize or improve, and then execute on said improvement. \n  Migrate existing infrastructure services to cloud-based solutions. \n  Manage security and access controls of cloud-based solutions. \n  Develop infrastructure as code (IaC) leveraging cloud native tooling to ensure automated and consistent platform deployments. \n  Develop & implement policy driven data protection best practices to ensure cloud solutions are protected from data loss. \n  Support cloud adoption of applications as they are being transformed and/or modernized. \n  Ensuring all infrastructure components meet proper performance and capacity standards. \n  Experience working with weblogic administration and MQ \n  Ability to understand the needs of the Cloud Services Stakeholders. \n  Ability to delegate the work and communicate the status. \n  Participate in a 24x7 on-call rotation to address and resolve technical escalations \n \n \n  What Do You Need To Bring? \n \n  Bachelor\u2019s degree with a minimum of 5+ years IT experience preferred, or equivalent combination of education/experience \n  Strong knowledge and experience of managing Kafka infrastructure, administration, and configuration (Confluent) \n  3+ years of Microsoft Azure experience involving design, deploy, config, optimization, and of IaaS and PaaS solutions. \n  Experience in the design and operation of medium to large scale enterprise infrastructure, databases, and application systems requiring 24x7x365 uptime. \n  Competence in a wide range of IT skills including networking, systems administration, data protection, information security, & CI/CD tooling. \n  Prior experience operating in a Lead role, preferably with both on-shore and off-shore resources including work prioritization, project tracking/management, participating in architecture discussions and design reviews, etc. \n  Demonstrated growth mindset, enthusiastic learner, ability to teach and mentor teammates and cross functional partners. \n  Excellent communication skills, both written and verbal, with a keen attention to detail. \n  Experience working within an Agile framework. \n  IaaC development with Terraform, Azure CLI, Puppet, and Ansible \n  Scripting experience with Perl, Python, and PowerShell \n  Proficient with GIT to perform source code management \n  Experience with Terraform Cloud and Azure DevOps \n  Experience with Jira and ServiceNow \n  Experience with Weblogic administration and MQ   \n \n Our Company \n  Abercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we\u2019re here for our associates, customers and communities on the journey to being and becoming who they are \u2013 and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas. \n  Our Values \n  We lead with purpose and always put our people first, which is evidenced by our Great Place to Work\u2122 Certification, as well as being a 2021 recipient of Fortune\u2019s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We\u2019re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities. \n  What You'll Get \n  As an Abercrombie & Fitch Co. (A&F Co.) associate, you\u2019ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company\u2019s culture and values, but most importantly \u2013 with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward: \n \n  Incentive Bonus Program \n  Paid Time Off and Work From Anywhere Flexibility \n  Paid Volunteer Day per Year, allowing you to give back to your community \n  Merchandise Discount \n  Medical, Dental and Vision Insurance Available \n  Life and Disability Insurance \n  Associate Assistance Program \n  Paid Parental and Adoption Leave \n  Access to Carrot to support your unique parenthood journey \n  Access to Headspace dedicated to creating healthier, happier lives from the inside out \n  401(K) Savings Plan with Company Match \n  Opportunities for Career Advancement, we believe in promoting from within \n  A Global Team of People Who'll Celebrate you for Being YOU \n \n \n \n \n Additional Information\n   ABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER \n  Notice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $117,000 - $141,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future.", "cleaned_desc": "  Bachelor\u2019s degree with a minimum of 5+ years IT experience preferred, or equivalent combination of education/experience \n  Strong knowledge and experience of managing Kafka infrastructure, administration, and configuration (Confluent) \n  3+ years of Microsoft Azure experience involving design, deploy, config, optimization, and of IaaS and PaaS solutions. \n  Experience in the design and operation of medium to large scale enterprise infrastructure, databases, and application systems requiring 24x7x365 uptime. \n  Competence in a wide range of IT skills including networking, systems administration, data protection, information security, & CI/CD tooling. \n  Prior experience operating in a Lead role, preferably with both on-shore and off-shore resources including work prioritization, project tracking/management, participating in architecture discussions and design reviews, etc. \n  Demonstrated growth mindset, enthusiastic learner, ability to teach and mentor teammates and cross functional partners. \n  Excellent communication skills, both written and verbal, with a keen attention to detail. \n  Experience working within an Agile framework. \n  IaaC development with Terraform, Azure CLI, Puppet, and Ansible \n  Scripting experience with Perl, Python, and PowerShell \n  Proficient with GIT to perform source code management \n  Experience with Terraform Cloud and Azure DevOps ", "techs": ["kafka", "confluent", "microsoft azure", "iaas", "paas", "networking", "systems administration", "data protection", "information security", "ci/cd tooling", "lead role", "agile framework", "terraform", "azure cli", "puppet", "ansible", "perl", "python", "powershell", "git", "terraform cloud", "azure devops"]}, "27637251e2d31d92": {"terms": ["mlops"], "salary_min": 114554.3, "salary_max": 145051.27, "title": "DevOps Engineer", "company": "AE Business Solutions", "desc": "AE Business Solutions is looking for a DevOps Engineer to take on a FULLY REMOTE position with our client in Wisconsin. The DevOps Engineer will focus on automation and support of the client environment. The DevOps Engineer will automate the CI/CD pipeline and support development/deployment/integration/refactoring/scripting needs for specific application systems. \n \n  **Candidate MUST be located in WI or willing to relocate at own expense \n \n  **No C2C inquiries, please \n \n  The environment this position will be working in and supporting includes: GitLab, Rancher, Argo CD, Nexus, Kustomize, Maven, Junit, JMeter, SonarQube, Prisma Cloud, KeyCloak, Okta, AzureAD and Relational Databases. \n \n  The DevOps Engineer should have extensive exposure and experience in automating, developing, and supporting a Java DevOps environment: -Language (Java) \u2013 Issue Management (Jira) \u2013 CI/CD (GitLab, Rancher, ArgoCD, Nexus Repository, Kustomize, Maven) - Unit tests (JUnit) \u2013 Performance Test Scripts(JMeter) -Frameworks for backend (Spring Boot and Spring Cloud) \u2013 Code Scan (SonarQube) \u2013 App Scan (Prisma Cloud) \u2013 Authentication and Authorization (KeyCloak, Okta, AzureAD) \u2013Containers (Docker) -Orchestration (Kubernetes) -Backend development principles (Database and cache, server, microservices and API (REST & SOAP). \n \n  AE Business Solutions does not sponsor applicants for employment visas. \n \n  AE Business Solutions is an Equal Opportunity Employer. EOE/AA", "cleaned_desc": "  The DevOps Engineer should have extensive exposure and experience in automating, developing, and supporting a Java DevOps environment: -Language (Java) \u2013 Issue Management (Jira) \u2013 CI/CD (GitLab, Rancher, ArgoCD, Nexus Repository, Kustomize, Maven) - Unit tests (JUnit) \u2013 Performance Test Scripts(JMeter) -Frameworks for backend (Spring Boot and Spring Cloud) \u2013 Code Scan (SonarQube) \u2013 App Scan (Prisma Cloud) \u2013 Authentication and Authorization (KeyCloak, Okta, AzureAD) \u2013Containers (Docker) -Orchestration (Kubernetes) -Backend development principles (Database and cache, server, microservices and API (REST & SOAP). \n ", "techs": ["java", "jira", "gitlab", "rancher", "argocd", "nexus repository", "kustomize", "maven", "junit", "jmeter", "spring boot", "spring cloud", "sonarqube", "prisma cloud", "keycloak", "okta", "azuread", "docker", "kubernetes", "rest", "soap"]}, "153e83f351779c23": {"terms": ["mlops"], "salary_min": 55.0, "salary_max": 55.0, "title": "DevOps Engineer", "company": "RAWKEY TECHNOLOGIES LLC", "desc": "Role: Sr. DevOps Engineer (Enterprise Service Bus) \n \n  Role Description:\n  \n \n \n Administering WebMethods environment and CI/CD automation \n Experience: 5-10 years \n \n Job Description: \n \n \n \n Good Experience in integration software (Software AG WebMethods) installation, patching and administration \n Knowledge of Retail supply chain management \n Very good exposure to CI/CD tools (Git, Jenkins Pipeline, Rundeck etc.) \n Experience with automation/configuration management using either Chef or Ansible \n Experience of code and script (Bash, Groovy, Python and/or Ruby) \n Experience in containerization technologies (Docker and Kubernetes) \n Good background in Linux/Unix Administration \n Ability to use a variety of open source technologies and cloud services (experience with Azure is required) \n Good understanding of network layer terminologies \n Good knowledge of database architecture (MySQL) \n Exposure to ITIL practices (Incident/Change management) \n Knowledge of best practices and IT operations in an always-up, always-available service \n \n \n This is a remote position.", "cleaned_desc": " Very good exposure to CI/CD tools (Git, Jenkins Pipeline, Rundeck etc.) \n Experience with automation/configuration management using either Chef or Ansible \n Experience of code and script (Bash, Groovy, Python and/or Ruby) \n Experience in containerization technologies (Docker and Kubernetes) \n Good background in Linux/Unix Administration ", "techs": ["git", "jenkins pipeline", "rundeck", "chef", "ansible", "bash", "groovy", "python", "ruby", "docker", "kubernetes", "linux/unix administration"]}, "ec6a144e42528606": {"terms": ["mlops"], "salary_min": 144488.33, "salary_max": 182954.42, "title": "Lead DevOps Engineer - GCP (Fully Remote)", "company": "Freestar", "desc": "About Freestar: \n  Freestar specializes in developing state-of-the-art monetization solutions for websites. Through the integration of industry-leading technology, advanced data analytics, and a robust infrastructure, we empower busy website owners to effortlessly maximize their revenue while relieving themselves of the complexities of ad operations. By leveraging our expertise, site owners can seamlessly optimize their revenue streams and gain valuable time to focus on their core strengths: creating exceptional content. With Freestar, publishers can unlock their full potential and achieve greater success in their online endeavors. \n  Job Description: \n  As a Lead DevOps Engineer at Freestar, you'll collaborate with the Engineering and Architecture teams to establish and maintain our global customer-facing infrastructure. This includes high scalability and availability, data pipelines, and microservices. Your role requires being a motivated self-starter who excels in problem-solving and values uninterrupted product availability. \n  Your tasks involve researching and implementing enhancements to improve availability, scalability, and performance. You'll deploy monitoring tools and suggest alternative design approaches. Additionally, you'll strengthen security by implementing tools, identifying breaches, and making necessary adjustments. Overseeing build and deployment tools, you'll focus on smooth deployments, minimizing downtime, and establishing rollback protocols. \n  Responsibilities: \n \n Architecture and Infrastructure Design:  Collaborate to design scalable and reliable GCP infrastructure solutions with software development teams and stakeholders. Understand application requirements, select suitable GCP services, and design a highly available and fault-tolerant architecture. \n Deployment Automation:  Implement and maintain automated deployment pipelines using appropriate tools and services. Automate the provisioning and configuration of infrastructure resources using Infrastructure as Code (IaC). \n Continuous Integration and Delivery:  Establish and enforce best practices for continuous integration and delivery (CI/CD) processes. Set up and maintain CI/CD pipelines to automate build, test, and deployment processes for applications and services. \n Infrastructure Provisioning and Management:  Implement infrastructure provisioning and management processes using GCP services like Compute Engine, Kubernetes Engine, and Cloud Functions. Utilize containerization technologies like Docker and orchestration tools like Kubernetes for containerized deployments. \n Observability:  Implement comprehensive monitoring and alerting solutions using GCP monitoring services and external services. Configure dashboards, alerts, and notifications to ensure timely identification and resolution of issues. \n Security and Compliance:  Implement security best practices and ensure compliance with industry standards and regulations. Set up proper access controls, encryption mechanisms, and security monitoring for GCP resources. Conduct regular security audits and vulnerability assessments. \n Disaster Recovery and Business Continuity:  Design and implement disaster recovery and business continuity plans for critical systems and data on GCP. Set up backup and recovery processes, implement failover mechanisms, and conduct periodic testing to ensure readiness. \n Cost Optimization:  Optimize infrastructure costs by implementing cost management strategies, such as rightsizing resources, using managed services, and leveraging auto-scaling capabilities. Monitor and analyze usage patterns to identify cost-saving opportunities. \n Collaboration and Knowledge Sharing:  Lead and mentor a team of DevOps engineers, providing guidance and support in adopting best practices and solving technical challenges. Foster collaboration across teams and facilitate knowledge sharing through documentation, training, and workshops. \n \n Qualifications: \n \n Curiosity. You love to stay up to date with the latest trends, features, and best practices related to Google Cloud services and DevOps methodologies. You are continuously evaluating new tools and technologies. \n 6-8 years of experience working in a DevOps role, with a strong understanding of DevOps principles and practices. Extensive experience in leading large-scale web applications in production. \n A deep understanding of GCP services such as Compute Engine, Kubernetes Engine, Cloud Functions, Cloud Storage, Cloud Pub/Sub, and more. Strong knowledge of GCP networking, security, and IAM (Identity and Access Management) is also important. \n Proficiency writing infrastructure code to provision and manage GCP resources in a declarative and reproducible manner (Terraform or Google Cloud Deployment Manager). \n Strong knowledge and experience with CI/CD pipelines and related tools such as Google Cloud Build, Jenkins, Github Action, or similar, with hands-on experience in automating build, test, and deployment processes for applications and infrastructure. \n Deep understanding of containerization technologies like Docker and container orchestration (k8s) is highly desirable. Experience deploying and managing containerized applications on GKE is a plus. \n Proficiency in implementing monitoring and observability solutions using GCP monitoring services such as Cloud Monitoring, Logging, and Tracing. Experience in working with industry standard tools like Datadog, Prometheus and Grafana. \n Strong understanding of security best practices and experience in implementing security controls and compliance frameworks on GCP. \n Excellent problem-solving skills and the ability to troubleshoot complex issues across different layers of the technology stack. You should be able to identify root causes, implement effective solutions, and provide technical guidance to the team. \n Excellent communication and collaboration skills are essential for working with cross-functional teams, stakeholders, and presenting technical concepts to both technical and non-technical audiences. \n \n What you can expect in return: \n \n Full-Time, Salaried Position \n Medical, Dental, and Vision benefits \n Generous Flexible Time Away policy \n 401K with company match, vested immediately \n The opportunity to be part of something BIG \n \n Freestar is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.", "cleaned_desc": " Architecture and Infrastructure Design:  Collaborate to design scalable and reliable GCP infrastructure solutions with software development teams and stakeholders. Understand application requirements, select suitable GCP services, and design a highly available and fault-tolerant architecture. \n Deployment Automation:  Implement and maintain automated deployment pipelines using appropriate tools and services. Automate the provisioning and configuration of infrastructure resources using Infrastructure as Code (IaC). \n Continuous Integration and Delivery:  Establish and enforce best practices for continuous integration and delivery (CI/CD) processes. Set up and maintain CI/CD pipelines to automate build, test, and deployment processes for applications and services. \n Infrastructure Provisioning and Management:  Implement infrastructure provisioning and management processes using GCP services like Compute Engine, Kubernetes Engine, and Cloud Functions. Utilize containerization technologies like Docker and orchestration tools like Kubernetes for containerized deployments. \n Observability:  Implement comprehensive monitoring and alerting solutions using GCP monitoring services and external services. Configure dashboards, alerts, and notifications to ensure timely identification and resolution of issues. \n Security and Compliance:  Implement security best practices and ensure compliance with industry standards and regulations. Set up proper access controls, encryption mechanisms, and security monitoring for GCP resources. Conduct regular security audits and vulnerability assessments. \n Disaster Recovery and Business Continuity:  Design and implement disaster recovery and business continuity plans for critical systems and data on GCP. Set up backup and recovery processes, implement failover mechanisms, and conduct periodic testing to ensure readiness.   Cost Optimization:  Optimize infrastructure costs by implementing cost management strategies, such as rightsizing resources, using managed services, and leveraging auto-scaling capabilities. Monitor and analyze usage patterns to identify cost-saving opportunities. \n Collaboration and Knowledge Sharing:  Lead and mentor a team of DevOps engineers, providing guidance and support in adopting best practices and solving technical challenges. Foster collaboration across teams and facilitate knowledge sharing through documentation, training, and workshops. \n \n Qualifications: \n \n Curiosity. You love to stay up to date with the latest trends, features, and best practices related to Google Cloud services and DevOps methodologies. You are continuously evaluating new tools and technologies. \n 6-8 years of experience working in a DevOps role, with a strong understanding of DevOps principles and practices. Extensive experience in leading large-scale web applications in production.   A deep understanding of GCP services such as Compute Engine, Kubernetes Engine, Cloud Functions, Cloud Storage, Cloud Pub/Sub, and more. Strong knowledge of GCP networking, security, and IAM (Identity and Access Management) is also important. \n Proficiency writing infrastructure code to provision and manage GCP resources in a declarative and reproducible manner (Terraform or Google Cloud Deployment Manager). \n Strong knowledge and experience with CI/CD pipelines and related tools such as Google Cloud Build, Jenkins, Github Action, or similar, with hands-on experience in automating build, test, and deployment processes for applications and infrastructure. \n Deep understanding of containerization technologies like Docker and container orchestration (k8s) is highly desirable. Experience deploying and managing containerized applications on GKE is a plus. \n Proficiency in implementing monitoring and observability solutions using GCP monitoring services such as Cloud Monitoring, Logging, and Tracing. Experience in working with industry standard tools like Datadog, Prometheus and Grafana. \n Strong understanding of security best practices and experience in implementing security controls and compliance frameworks on GCP. \n Excellent problem-solving skills and the ability to troubleshoot complex issues across different layers of the technology stack. You should be able to identify root causes, implement effective solutions, and provide technical guidance to the team. ", "techs": ["terraform", "google cloud deployment manager", "google cloud build", "jenkins", "github action", "docker", "kubernetes (k8s)", "gke", "cloud monitoring", "logging", "tracing", "datadog", "prometheus", "grafana."]}, "a4cf26db6e109263": {"terms": ["mlops"], "salary_min": 123782.4, "salary_max": 156736.1, "title": "DevOps Engineer", "company": "Cyberjin", "desc": "Hybrid Role \n  Looking for a DevOps Engineer with prior experience with Big Data Solutions, Cloud technology, and strong working knowledge of Linux. Passionate about the concept of infrastructure as code and leverages modern tools to define, build and manage virtual infrastructure in the cloud. Work is performed in a hybrid environment with a great team. \n \n  Essential Job Responsibilities \n  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications \n  Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills. \n  Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. \n  Prior experience or familiarity with Unified Platform (UP) Big Data Platform (formerly owned by DISA) is a plus. \n  Data parsing/transforming techniques to include JSON, XML, CSV formats. \n  Understanding of AGILE software development methodologies and use of standard software development tool suites. (e.g., JIRA, Confluence, Github Enterprise, etc.) \n  Willing to do on-call/pager duty is a big plus. Possible rotating shift in the future for this role as the current team is full. \n   \n S64qjYFuTv", "cleaned_desc": "  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications    Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills.    Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. ", "techs": ["java", "linux", "shell scripting", "bash", "javascript", "python", "hadoop", "nosql databases", "aws"]}, "509edf41edde0326": {"terms": ["mlops"], "salary_min": 160000.0, "salary_max": 180000.0, "title": "Principal DevOps Engineer (Remote)", "company": "Patterson Companies, Inc.", "desc": "JOB SUMMARY  The Principal DevSecOps Engineer supports web-based Cloud software applications, shared services, and hosting platforms for the Dental Software Organization. We are looking for a DevSecOps Engineer who has a keen eye toward automation and continually improving the security, availability, and scalability of our applications. This engineer will work with the latest Azure technologies. The DevSecOps Engineer focuses all aspects of security during the application life cycle, processes and sets direction with process workflows and improvements with system engineers, software engineers, and technical architects. This position advocates for security-first principles, constantly assess the threat landscape and adapting quickly to manage enterprise risk, as well as integration, configuration and deployment requirements. \n \n \n  ESSENTIAL FUNCTIONS \n  To perform this job successfully, an employee must be able to perform each essential function satisfactorily, with or without reasonable accommodation. To request a reasonable accommodation, notify Human Resources or the manager who oversees the position.\n     \n \n Builds relationships with developers, stakeholders, and technical leaders to incorporate security principles into engineering design and deployments. \n Oversee implementation of defensive configurations and countermeasures across cloud infrastructure and applications. \n Drafts and uphold Secure SDLC strategy and practices in tandem with other technical team leads. \n Partners with the Application Security team in implementing services and tools to enable developers and engineers to easily use security components produced by application security team members. \n Simplify automation that applies security inter-workings with CI/CD pipelines. \n Support the ability to \u201cshift left\u201d and incorporate security early on and throughout the development lifecycle including threat modeling and developer IDE security features. \n Assist prioritization of vulnerabilities identified in code through automated and manual assessments and promote quick remediation. \n Communicate vulnerability results in a manner understood by technical and non-technical business units based on risk tolerance and threat to the business, and gain support through influential messaging. \n Partner with architects to define security principles in architecture, infrastructure and code. \n Enrich application architecture with security standards, best practices and define baseline configuration. \n Partner with teams to define key performance indicators (KPIs), key risk indicators (KRIs) and distribute useful security related metrics to key stakeholders. \n Assist in documentation of application systems, process flows, and support processes. \n Participate in meetings to review processes and identify requirements and/or needs. \n Define needs by documenting processes; includes research, planning and writing supporting documentation. \n Communicate effectively with management to enhance their understanding of the opportunities and limitations of information systems. \n Research application security best practices and recommend solutions to solve problems or alleviate pain points. \n \n \n \n \n  REQUIRED QUALIFICATIONS \n \n \n Bachelor\u2019s or associate degree in Computer Science, Management Information Sciences or area of functional responsibility preferred, or equivalent years of industry work experience \n At least 7 years of DevSecOps or similar work experience. \n Possess a solid understand of information security and cloud application security \n Knowledge of all aspects of application development and project life cycles Design and development experience with engineering software design tools \n Proficient in securing Windows and Linux Operating Systems, applications, and networking \n Experience with operations and security across Microsoft Azure \n Strong experience in deployment and configuration of Azure Services such as: \n  o App Services and App Service Environment\n      o Azure Functions\n      o SQL Server\n      o API Manager\n      o Web Application Firewall (WAF)\n      o Azure Sentinel\n      o Azure NSG\n      o Vnets, Subnets, and DNS zones\n      o KeyVault\n      o App Insights\n      o Azure policies\n      o Azure Identity Management\n      o Azure RBAC and AAD services\n     \n \n Knowledge of DevSecOps concepts like SAST, DAST and SCA \n Experience in the application security and OWASP principles \n Automation experience using Terraform to ensure cloud services / infrastructure meet security guidelines \n Scripting experience required with strong focus on PowerShell and Azure CLI \n Proficiency with version control systems e.g., git, SVN, CVS \n Working knowledge of SQL and databases \n Experience in designing and implementing a continuous integration pipeline (CICD) \n Ability to troubleshoot issues in Stage and Production environments \n Consistent, positive attitude and respect for high quality standards \n Strong verbal and written communication skills with ability to effectively communicate \n Strong analytical and problem-solving abilities \n \n \n  EXPERIENCE WORKING IN A TEAM-ORIENTED, COLLABORATIVE ENVIRONMENT \n \n  PREFERRED QUALIFICATIONS \n \n \n Experience working in an agile development environment \n Experience working with APM and Incident Management tools \n Familiar with Cloud based web application \n Microsoft Azure experience \n Ability to read and comprehend code in C/C++ C# and scripting languages \n Familiarity with Azure DevOps and ServiceNow and project tracking systems \n \n \n \n \n  PHYSICAL DEMANDS \n \n \n None \n \n \n  The duties of this role may be performed remotely in the following states: AK,AZ,CA,CO,CT,DC,HI,ID,IL,KS,KY,ME,MA,MI,MN,MO,NE,NV,NH,NM,NY,OR,RI,SD,TN,TX,UT,VT,WV,WI  The potential compensation range for this role is $160,000-$180,000. The final offer amount would be based on various factors such as candidate location (geographical labor market), experience, and skills.  Periodic on call rotations and available outside of normal business hours on evenings and weekends during critical production release or issue escalation periods", "cleaned_desc": " Partner with teams to define key performance indicators (KPIs), key risk indicators (KRIs) and distribute useful security related metrics to key stakeholders. \n Assist in documentation of application systems, process flows, and support processes. \n Participate in meetings to review processes and identify requirements and/or needs. \n Define needs by documenting processes; includes research, planning and writing supporting documentation. \n Communicate effectively with management to enhance their understanding of the opportunities and limitations of information systems. \n Research application security best practices and recommend solutions to solve problems or alleviate pain points. \n \n \n \n \n  REQUIRED QUALIFICATIONS \n \n \n Bachelor\u2019s or associate degree in Computer Science, Management Information Sciences or area of functional responsibility preferred, or equivalent years of industry work experience \n At least 7 years of DevSecOps or similar work experience. \n Possess a solid understand of information security and cloud application security \n Knowledge of all aspects of application development and project life cycles Design and development experience with engineering software design tools   \n Knowledge of DevSecOps concepts like SAST, DAST and SCA \n Experience in the application security and OWASP principles \n Automation experience using Terraform to ensure cloud services / infrastructure meet security guidelines \n Scripting experience required with strong focus on PowerShell and Azure CLI \n Proficiency with version control systems e.g., git, SVN, CVS \n Working knowledge of SQL and databases \n Experience in designing and implementing a continuous integration pipeline (CICD) \n Ability to troubleshoot issues in Stage and Production environments \n Consistent, positive attitude and respect for high quality standards \n Strong verbal and written communication skills with ability to effectively communicate \n Strong analytical and problem-solving abilities \n \n \n  EXPERIENCE WORKING IN A TEAM-ORIENTED, COLLABORATIVE ENVIRONMENT \n \n  PREFERRED QUALIFICATIONS   \n \n Experience working in an agile development environment \n Experience working with APM and Incident Management tools \n Familiar with Cloud based web application \n Microsoft Azure experience \n Ability to read and comprehend code in C/C++ C# and scripting languages \n Familiarity with Azure DevOps and ServiceNow and project tracking systems \n \n \n \n \n  PHYSICAL DEMANDS \n \n \n None \n ", "techs": ["kpis", "kris", "metrics", "documentation", "research", "planning", "writing", "communication", "application security", "devsecops", "sast", "dast", "sca", "owasp", "terraform", "powershell", "azure cli", "version control systems", "sql", "databases", "continuous integration pipeline", "troubleshooting", "analytical skills", "team-oriented", "agile development environment", "apm", "incident management tools", "cloud based web application", "microsoft azure", "c/c++", "c#", "scripting languages", "azure devops", "servicenow", "project tracking systems."]}, "451dd24fc1c28d9c": {"terms": ["mlops"], "salary_min": 140000.0, "salary_max": 180000.0, "title": "DevOps/SRE Engineer", "company": "Morse Data Enterprises, LLC", "desc": "Job Title: DevOps/SRE Engineer \n Department: Engineering & Development \n Reports To: Manager of Engineering \n !!!!!!!! LinkedIn Candidates do not use the Quick Apply feature. Either go through the application process here or at our jobs portal at: MorseDataEnterprisesLLC.appone.com !!!!!!!! \n Job Summary: \n Morse Data Enterprises is seeking a talented DevOps/SRE Engineer to join our team. The successful candidate will work closely with our development, operations, and security teams to build and maintain our cloud infrastructure and automated deployment processes. The ideal candidate will have a deep understanding of DevOps and SRE principles and be comfortable working in a fast-paced, dynamic environment. \n Responsibilities: \n \n Build and maintain cloud infrastructure, including automation of deployment, scaling, and management of resources.   \n Develop and maintain continuous integration and deployment pipelines, including source control, build, and testing automation.   \n Monitor and analyze system performance and implement solutions to optimize resource utilization and availability.   \n Collaborate with development teams to ensure application architectures are optimized for cloud-based deployment and operations.   \n Implement and maintain security measures for cloud infrastructure and applications.   \n \n \n Troubleshoot and resolve infrastructure and application issues, and coordinate with other teams as necessary.   \n Participate in on-call rotations for production support and incident management.   \n Develop and maintain documentation related to cloud infrastructure and deployment processes.   \n Stay up-to-date with emerging trends and technologies in DevOps and SRE.   \n \n Qualifications: \n \n Bachelor's degree in Computer Science or related field.   \n Minimum of 5 years of experience in DevOps or SRE.   \n Strong understanding of cloud infrastructure, including experience with AWS, Azure, or GCP.   \n Experience with infrastructure as code tools such as Terraform or CloudFormation.   \n \n \n Experience with containerization technologies such as Docker and Kubernetes.   \n Familiarity with continuous integration and deployment tools such as GitHub Actions or Bitbucket Pipelines.   \n Understanding of software development principles and experience with scripting languages such as Bash as well as Javascript & Python..   \n Familiarity with monitoring and logging tools such as Prometheus and Grafana.   \n Excellent communication and collaboration skills.   \n \n \n Ability to work independently and manage multiple priorities and projects.   \n Relevant certifications such as AWS Certified DevOps Engineer or similar and Kubernetes Administrator Certification would be a plus.   \n \n Salary Range: $140,000.00-$180,000.00 \n Location: Harrisburg, PA, or Remote/Hybrid \n Applicants must currently be authorized to work in the United States without sponsorship. Morse Data Enterprises currently does not sponsor applicants for employment.", "cleaned_desc": " Build and maintain cloud infrastructure, including automation of deployment, scaling, and management of resources.   \n Develop and maintain continuous integration and deployment pipelines, including source control, build, and testing automation.   \n Monitor and analyze system performance and implement solutions to optimize resource utilization and availability.   \n Collaborate with development teams to ensure application architectures are optimized for cloud-based deployment and operations.   \n Implement and maintain security measures for cloud infrastructure and applications.   \n \n \n Troubleshoot and resolve infrastructure and application issues, and coordinate with other teams as necessary.     Participate in on-call rotations for production support and incident management.   \n Develop and maintain documentation related to cloud infrastructure and deployment processes.   \n Stay up-to-date with emerging trends and technologies in DevOps and SRE.   \n \n Qualifications: \n \n Bachelor's degree in Computer Science or related field.   \n Minimum of 5 years of experience in DevOps or SRE.     Strong understanding of cloud infrastructure, including experience with AWS, Azure, or GCP.   \n Experience with infrastructure as code tools such as Terraform or CloudFormation.   \n \n \n Experience with containerization technologies such as Docker and Kubernetes.   \n Familiarity with continuous integration and deployment tools such as GitHub Actions or Bitbucket Pipelines.   \n Understanding of software development principles and experience with scripting languages such as Bash as well as Javascript & Python..   \n Familiarity with monitoring and logging tools such as Prometheus and Grafana.   ", "techs": ["build and maintain cloud infrastructure", "automation of deployment", "scaling", "and management of resources", "continuous integration and deployment pipelines", "source control", "build", "and testing automation", "monitor and analyze system performance", "optimization of resource utilization and availability", "application architectures optimized for cloud-based deployment and operations", "security measures for cloud infrastructure and applications", "troubleshooting and resolving infrastructure and application issues", "coordinating with other teams", "on-call rotations for production support and incident management", "documentation related to cloud infrastructure and deployment processes", "staying up-to-date with emerging trends and technologies in devops and sre", "aws", "azure", "or gcp", "infrastructure as code tools like terraform or cloudformation", "containerization technologies such as docker and kubernetes", "continuous integration and deployment tools like github actions or bitbucket pipelines", "scripting languages such as bash", "javascript", "and python", "monitoring and logging tools like prometheus and grafana."]}, "a400fb6bc671e7bb": {"terms": ["mlops"], "salary_min": 118622.164, "salary_max": 150202.1, "title": "Senior DevOps / SecOps Engineer", "company": "Global Alliant Inc", "desc": "Senior DevOps / SecOps Engineer - Remote - Full time - Candidates should be in US to apply for this position!!! \n \n  Job Description: \n \n  The DevOps / SecOps Engineer will work using modern cloud infrastructure and CI workflow automation. \n \n  Based on your interests, we may ask you as a technology professional to support growth-related activities, including (but not limited to) RFI, RFP, prototypes, training interns and oral presentations. \n \n  You will: \n \n Build and set up new development tools and infrastructure using PaaS/SaaS or containerized-based deployment models. \n Lead cross-functional team collaborations and take ownership of assignments to gather functional requirements and drive Application Modernization onboarding efforts. \n Build, test, and deploy applications using modern CI workflow automation. \n \n \n \n  Requirements: \n \n 4+ years of experience building or maintaining a cloud-native CI/CD Pipeline. \n Experience working with AWS cloud service provider. \n Proven past performance utilizing DevOps/SecOps principles and best practices. \n 1+ years working with two or more of the following: Jenkins, CaC/Job DSL, Groovy, JSON, YAML, Ansible, Git. \n Experience with Kubernetes (EKS) \n \n \n \n  Preferred: \n \n Previous experience working with any CMS center is highly preferred. \n Significant experience with Infrastructure as Code (IaC). \n Significant experience with Terraform HCL directives and modular interpolations. \n AWS certifications. \n Federal Government contracting work experience. \n Prior experience working remotely full-time. \n \n \n \n  Global Alliant, Inc. provides equal employment opportunities(EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws. We especially invite women, minorities, veterans, and individuals with disabilities to apply.", "cleaned_desc": " \n  You will: \n \n Build and set up new development tools and infrastructure using PaaS/SaaS or containerized-based deployment models. \n Lead cross-functional team collaborations and take ownership of assignments to gather functional requirements and drive Application Modernization onboarding efforts. \n Build, test, and deploy applications using modern CI workflow automation. \n   \n \n  Requirements: \n \n 4+ years of experience building or maintaining a cloud-native CI/CD Pipeline. \n Experience working with AWS cloud service provider. \n Proven past performance utilizing DevOps/SecOps principles and best practices. ", "techs": ["paas/saas", "containerized-based deployment models", "ci workflow automation", "aws cloud service provider", "devops/secops"]}, "a7de0e0cbc36c768": {"terms": ["mlops"], "salary_min": 164123.05, "salary_max": 207816.36, "title": "Senior DevOps Engineer", "company": "Stellar Health", "desc": "About Stellar Health: \n  Historically, US Healthcare has relied on a fee-for-service reimbursement system where providers are paid based on the quantity of patient visits and procedures, rather than the quality of health outcomes. \n  At Stellar Health, we help primary care providers put patient health first. Our platform - a mix of technology, people, and analytics - supports providers at the point of care, delivering real-time patient information, activating practice staff, and empowering providers and care teams with incentives that reward the work they are already doing to keep patients healthy. Using the Stellar App, our web-based, point-of-care tool; practices receive a simple checklist of recommended actions that support the best quality care. Providers and care teams are then paid monthly for each action they complete, and Payors save money in reduced healthcare costs along the way. \n  Stellar is a US-based Health-tech backed by Top VCs ( General Atlantic, Point72, & Primary Venture Partners)  with an established product & proven operating model. We've shown that we make a real difference for physician practices and their patients. \n \n  DevOps at Stellar Health is in charge of supporting an increasingly diverse infrastructure setup, and support systems built by an increasing number of engineers. \n  The  original system was rather simplistic - a Django Application on top of Postgres, with a cron-driven ETL ingestion pipeline . While we have evolved this incrementally since to support customer growth (added Redis for caching, Celery for tasks, Elastic Search to serve certain jobs, a Postgres read replica to scale out some of the growth), due to increased customer growth we are now at  the cusp of building the next generation of systems and infrastructure . \n  As a Senior DevOps Engineer, you will work with our DevOps Lead and other DevOps Engineers to  guide the engineering team through this infrastructure evolution  and  be responsible for its scalability, monitoring, and general good performance and reliability . \n  As we transition to more complex usage of servers, we expect your team to be able to not only be  a stakeholder in informing teams' systems design  but also  a partner to the engineering team  when it comes to  release management, CI/CD, build cop and on-call rotations . \n  Originally, our systems diagram looked like this \n \n Job responsibilities \n  Systems / infrastructure setup and deployment \n \n Manage application deployment infrastructure across Aptible and AWS/GCP.  Our ETL'ing infrastructure, queueing, and application serving infrastructure are growing. Your responsibility is to ensure that it is set up in a HIPAA compliant, scalable, and resilient way. \n Migrate, set up and own new cloud deployments on AWS or GCP  in a HIPAA compliant way. Ensure that engineering is set up to deploy new services on AWS in a safe manner. \n Deploy and set up internal services  (Redis, Elastic Search, Postgres) to  match engineering business needs . Work together with engineering to coordinate upgrades of these systems to newer versions, scale, etc. Be responsible for the uptime of these services. \n Evolve our logging, monitoring, and alerting  - and drive a best in class engineering On Call rotation that allows us to ensure high availability of our production systems. \n Manage roles, responsibilities, and access to engineering services . AWS, Aptible, application, DB, grafana, Github - all need managed roles and responsibilities for the engineering team.  \n \n Developer productivity tools \n \n Evolve our release process  to make it easy for engineering to deploy and roll back releases. Help the engineering team move to a daily release cycle through speedy and automated deployments and rollbacks. \n Support the engineering organization through  setting up our testing infrastructure  in a way that allows for faster deployments. \n \n Requirements \n \n 5+ years of experience in a hands-on DevOps, Site Reliability (SRE), or Platform Engineering role. \n Work experience managing compliant infrastructure is a must. \n Working with Aptible, or modern AWS/GCP. We are a startup and the kinds of infrastructure startups have is significantly different from big companies. \n Experience with Terraform, Ansible, or other configuration management tools. \n Experience with a modern programming language (Python, JS, Go, etc). \n Experience with observability tools such as Datadog, NewRelic, Prometheus, Grafana, or similar. \n Familiarity with one or more CI/CD platforms (CircleCI, GitHub Actions, Jenkins, etc). \n \n Pay \n  At Stellar, we believe in transparency and we do our best to make sure the company and our candidates are on the same page as it relates to compensation. In addition to posting salary ranges for our open roles, candidates should expect to be asked about compensation expectations and requirements early on in their interview process. Our goal is to highlight when expectations and Steller's salary range may be out of sync, and work with the candidate to determine whether it makes sense to continue conversations. \n  Where a new hire falls within this range will be based on their individual skills and experience, and how these competencies compare across other employees in the same role. Stellar's bands are designed to allow for individual compensation growth within the role. As such, new hires typically start at the lower end of the range. Stellar rewards performance and outcomes - should you join the company, you will have the opportunity to grow your salary over time. \n \n The base salary range for a Senior DevOps Engineer l is  $175,000 - $215,000  and will be eligible  equity and an  annual performance based bonus. \n The base salary range for a Senior DevOps Engineer ll is  $200,000 - $240,000  and will be eligible for  equity and an  annual performance based bonus. \n \n Stellar reserves the right to change our compensation bands at any time. \n \n  Perks & Benefits: \n  Stellar offers a carefully curated selection of wellness benefits and perks to our employees: \n \n Medical, Dental and Vision Benefits \n Unlimited PTO (and ask our recruiting team about the ways we make sure employees are actually taking PTO) \n Universal Paid Family Leave, with up to 21 weeks of fully paid leave available to new parents and caregivers \n Company sponsored One Medical memberships and Citibike memberships \n Medical Travel Benefits \n A monthly wellness stipend that gives employees the freedom to choose where they spend their cash, whether it be on wellness, pet care, childcare, WFH items, or charitable donations \n Stock Options & a 401k matching program \n Career development opportunities like Manager Training, coaching, and an internal mobility program \n A broad calendar of company sponsored social events that for our in-office and remote employees \n \n Diversity is the key to our success . Stellar Health is an equal opportunity employer and we are open to all qualified applicants regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, veteran status, or any other legally protected status. \n  We believe that diverse teams -and the different identities, cultures, and life experiences our team members bring to the table- enable us to create amazing products, find creative solutions to interesting problems, and build an inclusive working environment. \n  Stellar Health Employment Privacy Notice \n  At Stellar Health, your privacy and security as a job seeker is a priority no matter where you are in the interview process . As recruiting scams have become more prevalent, please take note of the following practices to ensure the legitimacy of any interaction with our team. \n \n Please note that any communication from our recruiters and hiring managers at Stellar Health about a job opportunity will only be made by a Stellar Health employee with an  @stellar.health  email address. \n Stellar Health does not utilize third-party agencies for recruitment services and does not conduct text message or chat-based interviews. Any other email addresses, agencies, or forums may be phishing scams designed to obtain your personal information. \n We will not ask you to provide personal or financial information, including, but not limited to, your social security number, online account passwords, credit card numbers, passport information, and other related banking information until we begin onboarding activities, which will be coordinated by a member of the Stellar Health People Ops Team with an @stellar.health email address. \n \n If you are ever unsure whether you are in contact with a legitimate Stellar Health teammate, please contact people-team@stellar.health. If you believe you've been a victim of a phishing attack, please mark the communication as \"spam\" and immediately report it by contacting the U.S. Federal Trade Commission.", "cleaned_desc": "", "techs": ""}, "67a76817a2804fc4": {"terms": ["mlops"], "salary_min": 109156.07, "salary_max": 138215.9, "title": "Senior DevOps Engineer (HashiCorp Vault integration and Azure DevOps -\u00a0Remote)", "company": "Cognizant Technology Solutions", "desc": "Senior DevOps Engineer (HashiCorp Vault integration and Azure DevOps - Remote) \n  Cognizant\u2019s Digital Engineering practice is seeking a highly qualified Senior DevOps Engineer with experience in Hashicorp lifecycle management (including automating them) and Azure DevOps for pipelines management. You will be part of a digital software team that works on high-demand applications. Our engineers have a passion for high-quality, reliable and maintainable code. You will work side by side with product managers, designers, and clients, making decisions together in order to quickly deliver valuable working software to clients and their users. Our engineers are agile and retrospective, and not afraid to identify what we\u2019re doing wrong, so we can fix it, and what we\u2019re doing right, so we can improve on it. Above all, we judge success by the success of our team and the happiness of our customers. \n  Cognizant Digital Engineering If you\u2019re like us, you\u2019ve got big ideas. At Cognizant, we\u2019re exploring new ideas every day. We help industry leading companies reinvent their business models and innovate products that create new valueby connecting people with things, insights and experiences. Cognizant digital engineering designs, engineers and delivers digital products and experiences that drive digital-first business models. We offer the most comprehensive digital engineering expertise and client-centric methodology for sustainable innovation. \n  Location:  Louisville, KY or Remote or Various \n  **You must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.** \n \n  Responsibilities: \n \n \n Define best practices around Vault lifecycle management from the perspective of an application teams implementation. \n Report on DevOps analytics and pipeline reporting. \n Deployment Automation: Strong understanding of deployment automation concepts and tools, including experience with continuous integration/continuous deployment (CI/CD) workflows and related tools such as ADO and Github actions.Deploying to production the enhancements for various projects. \n Salesforce Development Lifecycle: Familiarity with the Salesforce development lifecycle, including sandboxes, change sets, metadata deployment, and version control. \n Source Control and Versioning: Experience with source control systems like Git or Azure DevOps, and understanding of versioning concepts, branching strategies, and code merging. \n Troubleshooting and Issue Resolution: Excellent problem-solving skills with the ability to troubleshoot and resolve deployment-related issues effectively. Experience in managing deployment errors, conflicts, and environment-specific challenges. \n \n \n \n  Qualifications: \n \n \n HashiCorp Vault integration w/ Azure DevOps Pipelines and GitHub Workflows,Hashi Vault management/automation/best practices. \n DevOps, principles and automation mentality. \n Collaboration and Communication: Strong interpersonal and communication skills to effectively collaborate with cross-functional teams, including developers, administrators, and business stakeholders. Ability to clearly convey technical concepts and deployment plans to both technical and non-technical audiences. \n Agile Methodologies: Familiarity with agile software development methodologies, such as Scrum or Kanban, and experience working in agile teams with a focus on iterative development and continuous improvement. \n Documentation and Change Management: Proficient in documenting release plans, deployment processes, and change management procedures. Understanding of the importance of maintaining proper documentation and adhering to change control and governance processes. \n Continuous Learning: Demonstrated ability and enthusiasm for keeping up-to-date with the latest developments in Salesforce technologies, Copado platform enhancements, and industry best practices related to release management and deployment. \n A proactive attitude to platform enhancements. A desire to implement best practice solutions. Available and responsive to questions. \n \n \n \n  Benefits:  Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:\n   \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n \n  Disclaimer:  The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law. \n  Travel:  0-5% \n  Why Choose Cognizant?  It takes a lot to succeed in today\u2019s fast-paced market, and Cognizant Technology Solutions has become a leader in the industry. We love big ideas and even bigger dreams! We stand out because we put human experiences at the core. Our associates enjoy robust benefits and training opportunities from our industry-recognized, award-winning Academy team. You will have access to hundreds of technical trainings to keep your skillsets fresh and have opportunities to acquire certifications on the newest technologies.  Everything we do at Cognizant we do with passion\u2014for our clients (fortune 100 companies), our communities, and our organization. It\u2019s the defining attribute that we look for in our people.  If you love ambiguity, excited by change, and excel through autonomy, we\u2019d love to hear from you! \n  About Cognizant Digital Engineering  Well-designed software transcends digital technology, going beyond the fulfillment of basic requirements to focus instead on human needs. Within Cognizant Digital Engineering, we help clients develop software products that transform human insights into tangible, production-ready digital solutions. We also work with our clients to scale their native cloud applications. Using insights from the lived experiences of our consumers, we seamlessly replace traditional service strategies with engaging, precise, and direct digital applications. Designing phenomenal software is vital to success in the digital economy\u2014and we understand that a human-centric approach is key to this design. \n  www.cognizant.com   NASDAQ: CTSH   #LI-ZR1   #IND123 \n  Employee Status :  Full Time Employee \n  Shift :  Day Job \n  Travel :  No \n  Job Posting :  Oct 10 2023 \n \n \n  About Cognizant \n  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.\n  \n  Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. \n \n  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. \n  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.", "cleaned_desc": " Deployment Automation: Strong understanding of deployment automation concepts and tools, including experience with continuous integration/continuous deployment (CI/CD) workflows and related tools such as ADO and Github actions.Deploying to production the enhancements for various projects. \n Salesforce Development Lifecycle: Familiarity with the Salesforce development lifecycle, including sandboxes, change sets, metadata deployment, and version control. \n Source Control and Versioning: Experience with source control systems like Git or Azure DevOps, and understanding of versioning concepts, branching strategies, and code merging. \n Troubleshooting and Issue Resolution: Excellent problem-solving skills with the ability to troubleshoot and resolve deployment-related issues effectively. Experience in managing deployment errors, conflicts, and environment-specific challenges. \n \n \n \n  Qualifications: \n \n \n HashiCorp Vault integration w/ Azure DevOps Pipelines and GitHub Workflows,Hashi Vault management/automation/best practices.   DevOps, principles and automation mentality. \n Collaboration and Communication: Strong interpersonal and communication skills to effectively collaborate with cross-functional teams, including developers, administrators, and business stakeholders. Ability to clearly convey technical concepts and deployment plans to both technical and non-technical audiences. \n Agile Methodologies: Familiarity with agile software development methodologies, such as Scrum or Kanban, and experience working in agile teams with a focus on iterative development and continuous improvement. \n Documentation and Change Management: Proficient in documenting release plans, deployment processes, and change management procedures. Understanding of the importance of maintaining proper documentation and adhering to change control and governance processes. \n Continuous Learning: Demonstrated ability and enthusiasm for keeping up-to-date with the latest developments in Salesforce technologies, Copado platform enhancements, and industry best practices related to release management and deployment. \n A proactive attitude to platform enhancements. A desire to implement best practice solutions. Available and responsive to questions. \n \n \n \n  Benefits:  Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:\n   ", "techs": ["deployment automation", "continuous integration/continuous deployment (ci/cd) workflows", "ado", "github actions", "salesforce development lifecycle", "sandboxes", "change sets", "metadata deployment", "version control", "source control systems", "git", "azure devops", "troubleshooting", "issue resolution", "hashicorp vault integration", "azure devops pipelines", "github workflows", "devops", "collaboration", "communication", "agile software development methodologies", "scrum", "kanban", "documentation", "change management", "continuous learning."]}, "b9a3a42fd260f208": {"terms": ["mlops"], "salary_min": 60.0, "salary_max": 63.0, "title": "Sr. AWS DevOps Application Engineer (Remote)", "company": "Source Select Group, LLC", "desc": "Senior AWS DevOps Engineer - (REMOTE) \n Location: Remote in approved states. Florida, Georgia, Tennessee, Colorado, Texas, Hawaii, Virginia, North Carolina \n Type: Contract to HIre \n NO C2C, NO VENDORS PLEASE, no 3rd party, Must Not now or in the future require sponsorship. \n Summary: \n As a Senior DevOps Engineer, you will be developing solutions for various platforms, on-prem, AWS and Azure. Focus is AWS but will be cross trained on Azure as well. \n You will provide solutions and support to the entire delivery pipeline to facilitate improved collaboration, version control, standardization of environments, continuous integration, continuous deployment, continuous delivery with an emphasis on using automation to improve quality checks and deployment efficiencies, to support faster and more reliable delivery and development cycles. \n Responsibilities \n Design and implement solutions to automate the CI/CD pipelines \n Build systems that dynamically scale \n Version Control and Merging \n Infrastructure provisioning, configuration, management, and monitoring \n Administer internal tools -  Azure DevOps tool set, JIRA, TeamCity \n Identify, troubleshoot, and resolve system and deployment issues \n Collaborate with multiple feature development teams to identify infrastructure needs and requirements for building and deploying their applications into shared environments. \n Work closely with development teams as SME to ensure deployable solutions that support best practices \n Skills/Experience \n Experience in AWS, Azure, Virtualized technology \n Experience building CI/CD pipelines \n Experience with Azure Repos, Pipelines and Artifacts \n Experience with JIRA, Confluence, TeamCity, Azure Boards \n Experience in Configuration Management \n Experience in installing, configuring, and administering Version Control (TFS, Git) \n Experience in Infrastructure provisioning on-Prem and in Cloud \n Experience in Infrastructure as Code leveraging tools like Terraform \n Relational Database Experience \n Fluency with test runners, scripting, TFS, Xamarin Test Cloud \n Coding/Scripting experience (i.e C#, Python, Groovy, PowerShell, Bash) \n Fluency in WiX and SetupBuilder to support package setup \n Assist in planning, organizing, and coordinating technical activities and work assignments \n Excellent analytical and problem-solving skills with a high aptitude to learn \n Excellent written and verbal communication skills including Strong interpersonal and presentation skills \n Strong organizational skills, with the ability to effectively prioritize and multi-task \n Experience implementing Application Security Testing tools preferred \n Education or Prior Work Experience \n Bachelor\u2019s degree or 4 more years of work-related experience \n 3+ years of deep, practical expertise installing, configuring, and maintaining enterprise-scale software products and solutions \n Job Type: Full-time \n Salary: $55.00 - $63.00 per hour \n Experience level: \n 4+ years \n Schedule: \n Monday to Friday \n Work Location: Remote \n Job Types: Contract, Full-time \n Pay: $60.00 - $63.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Compensation package: \n \n Hourly pay \n Yearly pay \n \n Experience level: \n \n 4 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote", "cleaned_desc": " Identify, troubleshoot, and resolve system and deployment issues \n Collaborate with multiple feature development teams to identify infrastructure needs and requirements for building and deploying their applications into shared environments. \n Work closely with development teams as SME to ensure deployable solutions that support best practices \n Skills/Experience \n Experience in AWS, Azure, Virtualized technology \n Experience building CI/CD pipelines \n Experience with Azure Repos, Pipelines and Artifacts \n Experience with JIRA, Confluence, TeamCity, Azure Boards \n Experience in Configuration Management \n Experience in installing, configuring, and administering Version Control (TFS, Git) \n Experience in Infrastructure provisioning on-Prem and in Cloud \n Experience in Infrastructure as Code leveraging tools like Terraform \n Relational Database Experience   Fluency with test runners, scripting, TFS, Xamarin Test Cloud \n Coding/Scripting experience (i.e C#, Python, Groovy, PowerShell, Bash) \n Fluency in WiX and SetupBuilder to support package setup \n Assist in planning, organizing, and coordinating technical activities and work assignments \n Excellent analytical and problem-solving skills with a high aptitude to learn \n Excellent written and verbal communication skills including Strong interpersonal and presentation skills \n Strong organizational skills, with the ability to effectively prioritize and multi-task \n Experience implementing Application Security Testing tools preferred \n Education or Prior Work Experience \n Bachelor\u2019s degree or 4 more years of work-related experience \n 3+ years of deep, practical expertise installing, configuring, and maintaining enterprise-scale software products and solutions \n Job Type: Full-time \n Salary: $55.00 - $63.00 per hour ", "techs": ["identify", "troubleshoot", "and resolve system and deployment issues", "aws", "azure", "virtualized technology", "ci/cd pipelines", "azure repos", "pipelines and artifacts", "jira", "confluence", "teamcity", "azure boards", "configuration management", "version control (tfs", "git)", "infrastructure provisioning", "infrastructure as code", "terraform", "relational database experience", "test runners", "scripting", "xamarin test cloud", "c#", "python", "groovy", "powershell", "bash", "wix", "setupbuilder", "application security testing tools", "bachelor\u2019s degree"]}, "2843be8b1c85fb92": {"terms": ["mlops"], "salary_min": 49.0, "salary_max": 59.0, "title": "technical writer (devops-confluence/jira, github, html, css, java, python) - remote", "company": "Randstad", "desc": "summary \n \n \n \n \n \n       $49 - $59 per hour\n      \n \n \n \n \n         contract\n        \n \n \n \n \n       bachelor degree\n      \n \n \n \n \n \n \n \n \n      category\n      computer and mathematical occupations\n    \n \n \n      reference\n      1029454\n    \n \n \n \n \n \n job summary:\n   Enterprise Healthcare client has an immediate opening for a highly motivated Systems Analysis Senior Advisor to join their dynamic and growing team. All qualified candidates are encouraged to apply!\n  \n  Obtain a deep understanding of products and services to translate complex product information into simple polished and engaging content\n   location: Bloomfield, Connecticut\n   job type: Contract\n   salary: $49 - 59 per hour\n   work hours: 8am to 5pm\n   education: Bachelors\n  \n  responsibilities:\n   Enterprise DevOps is looking for a Technical Writer to join our growing team. As the DevOps culture and supporting tool landscape gets more complex, the organization needs help keeping our documentation relevant and helpful to a diverse audience of software engineers, business partners and company leadership. If you are passionate about curating an elegant, well-organized experience for software developers, this role is for you.\n  \n  qualifications:\n  \n \n Experience level: Experienced  Minimum 5 years of experience \n    Education: Bachelors \n \n  skills: \n  \n DevOps \n  Systems Analysis \n  RF    Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.    At Randstad Digital, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.    Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).", "cleaned_desc": "", "techs": ""}, "0272392c061507e2": {"terms": ["mlops"], "salary_min": 0.0, "salary_max": 110.0, "title": "AWS DevOps Engineer", "company": "Real Soft, Inc.", "desc": "Job Description \n OneMain Financial is the country's largest lending-exclusive financial company, proudly serving millions of customers with safe, affordable and transparent installment loans. Our customers turn to us every day-online and at over 1,400 branches in 44 states-to help them take control and improve their financial lives . It's all about doing the right thing-a mission that hasn't changed for more than 100 years. \n \n Programmatically create infrastructure in AWS, leveraging Autoscaling Groups, Security Groups, Route53, S3, and IAM. \n Experience with Git. Enable our data development team to deliver new code daily through Continuous Integration and Deployment Pipelines. \n Build data infrastructure related to end to end data factory platform using Terraform and related technologies. \n \n Mandatory Skills \n Terraform , EKS, ECS, Jenkins, Python #IND123 \n Job Type: Contract \n Pay: Up to $110.00 per hour \n Expected hours: 40 per week \n Experience level: \n \n 6 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote", "cleaned_desc": " Experience with Git. Enable our data development team to deliver new code daily through Continuous Integration and Deployment Pipelines. \n Build data infrastructure related to end to end data factory platform using Terraform and related technologies. \n \n Mandatory Skills ", "techs": ["git", "continuous integration", "continuous deployment", "pipelines", "terraform"]}, "e4acac8a3c4b9018": {"terms": ["mlops"], "salary_min": 170000.0, "salary_max": 170000.0, "title": "DevOps Engineer", "company": "Procom", "desc": "DevOps Engineer Intro :\n    We are seeking a DevOps Engineer to join our client's dynamic and innovative team. The ideal candidate will be accessible, and demonstrate excellent teamwork, problem-solving, and communication skills. This is a remote position, allowing you to work from the comfort of your home while being part of a collaborative and supportive team.\n   \n \n DevOps Engineer Job Details :\n    As a DevOps Engineer, you will be responsible for developing and maintaining our software infrastructure. Your role will involve managing the interchange of data between servers and users, ensuring high performance and responsiveness. You will also be responsible for integrating front-end elements into applications, so a basic understanding of front-end technologies is necessary.\n   \n \n DevOps Engineer Mandatory Skills :\n   \n \n Proven experience as a DevOps Engineer or similar role in software development \n Strong knowledge of scripting languages such as Python, Java, Ruby, etc. \n Experience with systems and IT operations \n Comfort with frequent, incremental code testing and deployment \n Strong grasp of automation tools \n Data management skills \n Understanding of front-end technologies and platforms \n Problem-solving attitude \n Team player \n \n \n DevOps Engineer Desired Skills :\n   \n \n Excellent communication skills \n Ability to work independently and as part of a team \n Strong problem-solving skills \n Ability to handle multiple tasks and priorities \n Knowledge of accessibility and security compliance \n Understanding of fundamental design principles behind a scalable application \n \n \n DevOps Engineer Start Date :\n    The start date for this position is flexible, and we are ready to welcome the right candidate as soon as they are available.\n   \n \n DevOps Engineer Location :\n    This is a remote position.", "cleaned_desc": " \n DevOps Engineer Mandatory Skills :\n   \n \n Proven experience as a DevOps Engineer or similar role in software development \n Strong knowledge of scripting languages such as Python, Java, Ruby, etc. \n Experience with systems and IT operations   Comfort with frequent, incremental code testing and deployment \n Strong grasp of automation tools \n Data management skills \n Understanding of front-end technologies and platforms \n Problem-solving attitude \n Team player \n ", "techs": ["python", "java", "ruby", "automation tools"]}, "metadata": {"keywords": ["data science", "data analyst", "data engineer", "machine learning engineer", "mlops"], "locations": ["remote"], "time_ran": "12:17:22-11-10-23", "num_jobs": 434, "timings": {"start_drivers": 46.219477891922, "find_job_ids": 437.806827545166, "get_job_descs": 192.66964030265808}, "models": {"classifier": {"clf": "data/classifier_models/job_desc_classifier_v1.0.pkl", "tfidf": "data/classifier_models/job_desc_tfidf_vectorizer_v1.0.pkl"}, "NER": "gpt-3.5-turbo"}}}