{
    "25e1bb73f0d50292": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89600.0,
        "salary_max": 134400.0,
        "title": "Senior Sportsbook Data Analyst",
        "company": "DraftKings",
        "desc": "We\u2019re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming. \n Here, \u201cimpossible\u201d isn\u2019t part of our vocabulary. You\u2019ll face some of the toughest but most rewarding challenges of your career. They\u2019re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers. The Crown Is Yours \n As a Senior Sportsbook Data Analyst, you\u2019ll support data analysis and reporting efforts to inform our current and future initiatives. Through cross-functional collaboration and inventive metrics building, you will enable teams across our organization to make smarter, better, and faster decisions. What you\u2019ll do as a Senior Sportsbook Data Analyst \n \n  Monitor sportsbook performance and diagnose areas of opportunity. Example areas include high-value customer analysis, state and sport trends, and promotion optimization. \n \n  Develop data analysis and reports to measure and inform sportsbook initiatives and use those to guide business decisions. \n \n  Conduct analyst-driven \u201cdeep dives\u201d that explore broad topics and inspire new ways of thinking about our customers and products. \n \n  Provide opportunity size for major promotional events to help the Sportsbook team capitalize on significant sporting events. \n \n  Mentor and coach other analysts across the business using best practices. \n \n  Work cross-functionally across promotions, customer retention management, operations, and VIP to understand customer behavior. What you'll bring \n \n  4+ years of business analytics experience, preferably at a sportsbook or gaming provider. \n \n  Ability to take complicated problems and build simple frameworks. \n \n  Comfortable presenting complicated data views to cross-functional audiences and senior leadership. \n \n  Expertise in SQL/Snowflake, and Excel. Proficiency in Tableau or similar data visualization tool. \n \n  Experience with R, Python, or statistical programming languages a plus. \n \n  Bachelor\u2019s degree or equivalent in Mathematics, Statistics, Computer Science, Business Analytics, or another relevant discipline. \n #LI-BG1 #LI-REMOTE Join Our Team \n \n We\u2019re a publicly traded (NASDAQ:  DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don\u2019t worry, we\u2019ll guide you through the process if this is relevant to your role. The US base salary range for this full-time position is $89,600.00 - $134,400.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",
        "cleaned_desc": "  Comfortable presenting complicated data views to cross-functional audiences and senior leadership. \n \n  Expertise in SQL/Snowflake, and Excel. Proficiency in Tableau or similar data visualization tool. \n \n  Experience with R, Python, or statistical programming languages a plus. ",
        "techs": [
            "sql/snowflake",
            "excel",
            "tableau",
            "r",
            "python"
        ],
        "cleaned_techs": [
            "sql",
            "excel",
            "tableau",
            "r",
            "python"
        ]
    },
    "2294034edbd9e7e9": {
        "terms": [
            "data science"
        ],
        "salary_min": 88000.0,
        "salary_max": 144000.0,
        "title": "Data Scientist II, Product Analytics",
        "company": "BOLD LLC",
        "desc": "United States (Remote) \n   \n \n We are looking for a  Data Scientist II, Product Analytics  to join the Data Analytics team at BOLD! This team partners with Product, Marketing, and Finance to produce world-class analysis and provide recommendations that improve our products and increase customer engagement. \n  This position is 100% remote, work from home (within lawfully allowed States). In some areas of the US, you may utilize a co-work space (when you\u2019d like). \n  Lawfully allowed states :  Arizona, California, Colorado, Connecticut, Florida, Georgia, Illinois, Iowa, Kentucky, Maine, Maryland, Massachusetts, Minnesota, Nevada, New Hampshire, New Jersey, New York, North Carolina, Ohio, Oklahoma, Oregon, Pennsylvania, Tennessee, Texas, Utah, Virginia, Washington \n  ABOUT THIS TEAM   \n Reporting to the Director of Product Analytics, the  Data Scientist II, Product Analytics  will provide critical insights to business partners and strategic support to the executive team. You will also have your fingers on the pulse of the business and develop metrics and reporting to keep the organization informed. Through your high-quality analysis and attention to detail, you will be the go-to person for product performance and insights. The ideal candidate is highly motivated and will use their technical skills and business acumen to quickly make an impact! \n  WHAT YOU\u2019LL DO \n \n Conduct in-depth analysis to uncover opportunities for improving our products. \n Work closely with business partners to extract meaningful insights using a variety of data sources: relational databases, front-end analytics tools, clickstream data, etc. \n Present insights and recommendations to executive leadership using high quality visualizations and concise messaging. \n Design and analyze A/B tests to drive KPI improvements. \n Build machine learning models to predict customer behavior and better understand the drivers of customer engagement and retention. \n Develop dashboards to inform business decisions with an emphasis on automation and scalability. \n Collaborate with Engineering to advance data infrastructure and governance. \n \n WHAT YOU\u2019LL NEED \n \n 5+ years\u2019 experience performing quantitative data analysis, preferably for an internet or technology company. \n Ability to write complex SQL queries to drive critical business decisions. \n Robust understanding of Statistics with ability to explain statistical concepts to non-technical audiences. \n Bachelors or Masters\u2019 degree in Math, Engineering, Statistics or other quantitative field, with a track record of academic excellence. \n Self-starter with a desire to learn and the ability to rapidly understand the business and its drivers. \n Proficiency with Python/R \n Experience with building machine learning/predictive models. \n Ability to handle multiple projects and meet deadlines in a fast-paced environment. \n \n WHAT\u2019S GOOD TO HAVE   \n \n Proficiency with BI tools such as Tableau, Looker, or equivalent \n Experience with Google Analytics, MixPanel or other front-end analytical platforms a plus. \n Experience with NLP (Natural Language Processing) is a plus. \n \n HERE\u2019S A FEW OF OUR PERKS & BENEFITS \n  EXCELLENT COMPENSATION \n \n Competitive Salary \n Bi-annual Bonus \n 401(k) Plan Equivalent (with company match) \n Company Equity \n Flexible Spending Account (FSA for health and dependent care) \n \n WE LIKE YOU HEALTHY \n \n Medical, Dental, and Vision Insurance (additional plans for your family) \n Mental Health and Wellness perks (apps, additional support, etc.) \n Sick Time \n Life Insurance and AD&D \n Short-Term and Long-Term Disability Insurance \n Wellness reimbursement (gym, health apps, etc.) \n \n WE WANT YOU HAPPY \n \n Flexible PTO (take what you need) \n 11 paid holidays a year \n Additional 1-week PTO over December holidays \n Home Internet reimbursement \n Home Office Equipment reimbursement \n \n Under San Francisco's Fair Chance Ordinance, qualified applicants with arrest and conviction records will be considered for the position. \n \n \n \n \n  Individual pay is based on location, transferable skills, experience, and other relevant factors. This estimated range is based on the best available market data and factors, all of which are subject to change. This position may also be eligible for a bonus and medical, dental, vision, life, short and long-term disability insurance, 401(k), paid time off, sick leave, and paid holidays, all subject to applicable plan terms. \n \n \n     Starting Pay Range \n    \n \n    $88,000\u2014$144,000 USD\n    \n \n \n \n  ABOUT BOLD  As an established global organization (17 years and counting), BOLD helps people find jobs. Our story is one of growth, success, and professional fulfillment.  We create digital products that have empowered over three million people in 180 countries to build stronger resumes, cover letters, and CVs. The result of our work helps people interview confidently, finding the right job in less time.  Our employees are experts, learners, contributors, and creatives.     BOLD VALUES OUR POSITION AS AN EQUAL OPPORTUNITY EMPLOYER   WE VALUE, CELEBRATE, AND PROMOTE DIVERSITY AND INCLUSION.  We hire based on qualifications, merit, and our business needs. We don't discriminate regarding race, color, religion, gender, pregnancy, national origin or citizenship, ancestry, age, physical or mental disability, veteran status, sexual orientation, gender identity or expression, marital status, genetic information, or any other applicable characteristic protected by law. \n \n \n \n \n   United States (Remote)\n    \n  Data Scientist II, Product Analytics",
        "cleaned_desc": " Collaborate with Engineering to advance data infrastructure and governance. \n \n WHAT YOU\u2019LL NEED \n \n 5+ years\u2019 experience performing quantitative data analysis, preferably for an internet or technology company. \n Ability to write complex SQL queries to drive critical business decisions. \n Robust understanding of Statistics with ability to explain statistical concepts to non-technical audiences. \n Bachelors or Masters\u2019 degree in Math, Engineering, Statistics or other quantitative field, with a track record of academic excellence. \n Self-starter with a desire to learn and the ability to rapidly understand the business and its drivers. \n Proficiency with Python/R \n Experience with building machine learning/predictive models. \n Ability to handle multiple projects and meet deadlines in a fast-paced environment. \n \n WHAT\u2019S GOOD TO HAVE   \n \n Proficiency with BI tools such as Tableau, Looker, or equivalent ",
        "techs": [
            "sql",
            "statistics",
            "math",
            "engineering",
            "python/r",
            "tableau",
            "looker"
        ],
        "cleaned_techs": [
            "sql",
            "statistics",
            "math",
            "engineering",
            "python",
            "tableau",
            "looker"
        ]
    },
    "68b2fb9e611fb9c0": {
        "terms": [
            "data science"
        ],
        "salary_min": 105222.74,
        "salary_max": 133235.44,
        "title": "Product Leader - Healthcare, AI, Machine Learning, Data Science",
        "company": "Xen.ai",
        "desc": "About the company \n Xen.AI, is an Artificial Intelligence (AI) research and development (R&D) organization with operations in USA and India. We help our customers to develop innovative and customized solutions using Artificial Intelligence, Machine Learning, Deep Learning, Data Science and Open Source technologies. Please visit https://xen.ai/ to know more about us. \n Compensation for this position \n \n For the 1st year - 100% revenue based compensation based on the client projects that you help to win and deliver. \n After 1st year, based on company's progress we can consider formal corporate positions with market standard salary and equity etc. \n \n About the position \n Xen.AI is actively looking for a highly motivated Health Product leader with strong hands-on experience with AI, Machine Learning, Deep Learning, Python and other Data Science technologies and healthcare domain experience to join our growing team. This role involves building major product features in an iterative and collaborative environment as part of an agile team. Selected candidates would be able to work remotely from any location. This can be a full time or part-time role. For the 1st year compensation would be 100% revenue based on the client projects that you help to deliver. \n Role Summary \n \n Define the vision & roadmap for the products in the Xen.AI\u2019s Healthcare portfolio. \n Design and implement state-of-the-art AI/ML models for disease detection through acquisition, reconstruction, processing and analysis of medical images. \n Translate new AI technologies into product solutions for improved clinical care. \n Develop prototypes for new Analytical and AI/ML solutions in Healthcare that can be productized as SaaS applications. \n Collaborate with clinicians and customers to address unmet clinical needs. \n Conduct original research resulting in patents and scientific publications. \n \n Qualifications \n \n Bachelor's degree in Computer Science, Electrical Engineering, Biomedical Engineering or relevant Engineering areas \n M.S./Ph.D. (Candidate) in EE/CS/BME or related fields. \n Strong hands-on experience in general AI/ML, deep learning, computer vision, statistical pattern recognition, image and signal processing. \n Deep knowledge and experience in working Open Source software tools & technologies used in Healthcare and Medical Imaging. \n Familiar with Electronic Health Record (EHR). \n Excellent programming skills in Python and R. \n Experience with deep learning tools & frameworks (TensorFlow, PyTorch, Keras, Caffe, etc) \n Established track record of delivering productive solutions in Healthcare is a strong plus. \n Knowledge of rules & regulations related to healthcare software products is a plus. \n Strong experience on 1 or more OS: Linux, Windows, iOS. \n Strong development experience working with cloud computing tools & technologies. Strong experience with Azure is a strong plus. \n Strong team player, experience managing teams. \n Collaborative, self-motivated and have a can-do attitude. \n Must have Work Authorization in US, we will not be able to support any VISA sponsorship. No H1B or OPT. \n \n Compensation for this position \n \n For the 1st year - 100% revenue based compensation based on the client projects that you help to get and deliver. \n After 1st year, based on company's progress we can consider formal corporate positions with market standard salary and equity etc. \n \n Please visit https://xen.ai/ to know more about us. \n Job Types: Part-time, Contract \n Pay: $1.00 per year \n Experience level: \n \n 10 years \n \n Schedule: \n \n Choose your own hours \n \n Experience: \n \n Healthcare, AI, Machine Learning & Data Science: 5 years (Required) \n Product management: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Strong hands-on experience in general AI/ML, deep learning, computer vision, statistical pattern recognition, image and signal processing. \n Deep knowledge and experience in working Open Source software tools & technologies used in Healthcare and Medical Imaging. \n Familiar with Electronic Health Record (EHR). \n Excellent programming skills in Python and R. \n Experience with deep learning tools & frameworks (TensorFlow, PyTorch, Keras, Caffe, etc) \n Established track record of delivering productive solutions in Healthcare is a strong plus. \n Knowledge of rules & regulations related to healthcare software products is a plus. \n Strong experience on 1 or more OS: Linux, Windows, iOS. \n Strong development experience working with cloud computing tools & technologies. Strong experience with Azure is a strong plus. \n Strong team player, experience managing teams. \n Collaborative, self-motivated and have a can-do attitude. ",
        "techs": [
            "ai/ml",
            "deep learning",
            "computer vision",
            "statistical pattern recognition",
            "image processing",
            "signal processing",
            "open source software tools",
            "healthcare",
            "medical imaging",
            "electronic health record (ehr)",
            "python",
            "r",
            "tensorflow",
            "pytorch",
            "keras",
            "caffe",
            "deep learning tools & frameworks",
            "healthcare solutions",
            "rules & regulations",
            "os (linux",
            "windows",
            "ios)",
            "cloud computing tools & technologies",
            "azure",
            "team management"
        ],
        "cleaned_techs": [
            "ai",
            "computer vision",
            "statistical pattern recognition",
            "image processing",
            "signal processing",
            "open source software tools",
            "healthcare",
            "medical imaging",
            "electronic health record (ehr)",
            "python",
            "r",
            "tensorflow",
            "pytorch",
            "keras",
            "caffe",
            "deep learning tools & frameworks",
            "healthcare solutions",
            "rules & regulations",
            "os (linux",
            "windows",
            "ios)",
            "cloud computing tools & technologies",
            "azure",
            "team management"
        ]
    },
    "4c3fbfac4145f8c9": {
        "terms": [
            "data science"
        ],
        "salary_min": 140900.0,
        "salary_max": 225100.0,
        "title": "Senior Data Scientist",
        "company": "Zillow",
        "desc": "About the team  Zillow Group's acquisition of ShowingTime in 2021 represents the next step forward in the company's dedication to integrate an improved, more efficient showing process to benefit customers and partners, their clients and the real estate industry as a whole.\n  \n  The new ShowingTime+ organization is a market leader in developing innovative showing management, feedback, offer management, recruiting, transaction management and analytics solutions. Our wide array of products and services are built on technological innovations crafted to bring efficiencies to all users.\n  \n  About the role \n  The Product Analytics team within ShowingTime+ is hiring a Senior Data Scientist to lead analytics to uncover insights to drive both better business decisions and customer experiences across our product portfolio. \n \n  You Will Get To: \n \n  Collaborate with team members across product, engineering, marketing, operations, and more to develop evidence based approaches to finding gaps in the customer experience. \n  Use advanced analytics including clustering, propensity modeling, statistical knowledge, and other explanatory and causal inference techniques to gain a clearer picture of customer behavior. \n  Build compelling data stories and visualizations to influence decision makers. \n  Serve as a mentor and resource to other data scientists on the team. \n  Design and implement A/B tests, perform regression modeling, and provide recommendations for Showingtime+'s roadmap. \n \n  This role has been categorized as a Remote position. \u201cRemote\u201d employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.\n   In California, Colorado, Connecticut, Nevada, New York and Washington the standard base pay range for this role is $140,900.00 - $225,100.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York and Washington and may not be applicable to other locations.\n   In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.\n  \n  Who you are \n  You are ready to bring your data and analytics expertise to transform what it means for the real estate industry to unlock the ability for consumers to dream, search, and find a home. You have an appreciation of the unique challenges posed by business to business product development and go-to-market. \n \n  Additionally, we expect you to have: \n \n  An undergraduate or Master\u2019s degree in a quantitative field (e.g. mathematics, engineering, statistics, finance, or similar) \n  4 - 5+ years of work experience involving quantitative data analysis and complex problem solving. Experience working with product teams strongly preferred. \n  A strong understanding of statistical concepts, measurement issues, and inference techniques. \n  Proficiency in SQL, Excel, and either Python or R, along with some experience with Tableau, Mode, or other visualization software. \n  Extensive experience querying multi-terabyte-sized noisy data sets such as clickstream data. \n  Experience with ETL pipelines, scheduling and productionalizing is a plus. \n  Experience with A/B Testing, Experimentation, or Casual Inference \n  Strong written, verbal, and visual communication skills with the ability to work cross-functionally. \n \n \n  Get to know us \n  Zillow is reimagining real estate to make home a reality for more and more people. \n \n  As the most-visited real estate website in the United States, Zillow\u00ae and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people. \n \n  Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We\u2019re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don\u2019t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees\u2019 Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list. \n \n  Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com. \n \n  Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.",
        "cleaned_desc": "  An undergraduate or Master\u2019s degree in a quantitative field (e.g. mathematics, engineering, statistics, finance, or similar) \n  4 - 5+ years of work experience involving quantitative data analysis and complex problem solving. Experience working with product teams strongly preferred. \n  A strong understanding of statistical concepts, measurement issues, and inference techniques. \n  Proficiency in SQL, Excel, and either Python or R, along with some experience with Tableau, Mode, or other visualization software. \n  Extensive experience querying multi-terabyte-sized noisy data sets such as clickstream data. \n  Experience with ETL pipelines, scheduling and productionalizing is a plus. \n  Experience with A/B Testing, Experimentation, or Casual Inference \n  Strong written, verbal, and visual communication skills with the ability to work cross-functionally. ",
        "techs": [
            "sql",
            "excel",
            "python",
            "r",
            "tableau",
            "mode"
        ],
        "cleaned_techs": [
            "sql",
            "excel",
            "python",
            "r",
            "tableau",
            "mode"
        ]
    },
    "b94efa3b6c55670b": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Lead Data Scientist - Primary Care",
        "company": "CenterWell",
        "desc": "CenterWell\u2122 represents our payer-agnostic healthcare services for senior primary care, home health and pharmacy. Launched in spring 2021, CenterWell creates experiences that provide patients with ease, comprehensive care and a personal approach. By placing each patient at the center \u2014 focusing on their unique needs and personalizing the care we deliver to them \u2014 we can help them lead happier, healthier lives. \n  \n  CenterWell Senior Primary Care\u2122 provides proactive, preventive care to seniors, including wellness visits, physical exams, chronic condition management, screenings, minor injury treatment and more. It is part of Humana\u2019s Primary Care Organization, which is the nation\u2019s largest provider of value-based, senior-focused primary care. \n  \n  More about CenterWell Senior Primary Care: \n  \n  More than 85 locations, which are part of the 250 senior primary care centers operated by Humana\u2019s Primary Care Organization \n  \n  Integrated care teams that include physicians, nurse practitioners, medical assistants, medical coders and center administrators \n  \n  Nearly 250,000 total patients served in 2022, including those in Medicare Advantage, value-based arrangements or other Medicare programs\n  \n  The Lead Data Scientist uses mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions. The Lead Data Scientist works on problems of diverse scope and complexity ranging from moderate to substantial.\n  \n  Responsibilities \n  The Lead Data Scientist develops, maintains, and collects structured and unstructured data sets for analysis and reporting. Creates reports, projections, models, and presentations to support business strategy and tactics. Advises executives to develop functional strategies (often segment specific) on matters of significance. Exercises independent judgment and decision making on complex issues regarding job duties and related tasks, and works under minimal supervision, Uses independent judgment requiring analysis of variable factors and determining the best course of action. \n \n  Required Qualifications \n \n  Bachelor's degree and 3 years of experience \n  2 or more years project leadership experience \n  Experience in using mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions \n  Successful demonstrated experience in working on problems of diverse scope and complexity ranging from moderate to substantial \n  Experience in developing, maintaining, and collecting structured and unstructured data sets for analysis and reporting \n  Experience in creating reports, projections, models, and presentations to support business \n  Ability to exercise independent judgment and decision making on complex issues regarding job duties and related tasks \n  Ability to works under minimal supervision, using independent judgment \n  Must be passionate about contributing to an organization focused on continuously improving consumer experiences \n \n \n  Preferred Qualifications \n \n  Master's Degree \n \n \n  Additional Information \n \n  Interview Format: MODERN HIRE \n  As part of our hiring process, we will be using an exciting interviewing technology provided by Modern Hire, a third-party vendor. This technology provides our team of recruiters and hiring managers an enhanced method for decision-making. \n  If you are selected to move forward from your application prescreen, you will receive correspondence inviting you to participate in a pre-recorded Voice Interview and/or an SMS Text Messaging interview. If participating in a pre-recorded interview, you will respond to a set of interview questions via your phone. You should anticipate this interview to take approximately 10-15 minutes. \n  If participating in a SMS Text interview, you will be asked a series of questions to which you will be using your cell phone or computer to answer the questions provided. Expect this type of interview to last anywhere from 5-10 minutes. Your recorded interview(s) via text and/or pre-recorded voice will be reviewed and you will subsequently be informed if you will be moving forward to next round of interviews. \n \n  Benefits \n \n  Humana offers a variety of benefits to promote the best health and well-being of our employees and their families. We design competitive and flexible packages to give our employees a sense of financial security\u2014both today and in the future, including: \n \n  Health benefits effective day 1 \n  Paid time off, holidays, volunteer time and jury duty pay \n  Recognition pay \n  401(k) retirement savings plan with employer match \n  Tuition assistance \n  Scholarships for eligible dependents \n  Parental and caregiver leave \n  Employee charity matching program \n  Network Resource Groups (NRGs) \n  Career development opportunities \n \n \n  Remote \n  #LI-BL1 \n \n  Scheduled Weekly Hours \n  40\n  \n  Pay Range  The compensation range below reflects a good faith estimate of starting base pay for full time (40 hours per week) employment at the time of posting. The pay range may be higher or lower based on geographic location and individual pay decisions will vary based on demonstrated job related skills, knowledge, experience, education, certifications, etc.\n  \n  $126,800 - $174,500 per year\n  \n  This job is eligible for a bonus incentive plan. This incentive opportunity is based upon company and/or individual performance.\n  \n  Description of Benefits  Humana, Inc. and its affiliated subsidiaries (collectively, \u201cHumana\u201d) offers competitive benefits that support whole-person well-being. Associate benefits are designed to encourage personal wellness and smart healthcare decisions for you and your family while also knowing your life extends outside of work. Among our benefits, Humana provides medical, dental and vision benefits, 401(k) retirement savings plan, time off (including paid time off, company and personal holidays, volunteer time off, paid parental and caregiver leave), short-term and long-term disability, life insurance and many other opportunities.\n \n  Not Specified \n  0",
        "cleaned_desc": "  Responsibilities \n  The Lead Data Scientist develops, maintains, and collects structured and unstructured data sets for analysis and reporting. Creates reports, projections, models, and presentations to support business strategy and tactics. Advises executives to develop functional strategies (often segment specific) on matters of significance. Exercises independent judgment and decision making on complex issues regarding job duties and related tasks, and works under minimal supervision, Uses independent judgment requiring analysis of variable factors and determining the best course of action. \n \n  Required Qualifications \n \n  Bachelor's degree and 3 years of experience \n  2 or more years project leadership experience \n  Experience in using mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions \n  Successful demonstrated experience in working on problems of diverse scope and complexity ranging from moderate to substantial \n  Experience in developing, maintaining, and collecting structured and unstructured data sets for analysis and reporting \n  Experience in creating reports, projections, models, and presentations to support business \n  Ability to exercise independent judgment and decision making on complex issues regarding job duties and related tasks \n  Ability to works under minimal supervision, using independent judgment \n  Must be passionate about contributing to an organization focused on continuously improving consumer experiences ",
        "techs": [
            "mathematics",
            "statistics",
            "modeling",
            "business analysis",
            "technology"
        ],
        "cleaned_techs": [
            "mathematics",
            "statistics",
            "modeling",
            "business analysis",
            "technology"
        ]
    },
    "34dbad9b6ac63108": {
        "terms": [
            "data science"
        ],
        "salary_min": 115345.0,
        "salary_max": 149270.0,
        "title": "Senior Data Scientist Operations Consumer/Mortgage Banking - Remote",
        "company": "U.S. Bank National Association",
        "desc": "At U.S. Bank, we\u2019re on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at\u2014all from Day One. \n \n  Job Description \n  RESPONSIBILITIES \n  Responsible for big data/analytics projects that gather and integrate large volumes of data. Specializes in developing and programming methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate insights and solutions for client services and product enhancement. Acquires data from multiple data sources to perform analysis. Implements and validates predictive models as well as create and maintain statistical models with a focus on big data. Identifies, analyzes and interprets trends or patterns in complex data to provide answers to business questions as well as provide recommendations for action. Interprets data and analyzes results using various advanced statistical techniques and tools. Presents data and analysis in a clear and concise manner allowing the audience to quickly understand the results and recommendations and make data driven decisions. Collaborates with various partners to prioritize requests/needs and provide a holistic view of the analysis. Measures and monitors results of applied recommendations and present adjustments. Ensures all data acquisition, sharing and results of applied recommendations are compliant with company standards. \n   \n \n  REQUIRED\n   \n \n Eight or more years of relevant experience \n \n \n \n Bachelor's degree in a quantitative field such as statistics, computer science, engineering or applied mathematics, or equivalent work experience \n \n  PREFERRED\n  \n \n Strong analytic skills with the ability to extract, collect, organize, analyze and interpret trends or patterns in complex data sets \n Experience in analytics, advanced analytics/statistics, predictive modeling, machine learning, data visualization \n Understanding of machine learning techniques and algorithms \n Experience in python/R/SAS/SQL for data extraction, data mining, and predictive analytics \n Demonstrated project management skills \n Effective interpersonal, verbal and written communication skills \n \n   \n #CBBOJobs \n \n  If there\u2019s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants. \n \n  Benefits: \n  Our approach to benefits and total rewards considers our team members\u2019 whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours): \n \n  Healthcare (medical, dental, vision) \n  Basic term and optional term life insurance \n  Short-term and long-term disability \n  Pregnancy disability and parental leave \n  401(k) and employer-funded retirement plan \n  Paid vacation (from two to five weeks depending on salary grade and tenure) \n  Up to 11 paid holiday opportunities \n  Adoption assistance \n  Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law \n \n \n  EEO is the Law \n  U.S. Bank is an equal opportunity employer committed to creating a diverse workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors. \n \n  E-Verify \n  U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services. \n  The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, US Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401k contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $115,345.00 - $135,700.00 - $149,270.00\n   U.S. Bank will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.",
        "cleaned_desc": " Eight or more years of relevant experience \n \n \n \n Bachelor's degree in a quantitative field such as statistics, computer science, engineering or applied mathematics, or equivalent work experience \n \n  PREFERRED\n  \n \n Strong analytic skills with the ability to extract, collect, organize, analyze and interpret trends or patterns in complex data sets   Experience in analytics, advanced analytics/statistics, predictive modeling, machine learning, data visualization \n Understanding of machine learning techniques and algorithms \n Experience in python/R/SAS/SQL for data extraction, data mining, and predictive analytics \n Demonstrated project management skills \n Effective interpersonal, verbal and written communication skills \n \n   \n #CBBOJobs \n \n  If there\u2019s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants. ",
        "techs": [
            "statistics",
            "computer science",
            "engineering",
            "applied mathematics",
            "analytics",
            "advanced analytics",
            "statistics",
            "predictive modeling",
            "machine learning",
            "data visualization",
            "machine learning techniques",
            "algorithms",
            "python",
            "r",
            "sas",
            "sql",
            "data extraction",
            "data mining",
            "predictive analytics",
            "project management",
            "interpersonal skills",
            "verbal communication skills",
            "written communication skills"
        ],
        "cleaned_techs": [
            "statistics",
            "computer science",
            "engineering",
            "applied mathematics",
            "advanced analytics",
            "predictive modeling",
            "data visualization",
            "machine learning techniques",
            "algorithms",
            "python",
            "r",
            "sas",
            "sql",
            "data extraction",
            "data mining",
            "predictive analytics",
            "project management"
        ]
    },
    "dbc8260cec951fa7": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 64000.0,
        "salary_max": 74000.0,
        "title": "Data Engineer",
        "company": "Catalist",
        "desc": "For over 17 years, Catalist has been a leader in civic data and data science innovation. Our mission is to provide progressive organizations with the data, software, and services needed to better identify, understand, and communicate with the people they need to engage and mobilize. Our clients include the largest, most influential organizations in the U.S. active in civic engagement, advocacy, and political campaigns.\n  \n \n \n  Catalist is home to a dedicated, creative team of technologists, data scientists, and campaign experts committed to using our talents and technology to nurture a vibrant and growing progressive community.\n  \n \n \n  As a Data Engineer at Catalist, you will work closely with the Analytics and Technology departments to design, build, support, and maintain various data pipelines and processes with an end goal of providing data and intelligence to the progressive community. This role primarily involves translating data architecture designs into functional processes, code, and systems.\n  \n \n \n  The ideal candidate will be a highly motivated individual with excellent technical skills, a strong desire to learn new skills, and an interest in progressive politics. Catalist values creativity and problem-solving. Our work is on the cutting edge of data-driven politics, and your support will help Democratic candidates and progressive organizations conduct successful advocacy and electoral campaigns.\n  \n \n \n  This position reports to the Deputy Chief Data Officer. The Data Engineer is a part of a growing Data team that supports all underlying work at Catalist.\n  \n Principle Duties & Responsibilities \n \n  Develop scalable, production processes, code, and systems for data ingest, transformation, modeling, and reporting across a variety of platforms \n  Translate mock-ups and designs into functional processes, code, and systems \n  Create architecture designs when needed \n  Provide quality assurance and testing on processes, code, systems, and products \n  Become an internal subject matter expert on various datasets and support other Catalist departments/teams on usage of those datasets \n  Execute ad-hoc data and database maintenance tasks as requiredProject manage cross-departmental efforts, with direct responsibility for stakeholder engagement, management, and execution of technical elements \n \n  Requirements \n \n  BS or BA in a technical field, or relevant experience \n  1-2 years of experience working with SQL databases \n  Experience with data cleaning or ETL processes \n  Experience with distributed computing systems and/or distributed datastores (particularly the Hadoop ecosystem) \n  Experience managing projects \n  Familiarity with Catalist data, progressive politics, voter files, and/or commercial data \n  Background check required \n \n  Preferred Skills & Abilities \n \n  Willingness to be a problem solver and produce results in a fast paced environment \n  Ability to be creative and personable, and articulate ideas clearly \n  Experience working with SQL databases \n  Proficiency with Python or another object-oriented programming language (R, Java, Scala, etc\u2026) \n  Experience working in cloud environments (AWS, GCP, etc.) \n  Experience working in command line environments such as Bash \n  Experience with a version control tool such as git or github \n \n \n   Benefits\n  \n \n  Medical, Dental, Vision, Prescription Drug \n \n \n   Catalist offers Medical, Dental, Vision, and Prescription Drug coverage for eligible staff and their eligible dependents. Catalist\u2019s Medical plan is a comprehensive PPO program including Prescription Drug coverage with 85% of the premium paid by Catalist. Dental and Vision coverage is provided at no cost to employees.\n  \n \n \n  Group Term Life Insurance and Long-Term & Short-Term Disability Coverage \n \n \n   Group Term Life Insurance and Long-Term and Short-Term Disability coverage is available for eligible staff. These benefits are provided at no cost to Catalist employees.\n  \n \n \n  401(k) Safe Harbor Plan \n \n \n   A 401(k) Safe Harbor Plan is available to eligible staff with a 3% contribution from Catalist from the date of hire. Employees may contribute pre-tax or post-tax from their salary up to the legal limits set forth by the IRS.\n  \n \n \n  Medical and Dependent Care Flexible Spending Accounts (FSAs) \n \n \n   Catalist offers an FSA Program that gives eligible staff the ability to pay out-of-pocket medical/dental/vision/child care expenses from pre-tax earnings.\n  \n \n \n  Transit Benefits \n \n \n   Catalist also makes available a Transit benefit FSA program to eligible employees using pre-tax contributions with a company match.\n  \n \n \n  Professional Development and Remote Work Expenses \n \n \n   Eligible employees may be reimbursed up to $750 each year for professional development / education and remote work expenses.\n  \n \n \n  Student Loan PayDown or SaveUp \n \n \n   Catalist offers a Student Loan PayDown and College SaveUp benefit for eligible staff.\n  \n \n \n  Vacation, Personal Leave, Sick Leave Benefits \n \n \n   Catalist offers generous vacation benefits to all eligible staff. Eligible employees also receive:\n  \n \n 14 Paid Holidays \n Personal Days \n Sick Leave \n Parental Leave \n \n \n \n  Hybrid Office/Remote Work \n \n \n   Certain positions at Catalist are eligible for Office/Remote Hybrid or full Remote status.",
        "cleaned_desc": "For over 17 years, Catalist has been a leader in civic data and data science innovation. Our mission is to provide progressive organizations with the data, software, and services needed to better identify, understand, and communicate with the people they need to engage and mobilize. Our clients include the largest, most influential organizations in the U.S. active in civic engagement, advocacy, and political campaigns.\n  \n \n \n  Catalist is home to a dedicated, creative team of technologists, data scientists, and campaign experts committed to using our talents and technology to nurture a vibrant and growing progressive community.\n  \n \n \n  As a Data Engineer at Catalist, you will work closely with the Analytics and Technology departments to design, build, support, and maintain various data pipelines and processes with an end goal of providing data and intelligence to the progressive community. This role primarily involves translating data architecture designs into functional processes, code, and systems.\n  \n \n \n  The ideal candidate will be a highly motivated individual with excellent technical skills, a strong desire to learn new skills, and an interest in progressive politics. Catalist values creativity and problem-solving. Our work is on the cutting edge of data-driven politics, and your support will help Democratic candidates and progressive organizations conduct successful advocacy and electoral campaigns.\n  \n \n \n  This position reports to the Deputy Chief Data Officer. The Data Engineer is a part of a growing Data team that supports all underlying work at Catalist.\n  \n Principle Duties & Responsibilities \n \n  Develop scalable, production processes, code, and systems for data ingest, transformation, modeling, and reporting across a variety of platforms \n  Translate mock-ups and designs into functional processes, code, and systems \n  Create architecture designs when needed    Provide quality assurance and testing on processes, code, systems, and products \n  Become an internal subject matter expert on various datasets and support other Catalist departments/teams on usage of those datasets \n  Execute ad-hoc data and database maintenance tasks as requiredProject manage cross-departmental efforts, with direct responsibility for stakeholder engagement, management, and execution of technical elements \n \n  Requirements \n \n  BS or BA in a technical field, or relevant experience \n  1-2 years of experience working with SQL databases \n  Experience with data cleaning or ETL processes \n  Experience with distributed computing systems and/or distributed datastores (particularly the Hadoop ecosystem) \n  Experience managing projects \n  Familiarity with Catalist data, progressive politics, voter files, and/or commercial data \n  Background check required \n \n  Preferred Skills & Abilities \n \n  Willingness to be a problem solver and produce results in a fast paced environment \n  Ability to be creative and personable, and articulate ideas clearly \n  Experience working with SQL databases \n  Proficiency with Python or another object-oriented programming language (R, Java, Scala, etc\u2026) \n  Experience working in cloud environments (AWS, GCP, etc.) \n  Experience working in command line environments such as Bash \n  Experience with a version control tool such as git or github ",
        "techs": [
            "catalist",
            "data science",
            "data pipelines",
            "data architecture",
            "progressive politics",
            "sql databases",
            "data cleaning",
            "etl processes",
            "hadoop ecosystem",
            "project management",
            "catalist data",
            "voter files",
            "commercial data",
            "python",
            "object-oriented programming language",
            "cloud environments",
            "aws",
            "gcp",
            "bash",
            "git",
            "github"
        ],
        "cleaned_techs": [
            "catalist",
            "data science",
            "data pipelines",
            "data architecture",
            "progressive politics",
            "sql",
            "data cleaning",
            "etl processes",
            "hadoop ecosystem",
            "project management",
            "catalist data",
            "voter files",
            "commercial data",
            "python",
            "object-oriented programming language",
            "cloud environments",
            "aws",
            "gcp",
            "bash",
            "git",
            "github"
        ]
    },
    "e69bfd9e5f00cb76": {
        "terms": [
            "data science"
        ],
        "salary_min": 126793.55,
        "salary_max": 160548.89,
        "title": "Practice Lead \u2013 Data Science",
        "company": "i2e Consulting",
        "desc": "As a Practice Lead- Data Science, you will play a pivotal role in driving the success of the data science initiatives, leading multi-disciplinary teams and delivering a wide range of client, internal, and research and development projects. Your expertise in visualization tools, machine learning platforms, and emerging technologies will be instrumental in data-driven decision-making and delivering innovative solutions to our clients. As Practice Lead-Data Science you will oversee the practice\u2019s financial performance, including budgeting, forecasting, and financial planning, and ensure that we are meeting customer expectations and staying up to date with industry trends. Additionally, you will be responsible for leading and mentoring a team of data scientists and analysts. \n  Experience:  8+ Years \n  Responsibilities: \n \n Develop a vision and establish strategic goals for the Data Science practice. Drive excellence in multiple areas, including but not limited to web app development (Angular, Vue), data visualization (Spotfire, Tableau, Power BI), data engineering (Dataiku, Python, R), automation (UiPath, Microsoft Power Apps, shell scripting), and chatbots (AWS Lex and Alexa). \n Manage global service delivery projects, ensuring on-time, and on-budget delivery of high-quality software. \n Stay updated with industry trends in Data Analytics, recommending innovative approaches and best practices. \n Build and lead the analytics team, ensuring optimal resource allocation, workload distribution, and identifying skill gaps. \n Provide guidance, mentorship, and performance feedback to the team members, fostering a high-performance culture. \n Engage in pre-sales activities, collaborating with sales, pre-sales, and business development teams to drive revenue growth. \n Support the Sales and Marketing teams in writing proposals, RFI/RFPs, creating sales collateral, and identifying upsell and cross-sell opportunities. \n Monitor the financial performance of the practice, advising senior management on the implementation of new technologies and their possible impact. \n Keep abreast of emerging technology trends and assess their possible impact on the organization\u2019s technological platforms. \n Cultivate relationships with key stakeholders, mentor team members on technical best practices, and identify growth opportunities for the practice. \n \n  Ideal Candidate: \n \n A Bachelor\u2019s or Master\u2019s Degree in computer science, engineering, or a related field. \n Minimum 8 years of experience, including 2 years in technology leadership roles, managing complex technology platforms and teams. \n Extensive experience in leading data analytics and visualization teams, using analytics and visualization tools like Spotfire, Tableau, Power BI, and ML platforms. \n Solid background in data engineering, including proficiency in tools like Dataiku, Python, R etc. \n Experience in designing modern and scalable architectures on cloud platforms such as AWS and Azure. \n Strong leadership, mentoring, and project management skills, with a track record of inspiring talent, delivering successful projects, and excellent client-facing skills. \n Ability to establish and implement long-term technology strategies aligned with the company\u2019s business strategy. \n Proven ability to grow a business in collaboration with Sales and Marketing teams. \n Excellent problem-solving and communication skills.",
        "cleaned_desc": "As a Practice Lead- Data Science, you will play a pivotal role in driving the success of the data science initiatives, leading multi-disciplinary teams and delivering a wide range of client, internal, and research and development projects. Your expertise in visualization tools, machine learning platforms, and emerging technologies will be instrumental in data-driven decision-making and delivering innovative solutions to our clients. As Practice Lead-Data Science you will oversee the practice\u2019s financial performance, including budgeting, forecasting, and financial planning, and ensure that we are meeting customer expectations and staying up to date with industry trends. Additionally, you will be responsible for leading and mentoring a team of data scientists and analysts. \n  Experience:  8+ Years \n  Responsibilities: \n \n Develop a vision and establish strategic goals for the Data Science practice. Drive excellence in multiple areas, including but not limited to web app development (Angular, Vue), data visualization (Spotfire, Tableau, Power BI), data engineering (Dataiku, Python, R), automation (UiPath, Microsoft Power Apps, shell scripting), and chatbots (AWS Lex and Alexa).    Ideal Candidate: \n \n A Bachelor\u2019s or Master\u2019s Degree in computer science, engineering, or a related field. \n Minimum 8 years of experience, including 2 years in technology leadership roles, managing complex technology platforms and teams. \n Extensive experience in leading data analytics and visualization teams, using analytics and visualization tools like Spotfire, Tableau, Power BI, and ML platforms.   Solid background in data engineering, including proficiency in tools like Dataiku, Python, R etc. \n Experience in designing modern and scalable architectures on cloud platforms such as AWS and Azure. \n Strong leadership, mentoring, and project management skills, with a track record of inspiring talent, delivering successful projects, and excellent client-facing skills. \n Ability to establish and implement long-term technology strategies aligned with the company\u2019s business strategy. \n Proven ability to grow a business in collaboration with Sales and Marketing teams. ",
        "techs": [
            "angular",
            "vue",
            "spotfire",
            "tableau",
            "power bi",
            "dataiku",
            "python",
            "r",
            "uipath",
            "microsoft power apps",
            "shell scripting",
            "aws lex",
            "alexa"
        ],
        "cleaned_techs": [
            "angular",
            "vue",
            "spotfire",
            "tableau",
            "powerbi",
            "dataiku",
            "python",
            "r",
            "uipath",
            "microsoft power apps",
            "shell scripting",
            "aws",
            "alexa"
        ]
    },
    "b59f3af39b0db2d6": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 139215.69,
        "salary_max": 176278.1,
        "title": "Principal Data Scientist",
        "company": "Amplify Consulting Partners",
        "desc": "ABOUT THE COMPANY \n  Amplify Consulting Partners is a data-first consulting company trusted by Fortune 500 businesses to deliver high-impact professional services across the technology ecosystem\u2014from data engineering and visual analytics to data-driven marketing and program management. \n  We build and empower high-performing people by promoting growth and connection across our company culture. We don't just hang core values on the wall, we make every decision with them in mind\u2014developing trusted, long-term relationships on a foundation of transparency and accountability. \n  DEI STATEMENT \n  We hold ourselves accountable for creating an authentic workplace where every person feels heard and experiences a sense of belonging. \n  We believe that organizations can be an instrument for positive human impact when they champion a diverse, inclusive, and equitable environment. We do this at Amplify by enacting programs and policies that promote DEI\u2014and with humility, if we miss the mark, we rigorously amend our practices to better achieve our targeted outcomes.    Simply put, we turn our words into action.     ABOUT THE POSITION \n  We are seeking a detail-oriented and intellectually curious Data Engineer who is adept at navigating ambiguous situations. This role isn\u2019t simply about executing a task list; it demands proactive engagement, adaptability, and a deep understanding of our data-centric business objectives. While prior experience with a title such as 'Data Scientist' might be relevant, we emphasize the specific skills and experience outlined in this job description. Familiarity with Microsoft's tech stack is a plus. \n \n  RESPONSIBILITIES \n  As the Senior Data Scientist on the Analytics and Insights team, your work will include: \n \n Experience in R/Python (strong skills in at least 1 with a desire to know both) \n Experience with data management \n Experience with data analysis, data engineering, data visualization \n Ability to work from ambiguous requirements and navigate unclear situations \n Flexible working style \n Experience (or interest) working on analytical projects in the global health space \n Statistics and machine learning skills \n Intellectual curiosity to go out and learn new things to deliver results \n \n QUALIFICATIONS   \n \n Must be willing to commute to the Seattle office 2 days a week. \n Masters degree in Data Science, Data Engineering, Mathematics, Computer Engineering, Statistics, or related field, or equivalent working experience. \n 5+ years of experience in a Data Science role, with advanced work in Computer Science, Statistics, Informatics, Information Systems or another quantitative field preferred. \n 5+ years working in a customer-facing role interacting with business users, Data Analysts, and Data Scientists. \n 5+ years using R or Python to manipulate data and draw insights from large data sets. R programming is probably the most important skill. The individual will need to inherent an existing R end-to-end modeling framework that lives in GitHub \n Experience with Databricks for collaborative data science development workspaces and notebook-driven scripting is a plus. \n Proven track record of being part of a team delivering software solutions or services designed around customer needs. \n Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) as well as advanced statistical techniques (regression, properties of distributions, statistical tests and proper usage, etc.) and their real-world advantages and/or drawbacks. \n A drive to learn and master new technologies and techniques. Strong problem-solving skills with an emphasis on data and domain exploration. \n Experience working in cloud environments for data science workloads. \n SQL proficient \n PowerBI experience is a plus, or interest in doing so \n Azure Cloud experience \n \n SALARY AND BENEFIT HIGHLIGHTS \n \n  At Amplify we take a holistic approach to total rewards in order to invest in the satisfaction and success of our employees both now and in the future. We consider the whole person and want to support our employees in living full lives both personally and professionally. The following is an overview of what you\u2019ll get as a member of our team. \n  We consider a variety of factors when making compensation decisions and  do not hire employees at the highest point of the pay  range, targeting around the 50th percentile of the range. We share this to ensure transparency and set expectations for those considering opportunities with us. As you excel at Amplify, there is potential for salary increases and promotions. If you were to remain in this role, there is earning potential for this level of $175,000. The beginning salary range for this role is $130,000 - $160,000. \n \n 100% remote work option \n Flexible Time Off (time to recharge when you need it!) \n 11 observed holidays \n Medical/dental/vision \u2013 the employee is covered at 100%, dependents are subsidized \n Parental leave, short-term disability, long-term disability, and life insurance options \n \u2018Amplify You\u2019 program \u2013 $1,000 annually for your own development or investment in well-being after one year \n Student loan payback program \n Mentorship and training opportunities \n Business and employee referral bonus opportunities \n \n OUR HIRING PRACTICES \n  At Amplify, all qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. We are committed to creating a diverse and welcoming workplace that includes all employees with diverse backgrounds and experiences. We believe it enables us to better meet our mission and values while serving clients throughout our communities. People of color, women, LGBTQIA+, veterans, and persons with disabilities are encouraged to apply. Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Amplify is committed to offering reasonable accommodation to job applicants with disabilities. If you need assistance or accommodation due to a disability, please contact us at HR@amplifycp.com.",
        "cleaned_desc": " \n Experience in R/Python (strong skills in at least 1 with a desire to know both) \n Experience with data management \n Experience with data analysis, data engineering, data visualization \n Ability to work from ambiguous requirements and navigate unclear situations \n Flexible working style \n Experience (or interest) working on analytical projects in the global health space \n Statistics and machine learning skills \n Intellectual curiosity to go out and learn new things to deliver results \n   QUALIFICATIONS   \n \n Must be willing to commute to the Seattle office 2 days a week. \n Masters degree in Data Science, Data Engineering, Mathematics, Computer Engineering, Statistics, or related field, or equivalent working experience. \n 5+ years of experience in a Data Science role, with advanced work in Computer Science, Statistics, Informatics, Information Systems or another quantitative field preferred. \n 5+ years working in a customer-facing role interacting with business users, Data Analysts, and Data Scientists. \n 5+ years using R or Python to manipulate data and draw insights from large data sets. R programming is probably the most important skill. The individual will need to inherent an existing R end-to-end modeling framework that lives in GitHub \n Experience with Databricks for collaborative data science development workspaces and notebook-driven scripting is a plus. \n Proven track record of being part of a team delivering software solutions or services designed around customer needs. \n Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) as well as advanced statistical techniques (regression, properties of distributions, statistical tests and proper usage, etc.) and their real-world advantages and/or drawbacks. ",
        "techs": [
            "r",
            "python",
            "data management",
            "data analysis",
            "data engineering",
            "data visualization",
            "statistics",
            "machine learning",
            "seattle office",
            "data science",
            "data engineering",
            "mathematics",
            "computer engineering",
            "statistics",
            "informatics",
            "information systems",
            "r programming",
            "github",
            "databricks",
            "machine learning techniques."
        ],
        "cleaned_techs": [
            "r",
            "python",
            "data management",
            "data visualization",
            "statistics",
            "seattle office",
            "data science",
            "mathematics",
            "computer engineering",
            "informatics",
            "information systems",
            "r programming",
            "github",
            "databricks",
            "machine learning techniques."
        ]
    },
    "2c432fe56aa06277": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Data Scientist - Primary Care",
        "company": "CenterWell",
        "desc": "CenterWell\u2122 represents our payer-agnostic healthcare services for senior primary care, home health and pharmacy. Launched in spring 2021, CenterWell creates experiences that provide patients with ease, comprehensive care and a personal approach. By placing each patient at the center \u2014 focusing on their unique needs and personalizing the care we deliver to them \u2014 we can help them lead happier, healthier lives. \n  \n  CenterWell Senior Primary Care\u2122 provides proactive, preventive care to seniors, including wellness visits, physical exams, chronic condition management, screenings, minor injury treatment and more. It is part of Humana\u2019s Primary Care Organization, which is the nation\u2019s largest provider of value-based, senior-focused primary care. \n  \n  More about CenterWell Senior Primary Care: \n  \n  More than 85 locations, which are part of the 250 senior primary care centers operated by Humana\u2019s Primary Care Organization \n  \n  Integrated care teams that include physicians, nurse practitioners, medical assistants, medical coders and center administrators \n  \n  Nearly 250,000 total patients served in 2022, including those in Medicare Advantage, value-based arrangements or other Medicare programs\n  \n  The Senior Data Scientist uses mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions. The Senior Data Scientist work assignments involve moderately complex to complex issues where the analysis of situations or data requires an in-depth evaluation of variable factors.\n  \n  Responsibilities \n \n  The Senior Data Scientist develops, maintains, and collects structured and unstructured data sets for analysis and reporting. Creates reports, projections, models, and presentations to support business strategy and tactics. Begins to influence department\u2019s strategy. Makes decisions on moderately complex to complex issues regarding technical approach for project components, and work is performed without direction. Exercises considerable latitude in determining objectives and approaches to assignments. \n \n  Required Qualifications \n \n  Bachelor's Degree and 3 years of applicable experience OR Master's Degree and 2 or more years of experience \n  Experience in using mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions. \n  Experience in working with assignments that involve moderately complex to complex issues where the analysis of situations or data requires an in-depth evaluation of variable factors. \n  Experience in developing, maintaining, and collecting structured and unstructured data sets for analysis and reporting. \n  Experience in creating reports, projections, models, and presentations to support business strategy and tactics. \n  Ability to make decisions on moderately complex to complex issues regarding technical approach for project components. \n  Must be passionate about contributing to an organization focused on continuously improving consumer experiences. \n \n \n  Preferred Qualifications \n \n  Master's Degree \n  PhD \n \n \n  Additional Information \n \n  Interview Format: MODERN HIRE \n  As part of our hiring process, we will be using an exciting interviewing technology provided by Modern Hire, a third-party vendor. This technology provides our team of recruiters and hiring managers an enhanced method for decision-making. \n  If you are selected to move forward from your application prescreen, you will receive correspondence inviting you to participate in a pre-recorded Voice Interview and/or an SMS Text Messaging interview. If participating in a pre-recorded interview, you will respond to a set of interview questions via your phone. You should anticipate this interview to take approximately 10-15 minutes. \n  If participating in a SMS Text interview, you will be asked a series of questions to which you will be using your cell phone or computer to answer the questions provided. Expect this type of interview to last anywhere from 5-10 minutes. Your recorded interview(s) via text and/or pre-recorded voice will be reviewed and you will subsequently be informed if you will be moving forward to next round of interviews. \n \n  Benefits \n \n  Humana offers a variety of benefits to promote the best health and well-being of our employees and their families. We design competitive and flexible packages to give our employees a sense of financial security\u2014both today and in the future, including: \n \n  Health benefits effective day 1 \n  Paid time off, holidays, volunteer time and jury duty pay \n  Recognition pay \n  401(k) retirement savings plan with employer match \n  Tuition assistance \n  Scholarships for eligible dependents \n  Parental and caregiver leave \n  Employee charity matching program \n  Network Resource Groups (NRGs) \n  Career development opportunities \n \n \n  Remote \n  #LI-BL1 \n \n  Scheduled Weekly Hours \n  40\n  \n  Pay Range  The compensation range below reflects a good faith estimate of starting base pay for full time (40 hours per week) employment at the time of posting. The pay range may be higher or lower based on geographic location and individual pay decisions will vary based on demonstrated job related skills, knowledge, experience, education, certifications, etc.\n  \n  $104,800 - $144,300 per year\n  \n  This job is eligible for a bonus incentive plan. This incentive opportunity is based upon company and/or individual performance.\n  \n  Description of Benefits  Humana, Inc. and its affiliated subsidiaries (collectively, \u201cHumana\u201d) offers competitive benefits that support whole-person well-being. Associate benefits are designed to encourage personal wellness and smart healthcare decisions for you and your family while also knowing your life extends outside of work. Among our benefits, Humana provides medical, dental and vision benefits, 401(k) retirement savings plan, time off (including paid time off, company and personal holidays, volunteer time off, paid parental and caregiver leave), short-term and long-term disability, life insurance and many other opportunities.\n \n  Not Specified \n  0",
        "cleaned_desc": "  Responsibilities \n \n  The Senior Data Scientist develops, maintains, and collects structured and unstructured data sets for analysis and reporting. Creates reports, projections, models, and presentations to support business strategy and tactics. Begins to influence department\u2019s strategy. Makes decisions on moderately complex to complex issues regarding technical approach for project components, and work is performed without direction. Exercises considerable latitude in determining objectives and approaches to assignments. \n \n  Required Qualifications \n \n  Bachelor's Degree and 3 years of applicable experience OR Master's Degree and 2 or more years of experience \n  Experience in using mathematics, statistics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions. \n  Experience in working with assignments that involve moderately complex to complex issues where the analysis of situations or data requires an in-depth evaluation of variable factors. \n  Experience in developing, maintaining, and collecting structured and unstructured data sets for analysis and reporting. \n  Experience in creating reports, projections, models, and presentations to support business strategy and tactics. \n  Ability to make decisions on moderately complex to complex issues regarding technical approach for project components. \n  Must be passionate about contributing to an organization focused on continuously improving consumer experiences. \n ",
        "techs": [
            "mathematics",
            "statistics",
            "modeling",
            "business analysis",
            "technology"
        ],
        "cleaned_techs": [
            "mathematics",
            "statistics",
            "modeling",
            "business analysis",
            "technology"
        ]
    },
    "918ad336af7e09ae": {
        "terms": [
            "data science"
        ],
        "salary_min": 151800.0,
        "salary_max": 210000.0,
        "title": "Staff Data Analyst, Credit Analytics",
        "company": "Upstart Network, Inc.",
        "desc": "About Upstart \n  Upstart is a leading AI lending marketplace partnering with banks and credit unions to expand access to affordable credit. By leveraging Upstart's AI marketplace, Upstart-powered banks and credit unions can have higher approval rates and lower loss rates across races, ages, and genders, while simultaneously delivering the exceptional digital-first lending experience their customers demand. More than two-thirds of Upstart loans are approved instantly and are fully automated. \n  Upstart is a digital-first company, which means that most Upstarters can live and work anywhere in the U.S. We also have offices in San Mateo, California; Columbus, Ohio; and Austin, Texas. \n  Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we\u2019d love to hear from you! \n \n The Team \n  The Analytics   team plays the critical role of providing analytical capability across Upstart's organization to enable data-driven decision making. We leverage our analytical and technical skills to support our partners with a multitude of services, some of which include understanding our underwriting models and presenting on trends in our loan performance, analyzing market size opportunities, creating financial models, developing our business intelligence pipeline to enable self-service reporting, and architecting/automating of work processes. \n  As a  Staff Data Analyst  at Upstart, you will join our Credit Analytics horizontal team. You\u2019ll be responsible for driving understanding, insights and decision making relating to our platform level credit performance and development of credit and valuation analytics infrastructure suite. You\u2019ll partner with our Data Analytics vertical teams, Machine Learning, and Product teams to help shape the narrative and deepen our expertise in understanding credit performance across Upstart platform. \n \n \n  Position Location -  This role is available in the following locations: Remote; San Mateo, CA \n  Travel Requirements -  This team has regular onsite collaboration sessions. These occur  5  days per  Month  at the  San Mateo CA ,  Columbus OH , or  Austin TX  office. If you need to travel to make these meetups, Upstart will cover all travel related expenses. \n \n \n  How you\u2019ll make an impact: \n \n Influence Upstart\u2019s credit platform and investor/lending community through informing decisions, opportunities, and risks, while supported by deep understanding and insights on Upstart\u2019s model, credit, and valuation \n Lead and develop credit monitoring, model performance, and valuation analytics to conduct in-depth analyses on credit data, trends, and anomalies that drive model and product decisions \n Build foundational forecast models, data pipelines, and automated reporting to enable robust and dynamic credit intelligence for Upstart analyst community \n Partner with the Data Analytics vertical teams, Machine Learning, Product, Engineering, and Finance teams to shape credit metrics and narratives, financial forecast, and driving consensus in the state of Upstart platform \n Mentor junior team members on best practices and foster a center of excellence on data, credit, and analytics \n \n \n \n  What we\u2019re looking for: \n \n Minimum qualifications: \n    \n 5+ years work experience in increasingly senior analytical roles in technology and finance industry \n Experience in credit analytics, valuation, and/or financial analytics development with python, R, GSheet (AppScript), Excel (VBA), SAS \n Experience working with large datasets, data modeling, and data pipelines using tools like Databricks, DBT, Looker, Snowflake, Redshift \n Degree in Economics, Mathematics, Engineering, Data Science or other quantitative fields \n \n Preferred qualifications: \n    \n Experience in coaching and mentoring junior team members on technical subjects \n Ability to craft executive-ready narratives around complex business or performance topics, leveraging visualization and dashboards (e.g., Tableau, PowerBI, Looker), and to successfully influence and drive C-level decision-making \n Demonstrated ability to work collaboratively and in deep partnership with cross-functional colleagues especially in Finance, Product, Data Engineering, ML teams \n Experience in consumer lending, and/or knowledge of the consumer finance market, capital markets \n \n \n \n What you'll love: \n \n Competitive Compensation (base + bonus & equity) \n Comprehensive medical, dental, and vision coverage with Health Savings Account contributions from Upstart \n 401(k) with 100% company match up to $4,500 and immediate vesting and after-tax savings \n Employee Stock Purchase Plan (ESPP) \n Life and disability insurance \n Generous holiday, vacation, sick and safety leave \n Supportive parental, family care, and military leave programs \n Annual wellness, technology & ergonomic reimbursement programs \n Social activities including team events and onsites, all-company updates, employee resource groups (ERGs), and other interest groups such as book clubs, fitness, investing, and volunteering \n Catered lunches + snacks & drinks when working in offices \n \n \n \n  #LI-REMOTE \n  #LI-MidSenior \n \n \n \n \n \n At Upstart, your base pay is one part of your total compensation package. The anticipated base salary for this position is expected to be within the below range. Your actual base pay will depend on your geographic location\u2013with our \u201cdigital first\u201d philosophy, Upstart uses compensation regions that vary depending on location. Individual pay is also determined by job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. \n  In addition, Upstart provides employees with target bonuses, equity compensation, and generous benefits packages (including medical, dental, vision, and 401k). \n \n \n     United States | Remote - Anticipated Base Salary Range\n    \n \n     $151,800\u2014$210,000 USD\n    \n \n \n \n Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together. \n  If you require reasonable accommodation in completing an application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please email  candidate_accommodations@upstart.com \n  https://www.upstart.com/candidate_privacy_policy",
        "cleaned_desc": " \n Influence Upstart\u2019s credit platform and investor/lending community through informing decisions, opportunities, and risks, while supported by deep understanding and insights on Upstart\u2019s model, credit, and valuation \n Lead and develop credit monitoring, model performance, and valuation analytics to conduct in-depth analyses on credit data, trends, and anomalies that drive model and product decisions \n Build foundational forecast models, data pipelines, and automated reporting to enable robust and dynamic credit intelligence for Upstart analyst community \n Partner with the Data Analytics vertical teams, Machine Learning, Product, Engineering, and Finance teams to shape credit metrics and narratives, financial forecast, and driving consensus in the state of Upstart platform \n Mentor junior team members on best practices and foster a center of excellence on data, credit, and analytics \n \n \n \n  What we\u2019re looking for: \n \n Minimum qualifications: \n    \n 5+ years work experience in increasingly senior analytical roles in technology and finance industry \n Experience in credit analytics, valuation, and/or financial analytics development with python, R, GSheet (AppScript), Excel (VBA), SAS   Experience working with large datasets, data modeling, and data pipelines using tools like Databricks, DBT, Looker, Snowflake, Redshift \n Degree in Economics, Mathematics, Engineering, Data Science or other quantitative fields \n \n Preferred qualifications: \n    \n Experience in coaching and mentoring junior team members on technical subjects \n Ability to craft executive-ready narratives around complex business or performance topics, leveraging visualization and dashboards (e.g., Tableau, PowerBI, Looker), and to successfully influence and drive C-level decision-making \n Demonstrated ability to work collaboratively and in deep partnership with cross-functional colleagues especially in Finance, Product, Data Engineering, ML teams \n Experience in consumer lending, and/or knowledge of the consumer finance market, capital markets \n \n \n \n What you'll love: \n \n Competitive Compensation (base + bonus & equity) ",
        "techs": [
            "python",
            "r",
            "gsheet (appscript)",
            "excel (vba)",
            "sas",
            "databricks",
            "dbt",
            "looker",
            "snowflake",
            "redshift",
            "tableau",
            "powerbi",
            "looker"
        ],
        "cleaned_techs": [
            "python",
            "r",
            "gsheet (appscript)",
            "excel",
            "sas",
            "databricks",
            "dbt",
            "looker",
            "snowflake",
            "redshift",
            "tableau",
            "powerbi"
        ]
    },
    "cbe6e2cb5fd0faaf": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 142102.19,
        "salary_max": 179933.03,
        "title": "Principal Data Scientist - Customer Growth Marketing",
        "company": "Dell Technologies",
        "desc": "Principal Data Scientist \u2013 Customer Growth Marketing \n  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions.Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand-new methodologies, tools, statistical methods, and models. What\u2019s more, we are in collaboration with leading academics, industry experts, and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data. \n  Join us to do the best work of your career and make a profound social impact as a  Principal Data Scientist  on our Customer  Growth Marketing Team  working remotely in  Brazil,  or  Panama . \n  What you\u2019ll achieve  As a Principal Data Scientist on a growing team, you will bring your industry expertise to build machine-learning models.You will collaborate closely with our Field Marketing and Sales stakeholders to solve critical and highly-visible business problems with machine learning. \n \n \n  You will: \n \n \n \n  You will work with other Data Scientists, Data Engineers, ML Engineers, and Business Analyststo lead the end-to-end ML lifecycle, from use-case identification through model productionization, business outcome measurement, and data storytelling \n  Lead the growth and maturation of our marketing capabilities with machine learning at its core \n  Engage with business stakeholders to support customer-centric design of solutions \n  Mentor junior data scientists \n \n \n \n \n  Take the first step toward your dream career \n \n \n  Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role: \n \n \n  Essential Requirements \n \n \n \n  Expertise in machine learning, data science, statistics, or related, including a demonstrated portfolio of productionized models. \n  Expertise in statistical programming with proficiency in Python (including packages such as pandas, scikit-learn, TensorFlow, or PyTorch) and Jupyter Notebooks \n  Ability to quickly gain deep understanding of multiple domain data, business processes, business objectives, and build appropriate stakeholderrelationships. \n  Experience with data storytelling, including providing clear and concise analyses around model performance and business outcomes to nonexpert stakeholders in very good written and verbal English. \n \n \n \n  Desired Requirements \n \n \n \n  Bachelor\u2019s degree in Data Science, Machine Learning, Statistics, Economics, Physics, other quantitative fields, or equivalent professional experience; Master\u2019s degree preferred \n  Demonstrated experience of researching and applying new industry methodologies or techniques to solve business problems in unique ways \n \n \n \n \n  Who we are \n \n \n  We believe that each of us has the power to make an impact. That\u2019s why we put our team members at the center of everything we do. If you\u2019re looking for an opportunity to grow your career with some of the best minds and most advanced tech in the industry, we\u2019re looking for you.     Dell Technologies is a unique family of businesses that helps individuals and organizations transform how they work, live and play. Join us to build a future that works for everyone because Progress Takes All of Us. \n  Application close date: September 30th - 2023    Dell Technologies is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.",
        "cleaned_desc": " \n  Expertise in machine learning, data science, statistics, or related, including a demonstrated portfolio of productionized models. \n  Expertise in statistical programming with proficiency in Python (including packages such as pandas, scikit-learn, TensorFlow, or PyTorch) and Jupyter Notebooks \n  Ability to quickly gain deep understanding of multiple domain data, business processes, business objectives, and build appropriate stakeholderrelationships. \n  Experience with data storytelling, including providing clear and concise analyses around model performance and business outcomes to nonexpert stakeholders in very good written and verbal English. \n \n \n \n  Desired Requirements ",
        "techs": [
            "machine learning",
            "data science",
            "statistics",
            "python",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "jupyter notebooks",
            "data storytelling"
        ],
        "cleaned_techs": [
            "data science",
            "statistics",
            "python",
            "pandas",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "jupyter notebooks",
            "data storytelling"
        ]
    },
    "5357fd4ecab0e05f": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 140000.0,
        "salary_max": 165000.0,
        "title": "Senior Data Scientist",
        "company": "Phreesia Payment Services",
        "desc": "Job Description:\n  \n \n \n \n     Phreesia is in the search for an experienced and hands-on Senior Data Scientist to join our growing Data Science Team and take part in our mission to activate patients and drive positive health outcomes! We\u2019re looking for someone who has the analytical and technical skills to take ownership of business-critical data science projects for the entire lifecycle, from data exploration, modeling and analysis to model selection, validation, evaluation, and deployment.\n    \n \n \n \n \n  Picture yourself in a team of smart, humorous, quick-witted, and dedicated coworkers, all passionate about turning large sets of data into powerful insights that improve patient outcomes. You\u2019ll be responsible for planning, building data products for internal consumption, near real-time business intelligence tools, and predictive models. But this role is not just about crunching numbers, we need you to organize complex data in a way that tells a compelling story and drives critical decision-making for stakeholders across and outside of the business. So, if you\u2019re looking to be a part of cutting-edge clinical research on platforms exclusive to Phreesia, this may be the right opportunity for you.\n    \n \n \n \n \n  What You'll Do\n    \n \n \n \n \n \n       Leverage Phreesia\u2019s massive and ever-growing dataset to design and build data products that provide actionable business insights.\n      \n \n \n       Use NLP techniques to parse, process, and structure textual data.\n      \n \n \n       Develop methods to efficiently classify and characterize patient populations.\n      \n \n \n       Optimize targeted engagement strategies through modeling, forecasting, and evaluation.\n      \n \n \n       Navigate and use diverse machine learning stacks in Python and R.\n      \n \n \n       Quickly prototype ideas and solve complex problems by adapting creative approaches.\n      \n \n \n       Take ownership of data products and ensure they are properly tracked throughout their lifecycle.\n      \n \n \n       Participate in strategic project planning and reporting to executive leadership; build customized dashboards for internal and external stakeholders.\n      \n \n \n       Write clean, well-tested, code that will stand the test of time.\n      \n \n \n       Be an expert communicator: you could summarize your daily progress in a tweet.\n      \n \n \n \n \n \n  What You'll Bring\n    \n \n \n \n \n \n       Advanced degree in a quantitative field such as Data Science, Computer Science, Engineering, Mathematics, Statistics, Computational Linguistics, Physics, or related is required.\n      \n \n \n \n \n \n \n \n \n       5+ years of experience in an operational Data Science role\n      \n \n \n       Experience with academic or scientific research within the healthcare or clinical space is required.\n      \n \n \n       Experience using NLP toolsets, such as Spark NLP, NLTK or spaCy\n      \n \n \n       Excellent SQL and Python skills and experience using Apache Spark (pyspark) for large data sets.\n      \n \n \n       Experience in using statistical principles to inform decision making (experimental design, significance tests, a/b testing)\n      \n \n \n       Experience in collaborating with Data Scientists and Data Engineers to propose, test, validate, evaluate, and deploy Machine Learning models.\n      \n \n \n       Experience using AWS services including S3, EMR, Glue, SageMaker, Redshift, and Athena or comparable services from other cloud providers.\n      \n \n \n       Experience in one or more of the following: knowledge graphs, vector similarity search, large language models.\n      \n \n \n \n \n \n  Base pay for US is $140,000 - $165,000 USD depending on qualifications. In addition, Phreesia also offers equity as  \n part \n  an attractive & comprehensive Total Rewards package. \n \n \n \n \n \n   Who We Are:\n  \n \n \n   At Phreesia, we\u2019re looking for smart and passionate people to help drive our mission of creating a better, more engaging healthcare experience. We\u2019re committed to helping healthcare organizations succeed in an ever-evolving landscape by transforming the way healthcare is delivered. Our SaaS platform digitizes appointment check-in and offers tools to engage patients, improve efficiency, optimize staffing, and enhance clinical care.\n  \n \n \n   Phreesia cares about our employees by providing a diverse and dynamic work environment. We\u2019re a five-time winner of Modern Healthcare Magazine\u2019s Best Places to Work in Healthcare award and we\u2019ve been recognized on the Bloomberg Gender Equality Index. We are dedicated to continuously improving our employee experience by launching new programs and initiatives. If you thrive in a culture of recognition, value inclusivity, professional development, and growth opportunities, Phreesia could be a great fit!\n  \n \n \n \n    Top-rated Employee Benefits:\n   \n \n  100% Remote work + home office expense reimbursements \n  Competitive compensation + equity grants for all employees \n  Flexible PTO + 8 company holidays \n  Monthly reimbursement for cell phone + internet + wellness \n  100% Paid 12-week parental leave to our U.S. employees, as well as a generous parental benefit to our employees in Canada \n  Variety of insurance coverage for people (and pets!) \n  Continuing education and professional certification reimbursement \n \n \n \n \n  We strive to provide a diverse and inclusive environment and are an equal opportunity employer.",
        "cleaned_desc": " \n \n       Develop methods to efficiently classify and characterize patient populations.\n      \n \n \n       Optimize targeted engagement strategies through modeling, forecasting, and evaluation.\n      \n \n \n       Navigate and use diverse machine learning stacks in Python and R.\n      \n \n \n       Quickly prototype ideas and solve complex problems by adapting creative approaches.\n      \n \n \n       Take ownership of data products and ensure they are properly tracked throughout their lifecycle.\n      \n \n \n       Participate in strategic project planning and reporting to executive leadership; build customized dashboards for internal and external stakeholders.\n      \n \n \n       Write clean, well-tested, code that will stand the test of time.\n      \n \n   \n \n       Experience using NLP toolsets, such as Spark NLP, NLTK or spaCy\n      \n \n \n       Excellent SQL and Python skills and experience using Apache Spark (pyspark) for large data sets.\n      \n \n \n       Experience in using statistical principles to inform decision making (experimental design, significance tests, a/b testing)\n      \n \n \n       Experience in collaborating with Data Scientists and Data Engineers to propose, test, validate, evaluate, and deploy Machine Learning models.\n      \n \n \n       Experience using AWS services including S3, EMR, Glue, SageMaker, Redshift, and Athena or comparable services from other cloud providers.\n      \n \n \n       Experience in one or more of the following: knowledge graphs, vector similarity search, large language models.\n      \n \n \n \n \n \n  Base pay for US is $140,000 - $165,000 USD depending on qualifications. In addition, Phreesia also offers equity as  ",
        "techs": [
            "classification methods",
            "patient population characterization",
            "targeted engagement strategies",
            "modeling",
            "forecasting",
            "evaluation",
            "machine learning stacks",
            "python",
            "r",
            "prototyping",
            "problem solving",
            "data product ownership",
            "lifecycle tracking",
            "strategic project planning",
            "reporting",
            "customized dashboards",
            "clean code writing",
            "testing",
            "nlp toolsets",
            "spark nlp",
            "nltk",
            "spacy",
            "sql skills",
            "apache spark (pyspark)",
            "statistical principles",
            "decision making",
            "collaboration",
            "data scientists",
            "data engineers",
            "machine learning models",
            "aws services",
            "s3",
            "emr",
            "glue",
            "sagemaker",
            "redshift",
            "athena",
            "cloud providers",
            "knowledge graphs",
            "vector similarity search",
            "large language models"
        ],
        "cleaned_techs": [
            "classification methods",
            "patient population characterization",
            "targeted engagement strategies",
            "modeling",
            "forecasting",
            "evaluation",
            "machine learning stacks",
            "python",
            "r",
            "prototyping",
            "problem solving",
            "data product ownership",
            "strategic project planning",
            "reporting",
            "customized dashboards",
            "clean code writing",
            "testing",
            "nlp",
            "spark nlp",
            "nltk",
            "spacy",
            "apache spark (pyspark)",
            "statistical principles",
            "decision making",
            "collaboration",
            "data scientists",
            "data engineers",
            "aws",
            "s3",
            "emr",
            "glue",
            "sagemaker",
            "redshift",
            "athena",
            "cloud providers",
            "knowledge graphs",
            "vector similarity search",
            "large language models"
        ]
    },
    "344f12e094af0fa3": {
        "terms": [
            "data science",
            "data analyst",
            "machine learning engineer"
        ],
        "salary_min": 89108.04,
        "salary_max": 112830.63,
        "title": "Data Analyst for Sales and Labor Forecasting",
        "company": "Arthur Grand Technologies Inc",
        "desc": "Position: Data Analyst for Sales and Labor Forecasting \n Remote \n Proven experience in data analysis and forecasting, preferably in the restaurant or hospitality industry \n Job Summary: \n We are seeking a Data Analyst to work for Sales and Labor Forecasting at a restaurant Chain. The ideal candidate will have analytical skills along with some data engineering and data science experience. You will play a crucial role in optimizing the restaurant operations and enhancing their decision-making processes. You will work closely with their Analytics, Sales, Operations, and HR teams to analyze data, develop insights, and forecast sales and labor needs, enabling them to provide a seamless and efficient dining experience for their customers while controlling operational costs. \n Responsibilities: \n \n Collect and analyze data from various sources, including POS systems, historical sales records, and labor reports, to identify trends, patterns, and anomalies that impact sales and labor requirements. \n Work closely with the AI/ML engineer to develop an accurate sales forecast for each restaurant location, taking into account seasonality, special events, and market trends. \n Work closely with the AI/ML engineer to develop labor forecasts and staffing models to ensure appropriate staffing levels based on projected sales, taking into consideration employee availability, and optimal scheduling. \n You will work with leading edge technologies like  Azure Synapse Analytics, Azure Data Factory, Azure machine learning, Auto ML and more. \n Use modeling and analytics to understand how business decisions impact our bottom line. \n Seamlessly integrate data from multiple sources and platforms to generate customer insights. \n Explore new data sources to enhance models and build solutions that empower analytics \u2022 \n Implement data governance and security measures to protect sensitive data, ensure compliance with regulatory standards, and adhere to data privacy policies. \n \n Requirements \n \n Bachelor's or master\u2019s degree in computer science, Engineering, or a related field. \n Hands-on experience with cloud platform Azure \n Experience in SQL or Python \n Excellent communication and collaboration skills to work effectively in a team environment and interact with stakeholders from various disciplines. \n \n Preferred Qualifications: \n \n Bachelor's or master's degree in computer science, Data Science, Statistics, Math, Physics, or other Science. \n Ability to work collaboratively in a team environment and communicate complex technical concepts to non-technical stakeholders. \n \n Thanks & Regards \n Rajaram Pandiyan| Technical Recruiter \n Arthur Grand Technologies Inc \n 44355 Premier Plaza, Suite 110, Ashburn, VA 20147 \n SBA 8(a) Certified Minority Small Business | Certified Minority Business Enterprise by NMSDC \n Arthur Grand Technologies is an Equal Opportunity Employer (including disability/vets) \n Job Type: Temporary \n Experience: \n \n Auto ML: 5 years (Preferred) \n SQL: 1 year (Preferred) \n Data Analyst: 10 years (Preferred) \n Azure Synapse Analytics: 10 years (Preferred) \n Azure Data Factory: 5 years (Preferred) \n Azure machine learning: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Position: Data Analyst for Sales and Labor Forecasting \n Remote \n Proven experience in data analysis and forecasting, preferably in the restaurant or hospitality industry \n Job Summary: \n We are seeking a Data Analyst to work for Sales and Labor Forecasting at a restaurant Chain. The ideal candidate will have analytical skills along with some data engineering and data science experience. You will play a crucial role in optimizing the restaurant operations and enhancing their decision-making processes. You will work closely with their Analytics, Sales, Operations, and HR teams to analyze data, develop insights, and forecast sales and labor needs, enabling them to provide a seamless and efficient dining experience for their customers while controlling operational costs. \n Responsibilities: \n \n Collect and analyze data from various sources, including POS systems, historical sales records, and labor reports, to identify trends, patterns, and anomalies that impact sales and labor requirements.   Work closely with the AI/ML engineer to develop an accurate sales forecast for each restaurant location, taking into account seasonality, special events, and market trends. \n Work closely with the AI/ML engineer to develop labor forecasts and staffing models to ensure appropriate staffing levels based on projected sales, taking into consideration employee availability, and optimal scheduling. \n You will work with leading edge technologies like  Azure Synapse Analytics, Azure Data Factory, Azure machine learning, Auto ML and more. \n Use modeling and analytics to understand how business decisions impact our bottom line. \n Seamlessly integrate data from multiple sources and platforms to generate customer insights. \n Explore new data sources to enhance models and build solutions that empower analytics \u2022 \n Implement data governance and security measures to protect sensitive data, ensure compliance with regulatory standards, and adhere to data privacy policies. \n   Requirements \n \n Bachelor's or master\u2019s degree in computer science, Engineering, or a related field. \n Hands-on experience with cloud platform Azure \n Experience in SQL or Python \n Excellent communication and collaboration skills to work effectively in a team environment and interact with stakeholders from various disciplines. \n \n Preferred Qualifications: ",
        "techs": [
            "azure synapse analytics",
            "azure data factory",
            "azure machine learning",
            "auto ml"
        ],
        "cleaned_techs": [
            "azure",
            "auto ml"
        ]
    },
    "c68a9686bb064996": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 111900.91,
        "salary_max": 141691.48,
        "title": "Product Leader - Industrial and Manufacturing AI & Data Science Solutions",
        "company": "Xen.ai",
        "desc": "About the company \n Xen.AI, is an Artificial Intelligence (AI) research and development (R&D) organization with operations in USA and India. We help our customers to develop innovative and customized SaaS solutions using Artificial Intelligence, Machine Learning, Deep Learning, Data Science and Open Source technologies. Please visit https://xen.ai/ to know more about us. \n Compensation for this position \n \n For the 1st year - 100% revenue based compensation based on the client projects that you help to get and deliver. \n After 1st year, based on company's progress we can consider formal corporate positions with market standard salary and equity etc. \n \n About the position \n Xen.AI is seeking a highly skilled and experienced Product Leader and Data Scientist with the Industrial and manufacturing domain knowledge to join our team in the Industrial vertical. The successful candidate will have deep knowledge of the processes, pain points, and solution approaches in areas such as predictive maintenance and Computer Vision based visual inspection for manufacturing defect detection and quality control. \n The successful candidate will be responsible for end to end lifecycle of the identified solutions including product vision, product development, and implementation. \n The role will require working closely with data scientists, engineers, and business stakeholders to understand industry-specific requirements and ensure the successful delivery of solutions. \n Selected candidates would be able to work remotely from any location. This can be a full time or part-time role. For the 1st year compensation would be 100% revenue based on the client projects that you help to deliver. \n Qualifications \n \n Master's or PhD degree degree in Industrial Engineering or related fields \n At least 10 years of relevant work experience in industrial maintenance, engineering, or quality assurance \n Expert knowledge of predictive maintenance strategies, including condition-based monitoring, failure analysis, and reliability engineering \n Expert knowledge of inspection techniques, including visual inspection, \n Experience working with structured, unstructured, streaming and batch data, \n Strong knowledge of machine learning, deep learning techniques, \n Strong programming skills in Python and SQL \n Experience developing solutions on cloud platforms like Azure, AWS, or GCP, \n IoT streaming sensor data analytics, \n Computer Vision, Image and streaming video processing, \n Experience with data visualization tools like PowerBI is a plus, \n Strong experience with Linux, \n Experience with various hardware devices, \n Excellent communication skills and ability to work in a team environment, \n Ability to provide technical leadership and guidance to junior team members. \n \n Responsibilities \n \n Develop product strategy and product vision for identified solutions, \n Develop release strategy and product backlog, \n Work closely with data scientists to identify data sources, \n Provide expert guidance and support during the development, test, and implementation phases, \n Contribute to development of content for marketing and sales activities, \n Stay up to date with the latest developments in industrial engineering, predictive maintenance, and quality inspection \n \n Compensation for this position \n \n For the 1st year - 100% revenue based compensation based on the client projects that you help to get and deliver. \n After 1st year, based on company's progress we can consider formal corporate positions with market standard salary and equity etc. \n \n If you have a passion for solving complex industrial problems using data-driven solutions, this is the role for you. Join our team and make a difference in the world of predictive maintenance and visual inspection. \n Please visit https://xen.ai/ to know more about us. \n !!!! Please note that we do not work with any recruiters !!!! \n Job Types: Part-time, Contract \n Pay: $1.00 per year \n Experience level: \n \n 10 years \n \n Schedule: \n \n Choose your own hours \n \n Experience: \n \n Product Management in Industrial and Manufacturing: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Qualifications \n \n Master's or PhD degree degree in Industrial Engineering or related fields \n At least 10 years of relevant work experience in industrial maintenance, engineering, or quality assurance \n Expert knowledge of predictive maintenance strategies, including condition-based monitoring, failure analysis, and reliability engineering \n Expert knowledge of inspection techniques, including visual inspection, \n Experience working with structured, unstructured, streaming and batch data, \n Strong knowledge of machine learning, deep learning techniques, \n Strong programming skills in Python and SQL \n Experience developing solutions on cloud platforms like Azure, AWS, or GCP, \n IoT streaming sensor data analytics, \n Computer Vision, Image and streaming video processing,   Experience with data visualization tools like PowerBI is a plus, \n Strong experience with Linux, \n Experience with various hardware devices, \n Excellent communication skills and ability to work in a team environment, \n Ability to provide technical leadership and guidance to junior team members. \n \n Responsibilities \n \n Develop product strategy and product vision for identified solutions, \n Develop release strategy and product backlog, \n Work closely with data scientists to identify data sources, \n Provide expert guidance and support during the development, test, and implementation phases, ",
        "techs": [
            "condition-based monitoring",
            "failure analysis",
            "reliability engineering",
            "visual inspection",
            "structured data",
            "unstructured data",
            "streaming data",
            "batch data",
            "machine learning",
            "deep learning",
            "python",
            "sql",
            "cloud platforms (azure",
            "aws",
            "gcp)",
            "iot streaming sensor data analytics",
            "computer vision",
            "image processing",
            "streaming video processing",
            "data visualization (powerbi)",
            "linux",
            "hardware devices"
        ],
        "cleaned_techs": [
            "condition-based monitoring",
            "failure analysis",
            "reliability engineering",
            "visual inspection",
            "structured data",
            "unstructured data",
            "streaming data",
            "batch data",
            "python",
            "sql",
            "cloud platforms (azure",
            "aws",
            "gcp",
            "iot streaming sensor data analytics",
            "computer vision",
            "image processing",
            "streaming video processing",
            "data visualization (powerbi)",
            "linux",
            "hardware devices"
        ]
    },
    "f7ef7366c7556204": {
        "terms": [
            "data science"
        ],
        "salary_min": 105004.82,
        "salary_max": 132959.5,
        "title": "Product Leader - Banking, Financial Services, Insurance, AI & Data Science",
        "company": "Xen.ai",
        "desc": "About the company \n Xen.AI, is an Artificial Intelligence (AI) research and development (R&D) organization with operations in USA and India. We help our customers to develop innovative and customized SaaS solutions using Artificial Intelligence, Machine Learning, Deep Learning, Data Science and Open Source technologies. Please visit https://xen.ai/ to know more about us. \n Compensation for this position \n \n For the 1st year - 100% revenue based compensation based on the client projects that you help to get and deliver. \n After 1st year, based on company's progress we can consider formal corporate positions with market standard salary and equity etc. \n \n About the position \n Xen.AI is looking for a Product Leader with experience in Banking, Financial Services, Insurance and AI, Machine Learning and Data Science. Selected candidates would be able to work remotely from any location. This can be a full time or part-time role. For the 1st year compensation would be 100% revenue based on the client projects that you help to deliver. \n Qualifications \n \n You bring deep knowledge of processes within the small to medium businesses in the banking and financial services \n Empathy for users and a drive to discover and resolve their pain points \n Experience conducting user research to educate product design \n Strong analytical skills, and experience with tools for doing data analysis \n Experience designing intuitive user interfaces and executing product plans with a well-defined process \n You bring deep empathy but can effectively prioritize with limited resources \n You have a growth mindset and want to be challenged \n You have a high bar and want to be a difference-maker in the organization \n Experience managing and integrating a diverse set of partners and processes into a cohesive product \n An owner's mindset - you don't shy away from the hard stuff \n Strong collaboration in team environments but able to act quickly as the decision-maker \n Experience at a startup in a cross-functional environment \n 5+ years experience as a product manager \n \n Responsibilities \n \n You will own the end-end product strategy and roadmap for development of user centric AI/ML products in banking and financial services sector serving small to medium businesses \n You will lead the ideation and launch of innovative features \n You will drive decision-making through customer insights, quantitative analysis, and AB testing \n Establish shared vision across the company by building consensus on priorities leading to product execution \n Embrace the testing process: form and validate data-driven hypotheses for accelerating member acquisition, retention and revenue \n Perform quantitative and qualitative research to identify product opportunities and prioritize your roadmap \n Ship minimum-loveable-products that allow us to test our hypotheses while delivering a quality customer experience \n Inform product decisions with quantitative and qualitative data on user behavior and experimentation (eg a/b testing, survey data, usability studies) \n Rapidly iterate on services using customer feedback \n Define and analyze metrics that inform the success of products/experiments \n Capture insights from growth experiments successes and failures, and communicate them to the broader team \n Partner with various teams to build software collaboratively and inclusively \n \n Compensation for this position \n \n For the 1st year - 100% revenue based compensation based on the client projects that you help to get and deliver. \n After 1st year, based on company's progress we can consider formal corporate positions with market standard salary and equity etc. \n \n Please visit https://xen.ai/ to know more about us. \n Job Types: Part-time, Contract \n Pay: $1.00 per year \n Experience level: \n \n 10 years \n \n Schedule: \n \n Choose your own hours \n \n Experience: \n \n Product management in Banking, Financial services: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Empathy for users and a drive to discover and resolve their pain points \n Experience conducting user research to educate product design \n Strong analytical skills, and experience with tools for doing data analysis \n Experience designing intuitive user interfaces and executing product plans with a well-defined process \n You bring deep empathy but can effectively prioritize with limited resources \n You have a growth mindset and want to be challenged \n You have a high bar and want to be a difference-maker in the organization \n Experience managing and integrating a diverse set of partners and processes into a cohesive product \n An owner's mindset - you don't shy away from the hard stuff \n Strong collaboration in team environments but able to act quickly as the decision-maker \n Experience at a startup in a cross-functional environment \n 5+ years experience as a product manager ",
        "techs": [
            "empathy for users",
            "user research",
            "analytical skills",
            "data analysis tools",
            "intuitive user interfaces",
            "product plans",
            "prioritization with limited resources",
            "growth mindset",
            "high bar",
            "managing partners and processes",
            "owner's mindset",
            "collaboration in team environments",
            "decision-making",
            "cross-functional environment",
            "startup experience",
            "product manager"
        ],
        "cleaned_techs": [
            "empathy for users",
            "user research",
            "data analysis tools",
            "intuitive user interfaces",
            "product plans",
            "prioritization with limited resources",
            "growth mindset",
            "high bar",
            "managing partners and processes",
            "owner's mindset",
            "collaboration in team environments",
            "decision-making",
            "cross-functional environment",
            "startup experience",
            "product manager"
        ]
    },
    "0c47de4e531334a3": {
        "terms": [
            "data science"
        ],
        "salary_min": 54400.0,
        "salary_max": 81600.0,
        "title": "Senior Forecast Analyst",
        "company": "DraftKings",
        "desc": "We\u2019re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming. \n Here, \u201cimpossible\u201d isn\u2019t part of our vocabulary. You\u2019ll face some of the toughest but most rewarding challenges of your career. They\u2019re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers. The Crown Is Yours \n We are seeking a high-performing and self-driven Senior Forecasting Analyst to develop and refine our forecasting and capacity planning models and processes. In this role, you will be responsible for creating and maintaining forecasts and capacity plans for our Workforce Management and Operations teams by developing a detailed understanding of our user\u2019s needs, products, and business drivers. What you\u2019ll do as a Senior Forecasting Analyst \n \n  Prepare accurate long and short term forecasts, advising the business on what to expect for future state. \n \n  Prepare ad hoc forecast scenarios such as Super Bowl surge, Playoff scheduling demands, overlap of seasons for NHL, NBA, MLB. \n \n  Create dashboards and reports to clearly communicate forecasts, plans, and performance. \n \n  Ensure accurate headcount tracking and maintain capacity plans. \n \n  Support the maintenance and development of workforce planning processes and procedures. What you\u2019ll bring \n \n  At least 3 years of forecasting, demand planning, business analytics, or data science experience. \n \n  Understanding of SQL and Google Sheets; proficiency with Python is a plus. \n \n  Proficiency in Tableau, or similar data visualization tools. \n \n  Exceptional analytical skills with high attention to detail. \n \n  Clear and thorough understanding of short, medium and long term forecasting practices. \n \n  Driven to continual improvement of processes and working environment. \n \n  Experience in Workforce Management is preferred. \n #LI-CC1 \n #LI-Remote Join Our Team \n \n We\u2019re a publicly traded (NASDAQ:  DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don\u2019t worry, we\u2019ll guide you through the process if this is relevant to your role. The US base salary range for this full-time position is $54,400.00 - $81,600.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b1a4f8d51186538b": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 140000.0,
        "salary_max": 165000.0,
        "title": "Senior Data Scientist",
        "company": "Phreesia Payment Services",
        "desc": "Job Description:\n  \n \n \n \n     Phreesia is in the search for an experienced and hands-on Senior Data Scientist to join our growing Data Science Team and take part in our mission to activate patients and drive positive health outcomes! We\u2019re looking for someone who has the analytical and technical skills to take ownership of business-critical data science projects for the entire lifecycle, from data exploration, modeling and analysis to model selection, validation, evaluation, and deployment.\n    \n \n \n \n \n  Picture yourself in a team of smart, humorous, quick-witted, and dedicated coworkers, all passionate about turning large sets of data into powerful insights that improve patient outcomes. You\u2019ll be responsible for planning, building data products for internal consumption, near real-time business intelligence tools, and predictive models. But this role is not just about crunching numbers, we need you to organize complex data in a way that tells a compelling story and drives critical decision-making for stakeholders across and outside of the business. So, if you\u2019re looking to be a part of cutting-edge clinical research on platforms exclusive to Phreesia, this may be the right opportunity for you.\n    \n \n \n \n \n  What You'll Do\n    \n \n \n \n \n \n       Leverage Phreesia\u2019s massive and ever-growing dataset to design and build data products that provide actionable business insights.\n      \n \n \n       Use NLP techniques to parse, process, and structure textual data.\n      \n \n \n       Develop methods to efficiently classify and characterize patient populations.\n      \n \n \n       Optimize targeted engagement strategies through modeling, forecasting, and evaluation.\n      \n \n \n       Navigate and use diverse machine learning stacks in Python and R.\n      \n \n \n       Quickly prototype ideas and solve complex problems by adapting creative approaches.\n      \n \n \n       Take ownership of data products and ensure they are properly tracked throughout their lifecycle.\n      \n \n \n       Participate in strategic project planning and reporting to executive leadership; build customized dashboards for internal and external stakeholders.\n      \n \n \n       Write clean, well-tested, code that will stand the test of time.\n      \n \n \n       Be an expert communicator: you could summarize your daily progress in a tweet.\n      \n \n \n \n \n \n  What You'll Bring\n    \n \n \n \n \n \n       Advanced degree in a quantitative field such as Data Science, Computer Science, Engineering, Mathematics, Statistics, Computational Linguistics, Physics, or related is required.\n      \n \n \n \n \n \n \n \n \n       5+ years of experience in an operational Data Science role\n      \n \n \n       Experience with academic or scientific research within the healthcare or clinical space is required.\n      \n \n \n       Experience using NLP toolsets, such as Spark NLP, NLTK or spaCy\n      \n \n \n       Excellent SQL and Python skills and experience using Apache Spark (pyspark) for large data sets.\n      \n \n \n       Experience in using statistical principles to inform decision making (experimental design, significance tests, a/b testing)\n      \n \n \n       Experience in collaborating with Data Scientists and Data Engineers to propose, test, validate, evaluate, and deploy Machine Learning models.\n      \n \n \n       Experience using AWS services including S3, EMR, Glue, SageMaker, Redshift, and Athena or comparable services from other cloud providers.\n      \n \n \n       Experience in one or more of the following: knowledge graphs, vector similarity search, large language models.\n      \n \n \n \n \n \n  Base pay for US is $140,000 - $165,000 USD depending on qualifications. In addition, Phreesia also offers equity as  \n part \n  an attractive & comprehensive Total Rewards package. \n \n \n \n \n \n   Who We Are:\n  \n \n \n   At Phreesia, we\u2019re looking for smart and passionate people to help drive our mission of creating a better, more engaging healthcare experience. We\u2019re committed to helping healthcare organizations succeed in an ever-evolving landscape by transforming the way healthcare is delivered. Our SaaS platform digitizes appointment check-in and offers tools to engage patients, improve efficiency, optimize staffing, and enhance clinical care.\n  \n \n \n   Phreesia cares about our employees by providing a diverse and dynamic work environment. We\u2019re a five-time winner of Modern Healthcare Magazine\u2019s Best Places to Work in Healthcare award and we\u2019ve been recognized on the Bloomberg Gender Equality Index. We are dedicated to continuously improving our employee experience by launching new programs and initiatives. If you thrive in a culture of recognition, value inclusivity, professional development, and growth opportunities, Phreesia could be a great fit!\n  \n \n \n \n    Top-rated Employee Benefits:\n   \n \n \n \n      Remote First: 100% Remote work + home office expense reimbursements+ monthly reimbursement for cell phone, internet and wellness.\n     \n \n \n      Top of market rewards: Competitive compensation + equity grants for all employees\n     \n \n \n      Take time when you need time: Flexible PTO + company holidays\n     \n \n \n      Top class healthcare benefits: Variety of healthcare benefits for you and your family (and your pets!) starting day one\n     \n \n \n      Care about your families: Generous top-up for parental leave benefits\n     \n \n \n      Support personal development: Continuing education and professional certification reimbursement\n     \n \n \n      Connecting in person: Various offsite events and activities for team to connect and meet in person, to support team building and engagement.\n     \n \n \n      Giveback to community: Local in-person volunteer events, and give back programs to our communities.\n     \n \n \n      Recognition and perks: We have a company wide recognition tool (Phireworks) to celebrate milestones, recognize achievements and strengthen your bond with your teams. You can accumulate points and redeem them for a wide catalogue of items!\n     \n \n \n      Diversity and inclusive environment: At Phreesia, all employees are encouraged to bring their authentic self to work, feel supported and perform at their best. We have a variety of Employee Resources Groups (ERGs) which bring together individuals from a wide range of backgrounds, experiences and perspectives, and seek to foster a sense of shared community and empowerment for employees who share a common social identity, such as gender, race, ethnicity, and sexual orientation.\n     \n \n \n \n \n  We strive to provide a diverse and inclusive environment and are an equal opportunity employer.",
        "cleaned_desc": "       Advanced degree in a quantitative field such as Data Science, Computer Science, Engineering, Mathematics, Statistics, Computational Linguistics, Physics, or related is required.\n      \n \n \n \n \n \n \n \n \n       5+ years of experience in an operational Data Science role\n      \n \n \n       Experience with academic or scientific research within the healthcare or clinical space is required.\n      \n \n \n       Experience using NLP toolsets, such as Spark NLP, NLTK or spaCy\n      \n \n \n       Excellent SQL and Python skills and experience using Apache Spark (pyspark) for large data sets.\n      \n \n \n       Experience in using statistical principles to inform decision making (experimental design, significance tests, a/b testing)\n      \n \n \n       Experience in collaborating with Data Scientists and Data Engineers to propose, test, validate, evaluate, and deploy Machine Learning models.\n      \n \n \n       Experience using AWS services including S3, EMR, Glue, SageMaker, Redshift, and Athena or comparable services from other cloud providers.\n      \n ",
        "techs": [
            "spark nlp",
            "nltk",
            "spacy",
            "sql",
            "python",
            "apache spark (pyspark)",
            "statistical principles",
            "aws services (s3",
            "emr",
            "glue",
            "sagemaker",
            "redshift",
            "athena)"
        ],
        "cleaned_techs": [
            "spark nlp",
            "nltk",
            "spacy",
            "sql",
            "python",
            "apache spark (pyspark)",
            "statistical principles",
            "aws",
            "emr",
            "glue",
            "sagemaker",
            "redshift",
            "athena)"
        ]
    },
    "8384013a5e2cd7cd": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89600.0,
        "salary_max": 134400.0,
        "title": "Senior Sportsbook Data Analyst",
        "company": "DraftKings",
        "desc": "We\u2019re defining what it means to build and deliver the most extraordinary sports and entertainment experiences. Our global team is trailblazing new markets, developing cutting-edge products, and shaping the future of responsible gaming. \n Here, \u201cimpossible\u201d isn\u2019t part of our vocabulary. You\u2019ll face some of the toughest but most rewarding challenges of your career. They\u2019re worth it. Channeling your inner grit will accelerate your growth, help us win as a team, and create unforgettable moments for our customers. The Crown Is Yours \n As a Senior Sportsbook Data Analyst, you\u2019ll support data analysis and reporting efforts to inform our current and future initiatives. Through cross-functional collaboration and inventive metrics building, you will enable teams across our organization to make smarter, better, and faster decisions. What you\u2019ll do as a Senior Sportsbook Data Analyst \n \n  Monitor sportsbook performance and diagnose areas of opportunity. Example areas include high-value customer analysis, state and sport trends, and promotion optimization. \n \n  Develop data analysis and reports to measure and inform sportsbook initiatives and use those to guide business decisions. \n \n  Conduct analyst-driven \u201cdeep dives\u201d that explore broad topics and inspire new ways of thinking about our customers and products. \n \n  Provide opportunity size for major promotional events to help the Sportsbook team capitalize on significant sporting events. \n \n  Mentor and coach other analysts across the business using best practices. \n \n  Work cross-functionally across promotions, customer retention management, operations, and VIP to understand customer behavior. What you'll bring \n \n  4+ years of business analytics experience, preferably at a sportsbook or gaming provider. \n \n  Ability to take complicated problems and build simple frameworks. \n \n  Comfortable presenting complicated data views to cross-functional audiences and senior leadership. \n \n  Expertise in SQL/Snowflake, and Excel. Proficiency in Tableau or similar data visualization tool. \n \n  Experience with R, Python, or statistical programming languages a plus. \n \n  Bachelor\u2019s degree or equivalent in Mathematics, Statistics, Computer Science, Business Analytics, or another relevant discipline. \n #LI-BG1 #LI-REMOTE Join Our Team \n \n We\u2019re a publicly traded (NASDAQ:  DKNG) technology company headquartered in Boston. As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment. Don\u2019t worry, we\u2019ll guide you through the process if this is relevant to your role. The US base salary range for this full-time position is $89,600.00 - $134,400.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",
        "cleaned_desc": "  Comfortable presenting complicated data views to cross-functional audiences and senior leadership. \n \n  Expertise in SQL/Snowflake, and Excel. Proficiency in Tableau or similar data visualization tool. \n \n  Experience with R, Python, or statistical programming languages a plus. ",
        "techs": [
            "sql/snowflake",
            "excel",
            "tableau",
            "r",
            "python"
        ],
        "cleaned_techs": [
            "sql",
            "excel",
            "tableau",
            "r",
            "python"
        ]
    },
    "43846ba7b38938bd": {
        "terms": [
            "data science"
        ],
        "salary_min": 88000.0,
        "salary_max": 144000.0,
        "title": "Data Scientist II, Product Analytics",
        "company": "BOLD",
        "desc": "We are looking for a  Data Scientist II, Product Analytics  to join the Data Analytics team at BOLD! This team partners with Product, Marketing, and Finance to produce world-class analysis and provide recommendations that improve our products and increase customer engagement. \n  This position is 100% remote, work from home (within lawfully allowed States). In some areas of the US, you may utilize a co-work space (when you'd like). \n  Lawfully allowed states :  Arizona, California, Colorado, Connecticut, Florida, Georgia, Illinois, Iowa, Kentucky, Maine, Maryland, Massachusetts, Minnesota, Nevada, New Hampshire, New Jersey, New York, North Carolina, Ohio, Oklahoma, Oregon, Pennsylvania, Tennessee, Texas, Utah, Virginia, Washington \n  ABOUT THIS TEAM   \n Reporting to the Director of Product Analytics, the  Data Scientist II, Product Analytics  will provide critical insights to business partners and strategic support to the executive team. You will also have your fingers on the pulse of the business and develop metrics and reporting to keep the organization informed. Through your high-quality analysis and attention to detail, you will be the go-to person for product performance and insights. The ideal candidate is highly motivated and will use their technical skills and business acumen to quickly make an impact! \n  WHAT YOU'LL DO \n \n Conduct in-depth analysis to uncover opportunities for improving our products. \n Work closely with business partners to extract meaningful insights using a variety of data sources: relational databases, front-end analytics tools, clickstream data, etc. \n Present insights and recommendations to executive leadership using high quality visualizations and concise messaging. \n Design and analyze A/B tests to drive KPI improvements. \n Build machine learning models to predict customer behavior and better understand the drivers of customer engagement and retention. \n Develop dashboards to inform business decisions with an emphasis on automation and scalability. \n Collaborate with Engineering to advance data infrastructure and governance. \n \n WHAT YOU'LL NEED \n \n 5+ years' experience performing quantitative data analysis, preferably for an internet or technology company. \n Ability to write complex SQL queries to drive critical business decisions. \n Robust understanding of Statistics with ability to explain statistical concepts to non-technical audiences. \n Bachelors or Masters' degree in Math, Engineering, Statistics or other quantitative field, with a track record of academic excellence. \n Self-starter with a desire to learn and the ability to rapidly understand the business and its drivers. \n Proficiency with Python/R \n Experience with building machine learning/predictive models. \n Ability to handle multiple projects and meet deadlines in a fast-paced environment. \n \n WHAT'S GOOD TO HAVE   \n \n Proficiency with BI tools such as Tableau, Looker, or equivalent \n Experience with Google Analytics, MixPanel or other front-end analytical platforms a plus. \n Experience with NLP (Natural Language Processing) is a plus. \n \n HERE'S A FEW OF OUR PERKS & BENEFITS \n  EXCELLENT COMPENSATION \n \n Competitive Salary \n Bi-annual Bonus \n 401(k) Plan Equivalent (with company match) \n Company Equity \n Flexible Spending Account (FSA for health and dependent care) \n \n WE LIKE YOU HEALTHY \n \n Medical, Dental, and Vision Insurance (additional plans for your family) \n Mental Health and Wellness perks (apps, additional support, etc.) \n Sick Time \n Life Insurance and AD&D \n Short-Term and Long-Term Disability Insurance \n Wellness reimbursement (gym, health apps, etc.) \n \n WE WANT YOU HAPPY \n \n Flexible PTO (take what you need) \n 11 paid holidays a year \n Additional 1-week PTO over December holidays \n Home Internet reimbursement \n Home Office Equipment reimbursement \n \n Under San Francisco's Fair Chance Ordinance, qualified applicants with arrest and conviction records will be considered for the position. \n  #LI-Remote, #LI-Hybrid, #LI-Onsite \n \n \n  Individual pay is based on location, transferable skills, experience, and other relevant factors. This estimated range is based on the best available market data and factors, all of which are subject to change. This position may also be eligible for a bonus and medical, dental, vision, life, short and long-term disability insurance, 401(k), paid time off, sick leave, and paid holidays, all subject to applicable plan terms. \n \n  Starting Pay Range  \n \n   $88,000\u2014$144,000 USD\n   \n \n \n  ABOUT BOLD  As an established global organization (17 years and counting), BOLD helps people find jobs. Our story is one of growth, success, and professional fulfillment.  We create digital products that have empowered over three million people in 180 countries to build stronger resumes, cover letters, and CVs. The result of our work helps people interview confidently, finding the right job in less time.  Our employees are experts, learners, contributors, and creatives.     BOLD VALUES OUR POSITION AS AN EQUAL OPPORTUNITY EMPLOYER   WE VALUE, CELEBRATE, AND PROMOTE DIVERSITY AND INCLUSION.  We hire based on qualifications, merit, and our business needs. We don't discriminate regarding race, color, religion, gender, pregnancy, national origin or citizenship, ancestry, age, physical or mental disability, veteran status, sexual orientation, gender identity or expression, marital status, genetic information, or any other applicable characteristic protected by law.",
        "cleaned_desc": " \n WHAT YOU'LL NEED \n \n 5+ years' experience performing quantitative data analysis, preferably for an internet or technology company. \n Ability to write complex SQL queries to drive critical business decisions. \n Robust understanding of Statistics with ability to explain statistical concepts to non-technical audiences. \n Bachelors or Masters' degree in Math, Engineering, Statistics or other quantitative field, with a track record of academic excellence. \n Self-starter with a desire to learn and the ability to rapidly understand the business and its drivers. \n Proficiency with Python/R \n Experience with building machine learning/predictive models. \n Ability to handle multiple projects and meet deadlines in a fast-paced environment. \n \n WHAT'S GOOD TO HAVE   \n ",
        "techs": [
            "sql",
            "statistics",
            "math",
            "engineering",
            "python",
            "r"
        ],
        "cleaned_techs": [
            "sql",
            "statistics",
            "math",
            "engineering",
            "python",
            "r"
        ]
    },
    "91fd2f4eded7ccc1": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Sr. Data Analyst - Optum Behavioral Health - Remote",
        "company": "Optum",
        "desc": "Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together. \n  Join Optum Behavioral Health Solutions (OBHS) as a Senior Data Analyst. OBHS is one of the largest behavioral health networks in the country with more than 300,000 providers serving 37 million individuals. OBHS supports and engages people with mental health conditions or substance use disorders through our performance-tiered behavioral health network. \n  You\u2019ll enjoy the flexibility to work remotely* from anywhere within the U.S. as you take on some tough challenges. \n    Primary Responsibilities: \n \n Gather report requirements from customers, clarifying using business terms and translating to technical terms \n Write Microsoft SQL Server queries, stored procedures, functions, tables, and other objects to properly create and manage various datasets. \n Use Microsoft Visual Studio to Create, Run Test, and Deploy SQL Server Reporting Services reports for delivery to our customers \n Leverage GIT for source control and Azure DevOps for Pipeline Integration to your development \n Lead Design with System Admins, DBAs, and Web Developers to manage systems/processes for continual data-quality improvement \n Regularly review, get reviewed, and present at Code Reviews to show your SQL and Business Intelligence work \n Digitally document using Office 365, Microsoft Teams, and Microsoft SharePoint to collaborate with coworkers and customers \n \n \n  You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n  Required Qualifications: \n \n 5+ years of experience in Business Intelligence (SSRS, Power BI) \n 5+ years of experience with SQL Server Querying \n Experience working in Visual Studio \n Experience working with non-technical customers for specification gathering \n Accommodate Pacific Standard Time (PST) meetings and partial work schedule \n \n \n   Preferred Qualifications: \n \n Bachelor\u2019s or higher degree in Computer Science or related field \n Experience with SQL Server Database Design \n Experience with Data Modeling/SQL Server Analysis Services (SSAS) \n Experience with SharePoint development \n Experience in Healthcare EHR data analysis \n \n \n   Careers with Optum.  Our objective is to make health care simpler and more effective for everyone. With our hands at work across all aspects of health, you can play a role in creating a healthier world, one insight, one connection and one person at a time. We bring together some of the greatest minds and ideas to take health care to its fullest potential, promoting health equity and accessibility. Work with diverse, engaged and high-performing teams to help solve important challenges. \n    California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only:  The salary range for California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island or Washington residents is $85,000 to $167,300. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives. \n \n \n \n All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy \n \n \n    At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone-of every race, gender, sexuality, age, location and income-deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes - an enterprise priority reflected in our mission.     Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. \n \n  UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.",
        "cleaned_desc": "   Preferred Qualifications: \n \n Bachelor\u2019s or higher degree in Computer Science or related field \n Experience with SQL Server Database Design \n Experience with Data Modeling/SQL Server Analysis Services (SSAS) \n Experience with SharePoint development \n Experience in Healthcare EHR data analysis \n ",
        "techs": [
            "sql server database design",
            "data modeling/sql server analysis services (ssas)",
            "sharepoint development",
            "healthcare ehr data analysis"
        ],
        "cleaned_techs": [
            "sql",
            "data modeling/sql server analysis services (ssas)",
            "sharepoint development",
            "healthcare ehr data analysis"
        ]
    },
    "a551cdef70f234cd": {
        "terms": [
            "data science"
        ],
        "salary_min": 65300.0,
        "salary_max": 149000.0,
        "title": "Cost Analyst, Senior",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Washington,DC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0183388\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Cost Analyst, Senior\n          \n  The Opportunity: \n  Do you want to use your analysis skills to help the Navy get the most out of their funding? When it comes to considering the costs of building and maintaining systems, you know there is more to it than parts and labor. That's why we need you, a cost analyst who can turn requirements into a complete financial understanding for the Navy. \n \n  As a cost analyst on our team, you'll translate requirements into cost through data collection, model building, and cost and risk analyses. You'll help to develop recommendations that will impact how hundreds of millions of dollars are invested throughout the project's life cycle. You'll help identify cost data to be collected, develop data collection plans, and review draft work breakdown structures (WBSs) and cost reporting plans. You will extract data about the technology and performance of submarine communications systems and undersea integration systems through discussions with SMEs, engineers, and project managers. You'll derive meaning from raw numbers using a variety of data science techniques, like normalizing data, performing statistical regression, and using learning curve analysis. From modeling with dynamic formulas in Microsoft Excel to quantifying cost uncertainty with Monte Carlo discrete event simulation, you'll use your experience in analytics and data visualization to interpret and convey meaning. By developing total ownership cost estimates, you'll help program managers, senior leadership, and your client to plan and field systems on time. This is your chance to gain skills in naval systems while continuing to build your cost analysis experience. Join us as we help fuel our country's Navy with the funding they need. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  8+ years of experience with cost estimating or financial data analytics \n  Experience with DoD acquisition and supporting major milestones \n  Experience with data collection and analysis \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with the manufacturing process flow \n  Experience with management and business development \n  Ability to multi-task and work under minimal supervision \n  Possession of excellent verbal and written communication skills \n  Possession of excellent leadership, teamwork, and collaboration skills \n  Bachelor's degree in Engineering, Operations Research, Mathematics, or Economics \n  International Cost Estimating and Analysis Association (ICEAA) Certified Cost Estimator/Analyst (CCE/A) Certification  \n \n \n Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $65,300.00 to $149,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  Experience with data collection and analysis \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with the manufacturing process flow \n  Experience with management and business development \n  Ability to multi-task and work under minimal supervision \n  Possession of excellent verbal and written communication skills \n  Possession of excellent leadership, teamwork, and collaboration skills \n  Bachelor's degree in Engineering, Operations Research, Mathematics, or Economics \n  International Cost Estimating and Analysis Association (ICEAA) Certified Cost Estimator/Analyst (CCE/A) Certification  \n \n \n Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n ",
        "techs": [
            "international cost estimating and analysis association (iceaa) certified cost estimator/analyst (cce/a) certification"
        ],
        "cleaned_techs": []
    },
    "97a67c7e9a64dab5": {
        "terms": [
            "data science"
        ],
        "salary_min": 46584.465,
        "salary_max": 58986.316,
        "title": "Data Journalist",
        "company": "Insurify",
        "desc": "Do you want to be part of Boston's hottest up and coming startup? Insurify is one of the fastest-growing MIT FinTech startups and has been recognized as a global Top 100 InsurTech company. We're changing the way millions of people compare and buy insurance with artificial intelligence, technology, and superior product design. \n  Our team is highly analytical, fast-moving, and focused on one thing: getting more people to compare insurance quotes using Insurify. \n  Join us if you like: \n \n $1.3 Trillion market opportunity \n MIT alumni founders \n Female-led startup \n $130M total funding \n Strong leadership team from Kayak, Amazon, Wayfair, Facebook, Microsoft, Allstate, GEICO, Liberty Mutual, Zillow \n \n How you will make an impact: \n \n Dive deep into proprietary data sources to find and write the stories that will interest the media and establish Insurify as the leading source of insurance data \n Gather public data and research from the Census and other public sources to balance topical and tangential content topics \n Build and nurture relationships with journalists and editors at key media outlets, understanding their interests and how our data, content, studies and reports can resonate with them and their audiences \n Program survey to gather qualitative and quantitative insights \n Play a key role in creating a proactive content strategy that drives media attention and builds authority \n Analyze competitor content and successes to identify opportunities for improvement \n Drive digital PR strategy for topics including auto and homeownership in relation to insurance \n Owns the whole process of data insights content creation from ideation to data gathering to writing and to pitching \n Identify opportunities to collaborate with stakeholders to launch new data content \n \n Who you are: \n \n A self-starter who has a portfolio of data storytelling \n You have 3-5 years of data writing and data analysis experience \n You have some experience with digital PR and are motivated to get your insights reported on by the media \n You have at least 1 year experience in programming languages R or SQL \n You already understand or are interested in how links make an impact on SEO \n You are excited about brainstorming and shipping new data-driven content ideas \n You are always looking for incremental ways to improve whatever you are working on \n You love writing and have strong communication skills \n You are an analytical person who dives deep to understand the \"why\" behind questions \n You are a detailed-oriented person who takes time to understand what will engage your audience \n You consistently strike a writing tone that communicates depth of knowledge and empathy \n You can accurately employ AP style and active voice within your writing \n \n Benefits: \n \n Competitive compensation \n Generous stock options \n Health, Dental Coverages \n 401K plan with match \n Unlimited PTO \n Generous company holiday calendar \n Learning & Development Stipends \n Paid Family Leave \n Social impact volunteer time and donation matches \n Catered lunches in the office \n Free snacks and beverages every day in office \n \n \n \n We are proud to be  \n an Equal Employment Opportunity and Affirmative Action employer.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "cb1246a5962f567f": {
        "terms": [
            "data science"
        ],
        "salary_min": 73000.0,
        "salary_max": 166000.0,
        "title": "Artificial Intelligence Solution Architect",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Honolulu,HI,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0183382\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Artificial Intelligence Solution Architect\n           Key Role: \n  Design and implement effective AI solution architecture and strategy, utilizing approaches of various AI technologies and methods to address clients' business problems and needs, while complying with company's strategies, business goals, and key ethical considerations. Apply advanced consulting skills and extensive technical expertise, including full industry knowledge. Develop innovative solutions to complex problems. Work without considerable direction, and mentor and supervise team members. \n \n  Basic Qualifications: \n \n  Experience developing scripts and programs for converting various types of data into usable formats \n  Experience creating code for retrieving, parsing, and processing structured and unstructured data \n  Experience leading projects and analyzing ethical risks \n  Experience with Python, Pyspark, Scala, or Java \n  Experience with cloud engineering, including security, on Azure, AWS, or GCP \n  Experience creating solutions within a collaborative, cross-functional team environment \n  TS/SCI clearance \n  Bachelor\u2019s degree \n \n \n  Additional Qualifications: \n \n  3+ years of experience designing, developing, operationalizing, and maintaining complex data pipelines in a cloud environment, including AWS, Azure, or Google Cloud \n  Experience with distributed data and computing tools, including Spark, Databricks, Hive, AWS EMR, or Kafka \n  Experience working on real-time data and streaming applications \n  Experience with NoSQL implementation, including MongoDB, Elasticsearch, or Cassandra \n  Experience with Agile engineering practices \n  Experience with UNIX or Linux, including basic commands and Shell scripting \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,000.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  Basic Qualifications: \n \n  Experience developing scripts and programs for converting various types of data into usable formats \n  Experience creating code for retrieving, parsing, and processing structured and unstructured data \n  Experience leading projects and analyzing ethical risks \n  Experience with Python, Pyspark, Scala, or Java \n  Experience with cloud engineering, including security, on Azure, AWS, or GCP \n  Experience creating solutions within a collaborative, cross-functional team environment \n  TS/SCI clearance \n  Bachelor\u2019s degree \n \n \n  Additional Qualifications: \n \n  3+ years of experience designing, developing, operationalizing, and maintaining complex data pipelines in a cloud environment, including AWS, Azure, or Google Cloud \n  Experience with distributed data and computing tools, including Spark, Databricks, Hive, AWS EMR, or Kafka \n  Experience working on real-time data and streaming applications \n  Experience with NoSQL implementation, including MongoDB, Elasticsearch, or Cassandra ",
        "techs": [
            "python",
            "pyspark",
            "scala",
            "java",
            "azure",
            "aws",
            "gcp",
            "spark",
            "databricks",
            "hive",
            "aws emr",
            "kafka",
            "mongodb",
            "elasticsearch",
            "cassandra"
        ],
        "cleaned_techs": [
            "python",
            "pyspark",
            "scala",
            "java",
            "azure",
            "aws",
            "gcp",
            "spark",
            "databricks",
            "hive",
            "kafka",
            "mongodb",
            "elasticsearch",
            "cassandra"
        ]
    },
    "1e3488af9a3c0823": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 100422.83,
        "salary_max": 130016.93,
        "title": "Senior Data Scientist",
        "company": "Solera",
        "desc": "Who We Are \n Solera is a global leader in data and software services that strives to transform every touchpoint of the vehicle lifecycle into a connected digital experience. In addition, we provide products and services to protect life\u2019s other most important assets: our homes and digital identities. Today, Solera processes over 300 million digital transactions annually for approximately 235,000 partners and customers in more than 90 countries. Our 6,500 team members foster an uncommon, innovative culture and are dedicated to successfully bringing the future to bear today through cognitive answers, insights, algorithms and automation. For more information, please  visit solera.com. \n The Role \n This senior data scientist position will be a part of cross-functional technical team of engineers working on cutting-edge technology in video safety IoT platforms, leveraging data produced by computer vision and sensor data. Job duties will include overseeing the full lifecycle of edge algorithms, from R&D and design, to implementation and QA. This role requires strong problem-solving skills, an aptitude for team collaboration, and sharp communication skills. \n What You\u2019ll Do \n \n Design intelligent systems that consume computer-vision and sensor data that output probability of driving risk in real time \n Create clear and concise demos that advertise the success of a designed algorithm \n Garner feedback from firmware engineering and product management regarding product needs and constraints \n Take an active role in the implementation of algorithms on edge platforms \n Execute code reviews and oversee unit testing \n Continuously learn about the current technologies and industry standards \n Collaborate with team members on design and implementation \n Lead efforts to assess performance of edge algorithms and troubleshoot when improvements are needed \n \n What You\u2019ll Bring \n Education \n \n BS, MS, or PhD in STEM field, computer science, data science, or equivalent/proven professional experience \n \n Skills and Expertise \n \n 4-6 years data science and/or algorithm development experience \n Strong abilities in analytic and scientific problem solving \n Ability to learn quickly and efficiently when exposed to new concepts \n Significant experience with Python and SQL \n Expertise in machine learning and AI systems \n Knowledge of projective geometry and homographies a plus \n Experience with ADAS and driver-behavior systems a plus \n Experience in IoT and development of embedded applications is a plus \n Experience with Simulink and Alteryx is a plus \n \n Job Type: Full-time \n Salary: $100,422.83 - $130,016.93 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Life insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Supplemental pay types: \n \n Signing bonus \n \n Application Question(s): \n \n Could you share with us your salary expectation? \n \n Experience: \n \n Python: 5 years (Required) \n SQL: 5 years (Required) \n Data science: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Collaborate with team members on design and implementation \n Lead efforts to assess performance of edge algorithms and troubleshoot when improvements are needed \n \n What You\u2019ll Bring \n Education \n \n BS, MS, or PhD in STEM field, computer science, data science, or equivalent/proven professional experience \n \n Skills and Expertise \n \n 4-6 years data science and/or algorithm development experience \n Strong abilities in analytic and scientific problem solving ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "88935212649ed4b0": {
        "terms": [
            "data science"
        ],
        "salary_min": 175000.0,
        "salary_max": 200000.0,
        "title": "Director of Cloud Operations",
        "company": "Origami Risk LLC",
        "desc": "Overview: \n  \n   As the Director of Cloud Operations, you will be the leader of the Cloud Operations Site Reliability Engineering practice at Origami Risk and be responsible for Applications, Observability, and Problem Management functions. You are tasked with ensuring high-quality outcomes for Origami\u2019s customers, ensuring services are available, performant, and that full and actionable investigations are conducted into any service impairments to prevent recurrence.\n  \n \n \n  Starting base pay for this role is between $175,000 and $200,000. The actual base pay is dependent upon many factors, such as transferable skills, work experience, business needs, training, location, and market demands. The base pay range is subject to change and may be modified in the future. This role will be eligible for a bonus as well as competitive medical, dental, and vision benefits, wellness reimbursement, life insurance, and a 401(k) with company match. We offer vacation and sick leave benefits (under a flexible time off policy in most states).\n  \n \n \n  Origami Risk is proud to be an equal opportunity employer. We thrive and benefit from diversity and are committed to creating an inclusive and equitable environment for all employees. We do not discriminate against any individual based upon race, religion, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, color, sex, national origin, age, marital status, military or veteran status, disability, or any other characteristic protected by applicable law.\n   Responsibilities: \n  \n Develop and articulate a strategic vision for the SRE practice, aligning it with the organization's goals and objectives. \n  Provide strong leadership and guidance to SRE teams, fostering a culture of reliability and continuous improvement. \n  Oversee the availability, performance, and reliability of applications and services, collaborating closely with development and operations teams. \n  Define and track key performance indicators (KPIs) to measure the effectiveness of SRE initiatives and report on the state of system reliability. \n  Define and implement observability strategies, ensuring comprehensive monitoring, logging, and tracing across the infrastructure and applications. \n  Utilize observability tools and data to proactively identify performance bottlenecks and areas for optimization. \n  Develop and manage a robust problem management process, including post-incident analysis and root cause identification. \n  Lead investigations into service impairments, implement corrective actions, and establish preventive measures to enhance system reliability. \n  Develop and maintain incident response procedures, ensuring rapid incident detection, escalation, and resolution. \n  Manage on-call rotations and incident response procedures to minimize service disruptions. \n  Collaborate with capacity planning teams to ensure adequate resources are available to meet growing demands while maintaining performance and reliability. \n  Foster strong collaboration between SRE, Development, and DevOps teams, facilitating knowledge sharing and alignment on reliability goals. \n  Lead the maturing and advancement of Origami platforms and drive alignment between Cloud Operations and Engineering teams. \n  Recruit, mentor, and develop SRE team members, helping them grow in their roles and advance professionally. \n  Other responsibilities as assigned. \n  Qualifications: \n  \n 10+ years of Cloud Operations/SRE leadership experience \n  Bachelor's degree in Computer Science, Data Science, or related technology experience \n  Mastery of SaaS Cloud Operations \n  Extensive experience with Public Cloud platforms (AWS strongly preferred) \n  Ability to develop and articulate a strategic vision for SRE practices that aligns with organizational goals. \n  Deep technical knowledge of system architecture, application design, and cloud technologies, enabling informed decision-making and problem-solving. \n  Extensive experience with observability/monitoring tools such as Splunk, Dynatrace, Elastic, New Relic, Prometheus, and Grafana  \n Strong incident response and resolution experience, including managing on-call rotations and minimizing service disruptions. \n  Proficiency in observability tools, metrics, and data analysis to proactively identify performance bottlenecks and areas for optimization \n  Ability to integrate disparate systems via APIs and other means \n  Knowledge of Continuous Integration and Continuous Delivery (CI/CD) pipelines \n  Advanced written and verbal communication skills \n  Ability to present results to a diverse audience including non-technical colleagues \n  Ability to succeed when facing ambiguity and differing levels of operational maturation  \n \n \n  Additionally desired skills:\n  \n \n  Strong understanding of Kubernetes and other container-based architectures \n  Windows and SQL-server troubleshooting skills \n  Knowledge of AWS IAM, Organizations, Budgets, SCPs, and Control Tower \n \n \n  Who We Are \n \n \n   Origami Risk is an industry-leading provider of integrated SaaS solutions for the risk and insurance industry\u2014from insured corporate and public entities to brokers and risk consultants, insurers, third party claims administrators (TPAs), and risk pools. We deliver a full suite of risk management and insurance core system solutions from a single, secure, cloud-based platform. We have a singular focus on helping clients achieve their business objectives by developing, implementing, and supporting our technology solutions.\n  \n \n \n  Founded in 2009 by Risk Management Information System (RMIS) industry veterans, over the past decade Origami Risk has received more than two dozen awards for service excellence, technology innovation, and workplace culture. In addition to inclusion in Deloitte\u2019s Technology Fast 500\u2122, a ranking of the 500 fastest-growing tech companies in North America, Origami Risk also has been repeatedly recognized by Inc. magazine as one of the \u201cBest Places to Work\u201d and Best and Brightest\u00ae Companies To Work For in the Nation by the National Association for Business Resources (NABR).",
        "cleaned_desc": "  Foster strong collaboration between SRE, Development, and DevOps teams, facilitating knowledge sharing and alignment on reliability goals. \n  Lead the maturing and advancement of Origami platforms and drive alignment between Cloud Operations and Engineering teams. \n  Recruit, mentor, and develop SRE team members, helping them grow in their roles and advance professionally. \n  Other responsibilities as assigned. \n  Qualifications: \n  \n 10+ years of Cloud Operations/SRE leadership experience \n  Bachelor's degree in Computer Science, Data Science, or related technology experience \n  Mastery of SaaS Cloud Operations \n  Extensive experience with Public Cloud platforms (AWS strongly preferred) \n  Ability to develop and articulate a strategic vision for SRE practices that aligns with organizational goals. \n  Deep technical knowledge of system architecture, application design, and cloud technologies, enabling informed decision-making and problem-solving.    Extensive experience with observability/monitoring tools such as Splunk, Dynatrace, Elastic, New Relic, Prometheus, and Grafana  \n Strong incident response and resolution experience, including managing on-call rotations and minimizing service disruptions. \n  Proficiency in observability tools, metrics, and data analysis to proactively identify performance bottlenecks and areas for optimization \n  Ability to integrate disparate systems via APIs and other means \n  Knowledge of Continuous Integration and Continuous Delivery (CI/CD) pipelines \n  Advanced written and verbal communication skills \n  Ability to present results to a diverse audience including non-technical colleagues \n  Ability to succeed when facing ambiguity and differing levels of operational maturation  \n \n \n  Additionally desired skills:\n  ",
        "techs": [
            "splunk",
            "dynatrace",
            "elastic",
            "new relic",
            "prometheus",
            "grafana",
            "aws",
            "apis",
            "continuous integration",
            "continuous delivery"
        ],
        "cleaned_techs": [
            "splunk",
            "dynatrace",
            "elastic",
            "new relic",
            "prometheus",
            "grafana",
            "aws",
            "apis",
            "continuous integration",
            "continuous delivery"
        ]
    },
    "d571d768c651bdb0": {
        "terms": [
            "data science"
        ],
        "salary_min": 95000.0,
        "salary_max": 110000.0,
        "title": "Senior Digital Data Analyst",
        "company": "Gannett",
        "desc": "Gannett Co., Inc. (NYSE:  GCI) is a subscription-led and digitally-focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer Prize-winning content, consumer experiences and benefits, and advertiser products and services. \n \n  Our current portfolio of media assets includes The USA TODAY NETWORK, which includes USA TODAY, and local media organizations in 43 states in the United States, and Newsquest, a wholly-owned subsidiary operating in the United Kingdom. We also own digital marketing services companies under the brand LocaliQ, which provide a cloud-based platform of products to enable small and medium-sized businesses to accomplish their marketing goals. In addition, our portfolio includes one of the largest media-owned events businesses in the U.S., USA TODAY NETWORK Ventures. \n \n  Gannett open roles are featured on various external job boards. When applying to a position at Gannett, you should be completing an application on Gannett Careers via Dayforce. Job postings directing you to complete an application on other external sites may not be valid. \n \n  To connect with us, visit www.gannett.com \n \n  We are seeking an experienced Senior Digital Data Analyst to join our team. The successful candidate will be responsible for leading and supporting the development of data-driven insights from Google Analytics that inform business decisions and drive impact. You will work closely with cross-functional teams, including product, growth marketing, content strategy, and experimentation. The Senior Data Analyst, is a position on the Enterprise Data Management team, reporting to the Director of Data Enablement and works closely with Product, Marketing, and Testing teams \n \n  This is an in-the-trenches position from helping stakeholders scope projects and understand their analytics needs to showing them how this data will translate into actionable use cases. \n \n  The ideal candidate has elite experience with stakeholder management, can tell a story through data, and get their point across without too much technical jargon. The ability to quickly understand and join complex and disparate data sets is a must. Hence the ideal candidate should be a problem solver who is comfortable thinking outside the box. The ideal candidate will have a strong analytical background, excellent communication skills, a passion for problem-solving, and the ability to evangelize data across the company. \n \n \n Base Salary:  $95,000 - $110,000/annually \n \n  Key Responsibilities \n \n \n Collaborate with business partners to define and prioritize business problems, develop hypotheses, and design experiments to test them. \n Scope projects for accurate analytics tagging, and tracking across multiple platforms and content initiatives. \n Gather and analyze data from multiple sources to uncover insights that inform business decisions and drive growth. \n Develop and present reports, dashboards, and visualizations that effectively communicate insights and recommendations to senior management. \n Help maintain strong data governance \n Partner with stakeholders across the organization to understand their needs and translate those needs into actionable insights. \n Serve as a thought leader and subject matter expert for business analytics, continuously exploring new data sources and technologies to improve our capabilities. \n Mentoring and coaching stakeholders from across the company on the mechanics and nuances of our data sets. \n Unlock and explain data to stakeholders ranging from content creators to data scientists. \n Answer questions from across the company on what insights can be gleaned from different data sets. \n \n Requirements: \n \n \n 5+ years of experience in business analytics, data analytics, or related fields. \n Experience with Enterprise Google Analytics 4 and tag management tools including Google Tag Manager is a must. \n Strong analytical skills with experience in SQL, and BigQuery are a must. \n Experience with data visualization tools (Tableau, Looker Studio, Looker Pro, etc.) is a must. \n Experience with Salesforce Marketing Cloud (Datorama) and/or ExactTarget data is good to have. \n Experience with DataRobot and other data science tools is good to have. \n Strong communication and teaching skills. \n Ability to work independently as well as collaboratively with cross-functional teams and manage multiple projects simultaneously. \n Experience in the publishing, subscriptions, and ad revenue space is a plus. \n  #LI-NR2 \n #LI-REMOTE \n \n  The annualized base salary for this role will range between $59,400 and $140,300. Base compensation is reflective of many factors, including, but not limited to, the market in which one lives/works, individual education level, skills, certifications, and \n \n experience. Note:  variable compensation is not reflected in these figures and based on the role, may be applicable \n \n  Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee\u2019s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant\u2019s disability or religion, to complete this employment application and/or any other process in connection with an individuals\u2019 application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.\u2019s Recruitment Department at Recruit@gannett.com.",
        "cleaned_desc": " \n Requirements: \n \n \n 5+ years of experience in business analytics, data analytics, or related fields. \n Experience with Enterprise Google Analytics 4 and tag management tools including Google Tag Manager is a must. \n Strong analytical skills with experience in SQL, and BigQuery are a must. \n Experience with data visualization tools (Tableau, Looker Studio, Looker Pro, etc.) is a must. \n Experience with Salesforce Marketing Cloud (Datorama) and/or ExactTarget data is good to have. \n Experience with DataRobot and other data science tools is good to have. ",
        "techs": [
            "enterprise google analytics 4",
            "google tag manager",
            "sql",
            "bigquery",
            "tableau",
            "looker studio",
            "looker pro",
            "salesforce marketing cloud (datorama)",
            "exacttarget",
            "datarobot"
        ],
        "cleaned_techs": [
            "enterprise google analytics 4",
            "google tag manager",
            "sql",
            "bigquery",
            "tableau",
            "looker studio",
            "looker pro",
            "salesforce marketing cloud (datorama)",
            "exacttarget",
            "datarobot"
        ]
    },
    "fbc1477b9d3c7bc3": {
        "terms": [
            "data science"
        ],
        "salary_min": 100256.65,
        "salary_max": 126947.26,
        "title": "Remote - Data Scientist, Journeyman",
        "company": "Precise Systems",
        "desc": "Precise Systems is a professional services company supporting U.S. Department of Defense programs. Our core capabilities include Digital Transformation, Advanced Engineering, Acquisition & Lifecycle Support, Information Technology, and Technical Solutions. Precise was founded in 1990, and since our establishment, we have provided cutting-edge solutions and support to our warfighters. At Precise, we understand and provide expert consultation on network and weapons systems acquisition, maintenance/modernization, and sustainment programs. For over 30 years, Precise Systems has demonstrated and perfected our ability to manage any task, no matter how difficult or complex. \n  We are expanding our team by seeking a  Data Scientist, Journeyman  to support our government customers with data quality, fidelity, and analytics across several systems of record. \n  The ideal candidate will have proven professional experience in duties common across Data Science, Data Analytics, and Database Administration - not limited to expertise in ETL, data modeling and data validation - for the purpose of empowering business decisions at the highest level of leadership or to support routine and predictive operational assessments.  This position is fully remote . \n  Duties will include customer requirements gathering, data mining and modeling, creating ad hoc reports, contributing to a portfolio of data analytics products, presenting data using myriad business intelligence tools, and troubleshooting and maintenance support. The candidate will promote data stewardship both internally and externally to the team and be responsible for designing methods critical to data quality and analysis through utilization of contemporary statistical methodology and tools. \n  Functional Duties: \n \n Work with all levels of military and civilian leadership and internal team of analysts and process owners to identify opportunities for improvement. \n Expertise in multiple data tools, including staying abreast on emergent industry related capabilities or \n Experienced working with large, complex data sets and a high technical capacity to understand and derive relationships in data structures across multiple disparate systems for comparative analysis. \n Capable of working autonomously or across teams in high-pressure situations and in remote settings \n Ability to understand and document requirements to develop analytical products and supporting documentation, and demonstration of facilitating customer requirements through a project management process or system. \n Strong analytical and problem-solving skills with excellent attention to detail \n \n Required Education : \n \n BA/BS degree in accounting, statistics, mathematics, computer science, business, or related field.  OR  2 years of additional relevant experience will be considered in lieu of each year of education. \n \n Required Experience: \n \n Minimum of three (3) years of professional related analytical experience. Expert background in the use of data and visualization tools (to include Microsoft Excel, Tableau, Qlik, or Power BI), and knowledge of developing database queries for Microsoft SQL Server or other database tools. \n \n   Desired: \n \n Relevant and recent professional certifications (Microsoft Certified Data Analyst, Data Engineer, and Data Scientist, Tableau, etc.) desired. \n \n Must be able to obtain and maintain a Secret security clearance. Due to the sensitivity of customer related requirements, U.S. Citizenship is required. \n  Precise Systems, Inc. is an Affirmative Action/Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status. Precise Systems, Inc. participates in E-Verify. Precise Systems, Inc. encourages and supports workplace diversity. \n \n \n  Required Skills\n    \n \n  Required Experience",
        "cleaned_desc": "Precise Systems is a professional services company supporting U.S. Department of Defense programs. Our core capabilities include Digital Transformation, Advanced Engineering, Acquisition & Lifecycle Support, Information Technology, and Technical Solutions. Precise was founded in 1990, and since our establishment, we have provided cutting-edge solutions and support to our warfighters. At Precise, we understand and provide expert consultation on network and weapons systems acquisition, maintenance/modernization, and sustainment programs. For over 30 years, Precise Systems has demonstrated and perfected our ability to manage any task, no matter how difficult or complex. \n  We are expanding our team by seeking a  Data Scientist, Journeyman  to support our government customers with data quality, fidelity, and analytics across several systems of record. \n  The ideal candidate will have proven professional experience in duties common across Data Science, Data Analytics, and Database Administration - not limited to expertise in ETL, data modeling and data validation - for the purpose of empowering business decisions at the highest level of leadership or to support routine and predictive operational assessments.  This position is fully remote . \n  Duties will include customer requirements gathering, data mining and modeling, creating ad hoc reports, contributing to a portfolio of data analytics products, presenting data using myriad business intelligence tools, and troubleshooting and maintenance support. The candidate will promote data stewardship both internally and externally to the team and be responsible for designing methods critical to data quality and analysis through utilization of contemporary statistical methodology and tools. \n  Functional Duties: \n   Work with all levels of military and civilian leadership and internal team of analysts and process owners to identify opportunities for improvement. \n Expertise in multiple data tools, including staying abreast on emergent industry related capabilities or \n Experienced working with large, complex data sets and a high technical capacity to understand and derive relationships in data structures across multiple disparate systems for comparative analysis. \n Capable of working autonomously or across teams in high-pressure situations and in remote settings \n Ability to understand and document requirements to develop analytical products and supporting documentation, and demonstration of facilitating customer requirements through a project management process or system. \n Strong analytical and problem-solving skills with excellent attention to detail   \n Minimum of three (3) years of professional related analytical experience. Expert background in the use of data and visualization tools (to include Microsoft Excel, Tableau, Qlik, or Power BI), and knowledge of developing database queries for Microsoft SQL Server or other database tools. \n \n   Desired: \n \n Relevant and recent professional certifications (Microsoft Certified Data Analyst, Data Engineer, and Data Scientist, Tableau, etc.) desired. ",
        "techs": [
            "etl",
            "data modeling",
            "data validation",
            "business intelligence tools",
            "statistical methodology",
            "microsoft excel",
            "tableau",
            "qlik",
            "power bi",
            "microsoft sql server"
        ],
        "cleaned_techs": [
            "etl",
            "data validation",
            "business intelligence tools",
            "statistical methodology",
            "excel",
            "tableau",
            "qlik",
            "powerbi",
            "microsoft sql server"
        ]
    },
    "49d8b01b332c8cfe": {
        "terms": [
            "data science"
        ],
        "salary_min": 120750.0,
        "salary_max": 240000.0,
        "title": "Lead Data Scientist - Retail Strategic Health Analytics",
        "company": "CVS Health",
        "desc": "Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand \u2014 with heart at its center \u2014 our purpose sends a personal message that how we deliver our services is just as important as what we deliver.    Our Heart At Work Behaviors\u2122 support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. \n \n  Position Summary \n \n  Collaborates with business partners to shape the analytics approach to address business priorities (through predictive modeling, statistical analysis, or metric evaluation) as a thought leader \n  Owns and manages an analytics workstream, leading other analysts and data scientists to build end to end analytical products. \n  Uses strong knowledge in algorithms and predictive models to propose approaches, investigate problems, detect patterns and recommend solutions \n  Performs analyses of structured and unstructured data to solve multiple and/or complex business problems utilizing advanced statistical techniques and mathematical analyses and broad knowledge of the organization and/or industry \n  Develops and participates in presentations and consultations to existing and prospective constituents on analytics results and solutions \n  Use strong programming skills to explore, examine and interpret large volumes of data in various forms \n \n  Required Qualifications \n \n  5+ years of relevant analytic experience  \n Experience programming using R or Python  \n Experience in SQL \n \n  Preferred Qualifications \n \n  Demonstrates strong ability to communicate technical concepts and implications to business partners  \n Anticipates and prevents problems and roadblocks before they occur  \n Strong knowledge of advanced analytics tools and languages to analyze large data sets from multiple data sources  \n Demonstrates proficiency in most areas of mathematical analysis methods, machine learning, statistical analyses, and predictive modeling and in-depth specialization in some areas \n \n  Education \n \n  Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline. \n  Master\u2019s degree or PhD preferred \n \n \n  Pay Range \n  The typical pay range for this role is: \n  $120,750.00 - $240,000.00\n   This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company\u2019s equity award program.    In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company\u2019s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (\u201cPTO\u201d) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.    For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits \n \n  CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. \n \n  You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. \n \n  CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.",
        "cleaned_desc": "  Performs analyses of structured and unstructured data to solve multiple and/or complex business problems utilizing advanced statistical techniques and mathematical analyses and broad knowledge of the organization and/or industry \n  Develops and participates in presentations and consultations to existing and prospective constituents on analytics results and solutions \n  Use strong programming skills to explore, examine and interpret large volumes of data in various forms \n \n  Required Qualifications \n \n  5+ years of relevant analytic experience    Experience programming using R or Python  \n Experience in SQL \n \n  Preferred Qualifications \n \n  Demonstrates strong ability to communicate technical concepts and implications to business partners  \n Anticipates and prevents problems and roadblocks before they occur    Strong knowledge of advanced analytics tools and languages to analyze large data sets from multiple data sources  \n Demonstrates proficiency in most areas of mathematical analysis methods, machine learning, statistical analyses, and predictive modeling and in-depth specialization in some areas \n \n  Education \n \n  Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Business Analytics, Economics, Physics, Engineering, or related discipline. \n  Master\u2019s degree or PhD preferred ",
        "techs": [
            "r",
            "python",
            "sql"
        ],
        "cleaned_techs": [
            "r",
            "python",
            "sql"
        ]
    },
    "a435d40719bc99b6": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 140000.0,
        "salary_max": 190000.0,
        "title": "Machine Learning Engineer",
        "company": "Pie Insurance",
        "desc": "Pie's mission is to empower small businesses to thrive by making commercial insurance affordable and as easy as pie. We leverage technology to transform how small businesses buy and experience commercial insurance.\n   \n \n \n \n    Like our small business customers, we are a diverse team of builders, dreamers, and entrepreneurs who are driven by core values and operating principles that guide every decision we make.\n    \n \n \n About The Opportunity \n  You will be joining Pie's MLOps team as a Machine Learning Engineer, you will be a key contributor to our agile team with a focus on ML development tooling and productionizing feature generation pipelines and predictive models. Your primary responsibility will be the development, deployment, and maintenance of our state-of-the-art Machine Learning platform, but your role will extend beyond this. You will leverage your experience in data engineering and model development to help guide best practices, reusability, and simplification on the path to production. Leveraging knowledge and experience with advances in NLP, LLMs and other pretrained models, you will build and optimize scalable machine learning solutions across a wide variety of applications. \n  In this multifaceted role, you'll collaborate with product managers, data scientists, and data engineers to prioritize, build, implement, and support our ML platform. Understanding their data requirements and operational challenges, you will devise tailored solutions and ensure their successful deployment in the cloud using sound engineering practices. \n  Your role within the MLOps team is integral, with a particular emphasis on machine learning libraries, feature engineering, validation, and monitoring. Your contributions will directly impact the robustness, efficiency, and scalability of our ML infrastructure. \n  How You'll Do It \n \n Collaborate with product managers, data scientists, and data engineers to build, implement, and support a world-class ML Platform. This includes participating in designing, training, testing, and deploying ML models, and ensuring their optimal performance in production. \n Design, build, and maintain scalable machine learning solutions and data pipelines, keeping in mind performance and scalability. Use your skills in feature engineering to collaborate with data engineers and data scientists for creating reusable feature stores. \n Monitor the performance of machine learning models in production, debugging and resolving issues as they arise. \n Foster a culture of collaboration and knowledge sharing, educating team members about Machine Learning Engineering/ MLOps best practices like version control for models and data, reproducibility of experiments, evaluation and validation, drift detection and other forms of production monitoring. \n Ensure alignment of ML strategies with the company's broader infrastructure, advocating for compatibility and seamless integration. \n Stay up-to-date with the latest industry trends in machine learning and MLOps, advising on the potential adoption of new tools and techniques. \n Develop full-stack Python applications and service wrappers for delivering predictive services on public cloud infrastructure. Build and manage CI/CD pipelines specific to Machine Learning and Analytic workloads, utilizing Infrastructure as Code (IaC) tools such as AWS CDK, Pulumi, Terraform. \n Manage the full ML platform stack, taking ownership of the complete lifecycle of ML models, from development to maintenance. This includes managing monitoring and data observability. \n Respond promptly and professionally to define, escalate, and resolve all technical issues related to the ML platform stack and the machine learning lifecycle. \n \n The Right Stuff \n \n Minimum of 3 years of experience as a MLOps/Machine Learning Engineer, with a track record of designing, implementing, training, and deploying machine learning solutions in a production environment. \n \n Or 7+ years combination of Data Science, Data Engineer or other related field. \n \n Proficient in SQL, Python and Python based data engineering and machine learning libraries and frameworks like TensorFlow, PyTorch, or scikit-learn. \n Robust understanding of MLOps industry best practices and trends, and ability to select appropriate tools and platforms for machine learning operations. \n Additional expertise in a variety of programming and scripting languages including TypeScript, and Bash is preferred. \n Proficiency in building and deploying containerized microservices for pre-processing and model hosting. \n Knowledge of industry-standard ETL/ELT and data orchestration tools, such as Airflow \n Experience with model registries, production-level feature stores, model monitoring, and various SQL/NoSQL Databases. \n Strong problem-solving and analytical skills, with a demonstrated ability to troubleshoot and enhance machine learning models in production. \n Excellent communication, teamwork, with a proven ability to contribute to team efforts on complex technical initiatives and thrive in a fast-paced, Agile environment with production-oriented, incremental release cycles. \n \n #LI-MS1 \n \n  Base Compensation Range \n \n    $140,000\u2014$190,000 USD\n   \n \n \n  Compensation & Benefits \n \n Competitive cash compensation \n A piece of the pie (in the form of equity) \n Comprehensive health plans \n Generous PTO \n Future focused 401k match \n Generous parental and caregiver leave \n Our core values are more than just a poster on the wall; they're tangibly reflected in our work \n \n Our goal is to make all aspects of working with us as easy as pie.  That includes our offer process. When we've identified a talented individual who we'd like to be a Pie-oneer , we work hard to present an equitable and fair offer. We look at the candidate's knowledge, skills, and experience, along with their compensation expectations and align that with our company equity processes to determine our offer ranges. \n  Each year Pie reviews company performance and may grant discretionary bonuses to eligible team members. \n  Location Information \n  Unless otherwise specified, this role has the option to be hybrid or remote. Hybrid work locations provide team members with the flexibility of working partially from our Denver or DC office and from home. Remote team members must live and work in the United States* (*territories excluded), and have access to reliable, high-speed internet. \n  Additional Information \n  Pie Insurance is an equal opportunity employer. We do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, marital status, age, disability, national or ethnic origin, military service status, citizenship, or other protected characteristic. \n  Pie Insurance participates in the E-Verify program. Please click  here ,  here  and  here  for more information. \n  Pie Insurance is committed to protecting your personal data. Please review our Privacy Policy. \n  Pie Insurance Announces $315 Million Series D Round of Funding \n  Built In honors Pie in its 2023 Best Places to Work Awards \n \n \n    Pie Insurance Named a Leading Place to Work in Colorado\n    \n \n \n    #LI-REMOTE\n    \n \n    #BI-REMOTE",
        "cleaned_desc": " Collaborate with product managers, data scientists, and data engineers to build, implement, and support a world-class ML Platform. This includes participating in designing, training, testing, and deploying ML models, and ensuring their optimal performance in production. \n Design, build, and maintain scalable machine learning solutions and data pipelines, keeping in mind performance and scalability. Use your skills in feature engineering to collaborate with data engineers and data scientists for creating reusable feature stores. \n Monitor the performance of machine learning models in production, debugging and resolving issues as they arise. \n Foster a culture of collaboration and knowledge sharing, educating team members about Machine Learning Engineering/ MLOps best practices like version control for models and data, reproducibility of experiments, evaluation and validation, drift detection and other forms of production monitoring. \n Ensure alignment of ML strategies with the company's broader infrastructure, advocating for compatibility and seamless integration. \n Stay up-to-date with the latest industry trends in machine learning and MLOps, advising on the potential adoption of new tools and techniques. \n Develop full-stack Python applications and service wrappers for delivering predictive services on public cloud infrastructure. Build and manage CI/CD pipelines specific to Machine Learning and Analytic workloads, utilizing Infrastructure as Code (IaC) tools such as AWS CDK, Pulumi, Terraform. \n Manage the full ML platform stack, taking ownership of the complete lifecycle of ML models, from development to maintenance. This includes managing monitoring and data observability. \n Respond promptly and professionally to define, escalate, and resolve all technical issues related to the ML platform stack and the machine learning lifecycle. \n \n The Right Stuff \n \n Minimum of 3 years of experience as a MLOps/Machine Learning Engineer, with a track record of designing, implementing, training, and deploying machine learning solutions in a production environment. \n \n Or 7+ years combination of Data Science, Data Engineer or other related field.   \n Proficient in SQL, Python and Python based data engineering and machine learning libraries and frameworks like TensorFlow, PyTorch, or scikit-learn. \n Robust understanding of MLOps industry best practices and trends, and ability to select appropriate tools and platforms for machine learning operations. \n Additional expertise in a variety of programming and scripting languages including TypeScript, and Bash is preferred. \n Proficiency in building and deploying containerized microservices for pre-processing and model hosting. \n Knowledge of industry-standard ETL/ELT and data orchestration tools, such as Airflow \n Experience with model registries, production-level feature stores, model monitoring, and various SQL/NoSQL Databases. \n Strong problem-solving and analytical skills, with a demonstrated ability to troubleshoot and enhance machine learning models in production. \n Excellent communication, teamwork, with a proven ability to contribute to team efforts on complex technical initiatives and thrive in a fast-paced, Agile environment with production-oriented, incremental release cycles. \n \n #LI-MS1 \n \n  Base Compensation Range \n \n    $140,000\u2014$190,000 USD",
        "techs": [
            "aws cdk",
            "pulumi",
            "terraform",
            "sql",
            "python",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "typescript",
            "bash",
            "airflow",
            "etl/elt tools",
            "data orchestration tools",
            "model registries",
            "sql/nosql databases."
        ],
        "cleaned_techs": [
            "aws",
            "pulumi",
            "terraform",
            "sql",
            "python",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "typescript",
            "bash",
            "airflow",
            "etl/elt tools",
            "data orchestration tools",
            "model registries"
        ]
    },
    "89451d35464304f1": {
        "terms": [
            "data science"
        ],
        "salary_min": 150083.66,
        "salary_max": 190039.34,
        "title": "Head of CHC Data Architecture and Modeling",
        "company": "Sanofi",
        "desc": "Overview \n From Research and Development to Sales and Marketing, Sanofi offers a wide range of possibilities. Discover our open positions and become a health journey partner. \n \n \n \n \n \n \n \n \n \n Success Profile \n \n      Do you have what it takes for a successful career with Sanofi?\n      \n \n \n \n       Courageous\n       \n \n \n       Results-driven\n       \n \n \n       Proactive\n       \n \n \n       Problem-Solver\n       \n \n \n       Leadership\n       \n \n \n       Team player\n       \n \n \n \n \n \n \n \n \n Culture: Play to Win \n \n \n \n Growth \n \n \n \n \n Innovation \n \n \n \n \n Efficiency \n \n \n \n \n Collaboration \n \n \n \n \n \n \n \n Benefits \n \n \n \n Health & Wellness \n \n       Comprehensive coverage including medical, dental, vision, and health and wellness programs.\n       \n \n \n \n Financial \n \n       Sanofi wants to ensure employees are equipped for financial health, Sanofi provides a competitive 401K Match program and Financial Wel-Being Tools and Programs.\n       \n \n \n \n Culture \n \n       At Sanofi, we demonstrate our commitment to inclusion and diversity through Culture groups and programs. There are many ways to make a difference and connect with other Sanofi employees: including ERG groups and 2 PAID days off to Volunteer.\n       \n \n \n \n Work/Life Balance \n \n       Sanofi provides significant Work/Life benefits to help you excel beyond the workday. Including Workplace Flexibility through part\u2011time, remote work, flex\u2011time and job share options.\n       \n \n \n \n \n \n \n \n \n Quote \n \n \n \n \n \n \n \n \n        \"At Sanofi, We are guided by a deep appreciation and understanding of what it means to live with a rare blood disorder, and we learn by listening to the community \u2013 patients, caregivers physicians, and other healthcare professionals.\"\n        \n \n \n \n \n Shannon Resetich \n \n   \n \n US Head Rare Diseases & Blood Disorders \n \n   \n \n \n \n \n \n \n \n \n \n \n \n Responsibilities \n \n Global Digital Team.  The team is charged with accelerating the shift to precision marketing and to e-commerce sales, scaling best-in-class data driven decision making tools, capturing new opportunities in the digital health space and uphauling disjointed commercial systems. T his  team leverages both dedicated expertise internally at Sanofi, and delivery and deployment partners. It builds products, runs service / outsourcing contracts, and develops centers of excellence in technology and digital. \n  IShift . IShift is the new generation of SAP S4/ HANA, with one common framework across Sanofi BUs and geographies replacing JDEdwards in the US, OEP and unity in all other geographies. \n  POSITION OVERVIEW \n  A cornerstone of CHC transformation in the coming years, the  Business Intelligence team  defines the strategy and operationalization of data  practices  to lead the change and transform internal practices: \n \n  Embody Sanofi transformation with regular communications, team upskilling, and proactivity \n  The Head of Data Architecture, Modeling and BI, leads the CHC businesses and responsible for enterprise data and analytics architecture, providing thought leadership and architecture services for all aspects of data and analytics transversally, including data platforms, data services, advanced analytics, reporting, data visualizations, knowledge engineering, data acquisition, and integration. \n  Lead cross-functional enterprise-wide strategies for data and analytics, in partnership with Master Data Governance team, Platforms, Data and Learning Creation Center and other CHC Digital and business groups. \n  He/she expands the organization\u2019s data and analytics offerings, with focus on emerging analytical approaches, skills, and technologies to drive value from CHC data assets and enable business innovation. \n \n  As part of this team the  Head of Data Architecture & Modeling  will be working across different data projects, applications, and processes in order to enable CHC a true data driven organization. \n  KEY RESPONSIBILITIES \n  The  Head of Data Architecture & Modeling  will be responsible for: \n \n  Lead the CHC organization\u2019s enterprise data and analytics architecture, providing thought leadership and architecture services for all aspects of data and analytics, including data platforms, data services, advanced analytics, reporting, data visualizations, master data management, knowledge engineering, data acquisition and integration. \n  Initiate and oversee strategic efforts to identify, develop and host data and information services that reach across domains, support reuse of internal and external data, and build trust in data and analytical information, improving data access and usability to accelerate scientific and business insights. \n  Lead a team of data and analytics architects, Data Science and Visualization, responsible for research, analysis, design, and delivery of data and solution architectures to support business strategies and priorities across all CHC business functions. \n  Understand emerging industry and innovative technology trends to effectively prioritize and practically apply existing, new, and emerging technologies to harness insights and value from CHC\u2019s internal and external data. \n  Develop and promote modern architectural approaches that encourage data and value exchange with partners and customers, digitization of processes, business connectivity, and partner collaboration. \n  Perform an involved advisory role on large complex analytics initiatives. Provide leadership in building consensus on approach and provide technical execution oversight. Identify and mediate conflicting requirements among solution stakeholders. \n  Contributes to strategic efforts that support integration into other ecosystems through data while building trust in end-to-end use of data for decision sciences. \n  Lead and provide oversight on data, application, and technology lifecycles, from emerging technology assessments through to renewal or retirement. \n  Cultivate technical expertise and champion and enable learning, adoption, reskill and reuse across Digital. \n  Mentor, coach, guide and grow architecture team members and other Digital colleagues, creating a strong collaborative engaging cross functional team culture. \n  Partner with internal teams regarding innovation, technologies, governance, lifecycle management (platforms), adoption and/or training/use. \n  Ensure that data is managed in compliance with applicable quality, regulatory (Data Privacy, GxP, SOX, etc.) and cybersecurity requirement \n \n  QUALIFICATIONS \n \n  10  years or more experience in Data Analytics and Architecture space \n  Experience of Data Architecture & Modeling, preferably in FMCG \n  Experience in IICS, Tibco, SAP BODS \n  Experience in Advance Analytics & Cloud solutions \n  Experience in Data Science, AI and ML \n  Experience in DevOps and Product Lifecycle \n  Agile ways of working and large projects phased delivery \n  Data & Business intelligence domain and software experience is a plus \n  Strong Experience of Interfacing heterogeneous systems and data sources \n  Strong Experience of Snowflake, DataBricks, Python/R, Tableau, Power BI \n  Strong Experience of Informatica, Layer 7 and Apigee \n  Working knowledge of procuring data from ERPs (SAP, JDE, etc.). \n  Working knowledge of Data governance and Security \n \n  Education \n \n  Bachelor's degree \n  Fluent in English \n \n  International Program Management Skills \n \n  Leading multicultural and multi-sourced teams \n  Multi-country deployment, involving local stakeholders \n  Cross functional leadership and influencing \n  Lead people and timelines in a matrix organization in compliant and professional manner \n  Quarterly budgeting \n  Excellent presentation to executive teams, writing, power point and organizational skills \n  Contracting and contract managing software vendors and system integrators \n  Strategic development in a multi-dimensional and rapid changing environment \n \n  Digital Program Leadership \n \n  Leading cross-functional teams to create Digital strategies and roadmaps \n  Design thinking and product development methods (blueprint, iteration, fast pivot, etc.) \n  Transformative digital and/or technology solutions track record (design, develop, deliver) \n  Relentless & creative problem-solving to deliver in a complex governance environment \n  Outstanding risk management and \u201cget things done\u201d mindset \n  Educates on basics (SEO, UI/UX, Agile, etc.) and complexity (architecture, emerging tech) \n  Fast learner in new industries and functions (e.g., legal, finance) \n \n  People Leadership \n \n  Outstanding relationship-building, effective in a matrixed, culturally diverse organization. \n  Influence skills at all levels of seniority, including people who do not work for him/her. \n  Balance pushing for change and bringing people along; conflict resolution mindset. \n  Fast & high-quality written communications, business cases and analyses (MS Office) \n \n  SKILLS & COMPETENCIES \n \n  FMCH / IT Ckills and Competencies \n \n  Job in FMCG & Governance (advanced) \n  Lean & Agile practices (advanced) \n  User Experience (intermediate) \n  Program / Product & Portfolio Management (advanced) \n  Financial Planning (advanced) \n  Vendor Management (advanced) \n \n  Transversal Skills & Competencies (Soft Skills) \n \n  Business Acumen (advanced) \n  Business Partnership (advanced) \n  Transversal collaboration (advanced) \n  Strategic Thinking (advanced) \n  Decision Making (advanced) \n  Change Management (advanced) \n \n  Sanofi Inc. and its U.S. affiliates are Equal Opportunity and Affirmative Action employers committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race; color; creed; religion; national origin; age; ancestry; nationality; marital, domestic partnership or civil union status; sex, gender, gender identity or expression; affectional or sexual orientation; disability; veteran or military status or liability for military status; domestic violence victim status; atypical cellular or blood trait; genetic information (including the refusal to submit to genetic testing) or any other characteristic protected by law.) \n  #GD-SA  #LI-SA \n \n  At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.",
        "cleaned_desc": " Global Digital Team.  The team is charged with accelerating the shift to precision marketing and to e-commerce sales, scaling best-in-class data driven decision making tools, capturing new opportunities in the digital health space and uphauling disjointed commercial systems. T his  team leverages both dedicated expertise internally at Sanofi, and delivery and deployment partners. It builds products, runs service / outsourcing contracts, and develops centers of excellence in technology and digital. \n  IShift . IShift is the new generation of SAP S4/ HANA, with one common framework across Sanofi BUs and geographies replacing JDEdwards in the US, OEP and unity in all other geographies. \n  POSITION OVERVIEW \n  A cornerstone of CHC transformation in the coming years, the  Business Intelligence team  defines the strategy and operationalization of data  practices  to lead the change and transform internal practices: \n \n  Embody Sanofi transformation with regular communications, team upskilling, and proactivity \n  The Head of Data Architecture, Modeling and BI, leads the CHC businesses and responsible for enterprise data and analytics architecture, providing thought leadership and architecture services for all aspects of data and analytics transversally, including data platforms, data services, advanced analytics, reporting, data visualizations, knowledge engineering, data acquisition, and integration. \n  Lead cross-functional enterprise-wide strategies for data and analytics, in partnership with Master Data Governance team, Platforms, Data and Learning Creation Center and other CHC Digital and business groups. \n  He/she expands the organization\u2019s data and analytics offerings, with focus on emerging analytical approaches, skills, and technologies to drive value from CHC data assets and enable business innovation. \n \n  As part of this team the  Head of Data Architecture & Modeling  will be working across different data projects, applications, and processes in order to enable CHC a true data driven organization. \n  KEY RESPONSIBILITIES \n  The  Head of Data Architecture & Modeling  will be responsible for: \n \n  Lead the CHC organization\u2019s enterprise data and analytics architecture, providing thought leadership and architecture services for all aspects of data and analytics, including data platforms, data services, advanced analytics, reporting, data visualizations, master data management, knowledge engineering, data acquisition and integration. \n  Initiate and oversee strategic efforts to identify, develop and host data and information services that reach across domains, support reuse of internal and external data, and build trust in data and analytical information, improving data access and usability to accelerate scientific and business insights. \n  Lead a team of data and analytics architects, Data Science and Visualization, responsible for research, analysis, design, and delivery of data and solution architectures to support business strategies and priorities across all CHC business functions. \n  Understand emerging industry and innovative technology trends to effectively prioritize and practically apply existing, new, and emerging technologies to harness insights and value from CHC\u2019s internal and external data. \n  Develop and promote modern architectural approaches that encourage data and value exchange with partners and customers, digitization of processes, business connectivity, and partner collaboration. \n  Perform an involved advisory role on large complex analytics initiatives. Provide leadership in building consensus on approach and provide technical execution oversight. Identify and mediate conflicting requirements among solution stakeholders. \n  Contributes to strategic efforts that support integration into other ecosystems through data while building trust in end-to-end use of data for decision sciences. \n  Lead and provide oversight on data, application, and technology lifecycles, from emerging technology assessments through to renewal or retirement. \n  Cultivate technical expertise and champion and enable learning, adoption, reskill and reuse across Digital. \n  Mentor, coach, guide and grow architecture team members and other Digital colleagues, creating a strong collaborative engaging cross functional team culture. \n  Partner with internal teams regarding innovation, technologies, governance, lifecycle management (platforms), adoption and/or training/use. \n  Ensure that data is managed in compliance with applicable quality, regulatory (Data Privacy, GxP, SOX, etc.) and cybersecurity requirement \n \n  QUALIFICATIONS \n \n  10  years or more experience in Data Analytics and Architecture space \n  Experience of Data Architecture & Modeling, preferably in FMCG \n  Experience in IICS, Tibco, SAP BODS \n  Experience in Advance Analytics & Cloud solutions \n  Experience in Data Science, AI and ML \n  Experience in DevOps and Product Lifecycle \n  Agile ways of working and large projects phased delivery \n  Data & Business intelligence domain and software experience is a plus \n  Strong Experience of Interfacing heterogeneous systems and data sources \n  Strong Experience of Snowflake, DataBricks, Python/R, Tableau, Power BI \n  Strong Experience of Informatica, Layer 7 and Apigee \n  Working knowledge of procuring data from ERPs (SAP, JDE, etc.). \n  Working knowledge of Data governance and Security \n \n  Education \n \n  Bachelor's degree \n  Fluent in English \n \n  International Program Management Skills ",
        "techs": [
            "global digital team",
            "sap s4/ hana",
            "jdedwards",
            "oep",
            "unity",
            "iics",
            "tibco",
            "sap bods",
            "advance analytics & cloud solutions",
            "data science",
            "ai",
            "ml",
            "devops",
            "product lifecycle",
            "snowflake",
            "databricks",
            "python/r",
            "tableau",
            "power bi",
            "informatica",
            "layer 7",
            "apigee",
            "erps (sap",
            "jde)",
            "data governance",
            "security"
        ],
        "cleaned_techs": [
            "global digital team",
            "sap s4/ hana",
            "jdedwards",
            "oep",
            "unity",
            "iics",
            "tibco",
            "sap bods",
            "advance analytics & cloud solutions",
            "data science",
            "ai",
            "ml",
            "devops",
            "snowflake",
            "databricks",
            "python",
            "tableau",
            "powerbi",
            "informatica",
            "layer 7",
            "apigee",
            "erps (sap",
            "jde)",
            "data governance"
        ]
    },
    "215831ed4fe45ab2": {
        "terms": [
            "data science"
        ],
        "salary_min": 118392.11,
        "salary_max": 149910.8,
        "title": "Sr Generative AI Lab Author",
        "company": "Pluralsight",
        "desc": "Job Description:\n  \n \n   Join Pluralsight on our mission to advance the world's technology workforce and bring high-quality, hands-on instruction to thousands of technologists across the globe! Pluralsight is currently hiring a Sr Generative AI Lab Author to work full-time creating hands-on lab content to grow our Generative AI content offering.\n  \n \n \n   Role Requirements\n  \n \n   Pluralsight authors are a unique breed of technical professionals, combining years of in-the-trenches practitioner experience with outstanding teaching skills. As a Sr Generative AI Lab Author you will be accountable for:\n  \n \n \n \n     Authoring hands-on content in accordance with the Pluralsight Generative AI Domain content strategy\n    \n \n \n     Developing educational content of the highest quality to be published on the Pluralsight platform, including\n    \n \n \n \n       Engineering content and capabilities in support of hands-on learning\n      \n \n \n       Automating robust hands-on environments to create rich, interactive experiences\n      \n \n \n \n \n   Pluralsight authors must embrace the mindset of a \u201clifelong learner\u201d and be capable of learning new techniques, processes, and technologies through continuous and rigorous research and self-directed study. This is nowhere as important as in the field of Generative AI given the rate of change. It is expected that the research performed will be presented in the content you create.\n  \n \n \n   Pluralsight authors are also expected to:\n  \n \n \n \n     Work autonomously in a self-directed fashion\n    \n \n \n     Maintain a steady publication rate while also performing maintenance on previously published content\n    \n \n \n     Develop a technical specialty in one or more vendors within the GenAI space, such as OpenAI or Anthropic\n    \n \n \n     Take an active role in author mentoring programs\n    \n \n \n     Contribute to Pluralsight\u2019s commitment to the tech community with open source content and capabilities\n    \n \n \n     This role is specifically for hands-on content, so no presentation skills are required\n    \n \n \n \n   As a Sr Generative AI Lab Author it is expected you will meet the following requirements:\n  \n \n \n \n     3+ years of practitioner-level technical experience, ideally in artificial intelligence, machine learning, data science, or software development\n    \n \n \n     Previous experience as an author, content creator, instructor, and/or trainer with deep experience creating hands-on labs\n    \n \n \n \n  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. \n \n \n \n   #LI-EB1\n    #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ea7d46f5511243b8": {
        "terms": [
            "data science"
        ],
        "salary_min": 155840.94,
        "salary_max": 197329.34,
        "title": "Vice President of Data",
        "company": "Worth AI",
        "desc": "Worth AI, a trailblazing computer software company, is seeking a dynamic and experienced individual to join our team as the Vice President of Data. As the Vice President of Data, you will play a pivotal role in advancing our mission to revolutionize the way businesses make decisions leveraging the power of AI. \n  Our Vice President of Data will have distinct expertise in credit modeling and experience collaborating with third-party data providers. This role requires a dynamic leader to drive our data strategy, combining innovative risk solutions with top-tier data science, machine learning, and AI methodologies. \n \n  Responsibilities \n \n Leadership:  Direct and oversee the data team, defining a compelling vision and ensuring alignment with the company's overarching strategic goals. \n Risk, Fraud, and Credit Model Development:  Utilize data science, machine learning, and AI techniques to design, test, and deploy advanced risk, fraud, and credit scoring models. \n Third-Party Data Collaboration:  Establish and maintain relationships with third-party data providers to enhance our data capabilities and derive insights. \n Strategy:  Collaborate with executive leadership to shape and execute data and technology strategies, focusing on improving risk and credit assessment capabilities. \n Partner with Enterprise Clients:  Engage with enterprise clients to discern their risk and credit challenges, tailoring our technology solutions accordingly. \n Innovation:  Remain updated on cutting-edge trends in risk technology, credit modeling, data science, machine learning, and AI. \n Data Management and Governance:  Ensure data integrity, security, and the ethical use of both internal and external data resources. \n Cross-Functional Collaboration:  Partner with diverse teams, including engineering, product, sales, and customer support, ensuring the seamless delivery of data initiatives. \n \n Requirements \n \n Education:  Master\u2019s or Ph.D. degree in Data Science, Computer Science, Statistics, or a related discipline. \n Experience:  Minimum of 10 years in the technology sector, with a solid track record in senior data roles. At least 5 years' experience in risk technology with enterprise clients, emphasizing credit modeling. \n Technical Skills:  Profound expertise in data science, machine learning, AI, and credit modeling methodologies. \n Leadership:  Proven leadership qualities, including team management, vision setting, strategy formation, and tactical execution. \n Communication:  Outstanding communication abilities, adept at translating intricate technical concepts to a diverse audience. \n Analytical Skills:  Robust analytical and problem-solving skills, focusing on achieving tangible results. \n \n Benefits \n \n Health Care Plan (Medical, Dental & Vision) \n Retirement Plan (401k, IRA) \n Life Insurance  \n Unlimited Vacation \n Family Leave  \n Work From Home \n Free Food & Snacks \n Wellness Resources",
        "cleaned_desc": " Risk, Fraud, and Credit Model Development:  Utilize data science, machine learning, and AI techniques to design, test, and deploy advanced risk, fraud, and credit scoring models. \n Third-Party Data Collaboration:  Establish and maintain relationships with third-party data providers to enhance our data capabilities and derive insights. \n Strategy:  Collaborate with executive leadership to shape and execute data and technology strategies, focusing on improving risk and credit assessment capabilities. \n Partner with Enterprise Clients:  Engage with enterprise clients to discern their risk and credit challenges, tailoring our technology solutions accordingly. \n Innovation:  Remain updated on cutting-edge trends in risk technology, credit modeling, data science, machine learning, and AI. \n Data Management and Governance:  Ensure data integrity, security, and the ethical use of both internal and external data resources. ",
        "techs": [
            "data science",
            "machine learning",
            "ai",
            "third-party data providers",
            "data capabilities",
            "risk technology",
            "credit modeling",
            "data management",
            "data governance"
        ],
        "cleaned_techs": [
            "data science",
            "ai",
            "third-party data providers",
            "data capabilities",
            "risk technology",
            "credit modeling",
            "data management",
            "data governance"
        ]
    },
    "a375ca101ed03743": {
        "terms": [
            "data science"
        ],
        "salary_min": 137869.6,
        "salary_max": 174573.62,
        "title": "Principal Data Scientist",
        "company": "Kellanova",
        "desc": "As our Principal Data Scientist your main mission is to use the scientific method, math and statistics, specialized programming, advanced analytics, AI, and storytelling to uncover and explain the business insights buried in data. This will be accomplished by using data mining techniques, including pattern detection, graph analysis or statistical analysis \u2013 extracting knowledge from a dataset involving data management, data preprocessing, model and post-processing of found structure. As our principal data scientist, you are well versed in a wide array of analytical tools including artificial intelligence, machine learning, data mining, Bayesian regression, econometrics, and is aware of new and emerging methodologies. With your expertise, you will communicate, educate, and elevate the skills of the organization. \n \n  Join our dynamic, progressive team of IT professionals in an environment where you can learn, grow, and be an integral part of creating innovative technology solutions to help our business flourish. As a part of Kellanova, you are joining a leading company in global snacking, international cereal and noodles, plant-based foods and North American frozen breakfast, with iconic, world-class brands. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, ideas, and can bring their authentic selves to work. Become part of a team that works to better serve the needs of our diverse consumers by delivering winning ideas and innovations for brands like Cheez-Its, Pringles and Eggo. \n \n  A Taste of What You\u2019ll Be Doing \n Direct Business Partnering - In this role, you will be working with multiple levels of the business and leadership to better enable analytics and data across the supply chain organization in multiple regions. By leveraging your experience, leadership skills, positive attitude as well as your understanding for cross-functional relationships you will help deliver practical analytical and data solutions within in a global environment. Lead the design, development, and deployment of data-driven predictive models to solve business problems using the most appropriate techniques in data mining, artificial intelligence/machine learning, and statistical modeling. \n Data Analysis Leadership - Diving into large, noisy, and complex real-world data to produce an innovative analysis of historical patterns in customer behaviors and product performance. Working closely with data warehouse architects and software developers to generate seamless business intelligence solutions for business partners. Piloting emerging \u201cbig data\u201d technologies to help Kellanova understand how to exploit new methodologies, technologies, and tools. Driving toward deep visibility of the business, end-to-end through analytics and fact-based data disciplines. Advocating for and train the organization during deployment of analytic solutions. Establishing relationships with various data stakeholders and working with leadership to develop strategies for advanced analytics at Kellanova. In this role, you will be advising Executives on how data and predictive models (processes, practices, and technologies) playing a critical role in improving business management and optimization. \n Decision Support \u2013 Understanding and identifying what data is available and relevant, including internal and external data sources, leveraging new data collection processes. Working with supply chain subject matter experts to select the relevant sources of information. Evaluating the data sources on multiple criteria including cost. Working with, and advising, appropriate IT members to translate analytic prototypes into production. This role has one or more direct reports. \n \n  Your Recipe for Success \n Masters Degree or Ph.D. in Computer Science, Mathematics, Statistics, Actuarial Science, Engineering, Operations Research or related field and/or specialized training/certification and/or equivalent work experience. \n We are looking for a leader with significant experience leading direct reports. \n Do you have extensive related technical/business experience including experience in designing and developing data management processes and systems? This role is perfect for you! \n Do you have demonstrated experience and advanced skills in data analysis, modeling, data mining, and artificial intelligence/machine learning? Great, we\u2019d love to put them to good use! \n Like working with technology? We need strong experience with analytical software and technology (such as Python, R, SAS, Databricks, Sagemaker, Tableau etc.) \n Strong ability to communicate with Supply Chain Executives to translate complex ideas and technical subjects into digestible messages with the proven ability to influence a variety of business partners. \n Effectively lead and collaborate with people within a project team. \n Do you have relevant Supply Chain, Manufacturing or CPG experience? Great, we\u2019d love to put it to good use in IT. \n \n  What\u2019s Next \n After you apply, your application will be reviewed by a real recruiter \u2013 not a bot. This means it could take us a little while to get back with you so watch your inbox for updates. In the meantime, visit our How We Hire page to get insights into our hiring process and how to best prepare for a Kellanova interview. \n \n  If we can help you with a reasonable accommodation throughout the application or hiring process, please email USA.Recruitment@Kellanova.com . \n \n  About Kellanova \n Kellanova is a leading company in global snacking, international cereal and noodles, plant-based foods, and North America frozen breakfast, and a portfolio of iconic, world-class brands, including Pringles, Cheez-It, Pop-Tarts, Kellogg\u2019s Rice Krispies Treats, MorningStar Farms, Incogmeato, Gardenburger, Nutri-Grain, RXBAR, and Eggo. We also steward a suite of beloved international cereal brands, including Kellogg\u2019s, Frosties, Zucaritas, Special K, Krave, Miel Pops, Coco Pops, and Crunchy Nut, among others. \n \n  At Kellanova, we are committed to Equity, Diversity, and Inclusion (ED&I), uplifting each other and embracing our differences to achieve our common goals. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, ideas, and can bring their authentic selves to work. Learn more here . \n \n  We\u2019re proud to offer industry competitive Total Health benefits (Physical, Financial, Emotional, and Social) that vary depending on region and type of role. Be sure to ask your recruiter for more information! \n \n  The Finer Print \n Kellanova is an Equal Opportunity Employer that strives to provide an inclusive work environment, a seat for everyone at the table, and embraces the diverse talent of its people. All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, disability, religion, national origin, gender, gender identity, gender expression, marital status, sexual orientation, age, protected veteran status, or any other characteristic protected by law. For more information regarding our efforts to advance Equity, Diversity & Inclusion, please visit our website here . \n \n  Ready to Taste the Future of Food? \n \n \n Kellanova Recruitment",
        "cleaned_desc": "As our Principal Data Scientist your main mission is to use the scientific method, math and statistics, specialized programming, advanced analytics, AI, and storytelling to uncover and explain the business insights buried in data. This will be accomplished by using data mining techniques, including pattern detection, graph analysis or statistical analysis \u2013 extracting knowledge from a dataset involving data management, data preprocessing, model and post-processing of found structure. As our principal data scientist, you are well versed in a wide array of analytical tools including artificial intelligence, machine learning, data mining, Bayesian regression, econometrics, and is aware of new and emerging methodologies. With your expertise, you will communicate, educate, and elevate the skills of the organization. \n \n  Join our dynamic, progressive team of IT professionals in an environment where you can learn, grow, and be an integral part of creating innovative technology solutions to help our business flourish. As a part of Kellanova, you are joining a leading company in global snacking, international cereal and noodles, plant-based foods and North American frozen breakfast, with iconic, world-class brands. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, ideas, and can bring their authentic selves to work. Become part of a team that works to better serve the needs of our diverse consumers by delivering winning ideas and innovations for brands like Cheez-Its, Pringles and Eggo. \n \n  A Taste of What You\u2019ll Be Doing \n Direct Business Partnering - In this role, you will be working with multiple levels of the business and leadership to better enable analytics and data across the supply chain organization in multiple regions. By leveraging your experience, leadership skills, positive attitude as well as your understanding for cross-functional relationships you will help deliver practical analytical and data solutions within in a global environment. Lead the design, development, and deployment of data-driven predictive models to solve business problems using the most appropriate techniques in data mining, artificial intelligence/machine learning, and statistical modeling. \n Data Analysis Leadership - Diving into large, noisy, and complex real-world data to produce an innovative analysis of historical patterns in customer behaviors and product performance. Working closely with data warehouse architects and software developers to generate seamless business intelligence solutions for business partners. Piloting emerging \u201cbig data\u201d technologies to help Kellanova understand how to exploit new methodologies, technologies, and tools. Driving toward deep visibility of the business, end-to-end through analytics and fact-based data disciplines. Advocating for and train the organization during deployment of analytic solutions. Establishing relationships with various data stakeholders and working with leadership to develop strategies for advanced analytics at Kellanova. In this role, you will be advising Executives on how data and predictive models (processes, practices, and technologies) playing a critical role in improving business management and optimization.   Decision Support \u2013 Understanding and identifying what data is available and relevant, including internal and external data sources, leveraging new data collection processes. Working with supply chain subject matter experts to select the relevant sources of information. Evaluating the data sources on multiple criteria including cost. Working with, and advising, appropriate IT members to translate analytic prototypes into production. This role has one or more direct reports. \n \n  Your Recipe for Success \n Masters Degree or Ph.D. in Computer Science, Mathematics, Statistics, Actuarial Science, Engineering, Operations Research or related field and/or specialized training/certification and/or equivalent work experience. \n We are looking for a leader with significant experience leading direct reports. \n Do you have extensive related technical/business experience including experience in designing and developing data management processes and systems? This role is perfect for you! \n Do you have demonstrated experience and advanced skills in data analysis, modeling, data mining, and artificial intelligence/machine learning? Great, we\u2019d love to put them to good use! ",
        "techs": [
            "scientific method",
            "math",
            "statistics",
            "specialized programming",
            "advanced analytics",
            "ai",
            "storytelling",
            "data mining techniques",
            "pattern detection",
            "graph analysis",
            "statistical analysis",
            "data management",
            "data preprocessing",
            "model",
            "post-processing",
            "artificial intelligence",
            "machine learning",
            "bayesian regression",
            "econometrics",
            "analytical tools",
            "ed&i",
            "analytics",
            "data-driven predictive models",
            "data analysis",
            "historical patterns",
            "customer behaviors",
            "product performance",
            "data warehouse architects",
            "software developers",
            "big data technologies",
            "visibility of the business",
            "end-to-end analytics",
            "fact-based data disciplines",
            "data stakeholders",
            "strategies for advanced analytics",
            "decision support",
            "data collection processes",
            "it members",
            "computer science",
            "mathematics",
            "statistics",
            "actuarial science",
            "engineering",
            "operations research",
            "training/certification",
            "work experience",
            "leader",
            "designing",
            "developing data management processes and systems",
            "data analysis",
            "modeling",
            "data mining",
            "artificial intelligence/machine learning."
        ],
        "cleaned_techs": [
            "scientific method",
            "math",
            "statistics",
            "specialized programming",
            "advanced analytics",
            "ai",
            "storytelling",
            "data mining techniques",
            "pattern detection",
            "graph analysis",
            "statistical analysis",
            "data management",
            "data preprocessing",
            "model",
            "post-processing",
            "bayesian regression",
            "econometrics",
            "ed&i",
            "data-driven predictive models",
            "historical patterns",
            "customer behaviors",
            "product performance",
            "data warehouse architects",
            "software developers",
            "big data technologies",
            "visibility of the business",
            "end-to-end analytics",
            "fact-based data disciplines",
            "data stakeholders",
            "strategies for advanced analytics",
            "decision support",
            "data collection processes",
            "it members",
            "computer science",
            "mathematics",
            "actuarial science",
            "engineering",
            "operations research",
            "training/certification",
            "work experience",
            "leader",
            "designing",
            "developing data management processes and systems",
            "modeling",
            "data mining"
        ]
    },
    "cc93b4424539f6ca": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 75671.695,
        "salary_max": 95817.23,
        "title": "Senior Marketing Data Analyst",
        "company": "VisionPoint Marketing",
        "desc": "Are you a proactive analyst with a passion for data and marketing? Do you have the skills to provide insights across various channels and campaigns, including industry insights and case studies? We're on the lookout for a highly skilled and experienced Senior Marketing Data Analyst to elevate our clients' marketing success. \n  Your role is all about data empowerment. You'll bridge the gap between marketing and channel strategists (think digital marketing, SEO, CRM, web, and more) to enhance data fluency and fuel better execution and improved campaign performance. Working closely with cross-functional VisionPointers and our valued client partners, you'll help us not just meet but exceed client expectations and goals. \n  This is a full-time position with the flexibility to work remotely, and you'll report directly to our Director of Digital Experience and Analytics. If you're ready to make a significant impact and thrive in a dynamic environment, we want to hear from you. Join us and be the driving force behind data-driven marketing success. \n \n  WHAT YOU'LL DO \n \n  Lead Data-Driven Advancements:  Drive our company's progression toward cutting-edge digital experiences for our clients, guided by the wealth of insights within our and our client\u2019s data. Contribute to the development and refinement of digital strategies by helping to deliver innovative solutions that deliver outstanding results and engagement. \n  Data Collection:  Ensure that data is gathered and consolidated from various sources, including websites, social media platforms, advertising platforms, and CRM systems. \n  Data Analysis:  Utilize data analysis techniques to extract meaningful insights, trends, and patterns related to marketing performance, such as website traffic, conversion rates, click-through rates to maximize return on investment (ROI) on channels like paid media, SEO and web. \n  Reporting:  Develop comprehensive reports and intuitive dashboards using TapClicks to present data-driven insights to internal and external stakeholders, facilitating informed decision-making. Customize dashboards to meet the unique needs of our client and make complex data insights accessible to non-technical stakeholders. \n  Service Auditing:  Conduct comprehensive audits of Google Analytics 4 and Google Tag Manager accounts for our clients. Identify areas for improvement, ensure data accuracy, and recommend modifications to enhance tracking and data collection, aligning with clients' specific needs and objectives. \n  Conversion Tracking for KPI Support:  Determine and set up conversion tracking mechanisms to support the measurement of Key Performance Indicators (KPIs). This includes configuring tracking for various conversion events to ensure a clear understanding of campaign success and aligning strategies with performance goals. \n  Conversion Funnel Analysis:  Analyze user journeys through the conversion funnel, identifying points of drop-off and areas for improvement in the customer acquisition process. \n  Technical Support:  Offer technical support to internal teams and clients using TapClicks, helping them understand and maximize the platform's capabilities. \n  Client Engagement:  In an agency setting, communicate with clients to present data findings, explain marketing strategies, and address questions and concerns. Act as a trusted advisor on data-driven marketing decisions. \n  Data Empowerment and Facilitate Collaboration:  Take the lead in educating our strategists to harness the full potential of data. Empower them with the knowledge and skills needed to enhance collaboration with our analytics teammates. Your role is instrumental in bridging the gap between marketing strategy and data insights, enabling a seamless and productive partnership between teams. \n  Continuous Learning:  Stay current with industry trends, emerging tools, and best practices in data analysis and marketing to drive innovation and excellence. \n \n  The ideal candidate for this position will also: \n \n  Assist in Customer Segmentation and Targeting:  Collaborate with our media team in the development of customer segmentation and targeting strategies. Leverage data insights to create effective customer personas and optimize targeting for more personalized and successful marketing campaigns. \n  Assist with A/B Testing:  Collaborate with our media team to design and execute A/B tests to evaluate the effectiveness of different marketing strategies, campaigns, and website variations, and provide recommendations for optimization. \n  Assist with SEO Enhancement:  Collaborate with the SEO team to Identify opportunities for optimizing organic search performance, enhance keyword targeting, and monitor on-page and off-page SEO elements for continuous improvement. \n \n \n  EXPERIENCE & EDUCATION \n \n  Bachelor's degree in Marketing, Data Science, Business, Statistics, or a related field, or equivalent experience. Master's degree is a plus. \n  3+ years of experience in marketing analytics or a similar role. \n  Proficiency in data analysis tools and software (e.g., Google Analytics, Excel, Tableau). \n  Proven experience in using and configuring TapClicks for data collection and reporting. \n  Strong knowledge of digital marketing strategies and channels, including SEO, SEM, social media, and email marketing. \n  Exceptional analytical and problem-solving skills, with the ability to derive actionable insights from complex datasets. \n  Excellent communication skills, including the ability to convey data-driven insights to both technical and non-technical stakeholders. \n  Self-starter with a real drive for impact and an entrepreneurial mindset \n  Solid grasp of data security and compliance requirements related to client data. \n  Robust technical database knowledge and experience applying SQL concepts \n  Collaborative mindset and the ability to work effectively within a team. \n  Agency experience is highly preferred, as is familiarity with the intricacies of working with clients in various industries. \n  Willingness to actively contribute to VisionPoint\u2019s culture and embody our values. \n \n  Don\u2019t quite meet all of our requirements? Apply anyways. Research shows that people from underrepresented identities are less likely to apply to a job if they don\u2019t match the posted requirements to a T. We at VisionPoint value diversity and want to continue creating a diverse, inclusive, and equitable environment. If this role and the prospect of serving the higher education sector excites you, but you are missing a few bullet points, we would still love to see your application. Even if this role isn\u2019t the right fit, there\u2019s a chance another role or a future opportunity could align with your experience. \n  COMPENSATION \n  Commensurate with experience. \n  WHAT WE ARE LIKE HERE AT VISIONPOINT \n  At VisionPoint, we believe that a strong culture is as much a valued benefit as health insurance, PTO and 401k. That\u2019s why it\u2019s important to us that future team members connect with \u2014 and contribute to \u2014 our culture. Our communication, collaboration, satisfaction and growth are largely dependent upon how we all, as individuals, embrace and live out our values. We have a laser focus on knowing, providing solutions for, and advancing higher education because of its transformative power in the world. We believe in the work we do, we support each other, we work hard, and we like to have a bit of fun, too. When it comes right down to it, happy and fulfilled team members produce better work, and better work is what drives us every day. \n   \n aKIsNNscxX",
        "cleaned_desc": "  Bachelor's degree in Marketing, Data Science, Business, Statistics, or a related field, or equivalent experience. Master's degree is a plus. \n  3+ years of experience in marketing analytics or a similar role. \n  Proficiency in data analysis tools and software (e.g., Google Analytics, Excel, Tableau). \n  Proven experience in using and configuring TapClicks for data collection and reporting. \n  Strong knowledge of digital marketing strategies and channels, including SEO, SEM, social media, and email marketing. \n  Exceptional analytical and problem-solving skills, with the ability to derive actionable insights from complex datasets. \n  Excellent communication skills, including the ability to convey data-driven insights to both technical and non-technical stakeholders. \n  Self-starter with a real drive for impact and an entrepreneurial mindset \n  Solid grasp of data security and compliance requirements related to client data. ",
        "techs": [
            "google analytics",
            "excel",
            "tableau",
            "tapclicks"
        ],
        "cleaned_techs": [
            "google analytics",
            "excel",
            "tableau",
            "tapclicks"
        ]
    },
    "66186198e26a4c86": {
        "terms": [
            "data science"
        ],
        "salary_min": 100.0,
        "salary_max": 100.0,
        "title": "Lead Data Scientist",
        "company": "BayOne",
        "desc": "Client :  Hathway \n \n \n Location :  Remote \n \n \n Rate :  $ 100 \n \n \n JD for Lead Data Scientist: \n  Hands-on experience in Building, training and deploying Client models \n \n  12+ years of experience with 8+ in Machine Learningd \n \n  Expertise in programming using Python \n \n  Expertise in Data Analysis using SQL \n \n  Experience in Client techniques like Clustering, Classification, Regression \n \n  Experience in working with Neural Networks \n \n  Work experience in at least one of Natural Language Processing/Computer Vision \n \n  Hands-on experience in working with frameworks like Tensorflow, PyTorch, SkLearn \n \n  Working knowledge of deploying Client models as REST APIs \n \n  Working knowledge of Docker/Kubernetes \n \n  Experience in working on Azure/AWS cloud \n \n  Knowledge of data processing using Spark is a bonus \n \n  Knowledge of data visualization using PowerBI/Looker/Tableau is a bonus",
        "cleaned_desc": "  12+ years of experience with 8+ in Machine Learningd \n \n  Expertise in programming using Python \n \n  Expertise in Data Analysis using SQL \n    Experience in Client techniques like Clustering, Classification, Regression \n \n  Experience in working with Neural Networks \n \n  Work experience in at least one of Natural Language Processing/Computer Vision \n ",
        "techs": [
            "python",
            "sql",
            "clustering",
            "classification",
            "regression",
            "neural networks",
            "natural language processing",
            "computer vision"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "clustering",
            "classification",
            "regression",
            "neural networks",
            "nlp",
            "computer vision"
        ]
    },
    "6547239d8871789d": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Product Owner, Software Commercialization (Senior Associate) -Capital One Software (Remote)",
        "company": "Capital One",
        "desc": "Locations: US Remote, United States of America\n   Product Owner, Software Commercialization (Senior Associate) -Capital One Software (Remote)\n  \n  Capital One Software is seeking an experienced, data-focused Product Owner to help improve our snowflake optimization product, Slingshot. The product team needs your help to deliver external SaaS solutions derived from our best-in-class, internally developed data management platforms. The role offers a deep dive into feature definition, value-adding capabilities, and managing product roadmap initiatives. Working at the intersection of technology and cloud data innovation, this individual will be responsible for leading engineering teams and closely collaborating with multiple internal and external platform groups. \n \n  The candidate we are looking for: \n \n  Is self-driven, actively looks for ways to contribute, and knows how to get things done. \n  Is a dynamic product owner who will rally the team and work in a highly collaborative environment. \n  Will be able to understand customer expectations; current gaps & technical constraints; drive requirements and ultimately partner with the line of business, partner, and cyber security teams. \n  Has a strong track-record of leading the delivery of high-quality tech products and services in an Agile development environment. \n  Practices Design Thinking and applies lean product and user driven design principles when developing and refining product features and capabilities. \n  Has great communication and reasoning skills, including the ability to make a strong case for technology choices. \n  Is passionate about learning and doesn\u2019t hesitate to take on new responsibilities. \n  Accepts change, wants to grow, and strives to evolve into a better member of the team. \n  Has a bias to action and a proven track record of delivering minimum viable products and business models to market at rapid speed \n  Demonstrates a high level of intellectual curiosity and comfort with ambiguity. \n \n \n  Responsibilities: \n \n  Manage planning and delivery of key strategic products, translating tech strategy through distribution of best-in-class product experiences and tech products. \n  Drive product objectives with business cases, product success metrics, design thinking, customer feedback, market research, marketing strategy and competitive analysis \n  Ground assumptions in human centered design with a natural empathy for customers and business teams \n  Craft stories, epics, and features for our customers, working with engineering teams to deliver value. \n  Collaborate with technology, operations, product teams, cyber security and business partners to coordinate and manage resources and activities maximizing impact and overall return on investment. \n  Interface with 3rd party vendors and contractors, where required, to deliver necessary pieces of our Tech product with time-to-market excellence. \n  Stay abreast of new technologies that are driving business process simplification across the industry and be the leader in driving that change by partnering and piloting across various business areas. \n \n \n  Basic Qualifications: \n \n  Bachelor\u2019s degree or military experience \n  At least 1 year of product management experience or at least 1 year of experience in product design, agile delivery, business analysis, data science, or software engineering \n \n  Preferred Qualifications: \n \n  Bachelor\u2019s degree in computer science or engineering \n  1+ years translating business strategy or analysis into consumer facing digital products \n  1+ years of experience working on core product platforms powering digital experiences \n  1+ years working with cross functional teams as a product owner in an agile development process \n \n \n  At this time, Capital One will not sponsor a new applicant for employment authorization for this position. \n \n  The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked. \n  Remote (Regardless of Location): $95,300 - $108,700 for Sr. Associate, Product Management\n  \n  Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate\u2019s offer letter. \n  This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.\n  \n \n \n \n \n  Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. \n \n \n \n \n  No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City\u2019s Fair Chance Act; Philadelphia\u2019s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\n  \n  If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. \n \n  For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com \n \n  Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site. \n \n  Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",
        "cleaned_desc": "Locations: US Remote, United States of America\n   Product Owner, Software Commercialization (Senior Associate) -Capital One Software (Remote)\n  \n  Capital One Software is seeking an experienced, data-focused Product Owner to help improve our snowflake optimization product, Slingshot. The product team needs your help to deliver external SaaS solutions derived from our best-in-class, internally developed data management platforms. The role offers a deep dive into feature definition, value-adding capabilities, and managing product roadmap initiatives. Working at the intersection of technology and cloud data innovation, this individual will be responsible for leading engineering teams and closely collaborating with multiple internal and external platform groups. \n \n  The candidate we are looking for: \n \n  Is self-driven, actively looks for ways to contribute, and knows how to get things done. \n  Is a dynamic product owner who will rally the team and work in a highly collaborative environment. \n  Will be able to understand customer expectations; current gaps & technical constraints; drive requirements and ultimately partner with the line of business, partner, and cyber security teams. \n  Has a strong track-record of leading the delivery of high-quality tech products and services in an Agile development environment. \n  Practices Design Thinking and applies lean product and user driven design principles when developing and refining product features and capabilities. \n  Has great communication and reasoning skills, including the ability to make a strong case for technology choices. ",
        "techs": [
            "snowflake optimization product",
            "slingshot",
            "saas",
            "internally developed data management platforms",
            "engineering teams",
            "technology",
            "cloud data innovation",
            "agile development environment",
            "design thinking",
            "lean product",
            "user driven design principles"
        ],
        "cleaned_techs": [
            "snowflake optimization product",
            "slingshot",
            "saas",
            "internally developed data management platforms",
            "engineering teams",
            "technology",
            "cloud data innovation",
            "agile development environment",
            "design thinking",
            "lean product",
            "user driven design principles"
        ]
    },
    "da22125f81f1e3fb": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 112742.61,
        "salary_max": 142757.27,
        "title": "Data Scientist IV / Site Reliability Engineer",
        "company": "Exodus Integrity Services",
        "desc": "Nashville, TN\n     \n \n \n \n \n \n \n \n Exodus Integrity Services, Inc is a rapidly expanding technology company headquartered in Northeast Ohio. EIS provides quality services to our clients by instilling honesty, commitment, and hard work to find the most qualified candidates to fill each opportunity. Currently, we are seeking individuals for an opportunity with our client in Nashville, TN. This is a very exciting opportunity working with one of the top employers in the area. If you are interested in joining a vibrant organization where you are valued and rewarded for your contributions, and you possess the qualifications listed below, please forward your resume and salary requirements. \n \n  Alternate Job Title/Job Family: Site Reliability Engineer \n \n  No 3rd parties. Candidate MUST be W2 employee of Exodus Integrity Services, Inc. \n \n  Prefer Nashville, TN based candidates. Role can be REMOTE. \n \n  7-10+ years of experience \n \n  Data Scientist IV \n \n \n Offers guidance to less experienced peers \n Provides inputs for the development of standardized offerings to facilitate the successful deployment and operational health of on-premises and cloud stacks \n Design and implement highly available and scalable systems, ensuring the reliability and performance on-premises and cloud applications \n Collaborate with cross-functional teams to define and establish service level objectives (SLOs) and service level agreements (SLAs) for critical systems \n Monitor systems and applications, proactively identifying and resolving any performance bottlenecks or availability issues \n Develop and maintain monitoring tools, alerts, and dashboards to provide visibility into system health and performance \n Conduct post-incident analyses to identify root causes and implement preventive measures to avoid future incidents \n Automate repetitive tasks and processes to improve efficiency and reduce manual intervention \n Create and maintain documentation for system architecture, configuration, and troubleshooting procedures \n Perform capacity planning and resource allocation to ensure optimal system performance and scalability \n Collaborate with development teams to implement and deploy new features and enhancements, ensuring they meet reliability and performance standards \n Develop strategy for reliability and availability of applications in both on-premises and cloud environments \n Leads collection of metrics and generation of relevant reporting mechanisms \n Drives continuous delivery and site reliability operations communities of practice \n Educate team to design and implement based on Site Reliability best practices \n Provides hands-on technical coaching to accelerate cloud learning across technical and application teams \n Stay up to date with industry best practices, new technologies, and emerging trends in site reliability engineering \n Perform other duties as assigned \n \n \n \n Exodus Integrity Services (EIS) is an equal opportunity employer. In accordance with anti-discrimination law, it is the purpose of this policy to effectuate these principles and mandates. EIS prohibits discrimination and harassment of any type and affords equal employment opportunities to employees and applicants without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. EIS conforms to the spirit as well as to the letter of all applicable laws and regulations.\u201d",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "56a03fb125265ace": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 199400.0,
        "salary_max": 318600.0,
        "title": "Sr Manager, Machine Learning Engineering",
        "company": "Zillow",
        "desc": "About the team  AI products at Zillow help millions of people find the best home for them with less stress and more visibility. Zillow scientists develop a variety of ML models that enable our customers to find and move to their next home. Join the team that develops the underlying platform powering AI research and development at Zillow!\n  \n  As a member of the AI Platform team, you will help define Zillow\u2019s approach to Artificial Intelligence research & products, powering products like home value estimation, economic research, semantic search and home recommendations etc. You will work on building powerful ML infrastructure enabling containerized services, performing distributed computations at scale, empowering continuous research & deployments of ML models, evaluations and monitoring.\n  \n  About the role \n  We are looking for a Senior Engineering Manager to help us build the next generation of AI infrastructure powering multiple Zillow products. \n \n  The position gives you opportunities to: \n \n  Lead a team of talented engineers in building scalable infrastructure for end to end machine learning lifecycle, from experimentation to production jobs & services. \n  Collaborate with platform teams (Data platform, Human in the loop platform, LLM platform) to establish a shared ecosystem of platforms for end users. \n  Work closely with product partner and customer AI teams to understand requirements, prioritize feature requests, scope and deliver platform solutions. \n  Collaborate with Principal engineers to design and implement solutions to achieve the technical vision. \n  Use a variety of OSS technologies (Kubernetes, Argo, KNative, Spark, Kafka, Pytorch) in the development process. \n \n  This role has been categorized as a Remote position. \u201cRemote\u201d employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.\n   In California, Colorado, Connecticut, Nevada, New York and Washington the standard base pay range for this role is $199,400.00 - $318,600.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York and Washington and may not be applicable to other locations.\n   In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.\n  \n  Who you are \n \n  A degree (BS+) in Computer Science or equivalent highly technical field. Masters in Computer Science preferred. \n  3+ years of management experience. \n  5+ years of software engineering experience, with Machine Learning products (preferred), data and or backend web services & infrastructure (K8s preferred). \n  2+ years of experience successfully building large-scale platform solutions for AI or data. \n  Have vision and passion to make Machine Learning development easier for Scientists. \n  Excellent interpersonal skills and a strong passion for collaboration across organizational boundaries. \n  Passionate about supporting the growth and development of people\u2019s careers. \n  Experience with at least one cloud environment (AWS, Microsoft Azure or Google Cloud). \n \n \n  Bonuses:  \n \n \n Experience developing or leading complex software systems scaling to millions of users with production quality deployment, monitoring and reliability. \n  Experience with Machine Learning Frameworks (e.g. PyTorch, Keras, Tensorflow, XGBoost \n  Experience with building low latency, high reliability Web Services (K8s, KNative services) \n  Experience with modern data technologies (Spark, Hive, Kafka, Beam, Airflow) \n  Proficiency in python \n \n \n  Get to know us \n  Zillow is reimagining real estate to make home a reality for more and more people. \n \n  As the most-visited real estate website in the United States, Zillow\u00ae and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people. \n \n  Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We\u2019re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don\u2019t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees\u2019 Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list. \n \n  Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com. \n \n  Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.",
        "cleaned_desc": " \n  A degree (BS+) in Computer Science or equivalent highly technical field. Masters in Computer Science preferred. \n  3+ years of management experience. \n  5+ years of software engineering experience, with Machine Learning products (preferred), data and or backend web services & infrastructure (K8s preferred). \n  2+ years of experience successfully building large-scale platform solutions for AI or data. \n  Have vision and passion to make Machine Learning development easier for Scientists. \n  Excellent interpersonal skills and a strong passion for collaboration across organizational boundaries. \n  Passionate about supporting the growth and development of people\u2019s careers. \n  Experience with at least one cloud environment (AWS, Microsoft Azure or Google Cloud). \n   \n  Bonuses:  \n \n \n Experience developing or leading complex software systems scaling to millions of users with production quality deployment, monitoring and reliability. \n  Experience with Machine Learning Frameworks (e.g. PyTorch, Keras, Tensorflow, XGBoost \n  Experience with building low latency, high reliability Web Services (K8s, KNative services) \n  Experience with modern data technologies (Spark, Hive, Kafka, Beam, Airflow) \n  Proficiency in python \n ",
        "techs": [
            "pytorch",
            "keras",
            "tensorflow",
            "xgboost",
            "k8s",
            "knative services",
            "spark",
            "hive",
            "kafka",
            "beam",
            "airflow"
        ],
        "cleaned_techs": [
            "pytorch",
            "keras",
            "tensorflow",
            "xgboost",
            "k8s",
            "knative services",
            "spark",
            "hive",
            "kafka",
            "beam",
            "airflow"
        ]
    },
    "8deb4a39477e2356": {
        "terms": [
            "data science"
        ],
        "salary_min": 70000.0,
        "salary_max": 75000.0,
        "title": "Strategic Marketing Manager",
        "company": "AnswerNet Tech solution",
        "desc": "Strategic Marketing Manager \n Work Hours:  9am - 6 pm EST Monday through Friday \n Pay Scale:  Salary $70,000 -$75,000 \n Reports to:  Marketing Director \n Job Type:  Full-time \n Company Overview \n AnswerNet is a full-service provider of inbound, outbound, automated, and business process outsourcing (BPO) contact center and AI services. Our network consists of physical and virtual contact centers across the U.S. Canada, offering the broadest selection of services and experience in the market. \n Position Overview \n We are looking for an experienced Marketing Manager to join our team. The perfect candidate should demonstrate leadership skills, a passion for the collaborative process, take initiative, be a self-starter, thrive under pressure, and love to adapt to ever-changing plans. In this role, you will be overseeing the company messaging and implementing effective branding strategies , c oordinating content anddesign ,  marketing campaigns, and full-funnel activities to drive traffic to our website. As the Marketing Manager you oversee and implement strategies with your team to increase lead generation, increase the amount of quality leads, and strengthen the market presence of the company. \n Responsibilities: \n \u00b7 Manage and coach a high-performing team of marketing coordinators and creative artists. \n \u00b7 Develop, and implement marketing strategies that meet business objectives and drive leads. \n \u00b7 Responsible for understanding and implementing our company messaging. \n \n Monitor key performance indicators (KPIs) to assess the effectiveness of digital marketing campaigns and initiatives. \n \n \u00b7 Work closely with the sales department to align sales and marketing strategies. \n \n Collaborate with the digital marketing team to identify opportunities for improving conversion rates on websites and landing pages. \n \n \u00b7 Identify competitors and evaluate their strategies and positioning and devise counterstrategies. \n \u00b7 Oversee the process to curate, create and publish engaging content through unique and thought-provoking posts to position the company as a thought leader. \n \u00b7 Organize conference, tradeshows, and major events and provide post-event reports and analysis. \n \u00b7 Manage conception, development, and implementation of marketing plans and strategy, product concepts, and promotional programs to drive customer interest and sales. \n \u00b7 Oversee marketing management team, training, workloads, schedules, and deadlines. \n \u00b7 Work with our team to ensure optimization of web content, paid search ads, and landing pages using data collected from SEO analysis and research. \n \n Coordinating with advertising and media experts to improve marketing results. \n Working with your team to brainstorm new and innovative growth strategies. \n \n Requirements and Qualifications: \n \n Bachelor's degree in marketing, statistics, data science, or a related field preferred or equivalent applicable experience. \n 3-5 years management experience. \n Call Center industry experience required. \n XX years of management experience \n Extensive knowledge and use of social media marketing tools to maintain and grow the company\u2019s brand. \n Strong analytical and problem-solving skills. \n \n \u00b7 Technical understanding of SEO. \n \n Experience with CRMs. \n Excellent communication skills. \n Strong organizational and leadership skills. \n \n \u00b7 Proficient in MS Office applications. Strong in Excel. \n Job Type: Full-time \n Pay: $70,000.00 - $75,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Marketing: 5 years (Required) \n Management: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Working with your team to brainstorm new and innovative growth strategies. \n \n Requirements and Qualifications: \n \n Bachelor's degree in marketing, statistics, data science, or a related field preferred or equivalent applicable experience. \n 3-5 years management experience. \n Call Center industry experience required. \n XX years of management experience \n Extensive knowledge and use of social media marketing tools to maintain and grow the company\u2019s brand. \n Strong analytical and problem-solving skills. \n \n \u00b7 Technical understanding of SEO. \n \n Experience with CRMs. ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "4c426057fb0c8731": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Population Health Senior Analyst",
        "company": "Boston Medical Center",
        "desc": "POSITION SUMMARY:\n  \n \n \n   Boston Medical Center Health System is an integrated health system devoted to the proposition that every person regardless of their social or economic circumstances deserves the best health care. Our mission is to provide Exceptional Care, Without Exception and our vision is to make Boston the healthiest urban population in the world.\n  \n \n \n   Our health system includes:\n  \n \n  Boston Medical Center, a 498-bed academic medical center and the leading safety-net hospital in New England \n  WellSense Health Plan, a nonprofit health insurance company serving more than 740,000 members across Massachusetts and New Hampshire through Medicare, Individual and Family, and Medicaid plans. \n  Boston HealthNet, a network of 15 community health centers throughout Boston \n  Boston Accountable Care Organization, a partnership between BMC and local CHC\u2019s created to coordinate delivery of care across our health network \n  Clearway Health, partners with hospitals and health systems to build or strengthen their own specialty pharmacy program, improve access to care, and provide personalized support to vulnerable patients, families, providers, and care managers to eliminate barriers and ensure medications are received on time. \n \n \n \n   Essential to the success of our health system is our ability to work with data to understand who our patients are, identify who needs special intervention, and target clinical programs that will drive better health outcomes for our patients.\n  \n \n \n   The System Analytics team sits at the center of our strategy, supporting the health system to accurately measure performance, understand key drivers, and identify new opportunities. This will include collaborating with clinical and operational leaders to design the right metrics and analyses, as well as developing insights that will inform critical decisions by senior leadership. Key projects may include: Identifying high risk patients who would benefit from care management intervention; producing reports to track performance against priority HEDIS measures; and predicting member medication adherence.\n  \n \n \n   The Population Health Senior Analyst will play a key role on this team, leading analyses that will guide strategy, investigate performance drivers, and shape the future of our health system. This role is ideal for analysts who have built a strong technical and analytic foundation, and who are looking to grow capabilities in strategic thinking, project management, stakeholder management, and presenting.\n  \n \n \n   Position: Population Health Senior Analyst\n  \n \n   Department: System Analytics\n  \n \n   Schedule: Full Time\n  \n \n \n   LOCATION\n  \n \n   Remote work arrangements within the U.S. will be considered for this position.\n  \n \n \n   ESSENTIAL RESPONSIBILITIES / DUTIES:\n  \n \n \n   KEY RESPONSIBILITIES:\n  \n \n  Work independently with business leaders to scope and conduct analyses that help the organization understand and monitor performance, break down key drivers, and identify new opportunities \n  Lead analytic projects such as vendor partnerships, development of predictive analytic tools, or data validation workstreams \n  Act as technical and analytic expert for the System Analytics team \n  Mentor, train, and onboard new analysts to the team \n  Create reports and dashboards that effectively communicate performance to operational and clinical leaders and stakeholders \n  Translate complex analysis into simple visualizations that can communicate key takeaways to leaders and stakeholders \n  Understand health system data sources and support data architecture team to ensure that data is clean, normalized, and accurate \n  Establish credibility and trust in data integrity and accuracy across internal and external stakeholders \n  Present analyses to senior leaders and other stakeholders \n  Collaborate across the health system to ensure that assumptions and methodologies are consistent \n  Manage multiple projects and analyses simultaneously while meeting key deadlines and deliverables, and prioritizing time and resources \n  Identify and elevate key obstacles for intervention that may jeopardize timelines \n \n \n \n   JOB REQUIREMENTS\n  \n \n \n   EDUCATION:\n  \n \n  Bachelor\u2019s degree, preference for concentration in economics, math, statistics, health informatics or data science \n  Master\u2019s degree in a related field, preferred \n \n \n \n   EXPERIENCE:\n  \n \n  5+ years of data analytics experience with progressive responsibility, working with large data sets to answer important clinical, operational, or business questions \n  3+ years of experience working with medical claims data in managed healthcare or insurance operations, with preference for analysis on Medicare or Medicaid risk products \n  3+ years of experience developing dashboards using Tableau \n  Ability to conduct advanced analytics using SAS and SQL; fluent in Excel \n  Ability to meet deadlines, multi-task, problem solve and use appropriate technology to analyze business problems. Project management skills a plus. \n  Strong communications skills, both verbal and written. \n  Experience with quality measures (e.g. HEDIS, CMS measures) preferred. \n  Experience with external grouping methodologies such as DRG, ETG and DxCG/CDPS in analytics preferred. \n \n \n \n   KNOWLEDGE/SKILLS:\n  \n \n   The Ideal Candidate:\n  \n \n   We are seeking a top performing senior analyst to help us build a high performing analytic team that will find answers to difficult questions across large and complex data sets.\n  \n \n \n   The ideal candidate will have the following skills:\n  \n \n  Technically proficient: Capable of manipulating large data sets, cleaning and normalizing data, generating analysis and working through challenges independently \n  Strong analytic thinking: Effective at identifying the critical question, capable of navigating the trade-off\u2019s between accuracy / comprehensiveness / complexity vs. speed and simplicity, able to make independent decisions on how to adjust assumptions and analyses, can distill complex analysis into simple charts to communicate key takeaways \n  Experienced in working with medical claims: Possesses a baseline understanding of the structure of raw claims billing data, and how to extract relevant clinical insights \n  Curious and creative: Capable of finding the right analytic approach, always asking questions and testing the data and analysis to ensure that we are answering the right key questions \n  Outcomes-focused: Ability to manage multiple high priority projects simultaneously and prioritize to meet key projects \n  Passionate about our mission: Highest level of integrity and respect for colleagues and for our mission to provide Exceptional Care Without Exception to our patients and members \n \n \n \n   Remote work arrangements within the U.S. will be considered for this position.",
        "cleaned_desc": " \n   JOB REQUIREMENTS\n  \n \n \n   EDUCATION:\n  \n \n  Bachelor\u2019s degree, preference for concentration in economics, math, statistics, health informatics or data science \n  Master\u2019s degree in a related field, preferred \n \n \n \n   EXPERIENCE:\n  \n \n  5+ years of data analytics experience with progressive responsibility, working with large data sets to answer important clinical, operational, or business questions \n  3+ years of experience working with medical claims data in managed healthcare or insurance operations, with preference for analysis on Medicare or Medicaid risk products \n  3+ years of experience developing dashboards using Tableau \n  Ability to conduct advanced analytics using SAS and SQL; fluent in Excel \n  Ability to meet deadlines, multi-task, problem solve and use appropriate technology to analyze business problems. Project management skills a plus. \n  Strong communications skills, both verbal and written. \n  Experience with quality measures (e.g. HEDIS, CMS measures) preferred. ",
        "techs": [
            "tableau",
            "sas",
            "sql",
            "excel"
        ],
        "cleaned_techs": [
            "tableau",
            "sas",
            "sql",
            "excel"
        ]
    },
    "50b20474c125bde0": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 115184.664,
        "salary_max": 145849.45,
        "title": "Data Scientist",
        "company": "Moneythink",
        "desc": "We are looking for an experienced, top-notch Data Scientist to help us improve the way we manage our large dataset of financial aid results and develop a predictive model using past data results. If you want to help create a clearer path to college graduation without the burden of debt, and the opportunity to help shape a more inclusive, equitable economy for all, then this is the team for you! Please visit our website to learn more about our work, our values, our vision, our partners, and philanthropic supporters.  \n Operating in a start-up marketing team dynamic, you will closely collaborate with our product and engineering teams to audit our existing data, make improvements to our data structure in line with our product goals, develop guide rails and test a predictive model. An attention to detail and eye for quality are critical to your success, along with an ability to communicate and document the process and improvements. This position reports to Moneythink\u2019s VP of Product. \n  Key Responsibilities \n  For this project, you will work with Moneythink on a part-time basis (approximately 40-80 hours/month) on two specific projects. High level, we will expect you to: \n \n \n Lead data science projects from ideation to completion, ensuring timely delivery and adherence to organizational objectives. \n Engage closely with business stakeholders to define and refine quantitative problems, translating business challenges into data-driven solutions. \n Design, implement, and refine machine learning products, transforming data insights into practical tools that drive value. \n Conduct thorough and reproducible experiments, maintaining the highest standards of data integrity and validity in all analyses. \n Continuously research, evaluate, and apply advanced data science algorithms and techniques to ensure cutting-edge solutions and optimal results. \n \n Specifically, we see this project happening in three phases: \n  Responsibility #1: Consultation and Project Evaluation \n \n Review product goals and provide input on scope and effort required  \n Analyze existing financial aid data, identifying strengths and weaknesses, and make recommendations to Moneythink for improvement in line with established product goals. \n \n Responsibility #2: Predictive Model Testing \n \n Develop a weighted set of parameters to predict future potential student financial aid offers at a select number of colleges \n Develop a weighted set of parameters to improve classification of aid items that currently aren\u2019t easily categorized \n Test both models and work with Moneythink\u2019s institutional knowledge to develop guide rails. \n Document success and challenges in these two models and work with the Product team to scope the next phase of development. \n \n Responsibility #3 Expanding Predictive Model \n \n Expand on the initial parameters affecting potential student financial aid offers \n Expand on the initial letter classification parameters to better account for a wider array of variables such as state or regional differences \n Collaborate with an AI engineer on integration testing of AI-powered services \n Develop a series of health and sanitation checks that can be automated to monitor the model accuracy over time. \n \n Requirements \n  Knowledge, Approach and Know-how: \n  Moneythink will be leaning on the Data Scientist\u2019s expertise and leadership ability to support this project. Our ideal candidate is someone who has: \n \n Ability to see data science projects through from conception to completion, ensuring alignment with business goals. \n Strong proficiency in statistical and probabilistic reasoning, able to derive insights and make informed decisions from complex data sets. \n Expertise in designing rigorous and reproducible experiments that uphold the highest standards of data integrity. \n In-depth knowledge of classical machine learning algorithms such as decision trees, regression models, and support vector machines. \n Familiarity with the latest deep learning techniques, architectures, and best practices for a range of applications. \n Solid grounding in calculus and linear algebra, ensuring a deep understanding of underlying data science methodologies. \n Proven track record in transforming data insights into actionable machine learning products. \n \n Desired Experience: \n  Our ideal candidate has at least  \n \n Bachelor\u2019s degree in Data Science, Computer Science, Statistics, or a related field \n 3+ years experience as a Data Scientist, or comparable background \n Deep fluency in Python/pandas for data manipulation, modeling, and visualization \n Strong SQL skills to query and manipulate data from data warehouses (RedShift, BigQuery)",
        "cleaned_desc": " Develop a series of health and sanitation checks that can be automated to monitor the model accuracy over time. \n \n Requirements \n  Knowledge, Approach and Know-how: \n  Moneythink will be leaning on the Data Scientist\u2019s expertise and leadership ability to support this project. Our ideal candidate is someone who has: \n \n Ability to see data science projects through from conception to completion, ensuring alignment with business goals. \n Strong proficiency in statistical and probabilistic reasoning, able to derive insights and make informed decisions from complex data sets. \n Expertise in designing rigorous and reproducible experiments that uphold the highest standards of data integrity. \n In-depth knowledge of classical machine learning algorithms such as decision trees, regression models, and support vector machines.   Familiarity with the latest deep learning techniques, architectures, and best practices for a range of applications. \n Solid grounding in calculus and linear algebra, ensuring a deep understanding of underlying data science methodologies. \n Proven track record in transforming data insights into actionable machine learning products. \n \n Desired Experience: \n  Our ideal candidate has at least  \n \n Bachelor\u2019s degree in Data Science, Computer Science, Statistics, or a related field \n 3+ years experience as a Data Scientist, or comparable background \n Deep fluency in Python/pandas for data manipulation, modeling, and visualization ",
        "techs": [
            "python",
            "pandas"
        ],
        "cleaned_techs": [
            "python",
            "pandas"
        ]
    },
    "357b06e61e624232": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 112309.37,
        "salary_max": 142208.69,
        "title": "Machine Learning Infra Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n ff2yARnFe4",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c617549f6ac61ae8": {
        "terms": [
            "data science"
        ],
        "salary_min": 96005.125,
        "salary_max": 121563.875,
        "title": "Project Manager, Operational Assets Optimization",
        "company": "Pine Gate Renewables",
        "desc": "Pine Gate Renewables is a leading renewable energy company focused on project development and strategic financing of solar and storage projects throughout the United States. The company's Pine Gate Impact initiative contributes to multiple non-profit organizations aimed at improving the environment and local communities. Headquartered in Asheville, NC, Pine Gate Renewables made the Inc. 5000 list in 2021, placing at #37 and named to Fast Company's Most Innovative Companies list in 2021. Pine Gate Renewables works every day to achieve its mission to \"Get Solar Done.\" For more information, visit pinegaterenewables.com. \n \n  At Pine Gate Renewables, our Operating Assets team plays a pivotal role in ensuring the optimal performance of each currently operational asset. With 99 operational assets boasting a total capacity of 3 GW spread across 32 states, this team is instrumental in maintaining profitable and sustainable assets. The team encompasses various roles, including asset management, operations, performance engineering, partnership and lender management, and operational compliance. \n  We are currently seeking a Project Manager, Operational Assets Optimization, specializing in solar generation and energy storage facilities, to join our dynamic renewable energy team. In this role, you will take charge of identifying and resolving underperformance issues within our operational assets. Your expertise will be invaluable in improving the performance and efficiency of our solar and storage projects. Collaborating with cross-functional teams, including OEM vendors, field service technicians, SCADA engineers, and others, you will play a key role in our mission to optimize renewable generation facilities. The ideal candidate possesses a passion for renewable energy and holds a strong background in performance engineering, operations and maintenance, and data analytics. \n  What You'll Do \n  Project Leadership and Management: \n \n Identify the most substantial performance improvement opportunities and collaborate with cross-functional teams to ensure the successful execution of optimization efforts. \n Formally manage optimization projects from inception to completion, including the rollout of developed solutions and retrofits. \n \n Troubleshooting and Performance Enhancement: \n \n Apply your expertise to identify potential PV system component failures, modeling issues, and site design problems causing underperformance. \n Investigate and resolve operational issues, working closely with OEM vendors, field service technicians, SCADA engineers, and other relevant parties. \n Review CMMS work orders and commissioning documentation to monitor various root causes for equipment underperformance and failure modes. \n \n Solution Development: \n \n Conduct research and troubleshooting activities to identify and resolve systemic problems or obsolete components. \n Collect and analyze data from various sources to identify performance trends, potential modeling issues, and anomalies. \n Collaborate with OEM vendors to strategize for long-term solutions and enhancements. \n Lead site-specific projects from conception to execution, focusing on optimizing performance and delivering measurable results in key metrics. \n \n Collaboration and Communication: \n \n Collaborate with asset managers, operations and maintenance providers, and other stakeholders to align performance goals and strategies. \n Communicate performance metrics, trends, and findings to senior management and other relevant stakeholders, enabling data-driven decision-making and facilitating the implementation of effective solutions for achieving tangible results. \n Act as a subject matter expert, providing guidance on performance optimization. \n \n Must-Haves \n \n Proven experience (5+ years) in performance optimization, analytics, and operations within the renewable energy industry. \n Strong knowledge of solar and storage systems and their performance characteristics. \n Experience in managing and leading cross-functional teams. \n Strong problem-solving skills and the ability to think strategically. \n Excellent communication and interpersonal skills, with the ability to present complex information to technical and non-technical stakeholders effectively. \n Self-motivated with the ability to work both independently and collaboratively on multiple projects simultaneously. \n \n Education and Certifications  \n \n Bachelor's degree in Engineering, Data Science, or a related field. \n \n Working Environment and Physical Demand \n \n Remote, with occasional travel to various solar sites (up to 30%). \n \n \n \n  Pine Gate Renewables believes in taking care of our employees by offering benefits that support their physical, mental, and financial well-being. Our comprehensive benefits package includes medical, dental, vision, matching 401k, Paid Time Off, paid holidays, training, and development, giving back to the community, remote work options, dog-friendly offices, and much more. Pine Gate Renewables is committed to diversity, equity, and inclusion in the workplace. \n  Pine Gate Renewables does not accept any unsolicited resumes or referrals from any third-party recruiting firms or agencies.",
        "cleaned_desc": " Act as a subject matter expert, providing guidance on performance optimization. \n \n Must-Haves \n \n Proven experience (5+ years) in performance optimization, analytics, and operations within the renewable energy industry. \n Strong knowledge of solar and storage systems and their performance characteristics. \n Experience in managing and leading cross-functional teams. \n Strong problem-solving skills and the ability to think strategically. \n Excellent communication and interpersonal skills, with the ability to present complex information to technical and non-technical stakeholders effectively. ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "1462b323206c50a4": {
        "terms": [
            "data science"
        ],
        "salary_min": 73100.0,
        "salary_max": 152400.0,
        "title": "Area Business Analyst, Commercial Operations (Remote)",
        "company": "Stryker",
        "desc": "Why supply chain at Stryker? \n  As a member of our Supply Chain team, you will make a daily impact on the lives of others. Apply today and you will get a chance to work with high-functioning, driven people who all have the same mission of making healthcare better. \n  We are proud to be named one of the World\u2019s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting  stryker.com \n  Who we want- \n \n  Data managers.  People who enjoy compiling, organizing and consolidating large volumes of data and reports. \n  Meticulous documenters.  Detail-oriented people who enjoy maintaining meticulous documentation of reports, metrics, proposals, and presentations. \n  Strategic thinkers.  People who enjoy analyzing data or trends for the purposes of planning, forecasting, advising, budgeting, reporting, or sales opportunities. \n  Collaborative partners.  People who build and leverage cross-functional relationships to bring together ideas, data and insights to drive continuous improvement in functions. \n  Dedicated achievers.  People who thrive in a fast-paced environment and will stop at nothing to ensure a project is complete and meets regulations and expectations. \n \n \n  What you will do-  \n \n The Area Business Analyst will use data as a tool to identify business problems for sustainable results and oversee new requests for inventory placements. You will build relationships with customers and maximize inventory assets to grow the business. You will partner with Field Offices to ensure customer service levels and satisfaction are met while meeting the overall objective to create a leaner and more profitable supply chain. Essential duties and responsibilities may include but are not limited to: \n \n  Provide data-driven insights to validate or refute requests for elevated par levels and replacement of expired items \n  Provide data to the Joint Replacement Sales and BOM teams on inventory placements and sales opportunities \n  Support inventory strategies that optimize customer accounts and fuel future growth \n  Collaborate closely with US Field Operations teams to determine optimal allocation strategies for standard instrument kits and new product launches \n  Analyze and schedule order management activities to align with forecasts, target inventories, and various supply chain operations \n  Generate suggestions and input that will allow the team to make better supply chain decisions \n  Assist Field Offices with researching availability of critical backordered items across different Field Office locations \n \n \n  What you need- \n \n  Bachelor\u2019s Degree required, Degree in Supply Chain Management, Business Administration, Sales, Marketing or Finance preferred. \n  4 years of experience with supply chain, warehouse or financial inventory control systems, processes, and product placement - required \n  Strong analytical / quantitative skills - required \n  Demonstrated technical / data science skills required (e.g. Excel, PowerPoint, Access, ERP, Tableau, SQL and Power BI) - required \n  Demonstrated ability to deliver on multiple competing priorities and work under time pressure - required \n \n \n  $73,100 - $152,400 salary plus bonus eligible + benefits. Actual minimum and maximum may vary based on location. Individual pay is based on skills, experience, and other relevant factors. \n \n  About Stryker \n  Our benefits:   \n \n 12 paid holidays annually   \n Health benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program.   \n Financial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&D insurance, and short-term disability insurance.   \n \n For a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits     About Stryker  Stryker is one of the world\u2019s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.     Know someone at Stryker?  Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page    Stryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "9fa042b3410270c2": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 98410.984,
        "salary_max": 124610.234,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "00b12d8e1fb44032": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 81459.32,
        "salary_max": 103145.65,
        "title": "Senior Business Analyst",
        "company": "Copper River Family of Companies",
        "desc": "Copper River Cyber Solutions is seeking a  Senior Business Analyst  to work under the Team lead's direction to conduct extensive research and monitoring of business processes, portfolio health, and to support high-level communications allowing for informed decision-making from the Defense Health Agency (DHA) Director of Staff (DOS). The candidate will serve as a member of the DOS Resource Management (RM) Team supporting the development, maintenance, coordination, analysis, and reporting of DOS RM-level operations and resources. \n   Essential Job Functions, but not limited to:  \n \n Work within a team of technical and analytical experts to provide detailed analysis that enables the discovery and recommendations towards solutions for the existing and future requirements, programs, and initiatives for DoS. \n Provide the team and the client with appropriate interfaces, tools, dashboards, writeups, and other artifacts that enable the most effective decision-making. \n Support the development of tools, dashboards, and other artifacts \n Possesses a working knowledge of DOD and federal government procurement practices. \n Provides support for contract and finance oversight and tracking. \n Maintains a keen awareness of financial and contract-enabling requirements and the status of planned actions. \n Consistently demonstrates effective and efficient time management practices. \n Effectively and persuasively communicate salient points with peers, teammates, and the client. \n Proactively identify ways to improve current processes \n Interpret business requirements and simplify them for easy analysis and decision-making. In addition to being highly responsive to changing business priorities. \n Drive the collation of information from relevant sources for analysis and reporting relevant data trends for informed decision-making for major positive business impact. \n \n \n \n  Clearance:  \n \n Public trust \n \n Education: \n \n Bachelor's degree in Data Science/Finance/Business with 3-5 years of experience \n \n Essential Job Requirements:  \n Education: \n \n Bachelor's degree in data science/Finance/Business with 3-5 years of experience \n \n Required Knowledge/Experience: \n \n Extensive data and risk analysis experience \n Must possess exceptional oral and written presentation skills to effectively communicate with small, medium, and large audiences comprised of all ranks/grades within and supporting the DoD in a virtual or in-person setting. \n Must be proficient in Microsoft Office suite (i.e., Outlook, Teams, Excel, PowerPoint, Word, SharePoint, etc.) \n \n \n \n \n \n About Copper River & The Native Village of Eyak: \n  Owned by the Native Village of Eyak (NVE), a federally recognized Alaska Native Tribe, the Copper River Family of Companies are a collection of entities that deliver a complementary set of solutions and services to support the diverse missions and requirements of our clients. Proud participants of the Small Business Administration's (SBA) 8(a) Business Development Program since 2006, our companies consist of both current and graduation SBA 8(a) entities. It is our collective purpose to support the Tribe and diversify the NVE's ability to facilitate economic advancement. \n  The income generated from our companies helps the Native Village of Eyak fund health and social services, economic development, natural resource/environmental education, jobs, job training, and other benefits to the NVE in a manner that is consistent with Alaskan Native cultural values and traditions. \n  Copper River's Culture \n  The Copper River Family of Companies has a positive, supportive, and thriving culture. At the foundation of our culture is a focus on collaboration. No matter your role or which operating company you work for, we are ONE TEAM working toward the same goals for our customers and for our collective owner- The Native Village of Eyak. How we treat each other is just as important as the work we deliver. \n  Benefits \n \n Comprehensive medical, dental, and vision coverage \n Flexible Spending Account - healthcare and dependent care \n Health Savings Account - high deductible medical plan \n Retirement 401(k) with employer match \n Open leave policy and paid holidays \n Additional benefits including tuition reimbursement, transportation expense account, employee assistance program, and more! \n \n Note : These benefits are only applicable to full time, regular associates at Copper River. \n \n \n  Disclaimer: \n  The Copper River Family of Companies provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6d9f6d3cf2545985": {
        "terms": [
            "data science"
        ],
        "salary_min": 147468.0,
        "salary_max": 200000.0,
        "title": "Associate Director \u2013 Economics, Justice, and Society Research (Chicago, DC area, or Remote)",
        "company": "NORC at the University of Chicago",
        "desc": "JOB DESCRIPTION: \n \n \n \n \n \n \n NORC at the University of Chicago, an objective and non-partisan research organization, seeks an Associate Director in the Economics, Justice, and Society Department. The Associate Director assists the Senior Vice President, Vice Presidents, and senior staff in a broad range of activities which include strategic planning; business and proposal development; client relations; project and contract administration and oversight; staffing assignments; financial management; professional development of staff; resource planning and recruiting/hiring; and corporate activities. This position will support the efforts of the Center on Public Safety and Justice located within the Economics, Justice, and Society Department. This position is responsible for managing and directing research projects, including providing substantive input and direction on the project, managing the activities of staff, and providing oversight to ensure high quality deliverables. \n  NORC recognizes that talented and skilled researchers live throughout the U.S. and actively supports remote work arrangements. Occasional trips to client sites or the office may be required. For those interested in hybrid work schedules, our main offices are Bethesda, MD, Chicago, IL, Cambridge, MA, and Atlanta, GA. \n \n \n \n \n \n \n \n DEPARTMENT: The Economics, Justice, and Society (EJS) Department \n \n \n \n The Economics, Justice, and Society (EJS) Department  focuses on a broad range of topics relating to critical economic, demographic, and social issues. We are home to many of NORC's largest and longest-running surveys including the General Social Survey, the Survey of Consumer Finance, and the National Longitudinal Surveys; we engage in policy analysis and evaluation research relating to social programs and issues; we focus on the economy and the labor force, retirement plans; transportation and traffic safety; crime and law enforcement, and energy and the environment. We work with a diverse set of clients and partners, including policy-makers and data users in federal, state, and local governments, academia, and the press. We are home to two Centers \u2013 the NORC Center on Public Safety and Justice and the Center for Behavioral Economic Analysis & Decision Making. \n  The NORC Center on Public Safety and Justice  integrates a multi-disciplinary team of subject matter experts and thought leaders with deep expertise in criminology, demography, economics, and public health, and NORC\u2019s industry-leading survey data collection capacity. NORC has long had an important presence in the crime and justice research community, with over 200 past projects in the field from a wide variety of funders. With rapid growth in the field of crime and justice research, the goal of the Center on Public Safety and Justice is to increase NORC\u2019s visibility and thought leadership, provide a mechanism to link distributed efforts in the space within NORC, and to position NORC as a leader in developing and disseminating rigorous, objective, and transparent research. \n \n \n \n \n \n \n \n RESPONSIBILITIES: \n \n \n \n Support the Senior Vice President and Vice Presidents in department operations and administration, including resource planning, department communications, project and contract administration and financial management. \n Play a key role in staff management, including recruiting/hiring and fostering an environment that promotes mentoring and professional growth of staff, helping to build a cohesive, team-oriented culture. \n Champion strategic initiatives for the EJS Department and support NORC-wide administrative initiatives. \n Support a cohesive, team-oriented culture across a geographically dispersed staff and promote communication and integration among all members. \n Collaborate with the EJS Senior Vice President, Vice Presidents, and the Director of the Center for Public Safety and Justice to implement and support a strategy to strengthen and grow the Center\u2019s portfolio of work for federal and non-federal clients. \n Lead/support business development efforts with the federal government, foundations, and other funders with particular emphasis on expanding the portfolio of work. \n Develop and maintain client relationships with the federal, non-profit, academic, and foundation sectors. \n Develop and maintain key partnerships with other research organizations and research leaders that will support and advance the success of the EJS Department and the Center for Public Safety and Justice. \n Further grow the EJS research team both through the development of current staff and the strategic recruitment of new professionals with additional capabilities. \n Serve as a senior leader within the EJS Department. \n Lead and direct EJS research projects focused on quantitative social sciences, survey methods, advanced analytic methods, new data sources and/or data science. \n \n \n \n \n \n \n REQUIRED SKILLS: \n \n \n \n Minimum of 13 years directly applicable work experience in a nonprofit organization, research organization or government agency is required with increasing levels of responsibility. \n A track record for developing, managing and retaining a team of highly capable research professionals. \n Expert knowledge in some key focal areas of the department such as socio-economic research, criminal justice, transportation, economics, or data analytics. \n Understanding of qualitative and quantitative methodologies as well as developments in data science. \n Expertise in managing large scale, complex research projects, or other similar accomplishments. \n Proven success managing research projects end-to-end, including providing overall guidance, ensuring execution and oversight of deliverables. \n Demonstrated experience presenting to governmental organizations, foundations, industry groups, or academia, publishing methodological and analytical research, or other relevant thought leadership activities. \n Travel between NORC offices and to meet with current and prospective clients will be required. \n Candidate will be Chicago, Washington DC/Bethesda MD-based, or remote \n \n The position requires an individual with vision, proven leadership skills, extensive management experience, and a deep understanding of social science research. While no one candidate will embody all of the traits noted below, the successful candidate will bring many of the following professional and personal qualities to these important roles: \n \n An organized individual who can create and manage systematic processes that will support a well-run department; \n An analytical thinker possessing the ability to understand, interpret, and process sophisticated qualitative and quantitative information; \n An individual who has the ability to work within and manage a team-oriented environment, consisting of a multidisciplinary and diverse group of professional staff; \n A willingness to invest considerable time and energy in getting to know the staff, affiliated researchers, and their work; \n A broker and facilitator who can work through multiple agendas, determining what is best for individual team members and the group as a whole; \n A leader and consensus builder who recognizes organizational and personal barriers in order to build bridges and design effective solutions; \n A mature individual who is driven and determined; and \n An energetic and performance-driven individual. \n \n \n \n \n \n \n SALARY AND BENEFITS: \n \n \n \n The pay range for this position is $147,468-$235,788. The budgeted range for this role is: $147,468-$200,000. \n \n \n This position is classified as regular. Regular staff are eligible for NORC\u2019s comprehensive benefits program. Benefits include, but are not limited to: \n \n \n \n \n Generously subsidized health insurance, effective on the first day of employment   \n Dental and vision insurance   \n A defined contribution retirement program, along with a separate voluntary 403(b) retirement program   \n Group life insurance, long-term and short-term disability insurance   \n Benefits that promote work/life balance, including generous paid time off, holidays; paid parental leave, tuition assistance, and an Employee Assistance Program (EAP).   \n \n \n \n \n NORC\u2019s Approach to Equity and Transparency \n \n \n Pay and benefits transparency helps to reduce wage gaps. As part of our commitment to pay equity and salary transparency, NORC includes a salary range for each job opening along with information about eligible benefit offerings. At NORC, we take a comprehensive approach to setting salary ranges and reviewing raises and promotions, which is overseen by a formal Salary Review Committee (SRC). \n \n \n \n \n \n \n \n WHAT WE DO: \n \n \n NORC at the University of Chicago is an objective, non-partisan research institution that delivers reliable data and rigorous analysis to guide critical programmatic, business, and policy decisions. Since 1941, our teams have conducted groundbreaking studies, created and applied innovative methods and tools, and advanced principles of scientific integrity and collaboration. Today, government, corporate, and nonprofit clients around the world partner with us to transform increasingly complex information into useful knowledge. \n \n \n \n \n \n \n WHO WE ARE: \n \n \n For over 80 years, NORC has evolved in many ways, moving the needle with research methods, technical applications and groundbreaking research findings. But our tradition of excellence, passion for innovation, and commitment to collegiality have remained constant components of who we are as a brand, and who each of us is as a member of the NORC team. With world-class benefits, a business casual environment, and an emphasis on continuous learning, NORC is a place where people join for the stellar research and analysis work for which we\u2019re known, and stay for the relationships they form with their colleagues who take pride in the impact their work is making on a global scale. \n \n \n \n \n \n \n EEO STATEMENT: \n \n \n NORC is an affirmative action, equal opportunity employer that values and actively seeks diversity in the workforce. NORC evaluates qualified applicants without regard to race, color, religion, sex, national origin, disability, status as a protected veteran, sexual orientation, gender identity, and other legally protected characteristics.",
        "cleaned_desc": " Minimum of 13 years directly applicable work experience in a nonprofit organization, research organization or government agency is required with increasing levels of responsibility. \n A track record for developing, managing and retaining a team of highly capable research professionals. \n Expert knowledge in some key focal areas of the department such as socio-economic research, criminal justice, transportation, economics, or data analytics. \n Understanding of qualitative and quantitative methodologies as well as developments in data science. \n Expertise in managing large scale, complex research projects, or other similar accomplishments. \n Proven success managing research projects end-to-end, including providing overall guidance, ensuring execution and oversight of deliverables. \n Demonstrated experience presenting to governmental organizations, foundations, industry groups, or academia, publishing methodological and analytical research, or other relevant thought leadership activities. \n Travel between NORC offices and to meet with current and prospective clients will be required. \n Candidate will be Chicago, Washington DC/Bethesda MD-based, or remote \n \n The position requires an individual with vision, proven leadership skills, extensive management experience, and a deep understanding of social science research. While no one candidate will embody all of the traits noted below, the successful candidate will bring many of the following professional and personal qualities to these important roles: \n \n An organized individual who can create and manage systematic processes that will support a well-run department; \n An analytical thinker possessing the ability to understand, interpret, and process sophisticated qualitative and quantitative information; \n An individual who has the ability to work within and manage a team-oriented environment, consisting of a multidisciplinary and diverse group of professional staff; \n A willingness to invest considerable time and energy in getting to know the staff, affiliated researchers, and their work; \n A broker and facilitator who can work through multiple agendas, determining what is best for individual team members and the group as a whole; \n A leader and consensus builder who recognizes organizational and personal barriers in order to build bridges and design effective solutions; \n A mature individual who is driven and determined; and \n An energetic and performance-driven individual. \n \n \n \n \n \n \n SALARY AND BENEFITS: ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "4679feaa67a76670": {
        "terms": [
            "data science"
        ],
        "salary_min": 40.0,
        "salary_max": 45.0,
        "title": "Senior Manager, Analytics",
        "company": "ITgen systems",
        "desc": "Position: Senior Manager, Analytics \n Duration: 3-5 months \n Location: Remote \n Job Description : \n 7-10 years of experience working in data science  and analytics capacity ( A/B testing, predictive modeling, statistical analysis) \n Strong prior experience in  Experimental Design & Testing and Predictive Modeling \n Experience working with  Python, SQL, JMP \n Relational database  experience \n Fluency in  MS Excel, PowerPoint \n Job Type: Contract \n Salary: $40.00 - $45.00 per hour \n Experience: \n \n Manager: 6 years (Required) \n Data science: 8 years (Required) \n Python: 5 years (Required) \n SQL: 5 years (Required) \n A/B testing: 5 years (Required) \n statistical analysis: 5 years (Required) \n Predictive Modeling: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " 7-10 years of experience working in data science  and analytics capacity ( A/B testing, predictive modeling, statistical analysis) \n Strong prior experience in  Experimental Design & Testing and Predictive Modeling \n Experience working with  Python, SQL, JMP \n Relational database  experience ",
        "techs": [
            "a/b testing",
            "predictive modeling",
            "statistical analysis",
            "experimental design & testing",
            "predictive modeling",
            "python",
            "sql",
            "jmp",
            "relational database experience"
        ],
        "cleaned_techs": [
            "a/b testing",
            "predictive modeling",
            "statistical analysis",
            "experimental design & testing",
            "python",
            "sql",
            "jmp",
            "relational database experience"
        ]
    },
    "f8f07dc123f526b8": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 96148.28,
        "salary_max": 121745.16,
        "title": "Software Developer (with AI Focus)",
        "company": "Quantum Workplace",
        "desc": "Make Work Better Every Day \n \n \n \n  Success starts with our people and our talent is our greatest level for business success. Quantum Workplace, an HR technology provider, equips workplaces with the smartest talent solutions so that they can grow and succeed. We pioneered some of the earliest employee engagement and performance software and have since partnered with thousands of organizations to drive employee, team, and business success.\n  \n \n \n \n   At Quantum Workplace, we embody hustle and grit, fueling an atmosphere where care and flexibility meets curiosity, making our own work environment as awesome as the ones we help create.\n  \n \n \n \n   Check out our 2023 Employee Engagement Survey Results (yes, we use our own software):\n  \n \n 98% response rate \n 81% overall favorability \n 98% favorable on the item \"I feel accepted by my immediate coworkers\" \n \n \n \n \n   See what it means to be a Qwirk through this video or our Employee Voice Profile!\n  \n \n \n  What\u2019s the opportunity? \n \n \n   Build AI-powered tools in HR Tech! At Quantum Workplace, we're on a mission to \u201cMake Work Better Everyday\u201d, and we want YOU to be a part of it. Solve real-world problems with ChatGPT/OpenAI and other machine learning models inside our Employee Success SaaS platform. This is your chance to make a positive impact on real people by crafting intelligent solutions and harnessing the power of AI to create mind-blowing user experiences. Dive deep into exciting challenges, work alongside top-tier developers, and see your code making a positive impact in the world. Come help us make work better everyday!\n  \n \n \n  You believe developers should be involved much earlier in the process than when it's time to code (although that is pretty fun). You\u2019d prefer to sit in on customer interviews, design sprints, early non-dev prototypes, and throw on some noise-cancelling headphones when it's time to build. You strive to build beautiful, usable software, and if you aren't the type to wear your beret hat you are encouraged to work with the product designer who is a full-time resource for your team.\n  \n \n \n \n   We use our own flavor of agile processes to get things done. We use Git and an automated CI setup for builds and Octopus for shipping code to testing environments and to production. We review each other\u2019s pull requests. We believe in automation over repetition and aim to make our code and infrastructure more scalable.\n  \n You Will: \n \n  Act as part of a cross-functional team, working with developers, designers, Quality Engineers and product owners to bring prototypes to production. \n  Support our software by fixing bugs, improving performance, and contributing to documentation. \n  Use some of the following: Azure ML Ops, .NET, C#, Python, SQL Server, Octopus, Azure Dev Ops, Redis, Hangfire, Azure, and probably a few more things. (Not required to know all) \n  Write awesome code, be you, and revel in work. \n  Perform other duties/projects as assigned. \n  See what it's like to be on our product development team! \n \n  You Have: \n \n  Experience with APIs, object-oriented programming, SQL databases, and web technologies (JavaScript, HTML, etc.) \n  3+ years of professional experience building software \n  Ability to work in the U.S. without sponsorship \n  Skills in communication and developing documentation. \n  Used independent judgment and discretion while requiring minimum supervision. \n  A high attention to detail and organization. \n  Experience troubleshooting and helping others. \n \n \n  Why Quantum Workplace? \n \n \n   At Quantum Workplace, we believe in making work better every day. We try to do this in meaningful and unique ways \u2014 check our Glassdoor rankings to read our reviews. Here are some of the ways we make work better every day. \n  \n \n \n \n We care for our Qwirks and their families \n \n \n  Health Insurance: We offer 3 options (1 option is 100% premium paid by QW for employees) + Telehealth \n  Dental & Vision: We cover 100% of premiums for employees \n  401k: We match 100% of contributions up to 4% and you're fully vested on day 1 \n  Adoption + Fertility assistance and paid parental leave \n \n \n \n \n  We seek to belong \n \n \n  Employee-led Diversity Council works to create a more diverse and inclusive workplace \n  Biennial company retreat to create connections and make memories  \n  No dress code - wear what makes you feel confident - BE YOU! \n \n \n \n \n  We invest in wellness and development \n \n \n  Annual professional and wellness development allowance \u2013 conferences, books, gym reimbursements, workout equipment, and more! \n  Our Omaha office has an on-site fitness center - free for Qwirk use \n  Monthly manager-employee lunches for goal planning and development \n  Zoo membership to your closest zoo \n  Remote work stipend for 100% remote Qwirks \n \n \n \n \n  We value balance \n \n \n  Summer hours and flexible work schedules \n  Remote and hybrid work options \n  Paid time off (up to 20 days per year!) plus paid holidays, paid volunteer time off, & your birthday \n \n \n \n \n   At Quantum Workplace, we are an equal-opportunity employer. We are committed to building an inclusive team that represents a variety of backgrounds and skills. Please apply, regardless if you think you meet all the requirements. We want to hear from you. Please note, we are not currently hiring in California.\n  \n \n \n \n   Applicants with disabilities may contact the Quantum Workplace Employee Success Team via telephone, e-mail, and other means to request and arrange for accommodations. If you need assistance to accommodate a disability, you may request an accommodation at any time. Please contact the Employee Success team at careers@quantumworkplace.com or 402-415-8302.\n  \n \n \n  We value diversity and are committed to providing equal employment opportunities to all qualified applicants. However, we are unable to provide employment sponsorships at this time. Applicants must be authorized to work for ANY employer in the U.S. without the need for sponsorship now or in the future. We understand that this may be disappointing news for some candidates, and we apologize for any inconvenience this may cause.\n  \n \n \n  Go back to our job listings page.\n  \n \n \n  #LI-remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ac831f3e8d962712": {
        "terms": [
            "data science"
        ],
        "salary_min": 132633.98,
        "salary_max": 167944.17,
        "title": "Cloud Data Architect",
        "company": "Zen Strategics LLC",
        "desc": "Description: \n   You\u2026 \n  As Cloud Data Architect, you will provide design and architecture help and lead a Data migration project to our government customer . You will work with varying huge data sources with different schemas and data elements to produce an effective and efficient Data Lake solution. You have an eye for spotting data correlations and a desire to dig into large datasets to find technical solutions and deliver business value. This is a hands-on position that requires both technical and client-facing skills to lead data pipeline design and implementation, integration with structured and semi-structured data sources, data lake design and implementation, integration of disparate data technologies and technical writing skills. Must be proactive and a motivated self-starter. \n  Program Mission\u2026 \n  The program you will be supporting has a mission to provide development, security, and operations (DevSecOps) support to U.S. Citizenship and Immigration Services (USCIS) with a focus on development, operations, and modernization of the Agency\u2019s Enterprise Data Warehouse/Data Lake. The team utilizes open-source, AWS Cloud, and Big Data technologies and modern DevSecOps delivery to meet the reporting, data analytics, and machine learning/artificial intelligence needs critical to USCIS leadership, data/business analysts, data scientists, and other decision-makers.  Requirements: \n   Responsibilities\u2026 \n \n Interact with designated product owners, system owners, and source system business owners to understand transactional system data models and elicit requirements and logic for ETLs \n Develop ETL workflows/data pipelines to ingest data using AWS Data Migration Service (DMS), Scala, Kafka, Restful APIs, and other technologies as determined by the client from multiple transactional systems to the target (including ODS, data marts, and data lake) according to documented logic and source-to-target mappings \n \n  Required Skills \n \n 5+ years of experience with ETL development ingesting data from diverse and huge data sources \n 5+ years of experience with programming languages such as Java, Scala, Python, R, JSON Schema \n Experience with AWS Database Migration Service (DMS), Databricks/Apache Spark, and/or Kafka experience \n 5+ years of experience producing and consuming Rest APIs. \n 5+ years of experience with relational databases /RDS. \n Demonstrated experience in a Data Warehouse/Data Lake \n Ability to write complex SQL queries and scripts \n Strong teamwork, co-ordination, planning and influencing skills \n Self-driven with the ability to adapt quickly, work in a challenging and fast paced environment within cross-functional teams, and to promote creative problem solving within their team \n Experience with Agile development practices, including Scrum and Kanban, and management tools (e.g., Jira, Confluence) \n Experience with GIT and branching strategies \n Experience with engineering/DevOps tools (i.e. Jenkins) \n Excellent analytical, communication and organizational skills \n Experience working in AWS Cloud environment \n Experience with Microsoft Office Suite including Excel, PowerPoint, and Visio \n \n  Desired Skills \n \n Experience supporting DHS Agencies. \n Providing IT security engineering for systems deployed in AWS and GCP in addition to Azure is a plus. \n Ability to demonstrate and explain technical concepts to both technical and non-technical audiences \n Able to clearly communicate with both customers and teammates and provide recommendations for improvements to existing software applications \n Experience working in an agile development environment \n \n  Education : Bachelor\u2019s degree in a technical discipline preferred \u2013 Computer Science, Mathematics, or equivalent technical degree, or the equivalent combination of education, professional training, and work experience. \n  Clearance : Must be a US Citizen and be able to obtain a government agency Suitability Clearance. USCIS Entry on Duty (EOD) preferred. \n  Zen Strategics is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.",
        "cleaned_desc": "Description: \n   You\u2026 \n  As Cloud Data Architect, you will provide design and architecture help and lead a Data migration project to our government customer . You will work with varying huge data sources with different schemas and data elements to produce an effective and efficient Data Lake solution. You have an eye for spotting data correlations and a desire to dig into large datasets to find technical solutions and deliver business value. This is a hands-on position that requires both technical and client-facing skills to lead data pipeline design and implementation, integration with structured and semi-structured data sources, data lake design and implementation, integration of disparate data technologies and technical writing skills. Must be proactive and a motivated self-starter. \n  Program Mission\u2026 \n  The program you will be supporting has a mission to provide development, security, and operations (DevSecOps) support to U.S. Citizenship and Immigration Services (USCIS) with a focus on development, operations, and modernization of the Agency\u2019s Enterprise Data Warehouse/Data Lake. The team utilizes open-source, AWS Cloud, and Big Data technologies and modern DevSecOps delivery to meet the reporting, data analytics, and machine learning/artificial intelligence needs critical to USCIS leadership, data/business analysts, data scientists, and other decision-makers.  Requirements: \n   Responsibilities\u2026 \n   Interact with designated product owners, system owners, and source system business owners to understand transactional system data models and elicit requirements and logic for ETLs \n Develop ETL workflows/data pipelines to ingest data using AWS Data Migration Service (DMS), Scala, Kafka, Restful APIs, and other technologies as determined by the client from multiple transactional systems to the target (including ODS, data marts, and data lake) according to documented logic and source-to-target mappings \n \n  Required Skills \n \n 5+ years of experience with ETL development ingesting data from diverse and huge data sources \n 5+ years of experience with programming languages such as Java, Scala, Python, R, JSON Schema   Experience with AWS Database Migration Service (DMS), Databricks/Apache Spark, and/or Kafka experience \n 5+ years of experience producing and consuming Rest APIs. \n 5+ years of experience with relational databases /RDS. \n Demonstrated experience in a Data Warehouse/Data Lake \n Ability to write complex SQL queries and scripts \n Strong teamwork, co-ordination, planning and influencing skills \n Self-driven with the ability to adapt quickly, work in a challenging and fast paced environment within cross-functional teams, and to promote creative problem solving within their team   Experience with Agile development practices, including Scrum and Kanban, and management tools (e.g., Jira, Confluence) \n Experience with GIT and branching strategies \n Experience with engineering/DevOps tools (i.e. Jenkins) \n Excellent analytical, communication and organizational skills \n Experience working in AWS Cloud environment \n Experience with Microsoft Office Suite including Excel, PowerPoint, and Visio \n    Desired Skills \n \n Experience supporting DHS Agencies. \n Providing IT security engineering for systems deployed in AWS and GCP in addition to Azure is a plus. \n Ability to demonstrate and explain technical concepts to both technical and non-technical audiences \n Able to clearly communicate with both customers and teammates and provide recommendations for improvements to existing software applications \n Experience working in an agile development environment ",
        "techs": [
            "aws data migration service (dms)",
            "scala",
            "kafka",
            "restful apis",
            "java",
            "python",
            "r",
            "json schema",
            "aws database migration service (dms)",
            "databricks/apache spark",
            "relational databases /rds",
            "data warehouse/data lake",
            "sql queries",
            "agile development practices",
            "scrum",
            "kanban",
            "jira",
            "confluence",
            "git",
            "jenkins",
            "aws cloud",
            "microsoft office suite",
            "excel",
            "powerpoint",
            "visio",
            "it security engineering",
            "gcp",
            "azure"
        ],
        "cleaned_techs": [
            "aws",
            "scala",
            "kafka",
            "restful apis",
            "java",
            "python",
            "r",
            "json schema",
            "databricks/apache spark",
            "relational databases /rds",
            "data warehouse/data lake",
            "agile development practices",
            "scrum",
            "kanban",
            "jira",
            "confluence",
            "git",
            "jenkins",
            "microsoft",
            "excel",
            "powerpoint",
            "visio",
            "gcp",
            "azure"
        ]
    },
    "f994e7ce195ba1a2": {
        "terms": [
            "data science"
        ],
        "salary_min": 135300.0,
        "salary_max": 194700.0,
        "title": "Senior Technical Product Manager",
        "company": "Hitachi Solutions Ltd",
        "desc": "Company Description \n \n \n Company Overview \n \n  Hitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering innovative cloud solutions to help our clients innovative across their entire business. Our firm develops the business services and technology powering some of the products you use every day - and is closely aligned with Microsoft and other leaders in the cloud computing space.\n  \n  What sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers. Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike - helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion. With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.\n  \n  A part of Hitachi Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world's largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\n  \n  This is a high-visibility, full-time role in our Empower Product Group for professionals with a proven history of execution, and a desire to rapidly expand a product organization.\n  \n \n Job Description \n \n \n Position Overview \n \n  This is a high-visibility, high-impact, full-time role in our Empower Product Group for professionals with a proven history of execution, and a desire to rapidly expand a product organization. Technical acumen and domain experience in data engineering, Azure, SaaS, and Data Analytics are strongly preferred.\n  \n \n Who you are: \n \n \n  Overall:  We would like to see candidates with 5+ years experience in Product. \n \n \n  Experienced . You have experience building solutions involving data or analytics in product management or similar roles. You have a strong background in enterprise software. \n  Customer and user focused.  You have the ability to put yourself in a users' shoes and understand their needs. You listen closely to all avenues of feedback. You love to be the voice of the customer. \n  Passionate . You love the intersection of building software, deeply understanding customer needs, bringing products to market, and data science technologies. You have strong product and design instincts that inspire confidence. \n  Leader . You inspire trust with team members and can drive change in a positive and productive way. You anticipate problems and mitigate risks. \n  Growth mindset . You enjoy learning new things and see challenges as growth opportunities. You excel at mastering technical products and being the go-to person in your domain. \n  Strong communicator . You are comfortable representing your team & product, presenting vision & priorities to internal stakeholders, customers, and partners. You enjoy speaking opportunities and have a proven experience presenting to large teams and leadership. \n  Data Enthusiast . You have a strong desire to help people see and understand data. \n  A Ruthless Prioritizer . You treat time as a team's most valuable asset. \n  Entrepreneurial . You solve problems for your customers while jumping on opportunities to strategically add new lines of business. \n  Technical Focus . You have experience with technical work, having been a developer yourself in a former role or by having deep experience with developers and learning technologies they use. \n \n \n  Qualifications \n \n \n Your responsibilities: \n \n \n  Execute. This means being constantly biased towards action, knowing the data, being in the details, setting a high bar and building strong collaborative relationships with other teams, thinking boldly, disambiguating, always thinking of the customer first, and rapidly iterating towards something demonstrably awesome. \n  Creates a culture of self-reflection and actively seeks out two-way feedback within their team and direct stakeholder group. \n  Participates in the interview process and applies a consistently high bar with well-articulated feedback. \n  Achieves proper balance between taking direct ownership for work versus creating leverage through effective vision setting and delegation. \n  Sets ambitious but realistic goals, and productively challenges others to do the same. \n  Re-frames problems in outcome-oriented terms and identifies creative solutions that optimize speed-to-value while setting up for long-term sustainability. \n  Regularly identifies, experiments with, and implements new practices and processes that improve team performance. \n  Autonomously leads cross-functional delivery for the broad business strategy they are accountable for and aligns around OKRs to achieve key business outcomes. \n  Regularly reflects on and revises priorities to ensure optimal overall value delivery. Creates focus for team(s) and sets boundaries with stakeholders as needed across cross-functional initiatives. \n  Leads definition of 12 - 15 month vision for one or more roadmaps with technical and non-technical stakeholders. \n  Demonstrates deep subject matter expertise in their product domain, acting as functional level lead for problem investigation and solution design. Understands adjacent product areas and associated business and technical integration dependencies and risks. \n  Uses objective decision making frameworks with well-defined criteria for deciding among a number of valid options, helping structure ambiguity and complexity into clear paths to decision making and forward progress. \n  Demonstrates subject matter expertise and thought leadership in their product and business domain, and advocates compellingly for their point of view. \n  Demonstrates sound, independent decision making in the areas of prioritization, trade-offs, upward/outward communication, expectation setting, etc. \n  Communicates effectively with stakeholders who may not be familiar with domain - can build frameworks to communicate complex ideas to unfamiliar audiences. \n  Proactively defines appropriate communication mechanisms, like reporting and status updates, for their domain and ensures follow-through. \n  Can lead and/or facilitate cross-functional interactions with varying audiences. Clearly defines purpose and objectives and drives towards them. \n  Builds influential relationships with senior partners and stakeholders (Directors, VPs) and can persuade cross-functional teams to accept required work to achieve desired goals. \n  Able to effectively influence across teams to create shared alignment for vision and goals, key requirements, overall prioritization, and timing. \n  Drives technical discussions with development teams, and able to communicate with developers to sanity check their designs. \n  Researches technologies constantly to stay up-to-date with the cutting edge to continuously improve the product in terms of speed and efficiency. \n \n \n  Technical Tooling: \n \n \n  Azure Data Factory \n  Python \n  Databricks \n  MSFT Fabric \n  Apache Spark \n  SQL Servers \n  Microservice Architectures \n  Data Warehouses/Data Lakes \n  AI and ML \n  Large Language Models and Natural Language Processing \n \n \n  Additional Information \n \n \n Please note \n : Although this is a Remote / Virtual / Work-From-Home career opportunity, candidates MUST reside, and be authorized to work without sponsorship, in the US. \n \n \n We are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. \n \n \n #LI-JH1 \n \n \n #REMOTE \n \n \n Base Salary Pay Range*: USD $135,300 - USD $194,700 \n \n \n \n The current applicable Base Salary Pay Range for this role is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills relevant to the role, internal equity, alignment with market data, or other law.  \n \n \n Other Compensation / Benefit Overview \n \n  In addition to Base Salary, the successful candidate may be eligible to participate in the following plans / programs, upon satisfying all hiring requirements:\n  \n \n  Bonus Plan \n  Medical, Dental and Vision Coverage \n  Life Insurance and Disability Programs \n  Retirement Savings with Company Match \n  Paid Time Off \n  Flexible Work Arrangements including Remote Work \n \n \n  Beware of scams \n \n  Our recruiting team may communicate with candidates via our @hitachisolutions.com domain email address and/or via our SmartRecruiters (Applicant Tracking System) notification@smartrecruiters.com domain email address regarding your application and interview requests. \n  \n  All offers will originate from our @hitachisolutions.com domain email address. If you receive an offer or information from someone purporting to be an employee of Hitachi Solutions from any other domain, it may not be legitimate.",
        "cleaned_desc": "  Participates in the interview process and applies a consistently high bar with well-articulated feedback. \n  Achieves proper balance between taking direct ownership for work versus creating leverage through effective vision setting and delegation. \n  Sets ambitious but realistic goals, and productively challenges others to do the same. \n  Re-frames problems in outcome-oriented terms and identifies creative solutions that optimize speed-to-value while setting up for long-term sustainability. \n  Regularly identifies, experiments with, and implements new practices and processes that improve team performance. \n  Autonomously leads cross-functional delivery for the broad business strategy they are accountable for and aligns around OKRs to achieve key business outcomes. \n  Regularly reflects on and revises priorities to ensure optimal overall value delivery. Creates focus for team(s) and sets boundaries with stakeholders as needed across cross-functional initiatives. \n  Leads definition of 12 - 15 month vision for one or more roadmaps with technical and non-technical stakeholders. \n  Demonstrates deep subject matter expertise in their product domain, acting as functional level lead for problem investigation and solution design. Understands adjacent product areas and associated business and technical integration dependencies and risks. \n  Uses objective decision making frameworks with well-defined criteria for deciding among a number of valid options, helping structure ambiguity and complexity into clear paths to decision making and forward progress. \n  Demonstrates subject matter expertise and thought leadership in their product and business domain, and advocates compellingly for their point of view. \n  Demonstrates sound, independent decision making in the areas of prioritization, trade-offs, upward/outward communication, expectation setting, etc. \n  Communicates effectively with stakeholders who may not be familiar with domain - can build frameworks to communicate complex ideas to unfamiliar audiences. \n  Proactively defines appropriate communication mechanisms, like reporting and status updates, for their domain and ensures follow-through. \n  Can lead and/or facilitate cross-functional interactions with varying audiences. Clearly defines purpose and objectives and drives towards them. \n  Builds influential relationships with senior partners and stakeholders (Directors, VPs) and can persuade cross-functional teams to accept required work to achieve desired goals. \n  Able to effectively influence across teams to create shared alignment for vision and goals, key requirements, overall prioritization, and timing. \n  Drives technical discussions with development teams, and able to communicate with developers to sanity check their designs. \n  Researches technologies constantly to stay up-to-date with the cutting edge to continuously improve the product in terms of speed and efficiency. \n \n \n  Technical Tooling: \n \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "096990ce589c7da9": {
        "terms": [
            "data science"
        ],
        "salary_min": 88147.0,
        "salary_max": 111613.75,
        "title": "Generative AI Lab Author",
        "company": "Pluralsight",
        "desc": "Job Description:\n  \n \n   Join Pluralsight on our mission to advance the world's technology workforce and bring high-quality, hands-on instruction to thousands of technologists across the globe! Pluralsight is currently hiring a Generative AI Lab Author to work full-time creating hands-on lab content to grow our Generative AI content offering.\n  \n \n \n   Role Requirements\n  \n \n   Pluralsight authors are a unique breed of technical professionals, combining in-the-trenches practitioner experience with outstanding teaching skills. As a Generative AI Lab Author you will be accountable for:\n  \n \n \n \n     Authoring hands-on content in accordance with the Pluralsight Generative AI Domain content strategy\n    \n \n \n     Developing educational content of the highest quality to be published on the Pluralsight platform, including\n    \n \n \n \n       Engineering content and capabilities in support of hands-on learning\n      \n \n \n       Automating robust hands-on environments to create rich, interactive experiences\n      \n \n \n \n   Pluralsight authors must embrace the mindset of a \u201clifelong learner\u201d and be capable of learning new techniques, processes, and technologies through continuous and rigorous research and self-directed study. This is nowhere as important as in the field of Generative AI given the rate of change.\n  \n \n \n   Pluralsight authors are also expected to:\n  \n \n \n \n     Work autonomously in a self-directed fashion\n    \n \n \n     Maintain a steady publication rate while also performing maintenance on previously published content\n    \n \n \n     This role is specifically for hands-on content, so no presentation skills are required\n    \n \n \n \n   As a Generative AI Lab Author it is expected you will meet the following requirements:\n  \n \n \n \n     1+ year of practitioner-level technical experience, ideally in artificial intelligence, machine learning, data science, or software development\n    \n \n \n   Previous experience as an author, content creator, instructor, and/or trainer\n   \n \n \n We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. \n \n \n \n   #LI-EB1\n    #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "2d71b18ba8833142": {
        "terms": [
            "data science"
        ],
        "salary_min": 50.0,
        "salary_max": 85.0,
        "title": "Data Scientist",
        "company": "FocusKPI Inc.",
        "desc": "FocusKPI is seeking  Data Scientists  to enable deep media insights through advanced analytics for our client, one of the largest retailers/e-commerce companies in the U.S. \n  Work Location:   Remote in the U.S.  Duration:   6 months contract with potential for extension and conversion, depending on budget and performance  Pay range:  $50/hour to $70/hour \n  Responsibilities: \n \n  Perform hands-on coding to retrieve and analyze large datasets using Python and SQL \n  Integrate disparate data sources and leverage state-of-the-art analytics best practices to deliver integrated actionable insights to partners and stakeholders \n  Manage and streamline data extraction process with great attention to details \n  Assess the potential usefulness, validity, and rigor of new data sources \n  Work with cross-functional team to ensure that the quality of the data are of the highest standard \n  Help with media mix models to connect the impact of marketing tactics and business short-term and long-term outcomes \n \n  Qualifications: \n \n  Experience working with  Marketing Mix Modeling (MMM) and/or Multi-Touch Attribution Models (MTA)  is a must \n  Ph.D. degree in statistics/mathematics, engineering, computer science, economics, or a related field \n  3+ years of industry experience in data, analytics, and data science role \n  Experience with advertising, measurement, and/or digital marketing analytics \n  Experience with advertising technology platforms, Ad servers, DSPs, DMPs, etc. \n  Proficient coding skills ( SQL/Python/R ) \n  Deep knowledge of relational database capabilities and experience with big data technologies (Hive/Hadoop) \n  Proficient BI/BA data visualization tools ( Tableau , PowerBI, ThoughtSpot, Looker, etc. \n  Experience with Modeling and Machine learning \n  Experience with cloud technologies such as GCP, AWS, Azure \n  Experience in integrating, structuring, and analyzing large amounts of data from diverse sources \n  Strong project management skills and attend-to-detail documentation skills. \n  Strong written and verbal communication with the ability to communicate complex technical topics clearly to a range of audiences and to \u2018tell a story that provides insight into the business \n  Passion for working in a fast-paced agile environment. \n  A collaborative mindset and sense of curiosity \n  Experience with predictive modeling algorithms and optimization techniques \n  Experience applying statistics to business problems \n  Experience with PySpark is a plus \n \n  Thank you! \n  FocusKPI Hiring Team \n  Founded in 2010, FocusKPI, Inc. (FocusKPI) is a data science and technology firm specializing in predictive analytics practice and methodologies. FocusKPI is a US company headquartered in Silicon Valley, California with an East Coast office in Boston, Massachusetts. \n  NOTICE:  Please be aware of fraudulent emails regarding job postings, job offers and fake checks. FocusKPI's recruiting team will strictly reach out via @focuskpi.com email domain. If you have received fraudulent emails now or in the past, please report it to https://reportfraud.ftc.gov/ .  The domain @focuskpijobs.com is fraudulent and not related to FocusKPI. Please do not not reply or communicate to anyone with @focuskpijobs.com. \n   \n LJ3EgzfIaZ",
        "cleaned_desc": "  Ph.D. degree in statistics/mathematics, engineering, computer science, economics, or a related field \n  3+ years of industry experience in data, analytics, and data science role \n  Experience with advertising, measurement, and/or digital marketing analytics \n  Experience with advertising technology platforms, Ad servers, DSPs, DMPs, etc. \n  Proficient coding skills ( SQL/Python/R ) \n  Deep knowledge of relational database capabilities and experience with big data technologies (Hive/Hadoop) \n  Proficient BI/BA data visualization tools ( Tableau , PowerBI, ThoughtSpot, Looker, etc.    Experience with Modeling and Machine learning \n  Experience with cloud technologies such as GCP, AWS, Azure \n  Experience in integrating, structuring, and analyzing large amounts of data from diverse sources \n  Strong project management skills and attend-to-detail documentation skills. \n  Strong written and verbal communication with the ability to communicate complex technical topics clearly to a range of audiences and to \u2018tell a story that provides insight into the business \n  Passion for working in a fast-paced agile environment. \n  A collaborative mindset and sense of curiosity ",
        "techs": [
            "ph.d. degree in statistics/mathematics",
            "engineering",
            "computer science",
            "economics",
            "or a related field",
            "sql/python/r",
            "hive/hadoop",
            "tableau",
            "powerbi",
            "thoughtspot",
            "looker",
            "gcp",
            "aws",
            "azure"
        ],
        "cleaned_techs": [
            "engineering",
            "computer science",
            "economics",
            "or a related field",
            "sql",
            "hive/hadoop",
            "tableau",
            "powerbi",
            "thoughtspot",
            "looker",
            "gcp",
            "aws",
            "azure"
        ]
    },
    "20a06dc8dd53cb88": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 95000.0,
        "salary_max": 110000.0,
        "title": "Senior Digital Data Analyst",
        "company": "Gannett",
        "desc": "Gannett Co., Inc. (NYSE:  GCI) is a subscription-led and digitally-focused media and marketing solutions company committed to empowering communities to thrive. With an unmatched reach at the national and local level, Gannett touches the lives of millions with our Pulitzer Prize-winning content, consumer experiences and benefits, and advertiser products and services. \n \n  Our current portfolio of media assets includes The USA TODAY NETWORK, which includes USA TODAY, and local media organizations in 43 states in the United States, and Newsquest, a wholly-owned subsidiary operating in the United Kingdom. We also own digital marketing services companies under the brand LocaliQ, which provide a cloud-based platform of products to enable small and medium-sized businesses to accomplish their marketing goals. In addition, our portfolio includes one of the largest media-owned events businesses in the U.S., USA TODAY NETWORK Ventures. \n \n  Gannett open roles are featured on various external job boards. When applying to a position at Gannett, you should be completing an application on Gannett Careers via Dayforce. Job postings directing you to complete an application on other external sites may not be valid. \n \n  To connect with us, visit www.gannett.com \n \n  We are seeking an experienced Senior Digital Data Analyst to join our team. The successful candidate will be responsible for leading and supporting the development of data-driven insights from Google Analytics that inform business decisions and drive impact. You will work closely with cross-functional teams, including product, growth marketing, content strategy, and experimentation. The Senior Data Analyst, is a position on the Enterprise Data Management team, reporting to the Director of Data Enablement and works closely with Product, Marketing, and Testing teams \n \n  This is an in-the-trenches position from helping stakeholders scope projects and understand their analytics needs to showing them how this data will translate into actionable use cases. \n \n  The ideal candidate has elite experience with stakeholder management, can tell a story through data, and get their point across without too much technical jargon. The ability to quickly understand and join complex and disparate data sets is a must. Hence the ideal candidate should be a problem solver who is comfortable thinking outside the box. The ideal candidate will have a strong analytical background, excellent communication skills, a passion for problem-solving, and the ability to evangelize data across the company. \n \n \n Base Salary:  $95,000 - $110,000/annually \n \n  Key Responsibilities \n \n \n Collaborate with business partners to define and prioritize business problems, develop hypotheses, and design experiments to test them. \n Scope projects for accurate analytics tagging, and tracking across multiple platforms and content initiatives. \n Gather and analyze data from multiple sources to uncover insights that inform business decisions and drive growth. \n Develop and present reports, dashboards, and visualizations that effectively communicate insights and recommendations to senior management. \n Help maintain strong data governance \n Partner with stakeholders across the organization to understand their needs and translate those needs into actionable insights. \n Serve as a thought leader and subject matter expert for business analytics, continuously exploring new data sources and technologies to improve our capabilities. \n Mentoring and coaching stakeholders from across the company on the mechanics and nuances of our data sets. \n Unlock and explain data to stakeholders ranging from content creators to data scientists. \n Answer questions from across the company on what insights can be gleaned from different data sets. \n \n Requirements: \n \n \n 5+ years of experience in business analytics, data analytics, or related fields. \n Experience with Enterprise Google Analytics 4 and tag management tools including Google Tag Manager is a must. \n Strong analytical skills with experience in SQL, and BigQuery are a must. \n Experience with data visualization tools (Tableau, Looker Studio, Looker Pro, etc.) is a must. \n Experience with Salesforce Marketing Cloud (Datorama) and/or ExactTarget data is good to have. \n Experience with DataRobot and other data science tools is good to have. \n Strong communication and teaching skills. \n Ability to work independently as well as collaboratively with cross-functional teams and manage multiple projects simultaneously. \n Experience in the publishing, subscriptions, and ad revenue space is a plus. \n  #LI-NR2 \n #LI-REMOTE \n \n  The annualized base salary for this role will range between $59,400 and $140,300. Base compensation is reflective of many factors, including, but not limited to, the market in which one lives/works, individual education level, skills, certifications, and \n \n experience. Note:  variable compensation is not reflected in these figures and based on the role, may be applicable \n \n  Gannett Co., Inc. is a proud equal opportunity employer committed to building and maintaining a diverse workforce. As such, we will consider all qualified applicants for employment and do not discriminate in connection with employment decisions on the basis of an applicant or employee\u2019s race, color, national origin, ethnicity, ancestry, citizenship status, sex, gender, gender identity, gender expression, religion, age, marital status, personal appearance (including height and weight), sexual orientation, family responsibilities, physical or mental disability, medical condition, pregnancy status (including childbirth, breastfeeding or related medical conditions), education, genetic characteristics or information, political affiliation, military or veteran status or other classifications protected by applicable federal, state and local laws in the jurisdictions where Gannett employs employees. In addition, Gannett Co., Inc. will provide applicants who require a reasonable accommodation, as a result of an applicant\u2019s disability or religion, to complete this employment application and/or any other process in connection with an individuals\u2019 application for employment with Gannett Co., Inc. Applicants who require such accommodation should contact Gannett Co., Inc.\u2019s Recruitment Department at Recruit@gannett.com.",
        "cleaned_desc": " \n Requirements: \n \n \n 5+ years of experience in business analytics, data analytics, or related fields. \n Experience with Enterprise Google Analytics 4 and tag management tools including Google Tag Manager is a must. \n Strong analytical skills with experience in SQL, and BigQuery are a must. \n Experience with data visualization tools (Tableau, Looker Studio, Looker Pro, etc.) is a must. \n Experience with Salesforce Marketing Cloud (Datorama) and/or ExactTarget data is good to have. \n Experience with DataRobot and other data science tools is good to have. ",
        "techs": [
            "google analytics 4",
            "google tag manager",
            "sql",
            "bigquery",
            "tableau",
            "looker studio",
            "looker pro",
            "salesforce marketing cloud (datorama)",
            "exacttarget",
            "datarobot"
        ],
        "cleaned_techs": [
            "google analytics 4",
            "google tag manager",
            "sql",
            "bigquery",
            "tableau",
            "looker studio",
            "looker pro",
            "salesforce marketing cloud (datorama)",
            "exacttarget",
            "datarobot"
        ]
    },
    "437c121f7a6db237": {
        "terms": [
            "data science"
        ],
        "salary_min": 58967.33,
        "salary_max": 101510.73,
        "title": "Business Analyst-PN Operations (Remote, North Carolina Based)",
        "company": "Alliance Health",
        "desc": "This Business Analyst-PN position will support reporting through identified databases for identified reports, and support the additional report generation process for deliverables containing data needed from multiple resources or workstreams, including the ability to pull ad hoc reports from the Data Warehouse. The Analyst also conducts quality assurance testing related to IT reporting, data integrity, and analyses and serves as a liaison between Provider Network, Business Owners, and IT to coordinate data collection and report development efforts. \n  This position will be fully remote from home, located in North Carolina. The selected candidate will be required to report on-site to the Alliance Home office in Morrisville North Carolina for critical business meetings, as needed. \n  Responsibilities & Duties \n  Analyze Business Requirements and Translate into Specifications \n \n Analyze business activities to identify report and data requirements \n Translate business requirements into business report documentation specifications \n Conduct research through business specifications, contracts, journals, web resources, and in-person interviews to determine data requirements for projects \n Lead efforts to clarify any specifications that are unclear \n \n Develop Reports and Data Visualization Solutions \n \n Perform data acquisition, analysis, and evaluation via advanced SQL queries and stored procedures, MicroStrategy, and other data management tools \n Design solutions using BI concepts including dynamic and parameter driven reporting, dashboards, and alerts \n Using thorough knowledge of available data, design products that merge data from various sources including EDI files, HIE, State data, transactional system, and data warehouse \n Provide support as required to ensure the accuracy of developed reports and metrics for both external and internal users \n Ensure that reporting activities are conducted in ways that correspond with externally mandated specifications \n Assist the Provider Network Department with any data assurance/integrity efforts required as part of larger quality activities, and with the completion and validation of state-required reports \n Perform network adequacy reporting using Quest Analytics platform as needed \n \n Develop and Document Processes \n \n Engineer efficient processes for gathering statistical data, identifying complex trends, and translating insights into actionable recommendations \n \n Collaborate with Other Departments to Enhance Operations \n \n Work closely with IT Department to enhance operations and automation of reports and processes and perform quality assurance testing of systems and products \n Actively participate in Data Governance committee and Business Analyst teams as needed \n Attend IT/Reporting trainings or meetings that are relevant to the above responsibilities. \n \n Manage Testing and End User Support \n \n Manage the User Acceptance Testing process and feedback \n Provide End User support on solutions and data interpretation \n Conduct peer reviews and test solutions for functionality and data accuracy \n \n Minimum Requirements \n  Education & Experience \n  Bachelor\u2019s degree in computer science, information science, human services/healthcare, or related field and (2) two years of experience with quantitative and qualitative data collection and analysis methods, research design, program evaluation, and testing of applications or reports and dashboards. \n  Knowledge, Skills, & Abilities \n \n Knowledge of data integration (validation and cleaning) \n Knowledge of complex data and structures \n Knowledge of the healthcare industry \n Advanced knowledge of relational database systems, statistical analysis, data mining, predictive analytics, performance measurement, and other data science concepts \n Knowledge of data visualization principles and strategies \n Skilled in various software applications and informatics systems (Excel, Access, SAS, SPSS, Tableau, Power BI, Qualtrix, EPIC EMR system and SQL language/processes) \n Excellent interpersonal (verbal and written) communication skills are required to support working in project environments that includes internal, external and customer teams \n Strong analytical, conceptual, and problem-solving skills \n Ability to work with large-volume clinical and financial data and transactions \n Ability to manage projects and deliver within specified timeframes \n Ability to manage multiple priorities and adjust quickly to changing priorities \n \n Salary Range  \n $58,967.33 to $101,510.73/Annually \n  Exact compensation will be determined based on the candidate's education, experience, external market data and consideration of internal equity. \n  An excellent fringe benefit package accompanies the salary, which includes: \n \n Medical, Dental, Vision, Life, Long Term Disability \n Generous retirement savings plan \n Flexible work schedules including hybrid/remote options \n Paid time off including vacation, sick leave, holiday, management leave \n Dress flexibility \n \n \n Education  Preferred\n  \n  Bachelors or better in Human Services",
        "cleaned_desc": " Design solutions using BI concepts including dynamic and parameter driven reporting, dashboards, and alerts \n Using thorough knowledge of available data, design products that merge data from various sources including EDI files, HIE, State data, transactional system, and data warehouse \n Provide support as required to ensure the accuracy of developed reports and metrics for both external and internal users \n Ensure that reporting activities are conducted in ways that correspond with externally mandated specifications \n Assist the Provider Network Department with any data assurance/integrity efforts required as part of larger quality activities, and with the completion and validation of state-required reports \n Perform network adequacy reporting using Quest Analytics platform as needed \n \n Develop and Document Processes \n \n Engineer efficient processes for gathering statistical data, identifying complex trends, and translating insights into actionable recommendations \n \n Collaborate with Other Departments to Enhance Operations \n   Work closely with IT Department to enhance operations and automation of reports and processes and perform quality assurance testing of systems and products \n Actively participate in Data Governance committee and Business Analyst teams as needed \n Attend IT/Reporting trainings or meetings that are relevant to the above responsibilities. \n \n Manage Testing and End User Support \n \n Manage the User Acceptance Testing process and feedback \n Provide End User support on solutions and data interpretation \n Conduct peer reviews and test solutions for functionality and data accuracy \n \n Minimum Requirements \n  Education & Experience \n  Bachelor\u2019s degree in computer science, information science, human services/healthcare, or related field and (2) two years of experience with quantitative and qualitative data collection and analysis methods, research design, program evaluation, and testing of applications or reports and dashboards.    Knowledge, Skills, & Abilities \n \n Knowledge of data integration (validation and cleaning) \n Knowledge of complex data and structures \n Knowledge of the healthcare industry \n Advanced knowledge of relational database systems, statistical analysis, data mining, predictive analytics, performance measurement, and other data science concepts \n Knowledge of data visualization principles and strategies \n Skilled in various software applications and informatics systems (Excel, Access, SAS, SPSS, Tableau, Power BI, Qualtrix, EPIC EMR system and SQL language/processes) \n Excellent interpersonal (verbal and written) communication skills are required to support working in project environments that includes internal, external and customer teams \n Strong analytical, conceptual, and problem-solving skills \n Ability to work with large-volume clinical and financial data and transactions \n Ability to manage projects and deliver within specified timeframes \n Ability to manage multiple priorities and adjust quickly to changing priorities ",
        "techs": [
            "dynamic reporting",
            "parameter driven reporting",
            "dashboards",
            "alerts",
            "edi files",
            "hie",
            "state data",
            "transactional system",
            "data warehouse",
            "quest analytics platform",
            "data governance committee",
            "business analyst teams",
            "user acceptance testing",
            "data integration",
            "relational database systems",
            "statistical analysis",
            "data mining",
            "predictive analytics",
            "performance measurement",
            "data visualization",
            "excel",
            "access",
            "sas",
            "spss",
            "tableau",
            "power bi",
            "qualtrix",
            "epic emr system",
            "sql"
        ],
        "cleaned_techs": [
            "dynamic reporting",
            "parameter driven reporting",
            "dashboards",
            "alerts",
            "edi files",
            "hie",
            "state data",
            "transactional system",
            "data warehouse",
            "quest analytics platform",
            "data governance committee",
            "user acceptance testing",
            "data integration",
            "relational database systems",
            "statistical analysis",
            "data mining",
            "predictive analytics",
            "performance measurement",
            "data visualization",
            "excel",
            "access",
            "sas",
            "spss",
            "tableau",
            "powerbi",
            "qualtrix",
            "epic emr system",
            "sql"
        ]
    },
    "6af464bbed072125": {
        "terms": [
            "data science"
        ],
        "salary_min": 120000.0,
        "salary_max": 150000.0,
        "title": "Principal Technical Program Manager",
        "company": "2U",
        "desc": "At 2U, we are all in on purpose. We are motivated by our mission \u2013 to eliminate the back row in education \u2013 and connected by our shared passion to deliver world-class digital education at scale. As the parent company of edX, the world's leading online learning platform, 2U powers more than 4,000 online higher education offerings \u2013 from free courses to full degrees. Together with more than 230 colleges, universities, and corporate partners, we are helping to unlock human potential. \n  What We're Looking For: \n  We're seeking a Principal Technical Program Manager for our newly established Experimentation Platform Team. This team has an exciting opportunity to drive the development of a centralized experimentation platform across our diverse lines of business, shaping it from the ground up. Their mission is to establish a system that facilitates rapid, high-quality, and trustworthy experimentation company-wide, empowering internal teams to efficiently set up, execute, and analyze experiments at scale. \n  As the Principal Technical Program Manager, you'll be the driving force behind elevating experimentation capability throughout 2U. Drawing from your experience with experimentation platforms, you'll work closely with cross-functional partners, including a dedicated engineering team, to activity shape and execute on a vision and roadmap that propels our company forward. This is a highly visible role with big impact, given the significance of experimentation in driving 2U's future. \n  Responsibilities Include, But Are Not Limited To: \n \n Sets the strategic vision, roadmap, and direction for the Experimentation Platform and communicates this to the broader organization, including to executive stakeholders. \n Builds an in-depth knowledge of 2U teams running experiments to understand their pain points and identify opportunities. \n Takes an evidence-based approach to opportunity sizing and prioritization of opportunities with clear rationale. \n Actively partners with the Experiment Platform Engineers to execute on roadmap, ensuring experimentation platform projects are delivered on time and within scope. \n Coaches and mentors stakeholders across the organization seeking to run experiments and guides and build their capacity to enable experimentation in their specific contexts. \n Drives continuous improvement, regularly evaluating and enhancing the experimentation process through the creation of methods, techniques, and evaluation criteria. \n Fosters a culture of experimentation and data-driven decision-making, measuring improvements through relevant KPIs. \n Identifies areas within the organization requiring additional talent to meet experimentation needs, facilitating in the recruitment and onboarding of such talent. \n Stays abreast of industry best practices and emerging technologies related to experimentation and recommends improvements to enhance our platform's capabilities. \n \n Things That Should Be In Your Background: \n \n 8+ years in a Technical Program Manager, Technical Product Manager role or similar \n Knowledge and experience in experimentation platforms, tools and processes \n Understanding of experimental design, A/B testing, and statistical methodologies \n Familiarity and experience working with agile development methodologies \n Excellent communication skills and the ability to collaborate effectively with diverse, cross-functional teams \n Track record of successful project management and delivering high-quality results \n \n Other Attributes That Will Help You In This Role: \n \n Experience working across multiple technology stacks in a post-M&A organization \n Experience with data analysis, SQL, data science and data products \n Experience with software products for a SaaS Education Technology company \n Experience using Optimizely, Amplitude, Google Optimize, VWO, StatSig, and other feature flagging, personalization, and A/B testing platforms \n \n Benefits & Culture \n  Our global employee base is a diverse collection of innovators, dreamers, and doers working together to transform lives through higher education. We believe that every employee can advance our shared purpose, and that life at 2U should be fun and meaningful. If you're excited by the opportunity to provide over 40 million learners and counting with access to world-class online higher education, then join us \u2013 and do work that makes a difference. #NoBackRow \n  We offer comprehensive benefits (unique per country) and excellent work/life balance.  Full-time, U.S.benefits include: \n \n Medical, dental, and vision coverage \n Life insurance, disability, and 401(k) employer match \n Employee stock purchase plan \n Free snacks and drinks in-office \n Generous paid holidays and leave policies, including unlimited PTO \n Additional time off benefits include: volunteer days, parental leave, and a company-wide winter break \n \n The anticipated base salary range for this role is $120,000-$150,000, with potential bonus eligibility. Salary offers are made based on the candidate's qualifications, experience, skills, and education as they directly relate to the requirements of the position, budget for the position and cost of labor in the market in which the candidate will be hired. \n  2U Diversity and Inclusion Statement \n \n  At 2U, we are committed to building and sustaining a culture of belonging, respect, and inclusion. We are proud of the steps we've taken to bring together an employee base that embodies diverse walks of life, ideas, genders, ages, races, cultures, sexual orientations, abilities and other unique qualities. We strive to offer a workplace where every employee feels empowered by what makes us different, as well as by how we are alike. \n  2U is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodations, please reach out to us at: recruitingaccommodations@2u.com. \n  About 2U Inc. (NASDAQ: TWOU) \n  For more than a decade, 2U, Inc. has been the digital transformation partner of choice to great non-profit colleges and universities delivering high-quality online education at scale. As the parent company of edX, a leading global online learning platform, 2U provides over 45 million learners with access to world-class education in partnership with more than 230 colleges, universities, and corporations. Our people and technology are powering more than 4,000 digital education offerings \u2014 from free courses to full degrees \u2014 and helping unlock human potential. To learn more: visit 2U.com.     About edX \n  edX is the education movement for restless learners and a leading global online learning platform from 2U, Inc. (Nasdaq: TWOU). Together with the majority of the world's top-ranked universities and industry-leading companies, we bring our community of over 45 million learners world-class education to support them at every stage of their lives and careers, from free courses to full degrees. And we're not stopping there \u2014 we're relentlessly pursuing our vision of a world where every learner can access education to unlock their potential, without the barriers of cost or location. Learn more at edX.org. \n  Learn more at https://2u.com/careers/   #NoBackRow \n  The above statements are intended to describe the general nature and level of work performed by individuals assigned to this position, and are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required. All employees may be required to perform duties outside of their normal responsibilities from time to time, as needed. \n  2U is an equal opportunity employer that does not discriminate against applicants or employees and ensures equal employment opportunity for all persons regardless of their race, creed, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, age, marital status, disability, citizenship, military or veterans' status, or any other classifications protected by applicable federal, state or local laws. 2U's equal opportunity policy applies to all terms and conditions of employment, including but not limited to recruiting, hiring, training, promotion, job benefits and pay.",
        "cleaned_desc": " Understanding of experimental design, A/B testing, and statistical methodologies \n Familiarity and experience working with agile development methodologies \n Excellent communication skills and the ability to collaborate effectively with diverse, cross-functional teams \n Track record of successful project management and delivering high-quality results \n \n Other Attributes That Will Help You In This Role: \n \n Experience working across multiple technology stacks in a post-M&A organization \n Experience with data analysis, SQL, data science and data products \n Experience with software products for a SaaS Education Technology company ",
        "techs": [
            "experimental design",
            "a/b testing",
            "statistical methodologies",
            "agile development methodologies",
            "communication skills",
            "collaboration skills",
            "project management",
            "data analysis",
            "sql",
            "data science",
            "data products",
            "software products"
        ],
        "cleaned_techs": [
            "experimental design",
            "a/b testing",
            "statistical methodologies",
            "agile development methodologies",
            "project management",
            "sql",
            "data science",
            "data products",
            "software products"
        ]
    },
    "b7de9dafbada8949": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 140000.0,
        "salary_max": 150000.0,
        "title": "Product Manager (Spend Analytics)",
        "company": "Marathon TS",
        "desc": "This organization is a leading provider of risk mitigation solutions for spend management at large enterprises. Based in Atlanta, GA. We are a data-driven company with a suite of data analytics products that analyze billions of dollars in spend and financial transactions every year for some of the most innovative companies, universities, and government agencies in the world. \n Leveraging AI and machine learning, This organizations platform works across their customer's financial systems to continuously monitor and analyze all spend transactions for fraud, waste, and misuse. With a consolidated view of risk across their enterprise, customers can prevent financial loss and optimize spend while strengthening the controls that improve compliance. \n Position Overview \n As a Product Manager, you will lead the design, execution and delivery for all product functionality related to your assigned product line and determine the best ways for users to interact with our product. You will work with our engineers and data scientists to assess the existing product offering and explore new ways to deliver the best product experience for our customers. You will be working across teams to build and launch products and features that align with their vision, strategy and product roadmap. \n You will understand data and digital workflows and how to present them to end-users in a UI. The ideal candidate possesses a blend of technical know-how, business acumen, product design, is skilled at prioritization, and communicates effectively to influence, collaborate with, and educate teams within the organization. \n Responsibilities \n \n Own the overall product experience for your product line including user-facing analytics models, workflow applications, and BI dashboards and advocate on behalf of the customer to build a best-in-class user experience. \n Define product roadmap and deliver market-leading offering to our customers. \n Manage day-to-day product execution: collaborate with customers, conduct user research, define use cases, lead requirements sessions, track and prioritize enhancement requests, coordinate product releases. \n Define business requirements and functional specifications and work with engineering, UX, and data science teams throughout the product development life cycle. \n Track enhancement requests and work with engineering to continuously prioritize product backlog for sprint planning in Jira. \n Understand user/buyer needs to identify product enhancements. \n Analyze and evaluate complementary and competitive products, technologies, and solutions and maintain a product competitive advantage. \n Support product launch planning, go-to-market activities and partner with marketing and sales teams to provide necessary support to ensure sales success. \n Act as a product evangelist to build awareness and understanding throughout the company and provide product demos as needed. \n \n Required Qualifications \n \n 3+ years of experience as a product manager building and managing data-driven software products for end-users (preferably SaaS B2B). \n Bachelor's degree in Science, Engineering, Math, Finance, Business, Economics \n Product management experience with delivering successful software products including the full product development life cycle: planning, requirements, development, release, go-to-market. \n Ability to lead and collaborate across teams and influence product direction. \n Ability to prioritize feature development using qualitative and quantitative analysis. \n Ability to communicate functions and benefits for complex product features to customers and internal employees. \n Ability to present product functionality and represent the product team throughout the organization. \n Experience with Agile, Scrum and Jira or related tracking tools \n \n Preferred Qualifications \n \n MBA or graduate studies in data analytics, risk management, finance, or accounting. \n Familiarity with financial business processes such as Accounts Payable, Expense Management, Accounts Receivable, Order-to-Cash, Procurement, General Ledger. \n Experience leading enterprise SaaS products. \n Solid understanding of software UI/UX best practices. \n Experience launching products and features that use AI/Client. \n Experience identifying new product concepts and features through extensive market and user research. \n Track record of partnering with data engineering and data science teams. \n Experience with workflow applications and BI dashboards. \n Experience with UX design and user research. \n Experience developing risk focused products. \n \n This position is located in Atlanta, Georgia but can be remote with periodic travel for the right candidate. \n Job Type: Full-time \n Pay: $140,000.00 - $150,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Product management: 3 years (Preferred) \n Software product management: 3 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "This organization is a leading provider of risk mitigation solutions for spend management at large enterprises. Based in Atlanta, GA. We are a data-driven company with a suite of data analytics products that analyze billions of dollars in spend and financial transactions every year for some of the most innovative companies, universities, and government agencies in the world. \n Leveraging AI and machine learning, This organizations platform works across their customer's financial systems to continuously monitor and analyze all spend transactions for fraud, waste, and misuse. With a consolidated view of risk across their enterprise, customers can prevent financial loss and optimize spend while strengthening the controls that improve compliance. \n Position Overview \n As a Product Manager, you will lead the design, execution and delivery for all product functionality related to your assigned product line and determine the best ways for users to interact with our product. You will work with our engineers and data scientists to assess the existing product offering and explore new ways to deliver the best product experience for our customers. You will be working across teams to build and launch products and features that align with their vision, strategy and product roadmap. \n You will understand data and digital workflows and how to present them to end-users in a UI. The ideal candidate possesses a blend of technical know-how, business acumen, product design, is skilled at prioritization, and communicates effectively to influence, collaborate with, and educate teams within the organization. \n Responsibilities \n \n Own the overall product experience for your product line including user-facing analytics models, workflow applications, and BI dashboards and advocate on behalf of the customer to build a best-in-class user experience. \n Define product roadmap and deliver market-leading offering to our customers. \n Manage day-to-day product execution: collaborate with customers, conduct user research, define use cases, lead requirements sessions, track and prioritize enhancement requests, coordinate product releases. \n Define business requirements and functional specifications and work with engineering, UX, and data science teams throughout the product development life cycle. \n Track enhancement requests and work with engineering to continuously prioritize product backlog for sprint planning in Jira.   Ability to communicate functions and benefits for complex product features to customers and internal employees. \n Ability to present product functionality and represent the product team throughout the organization. \n Experience with Agile, Scrum and Jira or related tracking tools \n \n Preferred Qualifications \n \n MBA or graduate studies in data analytics, risk management, finance, or accounting. \n Familiarity with financial business processes such as Accounts Payable, Expense Management, Accounts Receivable, Order-to-Cash, Procurement, General Ledger. \n Experience leading enterprise SaaS products. \n Solid understanding of software UI/UX best practices. \n Experience launching products and features that use AI/Client. \n Experience identifying new product concepts and features through extensive market and user research. ",
        "techs": [
            "risk mitigation solutions",
            "spend management",
            "data analytics products",
            "ai",
            "machine learning",
            "financial systems",
            "fraud detection",
            "waste detection",
            "misuse detection",
            "consolidated risk view",
            "financial loss prevention",
            "spend optimization",
            "compliance controls",
            "product manager",
            "product functionality",
            "user interaction",
            "engineers",
            "data scientists",
            "product roadmap",
            "data workflows",
            "ui design",
            "technical know-how",
            "business acumen",
            "prioritization skills",
            "overall product experience",
            "user-facing analytics models",
            "workflow applications",
            "bi dashboards",
            "customer advocacy",
            "market-leading offering",
            "user research",
            "use case definition",
            "requirements sessions",
            "product releases",
            "business requirements",
            "functional specifications",
            "agile",
            "scrum",
            "jira",
            "mba",
            "data analytics",
            "risk management",
            "finance",
            "accounting",
            "financial business processes",
            "enterprise saas products",
            "software ui/ux best practices",
            "ai/client integration",
            "product launch",
            "market research"
        ],
        "cleaned_techs": [
            "risk mitigation solutions",
            "spend management",
            "data analytics products",
            "ai",
            "financial systems",
            "fraud detection",
            "waste detection",
            "misuse detection",
            "consolidated risk view",
            "financial loss prevention",
            "spend optimization",
            "compliance controls",
            "product manager",
            "product functionality",
            "user interaction",
            "engineers",
            "data scientists",
            "product roadmap",
            "data workflows",
            "ui design",
            "technical know-how",
            "business acumen",
            "overall product experience",
            "user-facing analytics models",
            "bi dashboards",
            "customer advocacy",
            "market-leading offering",
            "user research",
            "use case definition",
            "requirements sessions",
            "product releases",
            "business requirements",
            "functional specifications",
            "agile",
            "scrum",
            "jira",
            "mba",
            "data analytics",
            "risk management",
            "finance",
            "accounting",
            "financial business processes",
            "enterprise saas products",
            "product launch",
            "market research"
        ]
    },
    "2ff1d0cc302bf642": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 125000.0,
        "salary_max": 150000.0,
        "title": "Sr Machine Learning Engineer",
        "company": "TensorIoT",
        "desc": "Accepting remote candidates in the following states: Arizona, California, Colorado, Delaware, Florida, Georgia, Minnesota, Nevada, New York, North Carolina, Ohio, Pennsylvania, Tennessee, Texas, Virginia, Washington. \n TensorIoT an APN Advanced Consulting Partner. We help companies realize the value and efficiency of the AWS ecosystem. From building PoCs and MVPs to production ready applications, we are tackling complex business problems every day and developing solutions to drive customer success. \n TensorIoT is looking for skilled machine learning engineers to join our Machine Learning & AI Team! We are currently trying to grow our Machine Learning practice with enthusiastic and smart data scientists who have excellent analytical and communication skills and a track record of using end-to-end data science workflows to build ML/DL/AI models. The individual would be responsible for finding and implementing ML solutions to a broad scope of customer needs in a dynamic industry setting. \n Basic Qualifications: \n -AWS Certification (Solutions Architect Associate, Developer, DevOps, or ML Specialty) -Bachelor's or Master's degree in Computer Science, Data Science, Statistics, or a related highly quantitative field -5+ years of experience in data science, statistical modeling, machine learning algorithm development, or a related field -Experience with collecting, cleansing and parsing data -5+ years of experience working with ML Ops pipelines such as AWS SageMaker or equivalent. -Proficient in programming languages such as Python or R, and familiar with data science libraries such as NumPy, Pandas, PySparks, popular Python stats libraries and data visualization tools - Proficient in one or more ML frameworks such as TensorFlow, PyTorch etc. - Experience with ML algorithm optimization and hosting. Familiarity with GPU accelerator libraries such as TensorRT. - Experience with SQL and database technologies such as MySQL, PostgreSQL, or MongoDB - Familiar with container deployments -Ability to present and communicate complex technical concepts to a broad audience of stakeholders -Strong written and verbal communication skills \n Preferred Qualifications: \n -PhD in a highly quantitative field (Computer/Information Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) -Track record of diving into data to discover hidden patterns -Track record of building ML or DL models in a production environment -Computer vision / time series analytics experiences -Consulting experience and track record of helping customers with their AI needs -Experience with AWS technologies for storage, compute and ML -Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment \n Job Type: Full-time \n Pay: $125,000.00 - $150,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible schedule \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Referral program \n Vision insurance \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n Machine learning: 5 years (Required) \n AWS: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Accepting remote candidates in the following states: Arizona, California, Colorado, Delaware, Florida, Georgia, Minnesota, Nevada, New York, North Carolina, Ohio, Pennsylvania, Tennessee, Texas, Virginia, Washington. \n TensorIoT an APN Advanced Consulting Partner. We help companies realize the value and efficiency of the AWS ecosystem. From building PoCs and MVPs to production ready applications, we are tackling complex business problems every day and developing solutions to drive customer success. \n TensorIoT is looking for skilled machine learning engineers to join our Machine Learning & AI Team! We are currently trying to grow our Machine Learning practice with enthusiastic and smart data scientists who have excellent analytical and communication skills and a track record of using end-to-end data science workflows to build ML/DL/AI models. The individual would be responsible for finding and implementing ML solutions to a broad scope of customer needs in a dynamic industry setting. \n Basic Qualifications: \n -AWS Certification (Solutions Architect Associate, Developer, DevOps, or ML Specialty) -Bachelor's or Master's degree in Computer Science, Data Science, Statistics, or a related highly quantitative field -5+ years of experience in data science, statistical modeling, machine learning algorithm development, or a related field -Experience with collecting, cleansing and parsing data -5+ years of experience working with ML Ops pipelines such as AWS SageMaker or equivalent. -Proficient in programming languages such as Python or R, and familiar with data science libraries such as NumPy, Pandas, PySparks, popular Python stats libraries and data visualization tools - Proficient in one or more ML frameworks such as TensorFlow, PyTorch etc. - Experience with ML algorithm optimization and hosting. Familiarity with GPU accelerator libraries such as TensorRT. - Experience with SQL and database technologies such as MySQL, PostgreSQL, or MongoDB - Familiar with container deployments -Ability to present and communicate complex technical concepts to a broad audience of stakeholders -Strong written and verbal communication skills \n Preferred Qualifications: ",
        "techs": [
            "tensoriot",
            "aws ecosystem",
            "pocs",
            "mvps",
            "ml/dl/ai models",
            "ml solutions",
            "aws certification",
            "solutions architect associate",
            "developer",
            "devops",
            "ml specialty",
            "computer science",
            "data science",
            "statistics",
            "quantitative field",
            "data science workflows",
            "collecting",
            "cleansing",
            "parsing data",
            "ml ops pipelines",
            "aws sagemaker",
            "python",
            "r",
            "numpy",
            "pandas",
            "pysparks",
            "python stats libraries",
            "data visualization tools",
            "tensorflow",
            "pytorch",
            "ml algorithm optimization",
            "gpu accelerator libraries",
            "tensorrt",
            "sql",
            "mysql",
            "postgresql",
            "mongodb",
            "container deployments"
        ],
        "cleaned_techs": [
            "tensoriot",
            "aws",
            "pocs",
            "mvps",
            "ml/dl/ai models",
            "ml solutions",
            "solutions architect associate",
            "developer",
            "devops",
            "ml specialty",
            "computer science",
            "data science",
            "statistics",
            "quantitative field",
            "data science workflows",
            "collecting",
            "cleansing",
            "parsing data",
            "ml ops pipelines",
            "python",
            "r",
            "numpy",
            "pandas",
            "pysparks",
            "data visualization tools",
            "tensorflow",
            "pytorch",
            "ml algorithm optimization",
            "gpu accelerator libraries",
            "tensorrt",
            "sql",
            "mysql",
            "postgresql",
            "mongodb",
            "container deployments"
        ]
    },
    "bc59899776d26d18": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 112309.37,
        "salary_max": 142208.69,
        "title": "Machine Learning Infra Engineer",
        "company": "Cyberjin",
        "desc": "Remote Position \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n kSeOY5prM1",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a55dde5890b5ac6f": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89551.69,
        "salary_max": 113392.39,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "e7c7b66a3efdb125": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89551.69,
        "salary_max": 113392.39,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office",
            "finra series 7",
            "finra series 24"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft",
            "finra series 7",
            "finra series 24"
        ]
    },
    "4820dd60120206c3": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 204000.0,
        "salary_max": 220000.0,
        "title": "Senior Software Engineer, Machine Learning Platform",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a a voice, video, and text communication service company to hire a Senior Software Engineer, Machine Learning Platform. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability.What you'll do \n \n Design and build the platform engineers and data scientists throughout the company uses for the full machine learning workflow. \n Evaluate and integrate new machine learning frameworks and tools to ensure that the company keeps up with fast moving world of ML including LLMs and generative AI tooling \n Collaborate with model builders and gain a strong understanding of how to take a project from idea to production \n Help set and drive best practices in machine learning at the company \n Create foundational datasets and models \n \n Who are you \n \n 5+ years of experience working as a software engineer in data or backend with exposure to large datasets or highly distributed systems \n 2+ years working on platforms or infrastructure \n 2+ years experience with the machine learning workflow \n You've had experience with orchestration systems (such as Airflow, Dagster, or Argo) \n \n Bonus Points \n \n Experience with real-time data processing (Spark, Flink, Dataflow, Kafka, Pulsar, etc.) \n Experience debugging and maintaining live production systems on Kubernetes \n Experience building ML models in TensorFlow or PyTorch \n \n The US base salary range for this full-time position is $204,000 to $220,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits. \n Job Type: Full-time \n Pay: $204,000.00 - $220,000.00 per year \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " 5+ years of experience working as a software engineer in data or backend with exposure to large datasets or highly distributed systems \n 2+ years working on platforms or infrastructure \n 2+ years experience with the machine learning workflow \n You've had experience with orchestration systems (such as Airflow, Dagster, or Argo) \n \n Bonus Points ",
        "techs": [
            "airflow",
            "dagster",
            "argo"
        ],
        "cleaned_techs": [
            "airflow",
            "dagster",
            "argo"
        ]
    },
    "f30d1742a79bf6a5": {
        "terms": [
            "data science"
        ],
        "salary_min": 135300.0,
        "salary_max": 194700.0,
        "title": "Senior Technical Product Manager",
        "company": "Hitachi Solutions",
        "desc": "Company Description\n   Company Overview \n  Hitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering innovative cloud solutions to help our clients innovative across their entire business. Our firm develops the business services and technology powering some of the products you use every day \u2013 and is closely aligned with Microsoft and other leaders in the cloud computing space. \n  What sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers. Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike \u2013 helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion. With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction. \n  A part of Hitachi Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies. \n  This is a high-visibility, full-time role in our Empower Product Group for professionals with a proven history of execution, and a desire to rapidly expand a product organization. \n \n \n \n \n Job Description\n   Position Overview \n  This is a high-visibility, high-impact, full-time role in our Empower Product Group for professionals with a proven history of execution, and a desire to rapidly expand a product organization. Technical acumen and domain experience in data engineering, Azure, SaaS, and Data Analytics are strongly preferred. \n  Who you are: \n \n \n  Overall:  We would like to see candidates with 5+ years experience in Product. \n \n \n  Experienced . You have experience building solutions involving data or analytics in product management or similar roles. You have a strong background in enterprise software. \n  Customer and user focused.  You have the ability to put yourself in a users' shoes and understand their needs. You listen closely to all avenues of feedback. You love to be the voice of the customer. \n  Passionate . You love the intersection of building software, deeply understanding customer needs, bringing products to market, and data science technologies. You have strong product and design instincts that inspire confidence. \n  Leader . You inspire trust with team members and can drive change in a positive and productive way. You anticipate problems and mitigate risks. \n  Growth mindset . You enjoy learning new things and see challenges as growth opportunities. You excel at mastering technical products and being the go-to person in your domain. \n  Strong communicator . You are comfortable representing your team & product, presenting vision & priorities to internal stakeholders, customers, and partners. You enjoy speaking opportunities and have a proven experience presenting to large teams and leadership. \n  Data Enthusiast . You have a strong desire to help people see and understand data. \n  A Ruthless Prioritizer . You treat time as a team's most valuable asset. \n  Entrepreneurial . You solve problems for your customers while jumping on opportunities to strategically add new lines of business. \n  Technical Focus . You have experience with technical work, having been a developer yourself in a former role or by having deep experience with developers and learning technologies they use. \n \n \n \n \n Qualifications\n   Your responsibilities: \n \n  Execute. This means being constantly biased towards action, knowing the data, being in the details, setting a high bar and building strong collaborative relationships with other teams, thinking boldly, disambiguating, always thinking of the customer first, and rapidly iterating towards something demonstrably awesome. \n  Creates a culture of self-reflection and actively seeks out two-way feedback within their team and direct stakeholder group. \n  Participates in the interview process and applies a consistently high bar with well-articulated feedback. \n  Achieves proper balance between taking direct ownership for work versus creating leverage through effective vision setting and delegation. \n  Sets ambitious but realistic goals, and productively challenges others to do the same. \n  Re-frames problems in outcome-oriented terms and identifies creative solutions that optimize speed-to-value while setting up for long-term sustainability. \n  Regularly identifies, experiments with, and implements new practices and processes that improve team performance. \n  Autonomously leads cross-functional delivery for the broad business strategy they are accountable for and aligns around OKRs to achieve key business outcomes. \n  Regularly reflects on and revises priorities to ensure optimal overall value delivery. Creates focus for team(s) and sets boundaries with stakeholders as needed across cross-functional initiatives. \n  Leads definition of 12 - 15 month vision for one or more roadmaps with technical and non-technical stakeholders. \n  Demonstrates deep subject matter expertise in their product domain, acting as functional level lead for problem investigation and solution design. Understands adjacent product areas and associated business and technical integration dependencies and risks. \n  Uses objective decision making frameworks with well-defined criteria for deciding among a number of valid options, helping structure ambiguity and complexity into clear paths to decision making and forward progress. \n  Demonstrates subject matter expertise and thought leadership in their product and business domain, and advocates compellingly for their point of view. \n  Demonstrates sound, independent decision making in the areas of prioritization, trade-offs, upward/outward communication, expectation setting, etc. \n  Communicates effectively with stakeholders who may not be familiar with domain - can build frameworks to communicate complex ideas to unfamiliar audiences. \n  Proactively defines appropriate communication mechanisms, like reporting and status updates, for their domain and ensures follow-through. \n  Can lead and/or facilitate cross-functional interactions with varying audiences. Clearly defines purpose and objectives and drives towards them. \n  Builds influential relationships with senior partners and stakeholders (Directors, VPs) and can persuade cross-functional teams to accept required work to achieve desired goals. \n  Able to effectively influence across teams to create shared alignment for vision and goals, key requirements, overall prioritization, and timing. \n  Drives technical discussions with development teams, and able to communicate with developers to sanity check their designs. \n  Researches technologies constantly to stay up-to-date with the cutting edge to continuously improve the product in terms of speed and efficiency. \n \n  Technical Tooling: \n \n  Azure Data Factory \n  Python \n  Databricks \n  MSFT Fabric \n  Apache Spark \n  SQL Servers \n  Microservice Architectures \n  Data Warehouses/Data Lakes \n  AI and ML \n  Large Language Models and Natural Language Processing \n \n  Additional Information\n   Please note : Although this is a Remote / Virtual / Work-From-Home career opportunity, candidates  MUST  reside, and be authorized to work without sponsorship, in the US. \n  We are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. \n  #LI-JH1 \n  #REMOTE \n  Base Salary Pay Range*: USD $135,300 \u2013 USD $194,700 \n \n The current applicable Base Salary Pay Range for this role is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills relevant to the role, internal equity, alignment with market data, or other law.  \n \n Other Compensation / Benefit Overview \n  In addition to Base Salary, the successful candidate may be eligible to participate in the following plans / programs, upon satisfying all hiring requirements: \n \n  Bonus Plan \n  Medical, Dental and Vision Coverage \n  Life Insurance and Disability Programs \n  Retirement Savings with Company Match \n  Paid Time Off \n  Flexible Work Arrangements including Remote Work \n \n \n  Beware of scams \n  Our recruiting team may communicate with candidates via our @hitachisolutions.com domain email address and/or via our SmartRecruiters (Applicant Tracking System) notification@smartrecruiters.com domain email address regarding your application and interview requests. \n  All offers will originate from our @hitachisolutions.com domain email address. If you receive an offer or information from someone purporting to be an employee of Hitachi Solutions from any other domain, it may not be legitimate.",
        "cleaned_desc": "  Execute. This means being constantly biased towards action, knowing the data, being in the details, setting a high bar and building strong collaborative relationships with other teams, thinking boldly, disambiguating, always thinking of the customer first, and rapidly iterating towards something demonstrably awesome. \n  Creates a culture of self-reflection and actively seeks out two-way feedback within their team and direct stakeholder group. \n  Participates in the interview process and applies a consistently high bar with well-articulated feedback. \n  Achieves proper balance between taking direct ownership for work versus creating leverage through effective vision setting and delegation. \n  Sets ambitious but realistic goals, and productively challenges others to do the same. \n  Re-frames problems in outcome-oriented terms and identifies creative solutions that optimize speed-to-value while setting up for long-term sustainability. \n  Regularly identifies, experiments with, and implements new practices and processes that improve team performance. \n  Autonomously leads cross-functional delivery for the broad business strategy they are accountable for and aligns around OKRs to achieve key business outcomes. \n  Regularly reflects on and revises priorities to ensure optimal overall value delivery. Creates focus for team(s) and sets boundaries with stakeholders as needed across cross-functional initiatives. \n  Leads definition of 12 - 15 month vision for one or more roadmaps with technical and non-technical stakeholders. \n  Demonstrates deep subject matter expertise in their product domain, acting as functional level lead for problem investigation and solution design. Understands adjacent product areas and associated business and technical integration dependencies and risks. \n  Uses objective decision making frameworks with well-defined criteria for deciding among a number of valid options, helping structure ambiguity and complexity into clear paths to decision making and forward progress. \n  Demonstrates subject matter expertise and thought leadership in their product and business domain, and advocates compellingly for their point of view. \n  Demonstrates sound, independent decision making in the areas of prioritization, trade-offs, upward/outward communication, expectation setting, etc. \n  Communicates effectively with stakeholders who may not be familiar with domain - can build frameworks to communicate complex ideas to unfamiliar audiences. \n  Proactively defines appropriate communication mechanisms, like reporting and status updates, for their domain and ensures follow-through. \n  Can lead and/or facilitate cross-functional interactions with varying audiences. Clearly defines purpose and objectives and drives towards them. \n  Builds influential relationships with senior partners and stakeholders (Directors, VPs) and can persuade cross-functional teams to accept required work to achieve desired goals.    Able to effectively influence across teams to create shared alignment for vision and goals, key requirements, overall prioritization, and timing. \n  Drives technical discussions with development teams, and able to communicate with developers to sanity check their designs. \n  Researches technologies constantly to stay up-to-date with the cutting edge to continuously improve the product in terms of speed and efficiency. \n \n  Technical Tooling: \n \n  Azure Data Factory \n  Python \n  Databricks \n  MSFT Fabric \n  Apache Spark \n  SQL Servers \n  Microservice Architectures \n  Data Warehouses/Data Lakes \n  AI and ML \n  Large Language Models and Natural Language Processing \n \n  Additional Information",
        "techs": [
            "azure data factory",
            "python",
            "databricks",
            "msft fabric",
            "apache spark",
            "sql servers",
            "microservice architectures",
            "data warehouses/data lakes",
            "ai and ml",
            "large language models",
            "natural language processing"
        ],
        "cleaned_techs": [
            "azure",
            "python",
            "databricks",
            "msft fabric",
            "apache spark",
            "sql",
            "microservice architectures",
            "data warehouses/data lakes",
            "ai",
            "large language models",
            "nlp"
        ]
    },
    "583cc0acc8ab6d92": {
        "terms": [
            "data science"
        ],
        "salary_min": 79569.125,
        "salary_max": 100752.234,
        "title": "Senior Product Analyst, Growth",
        "company": "Jerry",
        "desc": "We'd love to hear from you if you like: \n \n  Making a big impact with a Forbes Top Startup Employer \n  Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category) \n  Solving problems in a huge market ($2T market size) \n  Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc. \n \n \n  About the opportunity: \n  We are looking for a Senior Product Analyst to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models. \n \n  Reporting to our VP of Business Operations and Analytics, you will leverage data to drive growth and retention for one of our emerging product groups (car maintenance marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap. Working with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will play a big role in accelerating our growth and taking our customer experience to the next level. \n \n  How you will make an impact: \n \n  Partner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product  \n Design, run, and analyze A/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps \n  Build key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams \n  Transform and refine raw production data for analytical needs \n  Continually improve our data governance and data consistency standards within our database \n  Work with data engineering team on data tracking, integrity, and security as needed \n  Work with other data scientists to evolve, optimize and integrate machine learning models \n \n \n  Who you are: \n \n  Intellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions. \n  Creative problem-solver: No challenge is too complex, no issue is too hard. \n  Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited. \n  Strong communicator: Able to drive alignment and communicate effectively to different audiences. \n \n \n  Ideal profile: \n \n  Bachelor\u2019s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline \n  2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment \n  Experience designing and implementing A/B tests, and analyzing user experience \n  Hands-on experience with SQL (advanced proficiency) \n \n \n  Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.  \n \n Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at  recruiting@getjerry.com \n \n  About Jerry: \n  Jerry is America\u2019s first and only AllCar app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets. \n \n  Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all. \n \n  We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u2014 and we\u2019re just getting started. \n \n  Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing. \n \n  Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u2019s disrupting a massive market.",
        "cleaned_desc": " \n \n  Ideal profile: \n \n  Bachelor\u2019s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline \n  2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment \n  Experience designing and implementing A/B tests, and analyzing user experience \n  Hands-on experience with SQL (advanced proficiency) \n \n ",
        "techs": [
            "sql"
        ],
        "cleaned_techs": [
            "sql"
        ]
    },
    "23c1d41a71cbe507": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 235000.0,
        "salary_max": 256000.0,
        "title": "Staff Software Engineer - Machine Learning Platform",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a voice, video, and text communication service company to hire a Staff Software Engineer - Machine Learning Platform. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n The ML Platform team is the foundation of ML and Data Science at the company. Our aim is to create the best experience throughout the machine learning workflow, from training to serving. We supplement our platform by building core and widely applicable datasets, models, and services, all to help our users find belonging in a safe and welcoming space. \n You will build the Machine Learning platform at the company, working with everything from feature stores, real-time data processing, LLM tooling, to model serving at scale. You will lead projects and work directly with ML practitioners. You have experience building Machine Learning Platforms, putting Machine Learning into production, and an understanding of ML models and techniques. You will report to the Engineering Manager of the ML Platform team. This is a great chance to help take machine learning into new and exciting areas to the benefit of our 150M users. \n What you'll do \n \n Design and build the platform ML engineers and data scientists use to understand and delight the company's users and keep them safe. \n Evaluate and integrate new machine learning frameworks and tools to ensure that the company keeps up with the fast moving world of ML, including LLMs and generative AI \n Collaborate with model builders to ensure we have a smooth path from idea to production \n Set best practices in machine learning at the company \n Create foundational datasets and models \n \n What you should have \n \n 8+ years of experience working as a software engineer in data or backend with exposure to large datasets or distributed systems \n 4+ years working on platforms or infrastructure \n 2+ years working on machine learning platforms \n You have experience with orchestration systems (such as Airflow, Dagster, or Argo) \n You have put machine learning models into production \n \n Bonus Points \n \n Experience with real-time data processing (Spark, Flink, Dataflow, Kafka, Pulsar, etc.) \n Experience debugging and maintaining live production systems on Kubernetes \n Experience building ML models in TensorFlow or PyTorch \n \n The US base salary range for this full-time position is $235,000 to $256,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits. #buildbelonging #LI-Remote #LI-Hybrid #LI-WK1 \n Job Type: Full-time \n Pay: $235,000.00 - $256,000.00 per year \n Schedule: \n \n Monday to Friday \n \n Work Location: Hybrid remote in San Francisco, CA 94114",
        "cleaned_desc": " \n Design and build the platform ML engineers and data scientists use to understand and delight the company's users and keep them safe. \n Evaluate and integrate new machine learning frameworks and tools to ensure that the company keeps up with the fast moving world of ML, including LLMs and generative AI \n Collaborate with model builders to ensure we have a smooth path from idea to production \n Set best practices in machine learning at the company \n Create foundational datasets and models   \n What you should have \n \n 8+ years of experience working as a software engineer in data or backend with exposure to large datasets or distributed systems \n 4+ years working on platforms or infrastructure \n 2+ years working on machine learning platforms   You have experience with orchestration systems (such as Airflow, Dagster, or Argo) \n You have put machine learning models into production \n \n Bonus Points \n \n Experience with real-time data processing (Spark, Flink, Dataflow, Kafka, Pulsar, etc.) ",
        "techs": [
            "airflow",
            "dagster",
            "argo",
            "spark",
            "flink",
            "dataflow",
            "kafka",
            "pulsar"
        ],
        "cleaned_techs": [
            "airflow",
            "dagster",
            "argo",
            "spark",
            "flink",
            "dataflow",
            "kafka",
            "pulsar"
        ]
    },
    "4dda8f81b3440193": {
        "terms": [
            "data science"
        ],
        "salary_min": 114847.41,
        "salary_max": 145422.4,
        "title": "Senior Statistical Programmer",
        "company": "Katalyst Healthcares & Life Sciences Inc",
        "desc": "Responsibilities: \n \n Oversee programming activities outsourced to CROs, including development of SDTM, ADaM datasets, TFLs and other clinical data products. \n Ensure data outputs meet protocol and SAP specifications and comply with regulatory guidelines and CDISC standards. Secure their timely delivery per timeline and agreement. \n Write validation programs with SAS or R and perform rigorous quality checks to ensure accuracy and consistency. \n Communicate discrepancies or issues with internal study teams and CROs to address and resolve them in a timely manner. \n Develop statistical programs with SAS or R to generate datasets and TFL outputs to support ad hoc statistical analysis and regulatory reports such as DSUR and IB. \n Maintain clear and detailed documentation of associated programming activities. \n Hands-on experience with SDTM, ADaM datasets, and TFL production and validation for clinical data. \n Experiences with early-phase clinical trial development and CRO oversight are preferred \n Understands and conducts work consistent with GCP, ICH, 21 CFR part 11, internal SOPs and training, and international regulatory requirements. \n \n Requirements: \n \n Bachelor's degree in computer science, Statistics, Engineering or Life Sciences related field. \n Minimum 4-5 years of experience in statistical programming within the pharmaceutical or clinical research industry. \n Thorough documentation keeping \n Team player; comfortable and effective in a collaborative research environment \n ISS/Client safety & efficacy experience is required. \n Experience creating define.xml and experience with Pinnacle 21 and specifications. \n SAS Certified Base and/or Advance Programmer experience is preferred. \n Proven experience in SAS programming including base SAS, SAS/Stat, SAS/Graph, macros, ODS. \n Strong organizational and time-management skills \n Excellent written and oral communication skills \n \n Job Type: Contract \n Experience level: \n \n 4 years \n \n Schedule: \n \n Day shift \n Monday to Friday \n \n Experience: \n \n Informatica: 1 year (Preferred) \n SQL: 1 year (Preferred) \n Data warehouse: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Responsibilities: \n \n Oversee programming activities outsourced to CROs, including development of SDTM, ADaM datasets, TFLs and other clinical data products. \n Ensure data outputs meet protocol and SAP specifications and comply with regulatory guidelines and CDISC standards. Secure their timely delivery per timeline and agreement. \n Write validation programs with SAS or R and perform rigorous quality checks to ensure accuracy and consistency. \n Communicate discrepancies or issues with internal study teams and CROs to address and resolve them in a timely manner. \n Develop statistical programs with SAS or R to generate datasets and TFL outputs to support ad hoc statistical analysis and regulatory reports such as DSUR and IB. \n Maintain clear and detailed documentation of associated programming activities.   Hands-on experience with SDTM, ADaM datasets, and TFL production and validation for clinical data. \n Experiences with early-phase clinical trial development and CRO oversight are preferred \n Understands and conducts work consistent with GCP, ICH, 21 CFR part 11, internal SOPs and training, and international regulatory requirements. \n \n Requirements: \n \n Bachelor's degree in computer science, Statistics, Engineering or Life Sciences related field. \n Minimum 4-5 years of experience in statistical programming within the pharmaceutical or clinical research industry.   Thorough documentation keeping \n Team player; comfortable and effective in a collaborative research environment \n ISS/Client safety & efficacy experience is required. \n Experience creating define.xml and experience with Pinnacle 21 and specifications. \n SAS Certified Base and/or Advance Programmer experience is preferred. \n Proven experience in SAS programming including base SAS, SAS/Stat, SAS/Graph, macros, ODS. \n Strong organizational and time-management skills \n Excellent written and oral communication skills ",
        "techs": [
            "cros",
            "sdtm",
            "adam datasets",
            "tfls",
            "sap",
            "regulatory guidelines",
            "cdisc standards",
            "sas",
            "r",
            "validation programs",
            "quality checks",
            "study teams",
            "statistical programs",
            "datasets",
            "tfl outputs",
            "dsur",
            "ib",
            "documentation",
            "early-phase clinical trial development",
            "cro oversight",
            "gcp",
            "ich",
            "21 cfr part 11",
            "sops",
            "international regulatory requirements",
            "computer science",
            "statistics",
            "engineering",
            "life sciences",
            "pharmaceutical",
            "clinical research industry",
            "documentation keeping",
            "team player",
            "collaborative research environment",
            "iss/client safety & efficacy",
            "define.xml",
            "pinnacle 21",
            "sas certified base",
            "advance programmer",
            "base sas",
            "sas/stat",
            "sas/graph",
            "macros",
            "ods",
            "organizational skills",
            "time-management skills",
            "written communication skills",
            "oral communication skills."
        ],
        "cleaned_techs": [
            "cros",
            "sdtm",
            "adam datasets",
            "tfls",
            "sap",
            "cdisc standards",
            "sas",
            "r",
            "validation programs",
            "quality checks",
            "study teams",
            "statistical programs",
            "datasets",
            "tfl outputs",
            "dsur",
            "ib",
            "early-phase clinical trial development",
            "cro oversight",
            "gcp",
            "ich",
            "21 cfr part 11",
            "sops",
            "computer science",
            "statistics",
            "engineering",
            "life sciences",
            "pharmaceutical",
            "clinical research industry",
            "team player",
            "collaborative research environment",
            "iss/client safety & efficacy",
            "define.xml",
            "pinnacle 21",
            "advance programmer",
            "base sas",
            "macros",
            "ods"
        ]
    },
    "cbfebca3458e08ec": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Commercial Account Executive",
        "company": "Anaconda",
        "desc": "Role: Commercial Account Executive \n  Department: Sales \n  Location: Remote, US & EMEA \n  Job Type: Full Time, Exempt \n  Help us Deliver Technology for Human Sensemaking \n  Anaconda is the world's most popular data science platform. With more than 20 million users, the open source Anaconda Distribution is the easiest way to do data science and machine learning. We pioneered the use of Python for data science, champion its vibrant community, and continue to steward open-source projects that make tomorrow's innovations possible. Our enterprise-grade solutions enable corporate, research, and academic institutions around the world to harness the power of open source for competitive advantage and groundbreaking research. \n  Anaconda is seeking people who want to play a role in shaping the future of enterprise machine learning, and data science. Candidates should be knowledgeable and capable, but always eager to learn more and to teach others. Overall, we strive to create a culture of ability and humility and an environment that is both relaxed and focused. We stress empathy and collaboration with our customers, open-source users, and each other. \n  Here is why people love most about working here: We're not just a company, we're part of a movement. Our dedicated employees and user community are democratizing data science and creating and promoting open-source technologies for a better world, and our commercial offerings make it possible for enterprise users to leverage the most innovative output from open source in a secure, governed way. \n  Summary \n  Anaconda is seeking a talented Commercial Account Executive II to join our rapidly-growing company. This is an excellent opportunity for you to leverage skills and apply it to the world of data science and machine learning. This role is an intermediate level sales role and we are looking for motivated enthusiastic candidates that have B2B selling experience in a SaaS start-up environment. \n  What You'll Do: \n \n Manage and follow up with leads, manage prospects, and acquire new business in assigned territory for SMB market through cold calling/ outbound reach \n Develop and maintain a thorough knowledge of company products and pricing structure \n Utilize Salesforce.com for scheduling, pipeline reporting, developing prospective customer profiles and documenting all sales-related activities \n Accurately and consistently forecast business in SFDC \n Maintain up-to-date and accurate account/opportunity information \n Account planning and forecasting for SMB accounts \n Calendar and meeting management \n Prospecting and closing to meet or exceed sales/revenue goals for assigned territory \n Participate in hand off calls with implementation \n \n What You Need: \n \n 2+ years of B2B technology sales experience \n Proven record of closing business \n Strong writing and communication skills \n Ability to learn and assimilate technical information quickly \n Demonstrated flexibility, organization, and driven \n Experience using Salesforce for managing pipeline \n \n What Will Make You Stand Out: \n \n Data science related software selling experience \n Start up experience \n Technical sales experience specific to AI/Machine Learning \n \n \n \n  Why You'll Like Working Here: \n \n Unique opportunity to translate strong open source adoption and user enthusiasm into commercial product growth \n Dynamic company that rewards high performers \n On the cutting edge of enterprise application of data science, machine learning and AI \n Collaborative team environment that values multiple perspectives and clear thinking \n Employees-first culture \n Flexible working hours \n Medical*, Dental*, Vision*, HSA*, Life* and 401K* \n Health and Remote working reimbursement \n Paid parental leave - both parents \n Pre-IPO stock options \n Open vacation policy* \n 100% remote and flexible working policy \u2013 we embrace this fully through how we operate as a company. \n \n \n FTE employees based on your region \n \n  An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. \n  Anaconda, Inc. (\"We\", \"Us\") are committed to protecting and respecting your privacy. This Privacy Notice sets out the basis on which the personal data collected from you, or that you provide to Us, will be processed by Us in connection with Our recruitment processes. By clicking \"Submit Application\", you acknowledge you have read our Privacy Policy and that Anaconda can retain your application data for up to 1-year, unless otherwise stated. For the purpose of the General Data Protection Regulation (\"GDPR\") \") and the version of the GDPR retained in UK law (the \"UK GDPR\") the Data Controller is Sydney Artt.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "5ccd8664d9aaf063": {
        "terms": [
            "data science"
        ],
        "salary_min": 120675.25,
        "salary_max": 152801.75,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join us as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n NXBIwICHp8",
        "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ",
        "techs": [
            "python",
            "deep learning",
            "tensorflow"
        ],
        "cleaned_techs": [
            "python",
            "tensorflow"
        ]
    },
    "f0c7a1d7fa596801": {
        "terms": [
            "data science"
        ],
        "salary_min": 120675.25,
        "salary_max": 152801.75,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n WNwk9HRMej",
        "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ",
        "techs": [
            "python",
            "deep learning",
            "tensorflow"
        ],
        "cleaned_techs": [
            "python",
            "tensorflow"
        ]
    },
    "ad77c75ef63d9efa": {
        "terms": [
            "data science"
        ],
        "salary_min": 137241.16,
        "salary_max": 173777.88,
        "title": "Principal Statistical Programmer (Oncology)",
        "company": "Statistics & Data Corporation (SDC)",
        "desc": "SDC is a team of diversified professionals who deliver exceptional Biometric Services, Consulting, and Technology Solutions to pharmaceutical, biologic, and medical device/diagnostic companies. Since 2005 our purpose has been to partner with sponsors to provide high-quality and experienced team members to develop great medicines that save lives and cure diseases in the most efficient manner possible. Our global team operates as a valued partner to our clients by fulfilling their needs as our own and delivering exceptional results. We are a specialty CRO in that we provide scalable service offerings, focused services area specialists, efficient project timelines, optimal technology solutions, and proven success and experience. Our commitment to our clients is the same commitment to our employees. By offering strong benefits including competitive pay, generous time off, attainable career advances, positive work/life balance, and 401k matching (US), we are able to attract some of the most talented people in the industry. \n  This person will provide statistical programming support to clinical trials. Produce statistical analyses, including generating/validating analysis datasets, tables, listings, and figures for clinical trials. Create SDTM mapping and datasets. Develop and maintain the infrastructure for project files of SAS datasets and SAS code. Support Data Management in data set creations/transfers, integrity checks, and quality audits. Act as a liaison between clinical and subcommittees and project teams on an as-needed basis. \n \n  ***Candidates must reside in Arizona or along the east costal line in US*** \n  Recruiting agencies, please do not submit unsolicited referrals for this or any open role. We have established agency partnerships, and we will not pay any fee associated with unsolicited referrals.     \n #LI-Remote \n  Primary Responsibilities \n \n Perform or oversee team in performing all statistical programming required for clinical trial analysis and reporting on large scale projects of high complexity \n Apply appropriate statistical methods for data analysis and provide statistical programming expertise for project teams \n Review the Statistical Analysis Plan in preparation for programming the planned analyses \n Lead design/development of SAS macros and other utilities to expedite SAS programming activities \n Organize and conduct internal training sessions and author papers for conferences \n Generate tables, listings, and figures per protocol, Statistical Analysis Plan, and/or approved client request \n Participate in statistical program validation and quality control activities \n Develop or review SDTM aCRF and specifications, ADaM specifications; complete programming and validation of CDISC SDTM and ADaM datasets \n Review pinnacle 21 reports and ensure compliance with CDISC and FDA guidelines \n Develop define.xml, study data reviewers guide and analysis datasets reviewers guide \n Identify study priorities and communicate effectively with project team and management \n Ensure quality, proper documentation and meet or exceed timely completion of the project within budgeted hours \n Manage statistical programming timelines, budgets, and client expectations \n Actively participate in study team meetings \n Interact with other departments, such as Clinical Operations, Project Management, and Data Management to ensure a high level of client satisfaction through successful execution of projects \n Participate in review process of study documents such as the CRF, edit check specifications, and database design specifications written by Data Management \n Program data cleaning checks, as necessary, to assist Data Management\u2019s data cleaning activities \n Participate in installation/validation of statistical software packages throughout the software development lifecycle \n Develop and maintain the infrastructure for project files of SAS datasets and SAS code \n Mentor junior level statistical programmers by developing training plans and providing oversight of their work \n Ensure all programming activities and processes performed are conducted according to SDC\u2019s standard procedures and/or sponsor requirements \n Contribute to the development of standard operating procedures for statistical programming. \n \n Requirements \n \n Strong analytical skills, with the ability to process scientific and medical data. \n Very strong SAS programming skills required, with proficiency in SAS/Base, SAS/Stat, SAS Macros and SAS/Graph \n Strong problem-solving skills \n Able to work independently \n Excellent knowledge of statistical programming \n Proficient in manipulating and analyzing SAS data \n Ability to identify data issues, present problems, and implement solutions quickly \n Capability of communicating technical concepts clearly, concisely, and understandably to non-statistical colleagues \n Good organizational and time management skills, with the ability to multi-task \n Familiarity with clinical trial design and analysis activities and basic knowledge of regulatory guidelines (FDA/CFR, ICH/GCP). Expert knowledge of CDISC SDTM and ADaM data models \n Very strong interpersonal communication, presentation, and leadership skills \n SAS Base, Advance and Clinical Trials Certification is preferred \n \n Education or Equivalent Experience \n \n  Bachelor\u2019s degree in computer science, statistics or other related, scientific field and at least eight years of relevant professional experience; or an equivalent combination of relevant education and/or experience. \n \n  Benefits \n  What you can expect from us: \n \n We are committed to developing our employees. We recognize achievements, provide growth opportunities and career advancement, and offer a flexible work schedule, engaging work culture, and employee benefits. \n We are passionate about our company culture. Our recognition program is directly tied to our core values of Energy, Integrity, Engagement, Innovation, Ownership, and Commitment. \n We strive to provide a place of belonging to our employees with fun and engaging activities from SDC\u2019s culture club. \n We constantly grow and innovate to support our clients and employees' needs. Global in nature, we bring diverse perspectives enabling our growth in this ever-evolving industry. \n With a proven track record, SDC has successfully executed client clinical programs since 2005. \n Health Care Plan (Medical, Dental & Vision) \n Retirement Plan (401k) \n Life Insurance (Basic, Voluntary & AD&D) \n Paid Time Off (Vacation, Sick & Public Holidays) \n Family Leave (Maternity, Paternity) \n Short-Term & Long-Term Disability \n Training & Development \n Work From Home \n Profit based incentive",
        "cleaned_desc": " Generate tables, listings, and figures per protocol, Statistical Analysis Plan, and/or approved client request \n Participate in statistical program validation and quality control activities \n Develop or review SDTM aCRF and specifications, ADaM specifications; complete programming and validation of CDISC SDTM and ADaM datasets \n Review pinnacle 21 reports and ensure compliance with CDISC and FDA guidelines \n Develop define.xml, study data reviewers guide and analysis datasets reviewers guide \n Identify study priorities and communicate effectively with project team and management \n Ensure quality, proper documentation and meet or exceed timely completion of the project within budgeted hours \n Manage statistical programming timelines, budgets, and client expectations \n Actively participate in study team meetings \n Interact with other departments, such as Clinical Operations, Project Management, and Data Management to ensure a high level of client satisfaction through successful execution of projects \n Participate in review process of study documents such as the CRF, edit check specifications, and database design specifications written by Data Management \n Program data cleaning checks, as necessary, to assist Data Management\u2019s data cleaning activities \n Participate in installation/validation of statistical software packages throughout the software development lifecycle   Develop and maintain the infrastructure for project files of SAS datasets and SAS code \n Mentor junior level statistical programmers by developing training plans and providing oversight of their work \n Ensure all programming activities and processes performed are conducted according to SDC\u2019s standard procedures and/or sponsor requirements \n Contribute to the development of standard operating procedures for statistical programming. \n \n Requirements \n \n Strong analytical skills, with the ability to process scientific and medical data. \n Very strong SAS programming skills required, with proficiency in SAS/Base, SAS/Stat, SAS Macros and SAS/Graph \n Strong problem-solving skills \n Able to work independently \n Excellent knowledge of statistical programming \n Proficient in manipulating and analyzing SAS data   Ability to identify data issues, present problems, and implement solutions quickly \n Capability of communicating technical concepts clearly, concisely, and understandably to non-statistical colleagues \n Good organizational and time management skills, with the ability to multi-task \n Familiarity with clinical trial design and analysis activities and basic knowledge of regulatory guidelines (FDA/CFR, ICH/GCP). Expert knowledge of CDISC SDTM and ADaM data models \n Very strong interpersonal communication, presentation, and leadership skills \n SAS Base, Advance and Clinical Trials Certification is preferred \n \n Education or Equivalent Experience \n \n  Bachelor\u2019s degree in computer science, statistics or other related, scientific field and at least eight years of relevant professional experience; or an equivalent combination of relevant education and/or experience. \n \n  Benefits \n  What you can expect from us: ",
        "techs": [
            "generate tables",
            "listings",
            "and figures per protocol",
            "statistical analysis plan",
            "and/or approved client request,\nparticipate in statistical program validation and quality control activities,\ndevelop or review sdtm acrf and specifications",
            "adam specifications; complete programming and validation of cdisc sdtm and adam datasets,\nreview pinnacle 21 reports and ensure compliance with cdisc and fda guidelines,\ndevelop define.xml",
            "study data reviewers guide and analysis datasets reviewers guide,\nidentify study priorities and communicate effectively with project team and management,\nensure quality",
            "proper documentation and meet or exceed timely completion of the project within budgeted hours,\nmanage statistical programming timelines",
            "budgets",
            "and client expectations,\nactively participate in study team meetings,\ninteract with other departments",
            "such as clinical operations",
            "project management",
            "and data management to ensure a high level of client satisfaction through successful execution of projects,\nparticipate in review process of study documents such as the crf",
            "edit check specifications",
            "and database design specifications written by data management,\nprogram data cleaning checks",
            "as necessary",
            "to assist data management\u2019s data cleaning activities,\nparticipate in installation/validation of statistical software packages throughout the software development lifecycle,\ndevelop and maintain the infrastructure for project files of sas datasets and sas code,\nmentor junior level statistical programmers by developing training plans and providing oversight of their work,\ncontribute to the development of standard operating procedures for statistical programming,\nstrong analytical skills",
            "with the ability to process scientific and medical data,\nvery strong sas programming skills required",
            "with proficiency in sas/base",
            "sas/stat",
            "sas macros and sas/graph,\nstrong problem-solving skills,\nable to work independently,\nexcellent knowledge of statistical programming,\nproficient in manipulating and analyzing sas data,\nability to identify data issues",
            "present problems",
            "and implement solutions quickly,\ncapability of communicating technical concepts clearly",
            "concisely",
            "and understandably to non-statistical colleagues,\ngood organizational and time management skills",
            "with the ability to multi-task,\nfamiliarity with clinical trial design and analysis activities and basic knowledge of regulatory guidelines (fda/cfr",
            "ich/gcp). expert knowledge of cdisc sdtm and adam data models,\nvery strong interpersonal communication",
            "presentation",
            "and leadership skills,\nsas base",
            "advance and clinical trials certification is preferred",
            "\nbachelor\u2019s degree in computer science",
            "statistics or other related",
            "scientific field and at least eight years of relevant professional experience; or an equivalent combination of relevant education and/or experience."
        ],
        "cleaned_techs": [
            "generate tables",
            "listings",
            "and figures per protocol",
            "statistical analysis plan",
            "and/or approved client request,\nparticipate in statistical program validation and quality control activities,\ndevelop or review sdtm acrf and specifications",
            "adam specifications; complete programming and validation of cdisc sdtm and adam datasets,\nreview pinnacle 21 reports and ensure compliance with cdisc and fda guidelines,\ndevelop define.xml",
            "study data reviewers guide and analysis datasets reviewers guide,\nidentify study priorities and communicate effectively with project team and management,\nensure quality",
            "budgets",
            "and client expectations,\nactively participate in study team meetings,\ninteract with other departments",
            "such as clinical operations",
            "project management",
            "and data management to ensure a high level of client satisfaction through successful execution of projects,\nparticipate in review process of study documents such as the crf",
            "edit check specifications",
            "and database design specifications written by data management,\nprogram data cleaning checks",
            "as necessary",
            "with proficiency in sas/base",
            "sas",
            "present problems",
            "and implement solutions quickly,\ncapability of communicating technical concepts clearly",
            "concisely",
            "ich/gcp). expert knowledge of cdisc sdtm and adam data models,\nvery strong interpersonal communication",
            "presentation",
            "advance and clinical trials certification is preferred",
            "statistics or other related",
            "scientific field and at least eight years of relevant professional experience; or an equivalent combination of relevant education and/or experience."
        ]
    },
    "c6b53fae5abb3f20": {
        "terms": [
            "data science"
        ],
        "salary_min": 135300.0,
        "salary_max": 194700.0,
        "title": "Senior Technical Product Manager",
        "company": "Hitachi Solutions Ltd",
        "desc": "Company Description \n \n \n Company Overview \n \n  Hitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering innovative cloud solutions to help our clients innovative across their entire business. Our firm develops the business services and technology powering some of the products you use every day - and is closely aligned with Microsoft and other leaders in the cloud computing space.\n  \n  What sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers. Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike - helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion. With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.\n  \n  A part of Hitachi Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world's largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\n  \n  This is a high-visibility, full-time role in our Empower Product Group for professionals with a proven history of execution, and a desire to rapidly expand a product organization.\n  \n \n Job Description \n \n \n Position Overview \n \n  This is a high-visibility, high-impact, full-time role in our Empower Product Group for professionals with a proven history of execution, and a desire to rapidly expand a product organization. Technical acumen and domain experience in data engineering, Azure, SaaS, and Data Analytics are strongly preferred.\n  \n \n Who you are: \n \n \n  Overall:  We would like to see candidates with 5+ years experience in Product. \n \n \n  Experienced . You have experience building solutions involving data or analytics in product management or similar roles. You have a strong background in enterprise software. \n  Customer and user focused.  You have the ability to put yourself in a users' shoes and understand their needs. You listen closely to all avenues of feedback. You love to be the voice of the customer. \n  Passionate . You love the intersection of building software, deeply understanding customer needs, bringing products to market, and data science technologies. You have strong product and design instincts that inspire confidence. \n  Leader . You inspire trust with team members and can drive change in a positive and productive way. You anticipate problems and mitigate risks. \n  Growth mindset . You enjoy learning new things and see challenges as growth opportunities. You excel at mastering technical products and being the go-to person in your domain. \n  Strong communicator . You are comfortable representing your team & product, presenting vision & priorities to internal stakeholders, customers, and partners. You enjoy speaking opportunities and have a proven experience presenting to large teams and leadership. \n  Data Enthusiast . You have a strong desire to help people see and understand data. \n  A Ruthless Prioritizer . You treat time as a team's most valuable asset. \n  Entrepreneurial . You solve problems for your customers while jumping on opportunities to strategically add new lines of business. \n  Technical Focus . You have experience with technical work, having been a developer yourself in a former role or by having deep experience with developers and learning technologies they use. \n \n \n  Qualifications \n \n \n Your responsibilities: \n \n \n  Execute. This means being constantly biased towards action, knowing the data, being in the details, setting a high bar and building strong collaborative relationships with other teams, thinking boldly, disambiguating, always thinking of the customer first, and rapidly iterating towards something demonstrably awesome. \n  Creates a culture of self-reflection and actively seeks out two-way feedback within their team and direct stakeholder group. \n  Participates in the interview process and applies a consistently high bar with well-articulated feedback. \n  Achieves proper balance between taking direct ownership for work versus creating leverage through effective vision setting and delegation. \n  Sets ambitious but realistic goals, and productively challenges others to do the same. \n  Re-frames problems in outcome-oriented terms and identifies creative solutions that optimize speed-to-value while setting up for long-term sustainability. \n  Regularly identifies, experiments with, and implements new practices and processes that improve team performance. \n  Autonomously leads cross-functional delivery for the broad business strategy they are accountable for and aligns around OKRs to achieve key business outcomes. \n  Regularly reflects on and revises priorities to ensure optimal overall value delivery. Creates focus for team(s) and sets boundaries with stakeholders as needed across cross-functional initiatives. \n  Leads definition of 12 - 15 month vision for one or more roadmaps with technical and non-technical stakeholders. \n  Demonstrates deep subject matter expertise in their product domain, acting as functional level lead for problem investigation and solution design. Understands adjacent product areas and associated business and technical integration dependencies and risks. \n  Uses objective decision making frameworks with well-defined criteria for deciding among a number of valid options, helping structure ambiguity and complexity into clear paths to decision making and forward progress. \n  Demonstrates subject matter expertise and thought leadership in their product and business domain, and advocates compellingly for their point of view. \n  Demonstrates sound, independent decision making in the areas of prioritization, trade-offs, upward/outward communication, expectation setting, etc. \n  Communicates effectively with stakeholders who may not be familiar with domain - can build frameworks to communicate complex ideas to unfamiliar audiences. \n  Proactively defines appropriate communication mechanisms, like reporting and status updates, for their domain and ensures follow-through. \n  Can lead and/or facilitate cross-functional interactions with varying audiences. Clearly defines purpose and objectives and drives towards them. \n  Builds influential relationships with senior partners and stakeholders (Directors, VPs) and can persuade cross-functional teams to accept required work to achieve desired goals. \n  Able to effectively influence across teams to create shared alignment for vision and goals, key requirements, overall prioritization, and timing. \n  Drives technical discussions with development teams, and able to communicate with developers to sanity check their designs. \n  Researches technologies constantly to stay up-to-date with the cutting edge to continuously improve the product in terms of speed and efficiency. \n \n \n  Technical Tooling: \n \n \n  Azure Data Factory \n  Python \n  Databricks \n  MSFT Fabric \n  Apache Spark \n  SQL Servers \n  Microservice Architectures \n  Data Warehouses/Data Lakes \n  AI and ML \n  Large Language Models and Natural Language Processing \n \n \n  Additional Information \n \n \n Please note \n : Although this is a Remote / Virtual / Work-From-Home career opportunity, candidates MUST reside, and be authorized to work without sponsorship, in the US. \n \n \n We are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. \n \n \n #LI-JH1 \n \n \n #REMOTE \n \n \n Base Salary Pay Range*: USD $135,300 - USD $194,700 \n \n \n \n The current applicable Base Salary Pay Range for this role is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills relevant to the role, internal equity, alignment with market data, or other law.  \n \n \n Other Compensation / Benefit Overview \n \n  In addition to Base Salary, the successful candidate may be eligible to participate in the following plans / programs, upon satisfying all hiring requirements:\n  \n \n  Bonus Plan \n  Medical, Dental and Vision Coverage \n  Life Insurance and Disability Programs \n  Retirement Savings with Company Match \n  Paid Time Off \n  Flexible Work Arrangements including Remote Work \n \n \n  Beware of scams \n \n  Our recruiting team may communicate with candidates via our @hitachisolutions.com domain email address and/or via our SmartRecruiters (Applicant Tracking System) notification@smartrecruiters.com domain email address regarding your application and interview requests. \n  \n  All offers will originate from our @hitachisolutions.com domain email address. If you receive an offer or information from someone purporting to be an employee of Hitachi Solutions from any other domain, it may not be legitimate.",
        "cleaned_desc": "  Participates in the interview process and applies a consistently high bar with well-articulated feedback. \n  Achieves proper balance between taking direct ownership for work versus creating leverage through effective vision setting and delegation. \n  Sets ambitious but realistic goals, and productively challenges others to do the same. \n  Re-frames problems in outcome-oriented terms and identifies creative solutions that optimize speed-to-value while setting up for long-term sustainability. \n  Regularly identifies, experiments with, and implements new practices and processes that improve team performance. \n  Autonomously leads cross-functional delivery for the broad business strategy they are accountable for and aligns around OKRs to achieve key business outcomes. \n  Regularly reflects on and revises priorities to ensure optimal overall value delivery. Creates focus for team(s) and sets boundaries with stakeholders as needed across cross-functional initiatives. \n  Leads definition of 12 - 15 month vision for one or more roadmaps with technical and non-technical stakeholders. \n  Demonstrates deep subject matter expertise in their product domain, acting as functional level lead for problem investigation and solution design. Understands adjacent product areas and associated business and technical integration dependencies and risks. \n  Uses objective decision making frameworks with well-defined criteria for deciding among a number of valid options, helping structure ambiguity and complexity into clear paths to decision making and forward progress. \n  Demonstrates subject matter expertise and thought leadership in their product and business domain, and advocates compellingly for their point of view. \n  Demonstrates sound, independent decision making in the areas of prioritization, trade-offs, upward/outward communication, expectation setting, etc. \n  Communicates effectively with stakeholders who may not be familiar with domain - can build frameworks to communicate complex ideas to unfamiliar audiences. \n  Proactively defines appropriate communication mechanisms, like reporting and status updates, for their domain and ensures follow-through. \n  Can lead and/or facilitate cross-functional interactions with varying audiences. Clearly defines purpose and objectives and drives towards them. \n  Builds influential relationships with senior partners and stakeholders (Directors, VPs) and can persuade cross-functional teams to accept required work to achieve desired goals. \n  Able to effectively influence across teams to create shared alignment for vision and goals, key requirements, overall prioritization, and timing. \n  Drives technical discussions with development teams, and able to communicate with developers to sanity check their designs. \n  Researches technologies constantly to stay up-to-date with the cutting edge to continuously improve the product in terms of speed and efficiency. \n \n \n  Technical Tooling: \n \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "c9e15f9da3c5eb47": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 90974.61,
        "salary_max": 115194.125,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "d54d0963905a24a1": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89087.805,
        "salary_max": 112805.01,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "6308721d3a6b34c2": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89214.33,
        "salary_max": 112965.22,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "f73fd671bf8b4deb": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89049.984,
        "salary_max": 112757.125,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "financial services industry experience",
            "reporting",
            "data analytics",
            "finra series 7",
            "finra series 24",
            "ms sql",
            "ms office",
            "business applications"
        ],
        "cleaned_techs": [
            "financial services industry experience",
            "reporting",
            "data analytics",
            "finra series 7",
            "finra series 24",
            "ms sql",
            "microsoft"
        ]
    },
    "30d569984b497f25": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 89127.51,
        "salary_max": 112855.29,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "605b47cdf9a65567": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 90187.54,
        "salary_max": 114197.52,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "2161de3c9237bbb8": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 88381.64,
        "salary_max": 111910.84,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "finra series 7",
            "series 24",
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "finra series 7",
            "series 24",
            "ms sql",
            "microsoft"
        ]
    },
    "e641233d29e656ea": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 88910.805,
        "salary_max": 112580.9,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office",
            "finra series 7",
            "finra series 24"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft",
            "finra series 7",
            "finra series 24"
        ]
    },
    "6d1059aead2a75c7": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 87601.164,
        "salary_max": 110922.6,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "finra series 7",
            "finra series 24",
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "finra series 7",
            "finra series 24",
            "ms sql",
            "microsoft"
        ]
    },
    "e2bb8a8ced28882b": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 83612.09,
        "salary_max": 105871.55,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "845c5fcc6d10ed41": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 88473.44,
        "salary_max": 112027.08,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "finra series 7",
            "series 24",
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "finra series 7",
            "series 24",
            "ms sql",
            "microsoft"
        ]
    },
    "6592c300c3846f33": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 96005.37,
        "salary_max": 121564.195,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "finra series 7",
            "finra series 24",
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "finra series 7",
            "finra series 24",
            "ms sql",
            "microsoft"
        ]
    },
    "1c24bde49a06be0e": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 150000.0,
        "salary_max": 150000.0,
        "title": "Sr Construction Business Intelligence Analyst",
        "company": "CBRE",
        "desc": "Posted \n      \n \n      27-Oct-2023 \n      \n \n \n \n      Service line \n      \n \n      GWS Segment \n      \n \n \n \n      Role type \n      \n \n      Full-time \n      \n \n \n \n \n \n \n \n \n \n      Areas of Interest \n      \n \n      Data & Analytics \n      \n \n \n \n \n \n \n \n \n \n      Location(s) \n      \n \n      Remote - US - Remote - US - United States of America, San Jose - California - United States of America \n      \n \n \n \n \n \n \n \n \n \n \n       The Senior Construction Business Intelligence Data Analyst is a pivotal role within a Global PMO team, responsible for in-depth data analysis and the delivery of actionable insights. This role supports a Global Project Management Office (PMO) team in managing a vast and rapidly expanding global data center construction portfolio. The ideal candidate is a data analytics expert who excels in working with a diverse range of data sources, including Quickbase, eBuilder, SAP, and Google Suite tools like Google Sheets. The analyst plays a crucial role in supporting portfolio planning, capital planning, creating and maintaining data dashboards, generating timely and insightful data for leadership reporting, and offering valuable insights for strategic decision-making.\n       \n \n \n  What you\u2019ll do\n       \n \n \n  Sophisticated Data Analysis. Apply advanced analytical techniques to conduct prescriptive, diagnostic, descriptive, and predictive data analysis on diverse construction-related data, incorporating data from Quickbase, eBuilder, SAP, and Google Sheets. \n  Dashboard Development: develop and meticulously maintain interactive dashboards that provide real-time insights into construction project data. Ensure these dashboards are user-friendly, intuitive, and deliver vital information to project collaborators. \n  Leadership Reporting: Generate regular and ad-hoc reports for the leadership team, highlighting essential performance indicators, project status, and emerging trends. Translate sophisticated data into practical, actionable insights, incorporating earned value measurement concepts to evaluate project performance. \n  Capital Planning Support: Provide meaningful support for annual capital planning by conducting comprehensive analysis of historical data, project costs, and resource allocation. Offer valuable insights to enhance financial planning and resource allocation. \n  Portfolio Planning Assistance: Collaborate on portfolio planning efforts by identifying optimization opportunities, resource allocation improvements, and strategic direction recommendations. Deliver data-driven insights that guide project decisions and enhance the efficiency of project portfolio management. \n  Data Management: Accept responsibility for managing and maintaining substantial volumes of construction-related data. Ensure data integrity, security, and accessibility, implementing data cleaning and transformation processes as needed. \n  Strategic Forecasting: Develop and maintain strategic forecasts for construction projects, demonstrating data analytics to identify trends and make informed predictions about future outcomes. Incorporate earned value measurement techniques to assess project performance and forecast project completion accurately. \n  Business Intelligence: Provide data-driven insights that support critical business decisions, helping to improve operational efficiency and profitability. Apply program management skills to coordinate and oversee multiple projects, ensuring alignment with broader business goals. \n  Collaboration with Partner Teams: Collaborate closely with other data analysts from partner teams to create a dynamic teamwork and shared insights. Share standard methodologies, work collectively to enhance data-driven decision-making, and align efforts across various projects and portfolios. \n \n \n \n \n \n \n \n \n \n \n \n \n \n       What you\u2019ll need\n       \n \n \n  Bachelor's degree in a relevant field (e.g., Data Science, Business Analytics, Construction Management). \n  A minimum of 10 years of hands-on experience in data analysis, with a preference for candidates with construction industry experience and a background in Project Management Office (PMO) functions. \n  Proficiency in data analytics tools such as Quickbase, eBuilder, SAP, and Google Suite. \n  Expertise in creating and maintaining dashboards using tools like Google Sheets. \n  Demonstrable ability to generate prescriptive, diagnostic, descriptive, and predictive insights from data, applying sophisticated analytics methods. \n  Exceptional problem-solving and critical-thinking skills, with a demonstrated commitment to data-driven decision-making and program management skills. \n  Superb interpersonal skills to convey sophisticated data in a concise and understandable manner, fostering collaboration with partner teams, and ensuring data analysis aligns with broader project and business objectives. \n \n \n \n \n  Preferred:\n       \n \n        PMO experience, preferably in a large construction industry, demonstrating a deep understanding of earned value measurement, portfolio planning, and program management concepts.\n       \n \n        Previous experience working on data center construction projects, with a demonstrable record of chipping in to the successful management of construction portfolios.\n       \n \n \n  Why CBRE?\n       \n \n \n  At CBRE, we believe we possess an encouraging environment where integrity, service, and excellence craft our approach to every opportunity. We are guided by the needs of the cities we inhabit, the communities we build and the world we live in. \n  FORTUNE 500 #12 \n  FORTUNE Most Admired Company #1 in real estate for third consecutive year; Ten years in a row on the list! \n  Forbes Named one of the best large employers in America and one of the World's Best Employers! \n \n \n \n \n \n \n \n \n \n \n \n \n \n       CBRE carefully considers multiple factors to determine compensation, including a candidate\u2019s education, training, and experience. The minimum salary for the Employment Recruiter position is $150,000.00 annually [or $72.11 per hour] and the maximum salary for the Employment Recruiter position is $157,000.00 annually [or $75.48 per hour]. The compensation that is offered to a successful candidate will depend on the candidate\u2019s skills, qualifications, and experience. Successful candidates will also be eligible for a discretionary bonus based on CBRE\u2019s applicable benefit program.\n       \n \n \n \n \n \n \n \n \n \n \n      CBRE is an equal opportunity employer that values diversity. We have a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law. We also provide reasonable accommodations, as needed, throughout the job application process. If you have a disability that inhibits your ability to apply for a position through our online application process, you may contact us via email at recruitingaccommodations@cbre.com or via telephone at +1 866 225 3099 (U.S.) and +1 866 388 4346 (Canada). \n      \n \n \n \n NOTE: Some, but not all, of our positions may have an additional requirement to comply with COVID-19 health and safety protocols, including COVID-19 vaccination proof and/or rigorous testing. If you have questions about the requirement(s) for this position, please inform your Recruiter. \n \n \n \n \n \n \n \n \n \n \n      CBRE GWS \n      \n \n \n \n \n \n \n \n \n \n \n \n        CBRE Global Workplace Solutions (GWS) works with clients to make real estate a meaningful contributor to organizational productivity and performance. Our account management model is at the heart of our client-centric approach to delivering integrated real estate solutions. Each client is entrusted with a dedicated leader and is supported by regional and global resources, leveraging the industry's most robust platform. CBRE GWS delivers consistent, measurably superior outcomes for our clients at every stage of the lifecycle, and across industries and geographies.",
        "cleaned_desc": " \n \n \n \n \n \n \n \n \n      Location(s) \n      \n \n      Remote - US - Remote - US - United States of America, San Jose - California - United States of America \n      \n \n \n \n \n \n \n \n \n \n \n       The Senior Construction Business Intelligence Data Analyst is a pivotal role within a Global PMO team, responsible for in-depth data analysis and the delivery of actionable insights. This role supports a Global Project Management Office (PMO) team in managing a vast and rapidly expanding global data center construction portfolio. The ideal candidate is a data analytics expert who excels in working with a diverse range of data sources, including Quickbase, eBuilder, SAP, and Google Suite tools like Google Sheets. The analyst plays a crucial role in supporting portfolio planning, capital planning, creating and maintaining data dashboards, generating timely and insightful data for leadership reporting, and offering valuable insights for strategic decision-making.\n       \n \n \n  What you\u2019ll do\n       \n \n \n  Sophisticated Data Analysis. Apply advanced analytical techniques to conduct prescriptive, diagnostic, descriptive, and predictive data analysis on diverse construction-related data, incorporating data from Quickbase, eBuilder, SAP, and Google Sheets. \n  Dashboard Development: develop and meticulously maintain interactive dashboards that provide real-time insights into construction project data. Ensure these dashboards are user-friendly, intuitive, and deliver vital information to project collaborators. \n  Leadership Reporting: Generate regular and ad-hoc reports for the leadership team, highlighting essential performance indicators, project status, and emerging trends. Translate sophisticated data into practical, actionable insights, incorporating earned value measurement concepts to evaluate project performance.    Capital Planning Support: Provide meaningful support for annual capital planning by conducting comprehensive analysis of historical data, project costs, and resource allocation. Offer valuable insights to enhance financial planning and resource allocation. \n  Portfolio Planning Assistance: Collaborate on portfolio planning efforts by identifying optimization opportunities, resource allocation improvements, and strategic direction recommendations. Deliver data-driven insights that guide project decisions and enhance the efficiency of project portfolio management. \n  Data Management: Accept responsibility for managing and maintaining substantial volumes of construction-related data. Ensure data integrity, security, and accessibility, implementing data cleaning and transformation processes as needed. \n  Strategic Forecasting: Develop and maintain strategic forecasts for construction projects, demonstrating data analytics to identify trends and make informed predictions about future outcomes. Incorporate earned value measurement techniques to assess project performance and forecast project completion accurately. \n  Business Intelligence: Provide data-driven insights that support critical business decisions, helping to improve operational efficiency and profitability. Apply program management skills to coordinate and oversee multiple projects, ensuring alignment with broader business goals. \n  Collaboration with Partner Teams: Collaborate closely with other data analysts from partner teams to create a dynamic teamwork and shared insights. Share standard methodologies, work collectively to enhance data-driven decision-making, and align efforts across various projects and portfolios. \n \n \n \n \n \n \n \n \n \n \n \n \n \n       What you\u2019ll need\n       \n \n \n  Bachelor's degree in a relevant field (e.g., Data Science, Business Analytics, Construction Management). \n  A minimum of 10 years of hands-on experience in data analysis, with a preference for candidates with construction industry experience and a background in Project Management Office (PMO) functions. \n  Proficiency in data analytics tools such as Quickbase, eBuilder, SAP, and Google Suite. \n  Expertise in creating and maintaining dashboards using tools like Google Sheets. \n  Demonstrable ability to generate prescriptive, diagnostic, descriptive, and predictive insights from data, applying sophisticated analytics methods. \n  Exceptional problem-solving and critical-thinking skills, with a demonstrated commitment to data-driven decision-making and program management skills. \n  Superb interpersonal skills to convey sophisticated data in a concise and understandable manner, fostering collaboration with partner teams, and ensuring data analysis aligns with broader project and business objectives. \n \n \n \n \n  Preferred:",
        "techs": [
            "quickbase",
            "ebuilder",
            "sap",
            "google sheets"
        ],
        "cleaned_techs": [
            "quickbase",
            "ebuilder",
            "sap",
            "google sheets"
        ]
    },
    "02353845acfe4c82": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 87073.414,
        "salary_max": 110254.35,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office",
            "finra series 7",
            "finra series 24"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft",
            "finra series 7",
            "finra series 24"
        ]
    },
    "09f025c4decee9e6": {
        "terms": [
            "data science"
        ],
        "salary_min": 85028.28,
        "salary_max": 107664.75,
        "title": "Senior Analyst, Marketing & Loyalty Analytics",
        "company": "Hilton",
        "desc": "***This role is based in Addison, TX (Allows telecommuting from the Dallas, TX metro area)*** \n Job title: \n Sr. Analyst, Marketing & Loyalty Analytics \n Location: \n Addison, TX (Allows telecommuting from Dallas, TX metro area) \n What will I be doing? \n Identify critical business problems to translate and evolve them into structured analyses. Synthesize data from multiple sources, utilize advanced analytics techniques, and deliver insights that drive strategy. Grow and support data and analysis requests, using all available data sources, tools, and techniques, including Web Analytics, SAS, R, prescriptive analytics and predictive analytics. Build, deliver, and support changes to reports, metrics, and dashboards.  \n Requirements: \n Requires a Master's degree in Business Analytics, Data Science, or related field. Must possess knowledge of: Web Analytics, database marketing, predictive analytics, prescriptive analytics, business analytics, data management, spreadsheet modeling, consumer behavior, Python, and programming for data science using SAS and R.  \n WHAT IT IS LIKE WORKING FOR HILTON \n The future of hospitality is bright at Hilton: a leading global hospitality company with a diverse portfolio of. Dedicated to filling the earth with the light and warmth of hospitality, we have welcomed more than 3 billion guests in our more-than 100-year history. Hilton is proud to have an award-winning workplace culture and we are consistently named among one of the World's Best Workplaces. Check out the and to learn more about what it's like to be on Team Hilton! \n It is the policy of Hilton to employ qualified persons without regard to color, race, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and related medication conditions), gender identity or gender expression, sexual orientation, marital status, military service, status as a protected veteran, disability, protected medical condition as defined by applicable law, genetic information, or any other protected group status as defined by and subject to applicable federal, state and local laws. Hilton's commitment to equal employment opportunity supports the attraction and retention of a diverse workforce that will enhance our effectiveness in attracting Team Members, customers, corporate partners, and owners.  \n We provide reasonable accommodations to qualified persons with disabilities to perform the essential functions of the position and provide other benefits and privileges of employment in accordance with applicable law. Please if you require an accommodation during the application process. #LI-DNI",
        "cleaned_desc": " Requires a Master's degree in Business Analytics, Data Science, or related field. Must possess knowledge of: Web Analytics, database marketing, predictive analytics, prescriptive analytics, business analytics, data management, spreadsheet modeling, consumer behavior, Python, and programming for data science using SAS and R.  \n WHAT IT IS LIKE WORKING FOR HILTON ",
        "techs": [
            "web analytics",
            "database marketing",
            "predictive analytics",
            "prescriptive analytics",
            "business analytics",
            "data management",
            "spreadsheet modeling",
            "consumer behavior",
            "python",
            "sas",
            "r"
        ],
        "cleaned_techs": [
            "web analytics",
            "database marketing",
            "predictive analytics",
            "prescriptive analytics",
            "business analytics",
            "data management",
            "spreadsheet modeling",
            "consumer behavior",
            "python",
            "sas",
            "r"
        ]
    },
    "3c1168848c82ee64": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 86761.86,
        "salary_max": 109859.84,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "ms sql",
            "microsoft"
        ]
    },
    "9f38c8a49cc03a02": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 86391.26,
        "salary_max": 109390.586,
        "title": "Data Engineer I \u2013 Remote",
        "company": "Core Group Resources",
        "desc": "Core Group Resources is America's leading recruitment company. Founded by a service academy graduate who has offshore experience, Core Group Resources' expertise is unmatched in the marine offshore market, finance, IT, renewables, & non-profit for executive search, staffing, and expertise identification.\n   Data Engineer I Description \n  You will be an independent contributor on a fast-growing Data Engineering team pursuing a vision of analytics-driven mining at Freeport. Your expertise in data engineering and software engineering will enable and empower our organization to build and deploy data driven solutions to production. At Freeport we understand that our data does not reach its full potential until it is analyzed, and insights effectively communicated to the enterprise. You will work in close collaboration with mining operations, subject matter experts, data scientists, and software engineers to develop advanced, highly automated data products. You will be a champion of DataOps, and agile practices; actively participating in project teams to drive value. \n \n Agile Project Work: Work in cross-functional, geographically distributed agile teams of highly skilled data engineers, software/machine learning engineers, data scientists, DevOps engineers, designers, product managers, technical delivery teams, and others to continuously innovate analytic solutions. \n    \n Design, develop, and review real-time/bulk data pipelines from a variety of sources (streaming data, APIs, data warehouse, messages, images, video, etc) \n Follow established design patterns for data ingest, transformation, and egress \n Develop documentation of Data Lineage and Data Dictionaries to create a broad awareness of the enterprise data model and its applications \n Apply best practices within DataOps (Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications) \n \n Problem Solving/Project Management: Constructively challenge while soliciting participation in problem solving to enrich possible solutions. \n Architecture: Utilize modern cloud technologies and employ best practices from DevOps/DataOps to produce enterprise quality production Python and SQL code with minimal errors. Participate in regular code review sessions and collaboratively discuss opportunities for continuous improvement in all solutions. \n Self-Development: Flexibly seek out new work or training opportunities to broaden experience. Independently research latest technologies and openly discuss applications within the department. \n Perform other duties as requested. \n \n Data Engineer I Qualifications \n \n Bachelor\u2019s degree in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and three (3) years of relevant work experience \n \n OR \n \n Master\u2019s or Ph.D. in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and one (1) year of relevant work experience \n Strong experience in at least two areas: \n    \n Knowledgeable Practitioner of SQL development with experience designing high quality, production SQL codebases \n Knowledgeable Practitioner of Python development with experience designing high quality, production Python codebases \n Knowledgeable Practitioner in data engineering, software engineering, and ML systems architecture \n Knowledgeable Practitioner of data modeling \n Experience applying software development best practices in data engineering projects, including Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Driven Development/Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications using Python and SQL \n Data science experience wrangling data, model selection, model training, modeling validation, e.g., Operational Readiness Evaluator and Model Development and Assessment Framework, and deployment at scale \n   \n \n Preferred Qualifications: \n \n Working knowledge of Azure Stream Architectures, DBT, Schema Change tools, Data Dictionary tools, Azure Machine Learning Environment, GIS Data \n Working knowledge of Software Engineering and Object Orient Programming Principles \n Working knowledge of Distributed Parallel Processing Environments such as Spark or Snowflake \n Working knowledge of problem solving/root cause analysis on Production workloads \n Working knowledge of Agile, Scrum, and Kanban \n Working knowledge of workflow orchestration using tools such as Airflow, Prefect, Dagster, or similar tooling \n Working knowledge with CI/CD and automation tools like Jenkins or Azure DevOps \n Experience with containerization tools such as Docker \n Strong verbal and written communication skills in English language \n \n #LI-Remote",
        "cleaned_desc": "Core Group Resources is America's leading recruitment company. Founded by a service academy graduate who has offshore experience, Core Group Resources' expertise is unmatched in the marine offshore market, finance, IT, renewables, & non-profit for executive search, staffing, and expertise identification.\n   Data Engineer I Description \n  You will be an independent contributor on a fast-growing Data Engineering team pursuing a vision of analytics-driven mining at Freeport. Your expertise in data engineering and software engineering will enable and empower our organization to build and deploy data driven solutions to production. At Freeport we understand that our data does not reach its full potential until it is analyzed, and insights effectively communicated to the enterprise. You will work in close collaboration with mining operations, subject matter experts, data scientists, and software engineers to develop advanced, highly automated data products. You will be a champion of DataOps, and agile practices; actively participating in project teams to drive value. \n \n Agile Project Work: Work in cross-functional, geographically distributed agile teams of highly skilled data engineers, software/machine learning engineers, data scientists, DevOps engineers, designers, product managers, technical delivery teams, and others to continuously innovate analytic solutions. \n    \n Design, develop, and review real-time/bulk data pipelines from a variety of sources (streaming data, APIs, data warehouse, messages, images, video, etc) \n Follow established design patterns for data ingest, transformation, and egress \n Develop documentation of Data Lineage and Data Dictionaries to create a broad awareness of the enterprise data model and its applications   Apply best practices within DataOps (Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications) \n \n Problem Solving/Project Management: Constructively challenge while soliciting participation in problem solving to enrich possible solutions. \n Architecture: Utilize modern cloud technologies and employ best practices from DevOps/DataOps to produce enterprise quality production Python and SQL code with minimal errors. Participate in regular code review sessions and collaboratively discuss opportunities for continuous improvement in all solutions. \n Self-Development: Flexibly seek out new work or training opportunities to broaden experience. Independently research latest technologies and openly discuss applications within the department. \n Perform other duties as requested. \n \n Data Engineer I Qualifications \n   Bachelor\u2019s degree in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and three (3) years of relevant work experience \n \n OR \n \n Master\u2019s or Ph.D. in engineering, computer science, analytical field (Statistics, Mathematics, etc.) or related discipline and one (1) year of relevant work experience \n Strong experience in at least two areas: \n    \n Knowledgeable Practitioner of SQL development with experience designing high quality, production SQL codebases \n Knowledgeable Practitioner of Python development with experience designing high quality, production Python codebases   Knowledgeable Practitioner in data engineering, software engineering, and ML systems architecture \n Knowledgeable Practitioner of data modeling \n Experience applying software development best practices in data engineering projects, including Version Control, P.R. Based Development, Schema Change Control, CI/CD, Deployment Automation, Test Driven Development/Test Automation, Shift left on Security, Loosely Coupled Architectures, Monitoring, Proactive Notifications using Python and SQL \n Data science experience wrangling data, model selection, model training, modeling validation, e.g., Operational Readiness Evaluator and Model Development and Assessment Framework, and deployment at scale \n   \n \n Preferred Qualifications: \n \n Working knowledge of Azure Stream Architectures, DBT, Schema Change tools, Data Dictionary tools, Azure Machine Learning Environment, GIS Data   Working knowledge of Software Engineering and Object Orient Programming Principles \n Working knowledge of Distributed Parallel Processing Environments such as Spark or Snowflake \n Working knowledge of problem solving/root cause analysis on Production workloads \n Working knowledge of Agile, Scrum, and Kanban \n Working knowledge of workflow orchestration using tools such as Airflow, Prefect, Dagster, or similar tooling \n Working knowledge with CI/CD and automation tools like Jenkins or Azure DevOps \n Experience with containerization tools such as Docker \n Strong verbal and written communication skills in English language \n ",
        "techs": [
            "core group resources",
            "freeport",
            "dataops",
            "agile",
            "devops",
            "data lineage",
            "data dictionaries",
            "version control",
            "p.r. based development",
            "schema change control",
            "ci/cd",
            "deployment automation",
            "test automation",
            "shift left on security",
            "loosely coupled architectures",
            "monitoring",
            "proactive notifications",
            "sql",
            "python",
            "ml systems architecture",
            "data modeling",
            "azure stream architectures",
            "dbt",
            "schema change tools",
            "data dictionary tools",
            "azure machine learning environment",
            "gis data",
            "software engineering",
            "object orient programming principles",
            "spark",
            "snowflake",
            "agile",
            "scrum",
            "kanban",
            "airflow",
            "prefect",
            "dagster",
            "jenkins",
            "azure devops",
            "docker."
        ],
        "cleaned_techs": [
            "core group resources",
            "freeport",
            "dataops",
            "agile",
            "devops",
            "data lineage",
            "data dictionaries",
            "version control",
            "p.r. based development",
            "schema change control",
            "ci/cd",
            "deployment automation",
            "test automation",
            "loosely coupled architectures",
            "monitoring",
            "proactive notifications",
            "sql",
            "python",
            "ml systems architecture",
            "azure",
            "dbt",
            "schema change tools",
            "data dictionary tools",
            "gis data",
            "software engineering",
            "object orient programming principles",
            "spark",
            "snowflake",
            "scrum",
            "kanban",
            "airflow",
            "prefect",
            "dagster",
            "jenkins",
            "docker."
        ]
    },
    "31711e0b58cd34dd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 73100.0,
        "salary_max": 166000.0,
        "title": "Data Analyst",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Bethesda,MD,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180269\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Analyst\n           The Opportunity:  As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to empower citizens to understand complex healthcare information. \n \n  As a client-facing data analyst on our Health team, you\u2019ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you\u2019ll also advise your client on what the information means and how it can be used to make an impact on optimizing their technologies and provide superior healthcare support \n \n  How You\u2019ll Contribute:  As a data analyst on our team, you\u2019ll: \n \n  Use your data analytics expertise to support client and stakeholder relationships. \n  Research, develop, and test data methodologies, and generate cross-functional solutions through collection, cleansing, interpretation, evaluation and analysis of large data sets. \n  Contribute to impactful work and guide decision-making across multiple organizations. \n  Apply consulting, communication skills, and data analytics expertise by simplifying technical requirements and trends, based on audience. \n  Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages such as SQL, Python and Microsoft Office Suite. \n  Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes. \n  Apply data visualization through different formats such as graphs, tables, Pie charts, PowerPoint slides \n  Grow your communication and technical skills by merging consulting and big data to create data-centric solutions. \n \n \n  Work with us to drive large-scale business and process decisions through data insights. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience with visualization tools, including Qlik Sense or Tableau \n  Knowledge of databases, cloud technologies, data analytics, Big Data, or Web development \n  Knowledge of SQL, JSON, Apache SOLR, ColdFusion, Node.js, Python, AWS RDS, WAF, ElasticSearch, Kibana, Logstash, or Active Directory \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree in Computer Science \n \n \n  Nice If You Have: \n \n  Experience with Advanced Data Analytics using Machine Learning \n  Knowledge of AWS \n  Masters degree in Computer Science \n  PMP, AWS Cloud Certification \n \n     Vetting:  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client.     Create Your Career:   Grow With Us  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": " \n \n \n \n \n \n \n \n         Data Analyst\n           The Opportunity:  As data analyst, you love diving into data and turning it into meaningful insights. With the abundance of structured and unstructured data, you understand the importance of transforming complex data sets into useful information to solve challenges. As a data analyst at Booz Allen, you can use your skills and experience to support a mission and use data for good. We need a data expert like you to bring your expertise to empower citizens to understand complex healthcare information. \n \n  As a client-facing data analyst on our Health team, you\u2019ll work closely with your clients to understand their questions and needs and then dig into their data-rich environments to find the pieces of their information puzzle. Not only will you provide a deep understanding of their data, you\u2019ll also advise your client on what the information means and how it can be used to make an impact on optimizing their technologies and provide superior healthcare support \n \n  How You\u2019ll Contribute:  As a data analyst on our team, you\u2019ll: \n \n  Use your data analytics expertise to support client and stakeholder relationships. \n  Research, develop, and test data methodologies, and generate cross-functional solutions through collection, cleansing, interpretation, evaluation and analysis of large data sets. \n  Contribute to impactful work and guide decision-making across multiple organizations. \n  Apply consulting, communication skills, and data analytics expertise by simplifying technical requirements and trends, based on audience. \n  Present data findings and recommendations to clients and stakeholders using your knowledge of databases, scripting languages such as SQL, Python and Microsoft Office Suite. \n  Establish quantitative and qualitative metrics and key performance indicators to drive technical outcomes.    Apply data visualization through different formats such as graphs, tables, Pie charts, PowerPoint slides \n  Grow your communication and technical skills by merging consulting and big data to create data-centric solutions. \n \n \n  Work with us to drive large-scale business and process decisions through data insights. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  Experience with visualization tools, including Qlik Sense or Tableau \n  Knowledge of databases, cloud technologies, data analytics, Big Data, or Web development \n  Knowledge of SQL, JSON, Apache SOLR, ColdFusion, Node.js, Python, AWS RDS, WAF, ElasticSearch, Kibana, Logstash, or Active Directory \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree in Computer Science \n \n \n  Nice If You Have: \n \n  Experience with Advanced Data Analytics using Machine Learning \n  Knowledge of AWS ",
        "techs": [
            "qlik sense",
            "tableau",
            "sql",
            "json",
            "apache solr",
            "coldfusion",
            "node.js",
            "python",
            "aws rds",
            "waf",
            "elasticsearch",
            "kibana",
            "logstash",
            "active directory"
        ],
        "cleaned_techs": [
            "qlik sense",
            "tableau",
            "sql",
            "json",
            "apache solr",
            "coldfusion",
            "node.js",
            "python",
            "aws",
            "waf",
            "elasticsearch",
            "kibana",
            "logstash",
            "active directory"
        ]
    },
    "1a9f69a8f973006a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 89080.0,
        "salary_max": 99560.0,
        "title": "Data Analyst",
        "company": "Mineral",
        "desc": "About Us \n \n \n    Every small business journey is different, filled with its own twists and turns. Mineral is with them every step of the way, taking the guesswork out of HR and compliance so that they\u2019re always ready for whatever lies ahead.\n   \n \n \n  Our innovative platform is a one-stop resource for small businesses, filled with everything they need to tackle even the trickiest workplace issues with confidence.\n   \n \n \n  Humble brag alert: Mineral has been consistently recognized for our award-winning culture, and we\u2019re especially proud of our 2022 Great Places to Work certification. Simply put, Mineral is a place where people want to be, which could explain why we\u2019ve also been ranked among the nation\u2019s fastest-growing private companies.\n   \n \n \n  As a company, Mineral is also made up of incredibly diverse, vibrant individuals, working together for the greater good. We\u2019re here to help our clients build healthy, thriving organizations, and we\u2019re looking for some like-minded people to help us do it.\n    \n \n \n \n \n   The\n     Data Analyst  will be responsible for developing and managing the organization's health insurer data strategy and processes, enabling the health insurer team to support their growth. The ideal candidate is conscientious, with a keen attention to detail, highly analytical, and is highly personable.\n    \n \n \n \n \n   As part of the team, the\n     Data Analyst  will be responsible for harnessing and maintaining the organization\u2019s key systems and data to enable data-driven decisions. They will partner with the sales team on operational aspects, such as providing data analysis to uncover upsell and expansion opportunities for the sales team.\n   \n \n \n \n You will: \n \n \n  Ownership of all health insurer data in Sharepoint, Mineral Data Warehouse and the maintenance of the data we use. \n  Processing data from Health Insurers so the revenue team can process bookings and deploy product.  \n Management of unique data process to query our database for existing companies on the Mineral platform. \n  Matching the data from Health Insurers to Mineral data and coordinating the tasks based on the defined rules \n  Follow current data standards and processes and propose additional data governance controls and data standards as necessary \n  Validate quality of data and build automated scripts to measure quality of data and workflows to get the data audited and corrected \n  Identify automation opportunities, propose improvements to the current Health Insurer data processes, and design and develop automation routines to handle the steps required to receive and process data \n  Work with revenue account management for one-off requests that come into the team outside of our normal data processing and alerting them when data processes are complete for the month. \n  Work cross functionally to provide support in solving for scalability, automation, and reliability. \n  Create visualizations, dashboards, and presentations that will evangelize our data insights with senior leadership, driving impact on a key company initiative. \n  Partner with Revenue team leadership to develop a deep understanding of the business, from its data and metrics to its operational challenges and opportunities. \n  Ad hoc requests around data to help support the growth of health insurer channel. \n  Manage and document of all data processes for knowledge transfer to team. \n  Provide reports to the team upon request. \n \n \n \n \n \n \n You have: \n \n \n  2-4 years of relevant experience in Data Management, Data Analysis, Analytics, or Sales Operations roles \n  Proficiency with MS Office suite, especially Excel and Sharepoint (Pivot tables, VLookups, etc.) \n  Proficient with CRM tools, Salesforce.com Account structures, dashboards and reports \n  Experience in Python and Data Wrangling tools dealing with customer data and matching functions \n  Understanding and/or working experience of Data Governance and Data Quality Management processes \n  Proficiency in SQL and Data Modeling for Analytical purposes \n  Understanding of APIs and working with APIs as the source of data \n  Exposure to AWS architecture (S3, Lambda) and Databricks is a plus \n  Experience with Business Intelligence tools a plus (Tableau, DOMO, AWS Quicksight, Looker) \n  Demonstrated ability to prioritize work to meet multiple, competing deadlines \n  Ability to work independently and collaboratively to achieve goals, deadlines and desired results \n  Effective oral, written and interpersonal communication skills \n  Bachelor\u2019s degree in Mathematics, Engineering, Economics, Business Management, Computer Science, Statistics or a related field preferred \n \n \n \n \n \n \n Compensation Philosophy \n \n \n \n  At Mineral, our compensation philosophy and practices are aligned with our commitment to pay equity and transparency. We determine total compensation packages with an intentional analysis of a candidate\u2019s skills, experience, qualifications, and job-related competencies, and consideration of internal equity.\n   \n \n \n  In order to offer competitive, market-based pay, our pay ranges are informed by geographic location.\n   \n \n \n \n  Hiring Range :\n   \n \n    Geo G\u2013(Examples: San Francisco, CA; Los Angeles, CA; New York City, NY; Chicago, IL; Seattle, WA): $111,350 - $124,450/year\n   \n \n    Geo E\u2013(Examples: Portland, OR; Austin, TX; Charlotte, NC; Denver, CO): $98,005 - $109,535/year\n   \n \n    Geo M\u2013(Examples: Milwaukee, WI; Orlando, FL; Nashville, TN; San Antonio, TX): $89,080 - $99,560/year\n   \n \n \n \n    We believe that meaningful total compensation also includes competitive benefits offerings that support the well-being of every Mineralist. In addition to the hiring range, this position is eligible for annual corporate bonus and our benefits offerings.\n   \n \n \n  Benefits and Perks \n \n \n    Generous Medical, Dental, and Vision Insurance Coverage\n   \n \n    401k + Company Match\n   \n \n    Flexible Vacation + Paid Sick Time + Company Holidays\n   \n \n    Corporate Bonus Program\n   \n \n    Paid Family Leave\n   \n \n    Lifestyle Spending Account\n   \n \n    Pet Insurance\n   \n \n    Other market competitive perks and benefits\n   \n \n \n  Equal opportunities, accessibility for all \n \n \n    Mineral values diversity and is proud to be an Equal Employment Opportunity employer. All individuals seeking employment at Mineral are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other legally protected characteristic.\n    \n \n \n \n \n   We\u2019re also committed to providing reasonable accommodations for qualified applicants with disabilities in our job application and recruitment process. If you need assistance or an accommodation, don\u2019t hesitate to reach out to us at careers@trustmineral.com\n   \n \n \n  Security Alert \n \n \n    We\u2019re aware of phishing scams targeting job candidates. Mineral will never ask you to do anything that puts your privacy at risk. Verify that your recruiter\u2019s contact information is from the trustmineral.com domain. If you encounter suspicious activity, please notify us at careers@trustmineral.com\n   \n \n \n  Privacy Statement \n \n \n    Any sensitive or personal information that you provide to us will be used solely to conduct our people and talent search, hiring and onboarding process. Information will not be shared or used for any other purpose unless you\u2019ve provided consent otherwise.",
        "cleaned_desc": " \n \n You will: \n \n \n  Ownership of all health insurer data in Sharepoint, Mineral Data Warehouse and the maintenance of the data we use. \n  Processing data from Health Insurers so the revenue team can process bookings and deploy product.  \n Management of unique data process to query our database for existing companies on the Mineral platform. \n  Matching the data from Health Insurers to Mineral data and coordinating the tasks based on the defined rules \n  Follow current data standards and processes and propose additional data governance controls and data standards as necessary \n  Validate quality of data and build automated scripts to measure quality of data and workflows to get the data audited and corrected \n  Identify automation opportunities, propose improvements to the current Health Insurer data processes, and design and develop automation routines to handle the steps required to receive and process data \n  Work with revenue account management for one-off requests that come into the team outside of our normal data processing and alerting them when data processes are complete for the month. \n  Work cross functionally to provide support in solving for scalability, automation, and reliability. \n  Create visualizations, dashboards, and presentations that will evangelize our data insights with senior leadership, driving impact on a key company initiative. \n  Partner with Revenue team leadership to develop a deep understanding of the business, from its data and metrics to its operational challenges and opportunities. \n  Ad hoc requests around data to help support the growth of health insurer channel. \n  Manage and document of all data processes for knowledge transfer to team. \n  Provide reports to the team upon request. \n \n \n \n \n \n \n You have: \n \n \n  2-4 years of relevant experience in Data Management, Data Analysis, Analytics, or Sales Operations roles \n  Proficiency with MS Office suite, especially Excel and Sharepoint (Pivot tables, VLookups, etc.) \n  Proficient with CRM tools, Salesforce.com Account structures, dashboards and reports \n  Experience in Python and Data Wrangling tools dealing with customer data and matching functions    Understanding and/or working experience of Data Governance and Data Quality Management processes \n  Proficiency in SQL and Data Modeling for Analytical purposes \n  Understanding of APIs and working with APIs as the source of data \n  Exposure to AWS architecture (S3, Lambda) and Databricks is a plus \n  Experience with Business Intelligence tools a plus (Tableau, DOMO, AWS Quicksight, Looker) \n  Demonstrated ability to prioritize work to meet multiple, competing deadlines \n  Ability to work independently and collaboratively to achieve goals, deadlines and desired results \n  Effective oral, written and interpersonal communication skills \n  Bachelor\u2019s degree in Mathematics, Engineering, Economics, Business Management, Computer Science, Statistics or a related field preferred \n \n \n \n \n \n \n Compensation Philosophy \n \n \n \n  At Mineral, our compensation philosophy and practices are aligned with our commitment to pay equity and transparency. We determine total compensation packages with an intentional analysis of a candidate\u2019s skills, experience, qualifications, and job-related competencies, and consideration of internal equity.\n   \n \n \n  In order to offer competitive, market-based pay, our pay ranges are informed by geographic location.\n   \n \n \n \n  Hiring Range :\n   \n \n    Geo G\u2013(Examples: San Francisco, CA; Los Angeles, CA; New York City, NY; Chicago, IL; Seattle, WA): $111,350 - $124,450/year",
        "techs": [
            "sharepoint",
            "mineral data warehouse",
            "health insurers",
            "revenue team",
            "mineral platform",
            "data standards",
            "data governance controls",
            "automated scripts",
            "workflows",
            "automation routines",
            "revenue account management",
            "visualizations",
            "dashboards",
            "presentations",
            "senior leadership",
            "ms office suite",
            "excel",
            "salesforce.com",
            "python",
            "data wrangling tools",
            "data governance",
            "data quality management processes",
            "sql",
            "apis",
            "aws architecture",
            "s3",
            "lambda",
            "databricks",
            "business intelligence tools",
            "tableau",
            "domo",
            "aws quicksight",
            "looker",
            "mathematics",
            "engineering",
            "economics",
            "business management",
            "computer science",
            "statistics"
        ],
        "cleaned_techs": [
            "sharepoint",
            "mineral data warehouse",
            "health insurers",
            "revenue team",
            "mineral platform",
            "data standards",
            "data governance controls",
            "automated scripts",
            "workflows",
            "automation routines",
            "revenue account management",
            "visualizations",
            "dashboards",
            "presentations",
            "senior leadership",
            "microsoft",
            "excel",
            "salesforce.com",
            "python",
            "data wrangling tools",
            "data governance",
            "data quality management processes",
            "sql",
            "apis",
            "aws",
            "s3",
            "lambda",
            "databricks",
            "business intelligence tools",
            "tableau",
            "domo",
            "looker",
            "mathematics",
            "engineering",
            "economics",
            "business management",
            "computer science",
            "statistics"
        ]
    },
    "cd40972106280c16": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 60000.0,
        "salary_max": 103000.0,
        "title": "Business Analyst",
        "company": "Insurity",
        "desc": "Who We Are \n  Insurity\u2019s vision is all about empowerment. Empowering insurance organizations to quickly capitalize on new opportunities by delivering the world\u2019s most configurable, cloud-native, easy-to-use, and intuitively analytical software. It\u2019s also about empowering our team members through tools, training, teamwork, and professional development opportunities. \n  To talk the talk, we must walk the walk. We are trusted by 15 of the top 25 Property & Casualty insurance carriers and 7 of the top 10 MGAs in the U.S. today with over 400 cloud-based deployments \u2013 and more on the way. That\u2019s proof we walk the walk. While our product suites are some of the most compelling in the industry, it\u2019s our team members who deliver the exceptional value and unrivaled industry expertise our customers appreciate from us. \n  Our team tells us over and over; working at Insurity offers you the opportunity to collaborate with and learn from some of the most creative and knowledgeable minds in insurance technology. You\u2019ll feel welcomed even before you start your first day with us through our award-winning onboarding program. \n  Take the first step to joining our team by applying today and we look forward to seeing  #UatInsurity . \n  Insurity\u2019s next Business Analyst \n  The Business Analyst is responsible for eliciting, analyzing, and documenting requirements and/or functional specifications as needed, including the determination of the regulatory impact and system impact. \n  Participate with customers and internal functional areas as appropriate throughout the development, testing, and installation processes. Research and evaluate alternative approaches and recommend efficient and cost-effective solutions. The individual contributes to activities to improve quality and advance the overall analysis practice throughout the organization. The Business Analyst may provide coordination for small initiatives. \n  The ideal candidate must possess a strong desire to develop technical and business knowledge relative to the implementation of insurance processing. \n  What Our Business Analyst Will Do \n \n Partnering with customers to define business needs and elicit business requirements \n Producing artifacts that accurately depict customer needs for enhancement, problem, and support requests, such as: \n Functional specifications \n Process flow diagrams and other diagrams \n Lead facilitation of requirements and design discussions \n Providing research and analysis in support of proposed solutions \n Participating in peer reviews/inspections for requirements, estimates, and specifications \n Assisting in the development of supporting documentation \n Providing support as needed to internal and external customers \n Developing a working knowledge of Insurity's software applications, data structures, architecture, and processing capabilities \n Developing working knowledge of Property/Casualty Insurance \n Assisting in the facilitation of estimating discussions and coordinating work efforts \n Accurately estimating analyst work efforts \n Providing support for testing activities \n Performing other duties as assigned \n \n Who We're Looking For \n \n Bachelor\u2019s degree or equivalent work experience \n Knowledge of the System Development Lifecycle \n Knowledge of project management principles \n Ability to travel to customer locations: up to 25% \n Experience with Commercial Property Insurance preferred \n \n What\u2019s In It For U \n \n Flex First Workforce : Do your work best from home or from one of our office locations; it\u2019s your choice. \n Generous Time Off : Our leadership believes in taking the time you need when you need it through our Open PTO Policy. \n Day One Health Benefits + Employer-Matched Retirement Savings : You might think these are table stakes, but we know these matter to you. \n More Than Just Core Values : Our values are fundamental in how we attract, train, and retain top talent. \n Award-Winning Onboarding Program : We set you up from the get-go to make a significant impact from Day One and follow you through your entire first year. \n Real Career Growth Opportunities : We love to promote from within with over 20% of our open roles filled through internal applicants last year. \n Mentorship Program:  We support a champion culture and growth mindset by pairing you with experienced, talented leaders to help you grow personally and professionally. \n Internal Networking:  Build relationships, network, collaborate, and stay connected with colleagues internally with our one-of-a kind online Coffee for Two program. \n Continuous Learning Opportunities : Own your development with your own LinkedIn Learning + Ted@Work + Kaplan licenses. \n Discounted University Tuition : Employees and their families can start or continue their university career with less out-of-pocket investment through our partnerships with the University of Arizona Global Campus. \n Employee Referral Bonus : Once you come onboard, give Insurity the biggest compliment you can give by referring someone to work here and earn a cash bonus. \n \n We have five Core Values at Insurity; one of which is to  Act with Integrity . Providing pay transparency helps you make the best decision for you. We continuously analyze and update our salary ranges for our roles according to market trends to not only ensure our employees are paid fairly, but also help close gender, race, and disability wage gaps. Along with the benefits listed above, the salary range for this role is $60,000 to $103,000, commensurate with experience. \n  Insurity is proud to be an Equal Opportunity Employer \n  We are dedicated to creating an exceptional work environment for all our employees by extending a culture of diversity, equity, inclusion, and belonging into the very fabric of our organization. We embrace differences and diversity of identity, experience, and thought, and actively strive for inclusive behaviors across our company. \n  We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application and/or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. \n \n #LI-REMOTE",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a812c3b1521f29df": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 82880.0,
        "salary_max": 126000.0,
        "title": "Data and Reporting Analyst II (Remote)",
        "company": "Blackhawk Network",
        "desc": "About Blackhawk Network: \n  \n   Blackhawk Network (BHN) is the leader in global branded payment technologies. We strengthen relationships between brands and their customers, employees, and partners by transforming transactions into connections. BHN\u2019s portfolio includes: Gift Card & eGift products, promotions and distribution that grow revenue faster; Rewards & Incentives that build loyalty and acquisition and are integrated into today\u2019s leading platforms; and Payments that enable businesses and customers to access and disburse funds in convenient and innovative ways. BHN\u2019s network spans across the globe with over 400,000 consumer touchpoints. Learn more at BHN.com.\n  \n \n \n  This position may be performed remotely anywhere within the United States except for the State of Alaska, North Dakota, or South Dakota.\n   Responsibilities: \n  \n Collecting data from various sources \n  Streamlining data collection methods to create automated and easy-to-use routines. \n  Analyzing collected data and putting it into a format that others can easily interpret. \n  Interpreting data trends and patterns as they relate to the organization. \n  Preparing reports for the stakeholders to understand the data-analysis steps, enabling them to take important decisions based on various facts and trends. \n  Responsible for data accuracy & data completeness \n  Responsible for utilizing ETL process or scripts to acquire, transform & load data from various sources. \n  Connecting to various data sources, importing data, and transforming data for providing business insights. \n  Troubleshoot data management issues and offer assistance across teams. \n  Collaborate with data architects and data engineers. \n  Encourage the adoption of an organization\u2019s frameworks by providing documentation, training, sample code, and developer support \n  Create adhoc reports using SQL \n  Qualifications: \n  \n Bachelor\u2019s degree in computer science, Information Technology, or related field, or foreign degree equivalent. \n  3+ years of experience in software development \n  Strong skills in writing SQL queries using databases like Redshift, Microsoft SQL Server, or other industry leading RDBMS. \n  Experience in data analysis & troubleshooting \n  Exposure to reporting tools like Microstrategy, Qlik, Power BI, Business Objects, Tableau etc \n  Exposure to various AWS services like Kinesis, Athena, S3, Glue, DMS, Redshift etc \n  Experience in working with virtual & global team across different time zones. \n  Experience in Java, Python etc are big plus \n  Provide on-call support to business intelligence platform. \n  Exposure to ETL tools for data acquisition and transformation \n  Excellent analytical and technical skills. \n  Willingness to learn new technologies based on organizational needs. \n  Good written and verbal communication skills. \n  Benefits: \n  \n   Salary Range for all U.S. Residents (excluding Alaska, California, North Dakota, South Dakota): $82,880.00 to $126,000.00\n  \n \n   Salary Range for California Residents Only: $112,066.00 to $126,000.00\n  \n \n \n  Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, Blackhawk Network offers benefits including 401k with employer match, medical, dental, vision, 12 paid holidays in the year 2023, sick pay accrual according to state law, parental leave, life insurance, disability insurance, accident and illness insurance, health and dependent care flexible spending accounts, wellness benefits, and flexible time off for all full-time employees. \n  EEO Statement: \n  \n   Blackhawk Network provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. Blackhawk Network believes that diversity leads to strength. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\n  \n \n \n  Blackhawk Network encourages applicants with previous criminal records to apply to all positions and, pursuant to the San Francisco and Los Angeles Fair Chance Acts (and other \u201cFair Chance\u201d laws), Blackhawk Network will consider for employment qualified applicants with arrest and conviction records. For Philadelphia applicants or jobs, please see a copy of Philadelphia\u2019s ordinance on this topic by clicking this link: https://codelibrary.amlegal.com/codes/philadelphia/latest/philadelphia_pa/0-0-0-280104.",
        "cleaned_desc": "  Streamlining data collection methods to create automated and easy-to-use routines. \n  Analyzing collected data and putting it into a format that others can easily interpret. \n  Interpreting data trends and patterns as they relate to the organization. \n  Preparing reports for the stakeholders to understand the data-analysis steps, enabling them to take important decisions based on various facts and trends. \n  Responsible for data accuracy & data completeness \n  Responsible for utilizing ETL process or scripts to acquire, transform & load data from various sources. \n  Connecting to various data sources, importing data, and transforming data for providing business insights. \n  Troubleshoot data management issues and offer assistance across teams. \n  Collaborate with data architects and data engineers. \n  Encourage the adoption of an organization\u2019s frameworks by providing documentation, training, sample code, and developer support    Create adhoc reports using SQL \n  Qualifications: \n  \n Bachelor\u2019s degree in computer science, Information Technology, or related field, or foreign degree equivalent. \n  3+ years of experience in software development \n  Strong skills in writing SQL queries using databases like Redshift, Microsoft SQL Server, or other industry leading RDBMS. \n  Experience in data analysis & troubleshooting \n  Exposure to reporting tools like Microstrategy, Qlik, Power BI, Business Objects, Tableau etc \n  Exposure to various AWS services like Kinesis, Athena, S3, Glue, DMS, Redshift etc \n  Experience in working with virtual & global team across different time zones. ",
        "techs": [
            "streamlining data collection methods",
            "analyzing collected data",
            "interpreting data trends and patterns",
            "preparing reports",
            "responsible for data accuracy & data completeness",
            "utilizing etl process or scripts",
            "connecting to various data sources",
            "troubleshooting data management issues",
            "collaborating with data architects and data engineers",
            "encouraging the adoption of an organization\u2019s frameworks",
            "creating adhoc reports using sql",
            "bachelor\u2019s degree in computer science",
            "3+ years of experience in software development",
            "strong skills in writing sql queries",
            "experience in data analysis & troubleshooting",
            "exposure to reporting tools like microstrategy",
            "qlik",
            "power bi",
            "business objects",
            "tableau",
            "exposure to various aws services like kinesis",
            "athena",
            "s3",
            "glue",
            "dms",
            "redshift",
            "experience in working with virtual & global team."
        ],
        "cleaned_techs": [
            "streamlining data collection methods",
            "analyzing collected data",
            "interpreting data trends and patterns",
            "preparing reports",
            "responsible for data accuracy & data completeness",
            "utilizing etl process or scripts",
            "connecting to various data sources",
            "troubleshooting data management issues",
            "encouraging the adoption of an organization\u2019s frameworks",
            "creating adhoc reports using sql",
            "3+ years of experience in software development",
            "experience in data analysis & troubleshooting",
            "exposure to reporting tools like microstrategy",
            "qlik",
            "powerbi",
            "business objects",
            "tableau",
            "exposure to various aws services like kinesis",
            "athena",
            "s3",
            "glue",
            "dms",
            "redshift",
            "experience in working with virtual & global team."
        ]
    },
    "df5fa6bd6d141644": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 59889.742,
        "salary_max": 75833.76,
        "title": "Functional Data Analyst",
        "company": "Patriot Enterprises LLC",
        "desc": "Functional Data Analyst \n  Company Overview \n  Patriot Enterprises, LLC (Patriot) is a registered Service Disabled Veteran Owned Small Business (SDVOSB) established in 2009 with corporate headquarters located in Alexandria, Virginia. We have personnel delivering services to the military community across approximately 70 military installations across the Continental United States (CONUS) and Outside Continental United Stated (OCONUS). \n  Location: Crystal City, VA (Taylor Bldg), or remote \n  Position Description: \n  Working with the Department of Army - Federal/Military Equal Opportunity (MEO) program - this position will be responsible for providing analytical support data to the Army as needed. \n \n Create and distribute monthly quality control and command reports as required to ensure integrity of data \n Support functional data management, data manipulation, and data integrity of case files associated with this program \n Providing requested reporting and knowledge management support \n Periodic service desk support to help with managing data residing in Data Management Systems (DMS), as well as providing support for users \n Serve as liaison between users and IT team to help resolve any DMS related issues for users and any DoD organization related issues \n Travel to supporting training events may be required \n \n  Required Experience: \n \n 2 years of functional program and analytical experience \n Extensive experience in data analysis with strong understanding of Microsoft Excel to include - creating data tables, macros, v-lookup and pivot tables is required \n Experience with developing and using metrics to analyze performance and developing reports \n Strong customer service skills (solving problems and using tact in handling customer inquiries) \n Strong communication skills and ability to interact with senior managers and officers \n Understanding of Army structure \n Three years of experience in handling/safeguarding PII \n \n  Preferred Experience: \n \n Process improvement skills including some experience using reporting tools such as SQL and reporting server (preferred, not required) \n Prior Army experience/understanding of Army MEO or SHARP directives (preferred, not required) \n \n  Education requirements: Bachelor\u2019s degree \n  Security requirements: \n \n U.S. citizenship required \n Extensive background investigation required \n \n  Patriot Enterprises is an equal opportunity employer. We recruit, employ, train, compensate, and promote without regard to race, religion, creed, color, national origin, age, gender, sexual orientation, marital status, disability, veteran status, or any other basis protected by applicable federal, state or local law. \n   \n dr0IGa15qp",
        "cleaned_desc": "  Required Experience: \n \n 2 years of functional program and analytical experience \n Extensive experience in data analysis with strong understanding of Microsoft Excel to include - creating data tables, macros, v-lookup and pivot tables is required \n Experience with developing and using metrics to analyze performance and developing reports \n Strong customer service skills (solving problems and using tact in handling customer inquiries) \n Strong communication skills and ability to interact with senior managers and officers ",
        "techs": [
            "microsoft excel",
            "macros",
            "v-lookup",
            "pivot tables"
        ],
        "cleaned_techs": [
            "excel",
            "macros",
            "v-lookup",
            "pivot tables"
        ]
    },
    "ed58856c29d47b33": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 64331.066,
        "salary_max": 81457.46,
        "title": "Data Analyst- Signpost",
        "company": "Internews",
        "desc": "ABOUT INTERNEWS AND SIGNPOST \n  Internews is an international non-profit organization whose mission is to ensure people have access to the news and information they need, the ability to connect and the means to make their voices heard. \n  Internews has played a pioneering role in the field of disaster, humanitarian and risk communications, working closely with community, humanitarian agencies, information providers such as local media, national disaster management agencies, community organizations and local responders to understand and support their role in the information ecosystem during crises. We strengthen existing and create new two-way information mechanisms that allow communities to access life-saving information, share questions, concerns and priorities with responders and shape the programs designed to support them. \n  Internews\u2019 approaches are heavily localized, participatory and are implemented through a variety of tools and systems. Through these approaches, Internews sets up processes that translate community-driven data into clear pathways for improved local and international coordination and bring the community closer to responders and local media. \n  Signpost is an innovative digital initiative providing the humanitarian community with a platform to reach refugees, asylum seekers and crisis-affected communities around the world with accessible information. It began in 2015 in Greece and is a collaboration between the International Rescue Committee (IRC) and Mercy Corps (MC). It has since expanded to include instances in Jordan and El Salvador. \n  Each Signpost platform provides users context-specific, up-to-date information on vital needs such as legal rights, transportation, and medical services in multiple languages \u2013 empowering individuals to make informed decisions at the most critical moments. \n \n \n  ABOUT THE OPPORTUNITY \n  Internews is responding to the information needs of people impacted by the current war in Sudan. Our focus is ensuring people are able to access accurate, timely and contextual information to inform their decision making and to identify and respond to rumors and misinformation that may put communities at greater risk. Internews is partnering with the International Rescue Committee (IRC) and the Norwegian Refugee Council (NRC) to create a digital platform which will allow communities to receive responsive answers to their questions and referrals to services to support them. This project will form part of the Signpost global network. \n  The Data Analyst provides a critical component of the project; to listen and respond to the information challenges faced by vulnerable groups in humanitarian contexts, encouraging open dialogue between citizens and scientists and stronger and more collaborative partnerships between information providers (such as local media) and humanitarian and health/legal sources. The Data Analyst will work closely with the Humanitarian Data Coordinator and liaise with the larger Signpost team and project partners (IRC \u2013 NRC) to ensure critical data is collected, analyzed and stored appropriately. \n \n   \n LOGISTICS \n  This is a remote/online position that is for candidates based outside of Sudan. You must have work authorization in your location that does not require sponsorship from Internews. Additionally, there are locations in which Internews is not able to support fully remote work. \n  Applications will be reviewed on a rolling basis, so candidates are encouraged to apply soon. This recruitment will remain open until November 10 2023.  \n This is a limited-duration position that is expected to last 7 months. \n \n   \n OUR COMMITMENT TO FOSTERING A CULTURE OF BELONGING \n  We are an organization of dynamic, mission-driven individuals who are passionate about our core values and about supporting positive change in the world. We pride ourselves on our commitment to innovation and flexibility. We believe that diverse teams are strong teams and work to support an ethic of belonging, dignity, and justice for all people. Our current team includes a mix of genders, parents and non-parents, and people of multiple races, nationalities, ages, sexual orientations and socioeconomic backgrounds. We are an EEO employer and encourage candidates of all races, genders, ages, orientations, ethnicities, and national origins to apply, and welcome those with alternative backgrounds and experiences. \n \n \n  DAY-TO-DAY TASKS will include:  \n \n Collate, clean and analyze community feedback data collected through various community engagement activities by Internews and NRC, and identify trends that may impact the outcomes of public health, legal and other humanitarian priorities and the safety of community members; \n Work with Project management to develop clear data sharing approaches between the two organizations to ensure seamless and timely analysis; \n Implement safe and accountable data handling and storage practices and collaborate with the Humanitarian Data Coordinator to ensure they meet Internews internal standards; \n Monitor and collect alternate approaches to community data capture and analysis and suggest improvements to our methodology where needed; \n Contribute to the production of regular rumor and feedback content and reports, papers, research and other products for humanitarian, media and health partners to improve their understanding of the concerns and questions among the affected population; \n Support the Humanitarian Liaison to implement a risk ranking and referral procedures for data that poses an increased risk to individuals or groups; \n Provide input into the editorial process by providing regular updates to the team on recurrent or emerging topics and trends; \n Support monitoring and evaluation activities to assess impact, reach and quality of the ongoing project; \n Perform any other duties as assigned by the supervisors; \n In all duties, an understanding of and demonstrated commitment to upholding Internews' Core Values. \n \n \n \n  QUALIFICATIONS WE\u2019RE LOOKING FOR: \n \n \n  Required \n \n Strong qualitative data analysis experience, including experience developing strategies to combine variable datasets for unified analysis  \n Strong experience in using excel formulas and Google Apps Script to perform data cleaning, data validation and data analysis. \n Information management experience in fast-changing humanitarian contexts; \n Good understanding of the Sudanese social media ecosystem and key platforms for communication and sharing; \n Good understanding of the humanitarian system and the Core Humanitarian Standards; \n Strong writing skills and the ability to bring data to life; \n Experience working in humanitarian and/or health emergencies; \n Fluent in Arabic, English and relevant local languages; \n Strong understanding of, and commitment towards editorial values of the project; \n Self-motivated and ability to work in a fast-paced environment; \n \n \n \n  Preferred \n  Note:  Candidates who do not have these preferred qualifications, but who are interested and willing to learn, are encouraged to apply.  \n \n Experience and/or understanding of sentiment analysis and/or social media listening tools (like Python's NLTK); \n Data visualization skills and knowledge of relevant software (Tableau, Power BI, or open-source alternatives like D3.js) to produce info-graphics; \n Knowledge of refugee issues in Sudan/East and Horn of Africa.",
        "cleaned_desc": " \n \n  QUALIFICATIONS WE\u2019RE LOOKING FOR: \n \n \n  Required \n \n Strong qualitative data analysis experience, including experience developing strategies to combine variable datasets for unified analysis  \n Strong experience in using excel formulas and Google Apps Script to perform data cleaning, data validation and data analysis. \n Information management experience in fast-changing humanitarian contexts; \n Good understanding of the Sudanese social media ecosystem and key platforms for communication and sharing; \n Good understanding of the humanitarian system and the Core Humanitarian Standards;   Strong writing skills and the ability to bring data to life; \n Experience working in humanitarian and/or health emergencies; \n Fluent in Arabic, English and relevant local languages; \n Strong understanding of, and commitment towards editorial values of the project; \n Self-motivated and ability to work in a fast-paced environment; \n \n \n \n  Preferred \n  Note:  Candidates who do not have these preferred qualifications, but who are interested and willing to learn, are encouraged to apply.  \n \n Experience and/or understanding of sentiment analysis and/or social media listening tools (like Python's NLTK); ",
        "techs": [
            "excel formulas",
            "google apps script",
            "humanitarian system",
            "core humanitarian standards",
            "arabic",
            "english",
            "sentiment analysis",
            "social media listening tools",
            "python's nltk"
        ],
        "cleaned_techs": [
            "excel",
            "google apps script",
            "humanitarian system",
            "core humanitarian standards",
            "arabic",
            "english",
            "sentiment analysis",
            "social media listening tools",
            "python"
        ]
    },
    "afa1bc70c719cbcd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Underwriting Systems Data Analyst",
        "company": "Farmers Insurance Group",
        "desc": "We are Farmers! \n We are\u2026 more than just your favorite commercials. We are a passionate, award winning, equal opportunity employer, committed to the strength of a diverse workforce. We are dedicated to supporting the well-being of our people through our extensive suite of benefits, as well as the well-being of the communities we serve through employee volunteer programs and nonprofit partnerships. Helping others in their time of need isn\u2019t just our business \u2013 it\u2019s our culture!  We are Farmers! \n \n \n Do you thrive in a high-volume, fast-paced environment? Do you enjoy the challenge of a position where no two days are alike? We are looking for positive, high-energy professionals who are not just looking for a job, but a meaningful career! \n \n \n At Farmers, our ambition is to be the leader in delivering peace of mind, innovating for customers whenever and wherever they need us. That means having people like you who can help us evolve to meet changing customer and business needs. Continuous development is critical to our success at Farmers; that means being curious, continually innovating, being open to new opportunities and embracing change. As the needs of our business and customers change, and you acquire needed experience, you may have opportunities to use your knowledge and skills in a different role. As you take on these new challenges, Farmers is committed to providing you with the necessary training and support along your career journey. \n \n \n Workplace: Remote  ( #LI-Remote ) \n \n \n Farmers believes in a culture of collaboration, creativity, and innovation, which thrives when we have the ability to work flexibly in a virtual setting as well as the opportunity to be together in person. Our hybrid work environment combines the best of both worlds with at least three (3) days in office and up to two (2) days virtual for employees who live within fifty (50) miles of a Farmers corporate office. Applicants beyond fifty (50) miles may still be considered. \n \n \n \n  Job Summary \n \n \n \n Provide data in response to one-time or recurring requests for reports or analysis. \n Understand customer objectives and processes; effectively communicate system capabilities and limitations; and deliver available data. \n Analyze data quality and take corrective action. \n Analyze impact of system changes to data/reporting infrastructure (support testing and implementation activities). \n \n \n \n \n \n Essential Job Functions \n \n \n \n Extract and manipulate data to solve business problems. \n Respond to new requests for reports/data, understand customer objectives and processes, review and refine requirements, and communicate estimated hours and timeline to complete; \n Extract data using SQL or similar business query interfaces. \n Extract data directly from relational databases (e.g. Dremio, Snowflake, SQL Server, Redshift, Clouder/Hadoop etc.) \n Format data for business use in formats including R, Excel XML, or similar format; \n Produce reports manually and through automated scripting, create and maintain scripts and macros used to automate reports. \n Support application testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. \n Communicate effectively, be concise and precise in written communication. \n Incorporate best practices in developing intuitive reports to share with a broad audience. \n Describe and document unique aspects or limitations of data to aid understanding. \n Demonstrate aptitude for business applications of data and analytics strategies. \n Demonstrate commitment to lifelong learning. \n Exemplify good teamwork. \n Proactively communicate with customers and team members. \n Provide excellent customer service by making realistic commitments and keeping them. \n Work productively on assigned tasks. \n Collaborate effectively with other team members. \n Demonstrate accountability to management and customers for hours spent on assigned tasks. \n Diligently strive to deliver value in the fewest possible hours. \n \n \n \n \n \n Physical Actions \n \n \n \n Essentially sedentary work consisting of occasional walking, standing, and lifting/carrying 10 lbs. maximum \n Functional ability of seeing, hearing and speaking \n Ability to type proficiently \n \n \n \n \n \n Physical Environment \n \n \n  Work in a climate-controlled office, with occasional travel by car or airplane \n \n \n \n \n  Education Requirements \n \n \n  High school diploma or equivalent required. Bachelor\u2019s degree in data/analytics-related field preferred. \n \n \n \n \n  Experience Requirements \n \n \n \n Internal Candidates: (Preferred) 2+ years of Farmers or other insurance experience. \n Technical experience that involves querying and manipulating data to address business problems. \n External Candidates: 2+ years experience with data extraction, manipulation and presentation in usable format \n \n \n \n \n \n Special Skill Requirement \n \n \n \n Familiarity with complex ETL processes that may link multiple database structures including SQL Server, Mongo DB, Snowflake, Redshift, Dremio, or other legacy formats (Excel XML, Access, etc.) \n \n \n \n \n Benefits \n \n Farmers offers a competitive salary commensurate with experience, qualifications and location.  o CA Only: $80,480 - $116,300  o CO Only: $75,440 - $100,600  o NY Only: $75,440 - $116,300  o Albany County: $80,480 - $100,600  o WA Only: $80,480 - $134,375 \n Bonus Opportunity (based on Company and Individual Performance) \n 401(k) \n Medical \n Dental \n Vision \n Health Savings and Flexible Spending Accounts \n Life Insurance \n Paid Time Off \n Paid Parental Leave \n Tuition Assistance \n \n \n   \n Job Location(s): Remote",
        "cleaned_desc": " Analyze impact of system changes to data/reporting infrastructure (support testing and implementation activities). \n \n \n \n \n \n Essential Job Functions \n \n \n \n Extract and manipulate data to solve business problems. \n Respond to new requests for reports/data, understand customer objectives and processes, review and refine requirements, and communicate estimated hours and timeline to complete; \n Extract data using SQL or similar business query interfaces. \n Extract data directly from relational databases (e.g. Dremio, Snowflake, SQL Server, Redshift, Clouder/Hadoop etc.) \n Format data for business use in formats including R, Excel XML, or similar format; \n Produce reports manually and through automated scripting, create and maintain scripts and macros used to automate reports. \n Support application testing for enhancements or system upgrades; identify and communicate data quality issues or data differences. \n Communicate effectively, be concise and precise in written communication. \n Incorporate best practices in developing intuitive reports to share with a broad audience. \n Describe and document unique aspects or limitations of data to aid understanding. \n Demonstrate aptitude for business applications of data and analytics strategies. \n Demonstrate commitment to lifelong learning. \n Exemplify good teamwork. \n Proactively communicate with customers and team members.   \n  Work in a climate-controlled office, with occasional travel by car or airplane \n \n \n \n \n  Education Requirements \n \n \n  High school diploma or equivalent required. Bachelor\u2019s degree in data/analytics-related field preferred. \n \n \n \n \n  Experience Requirements \n \n \n \n Internal Candidates: (Preferred) 2+ years of Farmers or other insurance experience. \n Technical experience that involves querying and manipulating data to address business problems. \n External Candidates: 2+ years experience with data extraction, manipulation and presentation in usable format \n \n \n ",
        "techs": [
            "sql",
            "dremio",
            "snowflake",
            "sql server",
            "redshift",
            "clouder/hadoop",
            "r",
            "excel xml"
        ],
        "cleaned_techs": [
            "sql",
            "dremio",
            "snowflake",
            "redshift",
            "clouder/hadoop",
            "r",
            "excel"
        ]
    },
    "473169f87e045622": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 56000.0,
        "salary_max": 83000.0,
        "title": "Associate Implementation Business Analyst",
        "company": "iController",
        "desc": "What You'll Do: \n  As an Associate Implementation Business Analyst [internally titled Associate Business Analyst], you will be responsible for documenting the functional requirements, technical specifications and template documentation designs for customers\u2019 business needs while providing expertise in product knowledge and feature/functionality as it relates to business requirements. You will also be responsible for reviewing complex data files, mapping documents, and customer requirements, and providing guidance on best practices. You will need to be able to speak to the internal technical capabilities of Billtrust\u2019s products while understanding customer requirements in order to provide customers the direction and guidance on their options for the best user experience as it pertains to their business needs. \n \n Regularly communicate progress and alert Project Managers and stakeholders if a deliverable is not achievable or is likely to slip, allowing sufficient time for a sensible course of action while recommending alternative approaches and/or options to accommodate deadlines and prevent slippages \n Work closely with stakeholders to clearly define what will be considered in and out of scope for the project and ensure all project team members and stakeholders understand the impacts if any and obtain all necessary sign-offs \n Be the main point of contact for the Application Support Team in fielding questions/concerns regarding requirements and assisting the team in developing their test plans \n Be the main point of contact for other internal Billtrust Teams in fielding questions/concerns as it relates to the build of how to support a customer\u2019s in-scope requirements \n Consistently learning and keeping up to date on Billtrust products, capabilities and new features \n Support and analyze the feasibility of presales and sales opportunities where necessary \n Recommend, and make improvements to the Standard Operating Procedures (SOP) and Desktop Procedures (DTP) documentation that is leveraged by the team for implementing customers \n \n What You'll Bring to the Team: \n \n 0-1+ years of experience in a Business Analyst or related role \n Experience or exposure with written and oral communication, in gathering and documenting requirements, creating functional design specifications, business writing skills, and interacting with business partners and technical resources at all levels of organizations both internally and externally \n Experience and proven ability to interact and communicate effectively with both technical and non-technical personnel \n Experience with problem-solving, analytical, and decision-making skills \n Ability to decompose high-level information into details and apply creativity to solving or providing options to complex problems \n Looks at the global picture and thinks outside of the box by communicating creative and innovative thinking by bringing new ideas and improvements forward \n Develops a well-defined, shared understanding of the project scope \n Bachelor\u2019s Degree, with a technology or business emphasis, or equivalent education/experience \n \n \n \n  Base Compensation: $56,000.00 - $83,000.00 + (bonus offered in addition to base compensation)  Please note that the compensation information is a good faith estimate and is provided pursuant to Equal Pay Laws. Billtrust intends to offer the selected candidate base pay dependent on job-related, non-discriminatory factors such as experience. Our Talent Acquisition team will provide more information about the total compensation package for this position during the interview process. \n \n Don't meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every single qualification. At Billtrust, we celebrate and support diversity and are committed to creating an inclusive environment for all employees. So, if your experience aligns but doesn't exactly match each and every qualification, apply anyway. You may be exactly what we are looking for! \n What You'll Get: \n \n Work from Anywhere:  Our state of the art office, your home, a company paid WeWork.... you decide! \n A Culture that Lives its Values:  Our values are not just words or window dressing, they guide our decisions - big and small - each and every day. \n Flexible   Working Hours : We support your lifestyle- the results are what count. \n Open PTO:  Work-life balance is important. We believe in giving our employees time to truly relax and recharge. \n Sabbatical:  A paid leave to reward longevity and commitment to Billtrust. \n Paid Parental Leave:  To promote parent-child bonding and increase gender equity at home and in the workplace. \n Opportunities for Growth:  Professional development can take many shapes. Join one of our seven ERGs or participate in our Mentor-Mentee, Leadership, and High-Potential Programs- we foster an environment where all employees can grow. \n Recognition:  From Billtrust Bucks and Gongings to Culture Champion and Founders Awards, our employees are recognized for hard work and outcomes achieved. \n Benefits:  Medical, dental, vision, 401(k) with company match, short-term and long-term disability, flexible spending accounts, HSA, and life, cancer, and AD&D insurance. \n Minimal Bureaucracy:  An entrepreneurial environment of ownership and accountability allows you to get work done. \n \n Who We Are: \n  Billtrust is a leading provider of cloud-based software and integrated payment processing solutions that simplify and automate B2B commerce. Accounts receivable is broken and relies on conventional processes that are outdated, inefficient, manual and largely paper based. Billtrust is at the forefront of the digital transformation of AR, providing mission-critical solutions that span credit decisioning and monitoring, online ordering, invoice delivery, payments and remittance capture, invoicing, cash application and collections. Our platform has processed $1 trillion+ invoice dollars and we have seen 28% year-over-year software & payments revenue growth (2021). With more than 2,400 customers, we have helped companies like GlobalTranz, United Rentals, Acushnet and Ferguson Enterprises get paid faster and more efficiently. \n  For more than 20 years, we have achieved remarkable success and we attribute our growth to our people and culture. We encourage employees to have autonomy, think creatively, share ideas - even with our CEO - and to challenge the status quo every day.#LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "86ddf8f4113e87e0": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "IT Data Analyst",
        "company": "Boston Medical Center",
        "desc": "POSITION SUMMARY:\n  \n \n \n   The IT Data Analyst applies technical and analytic skills to extract and interpret data across multiple integrated systems, documents report specifications, and produces analyses. Identifies trends and opportunities for growth through analysis of complex datasets. Responsible for creating, maintaining, updating and publishing reports and dashboards for IT systems, and recommends enhancements to reporting models. Develops and implements data quality assurance process and methodologies to ensure accuracy, completeness, and consistency of IT data.\n  \n \n \n   Position: IT Data Analyst\n  \n \n   Department: Service Desk\n  \n \n   Schedule: Full Time\n  \n \n \n   ESSENTIAL RESPONSIBILITIES / DUTIES:\n  \n \n  Proactively analyze data to answer key questions for stakeholders, with an eye on what drives operational performance, and investigate and communicate which areas need improvement in efficiency and productivity. \n  Designs and develops reports, dashboards, and data visualizations utilizing in-house tools. \n  Produces analyses based on operational data to support operational improvement and consistency. \n  Serves as the data expert for IT Service data, including ServiceNow system reports and maintains an inventory IT reports. \n  Responsible for educating IT and the Business on ServiceNow collected data. \n  Works closely with IT stakeholders, facilitating effective communication and collaboration to identify and address data-related issues, requirements, and opportunities. \n  Collaborates with ServiceNow Developer and/or directly with key business users to ensure business requirements and report specifications are documented accurately and completely. \n  Partners with IT resources to understand complex issues and analyzes and presents data in a meaningful way for decision making. \n  Present data-driven insights to IT stakeholders, enabling them o make informed decisions and drive continuous improvement. \n  Develops and implements data quality assurance process and methodologies to ensure the accuracy, completeness, and consistency of IT data. \n  Identifies and remediates data discrepancies, anomalies, and errors through data cleansing and validation techniques. \n  Drives workflow and process change by identifying opportunities for improvement derived from ServiceNow and other third party systems data analysis \n  Works with Business System Analysts and IT Project Managers to support requests for data on projects. \n  Follows established SDLC, change control, release management and incident management processes. \n  Applies business knowledge to recommend enhancements to reporting models \n  Leads sessions with business areas to understand their reporting needs, provide recommendations for potential revisions to existing reports or scope out new reports when required. \n  Contributes to the development and enforcement of data governance policies, standards, and practices. \n \n \n \n   JOB REQUIREMENTS\n  \n \n \n   EXPERIENCE:\n  \n \n  3+ years of experience in data analysis. \n  Proven analytics skills, including mining, evaluation, and visualization \n  Previous experience working with relational databases \n  Technical writing experience in relevant areas, including queries, report, and presentations \n  Strong SQL or Excel skills, with aptitude for learning other analytics tools \n  Experience with IT Service and Support workflows \n  Experience with ServiceNow platforms \n \n \n \n   KNOWLEDGE AND SKILLS:\n  \n \n  Effective collaborative and proven process improvement skills. \n  Strong oral and written communication skills; ability to interact within all levels of the organization. \n  A strong working knowledge of Microsoft Office products. \n  Demonstrated ability to successfully plan, organize and manage projects. \n  Detail oriented, excellent proof reading and editing skills. \n  Proven analytical and problem solving skills \n  Ability to exercise independent judgment and make sound business decisions effectively. \n  Working knowledge of healthcare industry",
        "cleaned_desc": "POSITION SUMMARY:\n  \n \n \n   The IT Data Analyst applies technical and analytic skills to extract and interpret data across multiple integrated systems, documents report specifications, and produces analyses. Identifies trends and opportunities for growth through analysis of complex datasets. Responsible for creating, maintaining, updating and publishing reports and dashboards for IT systems, and recommends enhancements to reporting models. Develops and implements data quality assurance process and methodologies to ensure accuracy, completeness, and consistency of IT data.\n  \n \n \n   Position: IT Data Analyst\n  \n \n   Department: Service Desk\n     Works closely with IT stakeholders, facilitating effective communication and collaboration to identify and address data-related issues, requirements, and opportunities. \n  Collaborates with ServiceNow Developer and/or directly with key business users to ensure business requirements and report specifications are documented accurately and completely. \n  Partners with IT resources to understand complex issues and analyzes and presents data in a meaningful way for decision making. \n  Present data-driven insights to IT stakeholders, enabling them o make informed decisions and drive continuous improvement. \n  Develops and implements data quality assurance process and methodologies to ensure the accuracy, completeness, and consistency of IT data. \n  Identifies and remediates data discrepancies, anomalies, and errors through data cleansing and validation techniques. \n  Drives workflow and process change by identifying opportunities for improvement derived from ServiceNow and other third party systems data analysis \n  Works with Business System Analysts and IT Project Managers to support requests for data on projects. \n  Follows established SDLC, change control, release management and incident management processes. \n  Applies business knowledge to recommend enhancements to reporting models \n  Leads sessions with business areas to understand their reporting needs, provide recommendations for potential revisions to existing reports or scope out new reports when required. \n  Contributes to the development and enforcement of data governance policies, standards, and practices. \n   \n \n   JOB REQUIREMENTS\n  \n \n \n   EXPERIENCE:\n  \n \n  3+ years of experience in data analysis. \n  Proven analytics skills, including mining, evaluation, and visualization \n  Previous experience working with relational databases \n  Technical writing experience in relevant areas, including queries, report, and presentations    Strong SQL or Excel skills, with aptitude for learning other analytics tools \n  Experience with IT Service and Support workflows \n  Experience with ServiceNow platforms \n \n \n \n   KNOWLEDGE AND SKILLS:\n  \n \n  Effective collaborative and proven process improvement skills. \n  Strong oral and written communication skills; ability to interact within all levels of the organization. \n  A strong working knowledge of Microsoft Office products. \n  Demonstrated ability to successfully plan, organize and manage projects. ",
        "techs": [
            "servicenow",
            "sql",
            "excel",
            "microsoft office"
        ],
        "cleaned_techs": [
            "servicenow",
            "sql",
            "excel",
            "microsoft"
        ]
    },
    "211b53e8a11af768": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 118000.0,
        "salary_max": 177000.0,
        "title": "Data Analyst IV",
        "company": "Galileo",
        "desc": "ABOUT US \n  Galileo is a team-based medical practice working to improve the quality and affordability of health care for all. Operating across 50 states, Galileo offers high-touch, data-driven, multi-specialty, longitudinal care to diverse and complex patients\u2014on the phone, in the home, and everywhere in between. Regional and national health plans, employers, and Fortune 500 organizations trust Galileo as the leading solution to improve population health. Founded by Dr. Tom X. Lee, the healthcare pioneer behind One Medical and Epocrates, Galileo is a team of leading innovators from healthcare, technology, and human-centered design. Our mission is to apply that talent and scientific thinking to transform society by solving our largest, toughest healthcare problems, while at the same time bringing patient and provider closer. \n \n  ABOUT THE ROLE \n  Galileo is looking for an experienced Data Analyst IV (Specialist) to join our Insights team. In this role, you will develop and own analytical models relative to Digital Analytics and contribute to our growing suite of data and Business Intelligence capabilities. Your work will enable and validate our innovative value-based care model in delivering high quality care to our growing patient population. \n  Here's what you'll do: \n \n Collaborate with Clinical and Operations teams to build and maintain a suite of Digital KPIs and metrics that are used to manage our Digital Business operations. \n Collaborate with Product and Engineering to understand UI/UX and downstream data flows relative to digital app utilization. \n Build and own analytical models with respect to Digital Analytics - including acquisition, engagement, user behavior, resource efficiency, among others. \n Learn and implement new technologies to increase the efficiency and predictive nature of our analytical models \n \n ABOUT YOU \n  You are a curious problem solver, with a high attention to detail, looking to leverage your digital app analytics expertise as an individual contributor in this innovative provider group. \n  We would love to hear from you if you have the following or equivalent experience: \n \n 5+ years experience with digital app analytics. \n Skilled at communication around technical concepts and ideas and the ability to collaborate with all parts of the organization. \n Proficient in SQL \n Experience with Looker (or similar BI tool) \n Experience with dbt (or similar data modeling tool) \n A willingness to learn and master new tools and technologies in our analytic stack \n A desire to make a difference and be a part of something meaningful \n \n COMPENSATION RANGE  $118,000 - $177,000 based upon experience and market location + equity options \n  #LIWA1 #LI-Remote \n \n  BENEFITS \n \n Medical / Dental / Vision insurance \n Flexible Spending Account \n Health Savings Account + match \n Company paid STD/LTD, AD&D, and Life insurance \n Paid Family Leave \n 401K + match \n Paid Time Off \n \n HOW WE HIRE \n  Galileo is committed to hiring the best team possible to build health care that works for everyone. We value a diverse set of perspectives to deliver the best possible solutions to those problems. We look for talent from a wide range of backgrounds\u2014including, but not limited to\u2014race, age, sexual orientation, gender identity and expression, national origin, religion, disability, and veteran status. Galileo is an Equal Opportunity Employer and provides reasonable accommodations to applicants and employees with a qualifying disability or conflict with a sincerely held religious belief, unless doing so would cause an undue hardship or fail to eliminate a direct threat.",
        "cleaned_desc": "  We would love to hear from you if you have the following or equivalent experience: \n \n 5+ years experience with digital app analytics. \n Skilled at communication around technical concepts and ideas and the ability to collaborate with all parts of the organization. \n Proficient in SQL \n Experience with Looker (or similar BI tool) \n Experience with dbt (or similar data modeling tool) ",
        "techs": [
            "digital app analytics",
            "sql",
            "looker (or similar bi tool)",
            "dbt (or similar data modeling tool)"
        ],
        "cleaned_techs": [
            "digital app analytics",
            "sql",
            "looker (or similar bi tool)",
            "dbt (or similar data modeling tool)"
        ]
    },
    "0f63ffe5dcd50132": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 51000.0,
        "salary_max": 55000.0,
        "title": "Jr. Program Analyst",
        "company": "Vital Edge Solutions",
        "desc": "Come join our team supporting the Department of Veteran Affairs. \n Must obtain a sponsored US Public Trust Clearance. \n Responsibilities: The Jr. Program Analyst supports the preparation of and maintains relevant reports pertaining to program performance. They support the development and execution of comprehensive program management plans, change management plans, and risk management plans. The Jr. Program Analyst also collects, reviews and analyzes data and prepares reports, charts, and other presentation materials utilizing word processing, spreadsheet, or specialized software. They prepare and distribute reports or other communications on a regular schedule. They also schedule and coordinate meetings, travel, and other group activities. They create and maintain agendas, meeting minutes, and action item lists. \n Qualifications: - Bachelor's degree in a relevant field such as Computer Science or Information Systems. - Excellent communication skills, both written and verbal. - Ability to work independently as well as collaboratively in a team environment. \n We offer competitive compensation packages including benefits such as health insurance, retirement plans, and paid time off. Join our team of talented professionals and contribute to meaningful projects in the field of data analytics. Apply now to begin your career as a Junior Program Analyst. \n Job Type: Full-time \n Pay: $51,000.00 - $55,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Disability insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Vision insurance \n Work from home \n \n Experience level: \n \n 1 year \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "8c75de7a2a6f0c17": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Research Informatics Data Analyst",
        "company": "Boston Medical Center",
        "desc": "Research Informatics Data Analyst, Research Informatics\n  \n \n   Location: Boston, MA\n  \n \n   Schedule: 40 hours per week, Remote\n  \n \n \n   ABOUT BMC:\n  \n \n \n   At Boston Medical Center (BMC), our diverse staff works together for one goal \u2014 to provide exceptional and equitable care to improve the health of the people of Boston. Our bold vision to transform health care is powered by our respect for our patients and our commitment to ensure everyone who comes through our doors has a positive experience.\n  \n \n \n   As one of the top places to work in health care, we know that providing exceptional care for patients begins with caring for our staff. That\u2019s why you\u2019ll find a supportive work environment at BMC, with rich opportunities throughout your career for training, development, and growth and where you\u2019ll have the tools you need to take charge of your own practice environment.\n  \n \n \n   There\u2019s never been a better or more exciting time to join our BMC community and help us continue to carry out our mission of delivering exceptional and equitable care to all.\n  \n \n \n   POSITION SUMMARY:\n  \n \n \n   The Research Informatics Data Analyst is responsible for the analysis of Research Operations data; reviewing/optimizing data capture and data streams; generating/analyzing regular reports for leadership, providing in-house content expertise in retrieving/managing data from various systems, informatics; and statistical/epidemiological analysis, working with Research Informatics staff, Research Operations staff, Department Administrators, and internal researchers.\n  \n \n \n   This position requires strong knowledge of data pipelines, quality assurance, and strict adherence to research and regulatory data policies to ensure secure transmission/retrieval of data. The position may provide limited project management support for data extraction projects and requires a willingness to learn new systems and data platforms utilized across the BMC Health System.\n  \n \n \n   JOB RESPONSIBILITIES:\n  \n \n \n   Data Systems Improvement\n  \n \n  Collaborate with Research Informatics and Research Operations staff to identify, mine, and analyze data captured across disparate systems, developing and managing reports and dashboards to reveal insights that lead to the facilitation of operational decisions. Support the Research Informatics team in developing automated systems/workflows. \n  Responsible for supporting the integration points between data systems, providing direction and support to ensure accurate data capture, optimizing workflows where necessary to produce high quality, accurate data. \n  Diagnoses data workflow process problems and proposes solutions, coordinating with other technical and/or business resources as necessary for assistance. Participates in all aspects of testing for data capture systems utilized by BMC Research Operations. \n  Works closely with various levels of management and other IT/analytic groups to understand data-related issues and other issues concerning how to quantitatively capture the BMC research portfolio, working in conjunction with the Research Information Systems (RIS) team to investigate problems and implement solutions. \n \n \n \n   Analytics and Data Visualizations\n  \n \n  Assists in the overall capture, tracking, consolidation, and analysis of BMC Research Operations programmatic and clinical research data. \n  Analyzes benchmarks and key indicators for BMC Research Operations at the institution and department level using R, SQL, or similar coding/programming language. \n  Collaborate with Research Informatics Systems Analyst and key users on the development of data visualizations and dashboards, ensuring all products leverage accurate and complete data. \n \n \n \n   OTHER DUTIES:\n  \n \n  Provides general analytical support to Research Operations and/or management as requested. \n  Completes special projects and other duties as needed. \n  Conforms to hospital standards of performance and conduct, including those pertaining to patient rights, to ensure that exceptional customer service and patient care may be provided. \n \n \n \n   JOB REQUIREMENTS:\n  \n \n  Bachelor's degree in Computer Science, Computer Information Systems, Computer/Electronic Engineering, Applied Biostatistics, Public Health, Systems Improvement, or Information Science. Master\u2019s degree a plus. \n \n \n     A minimum of 2 years of experience using R, SQL, or similar programming language to manipulate disparate data, conduct data mining, optimize data pipelines.\n    \n \n \n     At least 1 year of experience working in data systems and process improvement with multiple stakeholders.\n    \n \n \n \n   KNOWLEDGE AND SKILLS:\n  \n \n  Demonstrated ability to use R, SQL, or similar coding/programming language required. \n  Experience managing data workflow solutions in a dynamic and highly integrated organization required. \n  Experience with Infor, InfoEd, electronic data capture systems, or other research/clinical/administrive/financial data systems. \n  Ability to use R, Tableau, or similar data visualization tool required a plus. \n  Knowledge of EPIC Clarity is a plus. \n  Experiene with healthcare information management, healthcare analytics, clinical research, clinical data warehouses, other relevant healthcare field is a plus. \n \n \n \n   JOB BENEFITS:\n  \n \n  Competitive pay \n  Tuition reimbursement and tuition remission programs \n  Highly subsidized medical, dental, and vision insurance options \n  Access to Pathways, a leadership acceleration program increasing \n    \n    inclusion and diversity\n     at the leadership level across Boston Medical Center Health System \n  Supportive work environment with a focus on training, professional development, and growth \n \n \n \n   ABOUT THE DEPARTMENT:\n  \n \n \n   The BMC Research Informatics Department aims to serve as a centralized entity to support the Boston Medical Center (BMC) research community in research data strategy and infrastructure by leading optimization efforts to improve data quality and implementing innovative strategies to leverage research-quality data that support the institution\u2019s broad research goals.\n  \n \n \n   BMC Research Informatics collaborates with Research Operations on their data capture, tracking, reporting, and utilization regarding research awards and projects at BMC. BMC Research Operations data come from a wide rage of clinical and administrative systems.\n  \n \n \n \n    Boston Medical Center\n    is an Equal Opportunity/Affirmative Action Employer. If you need accommodation for any part of the application process because of a medical condition or disability, please send an e-mail to \n   \n   Talentacquisition@bmc.org\n    or call 617-638-8582 to let us know the nature of your request.",
        "cleaned_desc": " \n   POSITION SUMMARY:\n  \n \n \n   The Research Informatics Data Analyst is responsible for the analysis of Research Operations data; reviewing/optimizing data capture and data streams; generating/analyzing regular reports for leadership, providing in-house content expertise in retrieving/managing data from various systems, informatics; and statistical/epidemiological analysis, working with Research Informatics staff, Research Operations staff, Department Administrators, and internal researchers.\n  \n \n \n   This position requires strong knowledge of data pipelines, quality assurance, and strict adherence to research and regulatory data policies to ensure secure transmission/retrieval of data. The position may provide limited project management support for data extraction projects and requires a willingness to learn new systems and data platforms utilized across the BMC Health System.\n  \n \n \n   JOB RESPONSIBILITIES:\n  \n \n \n   Data Systems Improvement\n  \n \n  Collaborate with Research Informatics and Research Operations staff to identify, mine, and analyze data captured across disparate systems, developing and managing reports and dashboards to reveal insights that lead to the facilitation of operational decisions. Support the Research Informatics team in developing automated systems/workflows. \n  Responsible for supporting the integration points between data systems, providing direction and support to ensure accurate data capture, optimizing workflows where necessary to produce high quality, accurate data. \n  Diagnoses data workflow process problems and proposes solutions, coordinating with other technical and/or business resources as necessary for assistance. Participates in all aspects of testing for data capture systems utilized by BMC Research Operations. \n  Works closely with various levels of management and other IT/analytic groups to understand data-related issues and other issues concerning how to quantitatively capture the BMC research portfolio, working in conjunction with the Research Information Systems (RIS) team to investigate problems and implement solutions. \n   \n \n   Analytics and Data Visualizations\n  \n \n  Assists in the overall capture, tracking, consolidation, and analysis of BMC Research Operations programmatic and clinical research data. \n  Analyzes benchmarks and key indicators for BMC Research Operations at the institution and department level using R, SQL, or similar coding/programming language. \n  Collaborate with Research Informatics Systems Analyst and key users on the development of data visualizations and dashboards, ensuring all products leverage accurate and complete data. \n \n \n \n   OTHER DUTIES:\n  \n \n  Provides general analytical support to Research Operations and/or management as requested. \n  Completes special projects and other duties as needed. \n  Conforms to hospital standards of performance and conduct, including those pertaining to patient rights, to ensure that exceptional customer service and patient care may be provided. \n \n \n \n   JOB REQUIREMENTS:\n  \n \n  Bachelor's degree in Computer Science, Computer Information Systems, Computer/Electronic Engineering, Applied Biostatistics, Public Health, Systems Improvement, or Information Science. Master\u2019s degree a plus. \n   \n     A minimum of 2 years of experience using R, SQL, or similar programming language to manipulate disparate data, conduct data mining, optimize data pipelines.\n    \n \n \n     At least 1 year of experience working in data systems and process improvement with multiple stakeholders.\n    \n \n \n \n   KNOWLEDGE AND SKILLS:\n  \n \n  Demonstrated ability to use R, SQL, or similar coding/programming language required. \n  Experience managing data workflow solutions in a dynamic and highly integrated organization required. \n  Experience with Infor, InfoEd, electronic data capture systems, or other research/clinical/administrive/financial data systems. \n  Ability to use R, Tableau, or similar data visualization tool required a plus. \n  Knowledge of EPIC Clarity is a plus. \n  Experiene with healthcare information management, healthcare analytics, clinical research, clinical data warehouses, other relevant healthcare field is a plus. \n \n \n \n   JOB BENEFITS:\n  \n ",
        "techs": [
            "r",
            "sql",
            "infor",
            "infoed",
            "tableau",
            "epic clarity"
        ],
        "cleaned_techs": [
            "r",
            "sql",
            "infor",
            "infoed",
            "tableau",
            "epic clarity"
        ]
    },
    "9427eae01beef3ce": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 59941.273,
        "salary_max": 75899.01,
        "title": "Data Analytics Specialist",
        "company": "Diversified Services Network",
        "desc": "Diversified Services Network, Inc. is seeking a full-time  Data Analytics Specialist  to join our team! We offer  FULLY REMOTE  work, full benefits, PTO, 401k, and more! If you're looking to grow your career within a stable and extremely reputable Fortune 100 organization \u2013 let\u2019s talk! \n As  Data Analytics Specialist , you will be working closely with our Digital Analytics team to measure and analyze the business impact of Global Dealer Standards. You\u2019ll also work with various business partners to use analytics to maximize value realization from Global Dealer Standards. \n Job Responsibilities: \n \u00b7 Conduct Digital Standards Business Outcomes study. \n \u00b7 Prepare monthly Standards Adoption and Utilization report and highlights. \n \u00b7 Ensure data quality of Adoption and Utilization Data. \n \u00b7 Support new standards generations by aligning Business Outcomes with stakeholders. \n \u00b7 Coordinate and test external dashboards. \n \u00b7 Adoption and Utilization Data documentation development. \n \u00b7 Work with analytics and product team to identify data sources and get necessary data. \n Technical Skills Required: \n \u00b7 1+ years of eCommerce analytics experience. \n \u00b7 Ability to communicate complex data in a simple, actionable way. \n \u00b7 Ability to visualize data in the most effective way possible for a given project or study. \n \u00b7 Advance expertise with Excel. Power Bi. \n \u00b7 SQL knowledge is a benefit. \n \u00b7 Familiarity with statistics methods is a strong benefit. \n \u00b7 Previous experience as a Business Analyst is beneficial, but not a requirement. \n \u00b7 Preparing specifications, documentation for development. \n \u00b7 Experience with PowerBI, DAX, and SQL. \n \u00b7 Hypothesis testing/AB Testing experience is beneficial, but not a requirement. \n \u00b7 Experience partnering with data engineers. \n \u00b7 Experience supporting ETA, data pipeline development. \n \u00b7 Data insights and data modelling experience. \n Soft Skills: \n \u00b7 Proven ability to work with diverse, multi-functional teams with different backgrounds, and across business units. \n \u00b7 Self-driven, motivated, ability to work independently. \n \u00b7 Eagerness to research and learn new types of analysis. \n Education Requirements: \n \u00b7 College or university degree or certification. \n Benefits: \n \u00b7 Medical Insurance \n \u00b7 Dental Insurance \n \u00b7 Vision Insurance \n \u00b7 Life Insurance \n \u00b7 Short-term and Long-term Disability \n \u00b7 Paid Time Off \n \u00b7 Paid Holidays \n \u00b7 401K Options \n Job Type: Full-time \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 1 year \n 2 years \n Under 1 year \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Microsoft Excel: 1 year (Preferred) \n Power BI: 1 year (Preferred) \n SQL: 1 year (Preferred) \n eCommerce analytics: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": " \u00b7 Advance expertise with Excel. Power Bi. \n \u00b7 SQL knowledge is a benefit. \n \u00b7 Familiarity with statistics methods is a strong benefit. \n \u00b7 Previous experience as a Business Analyst is beneficial, but not a requirement. \n \u00b7 Preparing specifications, documentation for development. \n \u00b7 Experience with PowerBI, DAX, and SQL. \n \u00b7 Hypothesis testing/AB Testing experience is beneficial, but not a requirement. \n \u00b7 Experience partnering with data engineers. \n \u00b7 Experience supporting ETA, data pipeline development. \n \u00b7 Data insights and data modelling experience. \n Soft Skills: \n \u00b7 Proven ability to work with diverse, multi-functional teams with different backgrounds, and across business units. \n \u00b7 Self-driven, motivated, ability to work independently. \n \u00b7 Eagerness to research and learn new types of analysis. ",
        "techs": [
            "excel",
            "power bi",
            "sql",
            "statistics methods",
            "business analyst",
            "powerbi",
            "dax",
            "sql",
            "hypothesis testing",
            "ab testing",
            "data engineers",
            "eta",
            "data pipeline development",
            "data insights",
            "data modelling",
            "self-driven",
            "motivated",
            "ability to work independently",
            "eagerness to research and learn new types of analysis"
        ],
        "cleaned_techs": [
            "excel",
            "powerbi",
            "sql",
            "statistics methods",
            "dax",
            "hypothesis testing",
            "ab testing",
            "data engineers",
            "eta",
            "data pipeline development",
            "data insights",
            "data modelling",
            "self-driven",
            "motivated",
            "eagerness to research and learn new types of analysis"
        ]
    },
    "bb746c44724cdff6": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90205.58,
        "salary_max": 114220.36,
        "title": "USA - Data Engineering Business Systems Analyst",
        "company": "Avestacs",
        "desc": "Job Title:  Data Engineering Business Systems Analyst \n  Location:  Remote ( United States ) \n  Type:  Fulltime \n \n \n  About the Role: \n  They are seeking a highly motivated and experienced  Data Engineering Business Systems Analyst  ( BSA ) to join their team. \n  As a BSA, you will be responsible for gathering requirements, analyzing data, designing, and implementing data-driven solutions, and supporting data-related initiatives across the organization. \n \n \n  The ideal candidate will have a strong technical background in data engineering and a solid understanding of business processes. \n \n Should be Finance background or prior experience working for  Finance data warehousing \n Experience in carrying out business requirement gathering and solution design. \n Expert knowledge in  Data Analysis  &  SQL query  language \n Working experience with any reporting tool. \n \n \n \n  Key Responsibilities: \n \n Work closely with stakeholders to gather and understand business requirements. \n Analyze data to identify patterns, trends, and insights that can be used to drive business decisions. \n Design and implement data-driven solutions to support business initiatives. \n Develop and maintain data pipelines, data marts, and data lakes. \n Collaborate with cross-functional teams to ensure data is accurate, consistent, and accessible. \n \n \n \n  Skills Matrix: \n \n Should be  Finance background  and with  working experience in SAP  and prior experience working for Finance data warehousing project. \n Experience in carrying out business requirement gathering and solution design. \n Expert knowledge in  Data Analysis & SQL query  language \n Working experience with any reporting tool. \n Good Excel Skills. \n Excellent communication and soft skills.",
        "cleaned_desc": "  As a BSA, you will be responsible for gathering requirements, analyzing data, designing, and implementing data-driven solutions, and supporting data-related initiatives across the organization. \n \n \n  The ideal candidate will have a strong technical background in data engineering and a solid understanding of business processes. \n \n Should be Finance background or prior experience working for  Finance data warehousing \n Experience in carrying out business requirement gathering and solution design.   Work closely with stakeholders to gather and understand business requirements. \n Analyze data to identify patterns, trends, and insights that can be used to drive business decisions. \n Design and implement data-driven solutions to support business initiatives. \n Develop and maintain data pipelines, data marts, and data lakes. \n Collaborate with cross-functional teams to ensure data is accurate, consistent, and accessible. \n \n   \n  Skills Matrix: \n \n Should be  Finance background  and with  working experience in SAP  and prior experience working for Finance data warehousing project. \n Experience in carrying out business requirement gathering and solution design. \n Expert knowledge in  Data Analysis & SQL query  language \n Working experience with any reporting tool. ",
        "techs": [
            "sap",
            "sql",
            "reporting tool"
        ],
        "cleaned_techs": [
            "sap",
            "sql",
            "reporting tool"
        ]
    },
    "28206cd1c7a681ec": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 50.0,
        "salary_max": 55.0,
        "title": "LU - Data Analyst w/ MS Dataverse Exp - Remote",
        "company": "FOCUSED HR SOLUTIONS LLC",
        "desc": "** Candidates will be allowed to work remotely. Candidate must work EST Business Hours. \n ** \n \n \n  Our direct client has an opening for a Data Analyst w/ MS Dataverse Exp position # 686457. This position is for 12+ months, with option of extension, and will be worked in remotely 0must work EST business hours).\n  \n  If you are interested, please submit the following:\n   YOUR CURRENT RESUME\n   YOUR HOURLY RATE Max Rate is $50-55/hr W2 or $55-60/hr C2C\n  \n  Below is the job description \u2013 Resumes due ASAP \u2013\n  \n  Description:\n  \n  Currently, the client enterprise is a complex, multi-platform data environment. Technologies in use include Oracle, DB2, MySQL, and SQL Server, as well as desktop-based applications such as MS Access and MS Excel. DEQ aims to establish an enterprise data model with a primary goal of standardizing shared data entities and attributes and a secondary goal of standardizing database management systems and tools. Related transactional databases and data warehouses will be hosted in Azure, generally using Microsoft Dataverse and SQL Server. The Senior Data Analyst/Architect will provide analysis and leadership on data analysis projects across the client\u2019s enterprise. You will provide insight to other data analysts, data architects, and application developers related to creating an enterprise data model that meets DEQ's business and technical requirements. You will also provide subject matter expertise related to Microsoft Dataverse, SQL Server, Azure Data Factory, and SSIS.\n  \n  Required/Desired Skills\n  \n  Outstanding interpersonal and communication skills and experience collaborating and influencing across all levels of the organization. - Required - 3 Years\n   Experience with Azure Data Factory as an ETL tool - Required - 3 Years\n   Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) with a focus on data analysis, data structures \u2013 Required \u2013 3 Years\n   Experience with MS Dataverse \u2013 Required - 3 Years\n   Experience with MS SSIS - Required - 3 Years\n   Proven track record of solving real world problems using data. Excellent critical thinking skills is a must have for this role. - Required - 3 Years\n   Understanding of different database platforms: Oracle, SQL Server (On-Prem / Azure), DB2, and MS Access. - Required - 3 Years\n   Excellent communication skills including written, verbal, and technology illustrations. - Required - 3 Years\n   Understanding of Data Warehousing and data mining. - Required - 3 Years\n   Understanding of modeling strategies (dimensional, snowflake, relational, unstructured). - Required - 3 Years\n   Experience designing and delivering data mapping specifications for large reporting platforms. Writing and maintaining business rules using SQL logic - Required - 3 Years\n   Demonstrated experience in writing ad-hoc SQL statements - Required - 3 Years\n   Strong interest in playing a technical data steward role across our business and technology partners to understand and detail our data, appropriate - Required - 3 Years\n   Proven experience with ERD/Data Modelling tools (Toad or others). - Required - 3 Years\n   Experience in executing projects in an Agile / Hybrid environment - Required - 3 Years\n   Demonstrated technical ability in learning new technologies and adapting to frequent changes in the technical environment - Required - 3 Years\n   Experience with data reporting tools (Power BI, others) - Required - 3 Years\n  \n  By replying to this job advertisement, I agree I want to receive additional job advertisements from Focused HR Solutions, including email, phone and mail to the contact information I am submitting. I consent to Focused HR Solutions, its affiliates, third parties and partners processing my personal data for these purposes and as described in the Privacy Policy. I understand that I can withdraw my consent at any time.\n  \n This is a remote position.",
        "cleaned_desc": "  Currently, the client enterprise is a complex, multi-platform data environment. Technologies in use include Oracle, DB2, MySQL, and SQL Server, as well as desktop-based applications such as MS Access and MS Excel. DEQ aims to establish an enterprise data model with a primary goal of standardizing shared data entities and attributes and a secondary goal of standardizing database management systems and tools. Related transactional databases and data warehouses will be hosted in Azure, generally using Microsoft Dataverse and SQL Server. The Senior Data Analyst/Architect will provide analysis and leadership on data analysis projects across the client\u2019s enterprise. You will provide insight to other data analysts, data architects, and application developers related to creating an enterprise data model that meets DEQ's business and technical requirements. You will also provide subject matter expertise related to Microsoft Dataverse, SQL Server, Azure Data Factory, and SSIS.\n  \n  Required/Desired Skills\n  \n  Outstanding interpersonal and communication skills and experience collaborating and influencing across all levels of the organization. - Required - 3 Years\n   Experience with Azure Data Factory as an ETL tool - Required - 3 Years\n   Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) with a focus on data analysis, data structures \u2013 Required \u2013 3 Years    Experience designing and delivering data mapping specifications for large reporting platforms. Writing and maintaining business rules using SQL logic - Required - 3 Years\n   Demonstrated experience in writing ad-hoc SQL statements - Required - 3 Years\n   Strong interest in playing a technical data steward role across our business and technology partners to understand and detail our data, appropriate - Required - 3 Years\n   Proven experience with ERD/Data Modelling tools (Toad or others). - Required - 3 Years\n   Experience in executing projects in an Agile / Hybrid environment - Required - 3 Years\n   Demonstrated technical ability in learning new technologies and adapting to frequent changes in the technical environment - Required - 3 Years\n   Experience with data reporting tools (Power BI, others) - Required - 3 Years",
        "techs": [
            "oracle",
            "db2",
            "mysql",
            "sql server",
            "ms access",
            "ms excel",
            "microsoft dataverse",
            "azure data factory",
            "ssis",
            "toad",
            "power bi"
        ],
        "cleaned_techs": [
            "oracle",
            "db2",
            "mysql",
            "sql",
            "ms access",
            "excel",
            "microsoft dataverse",
            "azure",
            "ssis",
            "toad",
            "powerbi"
        ]
    },
    "aa5efd97b01e9e39": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Health Data Analyst III",
        "company": "WellSense Health Plan",
        "desc": "It\u2019s an exciting time to join the WellSense Health Plan, a growing regional health insurance company with a 25-year history of providing health insurance that works for our members, no matter their circumstances. \n  The Health Data Analyst III is a key member of the Finance management team whose responsibility is to lead analyses to support Finance staff and the Chief Financial Officer in meeting corporate objectives. \n  Our Investment in You: \n \n Full-time remote work \n Competitive salaries \n Excellent benefits \n \n Key Functions/Responsibilities: \n \n Leads the development and submission of key financial regulatory reports (i.e. 4B and 5C financial reports, membership reporting, etc.). \n Leads competitive analysis of regulatory financial and membership reports, including requesting the publicly available data from various state agencies, consolidating and analyzing the data, monitoring trends, researching unusual patterns, and presenting the results to senior leadership. \n Support marketing and sales departments in achieving corporate goals, and supports the Finance department in setting annual budget projections. \n Conducts budget to actual analysis. \n Leads analysis of medical expense reporting and monitoring/reporting of medical expense trend. \n Support other areas of Finance as needed, including, but not limited to, development of pricing and revenue requirements for all products, financial planning / budgeting, IBNR reserves, and high cost claimant tracking. \n Leads analysis of provider ratio reports, member disruption impacts, and provider termination impacts, including estimating future member and financial impacts of proposed changes. \n Develops and implements plans to measure and report on corporate-wide health care delivery cost and utilization / membership trends. \n Responsible for ad hoc analytics including modeling of membership and financial scenarios. Utilizes statistical applications as necessary. \n Serves as data expert for department. Advises Finance department on data warehouse design requests and works with IT to establish priorities. \n Responsible for supporting corporate initiatives/projects that require analysis of health plan data. \n \n \n \n  Qualifications: \n \n \n  Education: \n \n Bachelor\u2019s Degree in Finance, Health Care Administration, or related field required. \n Master\u2019s Degree preferred. \n \n Experience: \n \n 4 years of progressively responsible experience in data modeling, informatics and analysis. Commensurate educational experience in related field will be considered. \n A background in managed healthcare, insurance operations preferred. \n \n Competencies, Skills, and Attributes: \n \n The Analyst III is an experienced user of claims and membership data. \n Working knowledge of MS tools, including MS Office products, MS Access, MS Project, SQL and SAS or other statistical software. Should be proficient in Microsoft Excel. \n Analyst integrates external grouping methodologies such as DRG, ETG and DxCG in analytics. \n Ability to meet deadlines, multi-task, problem solve and use appropriate technology to analyze business problems. Project management skills a plus. \n Strong communications skills, both verbal and written, are required. \n \n \n \n  About WellSense \n  WellSense Health Plan is a nonprofit health insurance company serving more than 740,000 members across Massachusetts and New Hampshire through Medicare, Individual and Family, and Medicaid plans. Founded in 1997, WellSense provides high-quality health plans and services that work for our members, no matter their circumstances. \n \n \n \n  Required Skills\n    \n \n  Required Experience",
        "cleaned_desc": " \n 4 years of progressively responsible experience in data modeling, informatics and analysis. Commensurate educational experience in related field will be considered. \n A background in managed healthcare, insurance operations preferred. \n \n Competencies, Skills, and Attributes: \n \n The Analyst III is an experienced user of claims and membership data. \n Working knowledge of MS tools, including MS Office products, MS Access, MS Project, SQL and SAS or other statistical software. Should be proficient in Microsoft Excel. \n Analyst integrates external grouping methodologies such as DRG, ETG and DxCG in analytics. \n Ability to meet deadlines, multi-task, problem solve and use appropriate technology to analyze business problems. Project management skills a plus. \n Strong communications skills, both verbal and written, are required. ",
        "techs": [
            "ms office products",
            "ms access",
            "ms project",
            "sql",
            "sas",
            "microsoft excel",
            "drg",
            "etg",
            "dxcg"
        ],
        "cleaned_techs": [
            "microsoft",
            "ms access",
            "ms project",
            "sql",
            "sas",
            "excel",
            "drg",
            "etg",
            "dxcg"
        ]
    },
    "083615d42a51199f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81202.0,
        "salary_max": 125368.0,
        "title": "Business Analyst",
        "company": "CorVel Corporation",
        "desc": "CorVel Corporation is hiring a  Senior Business Analyst  to collaborate with our Development and Business Operations teams to facilitate the creation and enhancement of enterprise software applications. You will help the teams by making sure projects are well-organized, well-documented, and smoothly executed, from project initiation and requirements gathering through the final release. \n  The ideal candidate will be highly organized, possess a keen attention to detail, excel in a fast-paced environment, have excellent communication skills, and be able to work both independently and in cooperative team environments. The candidate will also have proven experience in business analysis and project management. \n  This is a remote opportunity. \n \n \n  ESSENTIAL DUTIES & RESPONSIBILITIES: \n \n Elicit and document project requirements in a variety of formats \n Schedule, facilitate and take minutes of meetings with technical and business teams \n Schedule, facilitate and take minutes of meetings with executive leadership and a variety of attendees, including high-value clients \n Document and track project decisions and tasks \n Create and maintain project timelines \n Clear roadblocks to allow the project team to work efficiently and effectively \n Create and present project metrics \n Learn our business model and understand our enterprise applications \n Perform other duties as assigned \n \n \n \n  MINIMUM QUALIFICATIONS (KNOWLEDGE, SKILLS, AND ABILITIES): \n \n Experience with business analysis and requirements gathering \n Experience with building workflow and process diagrams \n \n \n SQL experience \n Experience coordinating technical/software engineering projects \n Excellent written and verbal communication skills \n Excellent organizational and analytical skills \n Advanced skills with MS Office, including Excel \n Ability to multitask in a dynamic, fast-paced environment \n Familiarity with project management and software development lifecycle concepts \n \n \n \n  PREFERRED QUALIFICATIONS (KNOWLEDGE, SKILLS, AND ABILITIES): \n \n Advanced experience with SQL \n Project management experience \n Experience with visualization tools like PowerBI, Tableau \n \n \n \n  PAY RANGE: \n  CorVel uses a market based approach to pay and our salary ranges may vary depending on your location. Pay rates are established taking into account the following factors: federal, state, and local minimum wage requirements, the geographic location differential, job-related skills, experience, qualifications, internal employee equity, and market conditions. Our ranges may be modified at any time. \n  Pay Range: $81,202 \u2013 $125,368 \n  A list of our benefit offerings can be found on our CorVel website: CorVel Careers | Opportunities in Risk Management \n \n \n  About CorVel \n  CorVel, a certified Great Place to Work\u00ae Company, is a national provider of industry-leading risk management solutions for the workers\u2019 compensation, auto, health and disability management industries. CorVel was founded in 1987 and has been publicly traded on the NASDAQ stock exchange since 1991. Our continual investment in human capital and technology enable us to deliver the most innovative and integrated solutions to our clients. We are a stable and growing company with a strong, supportive culture and plenty of career advancement opportunities. Over 4,000 people working across the United States embrace our core values of Accountability, Commitment, Excellence, Integrity and Teamwork (ACE-IT!). \n  A comprehensive benefits package is available for full-time regular employees and includes Medical (HDHP) w/Pharmacy, Dental, Vision, Long Term Disability, Health Savings Account, Flexible Spending Account Options, Life Insurance, Accident Insurance, Critical Illness Insurance, Pre-paid Legal Insurance, Parking and Transit FSA accounts, 401K, ROTH 401K, and paid time off. \n  CorVel is an Equal Opportunity Employer, drug free workplace, and complies with ADA regulations as applicable. \n \n \n  #LI-Remote",
        "cleaned_desc": " Experience with building workflow and process diagrams \n \n \n SQL experience \n Experience coordinating technical/software engineering projects \n Excellent written and verbal communication skills \n Excellent organizational and analytical skills \n Advanced skills with MS Office, including Excel \n Ability to multitask in a dynamic, fast-paced environment \n Familiarity with project management and software development lifecycle concepts \n   \n \n  PREFERRED QUALIFICATIONS (KNOWLEDGE, SKILLS, AND ABILITIES): \n \n Advanced experience with SQL \n Project management experience \n Experience with visualization tools like PowerBI, Tableau \n \n \n \n  PAY RANGE: ",
        "techs": [
            "sql experience",
            "experience coordinating technical/software engineering projects",
            "excellent written and verbal communication skills",
            "excellent organizational and analytical skills",
            "advanced skills with ms office",
            "including excel",
            "ability to multitask in a dynamic",
            "fast-paced environment",
            "familiarity with project management and software development lifecycle concepts",
            "advanced experience with sql",
            "project management experience",
            "experience with visualization tools like powerbi",
            "tableau"
        ],
        "cleaned_techs": [
            "sql",
            "experience coordinating technical/software engineering projects",
            "including excel",
            "fast-paced environment",
            "advanced experience with sql",
            "project management experience",
            "experience with visualization tools like powerbi",
            "tableau"
        ]
    },
    "1fbf492398d8aa97": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 80000.0,
        "salary_max": 95000.0,
        "title": "Coding Business Analyst",
        "company": "CAMPOS EPC",
        "desc": "The primary role of the Business/Cost Analyst is to analyze and maintain cost control systems and processes to ensure assigned projects remain on budget. The Business/Cost Analyst is also responsible for identifying deviations from approved budgets and notifying and working with appropriate stakeholders to develop and publish budget corrections. \n Duties and Responsibilities: \n \n Communicate expenditures, budgets, commitments, estimate at completion, and forecast with Project Managers, Costs Leads, and Project Controls Manager. \n Manage large sets of data and generate meaningful reports, dashboards, and databases. \n Assist a Program Management Office (PMO) with analyzing data, trends that assist in identifying actionable solutions. \n Act as a backup to a Cost Analyst as requested. \n Ensure costs reports are issued on time and with accurate current data. \n Ensure all costs are accounted during the project life cycle. \n Work closely with Project Managers to review project financial status, identify deviations from planned budget, and explain variances. Advise concerning budget corrections. \n Ensure cost controls and reporting processes are applied to track: direct/indirect costs, budgets, and allocations. \n Ensure Work Order Authorization Budgets are not exceeded. \n Ensure accruals are reported and applied to monthly forecast projections. \n Recognize historical trends and provide forecasting for projects; monitor and modify cash flow. \n Run SAP reports with all cost data coming from company financial system (directs/indirect), and analyze reports to identify deviations. Work with proper stakeholder to correct identified deviations. \n Properly read the schedule and understand durations to incorporate in the forecast. \n Organize and track documents as they go through the approval process, make sure signed forms are gathered, and saved for auditing purposes. \n Ensure forecast is revised on a monthly basis, and is based on consideration of progress, pending change orders, expenditure rates, and earned value factors. \n Prepare graphs, diagrams, and other exhibits to illustrate cost status and forecast requirements for management. \n Ensure current budget is updated according to the change management process with latest approved change orders. \n Schedule and attend meetings, as required. \n Complete additional duties as assigned. \n Coding experience and any experience developing applications is a plus \n \n Job Type: Full-time \n Pay: $80,000.00 - $95,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Education: \n \n Bachelor's (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "13f2f39f4cd08205": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 50.0,
        "salary_max": 55.0,
        "title": "Data Visualization",
        "company": "Teamware Solutions",
        "desc": "Position: Data Visualization (Onsite) \n Location: Boynton Beach, FL | Temple Terrace, FL \n Roles & Responsibilities \n Google Dialog Flow Architect: \n \n Strong experience with Google Dialog Flow \n Design and developing ML/AI based conversation solutions using AI platforms like Google Dialog Flow. \n Evaluate solution architectures and identify opportunities for improvement. \n Lead the training of intent models and entity extraction models and develop conversational dialog flows using tools and APIs provided by the AI platform \n \n Job Type: Contract \n Pay: $50.00 - $55.00 per hour \n Experience level: \n \n 8 years \n \n Schedule: \n \n 8 hour shift \n \n Ability to commute/relocate: \n \n Temple Terrace, FL 33617: Reliably commute or planning to relocate before starting work (Required) \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: In person",
        "cleaned_desc": " Strong experience with Google Dialog Flow \n Design and developing ML/AI based conversation solutions using AI platforms like Google Dialog Flow. \n Evaluate solution architectures and identify opportunities for improvement. \n Lead the training of intent models and entity extraction models and develop conversational dialog flows using tools and APIs provided by the AI platform \n ",
        "techs": [
            "google dialog flow"
        ],
        "cleaned_techs": [
            "google dialog flow"
        ]
    },
    "ee22b9284264b8c6": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 32.47,
        "salary_max": 81.82,
        "title": "Business Analyst",
        "company": "TY Software",
        "desc": "Job Title Business Analyst \n Location \u2013 Washington, DC \n Duration \u2013 3 Months \n Business Analyst Job Responsibilities: \n Elicits, analyzes, specifies, and validates the business needs of stakeholders, be they customers or end users. \n Collaborates with project sponsors to determine project scope and vision. \n Clearly identifies project stakeholders and establish customer classes, as well as their characteristics. \n Conducts interviews to gather customer requirements via workshops, questionnaires, surveys, site visits, workflow storyboards, use cases, scenarios, and other methods. \n Identifies and establishes scope and parameters of requirements analysis on a project-by-project basis to define project impact, outcome criteria, and metrics. \n Works with stakeholders and project team to prioritize collected requirements. \n Job Type: Contract \n Salary: $32.47 - $81.82 per hour \n Experience: \n \n Business analysis: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "46a486ed1f52f950": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 72897.67,
        "salary_max": 92304.69,
        "title": "Business Analyst",
        "company": "Chainbridge Solutions Inc",
        "desc": "The Business Analyst is a customer-centric role, supporting the productive and value driven relationship between Chainbridge Solutions and its customers. The BA\u2019s role is to elicit, analyze, specify, and validate the business needs of project sponsors and stakeholders. This includes interviewing stakeholders for gathering and compiling detailed user requirements and developing business process flows to convey to development teams throughout the project lifecycle. This position requires leadership, business and technical competencies and the ability to apply proven communication, analytical, and problem-solving skills to help support the development process. The BA will ensure project deliverables fully satisfy business needs.\n     \n \n \n \n Key Responsibilities  \n \n \n \n \n Serves as liaison between technology and business end-users. \n Elicits requirements from stakeholders. Translates, simplifies and analyzes the feasibility of requirements to promote business process and solution design efficiency. \n Translates conceptual user needs into functional business requirements in a clear manner to development teams. \n Formulates, defines and verifies business cases as well as business and solutions requirements based on both business and user needs. \n Works with Delivery teams to drive alignment of solutions with business strategies and business capability requirements. \n Consults with customers to develop process flows reflecting business process requirements. \n Manages requirements and issues, leveraging tools such as JIRA. \n Verifies solutions align with requirements. \n Conducts reviews to ensure that requirement specifications are correctly interpreted. \n Communicates changes, enhancements, and modifications to project managers, sponsors and other stakeholders. \n Formulates, documents and verifies user stories, acceptance criteria, process flows, and mockups. \n Plays a key role in UAT efforts. \n Supports the development of release notes, user guides, training materials, etc. \n Participates in the implementation, and provides post-implementation support. \n Supports quality assurance testing and creates test plans \n \n \n \n \n Experience and Skill Requirements  \n \n \n \n \n Bachelor\u2019s degree or equivalent experience required. \n 3+ years of relevant Information Solutions /IT experience working in all major phases of software implementation projects. \n 3+ years as a Business Analyst, including proven experience with business and technical requirements analysis, elicitation, modeling, verification and prioritization. \n Experience in Agile Methodology. \n Experience creating and managing tickets in Jira \n Experience in quality assurance testing and test plan creation \n Diversified experience across multiple business domains and functional areas is preferred. \n Strong communication and presentation skills. \n Must possess strong interpersonal and information gathering skills and the ability to relate well to others at all levels throughout the organization. \n Strong organizational skills and ability to multi-task and successfully manage competing/changing priorities. \n Advanced MS Office skill set to include Excel, PowerPoint and Visio. \n Vaccinated against Covid-19. \n \n \n     Physical and Mental Requirements:\n     \n \n Frequently remain in a stationary position, often standing or sitting for prolonged periods of time looking at a computer screen. \n Continuous verbal and written communication with others to exchange information. \n Continuous repetitive movements that may include the wrists, hands, and/or fingers. \n Comprehension- Must continuously be able to understand direction and adhere to established procedures. \n Organization- Must continuously be able to gather and classify information. \n Reasoning and Decision Making- Must continuously use logic to analyze and interpret information and prioritize. \n \n \n \n \n About Chainbridge Solutions  \n \n \n   Entrusted since 2010, Chainbridge Solutions is an award-winning SBA-certified 8(a) and woman-owned small business that specializes in building automated workflow solutions for our federal, state, local and private sector customers.",
        "cleaned_desc": " 3+ years as a Business Analyst, including proven experience with business and technical requirements analysis, elicitation, modeling, verification and prioritization. \n Experience in Agile Methodology. \n Experience creating and managing tickets in Jira \n Experience in quality assurance testing and test plan creation \n Diversified experience across multiple business domains and functional areas is preferred. \n Strong communication and presentation skills. \n Must possess strong interpersonal and information gathering skills and the ability to relate well to others at all levels throughout the organization. \n Strong organizational skills and ability to multi-task and successfully manage competing/changing priorities. \n Advanced MS Office skill set to include Excel, PowerPoint and Visio. \n Vaccinated against Covid-19. \n \n ",
        "techs": [
            "jira",
            "excel",
            "powerpoint",
            "visio"
        ],
        "cleaned_techs": [
            "jira",
            "excel",
            "powerpoint",
            "visio"
        ]
    },
    "e7c1083a203edcfb": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 54039.574,
        "salary_max": 68426.14,
        "title": "Utility Billing Analyst",
        "company": "Resource Energy",
        "desc": "Resource Energy (RES) provides highly customized energy procurement and energy use and data management solutions to many of the world\u2019s largest commercial real estate companies as well as commercial and industrial businesses. At RES, we develop and implement energy strategies that reduce expenses, minimize, and manage risk, leverage our experience and data to optimize energy use and manage greenhouse gas emissions, report on best practices in sustainability as well as generate profitable revenue streams for our clients. These strategies include power and gas procurement, energy data collection and calculations, sustainability analysis/reporting and multiple other energy related services. \n  The Energy Billing Analyst supports multiple clients with primary responsibility for tenant utility billing calculations. Other responsibilities include tracking energy savings, analyzing and reporting energy consumption and costs and other ad hoc services. The role encompasses a detailed and analytically driven framework revolving around energy calculations and accounting. As part of this team, an energy analyst has the unique opportunity within a dynamic environment to shape the organization\u2019s solutions and direction. \n \n  Duties: \n \n Energy billing calculations on behalf of our clients for electric, gas, solar, water and HVAC for tenants within our national footprint of real estate.  \n Ensure the satisfaction of all clients and their tenants by providing a superior level of service. \n Responds timely to tenant/client inquiries in accordance with established Resource Energy procedures. \n Prepares client utility budgets and reforecasts and performs related variance analysis. \n Monthly maintenance of utility tariff data, and property information within our database to ensure consistency and accuracy of reporting. \n Reviews utility specific lease language, to ensure tenants are properly billed in accordance with their individual leases. \n Resolution of utility account issues with utility companies and bill processing firms. \n Participation in client requested or other internal projects to advance the mission of the organization; may include tenant metering, utility system analysis and shopping center allocation analysis. \n Energy performance reporting for clients and related analysis on usage and cost trends \n Ad hoc Reporting in response to client specific requests \n Other additional responsibilities might also include, but are not limited to: load study analysis, assisting in software development, demand response enrollment, and client presentations. \n \n Qualifications: \n \n BA/BS in Energy, Accounting, Engineering, Computer Science or similar analytical discipline preferred. \n Previous related work experience with knowledge of accounting concepts, energy calculations, or commercial real estate experience preferred. \n Proficient in using MS Excel to combine and analyze data from various sources and generate reports and graphics. Must be able to combine large volumes of data for consolidated reporting. \n Strong client service orientation with the ability to interface with all levels within our clients\u2019 organizations \n Strong attention to detail with excellent time management, project management and follow through skills",
        "cleaned_desc": " Previous related work experience with knowledge of accounting concepts, energy calculations, or commercial real estate experience preferred. \n Proficient in using MS Excel to combine and analyze data from various sources and generate reports and graphics. Must be able to combine large volumes of data for consolidated reporting. \n Strong client service orientation with the ability to interface with all levels within our clients\u2019 organizations \n Strong attention to detail with excellent time management, project management and follow through skills",
        "techs": [
            "ms excel",
            "consolidation",
            "data analysis",
            "data visualization",
            "reporting",
            "graphics",
            "client service",
            "time management",
            "project management",
            "follow through skills"
        ],
        "cleaned_techs": [
            "excel",
            "consolidation",
            "data visualization",
            "reporting",
            "graphics",
            "client service",
            "time management",
            "project management"
        ]
    },
    "57b813144a9f898a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 48000.0,
        "salary_max": 64800.0,
        "title": "Data Specialist",
        "company": "NRC Health",
        "desc": "At NRC Health, we promise to help our customers bring Human Understanding to healthcare for their patients and communities. Our associates are at the heart of delivering that promise, so we promise that same Human Understanding to each other. Come where culture is everything.\n  \n \n \n \n  Our associates. . . \n \n \n \n \n  Have Purpose \u2013  we do work that matters for our partners, the community, and the healthcare industry.\n  \n \n Innovate  with us to move healthcare forward.\n  \n \n Give back  to the community with paid volunteer time off.\n  \n \n \n \n  Think Boldly  \u2013 we have big ideas and are empowered to \u201cthink like an owner.\u201d\n  \n \n Fit your role  and do what you love.\n  \n \n Grow and develop  along a career path designed by you.\n  \n \n \n \n  Feel Connected  \u2013 our favorite thing about our workday is each other.\n  \n \n  Support one another  \u2013 no one says, \u201cThat\u2019s not my job.\u201d\n  \n \n Celebrate with  \n each other  at beer:30, virtual events, and company gatherings.\n  \n \n \n \n  Be Understood  \u2013 we are each unique and want to live our best lives at work and home.\n  \n \n  Let life happen  with My Time Off, a form of unlimited vacation, and up to 12 weeks paid for parental and emergency leave. \n  \n \n Live healthy  with complimentary lifestyle and financial coaches, a wellness program, and a comprehensive insurance plan.\n  \n \n \n \n  Who we  \n want \n \n \n Do you have a self-starter attitude with a high level of detail and a strong sense of ownership and dedication?  \n Can you multi-task, take initiative, and work collaboratively in a fast-paced environment characterized by multiple deadlines, changing priorities, and customer demands? \n Do you enjoy collaborating with team members and internal stakeholders across the organization to create, maintain and troubleshoot customer deliverables? \n \n \n \n \n  What you will do \n \n \n   As a Data Specialist, you will work with internal stakeholders and team members to create, maintain, and troubleshoot customer deliverables. You will collaborate with team members across the organization to assist with project set-up, ongoing change requests, meet multiple timelines and maintain the highest quality standards. You will ensure that all assigned projects are meeting established metrics for contract, deadline, and quality standards, and will complete ad hoc or team projects as needed. Additionally, you will document all project information and communicate project statuses, data, and logistical issues with internal stakeholders.\n  \n \n \n \n \n What you need \n \n \n Bachelor\u2019s degree or 1 \u2013 3 years prior professional experience \n 1-3 years of service-oriented experience \n Proficient in Microsoft Suite \n Exceptional verbal, written and interpersonal communication skills \n Technical aptitude for learning new software in systems \n Experience with querying databases (SQL, MySQL, etc.) \n NRC Health requires all U.S. associates to be fully vaccinated against COVID-19, unless entitled to an accommodation. \n \n \n \n \n  Have  \n Purpose. Think B \n oldly. Feel  \n C \n onnected \n . Be U \n nderstood. \n \n \n \n \n In the spirit of pay transparency, we are excited to share the salary range for this position is $48,000 - $64,800 exclusive of fringe benefits or potential bonuses. If you are hired at NRC Health, your final base salary compensation will be determined based on factors such as geographic location, skills, education, and/or experience. In addition to those factors \u2013 we believe in the importance of pay equity and consider internal equity of our current team members as a part of any final offer. Please keep in mind that the range mentioned above is the full base salary range for the role. Hiring at the maximum of the range would not be typical in order to allow for future and continued salary growth. We also offer a generous compensation and benefits package. For more information on specific benefits, please refer to our Careers Page. \n  NRC Health is not currently hiring in DE, HI, LA, MA, MD, NJ, OR, PA, RI, D.C.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "2ba6b97ca2f45997": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 59267.133,
        "salary_max": 75045.4,
        "title": "Junior Global Data Analyst - Remote",
        "company": "Olympus Corporation of the Americas",
        "desc": "Workplace Flexibility:  Field \n  Are you looking for a company that cares about people\u2019s lives and health, including yours? Let\u2019s inspire healthier lives, together. \n \n  Olympus, a leading medical technology company, has focused on making people\u2019s lives better for over 100 years. \n  Our Purpose is to make people\u2019s lives healthier, safer, and more fulfilling. \n \n  Our Core Values are reflected in all we do:   Integrity \u2013 Empathy \u2013 Agility \u2013 Unity \u2013 Long-Term View \n \n  We deliver on our purpose and our core values by staying  True to Life. \n \n \n \n  Job Description \n \n \n  As the Global Jr. Data Analyst you will take part in a fast paced, entrepreneurial environment. Supporting a global team, identifying gaps and opportunities and provide clarifying objectives; determining data needs and assisting in designing reports. Evaluating data and reports to assess if reporting meets end user requirements. Gather and compile documentation of metrics, data sources, ad hoc reporting to facilitate replication. Collaborate with data teams to obtain and maintain sources of data. Ensure data integrity and data quality, regularly review data for accuracy, identifies trends, and communicates changes. The ideal candidate will be detail oriented, technically capable, able to learn and think creatively to solve problems, and possesses a deep desire to learn and become the expert in our systems and Data. \n \n \n \n \n  Job Duties \n \n \n \n  Collaborates with Data Analyst Lead to support Global Complaint and Triage organization. \n  Utilizes data analytics expertise to respond to data inquiries from teams within the organization. Serving as a source of expertise surrounding operational BPO and Complaint data. \n  Apply analytical and statistical methods to answer a variety of business questions using multiple data sources and technical tools. \n  Understands the content and proper usage of the complaint handling or CRM systems being queried, without the existence of user documentation. This involves navigating the data to get a sense of typical ranges of values, interpreting the data, taking notes, and asking organized questions. \n  Interprets data, performs quantitative analyses, and makes recommendations to management regarding findings, data collection and quality issues, and follow-up enquiries/work. \n  Contributes to maintain documentation of data definitions, sources, and relationships. Contributes to maintain entity relationship diagrams (ERDs), data dictionaries, and other documentation describing what/how/where/why data is stored and how to access the data. \n  Work proactively to improve our existing reporting processes to make us faster, leaner, and bring more impactful insights. \n  Gathers and compiles documentation of Metrics, Data Sources, ad hoc reporting to facilitate replication. \n  Summarizes results of data analyses in written reports and oral presentations to Management, as required. \n  Adapts to new software packages, analytical tools, and database environments, as required. \n \n \n \n \n \n  Job Qualifications \n \n \n  Required: \n \n  Bachelor\u2019s Degree in a relevant discipline. Advanced Degree preferred. \n  Minimum of 3 years\u2019 experience in relative field of working with BPO\u2019s Globally. \n  Minimum of 3 years of experience working with CRM and/or Complaint systems and with data visualization tools such as Microsoft PowerBI, Tableau, Looker etc.  \n An equivalent mix of education and work experience is required.  \n Advanced SQL skills required.(Python experience a plus). \n  Expert-level skills in Microsoft Excel (VBA skills a plus). \n  Up to 50% domestic travel, occasional international travel may be required. \n \n \n  Preferred: \n \n  Working knowledge of secondary data sources including syndicated sales, promotional and marketing data, longitudinal patient level data; experience with payer data is preferred. \n  Working knowledge of data sources from call centers, service and repair and service centers; experience with complaints data is preferred.  \n Experience with statistical modeling, analysis, and presentation of results to a non-technical audience.  \n Proven track record of time-management, project management, and teamwork.  \n Persuasive written and verbal communication skills. \n  Highly capable in each of the following dimensions: adaptability, curiosity, resourcefulness, analytical thinking/problem solving, proactivity, collaboration, technological savvy, and operating with/through a KPI team. \n  Technically skilled and excel-guru, with expertise in data visualization and a demonstrated passion for process improvement. Possesses strong communication and analytical skills. \n  Ability to quickly understand the questions posed by some of our most time-consuming challenges and answer them with data. \n  Proven ability to prioritize and execute projects in a high-pressure environment. \n \n \n  #LI-Hybrid \n \n \n \n  Why join Olympus? \n  Here, people matter\u2014our health, our happiness, and our lives. \n \n  Competitive salaries, annual bonus and 401(k)* with company match \n  Comprehensive Medical, Dental, Visions coverage effective on start date \n  24/7 Employee Assistance Program \n  Free virtual live and on-demand wellness classes \n  Work-life balance supportive culture with hybrid and remote roles \n  12 Paid Holidays \n  Educational Assistance \n  Parental Leave and Adoption Assistance \n  Volunteering and charitable donation match programs \n  Diversity & Inclusion Programs including Colleague Affinity Networks \n  On-Site Child Daycare, Caf\u00e9, Fitness Center** \n \n \n US Only \n \n  **Limited locations \n   \n We care about your health and financial well-being and offer the resources you need to feel vital, confident and ready for wherever life takes you. Learn more about our benefit offerings at https://www.olympusamerica.com/careers/benefits-perks. \n \n  About us: \n  Our Medical business uses innovative capabilities in medical technology, therapeutic intervention, and precision manufacturing to help healthcare professionals deliver diagnostic, therapeutic, and minimally invasive procedures to improve clinical outcomes, reduce costs, and enhance the quality of life for patients and their safety. \n \n  Headquartered in Tokyo, Japan, Olympus employs more than 31,000 employees worldwide in nearly 40 countries and regions. Olympus Corporation of the Americas, a wholly owned subsidiary of Olympus Corporation, is headquartered in Center Valley, Pennsylvania, USA, and employs more than 5,200 employees throughout locations in North and South America. For more information, visit www.olympusamerica.com. \n \n  Olympus is dedicated to building a diverse, inclusive and authentic workplace \n  We recognize diversity in people, views and lifestyle choices and emphasize the importance of inclusion and mutual respect. We strive to continue to foster empathy and unity in the workplace so that our employees can fully contribute and thrive. \n \n  Let\u2019s realize your potential, together. \n  It is the policy of Olympus to extend equal employment and advancement opportunity to all applicants and employees without regard to race, color, national origin (including language use restrictions), citizenship status, religious creed (including dress and grooming practices), age, sex (including pregnancy, childbirth, breastfeeding, medical conditions related to pregnancy, childbirth and/or breastfeeding), gender, gender identity and expression, sexual orientation, marital status, disability (physical or mental) and/or a medical condition, genetic information, ancestry, veteran status or service in the uniformed services, and any other characteristic protected by applicable federal, state or local law. \n \n  Posting Notes: || United States (US) || Pennsylvania (US-PA) || Center Valley ||",
        "cleaned_desc": "  Job Duties \n \n \n \n  Collaborates with Data Analyst Lead to support Global Complaint and Triage organization. \n  Utilizes data analytics expertise to respond to data inquiries from teams within the organization. Serving as a source of expertise surrounding operational BPO and Complaint data. \n  Apply analytical and statistical methods to answer a variety of business questions using multiple data sources and technical tools. \n  Understands the content and proper usage of the complaint handling or CRM systems being queried, without the existence of user documentation. This involves navigating the data to get a sense of typical ranges of values, interpreting the data, taking notes, and asking organized questions. \n  Interprets data, performs quantitative analyses, and makes recommendations to management regarding findings, data collection and quality issues, and follow-up enquiries/work. \n  Contributes to maintain documentation of data definitions, sources, and relationships. Contributes to maintain entity relationship diagrams (ERDs), data dictionaries, and other documentation describing what/how/where/why data is stored and how to access the data. \n  Work proactively to improve our existing reporting processes to make us faster, leaner, and bring more impactful insights. \n  Gathers and compiles documentation of Metrics, Data Sources, ad hoc reporting to facilitate replication. \n  Summarizes results of data analyses in written reports and oral presentations to Management, as required. \n  Adapts to new software packages, analytical tools, and database environments, as required. \n \n \n \n \n \n  Job Qualifications   \n \n  Required: \n \n  Bachelor\u2019s Degree in a relevant discipline. Advanced Degree preferred. \n  Minimum of 3 years\u2019 experience in relative field of working with BPO\u2019s Globally. \n  Minimum of 3 years of experience working with CRM and/or Complaint systems and with data visualization tools such as Microsoft PowerBI, Tableau, Looker etc.  \n An equivalent mix of education and work experience is required.  \n Advanced SQL skills required.(Python experience a plus). \n  Expert-level skills in Microsoft Excel (VBA skills a plus). \n  Up to 50% domestic travel, occasional international travel may be required. \n \n \n  Preferred: \n \n  Working knowledge of secondary data sources including syndicated sales, promotional and marketing data, longitudinal patient level data; experience with payer data is preferred. \n  Working knowledge of data sources from call centers, service and repair and service centers; experience with complaints data is preferred.  \n Experience with statistical modeling, analysis, and presentation of results to a non-technical audience.  \n Proven track record of time-management, project management, and teamwork.  \n Persuasive written and verbal communication skills. ",
        "techs": [
            "microsoft powerbi",
            "tableau",
            "looker",
            "microsoft excel",
            "vba",
            "sql",
            "python"
        ],
        "cleaned_techs": [
            "powerbi",
            "tableau",
            "looker",
            "excel",
            "vba",
            "sql",
            "python"
        ]
    },
    "8ad5dfd6e4486ff9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 280.0,
        "salary_max": 300.0,
        "title": "Technical Business Analyst",
        "company": "Global Healthcare IT Resources",
        "desc": "We are looking to hire an experienced_  Technical Business Analyst _! If you are looking to further your career in the healthcare industry, look no further! We have an opportunity for you! \n Responsibilities \n \n Identify and balance business and technical needs for quality digital products and operational workflows. \n Conduct cost, benefit, and risk analysis, suggesting alternative solutions throughout the product life cycle. \n Collaborate with stakeholders and users to define and document business and system requirements. \n Analyze data, translate business requirements into technical specifications, and ensure system validation. \n Assist in coordinating the deployment of deliverables and contribute to the development of various product documents. \n \n Qualifications \n \n Bachelor's degree \n +2 years of relevant business and/or technical experience \n \n Job Type: Full-time \n Pay: $280.00 - $300.00 per day \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 4 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n No nights \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Business analysis: 4 years (Required) \n CMS, agile, Azure, & XML: 4 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6f195d5a827011d0": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 50.0,
        "salary_max": 50.0,
        "title": "Medical Economics Analyst",
        "company": "Techhive consulting llc",
        "desc": "Job Title: Health SQL Claims Specialist Location: Phoenix AZ \n Duration: 12 Months Contract to Hire \n Responsibilities: \n \u00b7 High value-based care experience and experience analyzing multi carrier health plans. A strong SQL/data analyst with insurance/clinical knowledge, Excel skills, a strong sense of curiosity and the ability to translate what doctor's ask for into what makes sense in the system etc. \n \u00b7 Claims Data experience \n \u00b7 Value-based care data analysis \n \u00b7 SQL coding \n \u00b7 Manipulating/Interpreting data \n \u00b7 Data analysis for Multi-carrier insurance health plans \n \u00b7 Someone who can design the data \n Experience: - Strong experience in data analysis, including ETL, SQL, R, and other statistical programming languages - Experience using Visio for process mapping is a plus \n Job Type: Full-time \n Pay: $50.00 per hour \n Expected hours: 40 per week \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Arizona \n \n Arkansas California  Colorado Florida Iowa Missouri Nevada  Nebraska  North Dakota Texas Washington Wyoming  Utah \n Experience: \n \n Medical Economics: 5 years (Required) \n SQL,R, Data Analyst: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b879f34d6bb96be4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 96931.34,
        "salary_max": 122736.69,
        "title": "Oracle Customer Care and Billing (CCB) Analyst",
        "company": "PS2G",
        "desc": "Position Overview: \n We are looking for an experienced Oracle Customer Care and Billing (CCB) Analyst with a strong background in the energy and utilities sectors. The ideal candidate will have expertise in CCB software and Oracle technologies. This role will play a crucial part in ensuring the successful implementation and operation of CCB systems. \n Key Responsibilities: \n \n CCB System Analysis: \n \n  Perform in-depth analysis of Oracle CCB system configurations, processes, and functionalities. \n  Identify opportunities for system optimization and enhancement to meet business needs. \n \n  Data Management: \n \n  Manage and maintain CCB system data, ensuring accuracy and consistency. \n  Generate reports and analyze data to support business decisions and regulatory compliance. \n \n  System Support: \n \n  Provide technical support for CCB system users, troubleshooting issues, and ensuring system availability. \n  Collaborate with IT teams to resolve technical problems and implement system improvements. \n \n  Documentation and Training: \n \n  Create and maintain documentation related to CCB system configurations, processes, and procedures. \n  Develop and deliver training materials and sessions for end-users. \n \n  Business Integration: \n \n  Collaborate with cross-functional teams to integrate CCB system functionality with other business systems and processes. \n  Ensure seamless data flow and system interoperability. \n \n \n Qualifications: \n \n Bachelor's degree in a relevant field (e.g., Computer Science, Information Technology). \n  Proven experience as an Oracle CCB Analyst in the energy and utilities sector. \n  Strong proficiency in Oracle CCB software and Oracle technologies. \n  Excellent analytical and problem-solving skills. \n  Knowledge of energy and utilities industry regulations and best practices is a plus. \n  Strong communication and interpersonal skills.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a678d5ec3be6486f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 85322.19,
        "salary_max": 108036.91,
        "title": "Utilities Meter Data Management | Oracle Analyst",
        "company": "PS2G",
        "desc": "Position Overview: \n We are looking for an experienced Utilities Meter Data Management (MDM) | Oracle Analyst with a strong background in the energy and utilities sector. The ideal candidate will have expertise in MDM software and Oracle technologies. This role will play a pivotal part in managing and optimizing meter data to enhance the efficiency and accuracy of our operations. \n Key Responsibilities: \n \n MDM System Management: \n \n  Oversee the configuration, administration, and maintenance of the Utilities Meter Data Management system. \n  Ensure data integrity and reliability of meter data through regular audits and validations. \n \n  Data Analysis: \n \n  Analyze meter data to identify trends, anomalies, and areas for improvement. \n  Generate reports and insights to support decision-making and operational efficiency. \n \n  Oracle Integration: \n \n  Collaborate with cross-functional teams to integrate MDM software with Oracle systems and other relevant technologies. \n  Ensure seamless data flow and system interoperability. \n \n  System Enhancements: \n \n  Identify opportunities for system optimization and improvement. \n  Work with developers and engineers to implement enhancements and upgrades. \n \n  Documentation and Reporting: \n \n  Create and maintain documentation related to MDM system configurations, processes, and procedures. \n  Generate regular reports on meter data performance and accuracy. \n \n \n Qualifications: \n \n Bachelor's degree in a relevant field (e.g., Computer Science, Information Technology). \n  Proven experience as a Utilities MDM | Oracle Analyst in the energy and utilities sector. \n  Strong proficiency in MDM software and Oracle technologies. \n  Knowledge of energy and utilities industry regulations and best practices is a plus. \n  Excellent analytical and problem-solving skills. \n  Strong communication and teamwork skills.",
        "cleaned_desc": "  Oracle Integration: \n \n  Collaborate with cross-functional teams to integrate MDM software with Oracle systems and other relevant technologies. \n  Ensure seamless data flow and system interoperability. \n \n  System Enhancements: \n   \n \n Qualifications: \n \n Bachelor's degree in a relevant field (e.g., Computer Science, Information Technology). \n  Proven experience as a Utilities MDM | Oracle Analyst in the energy and utilities sector. \n  Strong proficiency in MDM software and Oracle technologies. ",
        "techs": [
            "oracle integration",
            "mdm software",
            "oracle systems"
        ],
        "cleaned_techs": [
            "oracle",
            "mdm software"
        ]
    },
    "aee6b2aff4d11b61": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 69492.92,
        "salary_max": 87993.516,
        "title": "Federal Workforce Planning Data Analyst",
        "company": "Bryce Space and Technology",
        "desc": "BryceTech has partnered with technology and R&D clients to deliver mission and business success since 2017. Bryce combines core competencies in analytics and engineering with domain expertise. Our teams help government agencies, Fortune 500 firms, and investors manage complex programs, develop IT tools, and forecast critical outcomes. We offer clients proprietary, research-based models that enable evidence-based decision-making. Bryce cultivates a culture of engagement and partnership with our clients. BryceTech is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n BryceTech is looking for a Workforce Planning Data Analyst to join our team. The Data Analyst will work for our federal government customer. The ideal candidate will have a strong background in data analytics, business intelligence/data visualization tools including tableau and Power BI, and workforce strategic planning. \n \n Supporting a federal client by analyzing trends, metrics, and performance measurements relating to current and future workforce needs. \n Develop dashboards, reports, and informative analytical products using Tableau and/or Power BI \n Prepares analysis showing the pros and cons of various courses of action and suggests implications and possible effects of research findings to contribute to general knowledge and support decisions. \n Evaluate information gathered from multiple sources, reconcile conflicts, deconstruct high-level information into details, developing and understanding of trends and providing recommendations. \n Analyzes and determines the impact of proposed regulations, legislation, and policy changes on workforce and HC programs. \n Develop and evolve existing analysis products and tools and work with clients to identify and incorporate relevant data into the future scenarios including workforce and financial data. The data analyst will. \n Create, monitor, and analyze data for forecasting projections, trend analysis, and decision-making purposes. \n Generate and maintain short-, mid- and long-term forecasts of workforce needs within the Agency. \n Proactively communicate and collaborate with clients and stakeholders throughout the Agency to improve data products and identify needed analyses. \n Candidate will refine the tool adding data and additional parameters and approaches as needed to support different data users throughout the Agency. \n \n Qualifications \n \n Bachelor\u2019s or Master\u2019s degree in engineering, data analytics, human resources, business analytics, or related field. \n 3 to 8 years of related experience \n Strong analytical skills and attention to detail \n Experience in data analysis and data visualization \n Experience with human capital, workforce related topics, preferred \n Experience with NASA or related federal agencies preferred \n \n Additional Information \n BryceTech offers a full range of benefits, including competitive salary, a comprehensive health plan including dental and vision coverage, company-paid life & disability insurance policies, 401(k) plan with company match, and an educational reimbursement program. \n All your information will be kept confidential according to EEO guidelines. \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Health savings account \n Life insurance \n Paid holidays \n Paid time off \n Partner benefits \n Professional development assistance \n Retirement plan \n Tuition reimbursement \n Vision insurance \n \n Experience level: \n \n 3 years \n \n Application Question(s): \n \n Do you have your Bachelor\u2019s or Master\u2019s degree in engineering, data analytics, human resources, business analytics, or a related field? \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n data analysis and data visualization: 1 year (Preferred) \n \n Work Location: In person",
        "cleaned_desc": " Proactively communicate and collaborate with clients and stakeholders throughout the Agency to improve data products and identify needed analyses. \n Candidate will refine the tool adding data and additional parameters and approaches as needed to support different data users throughout the Agency. \n \n Qualifications \n \n Bachelor\u2019s or Master\u2019s degree in engineering, data analytics, human resources, business analytics, or related field. \n 3 to 8 years of related experience \n Strong analytical skills and attention to detail \n Experience in data analysis and data visualization \n Experience with human capital, workforce related topics, preferred \n Experience with NASA or related federal agencies preferred ",
        "techs": [
            "data analytics",
            "data analysis",
            "data visualization",
            "nasa"
        ],
        "cleaned_techs": [
            "data analytics",
            "data visualization",
            "nasa"
        ]
    },
    "c2aad0d22365911c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 89796.484,
        "salary_max": 113702.36,
        "title": "Business Analyst",
        "company": "Steampunk",
        "desc": "Overview: \n  \n   As a Business Analyst you will lead the collection, capture, and management of mission user needs from prioritization, concept development, and feature writing to support development and deployment. Provide expertise in business process and system analysis, design, improvement, and implementation efforts and in translating business process needs into technical requirements. Provide expertise in change management and training support. Provide organizational and strategic planning for a wide variety of technical and functional environments. Provide expertise in, but not limited to, Configuration Management, Strategic Planning, Knowledge Management, Business Analysis and Technical Analysis.\n   Contributions: \n  \n Envision, develop, and create requirements to improve tools to streamline processes to gain efficiencies and improve key metrics. \n  Apply different techniques to facilitate meetings and workshops, create a shared understanding with stakeholders, and engage team-members to produce product and portfolio roadmaps.  \n Collaborates with stakeholders and product teams to decompose large epics into features and user stories that can be understood and approved by members of the development team. \n  Facilitate Increment and planning sessions with clients and team members to ensure that planned work is well defined, planned, articulated, and understood. \n  Assist business analysts, team leads, clients, and other team members in the use of Jira as an Agile Lifecycle Management Tool to track work within the program across multiple product teams. \n  Provide guidance and assistance in the usage of Jira for reporting of work progress against epics and other larger bodies of work or types of work. \n  Use excellent communication skills, both verbal and written. Ability to explain technical concepts to non-technical stakeholders and present findings and recommendations. \n  Qualifications: \n  \n Bachelor's Degree and 4 years of functioning as a business analyst for the federal government \n  Experience using Agile methodologies \n  Strong critical thinking skills \n  Ability to communicate with technical and non-technical staff \n  Excellent oral and written communication skills \n  U.S. Citizen  Certified Scrum Master certification is preferred \n   About \n  steampunk :\n  \n \n  Steampunk is a \n   Change Agent  in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our \n   Human-Centered delivery methodology , we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an \n   employee owned company , we focus on investing in our employees to enable them to do the greatest work of their careers \u2013 and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.\n  \n \n \n  We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "53459a7f76a78c53": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55.0,
        "salary_max": 60.0,
        "title": "Epic Tapestry Business Analyst",
        "company": "Merican Inc",
        "desc": "Merican Inc. is a staffing firm that offers recruitment solutions to large clients across the United States. \n Job Role: Business Analyst \n Type: Contract \n Location: Remote \n Requirements: \n \n Epic Tapestry Certification \n Manipulating large sets of data in Excel, experience with vLookup, XLookup, Pivot tables, Macros. \n Excellent skills using Excel and Word \n Comfort with SQL and database languages \n Well organized, professional demeanor, with strong customer service skills. \n \n Tapestry Configuration Analysis and support \n \n Importing and exporting master files through Chronicles (TEXT), including components, component groups, contracts, code sets, fee schedules (RBRVS for all carrier/localities). Validating results and comparing across environments. \n Understanding of contract build and requirements needed for PPS pricing using 3rd party interface and system set up to effectively use in contracts. Codes sets needed and how they work in claims processing (DRG, MSDRG, APRDRG, HIPPS, RUGS). \n Build complex contracts \u2013 providers and hospitals with custom DRGs, carevouts, buckets, fee schedule mapping, stoploss, extensions and programming points. \n In depth knowledge of extensions and how to apply in various situations (contracts, vendors) \n Reporting workbench \u2013 creating custom reports to extract data for contract/claims analysis. \n Knowledge of Medi-Cal reimbursement methods and policies, CMS payment structures and rules, RBRVS calculations. \n \n Client Communications, Database - MS SQL Server, Epic: Tapestry, MS Excel \n Job Type: Contract \n Salary: $55.00 - $60.00 per hour \n Expected hours: 40 per week \n Work setting: \n \n Remote \n \n People with a criminal record are encouraged to apply \n License/Certification: \n \n Epic Tapestry Certification (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Epic Tapestry Certification \n Manipulating large sets of data in Excel, experience with vLookup, XLookup, Pivot tables, Macros. \n Excellent skills using Excel and Word \n Comfort with SQL and database languages \n Well organized, professional demeanor, with strong customer service skills. \n ",
        "techs": [
            "epic tapestry certification",
            "excel (vlookup",
            "xlookup",
            "pivot tables",
            "macros)",
            "word",
            "sql"
        ],
        "cleaned_techs": [
            "epic tapestry certification",
            "excel",
            "xlookup",
            "pivot tables",
            "macros)",
            "word",
            "sql"
        ]
    },
    "2cc5ed67a0b4d3f2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 60.0,
        "salary_max": 65.0,
        "title": "SR Business Analyst ALM,SQL Programming Lifesciences /Pharma Xcellerate",
        "company": "NovaTech",
        "desc": "Senior Business Analyst with ALM SQL, with experience in Lifesciences and clinical trials analysis, design, implementation, modification, and daily functional support of all applications. Experience with Xcellerate is a major plus \n Job Responsibilities: Works with key stakeholders within all business functions to align technology solutions with business strategies Gathers requirements from business units and translate those to programmers and developers Prepares cost-benefit and return-on-investment analyses to aid in decisions on system implementation Demonstrates an informed knowledge of business functions to resolve problems and capitalize on improvement opportunities Supports one or more highly complex business processes Works on multiple projects as a project team member Serves as a liaison between the business community and the IT organization in order to provide technical solutions to meet user needs Qualifications: Bachelor's degree in a technical field such as computer science, computer engineering or related field required. MBA or other related advanced degree preferred 5-7 years experience required Basic knowledge of programming languages in order to comprehend reading code and basic functions Ability to create business solutions that increase competitive advantage Ability to exercise good judgment in selecting methods and techniques for obtaining solutions Project management skills in order to handle diverse projects, often times simultaneously, and meet aggressive deadlines Ability to solve technical problems/ processes and understand complex details Ability to increase operating efficiency with produce high quality technical solutions A high level of interpersonal and verbal communication skills necessary to relate to other people at their systems knowledge level Ability to analyze complex situations and problems and do the necessary research using multiple sources of information to arrive at innovative solutions \n Additional Comments/Requirements  \n Relevant experience in Lifesciences & clinical trial management domains is a MUST \n Basic SQL programming skills is required \n Job Type: Contract \n Pay: $60.00 - $65.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n SQL: 7 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Senior Business Analyst with ALM SQL, with experience in Lifesciences and clinical trials analysis, design, implementation, modification, and daily functional support of all applications. Experience with Xcellerate is a major plus \n Job Responsibilities: Works with key stakeholders within all business functions to align technology solutions with business strategies Gathers requirements from business units and translate those to programmers and developers Prepares cost-benefit and return-on-investment analyses to aid in decisions on system implementation Demonstrates an informed knowledge of business functions to resolve problems and capitalize on improvement opportunities Supports one or more highly complex business processes Works on multiple projects as a project team member Serves as a liaison between the business community and the IT organization in order to provide technical solutions to meet user needs Qualifications: Bachelor's degree in a technical field such as computer science, computer engineering or related field required. MBA or other related advanced degree preferred 5-7 years experience required Basic knowledge of programming languages in order to comprehend reading code and basic functions Ability to create business solutions that increase competitive advantage Ability to exercise good judgment in selecting methods and techniques for obtaining solutions Project management skills in order to handle diverse projects, often times simultaneously, and meet aggressive deadlines Ability to solve technical problems/ processes and understand complex details Ability to increase operating efficiency with produce high quality technical solutions A high level of interpersonal and verbal communication skills necessary to relate to other people at their systems knowledge level Ability to analyze complex situations and problems and do the necessary research using multiple sources of information to arrive at innovative solutions \n Additional Comments/Requirements  \n Relevant experience in Lifesciences & clinical trial management domains is a MUST \n Basic SQL programming skills is required ",
        "techs": [
            "alm sql",
            "lifesciences",
            "clinical trials analysis",
            "xcellerate",
            "business strategies",
            "programmers and developers",
            "cost-benefit analysis",
            "return-on-investment analysis",
            "business functions",
            "highly complex business processes",
            "project team member",
            "it organization",
            "technical solutions",
            "bachelor's degree in a technical field",
            "mba",
            "programming languages",
            "business solutions",
            "project management skills",
            "technical problems",
            "operating efficiency",
            "interpersonal communication skills",
            "verbal communication skills",
            "complex situations",
            "research",
            "lifesciences & clinical trial management domains",
            "basic sql programming skills."
        ],
        "cleaned_techs": [
            "alm sql",
            "lifesciences",
            "clinical trials analysis",
            "xcellerate",
            "business strategies",
            "programmers and developers",
            "cost-benefit analysis",
            "return-on-investment analysis",
            "business functions",
            "highly complex business processes",
            "project team member",
            "it organization",
            "technical solutions",
            "mba",
            "programming languages",
            "business solutions",
            "technical problems",
            "operating efficiency",
            "complex situations",
            "research",
            "lifesciences & clinical trial management domains"
        ]
    },
    "fe920b2b876e6aba": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70304.0,
        "salary_max": 107266.0,
        "title": "Business Analyst, Procurement - Harris Health Medical Division (Hybrid Office / Remote)",
        "company": "Harris County",
        "desc": "Position Description \n \n \n \n \n    Performs various administrative, analytical, and reporting functions in support of departmental programs, projects, and services. Gathers, consolidates, processes, tracks, and analyzes data and information using automated systems. Utilizes data findings to provide recommendations regarding departmental policies, procedures, and services. Handles various department related questions and issues.\n    \n \n \n  Duties and Responsibilities: \n \n \n \n \n       Gathers and analyzes business requirements and identifies potential suppliers; develops formal scorecards for key vendors and supports the delivery of quarterly and annual business reviews\n      \n \n \n       Evaluates department and vendor performance using quantitative data based on cost, quality, service level metrics, and provides input and support to continuous improvement programs areas to meet the department/organization's needs.\n      \n \n \n       Assesses current practices and collects information and analyzes trends to determine organizational objectives.\n      \n \n \n       Provides monthly, quarterly, and annual business reviews to leadership and other key stakeholders.\n      \n \n \n       Develops, maintains, and improves key procurement dashboards and performance metrics to monitor and track internal performance to report and increase visibility for leadership groups and other stakeholders.\n      \n \n \n       Serves as knowledgeable point of contact by translating business needs into actionable analytics, assisting with the management of procurement strategies and programs, and providing focused support to procurement resources on ad hoc requests for departments or vendor issue resolution.\n      \n \n \n       Assists with the creation and implementation of programs to assess and promote vendor performance and development.\n      \n \n \n       Collaborates and communicates with various individuals and entities as needed to gather or disseminate data and information related to departmental programs, projects, and services.\n      \n \n \n \n  Harris County is an Equal Opportunity Employer \n  https://hrrm.harriscountytx.gov/Pages/EqualEmploymentOpportunityPlan.aspx\n      If you need special services or accommodations, please call (713) 274-5445 or email ADACoordinator@bmd.hctx.net.\n     \n \n This position is subject to a criminal history check. Only relevant convictions will be considered and, even when considered, may not automatically disqualify the candidate. \n \n \n \n \n Requirements \n \n \n \n \n \n Education and Experience: \n \n \n \n \n        Bachelor's degree in a directly related field and\n       \n \n \n        Three (3) years of directly related experience\n       \n \n \n  OR \n \n \n \n \n        Associate degree in a related field and\n       \n \n \n        Five (5) years of directly related work experience\n       \n \n \n  OR \n \n \n \n \n        High School Diploma/GED and\n       \n \n \n        Seven (7) years of directly related work experience\n       \n \n \n \n  Knowledge, Skills, and Abilities: \n \n \n \n \n        Strong analytic and problem-solving skills\n       \n \n \n        Strong knowledge in analyzing data to draw business-relevant conclusion and in data visualization techniques and tools.\n       \n \n \n        Proficient in Microsoft Suite which includes Word, Excel, PowerPoint, Power BI, and other related software\u2019s.\n       \n \n \n        Experience in designing and developing dashboards & reports by using Tableau, Power BI, Qlik etc.\n       \n \n \n        Excellent verbal and written communication skills.\n       \n \n \n        Excellent organizational skills and a strong attention to detail.\n       \n \n \n        Excellent time management skills with a proven ability to meet deadlines.\n       \n \n \n        Knowledge of department/field specific subject matter.\n       \n \n \n        Knowledge and experience with best practice processes, tools, and procurement/spend systems data and analysis.\n       \n \n \n        Ability to keep information confidential.\n       \n \n \n        Ability to work independently as well as part of a team.\n       \n \n \n        Ability to successfully support diverse company initiatives and business issues.\n       \n \n \n        Ability to develop relationships with key business partners using data to support recommendations and drive insights.\n       \n \n \n        Ability to perform in a fast-paced, goal-oriented, and time sensitive environment.\n       \n \n \n \n  NOTE \n :  Qualifying education, experience, knowledge, and skills must be documented on your job application. You may attach a resume to the application as supporting documentation but\n       ONLY information stated on the application will be used for consideration. \"See Resume\" \n  will not be accepted for qualifications. \n \n \n \n \n \n Preferences \n \n \n \n \n \n \n      Prior purchasing / procurement related experience\n      \n \n \n \n \n General Information \n \n \n \n \n \n Position Type and Typical Hours of Work: \n \n \n \n \n        Regular Full-time\n       \n \n \n        Monday - Friday | 8:00 A.M. - 5:00 P.M.\n       \n \n \n \n          Flexible work schedule\n         \n \n \n  Salary: \n \n \n  $70,304.00 - $107,266.00 Annually \n  Depends on Qualifications \n  Based on 26 Pay Periods\n       \n  Plus, benefits \n \n \n \n \n  Location: \n \n \n \n \n        Harris Health Office Building - 4800 Fournace Place W516, Bellaire, TX 77401\n       \n \n \n \n  Employment may be contingent on passing a drug screen and meeting other standards. \n \n \n Due to a high volume of applications positions may close prior to the advertised closing date or at the discretion of the Hiring Department. \n \n \n \n \n \n \n \n \n \n \n \n \n BENEFITS \n \n \n    Harris County offers a competitive benefits program, including comprehensive group health and related benefits plan as well as defined benefit retirement plan.\n    \n \n \n \n The following list of benefits is offered  \n only \n  to employees in  \n regular \n   \n (full-time) \n  positions: \n \n \n Medical  \n Dental  \n Vision  \n Wellness  \n Life Insurance  \n Long-term disability  \n Employee Assistance Program  \n 10 days of vacation each year for the first five (5) years of service. Accrual rates increase based on years of service.  \n 10 county holidays plus one (1) floating holiday  \n Professional development opportunities  \n Dependent Care Reimbursement Plan  \n Healthcare Reimbursement Account  \n 457 Deferred Compensation Plan \n \n \n The following benefits are also available to regular (full-time) employment and may be available to part-time employees: \n \n \n \n Retirement pension (TCDRS)\n       \n  Flexible schedules (varies by department)\n         \n Transportation Assistance (Metro RideSponsor Program) \n \n   \n \n \n \n In accordance with the Harris County Personnel Regulations, Group Health and related benefits are subject to amendment or discontinuance at any time. Commissioners Court reserves the right to make benefit modifications on the County's behalf as needed. \n \n For plan details, visit the Harris County benefits website:  \n \n \n    https://hrrm.harriscountytx.gov/Pages/Medical.aspx",
        "cleaned_desc": " \n \n \n Education and Experience: \n \n \n \n \n        Bachelor's degree in a directly related field and\n       \n \n \n        Three (3) years of directly related experience\n       \n \n \n  OR \n \n \n \n \n        Associate degree in a related field and\n       \n \n \n        Five (5) years of directly related work experience\n       \n \n \n  OR \n \n \n \n \n        High School Diploma/GED and\n       \n \n \n        Seven (7) years of directly related work experience\n       \n \n \n \n  Knowledge, Skills, and Abilities: \n \n \n \n \n        Strong analytic and problem-solving skills\n       \n \n \n        Strong knowledge in analyzing data to draw business-relevant conclusion and in data visualization techniques and tools.\n       \n \n \n        Proficient in Microsoft Suite which includes Word, Excel, PowerPoint, Power BI, and other related software\u2019s.\n       \n \n          Experience in designing and developing dashboards & reports by using Tableau, Power BI, Qlik etc.\n       \n \n \n        Excellent verbal and written communication skills.\n       \n \n \n        Excellent organizational skills and a strong attention to detail.\n       \n \n \n        Excellent time management skills with a proven ability to meet deadlines.\n       \n \n \n        Knowledge of department/field specific subject matter.\n       \n \n \n        Knowledge and experience with best practice processes, tools, and procurement/spend systems data and analysis.\n       \n \n \n        Ability to keep information confidential.\n       \n \n \n        Ability to work independently as well as part of a team.\n       \n \n \n        Ability to successfully support diverse company initiatives and business issues.\n       \n \n \n        Ability to develop relationships with key business partners using data to support recommendations and drive insights.\n       \n \n \n        Ability to perform in a fast-paced, goal-oriented, and time sensitive environment.\n       \n \n \n \n  NOTE \n :  Qualifying education, experience, knowledge, and skills must be documented on your job application. You may attach a resume to the application as supporting documentation but\n       ONLY information stated on the application will be used for consideration. \"See Resume\" \n  will not be accepted for qualifications. \n \n \n \n \n \n Preferences \n \n \n \n \n ",
        "techs": [
            "tableau",
            "power bi",
            "qlik",
            "microsoft suite",
            "word",
            "excel",
            "powerpoint",
            "power bi",
            "data visualization techniques and tools"
        ],
        "cleaned_techs": [
            "tableau",
            "powerbi",
            "qlik",
            "microsoft suite",
            "word",
            "excel",
            "powerpoint",
            "data visualization techniques and tools"
        ]
    },
    "26cf8a148b1e7bfe": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 117394.305,
        "salary_max": 148647.34,
        "title": "Data Analytics Lead",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  The Data Analytics Lead at Company has/is: \n \n  3 - 8 years experience in a data analytics role , preferably at a high-growth startup, CPG, loyalty, retail, or mobile gaming company \n  Entrepreneurial mindset with a  \u2018self-start\u2019 mentality ; Excels at finding answers. Customer centric. Comfortable with a workday and schedule that isn\u2019t always highly structured or predictable \n  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n \n  Additional: \n \n  Ability to handle multiple tasks simultaneously, maintain focus, and adapt to a variety of challenges in a  fast-paced agile environment \n  5 Location / ability to relocate to: Chicago (highly preferred) or San Diego \n \n   \n ssa7nupJsp",
        "cleaned_desc": "  Experience with  BI & data visualization tools  (e.g., Tableau, PowerBI).  Strong experience with SQL  and at  least   one  programming language (e.g., Python, R). Experience with  ETL tools  (Tableau Prep, Alteryx, Knime or similar). Proven experience in the cloud (Snowflake/AWS/GCP/Azure), Experience with  mobile products and analytics tools (Amplitude or similar) \n  A leader and a team player : ability to work and make decisions autonomously with appropriate levels of collaboration and engagement with the team to ensure alignment. \n ",
        "techs": [
            "tableau",
            "powerbi",
            "sql",
            "python",
            "r",
            "tableau prep",
            "alteryx",
            "knime",
            "snowflake",
            "aws",
            "gcp",
            "azure",
            "amplitude"
        ],
        "cleaned_techs": [
            "tableau",
            "powerbi",
            "sql",
            "python",
            "r",
            "tableau prep",
            "alteryx",
            "knime",
            "snowflake",
            "aws",
            "gcp",
            "azure",
            "amplitude"
        ]
    },
    "00a08667398bb974": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 0.0,
        "salary_max": 50.0,
        "title": "Business Analyst with EDI 834 Benefit Enrollment Processing",
        "company": "Garni software",
        "desc": "Job Description: \n We are seeking a highly skilled and motivated EDI Analyst to join our team. The successful candidate will play a crucial role in ensuring the smooth operation of our EDI (Electronic Data Interchange) systems and processes, particularly within the healthcare industry. If you have a strong background in EDI, SQL, EDI transaction validation, and possess a good understanding of healthcare claims workflow, we encourage you to apply. \n Responsibilities: \n \n Perform analysis, design, development, testing, and implementation of EDI solutions within the healthcare domain. \n Collaborate with cross-functional teams to gather and document EDI requirements specific to healthcare operations. \n Monitor and maintain EDI transaction processes in the healthcare sector to ensure data accuracy and integrity. \n Troubleshoot and resolve EDI transaction issues related to healthcare data in a timely manner. \n Develop and optimize SQL queries to extract, manipulate, and validate healthcare-related data. \n Conduct thorough testing and validation of EDI transactions in the healthcare industry to meet business needs. \n Maintain EDI documentation for healthcare processes and provide training to end-users as needed. \n Stay up-to-date with industry standards and best practices related to EDI in healthcare. \n Assist in the design and implementation of EDI-related enhancements and improvements in healthcare settings. \n Participate in on-call support rotation as required. \n \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field preferred. \n Minimum 8 years of experience in EDI analysis and support within the healthcare sector. \n Proficiency in EDI standards and protocols, particularly in healthcare. \n Strong SQL skills for data extraction and manipulation. \n Good knowledge of claims and or eligibility workflow in the healthcare payer industry. \n Excellent problem-solving and analytical skills within healthcare contexts. \n Detail-oriented with a strong commitment to data accuracy in healthcare data. \n Effective communication and interpersonal skills. \n Ability to work independently and as part of a team. \n Relevant certifications or training related to healthcare EDI are a plus. \n \n Job Types: Full-time, Contract \n Pay: Up to $50.00 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n Must have EDI 834 enrollment processing experience. Do you have it? \n Must have IT Healthcare experience. Do you have it? \n Maximum rate is $50/hr on C2C or W2. Are you fine with it? \n \n Experience: \n \n EDI 834: 9 years (Required) \n Business Analyst: 8 years (Required) \n SQL: 8 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Minimum 8 years of experience in EDI analysis and support within the healthcare sector. \n Proficiency in EDI standards and protocols, particularly in healthcare. \n Strong SQL skills for data extraction and manipulation. \n Good knowledge of claims and or eligibility workflow in the healthcare payer industry. \n Excellent problem-solving and analytical skills within healthcare contexts. \n Detail-oriented with a strong commitment to data accuracy in healthcare data. \n Effective communication and interpersonal skills. \n Ability to work independently and as part of a team. \n Relevant certifications or training related to healthcare EDI are a plus. ",
        "techs": [
            "edi analysis and support",
            "healthcare sector",
            "edi standards and protocols",
            "healthcare",
            "sql skills",
            "data extraction and manipulation",
            "claims workflow",
            "eligibility workflow",
            "healthcare payer industry",
            "problem-solving skills",
            "analytical skills",
            "detail-oriented",
            "data accuracy",
            "healthcare data",
            "communication skills",
            "interpersonal skills",
            "ability to work independently",
            "ability to work as part of a team",
            "relevant certifications",
            "training",
            "healthcare edi."
        ],
        "cleaned_techs": [
            "edi analysis and support",
            "healthcare sector",
            "edi standards and protocols",
            "healthcare",
            "data extraction and manipulation",
            "claims workflow",
            "eligibility workflow",
            "healthcare payer industry",
            "detail-oriented",
            "data accuracy",
            "healthcare data",
            "relevant certifications",
            "training",
            "healthcare edi."
        ]
    },
    "ffbbc0a01ee71333": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90000.0,
        "salary_max": 100000.0,
        "title": "Business Intelligence Analyst / Report Developer",
        "company": "Thrive Networks Inc",
        "desc": "About Us \n  Thrive is an innovative technology solutions provider focused on Cyber Security, Hybrid Cloud, Global Network Management, Disaster Recovery and traditional Managed Services. Our corporate culture, engineering talent, customer-centric approach, and focus upon NextGen services help us stand out among our peers. Thrive is on the look-out for individuals who don't view their weekdays spent at 'a job' but rather look to develop valuable skills that ignite their passion and lead to a CAREER. If you're attracted to a work hard, play hard environment and seek the guidance, training and experience necessary to build a lucrative career, then welcome to THRIVE! \n   \n Position Overview \n  At Thrive, IT is our business, so ServiceNow is the core of our digital platform and business strategy. This role works closely with senior management to design processes and reporting to gather and monitor key performance data. They will also be responsible for report development and will influence everything from process improvement to execution and training. Every member of the ServiceNow team has unbounded opportunity to solve business, IT, and human challenges with ServiceNow\u2019s deep pool of technical capabilities.  \n Qualifications \n \n  ServiceNow Reporting and Analytics design and development experience is essential. \n  Understanding of Business Intelligence concepts in general and hands-on experience using Microsoft PowerBI in particular \n  Knowledge and use of Database schema objects (table, query, index, view)  \n Proven reporting and dashboard design and development proficiency \n  Demonstrated analytical and critical thinking abilities \n  Respectful and clear communication is essential \n  Strong organizational and time management skills must be able to work effectively individually and in groups \n  Keen attention to detail \n  Ability to analyze problems and find solutions \n  Willingness to gather and evaluate user feedback and make adjustments as necessary \n  ITIL experience a plus \n \n  What we offer \n \n  Endless opportunities to solve real-world problems with the latest ServiceNow and related Now Platform capabilities \n  A friendly and collaborative team that both inspires and demands the best of each other \n  Remote work. Must be able to work during US/Canada eastern time zone hours \n  Great IT equipment and software tools provided \n  Realistic market value (aka competitive salary and bonus) \n  Benefits including health, vision, dental, and more! \n \n   \n CaaD82UjPx",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "d3ee15e57eab4aae": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Sr. Reimbursement Analyst",
        "company": "Boston Medical Center",
        "desc": "POSITION SUMMARY:\n  \n \n \n   Reporting to the Senior Director of Reimbursement/Payment Systems, the Senior Reimbursement Analyst will be responsible for the full range of reimbursement functions: cost reporting, audit, interim rate and settlement calculation, back up to net revenue preparation and analysis, and various special projects including the implementation and support of the Boston Medical Center\u2019s contract payment system.\n  \n \n \n   Position: Sr. Reimbursement Analyst\n  \n \n   Department: Payment System and Reporting\n  \n \n   Schedule: Full Time\n  \n \n \n   JOB REQUIREMENTS\n  \n \n \n   EDUCATION:\n  \n \n \n   Bachelor\u2019s Degree in Finance and Accounting\n  \n \n \n   EXPERIENCE:\n  \n \n  5+ years of proven experience in a Hospital Reimbursement setting, preferably in a Safety Net environment \n  5+ years of proven working knowledge of and experience with the HCFA 2552 cost report, the DHCFP 403 cost report and Uncompensated Care Cost Limit \n  5+ years of experience working with Hospital Net Revenue and Provision models \n \n \n \n   KNOWLEDGE AND SKILLS:\n  \n \n  Excellent verbal and written communication skills, including the ability to speak articulately to all staff levels and answer difficult questions with confidence. \n  Must have well-developed organizational skills, including the ability to manage multiple tasks and functions effectively and calmly in a deadline-oriented environment. \n  High analytical thinking with demonstrated talent for identifying, scrutinizing, improving, and streamlining complex work processes. Must have advanced MS Excel, Word, Access, and PowerPoint skills. \n  Ability to operate effectively in a fast-paced, constantly changing environment. \n  Ability to analyze data and interpret statistics; to identify and resolve problems; and to interpret guidelines and regulations and identify the effect of regulatory changes on departmental operations. \n  Interpersonal skills necessary to provide leadership in team building endeavors; to collaborate with others in support of hospital and departmental goals and objectives; to establish and maintain effective, cooperative working relationships with employees and managers",
        "cleaned_desc": " \n \n \n   KNOWLEDGE AND SKILLS:\n  \n \n  Excellent verbal and written communication skills, including the ability to speak articulately to all staff levels and answer difficult questions with confidence. \n  Must have well-developed organizational skills, including the ability to manage multiple tasks and functions effectively and calmly in a deadline-oriented environment. \n  High analytical thinking with demonstrated talent for identifying, scrutinizing, improving, and streamlining complex work processes. Must have advanced MS Excel, Word, Access, and PowerPoint skills. ",
        "techs": [
            "ms excel",
            "ms word",
            "ms access",
            "ms powerpoint"
        ],
        "cleaned_techs": [
            "excel",
            "microsoft",
            "ms access",
            "ms powerpoint"
        ]
    },
    "9bb8ea67ba2032aa": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 86761.86,
        "salary_max": 109859.84,
        "title": "Senior Data Analyst, Regulatory Relations",
        "company": "Osaic",
        "desc": "Regulatory Relations Compliance Opportunity in Financial Services  \n Sr. Data Analyst, Regulatory Relations \n  Location: Accepting qualified candidates in all locations & remote (within United States) \n  Type: Full Time \n \n  Summary:  \n The Sr. Data Analyst on the Regulatory Relations team is primarily responsible for producing data and reports in support of the Regulatory Relations team, including the collection, combination, analysis and reporting on complex data from a variety of data sources. The data and reports support the greater Regulatory Relations team in supplying information in response to regulatory inquiries. Reports and data must be accurate and provided timely, as deadlines are often set by the regulatory agencies. This role requires a data-minded individual who has experience in writing complex reports and is familiar with the financial services industry, especially as it relates to applicable regulations within the industry. \n \n  Responsibilities:  \n \n Respond to all regulatory exams requests which includes data analysis and generating reports from all Firm\u2019s production databases primarily using SQL scripts (50%) \n  Create ad-hoc statistical reports for Management (10%) \n  Analyze and report data trends (20%) \n  Assists with special projects, including creating compliance reports based upon deficiencies and/or recommendations from regulatory inquiries (20%) \n  All other duties as assigned. \n \n \n  Education Requirements:  \n \n Bachelor\u2019s degree is required, preferably in Finance, Business Administration, Computer Science, or another related field. \n \n \n  Basic Requirements:  \n \n 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. \n \n \n  #LI-Remote \n  Equal Opportunity Employer \n  Osaic is an equal opportunity employer. We celebrate diversity in our workplace and we hire the most qualified candidates without regard for age, ethnicity, gender, gender identity or expression, language differences, nationality or national origin, family or marital status, physical, mental, and developmental abilities (or the perception of a disability), genetic information, race, religion or belief, sexual orientation, skin color, social or economic class, education, work and behavioral styles, political affiliation, military service, caste, or any other characteristic protected by law. \n  Eligibility \n  Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Osaic. \n  Unqualified Applications \n  Osaic does not consider applications from candidates who do not meet the minimum qualifications stated in the job posting. \n  Recruiting Agencies \n  Osaic only accepts candidates from contracted recruiting firms and only for searches approved prior to submissions. Fees will not be paid for unsolicited submissions.",
        "cleaned_desc": " 5 to 8 years of Financial Services Industry experience required \n  3 to 5 years of reporting or data analytics experience \n  FINRA Series 7 and Series 24 required \n  Proficiency in MS SQL required \n  Proficiency in MS Office and various other business applications \n  Strong written and verbal communication skills \n  Ability to operate effectively as part of a project team or individually \n  Expert knowledge of financial services industry trends, directions, major issues, regulatory considerations and trendsetters; ability to provide specific financial knowledge and experience. ",
        "techs": [
            "finra series 7",
            "finra series 24",
            "ms sql",
            "ms office"
        ],
        "cleaned_techs": [
            "finra series 7",
            "finra series 24",
            "ms sql",
            "microsoft"
        ]
    },
    "c9164a55dad6495b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Electronic Processing Business Analyst",
        "company": "Work from Home",
        "desc": "Introduction \n  Do you want to join an organization that invests in you as a Electronic Processing Business Analyst? At Work from Home, you come first. HCA Healthcare has committed up to $300 million in programs to support our incredible team members over the course of three years. \n  Benefits \n  Work from Home, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include: \n \n  Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation. \n  Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more. \n  Free counseling services and resources for emotional, physical and financial wellbeing   \n  401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)   \n  Employee Stock Purchase Plan with 10% off HCA Healthcare stock   \n  Family support through fertility and family building benefits with Progyny and adoption assistance.   \n  Referral services for child, elder and pet care, home and auto repair, event planning and more   \n  Consumer discounts through Abenity and Consumer Discounts   \n  Retirement readiness, rollover assistance services and preferred banking partnerships   \n  Education assistance (tuition, student loan, certification support, dependent scholarships)   \n  Colleague recognition program   \n  Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)   \n  Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income. \n \n  Learn more about Employee Benefits \n  Note: Eligibility for benefits may vary by location. \n  You contribute to our success. Every role has an impact on our patients\u2019 lives and you have the opportunity to make a difference. We are looking for a dedicated Electronic Processing Business Analyst like you to be a part of our team. \n  Job Summary and Qualifications \n \n  Job Summary \u2013 Documentation and analysis of system balancing, clean claim rates, payer acceptance rates, and system edit requests. Creation or modification of system billing edits to ensure appropriate claim results that meet payer, regulatory and provider requirements. Assist service centers, clients and payers regarding billing system processes and policies. The Electronic Processing (EP) Business Analyst is considered to be the subject matter expert and the liaison between the SSC\u2019s and Relay Health. \n  A background and operational experience in Healthcare Revenue Cycle IT Solutions or Billing is recommended. Specific experience and understanding of HCA\u2019s Revenue Cycle applications (i.e. Relay Health, Patent Accounting, eRequest and Artiva) is desirable. \n  Supervisor \u2013 Manager Billing Edits \n  Duties (included but not limited to): \n \n \n  Analyzes daily balancing exceptions by service center to determine bridge routine rules that resulted in the discarding of the claim, reports results to appropriate service centers and suggests modifications in the bridge routine rules to eliminate future balancing exceptions. \n  Provides balancing exception trending information to manager and director with comments regarding peaks and valleys in data. \n  Publishes balancing exception reports, including reasons for exceptions and service center responses on imaging storage system. \n  Analyzes daily released claims to determine payer acceptance percentages and rejection rates, reviews claim rejections to determine reason for rejection, reports rejections to the appropriate service centers and assists the service center billing director in creating edits to prevent future payer rejections. \n  Provides payer acceptance trending information to manager and director with comments regarding peaks and valleys in data. \n  Publishes service center payer acceptance/rejection logs on imaging storage system \n  Analyzes daily service center clean claim rates (claims submitted to billing system without errors) to identify trends and works with service center billing director in creation of bridge routine rules that result in higher clean claim rates. \n  Provides clean claim rate trending by service center and client to manager and director with comments regarding peaks and valleys in data. \n  Publishes service center daily claim submission reports on imaging storage system. \n  Monitors the edit requesting system for edit modification requests; reviews request for completeness, appropriateness and receipt of approvals. \n  Analyzes edit requests to determine type of edit modification required; logs service orders with billing vendor for supplemental/payer edits or creates/modifies bridge routine edits for provider edits. \n  Creates/Modifies bridge routine edits in the billing test system. \n  Creates testing scenarios for new or modified bridge routines that include before and after examples and negative testing that fully satisfies edit testing policies and procedures. \n  Publishes all testing documentation on imaging storage system. \n  Monitors billing system service orders system to ensure all requests are appropriately and timely resolved. \n  Routinely corresponds with service center billing director to validate services provided are meeting their needs. \n  Assists co-workers in completing work assignments as necessary to ensure a high level of service is provided by the department. \n  Maintains listing of all supplemental edits and activation criteria by service center location. \n  Travel to service centers and/or other facilities for onsite work may be required. \n  Must have strong documentation skills, organization skills, and the ability to interact with team members cross-functionally \n  Demonstrates a customer orientation; establishes and maintains strong relationships with business owners and develops a diverse network of relationships with various stakeholders. \n  Supports implementation projects, including training and communication. \n  Identifies impact of edit requests and works with stakeholders to identify options and recommendations. \n  Supports annual audit reviews (e.g. internal & external audit for Sarbanes Oxley, etc.) \n  Practice and adhere to the \"Code of Conduct\" philosophy. \n  Attend all required billing process education classes. \n  Other duties as assigned. \n \n  Knowledge, Skills & Abilities \n \n \n  Communication - communicates clearly and concisely, verbally and in writing. \n  Customer orientation - establishes and maintains long-term customer relationships, building trust and respect by consistently meeting and exceeding expectations. \n  Interpersonal skills - able to work effectively with other employees, patients and external parties. \n  PC skills - demonstrates proficiency in PC applications as required. \n  Policies and Procedures - demonstrates knowledge and understanding of organizational policies, procedures and systems. \n  Basic skills - able to perform basic mathematical calculations, balance and reconcile figures, punctuate properly, spell correctly and transcribe accurately. \n  Must have strong documentation skills, organization, and able to prioritize work. \n \n  EDUCATION \n \n \n  High school diploma or GED required. \n  Bachelor\u2019s degree in information systems or healthcare-related field is preferred. \n  Relevant experience may substitute education requirements \n \n  EXPERIENCE \n \n \n  At least two years Parallon service center experience required. Emphasis on Billing or IT&S preferred. \n  Experience with ePremis, Relay Health and/or SSI billing vendor software. \n  Experience using SQL strongly preferred \n  Experience with Claim Update File (CUF) or XML is preferred. \n  Experience with professional and institutional claims \n  Proficient with Microsoft Office application such as Word, Excel, and Access. \n  Strong collaboration, facilitation, and data analysis skills \n  Working knowledge of the following applications: \n \n \n  Microsoft Office (Word, Excel, Access, Power Point) \n  Business Objects \n  Microsoft SharePoint \n \n \n   \n \n HealthTrust Supply Chain  is a critical part of HCA Healthcare\u2019s strategy. Our focus is to  improve performance  and reduce costs. We do this by joining non-clinical and administrative functions. HealthTrust Supply Chain best practice methodologies. We develop, apply and monitor  cost-efficient initiatives  and programs for HCA Healthcare. By improving facility efficiency, medical professionals can focus on our mission - patient care. \n  HCA Healthcare has been recognized as one of the World\u2019s Most Ethical Companies\u00ae by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses. \n \n \n \n \"Good people beget good people.\"- Dr. Thomas Frist, Sr.  HCA Healthcare Co-Founder \n We are a family 270,000 dedicated professionals! Our Talent Acquisition team is reviewing applications for our Electronic Processing Business Analyst opening. Qualified candidates will be contacted for interviews.  Submit your resume today to join our community of caring! \n  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "7b3854ea083b164f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40.0,
        "salary_max": 100.0,
        "title": "ServiceNow IT Service Management (ITSM) Analyst",
        "company": "Synovize",
        "desc": "Synovize is a leading technology consulting firm that specializes in providing innovative solutions to businesses across various industries. With a team of experienced professionals, we aim to deliver exceptional services to our clients and help them achieve their digital transformation goals. As a remote-first company, we offer flexible work opportunities to talented individuals across the United States. \n Overview: \n We are currently seeking a skilled and experienced ServiceNow IT Service Management (ITSM) Analyst to join our team. As a ServiceNow ITSM Analyst, you will be responsible for analyzing, designing, and implementing IT service management solutions using the ServiceNow platform. This is a full-time, permanent or contract position with the flexibility of remote work. \n Responsibilities: \n \n Collaborate with clients and stakeholders to understand their IT service management needs and translate them into ServiceNow configurations. \n Analyze existing IT service management processes and workflows, identifying areas for improvement and optimization. \n Design and configure ServiceNow ITSM modules, including incident management, problem management, change management, and service catalog. \n Customize ServiceNow functionalities using JavaScript, Angular, and other web technologies to meet specific client requirements. \n Integrate ServiceNow with external systems through REST API, SOAP API, and other integration methods. \n Develop and maintain the Configuration Management Database (CMDB) to ensure accurate and up-to-date data. \n Conduct testing and quality assurance activities to ensure the stability and reliability of the implemented ITSM solutions. \n Provide end-user training and support during and after the implementation process. \n Collaborate with cross-functional teams to ensure successful project delivery within agreed timelines and budgets. \n Stay updated with the latest ServiceNow features and enhancements, recommending and implementing improvements to optimize IT service management processes. \n \n Requirements: \n \n Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Contract, Permanent, Full-time \n Pay: $40.00 - $100.00 per hour \n Benefits: \n \n 401(k) matching \n Dental insurance \n Disability insurance \n Flexible schedule \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Parental leave \n Vision insurance \n \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 10 years \n 11+ years \n 1 year \n 2 years \n 3 years \n 4 years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n No experience needed \n Under 1 year \n \n Schedule: \n \n 10 hour shift \n 8 hour shift \n Day shift \n Monday to Friday \n Night shift \n Overtime \n \n Application Question(s): \n \n Do you have any ServiceNow Certifications? If so, were they paid out of pocket? \n \n Experience: \n \n ServiceNow: 2 years (Preferred) \n \n Security clearance: \n \n Secret (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Proven experience as a ServiceNow ITSM Analyst, working on IT service management projects and configuring the ServiceNow platform. \n Strong knowledge of IT service management processes and frameworks, such as ITIL. \n Proficiency in JavaScript, Angular, and web technologies for customization and enhancement purposes. \n Experience with integrating ServiceNow with external systems using REST API, SOAP API, and other methods. \n Familiarity with the Configuration Management Database (CMDB) and data management best practices. \n Strong problem-solving and analytical skills, with the ability to translate complex business requirements into technical solutions. \n Effective communication and collaboration skills to work with clients and cross-functional teams. \n \n Preferred Skills: \n \n ServiceNow certifications such as Certified Implementation Specialist or Certified Application Developer. \n Knowledge of ITIL best practices and their application in ServiceNow. \n Experience with other ServiceNow modules such as GRC, HAM, SAM, APM, and SPM. \n Familiarity with NoSQL databases and their usage in ServiceNow. \n Experience with ITOM, SCCM, JAMF, or other related tools and technologies. \n \n To apply for the position of ServiceNow IT Service Management (ITSM) Analyst at Synovize, please submit your resume and any relevant certifications. We are excited to hear from talented individuals who are passionate about leveraging the power of ServiceNow to drive efficient IT service delivery. Join us in shaping the future of technology consulting! \n Job Types: Contract, Permanent, Full-time ",
        "techs": [
            "servicenow itsm analyst",
            "servicenow platform",
            "itil",
            "javascript",
            "angular",
            "rest api",
            "soap api",
            "configuration management database (cmdb)",
            "servicenow certifications",
            "grc",
            "ham",
            "sam",
            "apm",
            "spm",
            "nosql databases",
            "itom",
            "sccm",
            "jamf"
        ],
        "cleaned_techs": [
            "servicenow platform",
            "itil",
            "javascript",
            "angular",
            "rest api",
            "soap api",
            "configuration management database (cmdb)",
            "servicenow certifications",
            "grc",
            "ham",
            "sam",
            "apm",
            "spm",
            "nosql",
            "itom",
            "sccm",
            "jamf"
        ]
    },
    "e7b954663a74e18f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 30.0,
        "salary_max": 50.0,
        "title": "Remote Business Analyst",
        "company": "Pinnacle Technical Resources",
        "desc": "Remote Business Analyst \n  Work Location \u2013 Remote \n   Positions Requested - 1\n   Hours per Day - 8\n   Hours per Week - 40\n   Total Hours \u2013 3-year contract \n  \n \n Project Name : Sourcing COE\n  \n \n TOP 5 SKILLS REQUIRED \n \n Great communication and cross-team building skills \n Proficient with Excel and Smartsheet \n Proficient with PowerPoint \n Process improvement and efficiency \n Change management skills \u2013 ability to support others as they navigate changes in policies, processes and systems. \n \n  The Sourcing Business Analyst will help support and drive several key Sourcing initiatives, and support the Sourcing COE Director as other ad hoc requests come up:\n  \n \n Supplier Performance Management \n \n QBRs (Quarterly Business Reviews) \u2013 Own the data collection, analysis, reporting and monitoring of the KPIs/SLAs and targets to prepare for QBRs \n Execute the formal escalation process for issue resolution \n Develop a Performance Improvement Plan to help Suppliers who are struggling (with BU input) and monitor PIPs \n Center of Excellence \n Monitor and report on spend analytics (monthly KPIs for 1:1 reviews with the BU leads, monthly reports on S2I initiatives that Sourcing is supporting, working capital spend, identify trends and root causes, etc.) \n Support with Knowledge Management \u2013 help build templates, update policies, research tools and best practices, create playbooks, etc. \n Support with Sourcing COE Brand Management \u2013 help with communications and marketing initiatives (brand strategy and identity, market research, awareness, and marketing campaigns, etc.) \n Oracle S2P Implementation \n Support facilitation of virtual workshops, capture notes, actions, etc. \n \n \n Comments : Work Hours: 8 AM to 5 PM or 9 AM to 6 PM as needed\n  \n \n Description : Responsible for working across multiple IT organizations/functions on business strategies and functional/business architectures. \n  \n Assesses and/or formulating strategic and/or tactical plans based on company business initiatives.  \n Manages large and important projects affecting business units across the Company.  \n Prepare detail plans, detail schedules, resource allocation and assignment, critical path analysis, methodology, coordination within all IT functions, and conducting budget analyses.  \n May be involved in user requirement definition, recommending business solutions/alternatives, assisting in RFP development and evaluations, and assisting clients in defining new services that ride on new technologies.  \n May also be responsible for analysis of existing business processes, design and implementation of streamlined processes and leading client organizations in the identification, planning and implementation of business process solutions.  \n Works as a liaison to clients and other IT organizations as a subject matter expert on the business processes they represent.  \n May coordinate, evaluate and partner with technology vendors and outside consultants as needed. \n \n \n \n Notes \n \n Remote position within U.S., laptop will be provided. \n Work Hours: 8 AM to 5 PM or 9 AM to 6 PM as needed would prefer Pacific Time \n Candidate required to be a U.S. Citizen or U.S. National \n Business Analyst with a sourcing background (Invoice to pay, etc) \n Strong data analytics background (Excel, Smartsheet \u2013 soon to be replaced with Oracle)  \n Facilitate meetings \n Building out Center of Excellence \u2013 help create PPT presentations for playbook  \n S2P Implementation \u2013 attend design workshops (follow up actions, note-taking) \n Knowledge of Agile is nice to have  \n Spans from acquiring customer to installation of satellites (customer service type background) \n Spend Analytics  \n \n \n  Pay Range: $30 - $50/HR W2\n     The specific compensation for this position will be determined by a number of factors, including the scope, complexity and location of the role as well as the cost of labor in the market; the skills, education, training, credentials and experience of the candidate; and other conditions of employment.\n     Our full-time consultants have access to benefits including medical, dental, vision as well as 401K contributions.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "28aab3ac6381d9fc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40000.0,
        "salary_max": 40000.0,
        "title": "Data Quality Analyst (Fraud Prevention)",
        "company": "owl.co",
        "desc": "Owl.co is a software company that enables insurers to fight illegitimate claims at scale while removing human bias from the process. Our clients are the top insurance companies across North America, and they are achieving incredible results through our AI-powered, evidence-based platform. We are on a mission to bring state-of-the-art ML and NLP methods to transform this traditionally manual activity into an equitable process. We are well-funded and have engineering offices in New York City, Toronto, and Vancouver. \n  We are looking for a Full-time Data Quality Analyst to join our team!  \n The Data Quality Analyst is responsible for collecting and analyzing data through thorough investigation practices to deliver a proactive insurance fraud monitoring, detection, and prevention solution for our clients. \n  Responsibilities & Scope: \n \n \n Perform thorough and timely insurance claims investigations, pulling from open data sources for your research. Logically organize evidence found and categorize documents accordingly.  \n Ensure proper quality assurance by analyzing external claimant data for quality, completeness, and accuracy. \n Analyze claims and report findings clearly and succinctly as they apply \n Drive efficiency and contribute meaningful input for automation throughout our operations process. \n Complete or exceed weekly file targets. \n Follow process & procedures for reviews.  \n Ensure the security & confidentiality of file PII. \n Operate within company security and disclosure guidelines.  \n \n Requirements \n \n Previous experience in content research (in an educational and/or professional context). \n Ability to work independently in a remote environment.  \n Strong written and verbal communication skills. Ability to clearly and concisely document research findings. \n Organized, a structured thinker with the ability to exercise creative, outside-the-box thinking while conducting an investigation. \n Strong ability to work independently and as part of a team. \n Disciplined in time management with the stressor to be flexible based on caseload and case management. \n Ability to adapt to changing technologies through dynamic training and open feedback. \n \n Benefits \n  The compensation for this role is USD $40,000.00 annually.  \n \n At Owl we recognize that your health is a priority, and we do our best to ensure you are well cared for through our Health & Dental Benefit Plan. \n Supplement your benefit plan with Owl\u2019s Health Care Spending and Wellness Spending Account, available for you to use on additional healthcare, personal wellness expenses, and/or your favourite activities. \n Your professional career is only one chapter of your life - through our 401k program, we help get you set up for the future. \n As we all know, there needs to be a balance between work and life. Cultivate this balance with our generous PTO policy which includes;\n    \n 20 Vacation Days \n 5 Sick/Personal Wellness Days \n Recognized Stat Holidays based on your Region \n \n Bring your friends on board! Help grow our team of top performers and receive a cash bonus through our uncapped, generous Employee Referral Program \n Build relationships and work towards meeting shared goals in our collaborative team environment.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "be644fe27ccd5c88": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90000.0,
        "salary_max": 100000.0,
        "title": "BCT Partners - Business Analyst 508 Compliance",
        "company": "BCT Partners, LLC",
        "desc": "Business Analyst 508 Compliance \n  It is a time of excitement and opportunity at BCT Partners \u2013 a great moment to join our team! We are seeking a  Business Analyst  with strong 508 compliance knowledge, who will play a pivotal role in ensuring accessibility across multiple projects, driving inclusivity, and fostering a culture of digital accessibility excellence. \n  About BCT \n  We solve complex social problems. \n  BCT is a management consulting firm that tackles complex social problems through data analytics, equity-centered solutions and program management. We believe complex issues are best solved through collaboration. As a result, we employ a multidisciplinary approach that combines domain expertise, research, evaluation, technology, organizational development, and a passion for change. \n  To learn more about how we live our values of Ubuntu (\u201cI am because we are\u201d) and our mission to harness the power of diversity, insights, and innovation to transform lives, accelerate equity, and create lasting change, go to our website and follow us on social media. \n  https://www.bctpartners.com/ \n \n  Responsibilities \n  The  Business Analyst - 508 Compliance  will be responsible for championing 508 compliance standards and best practices across a range of projects. You will collaborate closely with cross-functional teams, providing guidance, conducting assessments, and driving initiatives to ensure that our products and services are accessible to individuals with disabilities. \n  Skills / Who You Are \n  You will possess a proven background in 508 compliance, including WCAG (Web Content Accessibility Guidelines), ADA (Americans with Disabilities Act), and Section 508 of the Rehabilitation Act. The  Business Analyst - 508 Compliance  will collaborate with project managers, product owners, designers, developers, and content creators to integrate accessibility requirements into project plans and development cycles ensuring successful project delivery. By drafting policies, procedures, and practices for achieving Section 508 compliance you will organize, lead, coordinate, and facilitate all agency-wide functions and activities related to Section 508 compliance and ensure section 508 accessibility considerations are incorporated into planning, operation, and management of application software, intranet and public web sites that are developed, used, or maintained for our clients. \n  You bring to the table: \n \n  4 years minimum experience as a Business Analyst with experience in 508 compliance and accessibility; with an expert-level understanding of WCAG guidelines and ADA requirements. \n  Proficiency with accessibility testing tools, such as JAWS, NVDA, VoiceOver, or others. \n  Familiarity with software development methodologies (Agile, Scrum) is highly desirable. \n  Strong analytical and problem-solving capabilities, including the ability to devise innovative accessibility solutions. \n  Strong documentation skills with the ability to author or contribute to policies, procedures and practices. \n  Exceptional communication and interpersonal skills for effective collaboration and stakeholder engagement. \n  Ability to meet tight deadlines. \n  Proficiency in MS Office applications. \n \n  BCT offers a competitive total compensation package that, for this position, includes base pay with a target annual salary of $100,000, along with a generous benefits package. BCT\u2019s benefits include heavily subsidized medical, dental and vision coverage, fully vested 401k plan with company match, company paid life and disability insurance plans, a strong work-life balance/time-off structure and a fully supported remote work policy. \n  This is a remote position, located in any of the fifty United States or Washington, DC. BCT Partners works primarily on Eastern Time, though we do have staff in all four time zones. We support and encourage a strong staff community, leveraging virtual communication tools and collaborative work practices. The African philosophy of Ubuntu (\u201cI am because we are\u201d) is an overarching value that influences our leadership and interactions. \n   \n tDcSQF3FFc",
        "cleaned_desc": "  Proficiency with accessibility testing tools, such as JAWS, NVDA, VoiceOver, or others. \n  Familiarity with software development methodologies (Agile, Scrum) is highly desirable. \n  Strong analytical and problem-solving capabilities, including the ability to devise innovative accessibility solutions. \n  Strong documentation skills with the ability to author or contribute to policies, procedures and practices. \n  Exceptional communication and interpersonal skills for effective collaboration and stakeholder engagement. ",
        "techs": [
            "jaws",
            "nvda",
            "voiceover",
            "agile",
            "scrum"
        ],
        "cleaned_techs": [
            "jaws",
            "nvda",
            "voiceover",
            "agile",
            "scrum"
        ]
    },
    "cece4bfdbbe1ebf2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 85000.0,
        "salary_max": -1.0,
        "title": "Database Systems Analyst (100% Remote, Financial Services)",
        "company": "Orion First",
        "desc": "Our Company \n  Committed to the growth of our clients, Orion First appreciates the importance of its own team development. Orion\u2019s culture is built around empowering each employee to channel their drive and exercise his or her own judgment, care, and leadership. Our employees are continually leading our industry forward through active roles throughout the industry association's various councils and committees. We work hard to provide motivated and talented individuals an opportunity to achieve their career goals. We cultivate employees that express an earnest desire to learn and grow within the organization, filling new roles as they gain experience. We are always seeking to connect with driven individuals, because we know our growth and success is the result of talented, focused, and persistent hard work. \n \n  Your Benefits \n  In addition to a salary that is competitive for both the industry and the region, Orion First offers the following benefits and perquisites: \n \n Health Insurance \n Dental Insurance \n Vision Insurance \n Time Off \n Retirement \n WFH Benefit \n And More! \n \n \n \n  Job Summary \n  The Database Systems Analyst will be part of a team that ensures that data pipeline processes and databases and warehouses at Orion are available, secure, and healthy. The primary goal is to provide a seamless flow of information throughout Orion\u2019s operations and ensure that the data structure adheres to the overall company data governance policies.  \n For an individual to be successful in this role they should have a broad skillset in database management, creating and maintaining data transformations and data pipelines, and have 5-8 years of direct experience. \n  This position will be a part of a growing company with many different technologies in use and opportunities to grow technically.   \n \n \n Reports directly to: \n  VP/ Data & Analytics \n \n \n  Key Responsibilities \n \n Collect, clean, and analyze data from various sources to identify trends, patterns, and opportunities for improvement. \n Collaborate with data analysts, engineers, and stakeholders to identify and document requirements/needs for data pipelines. \n Monitor the performance, scalability, and security of data systems; performs analysis required to troubleshoot data related issues and assists in resolving them. \n Willing to learn new systems and take on new challenges. \n Administer vendor software systems, researching and troubleshooting issues, resolving end user concerns. \n Write complex SQL queries to extract, manipulate, and aggregate data for reporting and analysis. \n Assist in database design, maintenance, and optimization to ensure data accuracy and performance. \n Work closely with cross-functional teams to understand business requirements and provide data-driven solutions. \n Validate source data quality and drive improvements. \n Ensure data integrity and accuracy through thorough validation and testing procedures. \n Assist in the deployment of analytics products. \n Performs other duties as assigned. \n Strong communication skills, including the ability to simplify complex technical concepts. \n Document the \u201cas-is\u201d process to determine if a process can be streamlined. Develop options, including automation, and present to management. Implement the selected option and provide post-implementation support. \n Create email and file share subscriptions; monitor and troubleshoot subscription schedule errors.  \n Administer databases, user management, access management. \n Ability to create Azure Data Factory pipelines and import packages from SQL systems. \n Monitoring SQL agent jobs and troubleshooting SSIS packages. \n Create and optimize SSIS packages for data extraction, transformation, and loading. \n Develop and enhance SSRS reports using query logic, parameters, custom code, linked reports, variables, and built-in functions. \n \n \n \n  Required Qualifications \n \n Demonstrated ability to take projects from system design to implementation. \n 5+ years of industry experience. \n 5+ years using SQL to query and structure data. \n 2+ years of experience developing reports with SSRS, SSIS. \n At least 1 data migration project, preferably SQL server to Azure Cloud. \n Experience in designing data architecture and familiarity with data governance concepts. \n Bachelor\u2019s degree in relevant field. \n \n \n \n  Preferred Qualifications \n \n At least 7 years of experience in data analysis, reporting, and database management.   \n Experience with dimensional modeling techniques (Kimball techniques, star schemas) and how to apply dimensional modeling when developing business intelligence applications.    \n Experience with Powershell scripting is a plus. \n Knowledge of XML in SQL Server will be helpful. \n Master's degree in relevant field. \n \n \n \n  Soft Skills \n \n Strong analytical thinking and problem-solving skills, ability to quickly learn and troubleshoot. \n Must be highly motivated. \n Ability to set priorities and follow project schedules. \n Strong analytical and troubleshooting skills. \n Strong organizational, written, verbal and interpersonal communication skills. Must be able to work with and communicate with people of various knowledge levels from the very technical to the casual user. \n Must be very detail-oriented. \n Agile mindset that can handle a dynamic work environment. \n Need superior customer service skills, being able to work effectively with a variety of people in all departments to determine their problems and find solutions. \n Strives to deliver highest quality output without error. \n Effectively work as a member of a team or as the project leader. \n Self-starting and self-executing with minimal to no guidance or oversight. \n Desire to cross-train and learn reporting tools. \n Ability to adapt to changing requirements.",
        "cleaned_desc": "  The Database Systems Analyst will be part of a team that ensures that data pipeline processes and databases and warehouses at Orion are available, secure, and healthy. The primary goal is to provide a seamless flow of information throughout Orion\u2019s operations and ensure that the data structure adheres to the overall company data governance policies.  \n For an individual to be successful in this role they should have a broad skillset in database management, creating and maintaining data transformations and data pipelines, and have 5-8 years of direct experience. \n  This position will be a part of a growing company with many different technologies in use and opportunities to grow technically.   \n \n \n Reports directly to: \n  VP/ Data & Analytics \n \n \n  Key Responsibilities \n \n Collect, clean, and analyze data from various sources to identify trends, patterns, and opportunities for improvement. \n Collaborate with data analysts, engineers, and stakeholders to identify and document requirements/needs for data pipelines. \n Monitor the performance, scalability, and security of data systems; performs analysis required to troubleshoot data related issues and assists in resolving them. \n Willing to learn new systems and take on new challenges. \n Administer vendor software systems, researching and troubleshooting issues, resolving end user concerns. \n Write complex SQL queries to extract, manipulate, and aggregate data for reporting and analysis.   Assist in database design, maintenance, and optimization to ensure data accuracy and performance. \n Work closely with cross-functional teams to understand business requirements and provide data-driven solutions. \n Validate source data quality and drive improvements. \n Ensure data integrity and accuracy through thorough validation and testing procedures. \n Assist in the deployment of analytics products. \n Performs other duties as assigned. \n Strong communication skills, including the ability to simplify complex technical concepts. \n Document the \u201cas-is\u201d process to determine if a process can be streamlined. Develop options, including automation, and present to management. Implement the selected option and provide post-implementation support. \n Create email and file share subscriptions; monitor and troubleshoot subscription schedule errors.  \n Administer databases, user management, access management. \n Ability to create Azure Data Factory pipelines and import packages from SQL systems. \n Monitoring SQL agent jobs and troubleshooting SSIS packages. \n Create and optimize SSIS packages for data extraction, transformation, and loading. \n Develop and enhance SSRS reports using query logic, parameters, custom code, linked reports, variables, and built-in functions. \n \n \n    Required Qualifications \n \n Demonstrated ability to take projects from system design to implementation. \n 5+ years of industry experience. \n 5+ years using SQL to query and structure data. \n 2+ years of experience developing reports with SSRS, SSIS. \n At least 1 data migration project, preferably SQL server to Azure Cloud. \n Experience in designing data architecture and familiarity with data governance concepts. \n Bachelor\u2019s degree in relevant field. \n \n \n \n  Preferred Qualifications \n \n At least 7 years of experience in data analysis, reporting, and database management.   \n Experience with dimensional modeling techniques (Kimball techniques, star schemas) and how to apply dimensional modeling when developing business intelligence applications.    \n Experience with Powershell scripting is a plus.   Knowledge of XML in SQL Server will be helpful. \n Master's degree in relevant field. \n \n \n \n  Soft Skills \n \n Strong analytical thinking and problem-solving skills, ability to quickly learn and troubleshoot. \n Must be highly motivated. \n Ability to set priorities and follow project schedules. \n Strong analytical and troubleshooting skills. \n Strong organizational, written, verbal and interpersonal communication skills. Must be able to work with and communicate with people of various knowledge levels from the very technical to the casual user. \n Must be very detail-oriented. \n Agile mindset that can handle a dynamic work environment. \n Need superior customer service skills, being able to work effectively with a variety of people in all departments to determine their problems and find solutions. \n Strives to deliver highest quality output without error. \n Effectively work as a member of a team or as the project leader. ",
        "techs": [
            "azure data factory pipelines",
            "sql systems",
            "sql agent jobs",
            "ssis packages",
            "ssrs reports",
            "powershell scripting",
            "xml in sql server"
        ],
        "cleaned_techs": [
            "azure",
            "sql",
            "ssis packages",
            "ssrs reports",
            "powershell scripting",
            "xml in sql server"
        ]
    },
    "5f40de400dd9ae89": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 95000.0,
        "title": "Board Certified Behavior Analyst (BCBA)",
        "company": "Supportive Care ABA",
        "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "f816658071b7e686": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55730.0,
        "salary_max": 103500.0,
        "title": "EDI Financial Business Analyst, Sr",
        "company": "Tista Science and Technology Corporation",
        "desc": "Overview: \n  \n   TISTA Science and Technology is seeking a senior level \n   EDI Financial Business Analyst  who will work as a liaison between customers and subject matter expert in order to elicit, analyze, communicate, and validate requirements and business processes. Prepares and/or maintains detailed documentation pertaining to programming, systems operations, and requirements. Translates business specifications into the programmer, data scientist, and end-user documentation. Achieves and maintains subject matter expertise relevant to functional areas.\n  \n \n \n  TISTA associates enjoy above Industry Healthcare Benefits, Remote Working Options, Paid Time Off, Training/Certification opportunities, Healthcare Savings Account & Flexible Savings Account, Paid Life Insurance, Short-term & Long-term Disability, 401K Match, Tuition Reimbursement, Employee Assistance Program, Paid Holidays, Military Leave, and much more!\n   Responsibilities: \n  \n Write detailed Requirements for EDI related Epics/Features/Stories and transitioning them to technical team \n  Keep the EDI related user stories up to date. \n  Act as a bridge between business, design, development, and test teams for all EDI related questions/clarifications \n  Support integration test efforts between external systems and EDI (third-party providers) \n  Testing for EDI requirements \n  Plans and designs complex business processes and system modifications. Provide recommendations to improve and support business activities \n  Gathers business requirements through a variety of techniques such as work sessions, meetings, and interviews \n  Analyzes and documents client complex business requirements and processes; communicates these requirements to appropriate parties and get signoff \n  Provides inputs into developing and modifying systems to meet client needs \n  Coordinates and facilitates meetings with clients to gather and document requirements and explore potential solutions \n \n \n  Qualifications: \n  \n 5 years of experience supporting software development programs \n  Excellent financials and retail domain knowledge and work experience \n  Experience mapping and supporting EDI based transactions i.e., 810, 850, 855, 856, 832, and 842 \n  Knowledge of EDI, X12/EDIFACT standards and practices, and EDI translators \n  EDI experience (setup, mapping, testing, processing, troubleshooting) \n  Proficient in EDI layouts (loops, segments, data elements) \n  Perform EDI onboarding and testing with applicable third-party providers \n  Create workflows, process flows, and Manage EDI Maps and Connections \n  Create project plans, test plans, conduct end to end testing \n  Knowledge and experience with translator tool \n  Experience working with SQL Server databases \n  Experience in ETL/Data Warehousing skills \n  Experience in SAFe Agile team environment driving stand up, backlog grooming, and iteration planning \n  Experience in a customer\u2013facing role, including comprehending business needs, solving complex problems, and capturing business requirements to convert them into technical requirements \n  Experience with leading Scrum teams as a Scrum Master and working with developers to translate business needs into user stories \n  Experience working on Federal programs that are of high priority, visibility, and public-facing \n  Experience with Agile delivery programs \n  Must be able to work quickly with a high degree of accuracy with cross-functional teams \n  Able to work under minimal supervision, act independently and exercise an expert level of decision-making capability \n  Excellent writing skills and ability to produce polished written products \n  Demonstrated ability and experience using Microsoft Office Suite including Word, PowerPoint, Excel, Visio, and Access \n \n \n  Education  \n \n Bachelor of Science or Bachelor of Arts  or  an additional 7 years of experience (for a total of 12 years of working experience) \n  Certified Scrum Master, Certified Scrum Product Owner, SAFe and other Agile Certification (nice to have) \n \n  Clearance: \n \n  The ability to pass a Moderate Background Investigation (MBI) \n \n \n \n \n \n  Location: \n \n \n \n        Remote, USA\n       \n \n \n  Pay Range: \n \n \n  The pay for this position ranges from $55,730 to $103,500 \n  The actual salary offer will carefully consider a wide range of factors, including your skills, qualifications, experience, and location \n  Also, certain positions are eligible for additional forms of compensation, such as bonuses \n  TISTA associates are eligible to participate in our comprehensive benefits plan! More information can be found here: https://tistatech.com/working-at-tista/",
        "cleaned_desc": "  EDI experience (setup, mapping, testing, processing, troubleshooting) \n  Proficient in EDI layouts (loops, segments, data elements) \n  Perform EDI onboarding and testing with applicable third-party providers \n  Create workflows, process flows, and Manage EDI Maps and Connections \n  Create project plans, test plans, conduct end to end testing \n  Knowledge and experience with translator tool \n  Experience working with SQL Server databases \n  Experience in ETL/Data Warehousing skills \n  Experience in SAFe Agile team environment driving stand up, backlog grooming, and iteration planning \n  Experience in a customer\u2013facing role, including comprehending business needs, solving complex problems, and capturing business requirements to convert them into technical requirements \n  Experience with leading Scrum teams as a Scrum Master and working with developers to translate business needs into user stories \n  Experience working on Federal programs that are of high priority, visibility, and public-facing \n  Experience with Agile delivery programs \n  Must be able to work quickly with a high degree of accuracy with cross-functional teams    Able to work under minimal supervision, act independently and exercise an expert level of decision-making capability \n  Excellent writing skills and ability to produce polished written products \n  Demonstrated ability and experience using Microsoft Office Suite including Word, PowerPoint, Excel, Visio, and Access \n \n \n  Education  \n \n Bachelor of Science or Bachelor of Arts  or  an additional 7 years of experience (for a total of 12 years of working experience) \n  Certified Scrum Master, Certified Scrum Product Owner, SAFe and other Agile Certification (nice to have) \n \n  Clearance: \n \n  The ability to pass a Moderate Background Investigation (MBI) \n ",
        "techs": [
            "edi experience (setup",
            "mapping",
            "testing",
            "processing",
            "troubleshooting)",
            "edi layouts (loops",
            "segments",
            "data elements)",
            "translator tool",
            "sql server databases",
            "etl/data warehousing skills",
            "safe agile",
            "scrum master",
            "user stories",
            "federal programs",
            "agile delivery programs",
            "microsoft office suite",
            "certified scrum master",
            "certified scrum product owner",
            "safe certification",
            "moderate background investigation (mbi)"
        ],
        "cleaned_techs": [
            "edi experience (setup",
            "mapping",
            "testing",
            "processing",
            "troubleshooting)",
            "edi layouts (loops",
            "segments",
            "data elements)",
            "translator tool",
            "sql",
            "safe agile",
            "scrum master",
            "user stories",
            "federal programs",
            "agile delivery programs",
            "microsoft",
            "certified scrum master",
            "certified scrum product owner",
            "safe certification",
            "moderate background investigation (mbi)"
        ]
    },
    "944c4e81f5d5ad14": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Business Intelligence Analyst Intermediate (Work from Home United States)",
        "company": "Geisinger",
        "desc": "Job Summary  Responsible for performing tasks related to project completion including analysis, testing, documentation, problem resolution, and implementation of solutions as they apply to the organization's strategy. Responsible for performing tasks related to report development including requirements gathering, specification and definition documentation, design, testing, validation, analysis, and maintenance for all reporting projects.\n  \n  Job Duties \n \n  Gathers requirements and defines scope independently on small and medium sized projects. \n  Requires support of a senior analyst for large projects. \n  Assists in project plan and time and effort estimations. \n  Will also produce project plans and estimates with required sign off by senior resources. \n  Building the skillset and awareness on data project work - shadowing and reviewing solution architecture to learn data components. \n  Determines data needed and profile to establish quality and appropriateness. \n  Recognize show to transform the data set to establish what is needed for next stage BI and reporting. \n  Develop an understanding of how to be able to deliver clear requirements for requests to perform ETL from other team members but working with a senior to do this when appropriate. \n  Building the comfort in delivering powerful stories with data both in the solutions built as well as the approach for delivery. \n  Responsible for following data governance and stewardship practices as defined. \n  Performing documentation and discovery associated with these initiatives. \n  Identifying data quality issues while performing data profiling and testing and validation. \n \n  Work is typically performed in an office environment. Accountable for satisfying all job specific obligations and complying with all organization policies and procedures. The specific statements in this profile are not intended to be all-inclusive. They represent typical elements considered necessary to successfully perform the job. *Relevant experience may be a combination of related work experience and degree obtained (Associate\u2019s Degree = 2 years; Bachelor\u2019s Degree = 4 years, Master's Degree = 6 years). \n  Position Details \n \n  Key tools include SQL, Tableau, and/or familiarity with Epic EHR Clarity Database \n  Comfortable with relational database structure; uses SQL to produce accurate queries using joins and subqueries, pivots, aggregate functions, etc. \n  Develops interactive and user friendly visualizations using best practices to solve business problems \n \n  Education  High School Diploma or Equivalent (GED)- (Required)\n  \n  Experience  Minimum of 6 years-Relevant experience* (Required)\n  \n  Certification(s) and License(s) \n  OUR PURPOSE & VALUES: Everything we do is about caring for our patients, our members, our students, our Geisinger family and our communities. KINDNESS: We strive to treat everyone as we would hope to be treated ourselves. EXCELLENCE: We treasure colleagues who humbly strive for excellence. LEARNING: We share our knowledge with the best and brightest to better prepare the caregivers for tomorrow. INNOVATION: We constantly seek new and better ways to care for our patients, our members, our community, and the nation. SAFETY: We provide a safe environment for our patients and members and the Geisinger family We offer healthcare benefits for full time and part time positions from day one, including vision, dental and domestic partners. Perhaps just as important, from senior management on down, we encourage an atmosphere of collaboration, cooperation and collegiality. We know that a diverse workforce with unique experiences and backgrounds makes our team stronger. Our patients, members and community come from a wide variety of backgrounds, and it takes a diverse workforce to make better health easier for all. We are proud to be an affirmative action, equal opportunity employer and all qualified applicants will receive consideration for employment regardless to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or status as a protected veteran.",
        "cleaned_desc": "  Key tools include SQL, Tableau, and/or familiarity with Epic EHR Clarity Database \n  Comfortable with relational database structure; uses SQL to produce accurate queries using joins and subqueries, pivots, aggregate functions, etc. \n  Develops interactive and user friendly visualizations using best practices to solve business problems \n \n  Education  High School Diploma or Equivalent (GED)- (Required)",
        "techs": [
            "sql",
            "tableau",
            "epic ehr clarity database"
        ],
        "cleaned_techs": [
            "sql",
            "tableau",
            "epic ehr clarity database"
        ]
    },
    "b2968465e0471337": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 97275.0,
        "salary_max": 162125.0,
        "title": "Lead Business Analyst - Point of Sale",
        "company": "Builders FirstSource",
        "desc": "We are Builders FirstSource, America\u2019s largest supplier of building materials, value-added components and building services to the professional market. You\u2019ll feel proud of the work you do here every day to transform the future of home building and help make the dream of home ownership more achievable. At BFS, we believe building a successful career is not solely defined by a degree. Your experience, skills, and passion are just as important, if not more so. As such, we are committed to creating a diverse and inclusive workplace that welcomes candidates from all backgrounds and experience levels. \n \n  We are seeking a talented and experienced Lead Analyst to join our dynamic team and play a pivotal role in the implementation, optimization and enhancement of our Retail and Point of Sale (POS) systems. In this role, you will be responsible for identifying business needs, analyzing processes, and driving improvements to our Retail solutions. Your insights and recommendations will be instrumental in ensuring seamless transactions and enhanced customer experiences. \n \n  ESSENTIAL DUTIES AND RESPONSIBILITIES \n \n \n Business Process Analysis: Analyze existing business processes and workflows related to Retail systems. Identify areas of improvement and optimization to enhance efficiency, accuracy, and customer satisfaction. \n Data Analysis: Evaluate data related to sales, returns, inventory, and customer interactions. Extract meaningful insights and trends from the data to inform decision-making and enhancements to the Retail systems. \n System Evaluation: Assess the current Retail system landscape, including hardware and software components and leverage this knowledge to design and shape the functionality in the new Retail platform. Identify opportunities for process improvement, policy changes and system enhancements to meet evolving business needs. \n Solution Design: Collaborate with IT and development teams to design and propose solutions that address identified business needs. Create detailed specifications and functional requirements for Retail systems enhancements. \n User Acceptance Testing: Plan and conduct user acceptance testing (UAT) to ensure that Retail systems system changes meet business requirements and user expectations. \n Documentation: Maintain comprehensive and up-to-date documentation of Retail systems configurations, workflows, and user guides. Ensure that all stakeholders have access to relevant documentation. \n Training and Support: Assist in developing training materials and provide training to end-users, ensuring they can effectively use Retail systems. Offer ongoing support to resolve issues and address user concerns. \n Vendor Management: Collaborate with Retail system vendors to evaluate and implement new features, updates, or troubleshoot issues as needed. \n Compliance and Security: Ensure that Retail systems comply with relevant industry standards, data protection regulations, and security best practices. \n  MINIMUM REQUIREMENTS \n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. \n \n \n A minimum of 7 years of experience in gathering and analyzing business and technical requirements and demonstrated proficiency in translating business needs into technical solutions. \n A minimum of 5 years of experience working with Retail systems, including POS hardware and software components, with a deep understanding of Retail functionality and features. \n Proficiency in data analysis tools and techniques, with a minimum of 3 years of experience in extracting meaningful insights from sales and transaction data to inform business decisions and optimize POS systems. \n A solid understanding of retail operations, including inventory management, sales processes, and customer interactions, with a minimum of 3 years of experience in retail industry practices. \n Experience working within agile or similar project management methodologies, with a minimum of 2 years of experience in agile project environments, including user stories, sprint planning, and iterative development. \n Familiarity with payment processing technologies and payment security standards, such as PCI DSS, with a minimum of 2 years of experience in ensuring secure and compliant payment transactions at the POS. \n Bachelor's degree from an accredited college/university or equivalent relevant work experience. \n  COMPETENCIES \n \n \n Point of Sale (POS) Systems Proficiency: A comprehensive understanding of various POS systems, both hardware and software components, is essential. This includes knowledge of different POS software platforms, payment processing, barcode scanning, receipt printing, and customer display systems. \n Retail Software and ERP Knowledge: Familiarity with retail-specific software solutions and enterprise resource planning (ERP) systems is vital. This competency involves expertise in software used for merchandising, promotional pricing, inventory management, order fulfillment, supply chain management, and sales analysis, among others. \n Data Analytics and Business Intelligence Tools: Proficiency in data analytics and business intelligence tools is essential for extracting actionable insights from retail and POS data. This includes knowledge of data warehousing, data visualization tools, and the ability to create meaningful reports and dashboards for decision-makers. \n Payment and Security Technologies: An understanding of payment technologies, security protocols, and compliance standards in the retail environment is critical. This includes knowledge of PCI DSS compliance, encryption methods, and emerging payment technologies like mobile wallets and contactless payments. \n Evaluates Problems: Evaluates and analyzes different types of information objectively to identify appropriate solutions; writes fluently, establishing the key facts clearly and interprets numerical data effectively. \n Technical Communication/ Presentation: Communicates with clarity and precision, presenting complex information in a concise format that is audience appropriate. \n Adjusting and Driving Change: Takes a positive approach to tackling work and embraces change; invites feedback relating to performance and deals constructively with criticism. Identifies the need for and drives change when required to achieve objectives. \n Focuses on Customers: Understands and anticipates customer needs and takes action to provide high-quality products and services to exceed expectations. \n Demonstrates Business Acumen: Demonstrates working knowledge of market, economic, legal, and regulatory environments and how they impact the business. \n Agile Best Practices: Understands how agility is leveraged in IT ways of working. Adopts agile best practices as appropriate throughout the assigned work lifecycle. Responds to feedback quickly based on comments of internal and external customers and needs of the market. \n Bias for Action: Takes initiative and identifies what needs to be done and acts without waiting to be asked. Executes work in a timely manner. Suggests improvements to current ways of working. \n  BFS COMPETENCIES \n \n \n Business and Financial Acumen \n Demonstrates depth of understanding for the P&L and financial analysis \n Teaches business and financial acumen to others. \n Understands KPIs and how BFS makes money. \n Knows the different business segments and how they relate to one another. \n Understands customer sales and engagement. \n Demonstrates functional and/or technical expertise. \n Understands complex issues and demonstrates problem solving skills. \n Understands how to maximize business results regardless of industry cycle. \n Results Driven \n Holds self and others accountable. \n Communicates and sets clear goals with plans to deliver. \n Manages competing priorities effectively. \n Demonstrates appropriate urgency. \n Drives to exceed expectations in alignment with our BFS SPICE values. \n Embraces and follows best practices. \n Demonstrates self-starter, can-do attitude. \n Strategic Thinking and Decision Making \n Leverages resources and teams around them to solve problems and create mutually beneficial outcomes. \n Demonstrates willingness and courage to make tough decisions in a timely manner. \n Balances short-and-long term priorities \n Demonstrates proactive versus reactive thinking. \n Asks questions to identify root cause and analyze situations more accurately. \n Servant Leadership \n Demonstrates humility by putting others first. \n Builds trust-based relationships. \n Leads by example with kindness and respect. \n Collaborates well across all areas of the business. \n Advocates for others \n Actively listens to understand the meaning and intent of what the other person is communicating. \n Demonstrates authenticity and encourages others to do the same. \n Emotional Intelligence \n Demonstrates situational awareness \u2013 knows when and how to adjust leadership style in different situations. \n Demonstrates self-awareness \u2013 understands strengths and weaknesses. \n Demonstrates empathy \u2013 puts themselves in other\u2019s shoes. \n Assumes positive intent. \n Develops and Leads Others \n Drives alignment through clear communication of vision, goals, and expectations. \n Invests time on a regular basis in performance feedback and developmental conversations. \n Fosters a respectful and inclusive environment. \n Empowers, motivates, and inspires others. \n Coaches and mentor others for their development. \n Guides and persuades others to deliver positive outcomes. \n Growth Mindset \n Demonstrates a growth mindset; takes appropriate risks, fails fast and forward, learns from mistakes. \n Perseveres and champions growth, even in the face of resistance, ambiguity, or possible failure. \n Thinks like an owner with an entrepreneurial spirit. \n Demonstrates and encourages intellectual curiosity. \n Continuous learner; seeks opportunities and knowledge for personal and professional growth. \n Sees possibilities over problems \u2013 actively seeks solutions. \n Innovation \n Encourages out-of-the box thinking to create new ways of doing things. \n Continuously seeks to improve and simplify pain points in the business. \n Anticipates, embraces, and leads change. \n Develops and executes breakthrough strategies. \n Integrity \n Does the right thing even under challenging circumstances? \n Communicates with honesty. \n Consistently treats others fairly and equitably. \n Demonstrates reliability and does what they say they will do. \n Conducts tough conversations and delivers difficult messages with kindness and respect. \n  WORK ENVIRONMENT / PHYSICAL ACTIVITY \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n Subject to both typical office environment and outside locations with temperature and weather variations. \n Must be able to lift and carry up to 25 pounds. \n 25% travel may be required. \n  In addition to the base wage listed, this position is also eligible to earn an annual bonus subject to changes in plan design and documents and in accordance with applicable law. Eligibility and the amount of the bonus varies based on overall company success, thresholds met and other terms and conditions of the Company\u2019s active bonus policy for the respective year. \n \n  Full-Time Team Members are eligible for company benefits, including \u2022 Three Medical plan options \u2022 Dental & Vision \u2022 Critical Care \u2022 Accident & Hospital insurance \n \n \n Flexible Spending Accounts for Health & Dependent Care \u2022 Health Savings Account \u2022 401(k) with company match \u2022 Vacation & Sick Time \u2022 Paid company holidays \n Company Paid Life & AD&D \u2022 Supplemental Life \u2022 Short & Long Term Disability \u2022 Bereavement \u2022 Paid Parental Leave \u2022 Team Member Assistance Program \n  All benefits are subject to change pursuant to state and federal guidelines. \n \n  Builders FirstSource is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status or status as an individual with a disability. \n \n  In compliance with the ADA Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position with Builders FirstSource, please call (214) 765-3990 or email: ADA.Accommodation@bldr.com. Please do not send resumes to this email address - it is intended only to be used to request an accommodation in submitting an application for a job opening. \n \n  https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm \n \n  EEO THE LAW - English/Spanish \n EEO IS THE LAW - SUPPLEMENT - English/Spanish \n Pay Transparency Provision - English/Spanish",
        "cleaned_desc": "We are Builders FirstSource, America\u2019s largest supplier of building materials, value-added components and building services to the professional market. You\u2019ll feel proud of the work you do here every day to transform the future of home building and help make the dream of home ownership more achievable. At BFS, we believe building a successful career is not solely defined by a degree. Your experience, skills, and passion are just as important, if not more so. As such, we are committed to creating a diverse and inclusive workplace that welcomes candidates from all backgrounds and experience levels. \n \n  We are seeking a talented and experienced Lead Analyst to join our dynamic team and play a pivotal role in the implementation, optimization and enhancement of our Retail and Point of Sale (POS) systems. In this role, you will be responsible for identifying business needs, analyzing processes, and driving improvements to our Retail solutions. Your insights and recommendations will be instrumental in ensuring seamless transactions and enhanced customer experiences. \n \n  ESSENTIAL DUTIES AND RESPONSIBILITIES \n \n \n Business Process Analysis: Analyze existing business processes and workflows related to Retail systems. Identify areas of improvement and optimization to enhance efficiency, accuracy, and customer satisfaction. \n Data Analysis: Evaluate data related to sales, returns, inventory, and customer interactions. Extract meaningful insights and trends from the data to inform decision-making and enhancements to the Retail systems. \n System Evaluation: Assess the current Retail system landscape, including hardware and software components and leverage this knowledge to design and shape the functionality in the new Retail platform. Identify opportunities for process improvement, policy changes and system enhancements to meet evolving business needs. \n Solution Design: Collaborate with IT and development teams to design and propose solutions that address identified business needs. Create detailed specifications and functional requirements for Retail systems enhancements. \n User Acceptance Testing: Plan and conduct user acceptance testing (UAT) to ensure that Retail systems system changes meet business requirements and user expectations. \n Documentation: Maintain comprehensive and up-to-date documentation of Retail systems configurations, workflows, and user guides. Ensure that all stakeholders have access to relevant documentation. \n Training and Support: Assist in developing training materials and provide training to end-users, ensuring they can effectively use Retail systems. Offer ongoing support to resolve issues and address user concerns. \n Vendor Management: Collaborate with Retail system vendors to evaluate and implement new features, updates, or troubleshoot issues as needed. \n Compliance and Security: Ensure that Retail systems comply with relevant industry standards, data protection regulations, and security best practices. \n  MINIMUM REQUIREMENTS \n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. \n \n \n A minimum of 7 years of experience in gathering and analyzing business and technical requirements and demonstrated proficiency in translating business needs into technical solutions. \n A minimum of 5 years of experience working with Retail systems, including POS hardware and software components, with a deep understanding of Retail functionality and features. \n Proficiency in data analysis tools and techniques, with a minimum of 3 years of experience in extracting meaningful insights from sales and transaction data to inform business decisions and optimize POS systems. \n A solid understanding of retail operations, including inventory management, sales processes, and customer interactions, with a minimum of 3 years of experience in retail industry practices. \n Experience working within agile or similar project management methodologies, with a minimum of 2 years of experience in agile project environments, including user stories, sprint planning, and iterative development.   Familiarity with payment processing technologies and payment security standards, such as PCI DSS, with a minimum of 2 years of experience in ensuring secure and compliant payment transactions at the POS. \n Bachelor's degree from an accredited college/university or equivalent relevant work experience. \n  COMPETENCIES \n \n \n Point of Sale (POS) Systems Proficiency: A comprehensive understanding of various POS systems, both hardware and software components, is essential. This includes knowledge of different POS software platforms, payment processing, barcode scanning, receipt printing, and customer display systems. \n Retail Software and ERP Knowledge: Familiarity with retail-specific software solutions and enterprise resource planning (ERP) systems is vital. This competency involves expertise in software used for merchandising, promotional pricing, inventory management, order fulfillment, supply chain management, and sales analysis, among others. \n Data Analytics and Business Intelligence Tools: Proficiency in data analytics and business intelligence tools is essential for extracting actionable insights from retail and POS data. This includes knowledge of data warehousing, data visualization tools, and the ability to create meaningful reports and dashboards for decision-makers. \n Payment and Security Technologies: An understanding of payment technologies, security protocols, and compliance standards in the retail environment is critical. This includes knowledge of PCI DSS compliance, encryption methods, and emerging payment technologies like mobile wallets and contactless payments. \n Evaluates Problems: Evaluates and analyzes different types of information objectively to identify appropriate solutions; writes fluently, establishing the key facts clearly and interprets numerical data effectively. \n Technical Communication/ Presentation: Communicates with clarity and precision, presenting complex information in a concise format that is audience appropriate. \n Adjusting and Driving Change: Takes a positive approach to tackling work and embraces change; invites feedback relating to performance and deals constructively with criticism. Identifies the need for and drives change when required to achieve objectives. \n Focuses on Customers: Understands and anticipates customer needs and takes action to provide high-quality products and services to exceed expectations. \n Demonstrates Business Acumen: Demonstrates working knowledge of market, economic, legal, and regulatory environments and how they impact the business. \n Agile Best Practices: Understands how agility is leveraged in IT ways of working. Adopts agile best practices as appropriate throughout the assigned work lifecycle. Responds to feedback quickly based on comments of internal and external customers and needs of the market. \n Bias for Action: Takes initiative and identifies what needs to be done and acts without waiting to be asked. Executes work in a timely manner. Suggests improvements to current ways of working. \n  BFS COMPETENCIES \n \n \n Business and Financial Acumen \n Demonstrates depth of understanding for the P&L and financial analysis \n Teaches business and financial acumen to others. \n Understands KPIs and how BFS makes money. \n Knows the different business segments and how they relate to one another. \n Understands customer sales and engagement. ",
        "techs": [
            "builders firstsource\nretail and point of sale (pos) systems\nbusiness process analysis\ndata analysis\nsystem evaluation\nsolution design\nuser acceptance testing\ndocumentation\ntraining and support\nvendor management\ncompliance and security\npos systems\nretail software and erp knowledge\ndata analytics and business intelligence tools\npayment and security technologies\nevaluates problems\ntechnical communication/presentation\nadjusting and driving change\nfocuses on customers\ndemonstrates business acumen\nagile best practices\nbias for action\nbusiness and financial acumen"
        ],
        "cleaned_techs": []
    },
    "b42d68fb5b8dda61": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 73556.16,
        "salary_max": 93138.484,
        "title": "Software Systems Specialist II (Business Intelligence Analyst) \u2013 CMC IT - (Remote in SE Texas Region)",
        "company": "UTMB Health",
        "desc": "Minimum Qualifications: \n  Bachelor's degree or equivalent in related field and two years related experience. \n \n Job Summary: \n  To provide technical skills required to generate, modify and maintain computer operating system software and application system software of moderate complexity. \n \n Preferred Qualifications: \n \n Bachelor\u2019s Degree in Computer Science or related field (equivalent years of experience may be accepted in lieu of degree). \n Verifiable Business Intelligence development expertise. \n \n \n \n  Job Duties: \n  The Business Intelligence Analyst is responsible for providing meaning to the data in UTMB systems and developing methods to leverage that data in UTMB applications. Responsibilities include assisting in the standardizing and cleaning of data, helping to build prediction models, modeling outcomes, and developing metrics for complex data analysis projects that can be multi-disciplinary or interdepartmental. Addresses data requirements for analytic reporting and operating areas with expertise in specific data systems and/or analytical methodologies. \n \n \n \n Assists in the collection, aggregation, and analyzation of data from multiple internal and external sources to drive insights into business performance. Utilizes business intelligence tools to create reports and dashboards, and produces actionable reports that show key performance indicators, identify areas of improvement into current operations, and display root cause analysis of problems. \n Assist in the development, implementation, and validation of new predictive models, conduct QA of models\u2019 outcomes and monitor performance regularly. \n Uses analytics and metrics to improve processes and provide data-driven forecasts of potential costs, risks, and profits of new business initiatives. \n Works with BI expert and internal clients to develop and translate business requirements into project charters, business, and technical requirements, and ultimately produce effective and insightful interactive analytics. \n Assists in the compiling, cleaning, manipulating, and analyzing data related to department projects. Helps to diagnose and respond to data integrity and functional or interactive issues in existing and future dashboards quickly and effectively. \n Helps formulate validation strategies and methods to ensure accurate and reliable data. \n \n \n \n  Knowledge/Skills/Abilities: \n \n  Critical thinking skills to help predict the needs of various business units and leaders. \n Experience in SQL (Oracle and/or SQL Server). \n Ability to write SQL queries and stored procedures. \n Familiarity with ETL tools such as SSIS and/or Informatica. \n Familiarity with business intelligence tools such as Microsoft PowerBI, Qlik or SAP Business Objects to design and develop reporting analytics and visualizations. \n Familiarity with scripting languages such as PowerShell and Python. \n Analytical reasoning and problem-solving skills. \n Ability to function with moderate supervision in a fast-paced environment. \n \n \n \n  Work Schedule: \n   Monday through Friday, 8am to 5pm and as needed. \n \n \n  Salary Range: \n   Actual salary commensurate with experience. \n \n \n \n  Equal Employment Opportunity \n  UTMB Health strives to provide equal opportunity employment without regard to race, color, religion, age, national origin, sex, gender, sexual orientation, gender identity/expression, genetic information, disability, veteran status, or any other basis protected by institutional policy or by federal, state or local laws unless such distinction is required by law. As a VEVRAA Federal Contractor, UTMB Health takes affirmative action to hire and advance women, minorities, protected veterans and individuals with disabilities. \n \n \n \n \n \n  Primary Location  United States-Texas-Conroe\n     \n \n  Work Locations  CMC Conroe Office Park 200 River Pointe Dr, Suit#200 Conroe 77304\n     \n \n  Job  Information Technology\n     \n \n  Organization  UTMB Health\n     \n \n \n       :\n       Regular\n     \n \n  Shift  Standard\n     \n \n  Employee Status  Non-Manager\n     \n \n  Job Level  Day Shift\n     \n \n  Job Posting  Oct 27, 2023, 12:36:43 PM",
        "cleaned_desc": "Minimum Qualifications: \n  Bachelor's degree or equivalent in related field and two years related experience. \n \n Job Summary: \n  To provide technical skills required to generate, modify and maintain computer operating system software and application system software of moderate complexity. \n \n Preferred Qualifications: \n \n Bachelor\u2019s Degree in Computer Science or related field (equivalent years of experience may be accepted in lieu of degree). \n Verifiable Business Intelligence development expertise. \n \n \n \n  Job Duties: \n  The Business Intelligence Analyst is responsible for providing meaning to the data in UTMB systems and developing methods to leverage that data in UTMB applications. Responsibilities include assisting in the standardizing and cleaning of data, helping to build prediction models, modeling outcomes, and developing metrics for complex data analysis projects that can be multi-disciplinary or interdepartmental. Addresses data requirements for analytic reporting and operating areas with expertise in specific data systems and/or analytical methodologies. \n   \n \n Assists in the collection, aggregation, and analyzation of data from multiple internal and external sources to drive insights into business performance. Utilizes business intelligence tools to create reports and dashboards, and produces actionable reports that show key performance indicators, identify areas of improvement into current operations, and display root cause analysis of problems. \n Assist in the development, implementation, and validation of new predictive models, conduct QA of models\u2019 outcomes and monitor performance regularly. \n Uses analytics and metrics to improve processes and provide data-driven forecasts of potential costs, risks, and profits of new business initiatives. \n Works with BI expert and internal clients to develop and translate business requirements into project charters, business, and technical requirements, and ultimately produce effective and insightful interactive analytics. \n Assists in the compiling, cleaning, manipulating, and analyzing data related to department projects. Helps to diagnose and respond to data integrity and functional or interactive issues in existing and future dashboards quickly and effectively. \n Helps formulate validation strategies and methods to ensure accurate and reliable data. \n \n \n \n  Knowledge/Skills/Abilities: \n \n  Critical thinking skills to help predict the needs of various business units and leaders. \n Experience in SQL (Oracle and/or SQL Server). \n Ability to write SQL queries and stored procedures.   Familiarity with ETL tools such as SSIS and/or Informatica. \n Familiarity with business intelligence tools such as Microsoft PowerBI, Qlik or SAP Business Objects to design and develop reporting analytics and visualizations. \n Familiarity with scripting languages such as PowerShell and Python. \n Analytical reasoning and problem-solving skills. \n Ability to function with moderate supervision in a fast-paced environment. \n \n \n \n  Work Schedule: \n   Monday through Friday, 8am to 5pm and as needed. \n \n \n  Salary Range: \n   Actual salary commensurate with experience. \n \n ",
        "techs": [
            "sql",
            "oracle",
            "sql server",
            "ssis",
            "informatica",
            "microsoft powerbi",
            "qlik",
            "sap business objects",
            "powershell",
            "python"
        ],
        "cleaned_techs": [
            "sql",
            "oracle",
            "ssis",
            "informatica",
            "powerbi",
            "qlik",
            "sap business objects",
            "powershell",
            "python"
        ]
    },
    "e20ad70d8927e238": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 97275.0,
        "salary_max": 162125.0,
        "title": "Lead Business Analyst - Point of Sale",
        "company": "Builders FirstSource",
        "desc": "We are Builders FirstSource, America\u2019s largest supplier of building materials, value-added components and building services to the professional market. You\u2019ll feel proud of the work you do here every day to transform the future of home building and help make the dream of home ownership more achievable. At BFS, we believe building a successful career is not solely defined by a degree. Your experience, skills, and passion are just as important, if not more so. As such, we are committed to creating a diverse and inclusive workplace that welcomes candidates from all backgrounds and experience levels. \n \n  We are seeking a talented and experienced Lead Analyst to join our dynamic team and play a pivotal role in the implementation, optimization and enhancement of our Retail and Point of Sale (POS) systems. In this role, you will be responsible for identifying business needs, analyzing processes, and driving improvements to our Retail solutions. Your insights and recommendations will be instrumental in ensuring seamless transactions and enhanced customer experiences. \n \n  ESSENTIAL DUTIES AND RESPONSIBILITIES \n \n \n Business Process Analysis: Analyze existing business processes and workflows related to Retail systems. Identify areas of improvement and optimization to enhance efficiency, accuracy, and customer satisfaction. \n Data Analysis: Evaluate data related to sales, returns, inventory, and customer interactions. Extract meaningful insights and trends from the data to inform decision-making and enhancements to the Retail systems. \n System Evaluation: Assess the current Retail system landscape, including hardware and software components and leverage this knowledge to design and shape the functionality in the new Retail platform. Identify opportunities for process improvement, policy changes and system enhancements to meet evolving business needs. \n Solution Design: Collaborate with IT and development teams to design and propose solutions that address identified business needs. Create detailed specifications and functional requirements for Retail systems enhancements. \n User Acceptance Testing: Plan and conduct user acceptance testing (UAT) to ensure that Retail systems system changes meet business requirements and user expectations. \n Documentation: Maintain comprehensive and up-to-date documentation of Retail systems configurations, workflows, and user guides. Ensure that all stakeholders have access to relevant documentation. \n Training and Support: Assist in developing training materials and provide training to end-users, ensuring they can effectively use Retail systems. Offer ongoing support to resolve issues and address user concerns. \n Vendor Management: Collaborate with Retail system vendors to evaluate and implement new features, updates, or troubleshoot issues as needed. \n Compliance and Security: Ensure that Retail systems comply with relevant industry standards, data protection regulations, and security best practices. \n  MINIMUM REQUIREMENTS \n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. \n \n \n A minimum of 7 years of experience in gathering and analyzing business and technical requirements and demonstrated proficiency in translating business needs into technical solutions. \n A minimum of 5 years of experience working with Retail systems, including POS hardware and software components, with a deep understanding of Retail functionality and features. \n Proficiency in data analysis tools and techniques, with a minimum of 3 years of experience in extracting meaningful insights from sales and transaction data to inform business decisions and optimize POS systems. \n A solid understanding of retail operations, including inventory management, sales processes, and customer interactions, with a minimum of 3 years of experience in retail industry practices. \n Experience working within agile or similar project management methodologies, with a minimum of 2 years of experience in agile project environments, including user stories, sprint planning, and iterative development. \n Familiarity with payment processing technologies and payment security standards, such as PCI DSS, with a minimum of 2 years of experience in ensuring secure and compliant payment transactions at the POS. \n Bachelor's degree from an accredited college/university or equivalent relevant work experience. \n  COMPETENCIES \n \n \n Point of Sale (POS) Systems Proficiency: A comprehensive understanding of various POS systems, both hardware and software components, is essential. This includes knowledge of different POS software platforms, payment processing, barcode scanning, receipt printing, and customer display systems. \n Retail Software and ERP Knowledge: Familiarity with retail-specific software solutions and enterprise resource planning (ERP) systems is vital. This competency involves expertise in software used for merchandising, promotional pricing, inventory management, order fulfillment, supply chain management, and sales analysis, among others. \n Data Analytics and Business Intelligence Tools: Proficiency in data analytics and business intelligence tools is essential for extracting actionable insights from retail and POS data. This includes knowledge of data warehousing, data visualization tools, and the ability to create meaningful reports and dashboards for decision-makers. \n Payment and Security Technologies: An understanding of payment technologies, security protocols, and compliance standards in the retail environment is critical. This includes knowledge of PCI DSS compliance, encryption methods, and emerging payment technologies like mobile wallets and contactless payments. \n Evaluates Problems: Evaluates and analyzes different types of information objectively to identify appropriate solutions; writes fluently, establishing the key facts clearly and interprets numerical data effectively. \n Technical Communication/ Presentation: Communicates with clarity and precision, presenting complex information in a concise format that is audience appropriate. \n Adjusting and Driving Change: Takes a positive approach to tackling work and embraces change; invites feedback relating to performance and deals constructively with criticism. Identifies the need for and drives change when required to achieve objectives. \n Focuses on Customers: Understands and anticipates customer needs and takes action to provide high-quality products and services to exceed expectations. \n Demonstrates Business Acumen: Demonstrates working knowledge of market, economic, legal, and regulatory environments and how they impact the business. \n Agile Best Practices: Understands how agility is leveraged in IT ways of working. Adopts agile best practices as appropriate throughout the assigned work lifecycle. Responds to feedback quickly based on comments of internal and external customers and needs of the market. \n Bias for Action: Takes initiative and identifies what needs to be done and acts without waiting to be asked. Executes work in a timely manner. Suggests improvements to current ways of working. \n  BFS COMPETENCIES \n \n \n Business and Financial Acumen \n Demonstrates depth of understanding for the P&L and financial analysis \n Teaches business and financial acumen to others. \n Understands KPIs and how BFS makes money. \n Knows the different business segments and how they relate to one another. \n Understands customer sales and engagement. \n Demonstrates functional and/or technical expertise. \n Understands complex issues and demonstrates problem solving skills. \n Understands how to maximize business results regardless of industry cycle. \n Results Driven \n Holds self and others accountable. \n Communicates and sets clear goals with plans to deliver. \n Manages competing priorities effectively. \n Demonstrates appropriate urgency. \n Drives to exceed expectations in alignment with our BFS SPICE values. \n Embraces and follows best practices. \n Demonstrates self-starter, can-do attitude. \n Strategic Thinking and Decision Making \n Leverages resources and teams around them to solve problems and create mutually beneficial outcomes. \n Demonstrates willingness and courage to make tough decisions in a timely manner. \n Balances short-and-long term priorities \n Demonstrates proactive versus reactive thinking. \n Asks questions to identify root cause and analyze situations more accurately. \n Servant Leadership \n Demonstrates humility by putting others first. \n Builds trust-based relationships. \n Leads by example with kindness and respect. \n Collaborates well across all areas of the business. \n Advocates for others \n Actively listens to understand the meaning and intent of what the other person is communicating. \n Demonstrates authenticity and encourages others to do the same. \n Emotional Intelligence \n Demonstrates situational awareness \u2013 knows when and how to adjust leadership style in different situations. \n Demonstrates self-awareness \u2013 understands strengths and weaknesses. \n Demonstrates empathy \u2013 puts themselves in other\u2019s shoes. \n Assumes positive intent. \n Develops and Leads Others \n Drives alignment through clear communication of vision, goals, and expectations. \n Invests time on a regular basis in performance feedback and developmental conversations. \n Fosters a respectful and inclusive environment. \n Empowers, motivates, and inspires others. \n Coaches and mentor others for their development. \n Guides and persuades others to deliver positive outcomes. \n Growth Mindset \n Demonstrates a growth mindset; takes appropriate risks, fails fast and forward, learns from mistakes. \n Perseveres and champions growth, even in the face of resistance, ambiguity, or possible failure. \n Thinks like an owner with an entrepreneurial spirit. \n Demonstrates and encourages intellectual curiosity. \n Continuous learner; seeks opportunities and knowledge for personal and professional growth. \n Sees possibilities over problems \u2013 actively seeks solutions. \n Innovation \n Encourages out-of-the box thinking to create new ways of doing things. \n Continuously seeks to improve and simplify pain points in the business. \n Anticipates, embraces, and leads change. \n Develops and executes breakthrough strategies. \n Integrity \n Does the right thing even under challenging circumstances? \n Communicates with honesty. \n Consistently treats others fairly and equitably. \n Demonstrates reliability and does what they say they will do. \n Conducts tough conversations and delivers difficult messages with kindness and respect. \n  WORK ENVIRONMENT / PHYSICAL ACTIVITY \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. \n \n \n Subject to both typical office environment and outside locations with temperature and weather variations. \n Must be able to lift and carry up to 25 pounds. \n 25% travel may be required. \n  In addition to the base wage listed, this position is also eligible to earn an annual bonus subject to changes in plan design and documents and in accordance with applicable law. Eligibility and the amount of the bonus varies based on overall company success, thresholds met and other terms and conditions of the Company\u2019s active bonus policy for the respective year. \n \n  Full-Time Team Members are eligible for company benefits, including \u2022 Three Medical plan options \u2022 Dental & Vision \u2022 Critical Care \u2022 Accident & Hospital insurance \n \n \n Flexible Spending Accounts for Health & Dependent Care \u2022 Health Savings Account \u2022 401(k) with company match \u2022 Vacation & Sick Time \u2022 Paid company holidays \n Company Paid Life & AD&D \u2022 Supplemental Life \u2022 Short & Long Term Disability \u2022 Bereavement \u2022 Paid Parental Leave \u2022 Team Member Assistance Program \n  All benefits are subject to change pursuant to state and federal guidelines. \n \n  Builders FirstSource is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status or status as an individual with a disability. \n \n  In compliance with the ADA Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position with Builders FirstSource, please call (214) 765-3990 or email: ADA.Accommodation@bldr.com. Please do not send resumes to this email address - it is intended only to be used to request an accommodation in submitting an application for a job opening. \n \n  https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm \n \n  EEO THE LAW - English/Spanish \n EEO IS THE LAW - SUPPLEMENT - English/Spanish \n Pay Transparency Provision - English/Spanish",
        "cleaned_desc": "We are Builders FirstSource, America\u2019s largest supplier of building materials, value-added components and building services to the professional market. You\u2019ll feel proud of the work you do here every day to transform the future of home building and help make the dream of home ownership more achievable. At BFS, we believe building a successful career is not solely defined by a degree. Your experience, skills, and passion are just as important, if not more so. As such, we are committed to creating a diverse and inclusive workplace that welcomes candidates from all backgrounds and experience levels. \n \n  We are seeking a talented and experienced Lead Analyst to join our dynamic team and play a pivotal role in the implementation, optimization and enhancement of our Retail and Point of Sale (POS) systems. In this role, you will be responsible for identifying business needs, analyzing processes, and driving improvements to our Retail solutions. Your insights and recommendations will be instrumental in ensuring seamless transactions and enhanced customer experiences. \n \n  ESSENTIAL DUTIES AND RESPONSIBILITIES \n \n \n Business Process Analysis: Analyze existing business processes and workflows related to Retail systems. Identify areas of improvement and optimization to enhance efficiency, accuracy, and customer satisfaction. \n Data Analysis: Evaluate data related to sales, returns, inventory, and customer interactions. Extract meaningful insights and trends from the data to inform decision-making and enhancements to the Retail systems. \n System Evaluation: Assess the current Retail system landscape, including hardware and software components and leverage this knowledge to design and shape the functionality in the new Retail platform. Identify opportunities for process improvement, policy changes and system enhancements to meet evolving business needs. \n Solution Design: Collaborate with IT and development teams to design and propose solutions that address identified business needs. Create detailed specifications and functional requirements for Retail systems enhancements. \n User Acceptance Testing: Plan and conduct user acceptance testing (UAT) to ensure that Retail systems system changes meet business requirements and user expectations. \n Documentation: Maintain comprehensive and up-to-date documentation of Retail systems configurations, workflows, and user guides. Ensure that all stakeholders have access to relevant documentation. \n Training and Support: Assist in developing training materials and provide training to end-users, ensuring they can effectively use Retail systems. Offer ongoing support to resolve issues and address user concerns. \n Vendor Management: Collaborate with Retail system vendors to evaluate and implement new features, updates, or troubleshoot issues as needed. \n Compliance and Security: Ensure that Retail systems comply with relevant industry standards, data protection regulations, and security best practices. \n  MINIMUM REQUIREMENTS \n To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. \n \n \n A minimum of 7 years of experience in gathering and analyzing business and technical requirements and demonstrated proficiency in translating business needs into technical solutions. \n A minimum of 5 years of experience working with Retail systems, including POS hardware and software components, with a deep understanding of Retail functionality and features. \n Proficiency in data analysis tools and techniques, with a minimum of 3 years of experience in extracting meaningful insights from sales and transaction data to inform business decisions and optimize POS systems. \n A solid understanding of retail operations, including inventory management, sales processes, and customer interactions, with a minimum of 3 years of experience in retail industry practices. \n Experience working within agile or similar project management methodologies, with a minimum of 2 years of experience in agile project environments, including user stories, sprint planning, and iterative development.   Familiarity with payment processing technologies and payment security standards, such as PCI DSS, with a minimum of 2 years of experience in ensuring secure and compliant payment transactions at the POS. \n Bachelor's degree from an accredited college/university or equivalent relevant work experience. \n  COMPETENCIES \n \n \n Point of Sale (POS) Systems Proficiency: A comprehensive understanding of various POS systems, both hardware and software components, is essential. This includes knowledge of different POS software platforms, payment processing, barcode scanning, receipt printing, and customer display systems. \n Retail Software and ERP Knowledge: Familiarity with retail-specific software solutions and enterprise resource planning (ERP) systems is vital. This competency involves expertise in software used for merchandising, promotional pricing, inventory management, order fulfillment, supply chain management, and sales analysis, among others. \n Data Analytics and Business Intelligence Tools: Proficiency in data analytics and business intelligence tools is essential for extracting actionable insights from retail and POS data. This includes knowledge of data warehousing, data visualization tools, and the ability to create meaningful reports and dashboards for decision-makers. \n Payment and Security Technologies: An understanding of payment technologies, security protocols, and compliance standards in the retail environment is critical. This includes knowledge of PCI DSS compliance, encryption methods, and emerging payment technologies like mobile wallets and contactless payments. \n Evaluates Problems: Evaluates and analyzes different types of information objectively to identify appropriate solutions; writes fluently, establishing the key facts clearly and interprets numerical data effectively. \n Technical Communication/ Presentation: Communicates with clarity and precision, presenting complex information in a concise format that is audience appropriate. \n Adjusting and Driving Change: Takes a positive approach to tackling work and embraces change; invites feedback relating to performance and deals constructively with criticism. Identifies the need for and drives change when required to achieve objectives. \n Focuses on Customers: Understands and anticipates customer needs and takes action to provide high-quality products and services to exceed expectations. \n Demonstrates Business Acumen: Demonstrates working knowledge of market, economic, legal, and regulatory environments and how they impact the business. \n Agile Best Practices: Understands how agility is leveraged in IT ways of working. Adopts agile best practices as appropriate throughout the assigned work lifecycle. Responds to feedback quickly based on comments of internal and external customers and needs of the market. \n Bias for Action: Takes initiative and identifies what needs to be done and acts without waiting to be asked. Executes work in a timely manner. Suggests improvements to current ways of working. \n  BFS COMPETENCIES \n \n \n Business and Financial Acumen \n Demonstrates depth of understanding for the P&L and financial analysis \n Teaches business and financial acumen to others. \n Understands KPIs and how BFS makes money. \n Knows the different business segments and how they relate to one another. \n Understands customer sales and engagement. ",
        "techs": [
            "builders firstsource",
            "retail systems",
            "point of sale (pos) systems",
            "data analysis tools",
            "it",
            "development teams",
            "user acceptance testing",
            "documentation",
            "training materials",
            "end-users",
            "retail system vendors",
            "compliance",
            "security",
            "business requirements",
            "technical requirements",
            "retail functionality",
            "data analysis tools and techniques",
            "retail operations",
            "agile project management",
            "payment processing technologies",
            "payment security standards",
            "pci dss",
            "payment transactions",
            "pos hardware and software components",
            "payment technologies",
            "encryption methods",
            "mobile wallets",
            "contactless payments",
            "pos systems",
            "retail software",
            "enterprise resource planning (erp) systems",
            "data analytics",
            "business intelligence tools",
            "data warehousing",
            "data visualization tools",
            "payment technologies",
            "security protocols",
            "compliance standards",
            "pci dss",
            "agile best practices"
        ],
        "cleaned_techs": [
            "builders firstsource",
            "retail systems",
            "point of sale (pos) systems",
            "data analysis tools",
            "it",
            "development teams",
            "user acceptance testing",
            "training materials",
            "end-users",
            "retail system vendors",
            "compliance",
            "business requirements",
            "technical requirements",
            "retail functionality",
            "data analysis tools and techniques",
            "retail operations",
            "agile project management",
            "payment processing technologies",
            "pci dss",
            "payment transactions",
            "pos hardware and software components",
            "payment technologies",
            "encryption methods",
            "mobile wallets",
            "contactless payments",
            "pos systems",
            "retail software",
            "enterprise resource planning (erp) systems",
            "data analytics",
            "business intelligence tools",
            "data warehousing",
            "data visualization tools",
            "compliance standards"
        ]
    },
    "670a96556999916e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 80000.0,
        "salary_max": 82000.0,
        "title": "Business Technical Analyst",
        "company": "Ascendion",
        "desc": "Description \n About Ascendion \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n  Ascendion | Engineering to elevate life \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: \n \n Build the coolest tech for world\u2019s leading brands \n Solve complex problems \u2013 and learn new skill \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n \n Experience a community of change makers! \n  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n  About the Role: \n  Job Title: Business Technical Analyst (BTA) \n  Day-to-Day: \n \n Ascendion is looking for a BTA Developer to support a large healthcare organization in. \n This group will be working with risk adjustment team to help reconcile healthcare data sets. \n They are building out dashboards and reports and visualition in powerBI related to medicare and medicaid data sets. \n \n Must Haves: \n \n 4 + years of experience with SAS and SQL \n 4 + years of experience of with Power BI for building out complex dashboards \n Strong experience working with large database sets and dealing with the database management \n Healthcare experience with Medicaid and Medicare specifically \n \n Location: Remote \n  Salary Range:  The salary for this position is between $ 80,000 \u2013 $82,000 annually. Factors which may affect pay within this range may include geography/market, skill, education, experience, and other qualifications of the successful candidate. \n  Benefits:  The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day accrued each calendar year. The \n  Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day of paid vacation time] [6 paid holiday and 1 floating holiday per calendar year] [Ascendion Learning Management System] \n  Want to change the world? Let us know. \n  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n Preferred Skills: \n \n SAS \n  SQL \n  Power BI \n \n Job details \n \n \n Job ID \n \n \n   328978\n   \n \n \n \n Job Requirements \n \n \n   Business Technical Analyst\n   \n \n \n \n \n Location \n \n \n   Tampa, Florida, US\n   \n \n \n \n \n Recruiter \n \n \n   Poorvi\n   \n \n \n \n Email \n \n \n   poorvi.ratre@ascendion.com",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "3d51a30701fef3e0": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 95000.0,
        "title": "Board Certified Behavior Analyst (BCBA)",
        "company": "Supportive Care ABA",
        "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "085ef19429b42c6e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 95000.0,
        "title": "Board Certified Behavior Analyst (BCBA)",
        "company": "Supportive Care ABA",
        "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "53fc94403eaec351": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 95000.0,
        "title": "Board Certified Behavior Analyst (BCBA)",
        "company": "Supportive Care ABA",
        "desc": "Responsibilities: \n \n Conduct assessments to determine the needs and goals of individuals with developmental disabilities, specifically children with autism. \n Develop and implement behavior intervention plans based on individual needs and goals. \n Provide direct behavioral therapy to clients using evidence-based practices. \n Collect and analyze data to monitor progress and make necessary adjustments to treatment plans. \n Collaborate with families, caregivers on implementing behavior strategies at home. \n \n Skills: \n \n Board certified Behavior Analyst (BCBA) certification required. \n Experience working with children with special needs, particularly those with autism or developmental disabilities. \n Knowledge of applied behavior analysis (ABA) principles and techniques. \n Strong data collection and analysis skills. \n Excellent communication and interpersonal skills to effectively collaborate with clients, families, and other professionals. \n Ability to develop and implement behavior intervention plans tailored to individuals needs. \n \n Job Types: Part-time, Full-time \n Pay: $65,000.00 - $95,000.00 per year \n Benefits: \n \n Flexible schedule \n Paid time off \n Parental leave \n \n Compensation package: \n \n Signing bonus \n \n Medical specialties: \n \n Pediatrics \n \n Schedule: \n \n 10 hour shift \n 12 hour shift \n 4 hour shift \n 8 hour shift \n After school \n Choose your own hours \n Day shift \n Evening shift \n Monday to Friday \n Night shift \n No nights \n No weekends \n Overnight shift \n Weekends as needed \n Weekends only \n \n License/Certification: \n \n BCBA certification (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "3c4fc943ff05ea4a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Epic Business Intelligence Reporting and Analytics Developer/Analyst",
        "company": "Golden Five LLC",
        "desc": "Epic Business Intelligence Reporting and Analytics Developer/Analyst \n \n \n Experience :-  5+ Years \n \n \n Vacancy :-  1 \n \n \n Location :-  Santa Clara California, USA \n \n \n Salary :-  Negotiable  \n \n \n Job Type :-  Remote  \n \n \n \n \n This consultant will primarily convert existing Finance SAP Crystal reports into stored procedures and SSIS packages. The ideal candidate would have a working knowledge of SSIS development, SQL experience writing stored procedures (Microsoft), and be able to extract SQL logic from existing SAP Crystal reports.  \n Knowledge of Epic Professional and Hospital Billing are required. \n The role requires consultant communication skills \u2013 in particular, independently participating in project meetings and project decisions to ensure that deliverables support Analytics & projectgoals and deadlines. It further requires the ability to coalesce related requests and offer solutions that satisfy multiple requirements, and Software Development Life Cycle discipline: gathering & documenting and confirming requirements, designing solutions, obtaining SME signoff, coding, testing/validation, UAT, & documentation. \n This role also requires collaborative cross-functional team skills \u2013 in particular, working on collaborative solutions with operational clinical leaders, application build analysts, Epic boost and TS resources, as well as other analytics business intelligence developers and peer testers. \n \n \n Typical Tasks: \n \n Extract SQL query / logic from existing finance SAP Crystal reports. \n Evaluate/consolidate multiple instances of similar reports into a single output. \n Create stored procedures on SQL server. \n Create SSIS packages to call stored procedures while passing parameters. \n Optimize any existing SQL queries (knowledge of Clarity HB and PB required). \n Produce comprehensive documentation of developed processes and workflows. \n \n \n   \n Required Skills & Abilities: \n \n Minimum 3 years of experience with Epic reporting in a hospital / health system setting. \n 5+ years of SQL query and stored procedure development experience. \n Working knowledge of Epic Clarity HB & PB reporting. \n 3+ years of SSIS development experience. \n 2+ years of SAP Crystal report development. \n Must be a self-starter comfortable working under general direction. \n \n \n   \n Desired Qualifications: \n \n Any Epic certifications / experience reporting against Epic data. \n Professional (PB) and Hospital Billing (HB) reporting experience. \n Government, public or non-profit sector experience. \n \n \n   \n Certifications: \n Required: Epic Clarity, Caboodle Financial or Clinical Data Model (or legacy equivalents) \n \n \n On-Site Requirements: None. 100% remote. Santa Clara California, USA. \n \n Email Us:  jobs@goldenfive.net   .Only qualified applicants will be contacted.",
        "cleaned_desc": " Salary :-  Negotiable  \n \n \n Job Type :-  Remote  \n \n \n \n \n This consultant will primarily convert existing Finance SAP Crystal reports into stored procedures and SSIS packages. The ideal candidate would have a working knowledge of SSIS development, SQL experience writing stored procedures (Microsoft), and be able to extract SQL logic from existing SAP Crystal reports.  \n Knowledge of Epic Professional and Hospital Billing are required. \n The role requires consultant communication skills \u2013 in particular, independently participating in project meetings and project decisions to ensure that deliverables support Analytics & projectgoals and deadlines. It further requires the ability to coalesce related requests and offer solutions that satisfy multiple requirements, and Software Development Life Cycle discipline: gathering & documenting and confirming requirements, designing solutions, obtaining SME signoff, coding, testing/validation, UAT, & documentation. \n This role also requires collaborative cross-functional team skills \u2013 in particular, working on collaborative solutions with operational clinical leaders, application build analysts, Epic boost and TS resources, as well as other analytics business intelligence developers and peer testers. ",
        "techs": [
            "sap crystal reports",
            "stored procedures",
            "ssis packages",
            "ssis development",
            "sql",
            "microsoft",
            "epic professional",
            "hospital billing",
            "software development life cycle",
            "uat",
            "documentation",
            "collaborative cross-functional team skills"
        ],
        "cleaned_techs": [
            "sap crystal reports",
            "stored procedures",
            "ssis packages",
            "ssis development",
            "sql",
            "microsoft",
            "epic professional",
            "hospital billing",
            "software development life cycle",
            "uat"
        ]
    },
    "508a851bc9ba4aff": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81249.34,
        "salary_max": 102879.78,
        "title": "Navy Database Analyst",
        "company": "Serco North America",
        "desc": "Position Description : \n  \n   If you like working with enterprise applications supporting U.S. Navy\u2019s Advanced Manpower Analysis Division \u2013 Serco has a great opportunity for you! This data analyst will be on a dynamic team analyzing Navy manpower requirements and forecasting resource distribution using multiple end strength planning models. Bring your experience and collaborative skills to make an impact toward our military defense and safety of our sailors. Serco supports the U.S. Navy as a prime for their technical contract that supports manpower and personnel readiness analysis. Our team monitors and updates a portfolio of models and runs reports and analyzes data from the models to ensure our Navy has the right people in the right jobs at the right time. You will be part of a 6 \u2013 8 member team that works closely with the customer to ensure that critical manpower tracking applications operate correctly, and will update data, assist users, run high-level queries and analyze data from these applications.\n  \n \n \n  This position is contingent upon your ability to maintain and transfer your Secret Level Clearance post-employment. \n \n \n \n  In this role, you will: \n \n \n  Provide analytical support and quantitative analysis of modelled data. \n  Package analysis results for senior leadership using MS Office applications. \n  Act as a subject matter expert for selected Navy manpower models; assist users in understanding the capabilities of the models; and update model data, methodology, and parameters as required to support program/policy changes or other potential changes.  \n Coordinate with system administrators to test models and underlying data for any issues resulting from software maintenance and system-wide updates affecting the underlying model codebase. \n  Update and maintain selected Navy manpower models and analysis tools including populating data fields with updated information and ensuring the user interface is functional and compatible with the latest system-wide upgrades to associated and supporting systems. \n  Update and maintain manpower model technical documentation. \n  Qualifications: \n  \n  To be successful in this role, you will have: \n \n \n  An active DoD Secret clearance. \n  A Bachelor\u2019s degree in mathematics, statistics, business, engineering, social sciences, physical/applied sciences, business administration, accounting, finance, economics, information technology or similar. \n  4+ years of working experience in Data Analysis, Statistical Analysis, Coding, or Complex Problem Solving. \n  Former Navy or government servcie experience. \n  Excellent MS Office Skills (Excel, Word, PowerPoint). \n  Great communication skills and the ability to coordinate efficiently with a remote team. \n  Must be able to travel at least 10% of the time. \n \n \n   \n Desired Attributes: \n \n \n \n \n     Python, R-Programming, R-Studio, Oracle, BI, Tableau Prep, Tableau Server, Tableau Desktop, SQL.\n    \n \n \n     IT, programming, business analytical work, business requirements, Navy manpower requirements, military personnel management.\n    \n \n \n     Navy HQ staff, MyNavy HR components (OPNAV N1, Navy Personnel Command/BUPERS, Navy Recruiting Command, Navy Education and Training Command, Navy Manpower Analysis Center, other Navy or other Services manpower/personnel organizations.\n    \n \n \n \n  If you are interested in supporting and working with our military and sailors and a passionate Serco team- then submit your application now for immediate consideration. It only takes a few minutes and could change your career!\n  \n \n  Company Overview : \n  \n   Serco Inc. (Serco) is the Americas division of Serco Group, plc. In North America, Serco\u2019s 9,000+ employees strive to make an impact every day across 100+ sites in the areas of Defense, Citizen Services, and Transportation. We help our clients deliver vital services more efficiently while increasing the satisfaction of their end customers. Serco serves every branch of the U.S. military, numerous U.S. Federal civilian agencies, the Intelligence Community, the Canadian government, state, provincial and local governments, and commercial clients. While your place may look a little different depending on your role, we know you will find yours here. Wherever you work and whatever you do, we invite you to discover your place in our world. Serco is a place you can count on and where you can make an impact because every contribution matters.\n  \n \n \n  To review Serco benefits please visit: https://www.serco.com/na/careers/benefits-of-choosing-serco. If you require an accommodation with the application process please email: careers@serco-na.com or call the HR Service Desk at 800-628-6458, option 1. Please note, due to EEOC/OFCCP compliance, Serco is unable to accept resumes by email.\n  \n \n \n  Candidates may be asked to present proof of identify during the selection process. If requested, this will require presentation of a government-issued I.D. (with photo) with name and address that match the information entered on the application. Serco will not take possession of or retain/store the information provided as proof of identity. For more information on how Serco uses your information, please see our Applicant Privacy Policy and Notice.\n  \n \n \n  Serco does not accept unsolicited resumes through or from search firms or staffing agencies without being a contracted approved vendor. All unsolicited resumes will be considered the property of Serco and will not be obligated to pay a placement or contract fee. If you are interested in becoming an approved vendor at Serco, please email Agencies@serco-na.com.\n  \n \n \n  Serco is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.",
        "cleaned_desc": "  Package analysis results for senior leadership using MS Office applications. \n  Act as a subject matter expert for selected Navy manpower models; assist users in understanding the capabilities of the models; and update model data, methodology, and parameters as required to support program/policy changes or other potential changes.  \n Coordinate with system administrators to test models and underlying data for any issues resulting from software maintenance and system-wide updates affecting the underlying model codebase. \n  Update and maintain selected Navy manpower models and analysis tools including populating data fields with updated information and ensuring the user interface is functional and compatible with the latest system-wide upgrades to associated and supporting systems. \n  Update and maintain manpower model technical documentation. \n  Qualifications: \n  \n  To be successful in this role, you will have: \n \n \n  An active DoD Secret clearance. \n  A Bachelor\u2019s degree in mathematics, statistics, business, engineering, social sciences, physical/applied sciences, business administration, accounting, finance, economics, information technology or similar. \n  4+ years of working experience in Data Analysis, Statistical Analysis, Coding, or Complex Problem Solving. \n  Former Navy or government servcie experience.    Excellent MS Office Skills (Excel, Word, PowerPoint). \n  Great communication skills and the ability to coordinate efficiently with a remote team. \n  Must be able to travel at least 10% of the time. \n \n \n   \n Desired Attributes: \n \n \n \n \n     Python, R-Programming, R-Studio, Oracle, BI, Tableau Prep, Tableau Server, Tableau Desktop, SQL.\n    \n ",
        "techs": [
            "python",
            "r-programming",
            "r-studio",
            "oracle",
            "bi",
            "tableau prep",
            "tableau server",
            "tableau desktop",
            "sql"
        ],
        "cleaned_techs": [
            "python",
            "r-programming",
            "r-studio",
            "oracle",
            "bi",
            "tableau prep",
            "tableau server",
            "tableau desktop",
            "sql"
        ]
    },
    "fbc290e104a5e7b9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Epic Business Intelligence Reporting and Analytics Developer/Analyst",
        "company": "Golden Five LLC",
        "desc": "Epic Business Intelligence Reporting and Analytics Developer/Analyst \n \n \n Experience :-  5+ Years \n \n \n Vacancy :-  1 \n \n \n Location :-  Santa Clara, California, USA \n \n \n Salary :-  Negotiable  \n \n \n Job Type :-  Remote  \n \n \n \n \n This consultant will provide end-to-end delivery of reporting and analytics solutions in an Epic Clarity cross-functional Clinical/Financial domain. Work focuses on developing Global Payment \n Program (GPP) population, metrics, and quality performance measures, ensuring compliance with deliverables by performing quality data audits and analysis. Works with and is a liaison between the customers, application teams and appropriate IT personnel, when necessary, on a regular basis to align technology functionality to operational processes. Applies knowledge of clinical workflows to understand and interpret regulatory specifications, and additional duties as assigned. \n This consultant\u2019s primarily deliverables will be supporting the development of the GPP population SQL logic, GPP quality measure architecture, and optimizing existing GPP workflow to leverage stored procedures and SSIS to execute the queries. \n The role requires consultant communication skills \u2013 in particular, independently participating in project meetings and project decisions to ensure that deliverables support Analytics & project goals and deadlines. It further requires the ability to coalesce related requests and offer solutions that satisfy multiple requirements, and Software Development Life Cycle discipline: gathering & documenting and confirming requirements, designing solutions, obtaining SME signoff, coding, testing/validation, UAT, & documentation. \n This role also requires collaborative cross-functional team skills \u2013 in particular, working on collaborative solutions with operational clinical leaders, application build analysts, Epic boost \n and TS resources, as well as other analytics business intelligence developers and peer testers. \n \n \n Typical Tasks: \n \n Review GPP program\u2019s metric specifications for logic and data set changes and translate them into technical requirements. \n Develop new quality measure code (leverage existing QIP measure code) or update existing metric code based on new or revised metric definitions. \n Work closely with business SMEs to interpret specifications and requirements, quickly iterating on changes. \n Help design the GPP architecture using SQL Server tables, stored procedures and SSIS packages. \n Analyze result sets and present to operational leadership in easy to read and actionable formats. \n \n Required Skills & Abilities: \n \n \n \n Exceptional SQL coding skills in Epic Clarity, and familiarity with all financial tables, views and functions. \n Metric development experience with pay-for-performance programs like QIP, GPP or HEDIS. \n Experience with developing complex SQL queries, stored procedures and SSIS packages. \n Strong ability to work directly with operational clinical leaders, project office, clinic staff and other stakeholders. \n Epic PB/HB reporting experience. \n \n Certifications: \n Required: Epic Clarity Data Model: Financial \n \n \n On-Site Requirements:  None. 100% remote. Santa Clara, California, USA \n \n Email Us:  jobs@goldenfive.net   .Only qualified applicants will be contacted.",
        "cleaned_desc": " This consultant will provide end-to-end delivery of reporting and analytics solutions in an Epic Clarity cross-functional Clinical/Financial domain. Work focuses on developing Global Payment \n Program (GPP) population, metrics, and quality performance measures, ensuring compliance with deliverables by performing quality data audits and analysis. Works with and is a liaison between the customers, application teams and appropriate IT personnel, when necessary, on a regular basis to align technology functionality to operational processes. Applies knowledge of clinical workflows to understand and interpret regulatory specifications, and additional duties as assigned. \n This consultant\u2019s primarily deliverables will be supporting the development of the GPP population SQL logic, GPP quality measure architecture, and optimizing existing GPP workflow to leverage stored procedures and SSIS to execute the queries. \n The role requires consultant communication skills \u2013 in particular, independently participating in project meetings and project decisions to ensure that deliverables support Analytics & project goals and deadlines. It further requires the ability to coalesce related requests and offer solutions that satisfy multiple requirements, and Software Development Life Cycle discipline: gathering & documenting and confirming requirements, designing solutions, obtaining SME signoff, coding, testing/validation, UAT, & documentation. \n This role also requires collaborative cross-functional team skills \u2013 in particular, working on collaborative solutions with operational clinical leaders, application build analysts, Epic boost \n and TS resources, as well as other analytics business intelligence developers and peer testers. \n \n \n Typical Tasks: \n   Exceptional SQL coding skills in Epic Clarity, and familiarity with all financial tables, views and functions. \n Metric development experience with pay-for-performance programs like QIP, GPP or HEDIS. \n Experience with developing complex SQL queries, stored procedures and SSIS packages. \n Strong ability to work directly with operational clinical leaders, project office, clinic staff and other stakeholders. \n Epic PB/HB reporting experience. \n \n Certifications: \n Required: Epic Clarity Data Model: Financial \n \n ",
        "techs": [
            "epic clarity",
            "sql",
            "ssis",
            "epic pb/hb"
        ],
        "cleaned_techs": [
            "epic clarity",
            "sql",
            "ssis",
            "epic pb/hb"
        ]
    },
    "61564e6f6385f8df": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 104097.0,
        "salary_max": 135000.0,
        "title": "Principal Business Analyst",
        "company": "Universal Technical Institute",
        "desc": "Overview: \n  \n   The Principal Business Analyst conducts detailed analysis of systems, processes, and data, and acts as a liaison between the business owners and Information Technology teams. The role helps build and implement processes, and documents requirements, associated with critical, cross functional company initiatives. This position supports other members of the Business Analyst and Technology Solution teams by providing training, coaching, and mentoring. Business Analyst positions may report to this position, depending on the quantity of Business Analyst positions and if the individual is on a management career track. The Principal Business Analyst is considered Expert in all areas of Business Analysis practice, having authoritative and deep tacit understanding of all areas of practice.\n   Responsibilities: \n  \n Demonstrates an informed knowledge of the business to resolve problems and suggest/deliver technology solutions to maximize Company efficiencies, compliance, and user experiences for both students and staff. \n  Partners with business functional areas and IT teams to translate high-level business requirements into technology solutions to drive growth, scalability, efficiency and innovation in the organization. \n  Collaborates with all IT teams to ensure accurate design and implementation of business/system requirements \n  Collaborates with IT Directors, Technology Solution Managers, and Program/Project Managers to ensure overall success and team objectives are met \n  Captures customer requirements through iterative structured interviews with subject matter experts \n  Manages requirements from scope through design, development, and testing \n  Develops requirements, user stories and acceptance criteria from customer interviews, process flows, and CRC models \n  Ensures quality and accuracy of each requirements specification \n  Works with Quality Assurance Analysts to ensure comprehensive requirements based testing is achieved \n  Provides teaching, coaching and mentoring to IT staff and business partners and provides development and coaching to Business Analysts \n  Establish/maintain a high performance team of professional, motivated and engaged staff utilizing effective training, performance management and career-development activities while leading them to achieve established business results and performance metrics \n  Recognizes and rewards employee contributions and achievements \n  Other duties as assigned \n  Qualifications: \n  \n   Education / Experience\n  \n \n  Bachelor\u2019s or Master\u2019s degree in a business or IT discipline, or equivalent work experience with demonstrated ability required \n  Minimum ten (10+) years of relevant IT work experienceand growth \n  Minimum five (5+) years\u2019 experience as Business Analyst required \n  Certified Business Analysis Professional (CBAP) certification preferred \n  Mastery of technical and business knowledge in multiple disciplines required \n  Varied experience over different companies, projects, and / or applications required \n  Demonstrated experience gathering use cases and user stories through interviews, observations, and interpretation of policies and procedures required \n  Significant experience turning use cases into functional requirements or acceptance criteria required \n  Specific industry related experience a plus. \n \n \n   Skills\n  \n \n  Deep expertise in the business unit(s) they support. \n  Understanding of IT\u2019s systems and capabilities. \n  Participate with IT management and senior staff positions in the development and improvement of policies and procedures \n  Analyzes business partner\u2019s operations to understand their strengths and weaknesses to determine opportunities to automate processes and functions \n  Leads the business process redesign and documentation as needed for new technology \n  Works well in a matrixed environment as part of both Business Analysis and Technology Solutions teams \n  Complies with UTI\u2019s software development lifecycle practices and standards \n  Excellent verbal and written communication skills and high level of organization, planning, prioritizing in a fast paced environment where deadlines are essential \n  Controls, leads, and coordinates with all levels of staff, consultants and project management in both the business and technical areas while keeping discussions at the appropriate level of abstraction \n  Reconcile competing ideas or problems to a mutually beneficial conclusion \n  Ability to collaborate in a non-confrontational manner \n  Works well under minimal direction from management \n  Turns ambiguous information into meaningful requirements \n  Facilitates discussions about business processes with diverse participants \n  Builds consensus using a consultative approach \n  Strong logical, analytical, and problem solving skills \n  Advanced knowledge and demonstrated use of personal computer software applications including Microsoft Office Products (Word, Excel, PowerPoint, and Visio) \n \n \n \n  Abilities\n  \n \n  Ability to maintain professional image and work environment \n  Must be able to lift, carry, push, or pull up to 5 pounds or less 5% of the workday \n  Must be able stoop, kneel, crouch, or crawl 5% or less of the workday \n  Must be able to talk, see, hear, concentrate, think, learn and reason for all of the workday \n  Must be able to sit and walk or otherwise move around for prolonged periods throughout the workday \n  Must be able to use a keyboard and do manual tasks for prolonged periods throughout the workday \n  May require occasional travel \n \n \n \n  Pay and Benefits\n  \n \n  Salary range $104,097/yr - $135,000/yr depending on experience \n  Medical, dental, vision \n  Company paid LTD & STD \n  401K with Company match \n \n \n \n  #LI-PW1",
        "cleaned_desc": " \n \n   Skills\n  \n \n  Deep expertise in the business unit(s) they support. \n  Understanding of IT\u2019s systems and capabilities. \n  Participate with IT management and senior staff positions in the development and improvement of policies and procedures \n  Analyzes business partner\u2019s operations to understand their strengths and weaknesses to determine opportunities to automate processes and functions \n  Leads the business process redesign and documentation as needed for new technology \n  Works well in a matrixed environment as part of both Business Analysis and Technology Solutions teams \n  Complies with UTI\u2019s software development lifecycle practices and standards \n  Excellent verbal and written communication skills and high level of organization, planning, prioritizing in a fast paced environment where deadlines are essential \n  Controls, leads, and coordinates with all levels of staff, consultants and project management in both the business and technical areas while keeping discussions at the appropriate level of abstraction \n  Reconcile competing ideas or problems to a mutually beneficial conclusion \n  Ability to collaborate in a non-confrontational manner    Works well under minimal direction from management \n  Turns ambiguous information into meaningful requirements \n  Facilitates discussions about business processes with diverse participants \n  Builds consensus using a consultative approach \n  Strong logical, analytical, and problem solving skills \n  Advanced knowledge and demonstrated use of personal computer software applications including Microsoft Office Products (Word, Excel, PowerPoint, and Visio) \n \n \n \n  Abilities\n  \n \n  Ability to maintain professional image and work environment \n  Must be able to lift, carry, push, or pull up to 5 pounds or less 5% of the workday \n  Must be able stoop, kneel, crouch, or crawl 5% or less of the workday \n  Must be able to talk, see, hear, concentrate, think, learn and reason for all of the workday ",
        "techs": [
            "microsoft office products (word",
            "excel",
            "powerpoint",
            "visio)"
        ],
        "cleaned_techs": [
            "microsoft",
            "excel",
            "powerpoint",
            "visio)"
        ]
    },
    "b4ff68908d0ca024": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90959.29,
        "salary_max": 115174.73,
        "title": "Senior Business Analyst",
        "company": "Gallagher",
        "desc": "About Us: \n  \n   Gallagher Bassett is the world\u2019s premier provider of risk and claims management services. We believe that \u2013 with proper management \u2013 a world of risk becomes a world of possibilities. It becomes a world where businesses and organizations are freed to do what they do best. To build. To serve. To move forward. Knowing the responsibilities of today and their people are being cared for.\n  \n \n \n  So wherever opportunity and need come next in this world, Gallagher Bassett is there. More than 5,000 of the most dedicated professionals backed by the industry\u2019s most powerful technology. Each with a single and powerful purpose: To GUIDE those suffering a loss to the best outcomes for their health and financial wellbeing. To GUARD our clients\u2019 assets as the trusted stewards of their risk and claims management programs. To GO BEYOND expectations in the continuous pursuit of a better way.\n   Overview: \n  \n  This position is a 100% remote. \n  Responsibilities: \n  \n   Gallagher Bassett hiring for a Senior Business Analyst who has EDI and state reporting experience and is familiar with ESR jurisdictional error corrections processing.\n  \n \n \n  The candidate should possess a good understanding of EDI logic in regards to transactions that need to filed for claims, and what transaction should follow the prior accepted transaction; this will vary based on the current status of the claim. The candidate must have knowledge of IAIABC Release 1.0, 3.0 and 3.1 standards.\n  \n \n \n  The candidate should also have the ability to review errors and gain an understanding of what needs to be fixed to clear the error.\n   Qualifications: \n  \n  Required: \n \n \n  7 years experience required, with a minimum 3 to 5 years experience working at a senior data analyst level.  \n Excellent analytical skills. \n  Able to work in a fast-paced environment while staying organized to make sure errors are addressed timely. \n  Proficient in required system and computer applications. \n \n \n  Preferred: \n \n \n Bachelor degree and experience in insurance or claims industry \n  At least 5 years of experience in EDI filing \n  Highly analytical individual with proven understanding of Excel and Sharepoint. \n \n \n  Behaviors: \n \n \n  Outstanding analytical thinker.  \n Problem solver with the ability to clearly articulate findings and resolution.  \n Ability to act independently on assignment and understands appropriate escalation protocol.  \n Develops and maintains positive relationships within GB and externally with clients, carriers, and data vendors. Supports department and corporate initiatives. Adheres to Gallagher Shared Values. \n \n \n  #LI-TJ1 \n \n \n  #LI-Remote \n  Additional Information: \n  \n   Click Here to review our U.S. Eligibility Requirements\n  \n \n \n  We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "10f1fac014b596bd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 112323.94,
        "salary_max": 142227.14,
        "title": "Senior Business Analyst",
        "company": "BayOne",
        "desc": "Role:  Sr. Business Analyst \n \n \n Location:  REMOTE \n \n \n Type:  6 months+ \n \n \n Details: \n  Min 8 Years of Exp. \n \n  Help with a project around internal sharing of clinical trial data. \n \n  Business analyst will need to interview stakeholders, gather requirements, and deliver them in a format of user stories with acceptance criteria. business analysis and agile experience \n \n  D ata management experience \n \n  P harma R&D experience \n \n  Ideally, clinical data management and systems experience \n \n  E xperience with OMICs data or, at the very least, strong understanding of molecular biology . \n \n  Excellent communication skills.",
        "cleaned_desc": "  Ideally, clinical data management and systems experience \n \n  E xperience with OMICs data or, at the very least, strong understanding of molecular biology . \n ",
        "techs": [
            "clinical data management",
            "omics data",
            "molecular biology"
        ],
        "cleaned_techs": [
            "clinical data management",
            "omics data",
            "molecular biology"
        ]
    },
    "e25376be2823028d": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 56467.0,
        "salary_max": 95993.0,
        "title": "ServiceNow Business Analyst with DHS Public Trust (Remote)",
        "company": "ICF",
        "desc": "*We are open to supporting 100% remote work anywhere within the US *\n  \n \n \n \n    The Digital Modernization division of ICF is seeking a motivated Business Analyst with experience identifying, analyzing, and managing business and technical requirements for federal government projects. The successful candidate will possess an understanding of driving tasks to completion and is self-motivated, driven, and understands multiple technologies (ServiceNow, Test Automation Tools, Jira, Confluence) capabilities.\n   \n \n \n \n     Our Digital Modernization division is an information technology and management consulting department that offers integrated, strategic solutions to its public and private-sector clients. ICF has the expertise, agility, and commitment to design, build, and operate high-performance IT engines to support all aspects of our client\u2019s business.\n    \n \n \n     What you\u2019ll be doing:\n    \n \n \n \n       Work with government stakeholders, plan, manage, document, and analyze functional and testing requirements, identify gaps, and identify alternative approaches to meet requirements.\n      \n \n \n       Assist in analyzing and documenting client's business requirements and processes; communicates these requirements to technical and non-technical personnel by constructing basic conceptual data and process models.\n      \n \n \n       Assist with the management of requirements and collaboration sessions using tools like JIRA and Confluence\n      \n \n \n       Assist in the research and assessment of business goals, objectives, and needs to align information technology solutions with business initiatives.\n      \n \n \n       Communicate effectively with a wide variety of technical and non-technical audiences.\n      \n \n \n       Develop a strong understanding of the client mission, organization, and technology landscape to better understand how ICF can most effectively identify and address enterprise needs.\n      \n \n \n \n     What you must have:\n    \n \n \n \n       Must have a DHS Public Trust security clearance.\n      \n \n \n       2+ years of experience as a Business Analyst in a fast-paced client-facing solution delivery environment\n      \n \n \n       2+ years of recent experience working in an Agile development environment as a business analyst (i.e., Scrum, Kanban, etc.)\n      \n \n \n       2+ years of demonstrated experience driving direct client requirements\n      \n \n \n       2+ years of experience with the ServiceNow Platform\n      \n \n \n       2+ years of experience facilitating requirements gathering, Joint Application Design (JAD) sessions, capturing client requirements and feedback\n      \n \n \n       1+ years leading or mentoring teams\n      \n \n \n       US Citizenship is required due to federal contract requirements.\n      \n \n \n \n     Desired Skills:\n    \n \n \n \n       Good understanding of basic system technologies as they relate to the project deliverables.\n      \n \n \n       Experience with business process mapping and the use of project management software\n      \n \n \n       Excellent oral and written communication skills\n      \n \n \n       Strong analytical, problem-solving, and time-management skills\n      \n \n \n       Excellent attention to detail\n      \n \n \n       Experience with Technology Platforms such as ServiceNow, Appian, Salesforce, Jira, Confluence\n      \n \n \n       Ability to work independently and within one or more teams with excellent time management, organizational, and reporting skills.\n      \n \n \n       Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand.\n      \n \n \n       Experience thriving in ambiguous solution-delivery environments.\n      \n \n \n       Ability to work well under constantly changing deadlines and priorities.\n      \n \n \n     #DMD\n    \n \n     #SENW22\n    \n \n     #SWICE23\n    \n \n \n \n \n   Working at ICF\n  \n  ICF is a global advisory and technology services provider, but we\u2019re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.\n  \n \n   We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our \n   \n   EEO & AA policy\n   .\n  \n \n \n   Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email \n   \n   icfcareercenter@icf.com\n    and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: \n   \n   Know Your Rights\n    and \n   \n   Pay Transparency Statement.\n   \n \n \n \n  Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:\n   $56,467.00 - $95,993.00\n   Nationwide Remote Office (US99)",
        "cleaned_desc": "       Strong analytical, problem-solving, and time-management skills\n      \n \n \n       Excellent attention to detail\n      \n \n \n       Experience with Technology Platforms such as ServiceNow, Appian, Salesforce, Jira, Confluence\n      \n \n \n       Ability to work independently and within one or more teams with excellent time management, organizational, and reporting skills.\n      \n \n \n       Skilled at analyzing existing system documentation to summarize existing system functionality as it relates to the project at hand.\n      \n \n \n       Experience thriving in ambiguous solution-delivery environments.\n      \n \n \n       Ability to work well under constantly changing deadlines and priorities.\n      \n \n \n     #DMD\n    \n \n     #SENW22\n    ",
        "techs": [
            "servicenow",
            "appian",
            "salesforce",
            "jira",
            "confluence"
        ],
        "cleaned_techs": [
            "servicenow",
            "appian",
            "salesforce",
            "jira",
            "confluence"
        ]
    },
    "61c22dd90f9f0812": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 105679.305,
        "salary_max": 133813.55,
        "title": "Lead IT Business Analyst",
        "company": "Kellanova",
        "desc": "As an IT Business Analyst Lead you will learn, grow, and create innovative technology solutions to help our business flourish. This critical role will establish and maintain a strategic relationship with our key North America and global stakeholders and others in Research & Development (R&D), defining IT strategy and delivering solutions that enable the function to meet its goals. \n   \n At the heart of Kellanova is technology \u2014 a key enabler of how we market, sell and manufacture our well-known and beloved brands to consumers around the globe. Be a part of a leading company in global snacking, international cereal and noodles, and North America frozen foods, with iconic, world-class brands including Pringles, Cheez-It and Pop-Tarts. \n \n  A Taste of What You\u2019ll Be Doing \n   \n \n Partner with IT and the R&D business Function   -  This critical role will be the IT Business Analyst for all KNA R&D technology solutions for our function. In this role, you will be working closely with R&D leadership and global key stakeholders across the organization in designing and delivering technology capabilities and driving projects, roadmaps, strategy, and total cost of ownership. \n \n \n  Business Case Development   -  Works with business teams to understand project requirements, shapes the initial project request, and provides a high-level estimate of the project effort and cost used in cost-benefit analysis. Plan expenditures based on the size, scope, and cost of hardware and software components. Reviews and evaluates business cases to confirm identified financials and risks, validate value and business alignment, and recommend a course of action. \n \n \n  Requirements Documentation   \u2013  Works with business and project teams to capture and document requirements and expected functionality of the proposed solution. Leads clarification and validation of requirements during the development and delivery of the solution. Works closely with IT architects, security, delivery partners, and others to ensure a safe and successful solution launch. \n  Deliver IT Projects -   You\u2019ll deliver the technology platform strategy by providing leadership to our project teams and driving the successful delivery of capabilities within the function. You will manage the Regional R&D platform(s) from an IT product perspective including vendor and Global IT relationships. \n \n \n  Your Recipe for Success \n \n \n \n  Bachelor\u2019s degree in computer science, Information Systems, Business Administration, or related field, or equivalent work experience. \n  Experience implementing and working with industry-leading Research & Development platforms such as SAP Recipe Management, SAP Product Lifecycle Management, Ideation technologies, Microsoft Portfolio Management Tools and Analytics (ie. Tableau, Power BI) solutions. Experience managing a product line and clearly articulating the total cost of ownership to leadership \n  Strong analytical, project management, and team leadership skills \n  Strong background in systems/software development lifecycle \n  Excellent written and verbal communications \n  Experience in CPG (Consumer Packaged Goods) industry \n  PMP, Agile or similar Certification \n \n  What\u2019s Next    After you apply, your application will be reviewed by a real recruiter \u2013 not a bot. This means it could take us a little while to get back with you so watch your inbox for updates. In the meantime, visit our  How We Hire page  to get insights into our hiring process and how to best prepare for a Kellanova interview. \n \n  If we can help you with a reasonable accommodation throughout the application or hiring process, please email  USA.Recruitment@Kellanova.com . \n \n  About Kellanova \n \n  Kellanova is a leading company in global snacking, international cereal and noodles, plant-based foods, and North America frozen breakfast, and a portfolio of iconic, world-class brands, including Pringles, Cheez-It, Pop-Tarts, Kellogg\u2019s Rice Krispies Treats, MorningStar Farms, Incogmeato, Gardenburger, Nutri-Grain, RXBAR, and Eggo. We also steward a suite of beloved international cereal brands, including Kellogg\u2019s, Frosties, Zucaritas, Special K, Krave, Miel Pops, Coco Pops, and Crunchy Nut, among others. \n \n  At Kellanova, we are committed to Equity, Diversity, and Inclusion (ED&I), uplifting each other and embracing our differences to achieve our common goals. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, ideas, and can bring their authentic selves to work. Learn more here. \n \n  We\u2019re proud to offer industry competitive  Total Health benefits  (Physical, Financial, Emotional, and Social) that vary depending on region and type of role. Be sure to ask your recruiter for more information! \n   \n The Finer Print \n \n  Kellanova is an Equal Opportunity Employer that strives to provide an inclusive work environment, a seat for everyone at the table, and embraces the diverse talent of its people. All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, disability, religion, national origin, gender, gender identity, gender expression, marital status, sexual orientation, age, protected veteran status, or any other characteristic protected by law. For more information regarding our efforts to advance Equity, Diversity & Inclusion, please visit our website here. \n   \n Ready to Taste the Future of Food?  \n \n Kellanova Recruitment",
        "cleaned_desc": " \n \n \n  Bachelor\u2019s degree in computer science, Information Systems, Business Administration, or related field, or equivalent work experience. \n  Experience implementing and working with industry-leading Research & Development platforms such as SAP Recipe Management, SAP Product Lifecycle Management, Ideation technologies, Microsoft Portfolio Management Tools and Analytics (ie. Tableau, Power BI) solutions. Experience managing a product line and clearly articulating the total cost of ownership to leadership \n  Strong analytical, project management, and team leadership skills \n  Strong background in systems/software development lifecycle \n  Excellent written and verbal communications \n  Experience in CPG (Consumer Packaged Goods) industry ",
        "techs": [
            "sap recipe management",
            "sap product lifecycle management",
            "ideation technologies",
            "microsoft portfolio management tools",
            "tableau",
            "power bi"
        ],
        "cleaned_techs": [
            "sap recipe management",
            "ideation technologies",
            "microsoft portfolio management tools",
            "tableau",
            "powerbi"
        ]
    },
    "43ce3003febbda8f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75000.0,
        "salary_max": 85000.0,
        "title": "Sr. Operations Analyst, Contact Center",
        "company": "DeVry University",
        "desc": "DeVry University strives to close our society\u2019s opportunity gap by preparing learners to thrive in careers shaped by continuous technological change. Through innovative programs, relevant partnerships, and exceptional care, we empower students to meaningfully improve their lives, communities, and workplaces. \n   \n  When you apply for a DeVry University career, you become part of an institution that dates back to 1931. Our colleagues are passionate about higher education and shaping the future of today\u2019s learners. \n  \n \n \n \n    DeVry University strives to close our society\u2019s opportunity gap by preparing learners to thrive in careers shaped by continuous technological change. Through innovative programs, relevant partnerships, and exceptional care, we empower students to meaningfully improve their lives, communities, and workplaces.\n     \n  When you apply for a DeVry University career, you become part of an institution that dates back to 1931. Our colleagues are passionate about higher education and shaping the future of today\u2019s learners.\n    \n \n \n \n  Opportunity: \n \n \n \n \n     The Sr. Operations Analyst, Contact Center role at DeVry University presents an exciting opportunity for a candidate who is passionate about optimizing contact center operations and enhancing the learner experience in the education sector. In this position, you will be at the forefront of ensuring efficiency and exceptional service delivery.\n    \n \n     As a Sr. Operations Analyst, you will be instrumental in evaluating enrollment processes and outcomes while also possessing the expertise to optimize contact center operations. Your responsibilities involve analyzing data, developing reports, and providing actionable insights in collaboration with business leaders and colleagues. By leveraging your strong analytical skills and keen eye for process improvement, you will identify areas of opportunity that impact both learners and colleagues.\n    \n \n     Your role goes beyond data analysis; you will actively contribute to implementing solutions aligned with organizational strategy. This includes improving the learner experience from initial inquiry through graduation and career services, enhancing retention rates, and increasing colleague productivity and satisfaction. Furthermore, your efforts will foster collaboration across all teams that impact the learner experience, leading to a seamless coordination that significantly enhances both learner outcomes and colleague experiences.\n    \n \n     As a Sr.Operations Analyst, you will be a key player in driving continuous improvement across our systems and processes within our educational initiatives. Your contributions will directly impact the student journey, ensuring a positive and supportive experience while also optimizing internal processes to create a cohesive and efficient work environment.\n    \n \n \n \n  Responsibilities: \n \n \n \n \n     Operations and Workforce Management:\n    \n \n Develop and implement strategies for effective contact center workforce management, ensuring optimal staffing levels to meet service demands and performance targets. \n Align contact center staff skills with evolving customer needs and technological advancements, enabling the team to handle diverse inquiries and challenges effectively. \n Utilize data-driven insights to forecast staffing requirements, aligning resources with service levels during peak periods and special promotions. \n Implement workforce forecasting models and staffing strategies, optimizing the balance between operational costs and service quality, and ensuring efficient performance. \n Support record administration and mass communications, partnering with business process operations to execute campaigns.  \n \n \n    Customer Feedback, Data Analysis and Reporting:\n    \n \n Analyze data using CRM, LMS, SIS, and other applications, utilizing Power BI to identify trends and areas for improvement. \n Prepare detailed reports and dashboards for management, providing insights on key metrics and program outcomes. \n Analyze customer feedback and complaints, suggesting improvements for enhanced customer satisfaction. \n Collaborate with cross-functional teams to implement changes based on customer feedback. \n \n \n    System Enhancement and Optimization:\n    \n \n Provide tailored input for streamlined communication, task management, and reporting in the contact center's systems. \n Drive continuous enhancements in contact center operations through active participation in process optimization and efficiency improvement initiatives. \n Assist in the development and implementation of project plans, evaluating their feasibility and impact on contact center systems. \n Proactively monitor project timelines, addressing conflicts, and suggesting adjustments for operational efficiency. \n Collaborate with business process and project management teams to integrate systems and initiatives, aligning with the contact center's operational goals and objectives. \n Participate in cross-functional initiatives, offering expertise on contact center systems and workflows to support organizational strategies. \n Identify synergies between projects and contact center operations, fostering efficient collaboration and maximizing joint initiatives' impact. \n \n \n    Process Improvement and Training:\n    \n \n Evaluate call center processes, identify inefficiencies, and implement streamlined procedures. \n Ensure adherence to quality standards through trend analysis and evaluation of calls and interactions. \n Provide valuable feedback to enhance communication skills and customer service techniques within the team. \n Collaborate in the development of training materials focusing on best practices and product knowledge. \n Evaluate training program effectiveness, recommending improvements to meet operational needs. \n Collaborate with IT and Business Process teams to maximize call center software utility and identify technological solutions for efficiency. \n Engage in process improvement initiatives, evaluating existing operations and CRM systems to optimize efficiency and customer satisfaction. \n Foster a cohesive work environment through effective collaboration with cross-functional teams. \n \n \n    Documentation and Standardization:\n    \n \n Develop and maintain detailed documentation of operations processes, protocols, and best practices. \n Standardize procedures to ensure consistency in service delivery and facilitate training for new team members as needed. \n Manage and seek automation of the systems onboarding and provisioning for contact center colleagues. \n \n \n \n \n  Qualifications: \n \n \n \n \n Bachelor's degree (BS/BA) in Operations Management, Analytics, Project Management, or related Business disciplines. \n 5+ years of experience in a contact center environment, hospitality, or related industry. \n 2+ years of experience in managing operations, contact center teams, or related functions. \n Strong proficiency in MS Office, particularly MS Excel, with the ability to manipulate data effectively. \n Familiarity with Advanced Analytics/Statistical Analysis (Power BI DAX programming/Tableau, SQL, Power Query M programming) \u2013 Preferred, though a demonstrated math background is required due to the nature of the role. \n 3-5 years of experience preferred in working with CRM, Telephony, Workforce Management, SIS systems processes, or call center technologies. \n Capacity to quickly learn technical systems and environments, with a strong interest in developing technical skills. \n Proven ability to work independently and excel in a fast-paced work environment with minimal guidance. \n Strategic thinker with a track record of developing and executing innovative ideas. \n Exceptional organizational and project management skills, including the successful completion of complex projects. \n Demonstrated ability to manage professional relationships effectively. \n Excellent written and verbal communication skills for clear articulation of ideas and insights. \n \n \n DeVry University offers competitive wages and benefits, including: \n \n \n 401(k) and Roth IRA Plan w/match \n Medical, Dental and Vision Coverage \n Health Advocacy Service \n Domestic Partner Coverage \n Tax Savings Account (FSA and HSA) \n Short-Term/Long-Term Disability Coverage \n Life, Accident, AD&D, Critical Illness Insurance \n Fertility Coverage \n Wellness Programs \n Volunteer Time Off \n Remote and Flex Work Options \n Technology Stipend \n Paid Tuition Program \n Auto/Homeowners, Pet and Legal Insurance \n Exclusive Discount Programs \n Adoption Assistance  \n Career Development Programs \n \n \n    We believe diversity is essential to our educational mission and to the success of our community. We are committed to fostering a working environment where differences are respected, valued and embraced.\n     \n \n Salary Range 75-85k \n \n \n \n \n \n \n \n DeVry University offers competitive wages and benefit options, including: \n \n \n \n \n \n 401(k) and Roth Plan w/match \n Medical, Dental and Vision Coverage \n Paid Parental Leave \n Health Advocacy Service \n Family and Domestic Partner Coverage \n Tax Savings Account (FSA and HSA) \n Short-Term/Long-Term Disability Coverage \n Life, Accident, AD&D, Critical Illness Insurance \n Fertility Coverage \n Wellness Programs \n Volunteer Time Off \n Remote and Flex Work Options \n Technology Stipend \n Paid Tuition Program \n Auto/Homeowners, Pet and Legal Insurance \n Exclusive Discount Programs \n Adoption Assistance \n Career Development Programs \n Mental Health Care Programs \n Family Care Services \n 2nd.MD, a virtual expert medical consultation service \n \n \n \n \n \n     Benefits vary based on employment status. Part-time/Visiting Professors positions may not be eligible for all benefits. \n     \n \n \n     We believe diversity is essential to our educational mission and to the success of our community. We are committed to fostering a working environment where differences are respected, valued and embraced.",
        "cleaned_desc": " Evaluate call center processes, identify inefficiencies, and implement streamlined procedures. \n Ensure adherence to quality standards through trend analysis and evaluation of calls and interactions. \n Provide valuable feedback to enhance communication skills and customer service techniques within the team. \n Collaborate in the development of training materials focusing on best practices and product knowledge. \n Evaluate training program effectiveness, recommending improvements to meet operational needs. \n Collaborate with IT and Business Process teams to maximize call center software utility and identify technological solutions for efficiency. \n Engage in process improvement initiatives, evaluating existing operations and CRM systems to optimize efficiency and customer satisfaction. \n Foster a cohesive work environment through effective collaboration with cross-functional teams. \n \n \n    Documentation and Standardization:\n    \n \n Develop and maintain detailed documentation of operations processes, protocols, and best practices. \n Standardize procedures to ensure consistency in service delivery and facilitate training for new team members as needed. \n Manage and seek automation of the systems onboarding and provisioning for contact center colleagues. \n \n \n \n \n  Qualifications: \n \n \n \n \n Bachelor's degree (BS/BA) in Operations Management, Analytics, Project Management, or related Business disciplines. \n 5+ years of experience in a contact center environment, hospitality, or related industry. \n 2+ years of experience in managing operations, contact center teams, or related functions. \n Strong proficiency in MS Office, particularly MS Excel, with the ability to manipulate data effectively. \n Familiarity with Advanced Analytics/Statistical Analysis (Power BI DAX programming/Tableau, SQL, Power Query M programming) \u2013 Preferred, though a demonstrated math background is required due to the nature of the role. \n 3-5 years of experience preferred in working with CRM, Telephony, Workforce Management, SIS systems processes, or call center technologies. \n Capacity to quickly learn technical systems and environments, with a strong interest in developing technical skills. \n Proven ability to work independently and excel in a fast-paced work environment with minimal guidance. \n Strategic thinker with a track record of developing and executing innovative ideas. \n Exceptional organizational and project management skills, including the successful completion of complex projects. \n Demonstrated ability to manage professional relationships effectively. ",
        "techs": [
            "evaluate call center processes",
            "identify inefficiencies",
            "implement streamlined procedures",
            "trend analysis",
            "evaluation of calls and interactions",
            "feedback",
            "communication skills",
            "customer service techniques",
            "training materials",
            "training program effectiveness",
            "it",
            "business process teams",
            "call center software utility",
            "technological solutions",
            "process improvement initiatives",
            "existing operations",
            "crm systems",
            "automation",
            "documentation",
            "standardization",
            "operations processes",
            "protocols",
            "best practices",
            "consistency in service delivery",
            "training for new team members",
            "systems onboarding",
            "provisioning",
            "qualifications",
            "bachelor's degree",
            "operations management",
            "analytics",
            "project management",
            "contact center environment",
            "hospitality",
            "managing operations",
            "contact center teams",
            "ms office",
            "ms excel",
            "data manipulation",
            "advanced analytics",
            "statistical analysis",
            "power bi dax programming",
            "tableau",
            "sql",
            "power query m programming",
            "crm",
            "telephony",
            "workforce management",
            "sis systems processes",
            "call center technologies",
            "technical systems and environments",
            "technical skills",
            "independent work",
            "fast-paced work environment",
            "strategic thinker",
            "innovative ideas",
            "organizational skills",
            "project management skills",
            "complex projects",
            "professional relationships"
        ],
        "cleaned_techs": [
            "evaluate call center processes",
            "identify inefficiencies",
            "implement streamlined procedures",
            "trend analysis",
            "evaluation of calls and interactions",
            "feedback",
            "customer service techniques",
            "training materials",
            "training program effectiveness",
            "it",
            "business process teams",
            "call center software utility",
            "technological solutions",
            "process improvement initiatives",
            "existing operations",
            "crm systems",
            "automation",
            "standardization",
            "operations processes",
            "protocols",
            "consistency in service delivery",
            "training for new team members",
            "systems onboarding",
            "provisioning",
            "qualifications",
            "operations management",
            "project management",
            "contact center environment",
            "hospitality",
            "managing operations",
            "contact center teams",
            "microsoft",
            "excel",
            "data manipulation",
            "advanced analytics",
            "statistical analysis",
            "powerbi",
            "tableau",
            "sql",
            "power query m programming",
            "crm",
            "telephony",
            "workforce management",
            "sis systems processes",
            "call center technologies",
            "technical systems and environments",
            "independent work",
            "fast-paced work environment",
            "strategic thinker",
            "innovative ideas",
            "complex projects",
            "professional relationships"
        ]
    },
    "0e989dfdd7b272cc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 105679.305,
        "salary_max": 133813.55,
        "title": "Lead IT Business Analyst",
        "company": "Kellanova",
        "desc": "As an IT Business Analyst Lead you will learn, grow, and create innovative technology solutions to help our business flourish. This critical role will establish and maintain a strategic relationship with our key North America and global stakeholders and others in Research & Development (R&D), defining IT strategy and delivering solutions that enable the function to meet its goals. \n \n  At the heart of Kellanova is technology \u2014 a key enabler of how we market, sell and manufacture our well-known and beloved brands to consumers around the globe. Be a part of a leading company in global snacking, international cereal and noodles, and North America frozen foods, with iconic, world-class brands including Pringles, Cheez-It and Pop-Tarts. \n \n  A Taste of What You\u2019ll Be Doing \n \n  Partner with IT and the R&D business Function - This critical role will be the IT Business Analyst for all KNA R&D technology solutions for our function. In this role, you will be working closely with R&D leadership and global key stakeholders across the organization in designing and delivering technology capabilities and driving projects, roadmaps, strategy, and total cost of ownership. \n Business Case Development - Works with business teams to understand project requirements, shapes the initial project request, and provides a high-level estimate of the project effort and cost used in cost-benefit analysis. Plan expenditures based on the size, scope, and cost of hardware and software components. Reviews and evaluates business cases to confirm identified financials and risks, validate value and business alignment, and recommend a course of action. \n Requirements Documentation \u2013 Works with business and project teams to capture and document requirements and expected functionality of the proposed solution. Leads clarification and validation of requirements during the development and delivery of the solution. Works closely with IT architects, security, delivery partners, and others to ensure a safe and successful solution launch. \n Deliver IT Projects - You\u2019ll deliver the technology platform strategy by providing leadership to our project teams and driving the successful delivery of capabilities within the function. You will manage the Regional R&D platform(s) from an IT product perspective including vendor and Global IT relationships. \n \n  Your Recipe for Success \n \n  Bachelor\u2019s degree in computer science, Information Systems, Business Administration, or related field, or equivalent work experience. \n Experience implementing and working with industry-leading Research & Development platforms such as SAP Recipe Management, SAP Product Lifecycle Management, Ideation technologies, Microsoft Portfolio Management Tools and Analytics (ie. Tableau, Power BI) solutions. Experience managing a product line and clearly articulating the total cost of ownership to leadership \n Strong analytical, project management, and team leadership skills \n Strong background in systems/software development lifecycle \n Excellent written and verbal communications \n Experience in CPG (Consumer Packaged Goods) industry \n PMP, Agile or similar Certification \n What\u2019s Next \n \n  After you apply, your application will be reviewed by a real recruiter \u2013 not a bot. This means it could take us a little while to get back with you so watch your inbox for updates. In the meantime, visit our How We Hire page to get insights into our hiring process and how to best prepare for a Kellanova interview. \n \n  If we can help you with a reasonable accommodation throughout the application or hiring process, please email USA.Recruitment@Kellanova.com . \n \n  About Kellanova \n \n  Kellanova is a leading company in global snacking, international cereal and noodles, plant-based foods, and North America frozen breakfast, and a portfolio of iconic, world-class brands, including Pringles, Cheez-It, Pop-Tarts, Kellogg\u2019s Rice Krispies Treats, MorningStar Farms, Incogmeato, Gardenburger, Nutri-Grain, RXBAR, and Eggo. We also steward a suite of beloved international cereal brands, including Kellogg\u2019s, Frosties, Zucaritas, Special K, Krave, Miel Pops, Coco Pops, and Crunchy Nut, among others. \n \n  At Kellanova, we are committed to Equity, Diversity, and Inclusion (ED&I), uplifting each other and embracing our differences to achieve our common goals. Our focus on ED&I enables us to build a culture where all employees are inspired to share their passion, talents, ideas, and can bring their authentic selves to work. Learn more here . \n \n  We\u2019re proud to offer industry competitive Total Health benefits (Physical, Financial, Emotional, and Social) that vary depending on region and type of role. Be sure to ask your recruiter for more information! \n \n  The Finer Print \n \n  Kellanova is an Equal Opportunity Employer that strives to provide an inclusive work environment, a seat for everyone at the table, and embraces the diverse talent of its people. All qualified applicants will receive consideration for employment without regard to race, color, ethnicity, disability, religion, national origin, gender, gender identity, gender expression, marital status, sexual orientation, age, protected veteran status, or any other characteristic protected by law. For more information regarding our efforts to advance Equity, Diversity & Inclusion, please visit our website here . \n \n  Ready to Taste the Future of Food? \n \n \n Kellanova Recruitment",
        "cleaned_desc": " Requirements Documentation \u2013 Works with business and project teams to capture and document requirements and expected functionality of the proposed solution. Leads clarification and validation of requirements during the development and delivery of the solution. Works closely with IT architects, security, delivery partners, and others to ensure a safe and successful solution launch. \n Deliver IT Projects - You\u2019ll deliver the technology platform strategy by providing leadership to our project teams and driving the successful delivery of capabilities within the function. You will manage the Regional R&D platform(s) from an IT product perspective including vendor and Global IT relationships. \n \n  Your Recipe for Success \n \n  Bachelor\u2019s degree in computer science, Information Systems, Business Administration, or related field, or equivalent work experience. \n Experience implementing and working with industry-leading Research & Development platforms such as SAP Recipe Management, SAP Product Lifecycle Management, Ideation technologies, Microsoft Portfolio Management Tools and Analytics (ie. Tableau, Power BI) solutions. Experience managing a product line and clearly articulating the total cost of ownership to leadership \n Strong analytical, project management, and team leadership skills ",
        "techs": [
            "requirements documentation",
            "sap recipe management",
            "sap product lifecycle management",
            "ideation technologies",
            "microsoft portfolio management tools",
            "tableau",
            "power bi"
        ],
        "cleaned_techs": [
            "sap recipe management",
            "ideation technologies",
            "microsoft portfolio management tools",
            "tableau",
            "powerbi"
        ]
    },
    "07745a3f596e9967": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 84133.305,
        "salary_max": 106531.51,
        "title": "LU - Business Analyst/Child Welfare Expert",
        "company": "FOCUSED HR SOLUTIONS LLC",
        "desc": "This job is Hybrid you will need to relocate to Hartfort CT. Client will not pay for relocation. WORK SCHEDULE: 30-40 hours per week - Monday - Friday, 8 AM - 5 PM. Hybrid-remote schedule. Selected candidates will be required to work on-site 20% of the time. Our direct client has an opening for a Business Analyst/Child Welfare Expert 60328 This position is for 12 months with option of extension and is located in Hartford, CT We can work W2 or Corp to Corp. If you are interested, please submit the following: Please send your rate and resume. 5+ Years\u2019 Experience in Child Welfare or related fieldProduct Owner and/or Product Manager certification a plusKnowledge of DCF\u2019s mission, policy, practice, state agencies and community partners/service providersKnowledge of agile development methodologies, including developing acceptance criteriaKnowledge of case management systems and modern web-based capabilities/applicationsKnowledge of Business Process Mapping, requirements gathering and documentation processesExperience in facilitating large groups for presentations, LEAN Events and trainings a plus\u00b7 Experience in analyzing data to draw business-relevant conclusions 4. ADMINISTRATIVE CONSIDERATIONS WORK SCHEDULE: 30-40 hours per week - Monday - Friday, 8 AM - 5 PM. Hybrid-remote schedule. Selected candidates will be required to work on-site 20% of the time. 505 Hudson Street Hartford , Connecticut 06106-0000 Candidate must be local or willing to commute or relocate. Skills Others Problem Solving Skills Proficient (4-6 Years) No Skills Others Communication skills both verbal and written Proficient (4-6 Years) No Skills Tools Microsoft Office Proficient (4-6 Years) No \n \n  By replying to this job advertisement, I agree I want to receive additional job advertisements from Focused HR Solutions, including email, phone and mail to the contact information I am submitting. I consent to Focused HR Solutions, its affiliates, third parties and partners processing my personal data for these purposes and as described in the Privacy Policy. I understand that I can withdraw my consent at any time. \n \n  This is a remote position.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ca41220db54b9529": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40.38,
        "salary_max": 40.38,
        "title": "Provider Data Management Analyst",
        "company": "TotalMed Medfi",
        "desc": "Position Title  \u2013 Provider Data Management Analyst Address  \u2013 Remote National Pay  \u2013 $40.38/hr. Hours  \u2013 Monday \u2013 Friday standard working hours. 8:00 a.m. \u2013 5:00 p.m Contract Type  \u2013 contract to possible hire Vaccine Requirement  \u2013 not required \n Responsibilities: \n \n Provider Data Management Analyst will Review provider contracts, provider data rosters, quality review data and ensure it is in suitable format for submission, reconcile large sets of data \n Provider Data Management Analyst will Set up and perform facility (hospitals and clinics) enrollment in the provider data management system \n Provider Data Management Analyst will Enroll providers and practitioners in the provider data management system \n \n Required Skills & Education: \n \n 2+ years provider data management experience \n Moderate to master level Excel skills \n Bachelor's degree required \n \n #INDTMS \n Job Type: Contract \n Pay: $40.38 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Vision insurance \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Application Question(s): \n \n Are you Moderate to master level in Excel ? \n \n Experience: \n \n provider data management: 3 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "e5c377d148ab0b81": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75774.414,
        "salary_max": 95947.29,
        "title": "Enterprise Technology - Senior Digital Business Analyst",
        "company": "NBH Bank",
        "desc": "It starts with our culture ... \n Common sense has never been common. \n If it were, the world would be a different place. Things would run smoothly and on time. People would do what they say and say what they do. Everything would be fair, without all the small talk. And banks would only sell you what you need. When a banker looked at a client, they wouldn\u2019t just see a number, they\u2019d see a dad or a mom or a graduate or a business owner. Our Bankers understand the complexities of people\u2019s lives and offer simple solutions. \n \n  That's the basics of Relationships. Fairness. Simplicity\u00ae \n When you choose our Company, you have an opportunity to make an impact beyond the walls of our buildings. \n \n  We have a long-standing commitment to Equity, Diversity and Inclusion. Through our business relationships, investing, grants, and volunteerism, NBH Bank promotes the growth, revitalization and sustainability of the communities we serve. We believe that these are important elements in building and sustaining a successful organization and a positive, results-driven culture. We strive for all of our associates to feel welcome and empowered at work. \n \n  This type of position is ideal for someone looking to build a career in finance, banking, and technology. We will provide you training and coaching throughout your onboarding experience, as well as on the job. As you demonstrate success, there will be opportunities for advancement within our organization. \n \n  For this position, we are looking for a self-starting, results oriented team player to join us as a Digital Business Analyst Senior. \n \n  As a Digital Business Analyst Senior, you willbe a liaison, facilitating communication and driving solutions for internal business units and stakeholders with external vendors and partners. You will be responsible for a variety of tasks including providing daily Product + Tier 2 Operational Support and oversight of the bank\u2019s digital products and services, as needed. \n \n  This position will follow a hybrid-working model (a combination of work from the office and at home based on manager discretion). \n \n \n You will develop and implement solutions to: \n  1. Support business processes and automate work streams as appropriate. \n 2. Analyze bank current and future system processes and/or procedures. \n 3. Recommended solutions to improve the client experience, increase productivity and efficiency. \n 4. Assist with workflow planning process including design, configuration/develop, testing and delivery of solutions. \n 5. Participate in the research and evaluation of potential new vendors and technologies, and as appropriate costs and user applicability with current vendors and partners. \n 6. Provide input/interpretation to business designs and requirements to determine optimal solutions. \n Additionally, a Digital Business Analyst Senior, will follow policies and procedures; complete administrative tasks correctly and on time; support the Bank\u2019s goals and values; will perform other duties as assigned; benefit the bank through outside activities, participate in coordination of disaster recovery planning and preparation, build a great rapport with clients and fellow associates, and treat others with respect and consideration regardless of their status or position. \n \n \n Minimum Requirements: \n \n \n Bachelor\u2019s degree required in Business, Finance, Management or related discipline OR equivalent combination of education and related work experience. \n 5-7+ years of relevant job experience \n \n Desired Qualifications:  To be considered an ideal candidate, you should possess some of the following qualifications: \n \n \n Advanced degree or certification related to field \n 8+ years of relevant job experience in banking \n Experience with bank systems, project management, vendor partnerships and resolution of complex system issues \n \n Desired Skills:  Ideal candidates for this position should possess some or all of the following skills: \n \n \n Experience supporting processes and systems related to marketing, data and web analytics, online account opening, online banking, deposit and treasury functions, loan origination/loan servicing (including SBA), core system support, payments, cards, compliance (KYC, KYB, AML, BSA), and other bank functions as determined. \n Strong knowledge of banking regulations. \n Strong analytical and problem solving skills. \n Well developed and proven organization skills with ability to utilize time efficiently \n Exceptional verbal, written and interpersonal communication skills with the ability to apply common sense to carry out instruction and speak clearly to associates \n Absolute discretion when dealing with confidential matters \n Exceptional verbal, written and interpersonal communication skills with the ability to apply common sense to carry out instructions and instruct others, train personnel, write procedures and correspondence, speak clearly to clients and associates \n Strong typing skills to meet production needs of the position \n Ability to perform extensive system configurations in banking platforms \n Ability to train and coach associates, as appropriate \n \n Work Environment: \n  We are a culture that believes that people are our greatest asset and are at the heart of everything we do. We take pride in bringing clarity and simplicity to our associates (employees) and clients. Our decisions are made efficiently, fairly and locally. Our success is directly tied to the communities we serve. It is equally important for us to look through the lens of our applicants and associates to identify their individual needs. As such, we want to share the following: \n \n \n We are committed to our core value of meritocracy and supporting our associates in growing within their role \n Flexible scheduling: Hybrid office environment, manager permitting, with traditional hours \n Must be able to work at a rapid pace while sitting for long periods of time (typically no longer than 8 hours) \n Must be able to work overtime to the extent necessary \n Must be able to travel \u2013 estimated at 5% to 10% of the time \n \n Incentive and Benefits: \n  This role is eligible to participate in our annual incentive plan. \n \n  In addition to your financial compensation, we also offer a generous benefits package that includes insurance, 401k, an associate stock purchase program, paid time off, associate banking perks. For more information about the benefits offered click here. \n If this is what you believe in, then you\u2019re definitely right for us. Consider making an investment in us, so that we may invest in you and your bright future. \n \n  Thank you for your application! \n The Bank is committed to providing qualified applicants and associates reasonable accommodation, when necessary, to enable the individuals to complete the application process and/or perform the essential functions of the job. An applicant and/or associate requiring reasonable accommodation to perform any essential job function, should contact Human Resources. \n \n  The Bank's policy is to provide equal opportunity to all people without regard to race, color, religion, national origin, ancestry, marital status, veteran status, age, disability, pregnancy, genetic information, citizenship status, sex, sexual orientation, gender identity or any other legally protected category. The Bank is proud to be a drug-free workplace. \n \n  Selected candidate(s) for hire must complete the following prior to employment: a criminal history report, global screen, drug screen, employment credit report and if applicable, a driving record. Applicants must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "aa441c9d47962ceb": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 90000.0,
        "salary_max": 140000.0,
        "title": "Data Engineer",
        "company": "Sightline Climate",
        "desc": "CTVC (https://www.ctvc.co/) is the market intelligence platform for industry professionals navigating the evolving world of climate tech. We cover the go-to-market and capital flows of technologies and companies critical to decarbonization across energy, transportation, food & land use, industry, carbon, climate management, and the built environment. CTVC's data-driven insights are trusted by 60,000+ weekly readers and have been featured in channels including NYTimes, Bloomberg, Reuters, Financial Times, and TechCrunch. \n CTVC is looking for a passionate and entrepreneurial Data Engineer to join our data and product team. As a Data Engineer, you will design, develop and implement software solutions across our data and web stack, and play a crucial role in delivering insights into the new climate economy to investors, corporates, and governments mobilizing strategies in the climate transition. Our ideal candidate has a strong technical background and a willingness to \u201cwear many hats\u201d, learn new skills, and take the initiative to develop new features as needs arise. \n The Role \n \n Infrastructure \u2014 Develop and maintain our central database. This will include improving data input processes, maintaining our ETL pipeline, and expanding the functionality of our web backend. \n  Collection \u2014 Help us increase the speed and efficiency of data collection. This could include web scraping, natural language processing, and AI-enabled data transformation. \n  Analysis \u2014 Dig deeper into the data, providing insights to our research, editorial and customer success teams to demonstrate the power of our platform. \n \n The Essentials \n \n 2+ years experience as a Data Engineer, Software Engineer, Software Developer or equivalent \n  Experience in Python and PostgreSQL \n  A passion for addressing the climate crisis through high quality research and data \n  Interest in working for a fast-moving startup with a small, international team \n  A BSc degree in Computer Science, Engineering or other relevant field \n \n A Plus \n \n Experience using Django and/or DBT \n  Experience in machine learning / natural language processing \n  Experience with AWS (ECS, RDS, CloudFormation) \n  Experience working with Jira / Agile framework \n  Experience using Bitbucket Pipelines \n  Working understanding of climate tech sectors \n  Strong analytic skills related to working with unstructured datasets \n  A successful history of manipulating, processing and extracting value from datasets \n \n Our Offer \n \n Opportunity to work and learn at a fast-growing climate tech startup \n  Based in Washington D.C., London, or remote (US Eastern and Europe time zones) \n  Salary range $90,000\u2013$140,000 annual base \n  Generous stock options \n  Flexible working hours and PTO \n  Health coverage",
        "cleaned_desc": "CTVC (https://www.ctvc.co/) is the market intelligence platform for industry professionals navigating the evolving world of climate tech. We cover the go-to-market and capital flows of technologies and companies critical to decarbonization across energy, transportation, food & land use, industry, carbon, climate management, and the built environment. CTVC's data-driven insights are trusted by 60,000+ weekly readers and have been featured in channels including NYTimes, Bloomberg, Reuters, Financial Times, and TechCrunch. \n CTVC is looking for a passionate and entrepreneurial Data Engineer to join our data and product team. As a Data Engineer, you will design, develop and implement software solutions across our data and web stack, and play a crucial role in delivering insights into the new climate economy to investors, corporates, and governments mobilizing strategies in the climate transition. Our ideal candidate has a strong technical background and a willingness to \u201cwear many hats\u201d, learn new skills, and take the initiative to develop new features as needs arise. \n The Role \n \n Infrastructure \u2014 Develop and maintain our central database. This will include improving data input processes, maintaining our ETL pipeline, and expanding the functionality of our web backend. \n  Collection \u2014 Help us increase the speed and efficiency of data collection. This could include web scraping, natural language processing, and AI-enabled data transformation.    Analysis \u2014 Dig deeper into the data, providing insights to our research, editorial and customer success teams to demonstrate the power of our platform. \n \n The Essentials \n \n 2+ years experience as a Data Engineer, Software Engineer, Software Developer or equivalent \n  Experience in Python and PostgreSQL   Experience using Django and/or DBT \n  Experience in machine learning / natural language processing \n  Experience with AWS (ECS, RDS, CloudFormation) \n  Experience working with Jira / Agile framework \n  Experience using Bitbucket Pipelines \n  Working understanding of climate tech sectors ",
        "techs": [
            "ctvc",
            "ctvc's market intelligence platform",
            "energy",
            "transportation",
            "food & land use",
            "industry",
            "carbon",
            "climate management",
            "built environment",
            "ctvc's data-driven insights",
            "nytimes",
            "bloomberg",
            "reuters",
            "financial times",
            "techcrunch",
            "data engineer",
            "software solutions",
            "data input processes",
            "etl pipeline",
            "web backend",
            "web scraping",
            "natural language processing",
            "ai-enabled data transformation",
            "python",
            "postgresql",
            "django",
            "dbt",
            "machine learning",
            "aws (ecs",
            "rds",
            "cloudformation)",
            "jira",
            "agile framework",
            "bitbucket pipelines",
            "climate tech sectors."
        ],
        "cleaned_techs": [
            "ctvc",
            "ctvc's market intelligence platform",
            "energy",
            "transportation",
            "food & land use",
            "industry",
            "carbon",
            "climate management",
            "built environment",
            "ctvc's data-driven insights",
            "nytimes",
            "bloomberg",
            "reuters",
            "financial times",
            "techcrunch",
            "data engineer",
            "software solutions",
            "data input processes",
            "etl pipeline",
            "web backend",
            "web scraping",
            "nlp",
            "ai",
            "python",
            "postgresql",
            "django",
            "dbt",
            "aws",
            "rds",
            "cloudformation)",
            "jira",
            "agile framework",
            "bitbucket pipelines",
            "climate tech sectors."
        ]
    },
    "abf5152c511cedd5": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 155000.0,
        "salary_max": 185000.0,
        "title": "Data Engineer",
        "company": "Treez, Inc.",
        "desc": "Treez is not for everyone. Are you right for Treez?\n   \n  The company values at Treez are:\n  \n \n S tay Curious \n P resent Solutions \n E mbrace Simplicity \n E ncourage Candor \n D rive to Outcomes \n \n \n  With \n   SPEED , Treez team members are making an impact at our growing startup. We are motivated by our mission and do what it takes to get the job done. We need you to be as passionate as we are about making Treez the leader in powering the global cannabis economy. We are looking for hustlers, doers, people who see the goal and drive to it.\n   \n  We are seeking a skilled and experienced\n    Data Engineer / Architect  to join our dynamic team.\n   \n \n WHAT YOU WILL DO \n \n \n \n  As a\n    Data Engineer  at Treez you will be responsible for designing the data architecture for our organization. You will collaborate with and mentor cross-functional teams, including engineers, analysts, and business stakeholders, to ensure the integrity, availability, and security of our data assets. Your expertise in data modeling, database design, and data integration will play a vital role in driving data-driven decision-making and supporting our business objectives..\n   \n \n HOW YOU WILL DO IT \n \n \n Develop and maintain an enterprise-wide data architecture strategy that aligns with the organization's business goals and objectives. Define and implement data standards, principles, and guidelines for data modeling, database design, and data integration. \n Design and create logical and physical data models that meet the requirements of various business functions. Oversee the defining of data entities, relationships, attributes, and hierarchies to ensure data integrity and consistency across different systems and applications. \n Identify and design efficient data integration solutions to facilitate seamless near real time data flow between different systems and platforms. Develop strategies for data extraction, transformation, and loading, ensuring high data quality and reliability. \n Establish and enforce data governance policies and procedures to ensure compliance with regulatory requirements and industry best practices. Define data ownership, access controls, data retention policies, and data quality standards. \n Provide mentorship and guidance to engineers, and other team members. Share your expertise and knowledge to foster their professional growth and enhance their understanding of database design, SQL, query evaluation and performance tuning. \n Collaborate with cross-functional teams, including engineers, analysts, and business stakeholders, to understand data requirements and translate them into actionable data architecture solutions. Effectively communicate complex technical concepts to non-technical stakeholders. \n Stay abreast of industry trends, emerging technologies, and best practices in data architecture and management. Evaluate and recommend new tools and technologies to enhance data processing, analytics, and visualization capabilities. \n Create and maintain comprehensive documentation of data models, data flows, data dictionaries, and technical specifications. Ensure that documentation is up to date and accessible to relevant stakeholders. \n \n \n \n WHAT YOU WILL NEED \n \n Minimum 5+ years of software engineering experience \n Preferred 3+ as Data Engineer or Architect preferably at a SaaS software company. \n Strong understanding of data architecture principles, methodologies, and best practices. \n Proficiency in relational database management systems, particularly AWS RDS, Postgres, and MySQL. \n Experience with data integration technologies and ETL tools a plus \n In-depth knowledge of AWS data services such as AWS Redshift, AWS Athena, and AWS S3 a plus \n Understanding of data governance frameworks, data quality management, and data security practices. \n Strong analytical, problem-solving, and critical-thinking skills. \n Excellent communication and interpersonal skills to effectively collaborate with stakeholders at all levels. \n Ability to work independently and manage multiple priorities in a fast-paced environment. \n Bachelor's or Master's degree in Computer Science, Information Systems, or a related field. \n \n \n \n The anticipated compensation for this role is base salary of $155,000 to $185,000 USD depending upon a number of factors such as a candidate's qualifications, skills, competencies, work experience, geographic location, business needs and market demands. The base pay range is subject to change and may be modified in the future. \n \n \n \n \n BENEFITS THAT TREEPLE ENJOY \n \n \n A remote first work environment \n Medical, dental, vision and 401(K) - no match yet, we're a startup \n Equity \n \n COME AS YOU ARE \n  Treez continually strives to create a diverse and inclusive environment. Treez provides equal employment opportunities to all job applicants and employees and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\n    \n \n ABOUT TREEZ \n  Treez is the leading enterprise cloud commerce platform that streamlines retail and supply chain operations within the cannabis market. Through its innovative technology for retailers and brands, the company provides a robust breadth and depth of software solutions required to operate a successful modern dispensary.\n    \n  Solutions include point of sale, dispensary inventory management, omnichannel sales capabilities and multiple cashless payment options all on a mission-critical platform that ensures regulatory compliance across every supply chain transaction. The innovative platform also connects essential brands with their retailers through a centralized brand catalog with real-time market insights. The extensible open API platform provides smooth integration into a variety of best-of-breed solutions, including CRM, marketplace, cashless payments and data analytics across the partner ecosystem, giving retailers everything they need to grow their business.",
        "cleaned_desc": " Develop and maintain an enterprise-wide data architecture strategy that aligns with the organization's business goals and objectives. Define and implement data standards, principles, and guidelines for data modeling, database design, and data integration. \n Design and create logical and physical data models that meet the requirements of various business functions. Oversee the defining of data entities, relationships, attributes, and hierarchies to ensure data integrity and consistency across different systems and applications. \n Identify and design efficient data integration solutions to facilitate seamless near real time data flow between different systems and platforms. Develop strategies for data extraction, transformation, and loading, ensuring high data quality and reliability. \n Establish and enforce data governance policies and procedures to ensure compliance with regulatory requirements and industry best practices. Define data ownership, access controls, data retention policies, and data quality standards. \n Provide mentorship and guidance to engineers, and other team members. Share your expertise and knowledge to foster their professional growth and enhance their understanding of database design, SQL, query evaluation and performance tuning. \n Collaborate with cross-functional teams, including engineers, analysts, and business stakeholders, to understand data requirements and translate them into actionable data architecture solutions. Effectively communicate complex technical concepts to non-technical stakeholders. \n Stay abreast of industry trends, emerging technologies, and best practices in data architecture and management. Evaluate and recommend new tools and technologies to enhance data processing, analytics, and visualization capabilities. \n Create and maintain comprehensive documentation of data models, data flows, data dictionaries, and technical specifications. Ensure that documentation is up to date and accessible to relevant stakeholders. \n \n \n \n WHAT YOU WILL NEED \n \n Minimum 5+ years of software engineering experience \n Preferred 3+ as Data Engineer or Architect preferably at a SaaS software company.   Strong understanding of data architecture principles, methodologies, and best practices. \n Proficiency in relational database management systems, particularly AWS RDS, Postgres, and MySQL. \n Experience with data integration technologies and ETL tools a plus \n In-depth knowledge of AWS data services such as AWS Redshift, AWS Athena, and AWS S3 a plus \n Understanding of data governance frameworks, data quality management, and data security practices. \n Strong analytical, problem-solving, and critical-thinking skills. \n Excellent communication and interpersonal skills to effectively collaborate with stakeholders at all levels. \n Ability to work independently and manage multiple priorities in a fast-paced environment. \n Bachelor's or Master's degree in Computer Science, Information Systems, or a related field. \n \n \n \n The anticipated compensation for this role is base salary of $155,000 to $185,000 USD depending upon a number of factors such as a candidate's qualifications, skills, competencies, work experience, geographic location, business needs and market demands. The base pay range is subject to change and may be modified in the future. \n \n ",
        "techs": [
            "aws rds",
            "postgres",
            "mysql",
            "aws redshift",
            "aws athena",
            "aws s3",
            "etl tools"
        ],
        "cleaned_techs": [
            "aws",
            "postgres",
            "mysql",
            "etl tools"
        ]
    },
    "194fa06f606e662b": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 120254.445,
        "salary_max": 152268.92,
        "title": "Data Engineer",
        "company": "CareMetx",
        "desc": "Hey!\n   \n  Are YOU passionate about applying cutting-edge technology to improve the human experience? Are you passionate about fixing a broken healthcare system that is difficult to navigate, with barriers to access and afford life-changing medicine and treatment? Are you passionate about technical excellence and deploying software that makes people happier and healthier? If so, CareMetx wants you to be a part of our growing engineering team!\n   \n  At CareMetx, data teams own an outcome - that means teams are both accountable AND empowered for a unit of business value. We create an environment for learning opportunities and believe there is no such thing as \u201cthat\u2019s not my job.\u201d Our vision is to generate valuable insights from the data and drive strategic decision-making. All Caremetx data team members have the opportunity to explore new technologies and data trends. That means you will have the opportunity to grow deeper in the skills you\u2019re passionate about and expand your breadth by learning skills that will help the team succeed.\n   \n  As a Data engineer/analyst/scientist you will constantly deliver business value. You will also function as a catalyst for innovation and new ideas through creative problem-solving, elegant engineering, and the application of new technology and architectural patterns. You will help shape a performance-oriented learning culture by sharing your knowledge and skill depth within the team.\n   \n \n  Manage large data sets and model complex problems that impact patient outcomes. Discover insights and identify opportunities using statistical, algorithmic, mining, and visualization techniques.\n   \n \n  The core of the role is\u2026\n  \n \n Define and build an industry-standard pipeline and Data Warehouse for a variety of data sources (No SQL, Relational, Text) \n Enhance data collection procedures to include information that is relevant for building analytic systems \n Model front end and backend data sources to help draw a more comprehensive picture of user flows throughout our system and enable powerful data analysis \n Processing, cleansing, and verifying the integrity of data used for analysis. \n Performing ad-hoc analysis and presenting results in a clear manner \n Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed. \n Reformulating existing frameworks to optimize their functioning. \n Testing such structures to ensure that they are fit for use. \n Preparing raw data for manipulation by data scientists \n \n \n  Relevant experience\u2026\n  \n \n Degree(s) in Engineering, Computer Science, Math, Statistics, Economics, or related fields \n 5+ years of professional experience either in Big Data, Data Engineering, or Business Intelligence. This might include ETL, data warehousing, or data visualization. \n Experience with Talend is preferred \n Experience with API is preferred \n Understanding of CI/CD, data governance, and data quality framework (great expectations) is preferred \n 5+ years of hands-on experience applying principles, best practices, and trade-offs of schema design to various types of database systems: relational (Oracle, MSSQL, Postgres, MySQL), NoSQL (HBase, Cassandra, MongoDB), and in-memory (e.g., VoltDB). Understanding data manipulation principles. \n Deep understanding of NoSQL databases like MongoDB/Dynamo DB. \n Understanding of data flows, data architecture, ETL, Star vs Snowflake schema, and processing of structured and unstructured data \n Minimum 3 years of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala, etc.",
        "cleaned_desc": " \n Define and build an industry-standard pipeline and Data Warehouse for a variety of data sources (No SQL, Relational, Text) \n Enhance data collection procedures to include information that is relevant for building analytic systems \n Model front end and backend data sources to help draw a more comprehensive picture of user flows throughout our system and enable powerful data analysis \n Processing, cleansing, and verifying the integrity of data used for analysis. \n Performing ad-hoc analysis and presenting results in a clear manner \n Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.   \n Degree(s) in Engineering, Computer Science, Math, Statistics, Economics, or related fields \n 5+ years of professional experience either in Big Data, Data Engineering, or Business Intelligence. This might include ETL, data warehousing, or data visualization. \n Experience with Talend is preferred \n Experience with API is preferred \n Understanding of CI/CD, data governance, and data quality framework (great expectations) is preferred \n 5+ years of hands-on experience applying principles, best practices, and trade-offs of schema design to various types of database systems: relational (Oracle, MSSQL, Postgres, MySQL), NoSQL (HBase, Cassandra, MongoDB), and in-memory (e.g., VoltDB). Understanding data manipulation principles. ",
        "techs": [
            "talend",
            "api"
        ],
        "cleaned_techs": [
            "talend",
            "api"
        ]
    },
    "639ba1140f569f39": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 112830.49,
        "salary_max": 142868.55,
        "title": "Data Engineer",
        "company": "MatrixCare",
        "desc": "ResMed has always applied the best of technology to improve people's lives. Now our SaaS technology is fueling a new era in the healthcare industry, with dynamic systems that change the way people receive care in settings outside of the hospital\u2013and tools that work every day to help people stay well, longer. We have one of the largest actionable datasets in the industry, creating a complete view of people as they move between care settings. This is how we empower providers\u2013with vital insight to deliver the care people need, right when they need it.\n  \n \n \n   We're also ensuring that our health solutions connect to other companies' networks. Because when objectives align, everyone wins. And as we work today to drive better care and lower costs, we're developing more personalized solutions for tomorrow, utilizing machine learning, intelligent care paths, and predictive protocols. If you are an innovator who wants to make an impact we want to talk to you! We have exciting opportunities supporting Brightree by ResMed and MatrixCare by ResMed!\n  \n \n \n   We are looking for a savvy Data Engineer to join our growing team of platform experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams.\n  \n \n \n   You are an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The goal is to support our software developers, database architects, data analysts and data scientists on data initiatives to ensure optimal data delivery architecture is consistent throughout ongoing projects.\n  \n \n \n   You are self-directed and comfortable supporting the needs of multiple teams, systems and products. You are excited by the prospect of optimizing or even re-designing our company\u2019s data architecture to support our next generation of products and data initiatives. You are a team player who lifts the entire team through collaboration, mentoring and sharing your experience\n  \n \n \n   Location - Open for \"Remote\" across US\n  \n \n \n   Let's talk about the role\n  \n \n  Create and maintain optimal data pipeline architecture \n  Assemble large, complex data sets that meet functional / non-functional business requirements \n  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc \n  Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and AWS \u2018big data\u2019 technologies like Glue, Lambda, EMR etc \n  Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs \n  Keep our data separated and secure across national boundaries through multiple data centers and AWS regions \n  Work on data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. \n  Work with data and analytics experts to strive for greater functionality in our data systems \n \n \n \n   Let's talk about you\n  \n \n \n \n     Must have previous experience creating/running Python\n    \n  Excellent Python coding knowledge or Pyspark jobs working within AWS Glue \n  You will have 4+ years of total experience in a full cycle Data Engineer role, who has attained a graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field or equivalent working experience \n  Experience building and working with AWS Data Lakes \n  Experience working on GitHUB CI/CD processes \n  You will also be strong in \n  Experience with big data tools: Snowflake, Hadoop, Spark, Kafka, etc \n  Experience with data pipeline and workflow management tools: Luigi, Airflow, AWS Step etc \n  Experience with AWS cloud services: EMR, RDS, Redshift \n  Experience with DBT \\ Coalesce or other ELT tools \n  Experience with stream-processing systems: Kinesis, Spark-Streaming, etc \n  Experience with Docker Containers and Kubernetes \n  Familiarity with a variety of datasets, structured, semi structured and unstructured etc \n  Experience building and optimizing \u2018big data\u2019 data pipelines, architecture and data sets \n  Nice to have Experience with MS SQL Stack and SSIS \n  Strong analytic skills related to working with unstructured datasets \n  Build processes supporting data transformation, data structures, metadata, dependency and workload management \n  Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores \n  Experience supporting and working with cross-functional teams in a dynamic environment \n \n \n   #LI\n  \n \n   #LI-DG1\n  \n \n \n   Joining us is more than saying \u201cyes\u201d to making the world a healthier place. It\u2019s discovering a career that\u2019s challenging, supportive and inspiring. Where a culture driven by excellence helps you not only meet your goals, but also create new ones. We focus on creating a diverse and inclusive culture, encouraging individual expression in the workplace and thrive on the innovative ideas this generates. If this sounds like the workplace for you, apply now!",
        "cleaned_desc": "  Assemble large, complex data sets that meet functional / non-functional business requirements \n  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc \n  Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and AWS \u2018big data\u2019 technologies like Glue, Lambda, EMR etc \n  Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs \n  Keep our data separated and secure across national boundaries through multiple data centers and AWS regions \n  Work on data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. \n  Work with data and analytics experts to strive for greater functionality in our data systems \n \n \n \n   Let's talk about you\n  \n \n   \n     Must have previous experience creating/running Python\n    \n  Excellent Python coding knowledge or Pyspark jobs working within AWS Glue \n  You will have 4+ years of total experience in a full cycle Data Engineer role, who has attained a graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field or equivalent working experience \n  Experience building and working with AWS Data Lakes \n  Experience working on GitHUB CI/CD processes \n  You will also be strong in \n  Experience with big data tools: Snowflake, Hadoop, Spark, Kafka, etc \n  Experience with data pipeline and workflow management tools: Luigi, Airflow, AWS Step etc \n  Experience with AWS cloud services: EMR, RDS, Redshift \n  Experience with DBT \\ Coalesce or other ELT tools \n  Experience with stream-processing systems: Kinesis, Spark-Streaming, etc \n  Experience with Docker Containers and Kubernetes    Familiarity with a variety of datasets, structured, semi structured and unstructured etc \n  Experience building and optimizing \u2018big data\u2019 data pipelines, architecture and data sets \n  Nice to have Experience with MS SQL Stack and SSIS \n  Strong analytic skills related to working with unstructured datasets \n  Build processes supporting data transformation, data structures, metadata, dependency and workload management \n  Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores \n  Experience supporting and working with cross-functional teams in a dynamic environment \n \n \n   #LI\n  \n \n   #LI-DG1\n  ",
        "techs": [
            "python",
            "glue",
            "lambda",
            "emr",
            "aws",
            "snowflake",
            "hadoop",
            "spark",
            "kafka",
            "luigi",
            "airflow",
            "aws step",
            "emr",
            "rds",
            "redshift",
            "dbt",
            "coalesce",
            "kinesis",
            "spark-streaming",
            "docker containers",
            "kubernetes",
            "ms sql",
            "ssis"
        ],
        "cleaned_techs": [
            "python",
            "glue",
            "lambda",
            "emr",
            "aws",
            "snowflake",
            "hadoop",
            "spark",
            "kafka",
            "luigi",
            "airflow",
            "rds",
            "redshift",
            "dbt",
            "coalesce",
            "kinesis",
            "spark-streaming",
            "docker containers",
            "kubernetes",
            "ms sql",
            "ssis"
        ]
    },
    "2aed0a61d3e1971f": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 115657.9,
        "salary_max": 146448.67,
        "title": "Data Engineer",
        "company": "Brightree",
        "desc": "ResMed has always applied the best of technology to improve people's lives. Now our SaaS technology is fueling a new era in the healthcare industry, with dynamic systems that change the way people receive care in settings outside of the hospital\u2013and tools that work every day to help people stay well, longer. We have one of the largest actionable datasets in the industry, creating a complete view of people as they move between care settings. This is how we empower providers\u2013with vital insight to deliver the care people need, right when they need it.\n  \n \n \n   We're also ensuring that our health solutions connect to other companies' networks. Because when objectives align, everyone wins. And as we work today to drive better care and lower costs, we're developing more personalized solutions for tomorrow, utilizing machine learning, intelligent care paths, and predictive protocols. If you are an innovator who wants to make an impact we want to talk to you! We have exciting opportunities supporting Brightree by ResMed and MatrixCare by ResMed!\n  \n \n \n   We are looking for a savvy Data Engineer to join our growing team of platform experts. You will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams.\n  \n \n \n   You are an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The goal is to support our software developers, database architects, data analysts and data scientists on data initiatives to ensure optimal data delivery architecture is consistent throughout ongoing projects.\n  \n \n \n   You are self-directed and comfortable supporting the needs of multiple teams, systems and products. You are excited by the prospect of optimizing or even re-designing our company\u2019s data architecture to support our next generation of products and data initiatives. You are a team player who lifts the entire team through collaboration, mentoring and sharing your experience\n  \n \n \n   Location - Open for \"Remote\" across US\n  \n \n \n   Let's talk about the role\n  \n \n  Create and maintain optimal data pipeline architecture \n  Assemble large, complex data sets that meet functional / non-functional business requirements \n  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc \n  Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and AWS \u2018big data\u2019 technologies like Glue, Lambda, EMR etc \n  Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs \n  Keep our data separated and secure across national boundaries through multiple data centers and AWS regions \n  Work on data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. \n  Work with data and analytics experts to strive for greater functionality in our data systems \n \n \n \n   Let's talk about you\n  \n \n \n \n     Must have previous experience creating/running Python\n    \n  Excellent Python coding knowledge or Pyspark jobs working within AWS Glue \n  You will have 4+ years of total experience in a full cycle Data Engineer role, who has attained a graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field or equivalent working experience \n  Experience building and working with AWS Data Lakes \n  Experience working on GitHUB CI/CD processes \n  You will also be strong in \n  Experience with big data tools: Snowflake, Hadoop, Spark, Kafka, etc \n  Experience with data pipeline and workflow management tools: Luigi, Airflow, AWS Step etc \n  Experience with AWS cloud services: EMR, RDS, Redshift \n  Experience with DBT \\ Coalesce or other ELT tools \n  Experience with stream-processing systems: Kinesis, Spark-Streaming, etc \n  Experience with Docker Containers and Kubernetes \n  Familiarity with a variety of datasets, structured, semi structured and unstructured etc \n  Experience building and optimizing \u2018big data\u2019 data pipelines, architecture and data sets \n  Nice to have Experience with MS SQL Stack and SSIS \n  Strong analytic skills related to working with unstructured datasets \n  Build processes supporting data transformation, data structures, metadata, dependency and workload management \n  Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores \n  Experience supporting and working with cross-functional teams in a dynamic environment \n \n \n   #LI\n  \n \n   #LI-DG1\n  \n \n \n   Joining us is more than saying \u201cyes\u201d to making the world a healthier place. It\u2019s discovering a career that\u2019s challenging, supportive and inspiring. Where a culture driven by excellence helps you not only meet your goals, but also create new ones. We focus on creating a diverse and inclusive culture, encouraging individual expression in the workplace and thrive on the innovative ideas this generates. If this sounds like the workplace for you, apply now!",
        "cleaned_desc": "  Assemble large, complex data sets that meet functional / non-functional business requirements \n  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc \n  Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and AWS \u2018big data\u2019 technologies like Glue, Lambda, EMR etc \n  Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs \n  Keep our data separated and secure across national boundaries through multiple data centers and AWS regions \n  Work on data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. \n  Work with data and analytics experts to strive for greater functionality in our data systems \n \n \n \n   Let's talk about you\n  \n \n   \n     Must have previous experience creating/running Python\n    \n  Excellent Python coding knowledge or Pyspark jobs working within AWS Glue \n  You will have 4+ years of total experience in a full cycle Data Engineer role, who has attained a graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field or equivalent working experience \n  Experience building and working with AWS Data Lakes \n  Experience working on GitHUB CI/CD processes \n  You will also be strong in \n  Experience with big data tools: Snowflake, Hadoop, Spark, Kafka, etc \n  Experience with data pipeline and workflow management tools: Luigi, Airflow, AWS Step etc \n  Experience with AWS cloud services: EMR, RDS, Redshift \n  Experience with DBT \\ Coalesce or other ELT tools \n  Experience with stream-processing systems: Kinesis, Spark-Streaming, etc \n  Experience with Docker Containers and Kubernetes    Familiarity with a variety of datasets, structured, semi structured and unstructured etc \n  Experience building and optimizing \u2018big data\u2019 data pipelines, architecture and data sets \n  Nice to have Experience with MS SQL Stack and SSIS \n  Strong analytic skills related to working with unstructured datasets \n  Build processes supporting data transformation, data structures, metadata, dependency and workload management \n  Working knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores \n  Experience supporting and working with cross-functional teams in a dynamic environment \n \n \n   #LI\n  \n \n   #LI-DG1\n  ",
        "techs": [
            "python",
            "aws glue",
            "lambda",
            "emr",
            "aws data lakes",
            "snowflake",
            "hadoop",
            "spark",
            "kafka",
            "luigi",
            "airflow",
            "aws step",
            "emr",
            "rds",
            "redshift",
            "dbt",
            "coalesce",
            "kinesis",
            "spark-streaming",
            "docker containers",
            "kubernetes",
            "ms sql stack",
            "ssis"
        ],
        "cleaned_techs": [
            "python",
            "aws",
            "lambda",
            "emr",
            "snowflake",
            "hadoop",
            "spark",
            "kafka",
            "luigi",
            "airflow",
            "rds",
            "redshift",
            "dbt",
            "coalesce",
            "kinesis",
            "spark-streaming",
            "docker containers",
            "kubernetes",
            "ms sql stack",
            "ssis"
        ]
    },
    "2839aaf2f9e74a3a": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 85.0,
        "salary_max": 85.0,
        "title": "Data Engineer",
        "company": "BayOne",
        "desc": "Client :  Compass \n \n \n Location :  Remote \n \n \n Rate :  $ 85 an hour. \n \n \n Data Engineer : \n  Below are the must and good to have technical skills of an ideal candidate. \n \n  Strong Python programming (Must) \n \n  Strong on SQL & Database concepts (Must) \n \n  Strong on AWS - IAM, S3, EC2, EMR, Lambda, Cloud Watch etc. (Must) \n \n  Good to have Airflow experience. If the candidate does not have Apache Airflow experience, he/she needs to learn the same very quickly with minimum guidance. \n \n  Having Databricks experience would be great. However the candidate should be open to learn Databricks with minimum guidance. \n \n \n Soft skills: \n  Good in performing analysis and problem solving \n \n  Should be able to troubleshoot any production/staging issues and come up with root cause analysis along with the code/configuration fix \n \n  Should be open to learn new technologies as and when needed",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "8fab726b8a2eba63": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 103728.914,
        "salary_max": 131343.92,
        "title": "Data Engineer",
        "company": "Watts Water Technologies",
        "desc": "The Watts Water Technologies family of companies designs and manufactures valves and drains and related products that promote the comfort and safety of people and the quality, conservation and control of water used in commercial, residential, industrial, and municipal applications. Everything we design is made to keep the Earth's most precious resource safer, cleaner, and more useful for our customers.\n  \n \n \n   We are looking for a Data Engineer to join the Watts Digital team. In this role, you will have the opportunity to build a next generation data platform that serves digital solutions and other teams within Watts. You will be responsible for designing, developing, and maintaining our data architecture, ensuring the availability and reliability of data for various business functions. You will work with key stakeholders to apply data analytics, models, and techniques to assist in realizing the value of data. You will architect and implement scalable ETL pipelines that contribute to a centralized data repository leveraging data lake architecture. As a valued technical leader, you will be responsible for ensuring our technology decisions align and scale with our architectural north star. You will directly contribute to a culture of excellence in Watts Digital\u2019s growing engineering organization and be a pivotal member in enhancing our engineering standards and processes.\n  \n \n \n   You Will:\n  \n \n \n   Technical Implementation and Architecture\n  \n \n \n \n     Design, implement, and own ETL pipelines and data lakehouse architecture across Watts digital solutions\n    \n \n \n     Build large-scale batch and real-time data pipelines with data processing frameworks like Spark and Databricks\n    \n \n \n     Utilize optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources into a central Watts data repository that supports varying use-cases\n    \n \n \n     Work closely with Watts business units and engineering teams to develop a strategy for long term data platform architecture which will be efficient, reliable and scalable\n    \n \n \n     Lead and contribute to technical architecture discussions and driving technical decisions across engineering teams\n    \n \n \n     Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way\n    \n \n \n     Communicate technology decisions and outcomes to key stakeholders (e.g. sponsors, partners, product teams)\n    \n \n \n     Determine and implement a security model based on privacy requirements; addressing data quality issues, and evolving governance processes within allocated areas of ownership\n    \n \n \n     Ensure that the systems we develop and maintain result in highly scalable, feature-rich solutions that minimize support costs and deliver value to customers\n    \n \n \n     Develop and maintain solution architecture diagrams and documentation\n    \n \n \n     Advise and support the team on selection and implementation of modern technologies including languages, open-source and third-party tools to increase efficiency and improve technology and product offerings\n    \n \n \n \n   Execution, Product Delivery and Results\n  \n \n \n \n     Lead the architecture and delivery of scalable ETL pipelines and data stores\n    \n \n \n     Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts\n    \n \n \n     Enable streamlining our data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models\n    \n \n \n     Clean, prepare and optimize data at scale for ingestion and consumption\n    \n \n \n     Working closely with other Engineers, Quality Assurance, Operations, and 3rd party vendors to successfully deliver and deploy solutions to production\n    \n \n \n     Define and manage SLA for all data sets\n    \n \n \n     Identify and implement the right analytical libraries, programming languages, and frameworks for each task\n    \n \n \n     Advocate a continuous improvement mindset regarding our development process, with a focus on how we can automate regular, high-quality, releases in an agile environment\n    \n \n \n     Continuously rebalancing features, which maximize value and minimize effort to focus on the highest returning initiatives for business and customer\n    \n \n \n     Champion a culture of learning, measurement, accountability, and quality via code reviews, paired programming, and other collaboration opportunities with the team\n    \n \n \n     Collaborate with Product Owners on the backlog and providing high level effort estimation to plan feature prioritization more accurately and development\n    \n \n \n \n   BUs, Operations, IT, Information Security and Infrastructure\n  \n \n \n \n     Partner with hardware BUs to understand their needs and deliver platform-oriented solutions\n    \n \n \n     Continuing to evolve security practices and controls to meet the needs of protecting customer data\n    \n \n \n     Champion a culture of compliance as it pertains to data to meet legal, regulatory, and operational data requirements\n    \n \n \n     Partner with IT and operations in support of enterprise IT strategy\n    \n \n \n     Ensure we are building necessary observability into our systems that provide transparency across the entire data architecture stack\n    \n \n \n     Work with engineering teams and assisting Customer Success and Operations team in triaging and resolving production issues\n    \n \n \n   You Have:\n  \n \n \n \n     Bachelor\u2019s degree in computer science, information technology, engineering, or related discipline\n    \n \n \n     3+ years of experience with ETL technologies\n    \n \n \n     3+ years experience with Databricks, specifically within Azure\n    \n \n \n     3+ years of experience with Python, Scala, .NET, Java or similar languages\n    \n \n \n     5+ years of SQL experience (No-SQL experience is a plus)\n    \n \n \n     3+ years of experience with schema design and dimensional data modeling\n    \n \n \n     Proven ability around managing and communicating data roadmap plans to internal stakeholders\n    \n \n \n     Excellent product strategic thinking and communication to influence product and cross-functional teams by identifying data opportunities that drive impact\n    \n \n \n     Experience designing, building and maintaining data processing systems\n    \n \n \n     Deep understanding of software engineering practices (e.g. Agile software development, test driven development, unit testing, code reviews, design documentation, etc.)\n    \n \n \n     An entrepreneurial spirit that is flexible, experimental, and resourceful\n    \n \n \n \n   What\u2019s In It For You:\n  \n \n People-First Culture \u2013 Enriching and caring for people is at the core of who we are; this includes our Diversity, Equity, and Inclusion (DEI) strategy, and providing our employees with meaningful career growth opportunities, a positive and safe work environment, and affirmation that they are heard, valued, and respected. \n 401K Plan \n Flexible PTO & Generous Paid Holidays \n Educational Assistance \n Variety of Medical plan options \u2013 choose the one that is right for you! \n Sustainability \u2013 One of Newsweek\u2019s Top 400 of \u201cAmerica\u2019s Most Responsible Companies\u201d for sustainability performance, three years running. \n \n \n \n   PHYSICAL REQUIREMENTS:\n  \n \n   While performing the responsibilities of this job, the employee is frequently required to walk, talk, and/or hear. The employee is occasionally required to stand, sit, and use hands to finger, handle, or feel. You must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include: close vision, color vision, peripheral vision, depth perception and ability to adjust focus.\n  \n \n \n   WORK ENVIRONMENT:\n  \n \n   Work in both office and manufacturing environment. May occasionally be required to perform job responsibilities outside the typical office setting.\n  \n \n   #LI-Remote\n  \n  Watts is committed to equal employment opportunity. We follow a policy of administering all employment decisions and personnel actions without regard to race, color, religion, creed, sex, pregnancy, national origin, sexual orientation, age, physical or mental disability, genetic disposition or carrier status, marital status, military or veteran status, minorities, or any other category protected under applicable federal, state, or local law. Consistent with the obligations of state and federal law, Watts will make reasonable accommodations for qualified individuals with disabilities. Any employee who needs a reasonable accommodation should contact Human Resources.\n  \n   #LI-Remote",
        "cleaned_desc": "The Watts Water Technologies family of companies designs and manufactures valves and drains and related products that promote the comfort and safety of people and the quality, conservation and control of water used in commercial, residential, industrial, and municipal applications. Everything we design is made to keep the Earth's most precious resource safer, cleaner, and more useful for our customers.\n  \n \n \n   We are looking for a Data Engineer to join the Watts Digital team. In this role, you will have the opportunity to build a next generation data platform that serves digital solutions and other teams within Watts. You will be responsible for designing, developing, and maintaining our data architecture, ensuring the availability and reliability of data for various business functions. You will work with key stakeholders to apply data analytics, models, and techniques to assist in realizing the value of data. You will architect and implement scalable ETL pipelines that contribute to a centralized data repository leveraging data lake architecture. As a valued technical leader, you will be responsible for ensuring our technology decisions align and scale with our architectural north star. You will directly contribute to a culture of excellence in Watts Digital\u2019s growing engineering organization and be a pivotal member in enhancing our engineering standards and processes.\n  \n \n \n   You Will:\n  \n \n \n   Technical Implementation and Architecture\n  \n \n \n \n     Design, implement, and own ETL pipelines and data lakehouse architecture across Watts digital solutions\n    \n \n \n     Build large-scale batch and real-time data pipelines with data processing frameworks like Spark and Databricks\n    \n \n \n     Utilize optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources into a central Watts data repository that supports varying use-cases\n    \n \n \n     Work closely with Watts business units and engineering teams to develop a strategy for long term data platform architecture which will be efficient, reliable and scalable\n    \n \n \n     Lead and contribute to technical architecture discussions and driving technical decisions across engineering teams\n    \n \n \n     Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way\n    \n \n \n     Communicate technology decisions and outcomes to key stakeholders (e.g. sponsors, partners, product teams)\n    \n   \n     Determine and implement a security model based on privacy requirements; addressing data quality issues, and evolving governance processes within allocated areas of ownership\n    \n \n \n     Ensure that the systems we develop and maintain result in highly scalable, feature-rich solutions that minimize support costs and deliver value to customers\n    \n \n \n     Develop and maintain solution architecture diagrams and documentation\n    \n \n \n     Advise and support the team on selection and implementation of modern technologies including languages, open-source and third-party tools to increase efficiency and improve technology and product offerings\n    \n \n \n \n   Execution, Product Delivery and Results\n  \n \n \n \n     Lead the architecture and delivery of scalable ETL pipelines and data stores\n    \n \n \n     Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts\n    \n \n \n     Enable streamlining our data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models\n    \n \n \n     Clean, prepare and optimize data at scale for ingestion and consumption\n    \n \n \n     Working closely with other Engineers, Quality Assurance, Operations, and 3rd party vendors to successfully deliver and deploy solutions to production\n    \n \n \n     Define and manage SLA for all data sets     \n \n \n     Identify and implement the right analytical libraries, programming languages, and frameworks for each task\n    \n \n \n     Advocate a continuous improvement mindset regarding our development process, with a focus on how we can automate regular, high-quality, releases in an agile environment\n    \n \n \n     Continuously rebalancing features, which maximize value and minimize effort to focus on the highest returning initiatives for business and customer\n    \n \n \n     Champion a culture of learning, measurement, accountability, and quality via code reviews, paired programming, and other collaboration opportunities with the team\n    \n \n \n     Collaborate with Product Owners on the backlog and providing high level effort estimation to plan feature prioritization more accurately and development\n    \n \n \n \n   BUs, Operations, IT, Information Security and Infrastructure\n  \n \n \n \n     Partner with hardware BUs to understand their needs and deliver platform-oriented solutions\n    \n \n \n     Continuing to evolve security practices and controls to meet the needs of protecting customer data\n    \n \n \n     Champion a culture of compliance as it pertains to data to meet legal, regulatory, and operational data requirements\n    \n \n \n     Partner with IT and operations in support of enterprise IT strategy\n    \n   \n     Ensure we are building necessary observability into our systems that provide transparency across the entire data architecture stack\n    \n \n \n     Work with engineering teams and assisting Customer Success and Operations team in triaging and resolving production issues\n    \n \n \n   You Have:\n  \n \n \n \n     Bachelor\u2019s degree in computer science, information technology, engineering, or related discipline\n    \n \n \n     3+ years of experience with ETL technologies\n    \n \n \n     3+ years experience with Databricks, specifically within Azure\n    \n \n \n     3+ years of experience with Python, Scala, .NET, Java or similar languages\n    \n \n \n     5+ years of SQL experience (No-SQL experience is a plus)\n    \n \n \n     3+ years of experience with schema design and dimensional data modeling\n    \n \n \n     Proven ability around managing and communicating data roadmap plans to internal stakeholders\n    \n \n \n     Excellent product strategic thinking and communication to influence product and cross-functional teams by identifying data opportunities that drive impact\n    ",
        "techs": [
            "spark",
            "databricks",
            "etl",
            "data lakehouse architecture",
            "structured data sources",
            "unstructured data sources",
            "data repository",
            "data analytics",
            "data insights",
            "security model",
            "solution architecture diagrams",
            "modern technologies",
            "sla",
            "analytical libraries",
            "programming languages",
            "frameworks",
            "continuous improvement",
            "code reviews",
            "compliance",
            "observability",
            "production issues",
            "etl technologies",
            "databricks",
            "azure",
            "python",
            "scala",
            ".net",
            "java",
            "sql",
            "no-sql",
            "schema design",
            "dimensional data modeling",
            "data roadmap plans."
        ],
        "cleaned_techs": [
            "spark",
            "databricks",
            "etl",
            "data lakehouse architecture",
            "structured data sources",
            "unstructured data sources",
            "data repository",
            "data analytics",
            "data insights",
            "solution architecture diagrams",
            "modern technologies",
            "sla",
            "analytical libraries",
            "programming languages",
            "frameworks",
            "continuous improvement",
            "code reviews",
            "compliance",
            "observability",
            "production issues",
            "etl technologies",
            "azure",
            "python",
            "scala",
            ".net",
            "java",
            "sql",
            "no-sql",
            "schema design",
            "dimensional data modeling",
            "data roadmap plans."
        ]
    },
    "330baf0395d8b25c": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 120826.12,
        "salary_max": 152992.78,
        "title": "BI Data Engineer",
        "company": "Publishing.com",
        "desc": "BI Data Engineer \n  Full-Time \n \n  DEPARTMENT:   Software \n  REPORTS TO:   Head of Engineering \n \n  About Publishing.com \n  Publishing.com has helped thousands of normal everyday people to become successful self-published authors. And along the way, we also became one the most successful companies in the US (#19 on the Inc. 5000). \n  Want to be at the forefront of the AI revolution? Join us! We are building the most comprehensive AI-powered self-publishing platform and you get to join us at ground zero. Instead of just teaching people how to create successful books, we are going to help them do it. \n \n  About you \n  You are a data engineer with strong analytical skills and hands-on experience with modern data warehousing and business intelligence solutions. You know how to use code and no-code to ingest data from various sources, how to interpret data and translate it into business insight, and how to prepare reports and dashboards that are easy to understand and digest. \n  And you have a great attitude! \n  About this role \n  As our first data engineer, you will have the opportunity to make important contributions to various aspects of our data platform. Your main responsibilities are \n \n  Build a highly scalable data warehouse \n  Propose, design, and implement data ingestion pipelines (ELT/ETL) \n  Maintain our local and cloud data platforms \n  Understand and interpret business intelligence requirements and translate them into technical solutions \n  Build business analytics and dashboards to address sales and marketing needs \n \n  Required skills \n \n  Strong problem solving skills \n  Strong communication skills \n  Strong SQL skills \n  Expert in using data warehousing solutions such as BigQuery, Snowflake, or Databricks \n  Experience with data ingestion services such as Fivetran, Matilion, Segment, or similar \n  Experience with Google Sheets \n  Experience with business analytics for marketing and sales \n  Strong programming skills in JavaScript and Python \n  Experience with HubSpot \n  Experience with Git \n  Experience with agile development \n  Experience working with marketing and sales teams \n  Strong sense of ownership \n \n \n  Preferred Skills \n \n  Experience with Google Clouds \n  Experience building CI/CD pipelines \n  Experience with AWS, Azure, or GCP \n  Experience with Terraform or other IaC solutions \n  Experience with DevOps and SRE best practices \n \n  Why Publishing.com? \n \n  People love working here and your peers are great - check out our glassdoor reviews \n  We are growing (fast!) Ranked #19 on the Inc 5000 for Fastest Growing Private Companies in America for 2023. \n  We are located all over the world with 60+ employees. We were remote before remote was a thing! And we will continue to be. \n  Last year we hit $60M in revenue, and we are just getting started! \n  We have all the fun perks you\u2019d expect\u2014flexible vacation policy, competitive vision, dental, and health benefits, 401k plans, and socials (yes, even remotely!)* \n  We are proud of our culture and care about it deeply\u2014we live by our team values and are always trying to make Publishing.com a better company today than it was yesterday \n  We encourage learning, growth, and continuous improvement so always looking for ways to help our staff grow. From monthly training to hiring mentors, we care about your personal growth! \n  If you want to join a team on the ground floor, this is your chance. We have a grand vision for expanding beyond just an education company to become the one-stop shop for everything publishing related. \n \n \n \n  Some benefits are available to our US-based employees only. \n \n \n  Publishing.com is dedicated to building diverse teams that fuel an authentic workplace and sense of belonging for each and every employee. We know applying for a job can be intimidating, please don't hesitate to reach out - we encourage everyone interested in joining us to apply. \n \n  Publishing.com Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, disability, genetics, gender, sexual orientation, age, marital status, veteran status. In addition to federal law requirements, Publishing.com Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location we have employees in. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. \n \n \n \n \n Publishing.com is dedicated to building diverse teams that fuel an authentic workplace and sense of belonging for each and every employee. We know applying for a job can be intimidating, please don't hesitate to reach out - we encourage everyone interested in joining us to apply. \n Publishing.com LLC. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, disability, genetics, gender, sexual orientation, age, marital status, veteran status. In addition to federal law requirements, Publishing.com LLC. complies with applicable state and local laws governing nondiscrimination in employment in every location we have employees in. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. \n   \n eUT95FbkXw",
        "cleaned_desc": "  As our first data engineer, you will have the opportunity to make important contributions to various aspects of our data platform. Your main responsibilities are \n \n  Build a highly scalable data warehouse \n  Propose, design, and implement data ingestion pipelines (ELT/ETL) \n  Maintain our local and cloud data platforms \n  Understand and interpret business intelligence requirements and translate them into technical solutions \n  Build business analytics and dashboards to address sales and marketing needs \n \n  Required skills \n \n  Strong problem solving skills \n  Strong communication skills \n  Strong SQL skills \n  Expert in using data warehousing solutions such as BigQuery, Snowflake, or Databricks    Experience with data ingestion services such as Fivetran, Matilion, Segment, or similar \n  Experience with Google Sheets \n  Experience with business analytics for marketing and sales \n  Strong programming skills in JavaScript and Python \n  Experience with HubSpot \n  Experience with Git \n  Experience with agile development \n  Experience working with marketing and sales teams \n  Strong sense of ownership \n \n \n  Preferred Skills \n \n  Experience with Google Clouds ",
        "techs": [
            "bigquery",
            "snowflake",
            "databricks",
            "fivetran",
            "matillion",
            "segment",
            "google sheets",
            "javascript",
            "python",
            "hubspot",
            "git",
            "agile development",
            "google clouds"
        ],
        "cleaned_techs": [
            "bigquery",
            "snowflake",
            "databricks",
            "fivetran",
            "matillion",
            "segment",
            "google sheets",
            "javascript",
            "python",
            "hubspot",
            "git",
            "agile development",
            "google clouds"
        ]
    },
    "254acf610d040335": {
        "terms": [
            "data engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Data Quality Engineer",
        "company": "Vibrant Emotional Health",
        "desc": "Job Title: Data Quality Engineer \n \n \n Department: Information Technology \n \n \n Reports to: Data Governance Lead \n \n \n Salary Range: $80,000-$92,000 \n \n \n Location: Remote \n \n \n Schedule: M-F, 9-5 ET \n \n \n \n Formerly the Mental Health Association of New York City (MHA-NYC), Vibrant Emotional Health\u2019s groundbreaking solutions have delivered high quality services and support, when, where and how people need it for over 50 years. Through our state-of-the-art technology-enabled services, community wellness programs, and advocacy and education work, we are building a society in which emotional wellness can be a reality for everyone. \n \n \n \n Position Overview: \n \n \n \n  The Data Quality (DQ) Engineer designs, develops, documents and performs data quality checks across all data assets. The DQ Engineer stays informed of leading practices, emerging tools and technologies and enterprise initiatives to provide ongoing improvements and recommendations for data quality maintenance, including data profiling and cleansing.\n  \n \n \n  This role is the \u201cfirst line of defense\u201d protecting the quality of data and serves as a liaison between the business and technical stakeholders to ensure functional data needs are supported by a technical quality framework.\n  \n \n \n Duties/Responsibilities: \n \n \n Establish metrics and build Data Quality dashboards \n Collaborate with stakeholders to understand use cases and recommend proactive/ reactive business rules to address data integrity issues \n Recommend technology and process updates to improve quality and system performance. \n Develop technical design for data profiling, cleansing and quality maintenance. \n Develop models to monitor data quality and recommend remediations steps. \n Create alerts for various levels of data integrity disruptions. \n Perform assessments and model updates for new data sources and pipelines. \n Monitor Data Quality dashboards. \n Resolve service tickets related to data quality. \n Perform root cause analysis, anomaly detection. \n Monitor inbound data for new data elements to map. \n Participate in mapping and migration testing. \n \n \n \n Required Skills/Abilities: \n \n \n SQL. \n R, Python. \n Tableau, and one other BI analytics tool. \n Strong data analysis background. \n Experience with industry data quality dimensions and best practices. \n Can operate effectively within ambiguity. \n Familiar with Agile development. \n Ideally has ML/AI experience \n \n \n \n Required Qualifications: \n \n \n 1+ year of experience in a data quality role in a medium to large size organization. \n Experience working on data governance issues concerning health data and with government partners a plus. \n Bachelors\u2019 or Masters\u2019 Degree in analytics focused discipline or equivalent experience and knowledge. \n \n \n \n  Excellent comprehensive benefits, including medical, dental, vision, supplemental income insurance, pre-tax transit/parking, pre-tax FSA for medical and dependent care, and 401K available. 4 weeks\u2019 vacation, plum benefits, etc.\n  \n \n \n Studies have shown that women and people of color are less likely to apply for jobs unless they believe they are able to perform every task in the job description. We are most interested in finding the best candidate for the job, and that candidate may be one who come from a less traditional background. Vibrant will consider any equivalent combination of knowledge, skills, education and experience to meet minimum qualifications. If you are interested in applying, we encourage you to think broadly about your background and skill set for the role. \n \n  Vibrant Emotional Health is an equal opportunity employer. Applicants are considered for positions without regard to veteran status, uniformed service member status, race, creed, color, religion, gender, gender identity, sex, sexual orientation, citizenship status, national origin, marital status, age, physical or mental disability, genetic information, caregiver status or any other category protected by applicable federal, state or local laws.\n  \n \n \n \"Please be aware that fictitious job openings, consulting engagements, solicitations, or employment offers may be circulated on the Internet in an attempt to obtain privileged information, or to induce you to pay a fee for services related to recruitment or training. Vibrant does NOT charge any application, processing, or training fee at any stage of the recruitment or hiring process. All genuine job openings will be posted on our careers page and all communications from the Vibrant recruiting team and/or hiring managers will be from an @vibrant.org email address\"",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "1ba8ebaffbed8893": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105000.0,
        "salary_max": 160000.0,
        "title": "Data Engineer",
        "company": "New York Life Insurance Co",
        "desc": "Location Designation:  Hybrid \n \n  When you join New York Life, you\u2019re joining a company that values career development, collaboration, innovation, and inclusiveness. We want employees to feel proud about being part of a company that is committed to doing the right thing. You\u2019ll have the opportunity to grow your career while developing personally and professionally through various resources and programs. New York Life is a relationship-based company and appreciates how both virtual and in-person interactions support our culture. \n \n  The Senior Insights Data Engineer must be passionate about digging into data and understanding the stories the data are telling. You will be equally passionate about helping others solve problems, gain insights, and make decisions using data. You will work to solidify, enhance and support our data quality, analytics and dashboards/reports. \n \n Actively partner with Corporate Data Strategy and Governance and other Corporate Technology divisions to design and implement solutions for extraction and integration of data to and from data warehouses, data marts and data lakes for the purposes of reporting, decision support and driving insights. \n Identify, investigate, and resolve data discrepancies by finding the root cause of issues; work with partners across various cross-functional teams to prevent future occurrences. \n Proactively look for opportunities to optimize the data loading structure and develop new approaches to improve the onboarding and integrity of the data. \n Provide basic reporting and respond to inquiries asking for insights about the data sets from stakeholders, in a timely fashion thru data. \n Ensure that data is clean, consistent and synchronized across platforms as you oversee the design and implantation of data cleansing procedures. \n Represent area on projects, be a key player in meetings with all levels of management. \n Act as a mentor to team members and the Foundational Business on all technical issues. \n \n  Experience: \n \n Proficient knowledge of SQL \n Experience working with Redshift and Hadoop. \n Ability to interpret data to help in strategic decision making. \n Excellent problem-solving and critical thinking skills required \n Ability to clearly articulate and present ideas both in writing and verbally to all levels within NYLife \n Experience manipulating large data sets leveraging tools such as Python & R \n Knowledge of the ETL process \n Solid proficiency in all Microsoft Office applications; expert Excel skills \n Expertise in doing Root Cause Analysis and resolving performance bottlenecks \n Professional, positive demeanor \n \n \n  #LI - EM1 \n  #LI - REMOTE \n \n  Salary range:  $105,000-$160,000 \n  Overtime eligible:  Exempt \n  Discretionary bonus eligible:  Yes \n  Sales bonus eligible:  No \n \n  Click here to learn more about our benefits. Starting salary is dependent upon several factors including previous work experience, specific industry experience, and/or skills required. \n \n  Recognized as one of  Fortune\u2019s  World\u2019s Most Admired Companies, New York Life is committed to improving local communities through a culture of employee giving and volunteerism, supported by the Foundation. We're proud that due to our mutuality, we operate in the best interests of our policy owners. We invite you to bring your talents to New York Life, so we can continue to help families and businesses \u201cBe Good At Life.\u201d To learn more, please visit LinkedIn, our Newsroom and the Careers page of www.NewYorkLife.com. \n  Job Requisition ID: 89657",
        "cleaned_desc": "  Experience: \n \n Proficient knowledge of SQL \n Experience working with Redshift and Hadoop. \n Ability to interpret data to help in strategic decision making. \n Excellent problem-solving and critical thinking skills required \n Ability to clearly articulate and present ideas both in writing and verbally to all levels within NYLife ",
        "techs": [
            "sql",
            "redshift",
            "hadoop"
        ],
        "cleaned_techs": [
            "sql",
            "redshift",
            "hadoop"
        ]
    },
    "4ae4425749af96e4": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 121587.66,
        "salary_max": 153957.06,
        "title": "AWS Data Engineer",
        "company": "Arraya Solutions",
        "desc": "Arraya Solutions, a leading Mid-Atlantic technology consulting firm located just outside Philadelphia, is looking for an  AWS Data Engineer  to join our team! \n ***Prospective candidates must be in Eastern or Central Time Zone and much be able to be employed as a W2 employee*** \n We are a culture that embraces change, values family and are actively involved with the community. Our team consists of people with positive attitudes who are interested in growing their knowledge around technology and leaders that are heavily involved in day-to-day activities. \n Job Summary \n The Data Engineering Team is a part of the Modeling and Data Sciences technology organization. This team supports key initiatives and improves the competitiveness and operational efficiencies in our existing and next-generation offerings by developing digital solutions and technologies in condition monitoring, reliability/risk modeling, dynamic modeling, IIoT, and new technology development & evaluation. This team works in close collaboration with the Engineering, Technology, and Operational teams to deliver competitive world-leading solutions. The position will be on the technical ladder where the incumbent will be provided with learning and advancement opportunities focusing on long-term career growth and success. \n Essential Job Responsibilities : \n \n Design and implement data and analytics solutions leveraging Cloud native capabilities and using AWS services such as S3, Glue, Lambda, EMR, and Redshift \n Engineer AI/ML components to scale and integrate them into the larger ecosystem on Cloud or on Premise \n Develop efficient data pipelines for AWS Cloud using Native Tools. \n Migrate to AWS Data Cloud, implement data solutions, and integrate with existing platforms. \n Collaborate with cross-functional teams for effective data management \n Establish and communicate fit-for-purpose analytical platforms for business prototypes \n Act as the proactive and technical architect point person for the data platform end-to-end \n Lead innovation by exploring, investigating, recommending, benchmarking, and implementing data-centric technologies for the platform \n Collaborate with project teams to solve complex problems and work in a dynamic environment \n Coach and mentor peers, as well as mentor less experienced team members \n Operate as part of the extended management team \n Possess excellent communication, presentation, articulation, and relationship-building skills \n \n Job Requirements (Education/Skills/Experience) \n \n The ability to obtain and maintain a security clearance \n A minimum of four (4) years of experience in architecting, designing, and implementing data and analytics solutions in at least one cloud platform \n A good understanding of Cloud Data & Analytics solutions using native and 3rd party solutions \n At least 5 years of experience in AWS Cloud ecosystem, R, Python, SQL database technologies \n At least 3 years of hands-on experience in working on AWS Redshift for DWH Development as Architect \n Good understanding of Data integration, Data Quality and data architecture \n Experience in data modeling including logical and physical data models, advanced working SQL knowledge, and experience working with relational databases \n Experience with query authoring (SQL) and working familiarity with a variety of databases \n Strong knowledge of AWS services, including S3, Glue, Lambda, EMR, and Redshift \n Ability to design solutions leveraging Cloud native capabilities \n Excellent communication, presentation, articulation, and relationship-building skills \n Experience in leading and mentoring team members \n Ability to work in a dynamic environment and solve complex problems \n \n Job Types: Full-time, Contract \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Work Location: Remote",
        "cleaned_desc": " Engineer AI/ML components to scale and integrate them into the larger ecosystem on Cloud or on Premise \n Develop efficient data pipelines for AWS Cloud using Native Tools. \n Migrate to AWS Data Cloud, implement data solutions, and integrate with existing platforms. \n Collaborate with cross-functional teams for effective data management \n Establish and communicate fit-for-purpose analytical platforms for business prototypes \n Act as the proactive and technical architect point person for the data platform end-to-end \n Lead innovation by exploring, investigating, recommending, benchmarking, and implementing data-centric technologies for the platform \n Collaborate with project teams to solve complex problems and work in a dynamic environment   Coach and mentor peers, as well as mentor less experienced team members \n Operate as part of the extended management team \n Possess excellent communication, presentation, articulation, and relationship-building skills \n \n Job Requirements (Education/Skills/Experience) \n \n The ability to obtain and maintain a security clearance \n A minimum of four (4) years of experience in architecting, designing, and implementing data and analytics solutions in at least one cloud platform   A good understanding of Cloud Data & Analytics solutions using native and 3rd party solutions \n At least 5 years of experience in AWS Cloud ecosystem, R, Python, SQL database technologies \n At least 3 years of hands-on experience in working on AWS Redshift for DWH Development as Architect \n Good understanding of Data integration, Data Quality and data architecture \n Experience in data modeling including logical and physical data models, advanced working SQL knowledge, and experience working with relational databases \n Experience with query authoring (SQL) and working familiarity with a variety of databases \n Strong knowledge of AWS services, including S3, Glue, Lambda, EMR, and Redshift \n Ability to design solutions leveraging Cloud native capabilities ",
        "techs": [
            "engineer ai/ml components",
            "integrate them into the larger ecosystem on cloud or on premise",
            "develop efficient data pipelines for aws cloud",
            "migrate to aws data cloud",
            "implement data solutions",
            "integrate with existing platforms",
            "establish and communicate fit-for-purpose analytical platforms",
            "act as the proactive and technical architect point person for the data platform",
            "lead innovation",
            "collaborate with project teams",
            "coach and mentor peers",
            "operate as part of the extended management team",
            "obtain and maintain a security clearance",
            "architect",
            "design",
            "and implement data and analytics solutions",
            "understand cloud data & analytics solutions",
            "have experience in aws cloud ecosystem",
            "r",
            "python",
            "sql database technologies",
            "hands-on experience in working on aws redshift for dwh development as architect",
            "understand data integration",
            "data quality",
            "and data architecture",
            "have experience in data modeling",
            "sql knowledge",
            "relational databases",
            "query authoring (sql)",
            "working familiarity with a variety of databases",
            "knowledge of aws services including s3",
            "glue",
            "lambda",
            "emr",
            "and redshift",
            "ability to design solutions leveraging cloud native capabilities."
        ],
        "cleaned_techs": [
            "engineer ai/ml components",
            "integrate them into the larger ecosystem on cloud or on premise",
            "develop efficient data pipelines for aws cloud",
            "migrate to aws data cloud",
            "implement data solutions",
            "integrate with existing platforms",
            "establish and communicate fit-for-purpose analytical platforms",
            "act as the proactive and technical architect point person for the data platform",
            "lead innovation",
            "coach and mentor peers",
            "operate as part of the extended management team",
            "architect",
            "design",
            "and implement data and analytics solutions",
            "understand cloud data & analytics solutions",
            "have experience in aws cloud ecosystem",
            "r",
            "python",
            "sql",
            "hands-on experience in working on aws redshift for dwh development as architect",
            "understand data integration",
            "data quality",
            "and data architecture",
            "have experience in data modeling",
            "relational databases",
            "query authoring (sql)",
            "working familiarity with a variety of databases",
            "knowledge of aws services including s3",
            "glue",
            "lambda",
            "emr",
            "and redshift"
        ]
    },
    "bab2bfb7542fc4af": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 88266.234,
        "salary_max": 111764.72,
        "title": "Data Analysis/Tableau Engineer II",
        "company": "TeleWorld Solutions Inc",
        "desc": "Overview: \n  \n  TeleWorld Solutions  is seeking a \n   Data Analysis/Tableau Engineer II  to serve as a Business Intelligence Architect and will be responsible for building highly interactive, customizable Tableau reports for large datasets and maps. In this role, you will blend data to create powerful dashboards, create action filters, parameters, and calculations for preparing dashboards and worksheets in Tableau. You will also design and implement processes and standards to aid in report development and support.\n  \n \n \n  Come join our Team. The Company with Great Benefits and recently certified as \"A Great Place to Work\" \n  Responsibilities: \n  \n Design and create data visualizations (reports and dashboards) as required to support business needs \n  Analyze, define requirements, develop, and create documentation for dashboards \n  Champion dashboard quality, consistency, usability, and reliability by documenting and applying best practices to design and development \n  Communicate project status updates and recommendations \n  Inserting GIS information and maps into reports \n  Configure, optimize, and maintain Tableau Server and clients \n  Define, execute, and interpret SQL queries \n  Establish standards and best practices for requesting, prioritizing, and developing dashboards \n  Collaborate with technical staff and end users to understand and troubleshoot platform issues and develop appropriate solutions \n  Qualifications:\n  \n \n \n  Minimum of 3+ years of demonstrated hands-on development experience with Tableau \n  Tableau dashboard designer experience \n  Writing level of detail expressions in tableau \n  Experience with tableau dashboard publishing \n  Creating automate routine to update dashboards regularly \n  Working with data connection from Snowflake database \n  Mid level SQL query within snowflake input stream for tableau visualization requirement. \n  Strong understanding of data modeling based on specifications \n  Strong analytical skills to solve and model complex business requirements \n  Testing including unit, integration, and performance experience \n  Proven analytical, problem-solving, time management and organizational skills \n  Strong communication, presentation, and collaboration skills \n  Bachelor's degree in Computer Science or equivalent \n \n \n \n  TeleWorld Solutions is an EEO employer and gives consideration to qualified applicants in regard to race, age, religion, sex, sexual orientation, gender identity, national origin, veteran status, pregnancy or genetic information.",
        "cleaned_desc": "  Working with data connection from Snowflake database \n  Mid level SQL query within snowflake input stream for tableau visualization requirement. \n  Strong understanding of data modeling based on specifications \n  Strong analytical skills to solve and model complex business requirements \n  Testing including unit, integration, and performance experience \n  Proven analytical, problem-solving, time management and organizational skills \n  Strong communication, presentation, and collaboration skills ",
        "techs": [
            "snowflake database",
            "sql",
            "tableau",
            "data modeling",
            "analytical skills",
            "testing",
            "unit testing",
            "integration testing",
            "performance testing",
            "analytical skills",
            "problem-solving skills",
            "time management skills",
            "organizational skills",
            "communication skills",
            "presentation skills",
            "collaboration skills"
        ],
        "cleaned_techs": [
            "snowflake database",
            "sql",
            "tableau",
            "testing",
            "unit testing",
            "integration testing",
            "performance testing"
        ]
    },
    "eb96e976839a8adc": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 116877.64,
        "salary_max": 147993.14,
        "title": "Data Platform Engineer",
        "company": "SRS Acquiom",
        "desc": "About SRS Acquiom \n  SRS Acquiom is a leading disruptor in the financial services technology space with a long track record of consistent growth, profitability, and innovation. Since the Company was founded in 2007, they have had a tremendous impact on how Mergers and Acquisitions (M&A) and Loan Agency transactions are completed globally. Today, SRS Acquiom offers a comprehensive suite of services that include virtual data rooms, escrow, payment administration, shareholder representation, and administrative and collateral agent. This world-class platform has become the go-to solution for many of the world's largest and most successful companies as they manage and simplify complex transactions in the global M&A and Loan Agency markets. \n  In the 15 years since the Company was founded, SRS has supported more than 7,400+ deals with $775B in aggregate value including high-profile transactions such as Coca Cola Corporation's acquisition of Body Armor, Pfizer's acquisition of ReViral Limited, and Intel's acquisition of Granulate Cloud Solutions. In the same time, they've added a blue-chip private equity ownership base, and today they boast an impressive investor base, including Foundry, NorWest, Revolutions, and LMP. \n  We are looking for extraordinary people to help drive our continued success. If you are looking to join a growing, entrepreneurial environment in an established company, we want to hear from you! \n  Data Platform Engineer Position Summary \n  We are growing our Platform Engineering team and are looking to add a Data Engineer that will be able to help build our internal data platform. This data platform is central to ensure that our software development and data analytics teams have governed access to the data they need. As a Data Engineer on the Platform Team, you will be a part of driving the design, development, and implementation of our data platforms. Your responsibilities include partnering with architect and engineering teams in developing our platform as well as providing best practices and approaches to ensure security, resiliency, and availability of solutions. You will be challenged to create strategies that ensure the secure consumption of the platform through continuous innovation, simplification, and self-service automation. \n  The salary range for this position is between $111,000k - $124,000k, depending on level of experience. \n  This position can be fully remote. \n  Data Platform Engineer Primary Responsibilities \n \n Participate in all initiatives keeping all compliance, security and regulatory needs satisfied \n Be a thought leader by staying abreast of current and emerging technologies and industry trends. \n Work with your peers to design and build data platform capabilities and incorporate the necessary automations and tool configurations that ensure agile delivery and secure consumption \n Design and implement processes and tools that enable product engineering and BI/Analytics teams to consume an extensible and scalable data platform which enforces all needed governance and consistent operational models \n Be a trusted advisor for initiatives by providing objective, practical, and relevant ideas, insights, and advice while also building organizational partnerships and networks to ensure comprehensive capabilities are developed with input from appropriate business and Engineering resources \n Directly support the use and delivery of data platform services in the organization \n Ensure that all data platform solutions follow established security and compliance controls \n Maintain existing and future software services code and configuration \n Make recommendations for improvements to existing architecture \n Help implement new technologies for future deployment \n Provide technical guidance, knowledge transfers, and mentorship to clients on their data platform adoption \n Help implement and improve development of data pipelines \n Other duties as assigned \n \n Data Platform Engineer Required Qualifications & Skills \n \n B.S. in Computer Science or equivalent experience \n 2+ years of experience with and strong working knowledge of SQL required and understanding of data models is preferred \n 2+ years of experience with or strong knowledge of Postgresql, MySQL, or other relational database design and programming required: stored procedures, functions, PL/pgSQL a plus \n Experience with or working knowledge of managing AWS Data Infrastructure strongly preferred: S3, RDS, Managed Streaming Kafka, Lake Formation, Glue, Glue Data Catalog, Athena, Quicksight, DataZone \n Experience with systems engineering and/or software development preferred: Java, Javascript, Python, PHP \n Experience with cloud solution design patterns preferred: CI/CD, Docker, Kubernetes, containers, microservices, distributed caching \n Experience with Terraform scripting is preferred \n Experience with data integrations from third party platforms preferred: Netsuite, Salesforce, Workday, Pendo \n Experience with reporting and analytic tools a plus: Grafana, Kibana, Elasticsearch, Open Telemetry \n Experience with ETL processes, project, and tooling a plus: Boomi \n Experience with modern API platform design, security practices, and data architectures a plus: event driven architecture, change data capture, pub/sub \n Understanding of systems hardening and secure systems configuration a plus \n Experience with regulatory compliance standards as plus: HIPAA, PCI, SEC. FINRA \n Excellent written and verbal communication skills, with the ability to present complex technical information in a clear and concise manner to a variety of audiences \n Must understand Agile methodologies \n \n Data Platform Engineer Desired Characteristics \n \n Self-motivated \n Intellectually curious \n Collaborative \n Amiable \n Operates with highest integrity and attention to detail \n Passionate about efficient, scalable business processes \n Ability to prioritize and multi-task across many projects \n \n Data Platform Engineer Physical Requirements/Special Demands \n \n Must be available to work standard business hours, and occasional nights/weekends. \n \n A few benefits our employees enjoy \n \n Comprehensive benefit plans (medical/dental/vision) starting on day 1 \n 401(k) with 4% matching \n Discretionary time off \n Discretionary bonus incentive \n Fitness credit \n Several pre-tax plans (dependent care, transportation, flexible spending) \n Transportation reimbursement for qualified positions \n Benefits reimbursement \n \n This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee. Duties, responsibilities and activities may change, or new ones may be assigned at any time with or without advanced notice. \n  With respect to its programs, services, activities, and employment practices, SRS Acquiom Inc. assesses qualified individuals without regard to their race, color, religion, sex (including pregnancy, sexual orientation, or gender identity), age, national origin, disability, veteran status, genetic information, or other protected status. Requests for reasonable accommodation or the provision of auxiliary aids should be directed to Human Resources.",
        "cleaned_desc": "About SRS Acquiom \n  SRS Acquiom is a leading disruptor in the financial services technology space with a long track record of consistent growth, profitability, and innovation. Since the Company was founded in 2007, they have had a tremendous impact on how Mergers and Acquisitions (M&A) and Loan Agency transactions are completed globally. Today, SRS Acquiom offers a comprehensive suite of services that include virtual data rooms, escrow, payment administration, shareholder representation, and administrative and collateral agent. This world-class platform has become the go-to solution for many of the world's largest and most successful companies as they manage and simplify complex transactions in the global M&A and Loan Agency markets. \n  In the 15 years since the Company was founded, SRS has supported more than 7,400+ deals with $775B in aggregate value including high-profile transactions such as Coca Cola Corporation's acquisition of Body Armor, Pfizer's acquisition of ReViral Limited, and Intel's acquisition of Granulate Cloud Solutions. In the same time, they've added a blue-chip private equity ownership base, and today they boast an impressive investor base, including Foundry, NorWest, Revolutions, and LMP. \n  We are looking for extraordinary people to help drive our continued success. If you are looking to join a growing, entrepreneurial environment in an established company, we want to hear from you! \n  Data Platform Engineer Position Summary \n  We are growing our Platform Engineering team and are looking to add a Data Engineer that will be able to help build our internal data platform. This data platform is central to ensure that our software development and data analytics teams have governed access to the data they need. As a Data Engineer on the Platform Team, you will be a part of driving the design, development, and implementation of our data platforms. Your responsibilities include partnering with architect and engineering teams in developing our platform as well as providing best practices and approaches to ensure security, resiliency, and availability of solutions. You will be challenged to create strategies that ensure the secure consumption of the platform through continuous innovation, simplification, and self-service automation. \n  The salary range for this position is between $111,000k - $124,000k, depending on level of experience. \n  This position can be fully remote. \n  Data Platform Engineer Primary Responsibilities \n \n Participate in all initiatives keeping all compliance, security and regulatory needs satisfied \n Be a thought leader by staying abreast of current and emerging technologies and industry trends. \n Work with your peers to design and build data platform capabilities and incorporate the necessary automations and tool configurations that ensure agile delivery and secure consumption   Design and implement processes and tools that enable product engineering and BI/Analytics teams to consume an extensible and scalable data platform which enforces all needed governance and consistent operational models \n Be a trusted advisor for initiatives by providing objective, practical, and relevant ideas, insights, and advice while also building organizational partnerships and networks to ensure comprehensive capabilities are developed with input from appropriate business and Engineering resources \n Directly support the use and delivery of data platform services in the organization \n Ensure that all data platform solutions follow established security and compliance controls \n Maintain existing and future software services code and configuration \n Make recommendations for improvements to existing architecture \n Help implement new technologies for future deployment \n Provide technical guidance, knowledge transfers, and mentorship to clients on their data platform adoption \n Help implement and improve development of data pipelines \n Other duties as assigned \n \n Data Platform Engineer Required Qualifications & Skills \n   B.S. in Computer Science or equivalent experience \n 2+ years of experience with and strong working knowledge of SQL required and understanding of data models is preferred \n 2+ years of experience with or strong knowledge of Postgresql, MySQL, or other relational database design and programming required: stored procedures, functions, PL/pgSQL a plus \n Experience with or working knowledge of managing AWS Data Infrastructure strongly preferred: S3, RDS, Managed Streaming Kafka, Lake Formation, Glue, Glue Data Catalog, Athena, Quicksight, DataZone \n Experience with systems engineering and/or software development preferred: Java, Javascript, Python, PHP \n Experience with cloud solution design patterns preferred: CI/CD, Docker, Kubernetes, containers, microservices, distributed caching \n Experience with Terraform scripting is preferred \n Experience with data integrations from third party platforms preferred: Netsuite, Salesforce, Workday, Pendo \n Experience with reporting and analytic tools a plus: Grafana, Kibana, Elasticsearch, Open Telemetry \n Experience with ETL processes, project, and tooling a plus: Boomi \n Experience with modern API platform design, security practices, and data architectures a plus: event driven architecture, change data capture, pub/sub \n Understanding of systems hardening and secure systems configuration a plus \n Experience with regulatory compliance standards as plus: HIPAA, PCI, SEC. FINRA   Excellent written and verbal communication skills, with the ability to present complex technical information in a clear and concise manner to a variety of audiences \n Must understand Agile methodologies \n \n Data Platform Engineer Desired Characteristics \n \n Self-motivated \n Intellectually curious \n Collaborative \n Amiable \n Operates with highest integrity and attention to detail \n Passionate about efficient, scalable business processes \n Ability to prioritize and multi-task across many projects \n ",
        "techs": [
            "srs acquiom",
            "mergers and acquisitions (m&a)",
            "loan agency",
            "virtual data rooms",
            "escrow",
            "payment administration",
            "shareholder representation",
            "administrative agent",
            "collateral agent",
            "coca cola corporation",
            "body armor",
            "pfizer",
            "reviral limited",
            "intel",
            "granulate cloud solutions",
            "foundry",
            "norwest",
            "revolutions",
            "lmp",
            "data platform engineer",
            "data platform",
            "software development",
            "data analytics",
            "architect",
            "security",
            "resiliency",
            "availability",
            "compliance",
            "regulatory",
            "thought leader",
            "automations",
            "tool configurations",
            "agile delivery",
            "governance",
            "operational models",
            "organizational partnerships",
            "aws data infrastructure",
            "s3",
            "rds",
            "managed streaming kafka",
            "lake formation",
            "glue",
            "glue data catalog",
            "athena",
            "quicksight",
            "datazone",
            "systems engineering",
            "software development",
            "java",
            "javascript",
            "python",
            "php",
            "cloud solution design patterns",
            "ci/cd",
            "docker",
            "kubernetes",
            "containers",
            "microservices",
            "distributed caching",
            "terraform scripting",
            "data integrations",
            "netsuite",
            "salesforce",
            "workday",
            "pendo",
            "reporting tools",
            "analytic tools",
            "grafana",
            "kibana",
            "elasticsearch",
            "open telemetry",
            "etl processes",
            "boomi",
            "api platform design",
            "security practices",
            "data architectures",
            "event driven architecture",
            "change data capture",
            "pub/sub",
            "systems hardening",
            "secure systems configuration",
            "regulatory compliance standards",
            "hipaa",
            "pci",
            "sec",
            "finra",
            "agile methodologies."
        ],
        "cleaned_techs": [
            "srs acquiom",
            "mergers and acquisitions (m&a)",
            "loan agency",
            "virtual data rooms",
            "escrow",
            "payment administration",
            "shareholder representation",
            "administrative agent",
            "collateral agent",
            "coca cola corporation",
            "body armor",
            "pfizer",
            "reviral limited",
            "intel",
            "granulate cloud solutions",
            "foundry",
            "norwest",
            "revolutions",
            "lmp",
            "data platform engineer",
            "data platform",
            "software development",
            "data analytics",
            "architect",
            "resiliency",
            "availability",
            "compliance",
            "thought leader",
            "automations",
            "tool configurations",
            "agile delivery",
            "governance",
            "operational models",
            "organizational partnerships",
            "aws",
            "s3",
            "rds",
            "managed streaming kafka",
            "lake formation",
            "glue",
            "glue data catalog",
            "athena",
            "quicksight",
            "datazone",
            "systems engineering",
            "java",
            "javascript",
            "python",
            "php",
            "cloud solution design patterns",
            "ci/cd",
            "docker",
            "kubernetes",
            "containers",
            "microservices",
            "distributed caching",
            "terraform scripting",
            "data integrations",
            "netsuite",
            "salesforce",
            "workday",
            "pendo",
            "reporting tools",
            "analytic tools",
            "grafana",
            "kibana",
            "elasticsearch",
            "open telemetry",
            "etl processes",
            "boomi",
            "api platform design",
            "data architectures",
            "event driven architecture",
            "change data capture",
            "pub/sub",
            "systems hardening",
            "secure systems configuration",
            "hipaa",
            "pci",
            "sec",
            "finra",
            "agile methodologies."
        ]
    },
    "bd952fd05489e558": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 120000.0,
        "salary_max": 150000.0,
        "title": "Data Engineer",
        "company": "Pomelo Care",
        "desc": "About us \n  Pomelo Care is a multi-disciplinary team of clinicians, engineers and problem solvers who are passionate about improving care for moms and babies. We are transforming outcomes for pregnant people and babies with evidence-based pregnancy and newborn care at scale. Our technology-driven care platform enables us to engage patients early, conduct individualized risk assessments for poor pregnancy outcomes, and deliver coordinated, personalized virtual care throughout pregnancy, NICU stays, and the first postpartum year. We measure ourselves by reductions in preterm births, NICU admissions, c-sections and maternal mortality; we improve outcomes and reduce healthcare spend. \n \n  What you'll do \n  Trustworthy, actionable data plays a critical role in Pomelo's mission to improve pregnancy outcomes. Real-time insights empower our clinicians to focus their time efficiently and deliver outstanding care to our patients. As a data engineer, you will \n \n Build and orchestrate pipelines to ingest and harmonize data from many sources \n Collaborate on the design and improvement of our data infrastructure \n Partner with product managers and data scientists to turn raw data into actionable insights \n Photoshop custom slack emojis to express new feelings that aren't yet part of our library \n \n Who you are \n  You're an enthusiastic and collaborative problem-solver who is comfortable with ambiguity and enjoys finding patterns to bring order to chaos. You have a nose for value and proactively identify problems that have a big impact on the business. You have a passion for using technology to effect real, tangible good in the world. In particular, you have: \n \n A bachelors, masters or PhD in computer science or a related field \n At least two years of experience in a data engineering role building systems in a fast-paced environment \n Proficiency in Python and SQL or similar languages \n Have experience developing and maintaining data pipelines in a production setting \n Knowledge of visualization tools such as Metabase or Jupyter Notebooks  Enjoy tackling complex problems \n   - but strive to avoid unnecessary complexity \n \n We'll be super excited if you: \n \n Have experience with dbt and orchestration platforms like Dagster or Airflow \n Have developed distributed data processing systems (ex. Spark or Beam) against heterogeneous data sets \n Have experience at an early stage startup \n Are motivated by our mission to improve pregnancy outcomes \n \n Why you should join our team \n  By joining Pomelo, you will get in on the ground floor of a fast-moving, well-funded, and mission-driven startup that always puts the patient first. You will learn, grow and be challenged - and have fun with your team while doing it. \n  We strive to create an environment where employees from all backgrounds are respected. We also offer: \n \n Competitive healthcare benefits \n Generous equity compensation \n Unlimited vacation \n Membership in the First Round Network (a curated and confidential community with events, guides, thousands of Q&A questions, and opportunities for 1-1 mentorship) \n \n At Pomelo, we are committed to hiring the best team to improve outcomes for all mothers and babies, regardless of their background. We need diverse perspectives to reflect the diversity of problems we face and the population we serve. We look to hire people from a variety of backgrounds, including but not limited to race, age, sexual orientation, gender identity and expression, national origin, religion, disability, and veteran status. \n  Our salary ranges are based on paying competitively for our company's size and industry, and are one part of the total compensation package that also includes equity, benefits, and other opportunities at Pomelo Care. In accordance with New York City, Colorado, California, and other applicable laws, Pomelo Care is required to provide a reasonable estimate of the compensation range for this role. Individual pay decisions are ultimately based on a number of factors, including qualifications for the role, experience level, skillset, geography, and balancing internal equity. Given that this role is open to candidates of different skill levels, determining a salary range is challenging. A reasonable estimate of the current salary range is $120,000 to $150,000. We expect most candidates to fall in the middle of the range. We also believe that your personal needs and preferences should be taken into consideration, so we allow some choice between equity and cash. \n  #LI-Remote",
        "cleaned_desc": " A bachelors, masters or PhD in computer science or a related field \n At least two years of experience in a data engineering role building systems in a fast-paced environment \n Proficiency in Python and SQL or similar languages \n Have experience developing and maintaining data pipelines in a production setting \n Knowledge of visualization tools such as Metabase or Jupyter Notebooks  Enjoy tackling complex problems \n   - but strive to avoid unnecessary complexity \n ",
        "techs": [
            "python",
            "sql",
            "metabase",
            "jupyter notebooks"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "metabase",
            "jupyter notebooks"
        ]
    },
    "d69885858ca83ee7": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 100000.0,
        "title": "Data Engineer (Azure + AWS)",
        "company": "Rise Technical Recruitment Limited",
        "desc": "Data Engineer (Azure + AWS)  \n \n $100,000 + 401k + PTO + Medical + Dental + Vision \n \n New York - Fully Remote \n \n  Are you a Data Engineer looking for an exciting new opportunity where you will progress in your technical skills while growing in your career? \n  \n  On offer is an exciting opportunity to join an innovative health tech development team. You'll be at the forefront of expanding and optimizing their data infrastructure, playing a vital role in transforming healthcare with cutting-edge technology.\n  \n  This company is at the pinnacle of revolutionizing healthcare with data-driven solutions. You'll create and maintain data pipeline architecture, work with big data technologies while collaborating with your team enabling them to leverage data effectively.\n  \n  This role would suit an experienced Data Engineer looking for a chance to advance their career in data engineering, expand on their technical knowledge and be part of a team to transform technology based healthcare.\n  \n \n The Person \n \n \n 3+ Years Experience in Data Engineering \n Vast experience using SQL, Azure, Python and AWS \n Knowledge with Data warehouse, Data tools and creating ETL pipelines \n Experience working in healthcare \n Degree in Computer Science \n Great Communicator and team player \n \n \n The Role \n \n \n Develop and maintain data pipelines, including ETL. \n Automate tasks, optimize data delivery, and build scalable data infrastructure using SQL and AWS.  \n Construct analytics tools for actionable insights by collaborating with cross-functional teams.  \n Ensure data security, develop data tools for analytics, and enhance data system functionality.",
        "cleaned_desc": " 3+ Years Experience in Data Engineering \n Vast experience using SQL, Azure, Python and AWS \n Knowledge with Data warehouse, Data tools and creating ETL pipelines \n Experience working in healthcare \n Degree in Computer Science \n Great Communicator and team player ",
        "techs": [
            "sql",
            "azure",
            "python",
            "aws",
            "data warehouse",
            "etl pipelines"
        ],
        "cleaned_techs": [
            "sql",
            "azure",
            "python",
            "aws",
            "data warehouse",
            "etl pipelines"
        ]
    },
    "4ef7e779357efcd8": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 87700.0,
        "salary_max": 155000.0,
        "title": "AWS Cloud Data Engineer & Delivery (REMOTE)",
        "company": "Lincoln Financial",
        "desc": "Date:  Oct 25, 2023  \n Primary Location:  Radnor, PA, US  \n Company:  Lincoln Financial  \n \n \n Alternate Locations:  Work from Home\n   \n \n \n \n Work Arrangement: \n \n \n   Hybrid/Flexible : Work at home and use the office as appropriate for in-person collaboration.\n   \n \n \n \n Relocation assistance:  is not available for this opportunity.\n   \n \n \n \n Requisition #:  72250\n   \n \n \n \n \n \n \n  The Role at a Glance \n \n \n \n \n \n \n      This role will provide subject matter expertise and direction on complex projects/initiatives related to the configuration of systems and across operations for LFD IT data in applicable system(s). They will collaborate with business and IT teams and other stakeholders to understand data warehouse design and will focus on maintaining and improving our data environment, as well as providing expertise on system functionality to accommodate requirements. They will configure applicable system(s) when appropriate to provided required capabilities.\n       \n  This position will consult/analyze, design, and build on data assignments/projects for your assigned area(s) of application design responsibility to build out a data transformation through ETL on AWS to integrate with number of upstream and downstream applications.\n       \n \n \n \n \n \n \n What you'll be doing \n \n \n \n \n \n \n Participates in analysis, design, and build solution as part of Agile / Scrum Develop Team. \n Implement and support large data initiatives for the enterprise (using AWS PostgreSQL, Redshift, Glue and Python to further these objectives). \n Understands data mapping and data modeling methodologies including normal form, star, and snowflake to reduce data redundancy and improve data integrity. \n Consult with internal Lincoln business partners on requirements, design, testing and production topics to create solution proposals and develop code. \n Performs technical tasks including estimating, analysis, technical requirements, design, build and unit & integration testing following SDLC. \n Assist analytical teams with the design and implementation of Data solutions and systems, including integration with Operational Datastores and Data Warehouses, both on-premises and in the Cloud. \n Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assesses the impact, and collaborates with Scrum Team and Leadership to incorporate new trends and developments in current and future solutions. \n Participates and enhances organizational initiatives by positively influencing and supporting change management and/or departmental/enterprise initiatives within assigned area(s) of responsibility. \n Identifies and directs the implementation of process improvements that significantly improve quality across the team, department and/or business unit for his/her assigned area(s) of responsibility. \n Provides expertise to team members and applicable internal/external stakeholders on complex assignments/projects for his/her assigned area(s) of responsibility. \n Assists on complex assignments, projects, and/or initiatives to build and enhance the capability of his/her assigned area(s) of responsibility. \n Coordinate and release management activities the functions of (continuous integration/continuous delivery) Pipeline and is responsible in creating and maintaining automated CICD build and release pipelines using GitLab DevOps. \n \n \n \n \n \n \n \n \n \n What we\u2019re looking for \n \n \n \n \n \n \n 4 Year/bachelor\u2019s degree or equivalent work experience (4 years of experience in lieu of Bachelors) _Minimum Required in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience. \n 3+ years developing data movement and engineering applications and worked on integrating disparate systems using batch ETL/API following SDLC and/or Agile methodologies. \n 3+ years of experience working on various AWS Cloud services as Data Engineer experience. \n 3+ years of experience in creating complex technical specifications from business requirements/specifications. \n 2+ years of experience in scheduling jobs using Autosys (or comparable distributed scheduler like Stonebranch) \n Strong understanding of data architecture principles, methodologies, and best practices. \n Proficiency in relational database management systems, particularly AWS RDS and Postgres. \n Experience with data integration technologies and ETL tools a plus \n In-depth knowledge of AWS data services such as AWS Redshift, AWS Athena, AWS S3 and AWS Lambda a plus \n Experience in writing cloud formation templates and build IAM roles and policies. \n Understanding of data governance frameworks, data quality management, and data security practices. \n Strong analytical, problem-solving, and critical-thinking skills. \n Self-starter and highly motivated individual with strong AWS skills, problem solving skills, attention to detail, and ability to work in a fast-paced environment. \n \n \n \n \n \n      Must-haves\n      \n \n Expert in development of cloud base Data analytics solution, adoption cloud architecture, engineering, modeling, enterprise data platforms, based on Event-driven architecture, Microservices Pattern or serverless pattern implementations. \n AWS Glue/ Python/ Cloud Database development experience \n Rest API development experience \n Moderate to senior database knowledge (PostgreSQL, Redshift) \n Effective communication skills of complex solutions to technical and non-technical audience \n Solid understanding of DevOps processes and best practices. \n Knowledge of source control (Git or similar). \n Knowledge of Liquibase deployment patterns. \n Knowledge of MuleSoft API is plus. \n Knowledge of Salesforce CRM is plus. \n Knowledge of MicroStrategy or other BI reporting is plus. \n Knowledge of Master Data Management (MDM) \n \n \n \n  Nice-to-haves\n      \n \n Knowledge of insurance, financial systems/products Life Insurance, Annuity and 401k/ 403K \n AWS Developer or Architect or Specialty Certification (Active certifications) \n \n \n \n \n \n      #DICE\n      \n \n \n \n \n \n \n What\u2019s it like to work here? \n \n \n   At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.\n   \n \n \n \n What\u2019s in it for YOU: \n \n \n \n \n     A clearly defined career framework to help you successfully manage your career\n       \n \n \n     Leadership development and virtual training opportunities\n       \n \n \n     PTO/parental leave\n       \n \n \n     Competitive 401K and employee benefits\n       \n \n \n     Free financial counseling, health coaching and employee assistance program\n       \n \n \n     Tuition assistance program\n       \n \n \n     A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations\n       \n \n \n     Effective productivity/technology tools and training\n       \n \n \n \n Pay Range:  $87,700 - $155,000\n   \n \n \n \n   Actual base pay could vary based on non-discriminatory factors including but not limited to work experience, education, location, licensure requirements, proficiency and qualifications required for the role. The base pay is just one component of Lincoln\u2019s total rewards package for employees. In addition, the role may be eligible for the Annual Incentive Program, which is discretionary and based on the performance of the company, business unit and individual. Other rewards may include long-term incentives, sales incentives and Lincoln\u2019s standard benefits package.\n   \n \n \n \n About The Company \n \n \n   Lincoln Financial Group provides advice and solutions that help people take charge of their financial lives with confidence and optimism. Today, approximately 16 million customers trust our retirement, insurance and wealth protection expertise to help address their lifestyle, savings and income goals, and guard against long-term care expenses.\n   \n \n \n  Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE:LNC) and its affiliates. The company had $290 billion in end-of-period account balances net of reinsurance as of March 31, 2023.\n   \n \n \n \n   Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and ranks among Newsweek\u2019s Most Responsible Companies. Dedicated to diversity, equity and inclusion, we are included on transparency benchmarking tools such as the Corporate Equality Index, the Disability Equality Index and the Bloomberg Gender-Equality Index. Committed to providing our employees with flexible work arrangements, we were named to FlexJobs\u2019 list of the Top 100 Companies to Watch for Remote Jobs in 2022. With a long and rich legacy of acting ethically, telling the truth and speaking up for what is right, Lincoln was recognized as one of Ethisphere\u2019s 2022 World\u2019s Most Ethical Companies\u00ae. We create opportunities for early career talent through our intern development program, which ranks among WayUp and Yello\u2019s annual list of Top 100 Internship Programs.\n   \n \n \n \n   Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.\n   \n \n \n \n   Follow us on Facebook, Twitter, LinkedIn, and Instagram.\n   \n \n \n \n Be Aware of Fraudulent Recruiting Activities \n \n \n   If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.\n   \n \n   Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.\n   \n \n \n \n Additional Information \n \n \n   This position may be subject to Lincoln\u2019s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln\u2019s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.\n   \n \n \n \n   Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.\n   \n \n \n \n   Lincoln Financial Group (\u201cLFG\u201d) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",
        "cleaned_desc": " What you'll be doing \n \n \n \n \n \n \n Participates in analysis, design, and build solution as part of Agile / Scrum Develop Team. \n Implement and support large data initiatives for the enterprise (using AWS PostgreSQL, Redshift, Glue and Python to further these objectives). \n Understands data mapping and data modeling methodologies including normal form, star, and snowflake to reduce data redundancy and improve data integrity. \n Consult with internal Lincoln business partners on requirements, design, testing and production topics to create solution proposals and develop code. \n Performs technical tasks including estimating, analysis, technical requirements, design, build and unit & integration testing following SDLC. \n Assist analytical teams with the design and implementation of Data solutions and systems, including integration with Operational Datastores and Data Warehouses, both on-premises and in the Cloud. \n Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assesses the impact, and collaborates with Scrum Team and Leadership to incorporate new trends and developments in current and future solutions. \n Participates and enhances organizational initiatives by positively influencing and supporting change management and/or departmental/enterprise initiatives within assigned area(s) of responsibility. \n Identifies and directs the implementation of process improvements that significantly improve quality across the team, department and/or business unit for his/her assigned area(s) of responsibility. \n Provides expertise to team members and applicable internal/external stakeholders on complex assignments/projects for his/her assigned area(s) of responsibility. \n Assists on complex assignments, projects, and/or initiatives to build and enhance the capability of his/her assigned area(s) of responsibility. \n Coordinate and release management activities the functions of (continuous integration/continuous delivery) Pipeline and is responsible in creating and maintaining automated CICD build and release pipelines using GitLab DevOps. \n \n \n \n \n \n \n \n \n \n What we\u2019re looking for \n \n \n \n \n \n \n 4 Year/bachelor\u2019s degree or equivalent work experience (4 years of experience in lieu of Bachelors) _Minimum Required in Computer Science, Computer Information Systems, Information Systems, Information Technology or Computer Engineering or equivalent work experience. \n 3+ years developing data movement and engineering applications and worked on integrating disparate systems using batch ETL/API following SDLC and/or Agile methodologies. \n 3+ years of experience working on various AWS Cloud services as Data Engineer experience. \n 3+ years of experience in creating complex technical specifications from business requirements/specifications. \n 2+ years of experience in scheduling jobs using Autosys (or comparable distributed scheduler like Stonebranch) \n Strong understanding of data architecture principles, methodologies, and best practices. \n Proficiency in relational database management systems, particularly AWS RDS and Postgres. \n Experience with data integration technologies and ETL tools a plus \n In-depth knowledge of AWS data services such as AWS Redshift, AWS Athena, AWS S3 and AWS Lambda a plus \n Experience in writing cloud formation templates and build IAM roles and policies. \n Understanding of data governance frameworks, data quality management, and data security practices. \n Strong analytical, problem-solving, and critical-thinking skills. \n Self-starter and highly motivated individual with strong AWS skills, problem solving skills, attention to detail, and ability to work in a fast-paced environment. ",
        "techs": [
            "aws postgresql",
            "redshift",
            "glue",
            "python",
            "aws data services",
            "aws athena",
            "aws s3",
            "aws lambda",
            "autosys",
            "stonebranch",
            "cloud formation templates",
            "iam roles and policies"
        ],
        "cleaned_techs": [
            "aws",
            "redshift",
            "glue",
            "python",
            "autosys",
            "stonebranch",
            "cloud formation templates",
            "iam roles and policies"
        ]
    },
    "08e63c05538d95ac": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 110448.0,
        "salary_max": 137726.0,
        "title": "Senior Data Engineer - 2196705",
        "company": "Optum",
        "desc": "Senior Data Engineer \n \n \n EMPLOYER:  Optum Services Inc. \n \n \n JOB TITLE:  Senior Data Engineer \n \n \n LOCATION:  11000 Optum Circle, Eden Prairie, MN 55344 (Telecommuting available from anywhere in the U.S.) \n \n \n DUTIES:  Design, model, or implement corporate data warehousing activities. Program and configure warehouses of database information and provide support to warehouse users. Duties include: work on data warehouse involving in all phases of software engineering including requirements analysis, application design, and code development and testing; Designing reusable components, frameworks and libraries; Working closely with architecture group and driving solutions; Demonstrate expertise in leading-edge theories, techniques and/or technologies; Lead the development of new concepts, technologies and products to meet emerging customer requirements; Identify and solve problems that impact the management and direction of the business; Develop plans that impact the long-term success of the business; Influence senior management decisions that impact business direction; Has segment-wide and/or enterprise-wide impact; and lead cross-functional and/or industry-wide teams. Telecommuting available from anywhere in the U.S. \n \n \n REQUIREMENTS:  Employer will accept a Master\u2019s degree in Computer Science, Engineering or a related field and two (2) years of experience in the job offered or a related computer occupation. Position requires two years experience in the following: SQL Server; ETL; Azure Data Factory; Azure Synapse; Data Lake; PowerBI; and Star/Snowflake Schema. \n \n \n RATE OF PAY:  $110,448 - $137,726 /year \n \n  Please apply via careers.uhg.com and search for job #2196705 \n \n  Careers with Optum. Here's the idea. We built an entire organization around one giant objective; make health care work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do your life's best work.(sm) \n \n  UnitedHealth Group offers a full range of comprehensive benefits, including medical, dental and vision, as well as matching 401k and an employee stock purchase plan. \n \n \n Diversity creates a healthier atmosphere:  UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law. \n \n  UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment. \n \n  #LI-DNI",
        "cleaned_desc": " DUTIES:  Design, model, or implement corporate data warehousing activities. Program and configure warehouses of database information and provide support to warehouse users. Duties include: work on data warehouse involving in all phases of software engineering including requirements analysis, application design, and code development and testing; Designing reusable components, frameworks and libraries; Working closely with architecture group and driving solutions; Demonstrate expertise in leading-edge theories, techniques and/or technologies; Lead the development of new concepts, technologies and products to meet emerging customer requirements; Identify and solve problems that impact the management and direction of the business; Develop plans that impact the long-term success of the business; Influence senior management decisions that impact business direction; Has segment-wide and/or enterprise-wide impact; and lead cross-functional and/or industry-wide teams. Telecommuting available from anywhere in the U.S. \n \n \n REQUIREMENTS:  Employer will accept a Master\u2019s degree in Computer Science, Engineering or a related field and two (2) years of experience in the job offered or a related computer occupation. Position requires two years experience in the following: SQL Server; ETL; Azure Data Factory; Azure Synapse; Data Lake; PowerBI; and Star/Snowflake Schema. \n \n ",
        "techs": [
            "sql server",
            "etl",
            "azure data factory",
            "azure synapse",
            "data lake",
            "powerbi",
            "star/snowflake schema"
        ],
        "cleaned_techs": [
            "sql",
            "etl",
            "azure",
            "data lake",
            "powerbi",
            "star/snowflake schema"
        ]
    },
    "caef2374f05d333a": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Sr Data Engineer WFH",
        "company": "Work from Home",
        "desc": "Introduction \n  Are you looking for a work environment where diversity and inclusion thrive? Submit your application for our Sr Data Engineer WFH opening with Work from Home today and find out what it truly means to be a part of the HCA Healthcare team. \n  Benefits \n  Work from Home, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include: \n \n  Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation. \n  Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more. \n  Free counseling services and resources for emotional, physical and financial wellbeing   \n  401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)   \n  Employee Stock Purchase Plan with 10% off HCA Healthcare stock   \n  Family support through fertility and family building benefits with Progyny and adoption assistance.   \n  Referral services for child, elder and pet care, home and auto repair, event planning and more   \n  Consumer discounts through Abenity and Consumer Discounts   \n  Retirement readiness, rollover assistance services and preferred banking partnerships   \n  Education assistance (tuition, student loan, certification support, dependent scholarships)   \n  Colleague recognition program   \n  Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)   \n  Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income. \n \n  Learn more about Employee Benefits \n  Note: Eligibility for benefits may vary by location.   \n We are seeking a Sr Data Engineer WFH for our team to ensure that we continue to provide all patients with high quality, efficient care. Did you get into our industry for these reasons? We are an amazing team that works hard to support each other and are seeking a phenomenal addition like you who feels patient care is as meaningful as we do. We want you to apply! \n  Job Summary and Qualifications \n \n  What makes HCA Healthcare Information Technology Group (ITG) unique as a technology company is that our solutions ultimately impact the care of patients. Although our skills are needed in many industries, we in ITG apply them specifically to the noble cause of healthcare. We are \"Healthcare Inspired.\" It is this guiding vision that pervades and positively influences every level of our organization. It shapes our mission, defines our values, and brings our leaders and employees together in a shared enthusiasm for their work, setting ITG apart as a uniquely purpose-driven company in the IT industry. As a part of that, we exist to raise the bar, unlock possibilities, and care like family. \n  A Senior Data Engineer is responsible for development of database solutions inducing Data flow Diagrams, ER Diagrams (OLTP and Dimensional Data models), Logical and Physical Data. This individual will work closely with the Data Architects to prepare the data sets and build data pipelines needed for machine learning and statistical models from various data sources. \n  This position is within an innovation team that operates on multiple initiatives across the enterprise. The candidate must be comfortable in moving to different technical ecosystems from project to project that will require discovery and adaptation to systems, teams, and business stakeholders. \n  We are on a mission to change the face of the healthcare industry through value driven products. These products will create innovation to all users of healthcare across HCA\u2019s nationwide ecosystem. To do this we are building teams that are curious and quick to adapt to new technologies.  \n Major Responsibilities: \n \n Implement the technical solutions necessary to support OLTP, analytic and statistical processing requirements based on tradeoff between performance and quality.  \n Develop and implement data pipelines which includes interfaces to various source systems, destination workflows and processes.  \n Develop, maintain, and optimize streaming, near real-time, and batch ETL pipelines.  \n Employ a variety of programming and scripting languages to join data together from various systems and sources in an efficient and flexible storage solution.  \n Responsible for building and supporting a Cloud based ecosystem designed for analysis of structured, semi-structured, and unstructured data.  \n Develop, document, test, and debug new and existing data implementations and services for large-scale software for internal use. \n Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems \n Work closely with management, architects and other teams to develop and implement the projects. \n Actively participate in technical group discussions and adopt any new technologies to improve the development and operations. \n Refine and develop data quality where needed. \n \n  Technical \n \n Experience SQL Server, NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies. \n Working Knowledge of ETL tools (SSIS, Azure ADF, GCP Data Flow). \n Knowledge on At least one cloud Framework (Azure, AWS, GCP) and leveraging API services. \n Ability to integrate tools outside of the core Cloud ecosystem. \n Knowledge of Domain Driven Design or Application Data Modeling. \n Experience in data analysis, modeling and visualization. \n Experience with Unstructured Data, Real-Time Streaming with GCP \n Two Year of hands-on experience with GCP platform and experience with many of the following components: \n GCS, Cloud Run, Cloud Functions \n Bigtable, Cloud SQL \n Kafka, Pub/Sub \n Python, Golang, Spark, Scala or Java \n BigQuery, Dataflow, Data Fusion \n CICD process and Logging & Monitoring \n OpenShift, Docker \n Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support. \n Ability to multitask and to balance competing priorities \n Ability to utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills. \n Experience managing, delivering and supporting enterprise solutions  \n Experience with version control (Git) and open-source practices \n Experience with automation of CI/CD pipelines \n Experience with agile methodology \n Experience utilizing and managing product development in Jira or Azure DevOps tools \n \n  Interpersonal \n \n Interested in learning newer technologies and share knowledge with teammates \n Comfortable and proficient in a dynamic, agile team environment \n Able to work with a team and independently \n Great organizational and communication skills \n Able to take direction from team lead, manager, and product leadership \n Curious, full of excitement, and an outside of the box thinker \n Performs other duties as assigned \n Practices and adheres to the \u201cCode of Conduct\u201d philosophy and \u201cMission and Value Statement.\u201d \n \n  Education & Experience: \n \n \n Bachelor's degree required \n 7+ years of experience in related role required or equivalent combination of education and/or experience \n \n  Required Knowledge, Skills, Abilities, Behaviors: \n \n Service and Quality Excellence: Ability to demonstrate an uncompromising commitment to delivering exceptional care to create an unmatched value proposition for our patients. \n Honor our Mission and Values: Ability to build trust and act with authenticity to cultivate a culture of integrity, inclusion, and mutual respect. \n Effective Decision Making: Ability to make timely, informed decisions that are in the best interest of our patients, employees, providers, community and HCA. \n Attain and Leverage Strategic Relationships: Ability to develop and strengthen collaborative relationships with both internal and external stakeholders to advance the care of our patients and the growth of HCA. \n Lead and Develop Others: Ability to lead others to accomplish organizational goals and objectives; provide meaningful coaching and mentoring to increase the capabilities of individuals and teams and drive employee engagement. \n Communicate with Impact: Ability to deliver information in a clear, concise, and compelling manner to effectively engage others and achieve desired results. \n Achieve Success through Change: Ability to identify opportunities for improvement and innovation, remove barriers and resistance, and enable desired behaviors. \n Drive Execution and Financial Results: Ability to commit to the success and financial wellbeing of HCA by challenging others to excel and hold themselves and others accountable for achieving results. \n \n  Travel Required \n   \n \n No Travel: The job does not require any travel. \n \n \n HCA Healthcare has been recognized as one of the World's Most Ethical Companies by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses. \n \n  \"Across HCA Healthcare\u2019s more than 2,000 sites of care, our nurses and colleagues have a positive impact on patients, communities and healthcare.  Together, we uplift and elevate our purpose to give people a healthier tomorrow.\"- Jane Englebright, PhD, RN CENP, FAAN  Senior Vice President and Chief Nursing Executive \n If you find this opportunity compelling, we encourage you to apply for our Sr Data Engineer WFH opening. We promptly review all applications. Highly qualified candidates will be directly contacted by a member of our team.  We are interviewing apply today! \n  We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",
        "cleaned_desc": " We are seeking a Sr Data Engineer WFH for our team to ensure that we continue to provide all patients with high quality, efficient care. Did you get into our industry for these reasons? We are an amazing team that works hard to support each other and are seeking a phenomenal addition like you who feels patient care is as meaningful as we do. We want you to apply! \n  Job Summary and Qualifications \n \n  What makes HCA Healthcare Information Technology Group (ITG) unique as a technology company is that our solutions ultimately impact the care of patients. Although our skills are needed in many industries, we in ITG apply them specifically to the noble cause of healthcare. We are \"Healthcare Inspired.\" It is this guiding vision that pervades and positively influences every level of our organization. It shapes our mission, defines our values, and brings our leaders and employees together in a shared enthusiasm for their work, setting ITG apart as a uniquely purpose-driven company in the IT industry. As a part of that, we exist to raise the bar, unlock possibilities, and care like family. \n  A Senior Data Engineer is responsible for development of database solutions inducing Data flow Diagrams, ER Diagrams (OLTP and Dimensional Data models), Logical and Physical Data. This individual will work closely with the Data Architects to prepare the data sets and build data pipelines needed for machine learning and statistical models from various data sources. \n  This position is within an innovation team that operates on multiple initiatives across the enterprise. The candidate must be comfortable in moving to different technical ecosystems from project to project that will require discovery and adaptation to systems, teams, and business stakeholders. \n  We are on a mission to change the face of the healthcare industry through value driven products. These products will create innovation to all users of healthcare across HCA\u2019s nationwide ecosystem. To do this we are building teams that are curious and quick to adapt to new technologies.  \n Major Responsibilities: \n \n Implement the technical solutions necessary to support OLTP, analytic and statistical processing requirements based on tradeoff between performance and quality.  \n Develop and implement data pipelines which includes interfaces to various source systems, destination workflows and processes.  \n Develop, maintain, and optimize streaming, near real-time, and batch ETL pipelines.  \n Employ a variety of programming and scripting languages to join data together from various systems and sources in an efficient and flexible storage solution.  \n Responsible for building and supporting a Cloud based ecosystem designed for analysis of structured, semi-structured, and unstructured data.  \n Develop, document, test, and debug new and existing data implementations and services for large-scale software for internal use. \n Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems \n Work closely with management, architects and other teams to develop and implement the projects. \n Actively participate in technical group discussions and adopt any new technologies to improve the development and operations. \n Refine and develop data quality where needed. \n \n  Technical   \n Experience SQL Server, NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies. \n Working Knowledge of ETL tools (SSIS, Azure ADF, GCP Data Flow). \n Knowledge on At least one cloud Framework (Azure, AWS, GCP) and leveraging API services. \n Ability to integrate tools outside of the core Cloud ecosystem. \n Knowledge of Domain Driven Design or Application Data Modeling. \n Experience in data analysis, modeling and visualization. \n Experience with Unstructured Data, Real-Time Streaming with GCP \n Two Year of hands-on experience with GCP platform and experience with many of the following components: \n GCS, Cloud Run, Cloud Functions \n Bigtable, Cloud SQL \n Kafka, Pub/Sub \n Python, Golang, Spark, Scala or Java \n BigQuery, Dataflow, Data Fusion \n CICD process and Logging & Monitoring \n OpenShift, Docker \n Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support. \n Ability to multitask and to balance competing priorities \n Ability to utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills. \n Experience managing, delivering and supporting enterprise solutions  \n Experience with version control (Git) and open-source practices   Experience with automation of CI/CD pipelines \n Experience with agile methodology \n Experience utilizing and managing product development in Jira or Azure DevOps tools \n \n  Interpersonal \n \n Interested in learning newer technologies and share knowledge with teammates \n Comfortable and proficient in a dynamic, agile team environment \n Able to work with a team and independently \n Great organizational and communication skills \n Able to take direction from team lead, manager, and product leadership \n Curious, full of excitement, and an outside of the box thinker \n Performs other duties as assigned \n Practices and adheres to the \u201cCode of Conduct\u201d philosophy and \u201cMission and Value Statement.\u201d \n \n  Education & Experience: \n \n \n Bachelor's degree required \n 7+ years of experience in related role required or equivalent combination of education and/or experience \n ",
        "techs": [
            "sql server",
            "nosql",
            "hbase",
            "cassandra",
            "mongodb",
            "cosmos",
            "in-memory",
            "columnar",
            "ssis",
            "azure adf",
            "gcp data flow",
            "azure",
            "aws",
            "gcp",
            "api services",
            "domain driven design",
            "application data modeling",
            "gcs",
            "cloud run",
            "cloud functions",
            "bigtable",
            "cloud sql",
            "kafka",
            "pub/sub",
            "python",
            "golang",
            "spark",
            "scala",
            "java",
            "bigquery",
            "dataflow",
            "data fusion",
            "cicd process",
            "logging & monitoring",
            "openshift",
            "docker",
            "git",
            "jira",
            "azure devops"
        ],
        "cleaned_techs": [
            "sql",
            "nosql",
            "hbase",
            "cassandra",
            "mongodb",
            "cosmos",
            "in-memory",
            "columnar",
            "ssis",
            "azure",
            "gcp",
            "aws",
            "api services",
            "domain driven design",
            "application data modeling",
            "gcs",
            "cloud run",
            "cloud functions",
            "bigtable",
            "cloud sql",
            "kafka",
            "pub/sub",
            "python",
            "golang",
            "spark",
            "scala",
            "java",
            "bigquery",
            "dataflow",
            "data fusion",
            "cicd process",
            "logging & monitoring",
            "openshift",
            "docker",
            "git",
            "jira"
        ]
    },
    "c7367f9bc52fc866": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 120.0,
        "salary_max": 120.0,
        "title": "Senior Data Engineer with Orchestration Tools",
        "company": "BayOne",
        "desc": "We are looking to backfill a Senior Data Engineer requirement with data platforms, platform-specific technologies, and integration with external orchestration tools. Integration experience is key for this role . Must be a hands-on developer (Java/Python). \n \n  You can look for Senior Data Engineer profiles with experience integrating orchestration tools (e.g.: Adobe Campaign, Salesforce, etc. not exactly those, but similar kinds of tools). \n \n  This is a 100% remote role, PST hours (Target West Coast candidates but don't limit your search). Bill rate: $120, PR: $85W2, or $95-$100 C2C. We only need stellar candidates. 3-4 rounds of Interviews (tech screening, including real-time coding).",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b0e5e69b5272bea0": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 120087.16,
        "salary_max": 152057.1,
        "title": "Senior Data Engineer - HYBRID",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Data Engineer - HYBRID. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n Job Description: \n Investments Workplace Solutions (WS) organization is looking for a Senior Data Engineer. This person will be playing a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support Equity Compensation products for the Global markets. This person will be working closely with other engineers and business SMEs to build and release solutions that help customers get the information they need fast and intuitively. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required \n 7+ years of hands-on experience in Data engineering, data warehousing and analytics technologies \n Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform \n Strong knowledge of designing data engineering solutions and platforms \n Working experience with Relational Databases like Oracle \n Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau \n Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc. \n Experience building scalable patterns for data consumption from cloud based data-lakes. \n Advanced experience with PL/SQL and complex queries \n Working experience with Python focused on Data Engineering \n Solid understanding of Cloud technologies like AWS, Azure and DevOps concepts including CI/CD pipelines \n Significant experience with ELT data integration and data movement design patterns \n Strong knowledge of ETL technologies like Informatica, Snaplogic \n Knowledge of streaming platforms such as Apache Kafka \n Your ability to learn and experiment with new technologies and patterns \n Your penchant for modern test driven and automation driven software development methodologies \n Your experience in executing projects in an Agile environment \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " \n Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required \n 7+ years of hands-on experience in Data engineering, data warehousing and analytics technologies \n Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform \n Strong knowledge of designing data engineering solutions and platforms \n Working experience with Relational Databases like Oracle   Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau \n Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc. \n Experience building scalable patterns for data consumption from cloud based data-lakes. \n Advanced experience with PL/SQL and complex queries \n Working experience with Python focused on Data Engineering \n Solid understanding of Cloud technologies like AWS, Azure and DevOps concepts including CI/CD pipelines   Significant experience with ELT data integration and data movement design patterns \n Strong knowledge of ETL technologies like Informatica, Snaplogic \n Knowledge of streaming platforms such as Apache Kafka \n Your ability to learn and experiment with new technologies and patterns \n Your penchant for modern test driven and automation driven software development methodologies \n Your experience in executing projects in an Agile environment ",
        "techs": [
            "oracle",
            "obiee",
            "powerbi",
            "tableau",
            "snowflake",
            "redshift",
            "pl/sql",
            "python",
            "aws",
            "azure",
            "informatica",
            "snaplogic",
            "apache kafka"
        ],
        "cleaned_techs": [
            "oracle",
            "obiee",
            "powerbi",
            "tableau",
            "snowflake",
            "redshift",
            "pl/sql",
            "python",
            "aws",
            "azure",
            "informatica",
            "snaplogic",
            "apache kafka"
        ]
    },
    "94a97e9902178aec": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 132110.36,
        "salary_max": 167281.14,
        "title": "Senior Data Engineer, Product Data",
        "company": "Sonos, Inc",
        "desc": "At Sonos we want to create the ultimate listening experience for our customers and know that it starts by listening to each other. As part of the Sonos team, you\u2019ll collaborate with people of all styles, skill sets, and backgrounds to realize our vision while fostering a community where everyone feels included and empowered to do the best work of their lives.\n         \n \n \n \n \n \n \n \n \n \n   This role can be done from home\n  \n \n   Building the world\u2019s leading sound experience starts with the experience we provide for our people. That\u2019s why we\u2019ve been distributed from the start: initially between offices in Boston & Santa Barbara, and now with additional offices in Seattle, San Francisco & Paris. This role can be done from anywhere in the United States- any of our offices, or remotely from home. It\u2019s about impact, not location.\n  \n \n \n   At Sonos data helps us build a better business, a better product and ultimately helps us make happier customers. By understanding how our customers listen in their homes (and beyond), the Product Data team uses data to guide and influence the product direction and improve the customer experience. Within the software organization, a group of data analysts, scientists, engineers and product managers work to maintain our product data infrastructure.\n  \n \n \n   We are searching for a highly skilled Senior Data Engineer with extensive cloud experience, and a proven track record in designing and managing complex data pipelines and infrastructure. In this role, you will also need to be well-versed in tools such as AWS services, Apache Airflow, dbt, Snowflake, and managing data lakes. You will play a pivotal role in our data team, collaborating with a passionate team of data engineers to drive data-driven decisions and build & maintain cutting-edge data solutions and products for the organization. Your responsibilities include ensuring data availability, reliability, and quality.\n  \n \n \n   What You\u2019ll Do\n  \n \n \n \n     Work with event style data and build tooling to ensure that product data is high quality, performant and useful for analysis.\n    \n \n \n     Design, develop, and optimize highly scalable and efficient streaming & batch data pipelines.\n    \n \n \n     Collaborate with software engineers, data experts, and business stakeholders to comprehensively understand their data needs and translate these into complex data models and infrastructure designs.\n    \n \n \n     Utilize tools like Apache Airflow to orchestrate and schedule data pipeline workflows, ensuring reliability and timeliness of data delivery.\n    \n \n \n     Develop and maintain data transformation and modeling using DBT to provide structured and clean data to data consumers.\n    \n \n \n     Evaluate, recommend, and implement emerging technologies and tools to improve our data infrastructure, pipeline operations, and data lakes.\n    \n \n \n     Ensure data governance, compliance, and access control best practices are in place to maintain data security and integrity.\n    \n \n \n     Mentor and guide junior data engineers, fostering their growth and expertise.\n    \n \n \n \n   What You\u2019ll Need\n  \n \n   Research shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria. If you don\u2019t have 100% of the skills listed, we strongly encourage you to apply if interested.\n  \n \n \n   Basic Qualifications\n  \n \n \n \n     Bachelor's degree in computer science, information technology, or a related field. A master's degree is a plus.\n    \n \n \n     5+ years experience as a data engineer with a strong focus on complex data pipeline modeling and infrastructure design.\n    \n \n \n     Strong proficiency in AWS cloud services, including but not limited to S3, Glue, Lambda, Kinesis.\n    \n \n \n     Strong understanding of Elasticsearch and Kibana for data search and analytics.\n    \n \n \n     Proficiency in scripting and automation for cluster maintenance and data ingestion.\n    \n \n \n     Solid programming skills in languages such as Python, Java, or Scala.\n    \n \n \n     Excellent communication and teamwork skills.\n    \n \n \n \n   Preferred Qualifications\n  \n \n \n \n     AWS certification in relevant specialties.\n    \n \n \n     Strong Parquet format knowledge and data serialization experience.\n    \n \n \n     Proficiency in managing data lakes, especially in Snowflake.\n    \n \n \n     Experience with containerization and orchestration tools like Docker and Kubernetes.\n    \n \n \n     Familiarity with data streaming technologies, such as Apache Kafka, Apache Flink.\n    \n \n \n \n   #LI-Remote\n  \n \n \n   At Sonos we consider a wide range of factors when determining compensation, which may lead individual compensation to vary depending on job related qualifications, skills, and experience. All full time employees are eligible for merit increases, discretionary bonuses, and equity. Our job postings may span more than one career level and the base pay range may be modified in the future based on changing market conditions. The starting base pay for this role for all US candidates is between:\n  \n  $134,000 and $164,340\n  \n \n   Please note that compensation details listed in US job postings reflect the base salary only, and do not include bonus, equity, or benefits.\n  \n \n \n \n \n \n \n       We also offer a comprehensive benefits program with choice and flexibility in mind to help support the health, wealth, and overall well-being of our employees. Regular full time employees in the US are eligible for benefits on day one, including:\n      \n \n \n \n         Medical, Dental, and Vision Insurance\n        \n \n \n         A 401(k) plan with company matching and immediate vesting\n        \n \n \n         An Open Time Off policy (OTO) so you have maximum opportunity to disconnect and recharge, with no tenure-based vacation accruals required\n        \n \n \n         80 hours of sick time upon hire, refreshed annually\n        \n \n \n         Up to 12 paid holidays per calendar year\n        \n \n \n         12 weeks of paid Bonding Leave following the birth or adoption of a new child, plus up to an additional 12 weeks of Medical Leave for birthing parents under our Short Term Disability policy\n        \n \n \n         Company-paid Disability, Life, and AD&D Insurance\n        \n \n \n         Voluntary benefits, including Voluntary Life, AD&D, Accident, and Pet Insurance\n        \n \n \n         Mental health benefits to support your holistic well-being\n        \n \n \n         A generous employee discount program & paid streaming music services on the Sonos platform\n        \n \n \n \n       For a holistic overview of our benefits, please visit \n       \n       sonosbenefits.com\n       .\n      \n \n \n  Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company\u2019s sole discretion, consistent with the law. \n \n \n \n       Your profile will be reviewed and you'll hear from us once we have an update. At Sonos we take the time to hire right and appreciate your patience.\n      \n \n \n  Notice to U.S. Job Applicants:  \n Sonos is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics. \n \n \n  Follow the links to review the  \n \n EEO is the Law poster \n \n  and its  \n \n supplement \n \n .  \n Sonos is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to  \n accommodations@sonos.com \n  and let us know the nature of your request and your contact information.",
        "cleaned_desc": "At Sonos we want to create the ultimate listening experience for our customers and know that it starts by listening to each other. As part of the Sonos team, you\u2019ll collaborate with people of all styles, skill sets, and backgrounds to realize our vision while fostering a community where everyone feels included and empowered to do the best work of their lives.\n         \n \n \n \n \n \n \n \n \n \n   This role can be done from home\n  \n \n   Building the world\u2019s leading sound experience starts with the experience we provide for our people. That\u2019s why we\u2019ve been distributed from the start: initially between offices in Boston & Santa Barbara, and now with additional offices in Seattle, San Francisco & Paris. This role can be done from anywhere in the United States- any of our offices, or remotely from home. It\u2019s about impact, not location.\n  \n \n \n   At Sonos data helps us build a better business, a better product and ultimately helps us make happier customers. By understanding how our customers listen in their homes (and beyond), the Product Data team uses data to guide and influence the product direction and improve the customer experience. Within the software organization, a group of data analysts, scientists, engineers and product managers work to maintain our product data infrastructure.\n  \n \n \n   We are searching for a highly skilled Senior Data Engineer with extensive cloud experience, and a proven track record in designing and managing complex data pipelines and infrastructure. In this role, you will also need to be well-versed in tools such as AWS services, Apache Airflow, dbt, Snowflake, and managing data lakes. You will play a pivotal role in our data team, collaborating with a passionate team of data engineers to drive data-driven decisions and build & maintain cutting-edge data solutions and products for the organization. Your responsibilities include ensuring data availability, reliability, and quality.\n  \n \n \n   What You\u2019ll Do\n  \n \n \n \n     Work with event style data and build tooling to ensure that product data is high quality, performant and useful for analysis.\n    \n \n \n     Design, develop, and optimize highly scalable and efficient streaming & batch data pipelines.\n    \n \n \n     Collaborate with software engineers, data experts, and business stakeholders to comprehensively understand their data needs and translate these into complex data models and infrastructure designs.\n    \n \n \n     Utilize tools like Apache Airflow to orchestrate and schedule data pipeline workflows, ensuring reliability and timeliness of data delivery.     \n \n \n     Develop and maintain data transformation and modeling using DBT to provide structured and clean data to data consumers.\n    \n \n \n     Evaluate, recommend, and implement emerging technologies and tools to improve our data infrastructure, pipeline operations, and data lakes.\n    \n \n \n     Ensure data governance, compliance, and access control best practices are in place to maintain data security and integrity.\n    \n \n \n     Mentor and guide junior data engineers, fostering their growth and expertise.\n    \n \n \n \n   What You\u2019ll Need\n  \n \n   Research shows that candidates from underrepresented backgrounds often don't apply for roles if they don't meet all the criteria. If you don\u2019t have 100% of the skills listed, we strongly encourage you to apply if interested.\n  \n \n \n   Basic Qualifications\n  \n \n \n \n     Bachelor's degree in computer science, information technology, or a related field. A master's degree is a plus.\n    \n \n \n     5+ years experience as a data engineer with a strong focus on complex data pipeline modeling and infrastructure design.\n    \n \n \n     Strong proficiency in AWS cloud services, including but not limited to S3, Glue, Lambda, Kinesis.\n    \n \n       Strong understanding of Elasticsearch and Kibana for data search and analytics.\n    \n \n \n     Proficiency in scripting and automation for cluster maintenance and data ingestion.\n    \n \n \n     Solid programming skills in languages such as Python, Java, or Scala.\n    \n \n \n     Excellent communication and teamwork skills.\n    \n \n \n \n   Preferred Qualifications\n  \n \n \n \n     AWS certification in relevant specialties.\n    \n \n \n     Strong Parquet format knowledge and data serialization experience.\n    \n \n \n     Proficiency in managing data lakes, especially in Snowflake.\n    \n \n \n     Experience with containerization and orchestration tools like Docker and Kubernetes.\n    \n \n \n     Familiarity with data streaming technologies, such as Apache Kafka, Apache Flink.\n    \n \n \n \n   #LI-Remote",
        "techs": [
            "sonos",
            "aws services",
            "apache airflow",
            "dbt",
            "snowflake",
            "apache kafka",
            "apache flink",
            "docker",
            "kubernetes"
        ],
        "cleaned_techs": [
            "sonos",
            "aws",
            "apache airflow",
            "dbt",
            "snowflake",
            "apache kafka",
            "apache flink",
            "docker",
            "kubernetes"
        ]
    },
    "8ca22ab9eb391def": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 150000.0,
        "salary_max": 200000.0,
        "title": "Senior Software Engineer - Cloud Data Engineering (23-044)",
        "company": "CTI",
        "desc": "CTI, a high-tech software, systems engineering, and operational support corporation in the defense and space industry, is seeking a skilled Senior Software Engineer - Cloud Data Engineering to join our team. Our company is dedicated to providing top-quality engineering, system development, and support for operator-focused technology solutions in military and security applications. As an expert in real-time, decision support, and electronic warfare systems, CTI specializes in sensor integration, information management, and the development of cutting-edge solutions. \n \n  Responsibilities include but are not limited to:     \n \n Work closely with the development team to refactor and rework an existing, Java-based monolith into microservices-based data pipelines. \n Design, deploy, and manage containerized applications using Kubernetes and GitOps principles to support microservices-based data pipelines. \n Implement big data processing and streaming solutions to handle large volumes of data efficiently. \n Interface with REST APIs, data lakes, and messaging systems such as RabbitMQ to extract, transform, and load data into the new system. \n Collaborate with cross-functional teams to identify and integrate relevant data sources and establish data flow processes. \n Design and develop data transformation pipelines, ensuring data quality, reliability, and scalability. \n Implement monitoring and error-handling mechanisms to ensure the stability and performance of data pipelines. \n Troubleshoot, optimize, and enhance the performance of data pipelines as needed. \n Mentor and guide junior engineers in best practices for data engineering and cloud-native development. \n \n Requirements \n  Necessary skills and experience \n \n Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. \n Proven experience in developing and maintaining software systems with a focus on data engineering and cloud-native architecture. \n Experience in Java, Python, and similar languages. \n Experience in container orchestration with Kubernetes, including deployment, scaling, and monitoring of applications in a cloud-native environment. \n Expertise in big data processing and streaming technologies, such as Apache Kafka, Spark, or Flink. \n The ability to obtain a US security clearance post start date. U.S. Citizenship is required as only U.S. citizens are eligible for a security clearance. \n \n Beneficial skills and experience \n \n Knowledge of GitOps practices and experience with tools like Flux CD to automate and manage Kubernetes configurations, ensuring system reliability and scalability. \n Familiarity with data lake architectures and best practices. \n Proficiency in RESTful API integration and data extraction. \n Experience with messaging systems like RabbitMQ or similar technologies. \n Strong problem-solving skills and the ability to architect and implement data solutions from scratch. \n Excellent communication skills and the ability to collaborate effectively in cross-functional teams. \n Experience re-designing legacy systems or building greenfield data architectures is a significant plus. \n \n Benefits \n  CTI is a rapidly growing company offering the following: \n \n \n Medical, dental and vision insurance \n H.S.A. (partially funded by CTI) and Flex Spending \n Company-paid life insurance/AD&D and disability insurance \n Optional supplemental life, critical illness, hospital indemnity and accident insurances \n Paid vacation, sick leave and holidays \n 401k plan with Safe Harbor contribution \n Tuition reimbursement/professional training options \n Employee Assistance Program \n Travel Assistance \n Financial Planning Assistance \n Voluntary Pre-Paid Legal \n Flexible schedules with telecommuting options \n Service awards program \n \n \n \n CTI is an Equal Opportunity employer and shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.",
        "cleaned_desc": "CTI, a high-tech software, systems engineering, and operational support corporation in the defense and space industry, is seeking a skilled Senior Software Engineer - Cloud Data Engineering to join our team. Our company is dedicated to providing top-quality engineering, system development, and support for operator-focused technology solutions in military and security applications. As an expert in real-time, decision support, and electronic warfare systems, CTI specializes in sensor integration, information management, and the development of cutting-edge solutions. \n \n  Responsibilities include but are not limited to:     \n \n Work closely with the development team to refactor and rework an existing, Java-based monolith into microservices-based data pipelines. \n Design, deploy, and manage containerized applications using Kubernetes and GitOps principles to support microservices-based data pipelines. \n Implement big data processing and streaming solutions to handle large volumes of data efficiently. \n Interface with REST APIs, data lakes, and messaging systems such as RabbitMQ to extract, transform, and load data into the new system. \n Collaborate with cross-functional teams to identify and integrate relevant data sources and establish data flow processes. \n Design and develop data transformation pipelines, ensuring data quality, reliability, and scalability.   Implement monitoring and error-handling mechanisms to ensure the stability and performance of data pipelines. \n Troubleshoot, optimize, and enhance the performance of data pipelines as needed. \n Mentor and guide junior engineers in best practices for data engineering and cloud-native development. \n \n Requirements \n  Necessary skills and experience \n \n Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. \n Proven experience in developing and maintaining software systems with a focus on data engineering and cloud-native architecture. \n Experience in Java, Python, and similar languages.   Experience in container orchestration with Kubernetes, including deployment, scaling, and monitoring of applications in a cloud-native environment. \n Expertise in big data processing and streaming technologies, such as Apache Kafka, Spark, or Flink. \n The ability to obtain a US security clearance post start date. U.S. Citizenship is required as only U.S. citizens are eligible for a security clearance. \n \n Beneficial skills and experience \n \n Knowledge of GitOps practices and experience with tools like Flux CD to automate and manage Kubernetes configurations, ensuring system reliability and scalability. \n Familiarity with data lake architectures and best practices. \n Proficiency in RESTful API integration and data extraction. \n Experience with messaging systems like RabbitMQ or similar technologies. ",
        "techs": [
            "cti",
            "java",
            "kubernetes",
            "gitops",
            "rabbitmq",
            "apache kafka",
            "spark",
            "flink",
            "flux cd"
        ],
        "cleaned_techs": [
            "cti",
            "java",
            "kubernetes",
            "gitops",
            "rabbitmq",
            "apache kafka",
            "spark",
            "flink",
            "flux cd"
        ]
    },
    "fe502fde8cac1629": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 124470.49,
        "salary_max": 157607.38,
        "title": "Senior Mechanical Engineer - Data Center - Remote USA",
        "company": "Jacobs",
        "desc": "Our People & Places Solutions business \u2013 reinforces our drive to improve the lives of people everywhere and epitomizes the \"why\" of what we do \u2013 the tremendous positive impact and value our solutions bring to our communities and society as a whole. From facilities delivering life-saving therapies and ensuring clean water to enabling the connection of people through all modes of transportation and providing access to technology \u2013 we're integrating a multitude of these solution elements to build the smart environments of tomorrow.     Start your Jacobs career with a company that inspires and empowers you to deliver your best work so you can evolve, grow and succeed \u2013 today and into tomorrow. \n \n \n Your Impact: \n  At Jacobs, we challenge what is currently accepted so we can shape innovative and lasting solutions for tomorrow. If you\u2019re interested in a rewarding career working with the industry\u2019s best and most innovative engineers, then Jacobs is where you belong.    Jacobs is seeking a Senior Mechanical Engineer focused primarily on Data Center work who is excited about working on Advanced Facilities projects that enable the heart of our client's business. Similarly, Mechanical Engineering design experience in Laboratory & Hospital are relatable. Join us and you\u2019ll have the chance to both support and lead projects at some of the world\u2019s most state-of-the-art industrial and commercial facilities. You\u2019ll be accountable for the schedule and technical quality of challenging engineering tasks as you gain familiarity with the client\u2019s expectations, scope, budget, and schedule. You\u2019ll also provide on-site assistance during startup, coordinating work activities with other design and engineering professionals and the discipline lead. Your multi-discipline, highly interactive team will successfully deliver the design, development, application, evaluation, recommendation, and specification of engineered systems for Piping, HVAC, Plumbing, and Fire Protection systems and components. \n You\u2019ll also have the chance to utilize your technical expertise in mentoring junior team members to help them discover what drives their careers, nurture their purpose, and guide them forward. Your role keeps our company connected, and we\u2019ll support you with what you need to be successful. Bring your creativity, ambitious spirit, and extreme attention to detail. We\u2019ll help you grow, pursue, and fulfill what drives you \u2013 so we can deliver extraordinary solutions for a better tomorrow together.    At Jacobs, we\u2019re partnering across the globe to create the best project outcomes by maximizing the design, digital technology, and support capabilities of our Global Integrated Delivery (GID) teammates. By joining Jacobs, you\u2019ll commit to supporting and engaging with these teams as we work to build a company like no other. \n \n  #dchotjobs\n  \n \n  #SpecializedManufacturing\n  \n \n  #AMmanufacturing\n  \n \n \n \n Here\u2019s What You\u2019ll Need: \n \n \n Bachelor's degree in Mechanical Engineering \n At least 10 years of practical application of mechanical engineering and design, including HVAC, fire protection, plumbing, piping, and related mechanical building systems \n Professional Engineer (PE) \n Strong communication skills both verbal and written \n Strong analytical and problem-solving skills \n Ability to collaborate and work effectively in a variety of teams, including multi-disciplinary teams \n \n Ideally, you\u2019ll also have: \n \n Proficient working knowledge of Revit software \n Forward-thinking, eager to learn best practices, and contribute with innovative ideas \n Displayed ability to learn quickly and driven to broaden the knowledge base \n Passion for buildings and construction design  Preferred candidates will have prior experience with semiconductor cleanrooms, central utility buildings (CUBs), piping systems, and large, complex industrial HVAC supply and exhaust systems \n  \n \n At Jacobs, we\u2019re challenging today to reinvent tomorrow by solving the world\u2019s most critical problems for thriving cities, resilient environments, mission-critical outcomes, operational advancement, scientific discovery and cutting-edge manufacturing, turning abstract ideas into realities that transform the world for good. With $15 billion in revenue and a talent force of more than 60,000, Jacobs provides a full spectrum of professional services including consulting, technical, scientific and project delivery for the government and private sector.",
        "cleaned_desc": " Bachelor's degree in Mechanical Engineering \n At least 10 years of practical application of mechanical engineering and design, including HVAC, fire protection, plumbing, piping, and related mechanical building systems \n Professional Engineer (PE) \n Strong communication skills both verbal and written \n Strong analytical and problem-solving skills \n Ability to collaborate and work effectively in a variety of teams, including multi-disciplinary teams \n ",
        "techs": [
            "bachelor's degree in mechanical engineering",
            "hvac",
            "fire protection",
            "plumbing",
            "piping",
            "professional engineer (pe)"
        ],
        "cleaned_techs": [
            "hvac",
            "fire protection",
            "plumbing",
            "piping",
            "professional engineer (pe)"
        ]
    },
    "52dd94fb36533f37": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 120287.37,
        "salary_max": 152310.61,
        "title": "Senior Data Engineer - HYBRID",
        "company": "Inclusively",
        "desc": "Inclusively is partnering with a multinational financial services company to hire a Senior Data Engineer - HYBRID. \n ABOUT INCLUSIVELY: \n Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD).  Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability. \n Job Description: \n Investments Workplace Solutions (WS) organization is looking for a Senior Data Engineer. This person will be playing a key role in designing and crafting a modern Data and Information Delivery and Analytics platform in the cloud to support Equity Compensation products for the Global markets. This person will be working closely with other engineers and business SMEs to build and release solutions that help customers get the information they need fast and intuitively. \n The Expertise and Skills You Bring \n \n Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required \n 7+ years of hands-on experience in Data engineering, data warehousing and analytics technologies \n Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform \n Strong knowledge of designing data engineering solutions and platforms \n Working experience with Relational Databases like Oracle \n Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau \n Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc. \n Experience building scalable patterns for data consumption from cloud based data-lakes. \n Advanced experience with PL/SQL and complex queries \n Working experience with Python focused on Data Engineering \n Solid understanding of Cloud technologies like AWS, Azure and DevOps concepts including CI/CD pipelines \n Significant experience with ELT data integration and data movement design patterns \n Strong knowledge of ETL technologies like Informatica, Snaplogic \n Knowledge of streaming platforms such as Apache Kafka \n Your ability to learn and experiment with new technologies and patterns \n Your penchant for modern test driven and automation driven software development methodologies \n Your experience in executing projects in an Agile environment \n \n Job Type: Full-time \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " \n Bachelor\u2019s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) required \n 7+ years of hands-on experience in Data engineering, data warehousing and analytics technologies \n Advanced skills in data intensive application development, data integration, and data pipeline design patterns on a distributed platform \n Strong knowledge of designing data engineering solutions and platforms \n Working experience with Relational Databases like Oracle   Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau \n Strong working knowledge of cloud native data warehousing and data lake solutions using Snowflake, Redshift etc. \n Experience building scalable patterns for data consumption from cloud based data-lakes. \n Advanced experience with PL/SQL and complex queries \n Working experience with Python focused on Data Engineering \n Solid understanding of Cloud technologies like AWS, Azure and DevOps concepts including CI/CD pipelines   Significant experience with ELT data integration and data movement design patterns \n Strong knowledge of ETL technologies like Informatica, Snaplogic \n Knowledge of streaming platforms such as Apache Kafka \n Your ability to learn and experiment with new technologies and patterns \n Your penchant for modern test driven and automation driven software development methodologies \n Your experience in executing projects in an Agile environment ",
        "techs": [
            "oracle",
            "obiee",
            "powerbi",
            "tableau",
            "snowflake",
            "redshift",
            "pl/sql",
            "python",
            "aws",
            "azure",
            "ci/cd pipelines",
            "informatica",
            "snaplogic",
            "apache kafka"
        ],
        "cleaned_techs": [
            "oracle",
            "obiee",
            "powerbi",
            "tableau",
            "snowflake",
            "redshift",
            "pl/sql",
            "python",
            "aws",
            "azure",
            "ci/cd pipelines",
            "informatica",
            "snaplogic",
            "apache kafka"
        ]
    },
    "b42d5bfb834ab320": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 58000.0,
        "salary_max": 67000.0,
        "title": "Data Services Engineer",
        "company": "Catalist",
        "desc": "For over 17 years, Catalist has been a leader in civic data and data science innovation. Our mission is to provide progressive organizations with the data, software, and services needed to better identify, understand, and communicate with the people they need to engage and mobilize. Our clients include the largest, most influential organizations in the U.S. active in civic engagement, advocacy, and political campaigns.\n  \n \n \n  Catalist is home to a dedicated, creative team of technologists, data scientists, and campaign experts committed to using our talents and technology to nurture a vibrant and growing progressive community.\n  \n \n \n  As a Data Services Engineer (DSE) at Catalist, you will have a leading role in providing support and creating solutions for a wide array of Catalist clients and partners as well assisting or leading efforts to manage cross-departmental projects. The DSE supports the Client Services team by providing reports, data for visualizations, lists, and appends that the Catalist suite of tools cannot readily provide.\n  \n \n \n  The ideal candidate will be a highly motivated individual with excellent technical skills, a strong desire to learn new skills, and an interest in progressive politics. Catalist values creativity and problem-solving. Our work is on the cutting edge of data-driven politics, and your support will help Democratic candidates and progressive organizations conduct successful advocacy and electoral campaigns.\n  \n \n \n  This position reports to the Deputy Chief Data Officer. While Data Services Engineers work closely with the Client Services, Analytics, and Tech teams, they are a part of the growing Data team that supports all underlying work at Catalist.\n  \n Principal Duties & Responsibilities \n \n  Acts as an advanced user of all internal and external Catalist tools, data, and products for the purpose of supporting client requests and internal projects as needed \n  Gains an understanding of client needs, political implications, and scope by interacting with the Client Services, Analytics, and Technology departments on a regular basis \n  Oversees all projects assigned from start to finish; successfully delivers reports, lists, and other material requests on time, accurately, and in a client-friendly format with actionable insights \n  Executes requests for new business development support from Marketing team \n  Escalates issues and concerns to the Deputy Chief Data Officer as needed \n  Creates and maintains documentation to support all deliverables for future replication \n \n  Requirements \n \n  BS or BA or relevant experience \n  Willingness to be a problem solver and produce results in a fast paced environment \n  Ability to focus on details and make productive suggestions on ways to streamline and improve processes \n  Ability to be creative and personable, and articulate ideas clearly \n  Ability and willingness to learn new skills quickly \n  Ability to become an internal subject matter expert on various datasets and support other Catalist departments/teams on usage of those datasets \n  Background check required \n \n  Preferred Skills & Abilities \n \n  Interest, familiarity or experience with SQL, Python or other relational database programming language \n  Experience in the following: Terminal, R, or using a Unix command line interface \n  Experience managing projects \n  Familiarity with Catalist data, progressive politics, voter files, and/or commercial data \n \n \n   Benefits\n  \n \n  Medical, Dental, Vision, Prescription Drug \n \n \n   Catalist offers Medical, Dental, Vision, and Prescription Drug coverage for eligible staff and their eligible dependents. Catalist\u2019s Medical plan is a comprehensive PPO program including Prescription Drug coverage with 85% of the premium paid by Catalist. Dental and Vision coverage is provided at no cost to employees.\n  \n \n \n  Group Term Life Insurance and Long-Term & Short-Term Disability Coverage \n \n \n   Group Term Life Insurance and Long-Term and Short-Term Disability coverage is available for eligible staff. These benefits are provided at no cost to Catalist employees.\n  \n \n \n  401(k) Safe Harbor Plan \n \n \n   A 401(k) Safe Harbor Plan is available to eligible staff with a 3% contribution from Catalist from the date of hire. Employees may contribute pre-tax or post-tax from their salary up to the legal limits set forth by the IRS.\n  \n \n \n  Medical and Dependent Care Flexible Spending Accounts (FSAs) \n \n \n   Catalist offers an FSA Program that gives eligible staff the ability to pay out-of-pocket medical/dental/vision/child care expenses from pre-tax earnings.\n  \n \n \n  Transit Benefits \n \n \n   Catalist also makes available a Transit benefit FSA program to eligible employees using pre-tax contributions with a company match.\n  \n \n \n  Professional Development and Remote Work Expenses \n \n \n   Eligible employees may be reimbursed up to $750 each year for professional development / education and remote work expenses.\n  \n \n \n  Student Loan PayDown or SaveUp \n \n \n   Catalist offers a Student Loan PayDown and College SaveUp benefit for eligible staff.\n  \n \n \n  Vacation, Personal Leave, Sick Leave Benefits \n \n \n   Catalist offers generous vacation benefits to all eligible staff. Eligible employees also receive:\n  \n \n 14 Paid Holidays \n Personal Days \n Sick Leave \n Parental Leave \n \n \n \n  Hybrid Office/Remote Work \n \n \n   Certain positions at Catalist are eligible for Office/Remote Hybrid or full Remote status.",
        "cleaned_desc": "For over 17 years, Catalist has been a leader in civic data and data science innovation. Our mission is to provide progressive organizations with the data, software, and services needed to better identify, understand, and communicate with the people they need to engage and mobilize. Our clients include the largest, most influential organizations in the U.S. active in civic engagement, advocacy, and political campaigns.\n  \n \n \n  Catalist is home to a dedicated, creative team of technologists, data scientists, and campaign experts committed to using our talents and technology to nurture a vibrant and growing progressive community.\n  \n \n \n  As a Data Services Engineer (DSE) at Catalist, you will have a leading role in providing support and creating solutions for a wide array of Catalist clients and partners as well assisting or leading efforts to manage cross-departmental projects. The DSE supports the Client Services team by providing reports, data for visualizations, lists, and appends that the Catalist suite of tools cannot readily provide.\n  \n \n \n  The ideal candidate will be a highly motivated individual with excellent technical skills, a strong desire to learn new skills, and an interest in progressive politics. Catalist values creativity and problem-solving. Our work is on the cutting edge of data-driven politics, and your support will help Democratic candidates and progressive organizations conduct successful advocacy and electoral campaigns.\n  \n \n \n  This position reports to the Deputy Chief Data Officer. While Data Services Engineers work closely with the Client Services, Analytics, and Tech teams, they are a part of the growing Data team that supports all underlying work at Catalist.\n  \n Principal Duties & Responsibilities \n \n  Acts as an advanced user of all internal and external Catalist tools, data, and products for the purpose of supporting client requests and internal projects as needed \n  Gains an understanding of client needs, political implications, and scope by interacting with the Client Services, Analytics, and Technology departments on a regular basis    Oversees all projects assigned from start to finish; successfully delivers reports, lists, and other material requests on time, accurately, and in a client-friendly format with actionable insights \n  Executes requests for new business development support from Marketing team \n  Escalates issues and concerns to the Deputy Chief Data Officer as needed \n  Creates and maintains documentation to support all deliverables for future replication \n \n  Requirements \n \n  BS or BA or relevant experience \n  Willingness to be a problem solver and produce results in a fast paced environment \n  Ability to focus on details and make productive suggestions on ways to streamline and improve processes \n  Ability to be creative and personable, and articulate ideas clearly \n  Ability and willingness to learn new skills quickly \n  Ability to become an internal subject matter expert on various datasets and support other Catalist departments/teams on usage of those datasets \n  Background check required \n \n  Preferred Skills & Abilities \n \n  Interest, familiarity or experience with SQL, Python or other relational database programming language \n  Experience in the following: Terminal, R, or using a Unix command line interface \n  Experience managing projects \n  Familiarity with Catalist data, progressive politics, voter files, and/or commercial data \n ",
        "techs": [
            "sql",
            "python",
            "terminal",
            "r",
            "unix command line interface"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "terminal",
            "r",
            "unix command line interface"
        ]
    },
    "5141e57d3d341b43": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 101570.0,
        "salary_max": 130000.0,
        "title": "Senior Data Engineer (remote)",
        "company": "Ad Hoc Team",
        "desc": "This is a fully remote position. \n  Work on things that matter  Ad Hoc is a digital services company that helps the federal government better serve people. Our teams use modern, agile methods to design and engineer government systems that connect Veterans with services, bring affordable health care to millions of people, and support important programs like Head Start. And as we work to make critical government services intuitive, accessible, and human-centered, we're also changing how the government thinks about and uses technology. If you thrive on change, want to help close the gap between consumer expectations and government services, and can see the possibilities in ambiguity, then we want you here with us. \n  What matters most  Ad Hoc operates according to our commitment to inclusivity, acceptance, accountability, and humility. We aren't heroes. We believe in missions larger than our individual selves and leave our egos at the door, learn from our mistakes, and iterate in order to better serve the people in our country. We prioritize building teams that represent the diversity of the people our government serves. We love the challenge of government-size projects. We want to bring skills to federal agencies, help them better meet the needs of their users, and close the gap between consumer expectations and government. \n  Built for a remote life  Ad Hoc is remote-first and remote-always. We've designed our culture, communications, and tools to support a nationwide distributed team since the beginning. Being remote by design allows Ad Hoc to be thoughtful and intentional about creating diverse teams and supporting them with a work environment that fits their lives. With a generous PTO policy and Slack channels for every interest (from bird watching to space nerds to parenting) our culture embraces the things happening in your life. Maybe you need to adjust your schedule to care for your family or take a bike ride. At Ad Hoc, that's embraced. \n  The selected candidate will exhibit influential skills to drive improvements in data engineering processes and practices; and they will exhibit a comprehensive understanding of the business, the practices, as well as customer's needs. Build systems that collect, manage, and convert raw data into usable information for data analysts to interpret. Make data accessible so that VA leaders can use it to understand, evaluate, and optimize Veteran experiences. \n  Organizational Overview: \n  The  Veterans Affairs  business unit helps transform the VA into a modern digital services organization where Veteran outcomes are at the center of every effort. We partner with the VA to design and deliver seamless user experiences for Veterans, their families and caregivers, and VA employees. By applying better practices in service design, product management, and technology, we enable VA to increase the usage, quality, and reliability of services and decrease the time Veterans spend waiting for outcomes. \n \n \n  Primary Responsibilities: \n \n  In this role, you will serve as an experienced individual contributor within a team, with the expectation that you will further develop your leadership, guidance and mentoring skills. With minimal oversight from leadership, you will be responsible for supporting the goal of meeting scope, schedule and delivery requirements. A Senior Data Engineer impacts the long-term goals of the program, while contributing to the development of the program's data strategy. You may serve as the discipline's primary lead when working with stakeholders and utilize strong influential skills to drive improvements in data processes and practices. Primary expectations of a Senior Data Engineer include: \n \n Strong influential skills to propose and evaluate multiple approaches to technical and process problems \n Serves as a mentor to individuals within the team \n May leads small, less critical, or temporary team structures and projects \n Presents design documents, system diagrams, etc. to clients, stakeholders, partners, and other engineers \n Fully understands and consistently implements data engineering best practices \n Generates data architecture recommendations and demonstrates the ability to implement them \n Diagnoses and effectively resolves issues with the systems they own, using incidents to inform educational opportunities and system improvements \n Actively mentors and assists more junior engineers in the development of their skills \n Effectively communicates technical issues and developments with team members and clients Deliver large features and foundational improvements with minimal guidance and support \n Participates in technical interviews with new candidates \n \n Basic Qualifications: \n \n Degree - Bachelor's - Business Administration, Business Management, Computer Science, Information Systems, Information Resource Management, Industrial Engineering, or related fields \n 5 years professional experience \n 10 years of profession experience may be substituted for a Degree \n Expert level SQL \n Intermediate experience with Python (including PySpark) \n Experience with data warehousing and data conditioning for analysis, using BigQuery, Synapse, and other tools \n Experience with Databricks, Redshift, or similar (MPB warehouse or lakehouse) \n Experience with Terraform or other infrastructure as code \n Experience gaining access to siloed data sources, integrating into a single working environment \n Working with other technical experts on access requests process espy \n \n Preferred Qualifications: \n \n Experience with JSON, Parquet formats \n Experience working with SAS and other flat files \n \n Learn more about engineering at Ad Hoc. \n  Benefits \n \n Company-subsidized Health, Dental, and Vision Insurance \n Use What You Need Vacation Policy \n 401K with employer match \n Paid parental leave after one year of service \n \n Ad Hoc LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination. \n  In support of the Colorado Equal Pay Transparency Act, and others like it across the country, Ad Hoc job descriptions feature the starting range we reasonably expect to pay to candidates who would join our team with little to no need for training on the responsibilities we've outlined above. Actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, and responsibility. The range of starting pay for this role is $101,570 - $130,000 and information on benefits offered is here. Our recruiters will be happy to answer any questions you may have, and we look forward to learning more about your salary requirements. \n  job reference: 2210",
        "cleaned_desc": " Intermediate experience with Python (including PySpark) \n Experience with data warehousing and data conditioning for analysis, using BigQuery, Synapse, and other tools \n Experience with Databricks, Redshift, or similar (MPB warehouse or lakehouse) \n Experience with Terraform or other infrastructure as code \n Experience gaining access to siloed data sources, integrating into a single working environment \n Working with other technical experts on access requests process espy \n \n Preferred Qualifications: \n \n Experience with JSON, Parquet formats ",
        "techs": [
            "python",
            "pyspark",
            "bigquery",
            "synapse",
            "databricks",
            "redshift",
            "mpb warehouse",
            "lakehouse",
            "terraform",
            "json",
            "parquet"
        ],
        "cleaned_techs": [
            "python",
            "pyspark",
            "bigquery",
            "synapse",
            "databricks",
            "redshift",
            "mpb warehouse",
            "lakehouse",
            "terraform",
            "json",
            "parquet"
        ]
    },
    "b0df89ca99c56243": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 55.0,
        "salary_max": -1.0,
        "title": "Sr. Data Engineer",
        "company": "Computer Enterprises, Inc. (CEI)",
        "desc": "Summary: \n \n CEI's client in the retail industry is currently searching for a Sr. Data Engineer to support their data catalogue platform. \n \n Job at a glance: \n \n Fully remote schedule \n Flexible pay rate on W2 \n 6 Month contract to hire \n \n Responsibilities: \n \n Collaborate with cross-functional teams to contribute to and validate the technical aspects of the Data Catalog Roadmap, ensuring alignment with organizational goals and objectives. \n Configure and customize the data catalog platform, such as Alation, to accurately represent our organization's data landscape, making it a valuable resource for data users. \n Implement and maintain permissions in Alation, ensuring that the Data Catalog is used in accordance with data access policies and security protocols. \n Take ownership of data source-specific configurations in Alation, and delegate specific actions to Data Source Administrators, overseeing their work to maintain consistency and accuracy. \n \n Qualifications: \n \n 2+ years of direct experience in managing and curating data catalogs, with a proven track record of technical expertise. \n 2+ years of experience working closely with data stewardship principles and practices, demonstrating a strong understanding of data governance and stewardship concepts. \n Experience with Cloud Platforms, including Azure Data Lake Storage (ADLS), Unity Catalog, Databricks, and Azure Synapse, with a strong understanding of metadata management, security principles, and fundamental cloud concepts \n Expertise with Python and SQL for querying and managing databases for data storage and retrieval. \n Strong experience in network administration, with a solid foundation in managing data access and security in a networked environment. \n Strong previous experience working with Alation or any other leading data catalog platform, showcasing proficiency in configuring and customizing such tools. \n \n #INDREM \n Job Types: Full-time, Contract \n Pay: From $55.00 per hour \n Expected hours: 40 per week \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Data Catalogue: 2 years (Required) \n Azure: 2 years (Required) \n SQL: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Responsibilities: \n \n Collaborate with cross-functional teams to contribute to and validate the technical aspects of the Data Catalog Roadmap, ensuring alignment with organizational goals and objectives. \n Configure and customize the data catalog platform, such as Alation, to accurately represent our organization's data landscape, making it a valuable resource for data users. \n Implement and maintain permissions in Alation, ensuring that the Data Catalog is used in accordance with data access policies and security protocols. \n Take ownership of data source-specific configurations in Alation, and delegate specific actions to Data Source Administrators, overseeing their work to maintain consistency and accuracy. \n \n Qualifications: \n \n 2+ years of direct experience in managing and curating data catalogs, with a proven track record of technical expertise.   2+ years of experience working closely with data stewardship principles and practices, demonstrating a strong understanding of data governance and stewardship concepts. \n Experience with Cloud Platforms, including Azure Data Lake Storage (ADLS), Unity Catalog, Databricks, and Azure Synapse, with a strong understanding of metadata management, security principles, and fundamental cloud concepts \n Expertise with Python and SQL for querying and managing databases for data storage and retrieval. \n Strong experience in network administration, with a solid foundation in managing data access and security in a networked environment. \n Strong previous experience working with Alation or any other leading data catalog platform, showcasing proficiency in configuring and customizing such tools. \n \n #INDREM \n Job Types: Full-time, Contract \n Pay: From $55.00 per hour \n Expected hours: 40 per week ",
        "techs": [
            "alation",
            "azure data lake storage (adls)",
            "unity catalog",
            "databricks",
            "azure synapse",
            "python",
            "sql"
        ],
        "cleaned_techs": [
            "alation",
            "azure",
            "unity catalog",
            "databricks",
            "python",
            "sql"
        ]
    },
    "660a3142e6c88d46": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 135900.0,
        "salary_max": 166500.0,
        "title": "Senior Data Engineer",
        "company": "Spokeo",
        "desc": "Note: Contractors (C2C, C2H) that directly apply will not be considered. Individual applicants only \n \n  Spokeo is a people search engine and identity platform that enlightens and empowers our customers. With nearly 15 billion records and 18 million monthly visitors, we reconnect friends, reunite families, prevent fraud, and more. \n \n  As a  Senior  Data Engineer  at Spokeo, you will develop, optimize, and maintain the ETL data pipeline. This involves working with infrastructure built in AWS, including Airflow, PySpark, EMR, S3, DynamoDB, and more. This role will help build and improve automation platform features, analytical software packages, and data pipeline orchestration tools. \n \n  What You'll Do:  This includes an estimate of where time will be spent. This is subject to change:  \n \n 40% - Build infrastructure and data automation pipeline for extracting, preparing, and loading data from various sources. Automate and integrate new components into the data pipeline. \n  30% - Implement robust ETL processes to efficiently execute product vision and strategy in alignment with organizational goals and priorities. \n  10% - Create unit and stress test components to monitor technical performance and ensure identified issues are resolved. \n  10% - Develop data analysis tools to provide data insights and capture key metrics. \n  10% - Research solutions and maintain technical documentation. \n  Follow best practices for data governance, quality, cleansing, and ETL-related activities. \n \n \n  Requirements: \n \n  7+ years of development experience in data engineering. \n  5+ years of hands-on programming experience with Python. \n  5+ years of professional experience working in big data ecosystems, preferably with Spark \n  3+ years experience with SQL, schema design, and dimensional data modeling. \n  2+ years of professional experience working with dataflow management tools, such as Airflow \n  2+ years of development experience in highly scalable, distributed systems and cluster architectures using AWS. \n  2+ years experience with non-relational databases (e.g., DynamoDB, Elasticsearch, etc.) \n  Prior experience working with large data sets (>100M+ records) \n  B.S. in Computer Science, Information Systems, or related fields \n \n \n  Named  Best Company for 2023  by Comparably in the areas of  Perks & Benefits, Happiness, Compensation, and Work-Life Balance . \n \n  Spokeo offers a bonus program, equity plans, and 401K matching for qualified roles. Twice a year, we do discretionary, merit-based salary increases. Additional benefits include 100% medical/dental/vision coverage for all employees and unlimited PTO. \n \n  Spokeo extends written offers to candidates who successfully complete their selection process. Spokeo\u2019s offers include a base salary, participation in a company bonus program, stock options, and comprehensive benefits. A final offer will depend on several factors, including, but not limited to, marketplace competition, job leveling, the candidate\u2019s experience, skills, etc. \n \n  Privacy Notice for Candidates: https://www.spokeo.com/recruiting-policy \n \n  Spokeo is an equal opportunity employer. Applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, or protected veteran status. Spokeo fosters a business culture where ideas and decisions from all people help us grow, innovate, create the best products, and be relevant in a rapidly changing world. \n \n  Recruiters or staffing agencies: Spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a Spokeo employee without 1) a current, fully-executed agreement on file, and 2) being assigned to the open position (as a search) via our applicant tracking solution. \n \n  #LI-Remote \n  This is a remote position.",
        "cleaned_desc": " 40% - Build infrastructure and data automation pipeline for extracting, preparing, and loading data from various sources. Automate and integrate new components into the data pipeline. \n  30% - Implement robust ETL processes to efficiently execute product vision and strategy in alignment with organizational goals and priorities. \n  10% - Create unit and stress test components to monitor technical performance and ensure identified issues are resolved. \n  10% - Develop data analysis tools to provide data insights and capture key metrics. \n  10% - Research solutions and maintain technical documentation. \n  Follow best practices for data governance, quality, cleansing, and ETL-related activities. \n \n    Requirements: \n \n  7+ years of development experience in data engineering. \n  5+ years of hands-on programming experience with Python. \n  5+ years of professional experience working in big data ecosystems, preferably with Spark \n  3+ years experience with SQL, schema design, and dimensional data modeling. \n  2+ years of professional experience working with dataflow management tools, such as Airflow \n  2+ years of development experience in highly scalable, distributed systems and cluster architectures using AWS. ",
        "techs": [
            "build infrastructure",
            "data automation pipeline",
            "extracting data",
            "preparing data",
            "loading data",
            "automate components",
            "integrate components",
            "etl processes",
            "unit testing",
            "stress testing",
            "data analysis tools",
            "data insights",
            "key metrics",
            "research solutions",
            "maintain technical documentation",
            "data governance",
            "data quality",
            "data cleansing",
            "etl-related activities",
            "development experience",
            "data engineering",
            "programming experience",
            "python",
            "big data ecosystems",
            "spark",
            "sql",
            "schema design",
            "dimensional data modeling",
            "dataflow management tools",
            "airflow",
            "scalable systems",
            "distributed systems",
            "cluster architectures",
            "aws"
        ],
        "cleaned_techs": [
            "build infrastructure",
            "data automation pipeline",
            "extracting data",
            "preparing data",
            "loading data",
            "automate components",
            "integrate components",
            "etl processes",
            "unit testing",
            "stress testing",
            "data analysis tools",
            "data insights",
            "key metrics",
            "research solutions",
            "data governance",
            "data quality",
            "data cleansing",
            "etl-related activities",
            "development experience",
            "programming experience",
            "python",
            "big data ecosystems",
            "spark",
            "sql",
            "schema design",
            "dimensional data modeling",
            "dataflow management tools",
            "airflow",
            "scalable systems",
            "distributed systems",
            "cluster architectures",
            "aws"
        ]
    },
    "0b376b633602afc3": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 145000.0,
        "salary_max": 185000.0,
        "title": "Data Engineer",
        "company": "CyberCoders",
        "desc": "Data Engineer \n  \n Job Title:  Senior Data Engineer\n   \n Remote:  Yes, 100% Remote\n   \n Job Type:  Direct Hire\n   \n Hours:  Full-Time\n   \n Base Salary Range:  $140-185k (base) / year\n   \n \n Given the clients work with government contracts, you must be an active US Citizen to apply. You will need to obtain a security clearance after hire, but do not need to have one currently. US CITIZENSHIP REQUIRED is for all Government Clearance. Thank you. \n \n  Our team is looking for an experienced Senior Data Engineer to join us in working on top secret DOD cleared projects. Ideally someone with experience in time series and sensor data collecting with the ability to program in Python or R. We are building out a new data engineering team and this role would support our existing 4 data scientists in their efforts by building data pipelines, shaping data, etl, etc.\n  \n  What You Need for this Position \n \n Data Engineering / Cloud Engineering / Database Management Experience \n Incredible SQL Skills (MySQL / SQLite / Oracle) \n Programming experience (Python or R) \n \n \n  Bonus Point For: \n \n \n Sensor Data / Imaging Data / Time Series Data \n IOT  \n Azure Gov / AWS \n Government Clearance \n \n  What's In It for You \n \n Generous Base Salary \n 401k (+match) \n Flexible Remote Schedule \n Health / Dental / Vision \n Vacation / PTO \n 14 Paid holidays + Holiday break around new year / end of year \n \n \n   So, if you are a Data Engineer with experience, please apply today!\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Hanna Frauen\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",
        "cleaned_desc": " Incredible SQL Skills (MySQL / SQLite / Oracle) \n Programming experience (Python or R) \n \n \n  Bonus Point For: \n \n \n Sensor Data / Imaging Data / Time Series Data \n IOT  \n Azure Gov / AWS ",
        "techs": [
            "mysql",
            "sqlite",
            "oracle",
            "python",
            "r",
            "sensor data",
            "imaging data",
            "time series data",
            "iot",
            "azure gov",
            "aws"
        ],
        "cleaned_techs": [
            "mysql",
            "sqlite",
            "oracle",
            "python",
            "r",
            "sensor data",
            "imaging data",
            "time series data",
            "iot",
            "azure",
            "aws"
        ]
    },
    "4bc56b750abd54b0": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 130000.0,
        "title": "Data Engineer (Healthcare)",
        "company": "Rise Technical Recruitment Limited",
        "desc": "Data Engineer (Healthcare)   $100,000 - $130,000 + 401k + PTO + Medical + Dental + Vision   New York - Fully Remote \n  Are you a Data Engineer with experience in Azure, data warehouses, and data pipelines who has worked in the healthcare sector and is looking for a fresh and exciting opportunity to join a health tech firm in its early stages? \n  On offer is an exciting opportunity to join an innovative health tech development team. You'll be at the forefront of expanding and optimizing their data infrastructure, playing a vital role in transforming healthcare with cutting-edge technology. \n  This company is at the pinnacle of revolutionizing healthcare with data-driven solutions. You'll create and maintain data pipeline architecture, work with big data technologies while collaborating with your team enabling them to leverage data effectively. \n  This role would suit an experienced Data Engineer looking for a chance to advance their career in data engineering, expand on their technical knowledge and be part of a team to transform technology based healthcare. \n  The Person \n \n 3+ Years Experience in Data Engineering \n Experience using SQL, Azure and Python \n Knowledge with Data warehouse, Database development and creating ETL pipelines \n Experience working in healthcare \n Degree in Computer Science \n Great Communicator and team player \n \n   \n The Role \n \n Develop and maintain data pipelines. \n Automate tasks, optimize data delivery, and build scalable data infrastructure \n Construct analytics tools for actionable insights by collaborating with cross-functional teams. \n Ensure data security, develop data tools for analytics, and enhance data system functionality.",
        "cleaned_desc": " Experience using SQL, Azure and Python \n Knowledge with Data warehouse, Database development and creating ETL pipelines \n Experience working in healthcare \n Degree in Computer Science   \n Develop and maintain data pipelines. \n Automate tasks, optimize data delivery, and build scalable data infrastructure \n Construct analytics tools for actionable insights by collaborating with cross-functional teams. ",
        "techs": [
            "sql",
            "azure",
            "python",
            "data warehouse",
            "database development",
            "etl pipelines",
            "healthcare",
            "computer science",
            "data pipelines",
            "automate tasks",
            "optimize data delivery",
            "scalable data infrastructure",
            "analytics tools"
        ],
        "cleaned_techs": [
            "sql",
            "azure",
            "python",
            "data warehouse",
            "database development",
            "etl pipelines",
            "healthcare",
            "computer science",
            "data pipelines",
            "automate tasks",
            "optimize data delivery",
            "scalable data infrastructure",
            "analytics tools"
        ]
    },
    "359b49dd25ce92c5": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 226000.0,
        "salary_max": 240000.0,
        "title": "Full Stack Principal Engineer II - Payments Team",
        "company": "Stitch Fix",
        "desc": "We\u2019re a team of bright, kind individuals who are motivated by challenge and who care deeply about achieving great things. We know our individual strengths, but believe we only win as a team. We\u2019re transforming the way people find what they love - and we need your big ideas. We just might be the perfect fit. \n \n \n \n  ABOUT THE ROLE\n  \n \n   You will deliver products and solutions\u2014not just features\u2014by developing an understanding of how Stitch Fix works. We trust you to focus your time and efforts where they are needed most. Your commitment to applying technology to business challenges in clean & innovative ways will make you a trusted advisor to your partners and their teams. You will own projects and influence our direction.\n  \n \n   You won\u2019t do this alone. Your team will collaborate with business partners to define product requirements, plans, and deliverables. You will work with team members to take advantage of learning and growth opportunities in tech and product through real day-to-day work. You will impact the business in tangible, visible ways and always have a seat at the table.\n  \n \n   We are looking for Engineers for our Payments team: We cannot succeed without creative engineers. Your cross-functional team will propose and build solutions for financial transaction processing, discount application, tax accounting, and decline resolution. In Payments Engineering, we are scaling our payments system to serve more and more clients. As a Principal Software Engineer, you will help shape the future of Stitch Fix\u2019s payments systems. You will also be responsible for planning, building, and maintaining features and software in support of that future.\n  \n \n   Building valuable and sustainable software is a group activity. You will work within a distributed team of 6 - 8 software engineers and cross-functional partners including product, design, algorithms, finance, etc. You're expected to have strong written communication skills and be able to develop strong working relationships with coworkers and business partners. You will need to know when and how to listen to, influence, coach, share with, advocate to, and lead others.\n  \n \n   This is a remote position available within the United States. We operate in an agile-inspired manner; collaborating across multiple time zones. We build modern software with modern techniques like TDD, continuous delivery, DevOps, and service-oriented architecture. We focus on high-value products that solve clearly identified problems but are designed in a sustainable way and deliver long-term value.\n  \n \n   YOU\u2019RE EXCITED ABOUT THIS OPPORTUNITY BECAUSE YOU WILL\u2026\n  \n \n \n   Operate as an engaged member of the engineering team - designing complex system designs, recommending solutions and 3rd party integrations, providing input on technical design documents & project plans, pairing with other engineers and stakeholders to work toward a solution, etc.\n   \n \n   Collaborate with stakeholders while leading the execution of complex and/or critical projects within the Payments team or across multiple engineering teams.\n   \n \n   Model consistently sustainable results against measurable goals.\n   \n \n   Break down projects into actionable milestones.\n   \n \n   Proactively communicate status updates or changes to the scope or timeline of projects to stakeholders and leadership.\n   \n \n   Provide technical leadership, mentorship, pairing opportunities, timely feedback, and code reviews to encourage the growth of others.\n   \n \n   Actively invest in the professional development and career growth of your teammates and peers.\n   \n \n   Frame business problems using high-quality data analysis and empirical evidence for leadership.\n   \n \n   Find new and better ways of doing things that align with business priorities.\n   \n \n   Influence other engineers toward right-sized solutions.\n   \n \n   Participate in on-call rotations and improve the on-call experience for others.\n   \n \n   Help Stitch Fix continue to develop new methods of collaborating with partners across the organization.\n   \n \n \n  WE ARE EXCITED ABOUT YOU BECAUSE...\n  \n \n \n   You have roughly 10+ years of professional programming experience.\n   \n \n   You have experience in the payment processing engineering space\n   \n \n   You have hands-on experience with running Ruby on Rails, along with other modern web stacks (e.g. Node, React, Golang, Postgres, GraphQL, Kafka).\n   \n \n   3+ years of experience in technical leadership - including driving technical decisions and guiding broader project goals.\n   \n \n   You are bright, kind, and motivated by challenges.\n   \n \n   You have excellent analytical skills as well as communication skills both verbal and written.\n   \n \n   You treasure helping your team members grow and learn.\n   \n \n   You take initiative and operate with accountability.\n   \n \n   You are motivated by solving problems and finding creative client-focused solutions.\n   \n \n   You build high-quality solutions and are pragmatic about weighing project scope and value.\n   \n \n   You are flexible, dedicated to your craft, and curious.\n   \n \n   You might have experience working remotely alongside a distributed software engineering team.\n   \n \n   You might have experience with evolving a resilient distributed service architecture.\n   \n \n \n \n   You might have experience with GraphQL schema design.\n   \n \n   You might have prior experience with accessibility best practices.\n   \n \n \n  OUR TECH STACK INCLUDES...\n  \n \n \n   Ruby, Rails, Golang and some Node.js\n   \n \n   GraphQL and PostgreSQL\n   \n \n   Kafka\n   \n \n   React, JavaScript, TypeScript, CSS, HTML\n   \n \n \n  YOU'LL LOVE WORKING AT STITCH FIX BECAUSE WE...\n  \n \n \n   Are a group of bright, kind people who are motivated by challenge. You can be your authentic self here, and are empowered to encourage others to do the same!\n   \n \n   Value integrity, innovation, and trust.\n   \n \n   Are a technologically and data-driven business.\n   \n \n   Are at the forefront of tech and fashion, redefining shopping for the next generation.\n   \n \n   Are passionate about our clients and live/breathe the client experience.\n   \n \n   Get to be creative every day.\n   \n \n   Have a smart, experienced, and diverse leadership team that wants to do it right & is open to new ideas.\n   \n \n   Believe in autonomy & taking initiative.\n   \n \n   Full support for remote work & lean into async communications.\n   \n \n   Offer transparent, equitable, and competitive compensation based on your level to help eliminate bias in salaries, as well as equity and comprehensive health benefits.\n   \n \n   Are serious about our commitment to life-work balance, and have generous parental leave policies.\n   \n \n \n \n \n \n \n    COMPENSATION AND BENEFITS\n     \n  Our anticipated compensation reflects the cost of labor across several US geographic markets, and the range below indicates the low end of the lowest-compensated market to the high end of the highest-compensated market. This position is eligible for new hire and ongoing grants of restricted stock units depending on employee and company performance. In addition, the position is eligible for medical, dental, vision, and other benefits. Applicants should apply via our internal or external careers site.\n    \n  Salary Range \n \n     $226,000\u2014$240,000 USD\n    \n \n \n \n \n   This link leads to the machine readable files that are made available in response to the federal Transparency in Coverage Rule and includes negotiated service rates and out-of-network allowed amounts between health plans and healthcare providers. The machine-readable files are formatted to allow researchers, regulators, and application developers to more easily access and analyze data.\n   \n \n    Please review Stitch Fix's US Applicant Privacy Policy and Notice at Collection here: https://stitchfix.com/careers/workforce-applicant-privacy-policy\n   \n \n    RECRUITING FRAUD ALERT:\n   \n \n    To all candidates: your personal information and online safety are top of mind for us. At Stitch Fix, recruiters only direct candidates to apply through our official career pages at https://www.stitchfix.com/careers/jobs or https://web.fountain.com/c/stitch-fix.\n   \n \n    Recruiters will never request payments, ask for financial account information or sensitive information like social security numbers. If you are unsure if a message is from Stitch Fix, please email RecruitingOperations@stitchfix.com.\n   \n \n    You can read more about Recruiting Scam Awareness on our FAQ page here: https://support.stitchfix.com/hc/en-us/articles/1500007169402-Recruiting-Scam-Awareness",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "5b30a33385f8e255": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 110000.0,
        "title": "Software Engineer - Reports",
        "company": "Law School Admission Council",
        "desc": "Overview: \n  \n   LSAC is a not-for-profit organization whose mission is to advance law and justice by encouraging diverse, talented individuals to study law and by supporting their enrollment and learning journeys from prelaw through practice. LSAC provides products and services that support candidates and schools throughout the law school admission process, and innovative solutions to expand and diversify the range of prelaw students, enhance student outcomes in law school, and support legal professionals throughout their careers.\n  \n \n  Summary of Position: \n \n   We are seeking a Power BI embedded reports Software Engineer/ Developer to join our reporting team. You will work as part of an autonomous agile team to develop reports to meet the needs of your stakeholders. We are looking for a candidate with a strong agile mindset. In addition, this position will be responsible for creating and maintaining visual reports, predictive analytics, data analyses and maintaining a web-based application. We rely heavily on web-based services, and you will have the opportunity to work with new and interesting technology.\n  \n \n \n  Salary Range is $100-110k  \n Responsibilities: \n   Essential Functions: \n  Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position. The individual employed in this position will be required to: \n \n  Collaborate with partners within the company to design, configure, maintain, and promote a variety of internally and externally facing reports. \n  Use Power BI and other tools to mine data, create dashboards, analyze data, identify trends, and help others explore data.  \n Continuously monitor, evaluate, and optimize reports. \n  Collaborate with software engineers, product managers, analysts, and stakeholders to deliver solutions that meet customer expectations. \n  Contributes as part of the team to continuous code delivery using source control and deployment tools. \n  Responsible for delivering high quality products and reliable analysis. \n  Be a contributor of knowledge to the team by reviewing code, dashboards and data analysis as well as sharing experience and listening. \n  Qualifications: \n  \n  Competencies:   \n \n \n \n \n Comfortable working in an agile environment and are comfortable challenging yourself and your team to improve their ways of working. \n  Knowledge of modern development practices and the development lifecycle with experience using Scrum, Kanban, Lean or other agile methodologies. \n  Values the success of the team over personal objectives. \n  Effective communication skills, both written and verbal as well as experience with MS Teams. \n  Experience with editing/creating work product for all, including people with disabilities, which is compliant with Web Content Accessibility Guidelines (WCAG) 2.1 or a willingness and aptitude to learn accessibility best practices and standards. \n \n  Required Experience and Education:  \n \n B.A. or B.S. degree (preferred) or 5+ years related experience. \n  Experience with relational databases. Specifically, strong knowledge in SQL Server, Oracle, and Cosmos. \n  Experience with Microsoft Power BI software and DAX (preferred) in an embedded environment or other visual reporting software (Tableau, SAP, Qlik\u2026). \n  Experience with Power BI paginated reports or SSRS experience. \n  Experience embedding Power BI reports in a custom web application using the Power BI API\u2019s, C#, and .NET. \n \n  Preferred Experience and Education:  \n \n Experience with any of the following disciplines is a plus:\n    \n  .NET Core, . Framework, RESTful API, Web API \n  MS Azure (Service Fabric, DevOps, Cloud Services, etc.) \n \n \n  Supervisory Responsibilities: \n \n  This position has no supervisory responsibilities. \n \n  Position Type: \n \n  The LSAC standard business hours are Monday-Friday, 8:30 a.m. - 4:45 p.m. ET. While these are the standard office hours for LSAC, as an exempt employee, the employee will be expected to work the hours necessary to satisfactorily complete their assignments in a responsible and professional manner. \n \n \n  Travel:  \n \n \n No travel is expected for this opening. \n \n \n  Work Environment: \n \n \n  This job operates in a remote and professional office environment. Whether remote or in-office, this role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. \n \n \n  Physical Demands:  \n \n \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. \n  While performing the duties of this job, the employee is regularly required to write, hear, speak, and present materials.  \n \n \n Additional Information: \n \n \n  Please note that this job description may not contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Job responsibilities may change at any time with or without notice. Except as otherwise provided by law, all terms of employment are subject on an at-will basis and can change at any time. \n \n \n  LSAC actively seeks to foster greater levels of diversity in our workforce and in our pipeline of future leaders. We are committed to attract and retain candidates who have a passion for their work and encourage all qualified individuals, including minorities, women, LGBTQIA+, and individuals with a disability, to apply. LSAC is an Equal Opportunity Employer. \n \n \n \n  #LI-Remote",
        "cleaned_desc": " Continuously monitor, evaluate, and optimize reports. \n  Collaborate with software engineers, product managers, analysts, and stakeholders to deliver solutions that meet customer expectations. \n  Contributes as part of the team to continuous code delivery using source control and deployment tools. \n  Responsible for delivering high quality products and reliable analysis. \n  Be a contributor of knowledge to the team by reviewing code, dashboards and data analysis as well as sharing experience and listening. \n  Qualifications: \n  \n  Competencies:   \n \n \n \n \n Comfortable working in an agile environment and are comfortable challenging yourself and your team to improve their ways of working. \n  Knowledge of modern development practices and the development lifecycle with experience using Scrum, Kanban, Lean or other agile methodologies. \n  Values the success of the team over personal objectives. \n  Effective communication skills, both written and verbal as well as experience with MS Teams. \n  Experience with editing/creating work product for all, including people with disabilities, which is compliant with Web Content Accessibility Guidelines (WCAG) 2.1 or a willingness and aptitude to learn accessibility best practices and standards. \n    Required Experience and Education:  \n \n B.A. or B.S. degree (preferred) or 5+ years related experience. \n  Experience with relational databases. Specifically, strong knowledge in SQL Server, Oracle, and Cosmos. \n  Experience with Microsoft Power BI software and DAX (preferred) in an embedded environment or other visual reporting software (Tableau, SAP, Qlik\u2026). \n  Experience with Power BI paginated reports or SSRS experience. \n  Experience embedding Power BI reports in a custom web application using the Power BI API\u2019s, C#, and .NET. \n \n  Preferred Experience and Education:  \n \n Experience with any of the following disciplines is a plus:\n    \n  .NET Core, . Framework, RESTful API, Web API \n  MS Azure (Service Fabric, DevOps, Cloud Services, etc.) \n \n \n  Supervisory Responsibilities: \n ",
        "techs": [
            "sql server",
            "oracle",
            "cosmos",
            "microsoft power bi software",
            "dax",
            "tableau",
            "sap",
            "qlik",
            "power bi paginated reports",
            "ssrs",
            "power bi api's",
            "c#",
            ".net",
            ".net core",
            "restful api",
            "web api",
            "ms azure",
            "service fabric",
            "devops",
            "cloud services"
        ],
        "cleaned_techs": [
            "sql",
            "oracle",
            "cosmos",
            "powerbi",
            "dax",
            "tableau",
            "sap",
            "qlik",
            "ssrs",
            "c#",
            ".net",
            ".net core",
            "restful api",
            "web api",
            "ms azure",
            "service fabric",
            "devops",
            "cloud services"
        ]
    },
    "7a9da4412abf8268": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 80000.0,
        "salary_max": -1.0,
        "title": "Software Engineer (Remote)",
        "company": "M-Partners, Inc.",
        "desc": "At M-Partners, we leverage new concepts in automation, analytics, artificial intelligence, and systems integrations to pioneer solutions for our clients. We are seeking a motivated software engineer to join our team. If you love to code and solve challenging problems while working independently, we'd love to work with you! \n What you\u2019ll do: \n \n Assist in building scalable, highly reliable product features \n Assist with designing, implementing, and maintaining applications used by both mobile and internal systems \n Work closely with development team to architect high-throughput systems \n Assist in creating, maintaining, and improving systems and architecture used for data analysis \n Build user-facing interfaces for interacting with data \n Apply problem solving and analytical skills to a variety of issues \n Interact with cross functional teams to produce scalable solutions \n Rapidly fix bugs and solving problems \n Conduct design and code reviews \n Use source control and bug tracking systems \n Document best practices and help create knowledge base \n Unit-testing code for robustness, including edge cases, usability, and general reliability \n Refactor and improving maintainability of existing code base \n Participate in resolving customer support issues as needed \n \n What we\u2019re looking for: \n \n Bachelor\u2019s Degree in Computer Science, Computer Engineering, or related field \n 2+ years of software development experience \n Solid understanding of the full development life cycle \n Knowledge of version control systems such as GIT \n Ability to understand and articulate both technical and business issues with peers, management, and external teams \n Knowledge of agile development methodologies \n Exceptional collaborative, written and, verbal communication skills \n Experience in dynamic scripting languages \n Knowledge of machine learning languages such as Python and R along with associated libraries for modelling, analysis and outlier identification \n Knowledge of SQL and relational database design \n Knowledge of RESTful API design \n Must be a U.S. Person/Permanent Resident \u201cGreen Card\u201d holder \n \n What we offer: \n \n Challenging work and cutting-edge technology \n Flexibility and autonomy \n Comprehensive health benefits \n Paid time off and holidays \n Opportunity to grow \n \n Job Type: Full-time \n Salary: From $80,000.00 per year \n Benefits: \n \n Dental insurance \n Employee assistance program \n Flexible schedule \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Professional development assistance \n Referral program \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n COVID-19 considerations: This is a remote position, however if gathering with others for work purposes a mask and social distancing may be required. Compliance requirements with federal or state rules will be followed. \n Application Question(s): \n \n What is your desired salary? \n Do you now or will you at any time in the future require Visa sponsorship? \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Python: 2 years (Required) \n Microservices: 2 years (Preferred) \n JavaScript: 2 years (Preferred) \n Docker: 2 years (Preferred) \n Databases: 2 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "At M-Partners, we leverage new concepts in automation, analytics, artificial intelligence, and systems integrations to pioneer solutions for our clients. We are seeking a motivated software engineer to join our team. If you love to code and solve challenging problems while working independently, we'd love to work with you! \n What you\u2019ll do: \n \n Assist in building scalable, highly reliable product features \n Assist with designing, implementing, and maintaining applications used by both mobile and internal systems \n Work closely with development team to architect high-throughput systems \n Assist in creating, maintaining, and improving systems and architecture used for data analysis \n Build user-facing interfaces for interacting with data \n Apply problem solving and analytical skills to a variety of issues \n Interact with cross functional teams to produce scalable solutions \n Rapidly fix bugs and solving problems \n Conduct design and code reviews \n Use source control and bug tracking systems \n Document best practices and help create knowledge base \n Unit-testing code for robustness, including edge cases, usability, and general reliability   Refactor and improving maintainability of existing code base \n Participate in resolving customer support issues as needed \n \n What we\u2019re looking for: \n \n Bachelor\u2019s Degree in Computer Science, Computer Engineering, or related field \n 2+ years of software development experience \n Solid understanding of the full development life cycle \n Knowledge of version control systems such as GIT \n Ability to understand and articulate both technical and business issues with peers, management, and external teams \n Knowledge of agile development methodologies \n Exceptional collaborative, written and, verbal communication skills \n Experience in dynamic scripting languages \n Knowledge of machine learning languages such as Python and R along with associated libraries for modelling, analysis and outlier identification \n Knowledge of SQL and relational database design ",
        "techs": [
            "automation",
            "analytics",
            "artificial intelligence",
            "systems integrations",
            "software engineer",
            "scalable",
            "highly reliable",
            "designing",
            "implementing",
            "maintaining",
            "mobile",
            "internal systems",
            "development team",
            "architect",
            "high-throughput systems",
            "creating",
            "improving",
            "systems",
            "architecture",
            "data analysis",
            "user-facing interfaces",
            "problem solving",
            "analytical skills",
            "cross functional teams",
            "bugs",
            "problems",
            "design",
            "code reviews",
            "source control",
            "bug tracking systems",
            "best practices",
            "knowledge base",
            "unit-testing",
            "edge cases",
            "usability",
            "reliability",
            "refactoring",
            "maintainability",
            "customer support",
            "computer science",
            "computer engineering",
            "software development",
            "development life cycle",
            "git",
            "technical issues",
            "business issues",
            "agile development methodologies",
            "collaborative",
            "written communication skills",
            "verbal communication skills",
            "dynamic scripting languages",
            "machine learning languages",
            "python",
            "r",
            "modelling",
            "analysis",
            "outlier identification",
            "sql",
            "relational database design"
        ],
        "cleaned_techs": [
            "automation",
            "ai",
            "systems integrations",
            "software engineer",
            "scalable",
            "highly reliable",
            "designing",
            "implementing",
            "maintaining",
            "mobile",
            "internal systems",
            "development team",
            "architect",
            "high-throughput systems",
            "creating",
            "improving",
            "systems",
            "architecture",
            "user-facing interfaces",
            "problem solving",
            "cross functional teams",
            "bugs",
            "problems",
            "design",
            "code reviews",
            "source control",
            "bug tracking systems",
            "knowledge base",
            "unit-testing",
            "edge cases",
            "usability",
            "reliability",
            "refactoring",
            "maintainability",
            "customer support",
            "computer science",
            "computer engineering",
            "software development",
            "development life cycle",
            "git",
            "technical issues",
            "business issues",
            "agile development methodologies",
            "collaborative",
            "dynamic scripting languages",
            "machine learning languages",
            "python",
            "r",
            "modelling",
            "analysis",
            "outlier identification",
            "sql",
            "relational database design"
        ]
    },
    "e79a656b4a44fc11": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 168000.0,
        "salary_max": 206000.0,
        "title": "Frontend Engineer",
        "company": "Cloudflare",
        "desc": "About Us \n \n \n At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world's largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine's Top Company Cultures list and ranked among the World's Most Innovative Companies by Fast Company. \n  We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us! \n \n \n  About the team \n  The Support Operations is a team of engineers and data scientists who write applications to improve the efficiency of the Global Cloudflare Customer Support Team. We are responsible for a diverse mix of systems and network tooling that leverage machine learning to provide intelligent responses to Cloudflare customers' and diagnostics across the Cloudflare edge network. \n  What you'll do \n  As a Frontend Engineer on the Support Operations team, you will be responsible for building and maintaining the frontend pages that enable our customers to receive support for Cloudflare products. Our pages are feature rich and offer customers a variety of dynamic information and opportunities to self service their issues. As Cloudflare continues to grow our demand for top notch support becomes ever increasing. An ideal candidate will need to be able to rapidly evolve the existing pages, while being responsibly independent with technical decision making. \n  Key Responsibilities: \n \n Collaborate with the product team to design and implement user-friendly and responsive web applications. \n Develop high-quality, maintainable, and scalable code using React and TypeScript. \n Implement best practices for user interface development and ensure cross-browser compatibility. \n Work closely with backend developers to integrate front-end components with API endpoints. \n Write unit tests and perform debugging to ensure the quality and reliability of the codebase. \n Optimize web applications for a smooth user experience. \n Stay up-to-date with the latest trends in web development and propose innovative solutions to enhance the portal. \n \n Qualifications : \n \n Proven experience in front-end development with React and TypeScript. \n Strong understanding of modern web technologies (HTML5, CSS3, JavaScript). \n Experience building tests for front end applications. \n Experience with state management libraries like Redux or Mobx. \n Familiarity with RESTful APIs and asynchronous programming. \n Knowledge of version control systems, preferably Git. \n Ability to work in an Agile development environment and collaborate effectively with cross-functional teams. \n Excellent problem-solving and debugging skills. \n Strong communication and teamwork skills. \n \n Bonus Points \n \n Experience using Cloudflare's products. \n Experience of Zendesk and/or Salesforce, particularly APIs. \n Familiarity with event based analytics systems. \n Design experience. \n Exposure to AI technologies. \n \n Compensation \n  Compensation may be adjusted depending on work location. \n \n For Colorado-based hires: Estimated annual salary of $168,000 - $206,000. \n For New York City-based and California (excluding Bay Area) and Washington hires: Estimated annual salary of $187,000 - $229,000. \n For Bay Area-based hires: Estimated annual salary of $196,000 - $240,000. \n \n Equity \n  This role is eligible to participate in Cloudflare's equity plan. \n  Benefits \n  Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S. \n  Health & Welfare Benefits \n \n Medical/Rx Insurance \n Dental Insurance \n Vision Insurance \n Flexible Spending Accounts \n Commuter Spending Accounts \n Fertility & Family Forming Benefits \n On-demand mental health support and Employee Assistance Program \n Global Travel Medical Insurance \n \n Financial Benefits \n \n Short and Long Term Disability Insurance \n Life & Accident Insurance \n 401(k) Retirement Savings Plan \n Employee Stock Participation Plan \n \n Time Off \n \n Flexible paid time off covering vacation and sick leave \n Leave programs, including parental, pregnancy health, medical, and bereavement leave \n \n \n  What Makes Cloudflare Special? \n  We're not just a highly ambitious, large-scale technology company. We're a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet. \n  Project Galileo : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare's enterprise customers-at no cost. \n  Athenian Project : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration. \n  Path Forward Partnership : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one. \n  1.1.1.1 : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here's the deal - we don't store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers. \n  Sound like something you'd like to be a part of? We'd love to hear from you! \n  This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license. \n  Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer. \n  Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.",
        "cleaned_desc": " Write unit tests and perform debugging to ensure the quality and reliability of the codebase. \n Optimize web applications for a smooth user experience. \n Stay up-to-date with the latest trends in web development and propose innovative solutions to enhance the portal. \n \n Qualifications : \n \n Proven experience in front-end development with React and TypeScript. \n Strong understanding of modern web technologies (HTML5, CSS3, JavaScript). \n Experience building tests for front end applications. \n Experience with state management libraries like Redux or Mobx. \n Familiarity with RESTful APIs and asynchronous programming. \n Knowledge of version control systems, preferably Git. \n Ability to work in an Agile development environment and collaborate effectively with cross-functional teams. \n Excellent problem-solving and debugging skills. \n Strong communication and teamwork skills. \n \n Bonus Points ",
        "techs": [
            "react",
            "typescript",
            "html5",
            "css3",
            "javascript",
            "redux",
            "mobx",
            "restful apis",
            "git"
        ],
        "cleaned_techs": [
            "react",
            "typescript",
            "html5",
            "css3",
            "javascript",
            "redux",
            "mobx",
            "restful apis",
            "git"
        ]
    },
    "f0cbeaad037b7dd5": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 106174.24,
        "salary_max": 134440.25,
        "title": "Junior Software Engineer - Partial Telework",
        "company": "GliaCell Technologies",
        "desc": "Are you a Junior Software Engineer who is ready for a new challenge that will launch your career to the next level? \n \n  Tired of being treated like a company drone? \n  Tired of promised adventures during the hiring phase, then being dropped off on a remote contract and never seen or heard from the mothership again? \n  Our engineers were certainly tired of the same. \n \n  At GliaCell our slogan is \u201cWe make It happen\u201d. \n \n  We will immerse you in the latest technologies. \n  We will develop and support your own personalized training program to continue your individual growth. \n  We will provide you with work that matters with our mission-focused customers, and surround you with a family of brilliant engineers.   \n \n Culture isn\u2019t something you need to talk about\u2026if it just exists. \n  If this sounds interesting to you, then we\u2019d like to have a discussion regarding your next adventure! If you want to be a drone, this isn\u2019t the place for you. \n  We Make It Happen! \n  GliaCell Technologies focuses on Software & System Engineering in Enterprise and Cyber Security solution spaces. We excel at delivering stable and reliable software solutions using Agile Software Development principles. These provide us the capability to deliver a quick turn-around using interactive applications and the integration of industry standard software stacks.  \n GliaCell\u2019s Enterprise capabilities include Full-Stack Application Development, Big Data, Cloud Technologies, Analytics, Machine Learning, AI, and DevOps Containerization. We also provide customer solutions in the areas of CND, CNE, and CNO by providing our customers with assessments and solutions in Threat Mitigation, Vulnerability Exposure, Penetration Testing, Threat Hunting, and Preventing Advanced Persistent Threat. \n  We Offer: \n \n  Long term job security \n  Competitive salaries & bonus opportunities \n  Challenging work you are passionate about \n  Ability to work with some amazingly talented people \n \n  Job Description: \n  GliaCell is seeking a  Junior Software Engineer  on one of our subcontracts. This is a full-time position offering the opportunity to support a U.S. Government customer. The mission is to provide technical expertise that assists in sustaining critical mission-related software and systems to a large government contract. \n  Position Description: \n \n  The team designs, develops, and maintains systems of web-based analysis tools. \n  The software suite includes containerized React user interfaces, Java and Go microservices, a custom REST security, and various data stores including MongoDB and an OpenSearch cluster. \n  It offers users access to real-time alerting, and historical querying using smart query builders, as well as document storage and retrieval. \n  This position will utilize the candidate's software engineering experience as a full-time front-end developer. \n \n  Key Requirements: \n  To be considered for this position you must have the following: \n \n  Possess an active or rein-statable TS/SCI with Polygraph security clearance. \n  U.S. Citizenship. \n  No demonstrated experience is required with a Bachelor's Degree in Computer Science (or related field), or 4 years of experience without the degree. \n  Works well independently as well as on a team. \n  Strong communication skills. \n \n  Key Skills: \n \n  HTML, JavaScript, CSS, React, npm \n \n  Desired Skills: \n \n  REST, Git, CI/CD, Maven, Docker, Java, Go \n \n  Location:  Columbia, MD / Partial Telework \n  Salary:  Based on Education, Years of Experience, Skill and Abilities \n  Check Out Our Benefits: \n \n  Paid Time Off \n  Medical, Dental & Vision Benefits \n  Life & Disability Insurance \n  Tuition, Training & Certification Reimbursement \n  401K Contribution \n  Employee Referral Bonus Program \n  Equipment Reimbursement \n  Team Engagement & Outings \n  Swag \n \n  \u2026And more! \n  Learn more about GliaCell Technologies: https://gliacelltechnologies.applytojob.com/apply/ \n  To apply for this position, respond to this job posting and attach an updated resume for us to review. \n  GliaCell Technologies, LLC is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. \n   \n ghjDds3zSS",
        "cleaned_desc": "  Position Description: \n \n  The team designs, develops, and maintains systems of web-based analysis tools. \n  The software suite includes containerized React user interfaces, Java and Go microservices, a custom REST security, and various data stores including MongoDB and an OpenSearch cluster. \n  It offers users access to real-time alerting, and historical querying using smart query builders, as well as document storage and retrieval. \n  This position will utilize the candidate's software engineering experience as a full-time front-end developer. \n \n  Key Requirements: \n  To be considered for this position you must have the following: \n \n  Possess an active or rein-statable TS/SCI with Polygraph security clearance. \n  U.S. Citizenship. \n  No demonstrated experience is required with a Bachelor's Degree in Computer Science (or related field), or 4 years of experience without the degree. ",
        "techs": [
            "containerized react user interfaces",
            "java",
            "go microservices",
            "custom rest security",
            "mongodb",
            "opensearch cluster"
        ],
        "cleaned_techs": [
            "containerized react user interfaces",
            "java",
            "go microservices",
            "mongodb",
            "opensearch cluster"
        ]
    },
    "e3babdce647469f6": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 118300.0,
        "salary_max": 213850.0,
        "title": "Principal Splunk Engineer",
        "company": "Leidos",
        "desc": "Description   \n Leidos Corporate Group has an immediate opening for a  Principal Splunk Engineer  to join our CIO Performance Management team. In this role, you will lead overall engineering and design support for a very large clustered multi-terabyte distributed Splunk Enterprise and Cribl Stream environment, spanning security, performance, and operational roles. In addition, you will support the full system engineering life cycle, including requirements analysis, design, development, integration, test, documentation, and implementation following defined best practices and operational workflows. \n \n  The ideal candidate will have the skillset to implement, maintain and evolve complex monitoring solutions from the ground up and be able to lead the analysis of complex operational issues in real-time, as well as to lead continuous process improvement through design and application of modern automation tools and methodologies. \n \n  Ability to work well with all levels of management including executives is important in this role as you will collaborate with other engineering team leaders, members and end users to gather requirements and perform troubleshooting. You should also be able to handle seldom, barely defined, and unusual job events. \n \n  This position offers a 100% remote working opportunity. \n \n  Required Qualifications: \n \n  Bachelor's degree and minimum 12 years of experience in Information Technology field. \n  Prior experience should include 6+ years in a Splunk role and 8+ years\u2019 experience in Linux \n  Ability to create, troubleshoot, debug custom Splunk Apps and Add-ons \n  In depth knowledge of props and transforms \n  Deep understanding of the Splunk Common Information Model \n  Knowledge of Cribl Stream \n  Adeptness with Splunk ITSI and service decomposition \n  Exposure to app interface development, using REST API\u2019s \n  Expertise in regular expressions \n  Experience in an object-oriented programming language, preferably Python and JavaScript \n  Understanding of source control tools like git and bitbucket \n  Expert understanding and ability to use of AWS/Azure technology \n  Project Management experience \n  Understanding of iterative development Agile methodology \n  Working knowledge of ITIL Change & Configuration Management \n  US Citizenship is required and able to obtain security clearance \n \n \n  Desired Qualifications: \n \n  Experience maintaining secure and stable Kafka platforms \n  Knowledge of Machine Learning implementation via Splunk \n  Familiarity with Splunk Cloud migrations \n  Understanding the importance of data and how to apply data in decision making \n  Practical applications of automation to workflows and processes - scripting, low-code / no code \n  Familiarity with software languages (ie Python, Java, C++, Go, etc) \n  Familiarity with container technologies (ie Docker, Kubernetes, etc) \n  Familiarity with SQL/ODBC interfaces \n  Exhibit a continuous learning mindset and ability to adapt new technologies to improve Splunk and Cribl operations. \n  Background in Ansible playbook automation \n  Experience in other systems and network management/monitoring products \n  Complete or partial Splunk Admin/Architect training \n  Master\u2019s Degree in related field \n \n \n  Pay Range:  Pay Range $118,300.00 - $213,850.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote",
        "cleaned_desc": "  Required Qualifications: \n \n  Bachelor's degree and minimum 12 years of experience in Information Technology field. \n  Prior experience should include 6+ years in a Splunk role and 8+ years\u2019 experience in Linux \n  Ability to create, troubleshoot, debug custom Splunk Apps and Add-ons \n  In depth knowledge of props and transforms \n  Deep understanding of the Splunk Common Information Model \n  Knowledge of Cribl Stream \n  Adeptness with Splunk ITSI and service decomposition    Exposure to app interface development, using REST API\u2019s \n  Expertise in regular expressions \n  Experience in an object-oriented programming language, preferably Python and JavaScript \n  Understanding of source control tools like git and bitbucket \n  Expert understanding and ability to use of AWS/Azure technology \n  Project Management experience \n  Understanding of iterative development Agile methodology \n  Working knowledge of ITIL Change & Configuration Management \n  US Citizenship is required and able to obtain security clearance   \n \n  Desired Qualifications: \n \n  Experience maintaining secure and stable Kafka platforms \n  Knowledge of Machine Learning implementation via Splunk \n  Familiarity with Splunk Cloud migrations \n  Understanding the importance of data and how to apply data in decision making \n  Practical applications of automation to workflows and processes - scripting, low-code / no code    Familiarity with software languages (ie Python, Java, C++, Go, etc) \n  Familiarity with container technologies (ie Docker, Kubernetes, etc) \n  Familiarity with SQL/ODBC interfaces \n  Exhibit a continuous learning mindset and ability to adapt new technologies to improve Splunk and Cribl operations. \n  Background in Ansible playbook automation \n  Experience in other systems and network management/monitoring products \n  Complete or partial Splunk Admin/Architect training \n  Master\u2019s Degree in related field \n ",
        "techs": [
            "splunk",
            "linux",
            "cribl stream",
            "splunk itsi",
            "rest api",
            "python",
            "javascript",
            "git",
            "bitbucket",
            "aws/azure",
            "kafka",
            "machine learning",
            "splunk cloud",
            "automation",
            "scripting",
            "low-code/no code",
            "software languages (python",
            "java",
            "c++",
            "go)",
            "container technologies (docker",
            "kubernetes)",
            "sql/odbc interfaces",
            "ansible playbook automation",
            "systems and network management/monitoring products."
        ],
        "cleaned_techs": [
            "splunk",
            "linux",
            "cribl stream",
            "splunk itsi",
            "rest api",
            "python",
            "javascript",
            "git",
            "bitbucket",
            "aws",
            "kafka",
            "splunk cloud",
            "automation",
            "scripting",
            "low-code/no code",
            "software languages (python",
            "java",
            "c++",
            "go)",
            "container technologies (docker",
            "kubernetes)",
            "sql",
            "ansible playbook automation",
            "systems and network management/monitoring products."
        ]
    },
    "2e524176ae71fcb9": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 90937.6,
        "salary_max": 133681.6,
        "title": "IT Software Engineer - Remote",
        "company": "Mayo Clinic",
        "desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  Mayo Clinic is seeking a Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. \n  Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction. \n  Qualifications \n \n  Bachelor's Degree in Computer Science/Engineering or related field; Or an Associates\u2019 degree in Computer Science/Engineering or related field with an additional 2 years of experience as described below. \n \n Have working knowledge and experience of Software Engineering with a minimum of internships and a minimum of 1 yr. of experience, or 2yrs of experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.). \n Demonstrated problem solving and time management skills. \n Possesses strong technical aptitude for designing and implementing software solutions. \n Experience with modern application development frameworks. \n Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. \n Deep hands-on technical expertise, excellent verbal and written communication skills. \n Experience with Agile software development techniques. \n \n Preferred Qualifications: \n \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience with Google and Azure cloud environments \n Experience in databases, analytics, big data systems or business intelligence products \n Experience with building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n \n Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program. \n  Exemption Status \n \n  Exempt\n  \n \n Compensation Detail \n \n  $90,937.60 - $133,681.60 / year\n  \n \n Benefits Eligible \n \n  Yes\n  \n \n Schedule \n \n  Full Time\n  \n \n Hours/Pay Period \n \n  80\n  \n \n Schedule Details \n \n  Monday - Friday; 8:00 am - 5:00 pm\n  \n \n Weekend Schedule \n \n  As needed\n  \n \n International Assignment \n \n  No\n  \n \n Site Description \n \n \n  Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.\n   \n \n \n \n \n Affirmative Action and Equal Opportunity Employer \n \n \n  As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.\n    \n \n \n \n \n Recruiter \n \n  Miranda Grabner",
        "cleaned_desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  Mayo Clinic is seeking a Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. \n  Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. Participate in DevOps, Agile, continuous development and integration frameworks. Programming in high-level languages such as Go, Python, Java etc. Work on deployment automation/configuration management with tools including but not limited to ADO, Puppet, Chef or Ansible or Azure Pipelines, CloudFormation, Terraform following a DevOps model. Ensure all appropriate documentation of processes and source code is created and maintained. Communicate effectively with peers, leaders, and customers throughout the organization. Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. Continues to build knowledge of the organization, processes and customers. Performs a range of mainly straightforward assignments. Uses prescribed guidelines or policies to analyze and resolve problems. Receives a moderate level of guidance and direction. \n  Qualifications \n \n  Bachelor's Degree in Computer Science/Engineering or related field; Or an Associates\u2019 degree in Computer Science/Engineering or related field with an additional 2 years of experience as described below. \n \n Have working knowledge and experience of Software Engineering with a minimum of internships and a minimum of 1 yr. of experience, or 2yrs of experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.). \n Demonstrated problem solving and time management skills. \n Possesses strong technical aptitude for designing and implementing software solutions.   Experience with modern application development frameworks. \n Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. \n Deep hands-on technical expertise, excellent verbal and written communication skills. \n Experience with Agile software development techniques. \n \n Preferred Qualifications: \n \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience with Google and Azure cloud environments \n Experience in databases, analytics, big data systems or business intelligence products \n Experience with building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n \n Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program. \n  Exemption Status \n \n  Exempt\n  ",
        "techs": [
            "u.s. news & world report",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "machine learning",
            "software development applications",
            "micro-services",
            "data engineering",
            "platform",
            "solutions teams",
            "devops",
            "agile",
            "high-level languages",
            "go",
            "python",
            "java",
            "deployment automation/configuration management",
            "ado",
            "puppet",
            "chef",
            "ansible",
            "azure pipelines",
            "cloudformation",
            "terraform",
            "computer science/engineering",
            "c",
            "c++",
            "golang",
            "c#",
            "problem solving",
            "time management skills",
            "technical aptitude",
            "application development frameworks",
            "professional software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "open-source technologies",
            "google cloud",
            "azure cloud",
            "databases",
            "analytics",
            "healthcare related industries",
            "united states citizenship or permanent resident status."
        ],
        "cleaned_techs": [
            "u.s. news & world report",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "micro-services",
            "platform",
            "solutions teams",
            "devops",
            "agile",
            "high-level languages",
            "go",
            "python",
            "java",
            "deployment automation/configuration management",
            "ado",
            "puppet",
            "chef",
            "ansible",
            "azure",
            "cloudformation",
            "terraform",
            "computer science/engineering",
            "c",
            "c++",
            "golang",
            "c#",
            "problem solving",
            "technical aptitude",
            "application development frameworks",
            "professional software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "open-source technologies",
            "gcp",
            "databases",
            "healthcare related industries",
            "united states citizenship or permanent resident status."
        ]
    },
    "eb549020902cdd09": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 163200.0,
        "salary_max": 250920.0,
        "title": "Principal Technical Architect",
        "company": "Grainger",
        "desc": "About Grainger:\n  \n Grainger is a leading broad line distributor with operations primarily in North America, Japan and the United Kingdom. We achieve our purpose, We Keep the World Working\u00ae, by serving more than 4.5 million customers with a wide range of products that keep their operations running and their people safe. Grainger also delivers services and solutions, such as technical support and inventory management, to save customers time and money. \n We're looking for passionate people who can move our company forward. As one of the 100 Best Companies to Work For, we have a welcoming workplace where you can build a career for yourself while fulfilling our purpose to keep the world working. We embrace new ways of thinking and recognize everyone is an individual. Find your way with Grainger today. \n \n \n \n  Position Details:\n  \n This is a director level role and will look across business, data, applications, and technology to support delivery teams while providing expertise and perspective on modern software delivery practices. You are champions and co-creators with Product managers and tech leads to bring new ideas, new technologies, and new design patterns to life. You will have a focus on data and analytics systems and patterns, where you will help develop Intelligent data products and solutions. \n You will work with Product Management, Product Engineering leadership, engineers and other Architects, specializing in component capabilities within one or more product domains. You will apply necessary Architectural principles, e.g., APIs, Event-Driven or Cloud-Native Architectures, ensuring there is a program for work agreement across domains. \n You will report to the Senior Director, Technical Architecture and this will be a hybrid or remote role based in Chicago, IL. \n \n \n This position is salaried and will pay $163,200 to $250,920. Total compensation will include annual bonus and long-term incentive. Target total compensation will be in the range of $280,000 - $400,000. \n The range provided is a guideline and not a guarantee of compensation. Other factors that are involved in offer decisions include, and are not limited to: a candidate's experience, qualifications, geographical area, and internal equity of the team. \n \n \n \n \n  You Will:\n  \n \n Steer domain level architecture decisions within the design and architecture review process \n Co-define a domains' roadmap along with a Product Director and an Engineering Director. \n Work with Tech Leads on hard engineering challenges and will write code. \n Research current and latest technologies and proposing changes, where needed at a domain level or enterprise-wide depending on the scope. \n Use lightweight Architecture Decision Records (ADRs) for evaluating architecture approaches or design choices. \n Inform partners about any problems with the current technical solutions being implemented. \n Define new Data Products (in a Data Mesh Architecture) \n Define conceptual, logical, integration and transitional architectures, a lot this other architecture perspectives. \n Lead POCs to validate Solution Options. \n \n \n \n \n \n  You Have:\n  \n \n At least 12 years of industry experience in software engineering and architecture. \n Experience with engineering patterns and multiple implementations (on-prem and cloud) technical expertise. \n Bring a systems-thinking perspective, choosing the appropriate integration patterns between capabilities within their specific domain. \n Demonstrated proficiency in applying machine learning techniques to solve real-world problems using Python, TensorFlow, PyTorch, or similar frameworks. \n Experience in Event-driven, Cloud-native architectures, Data and Analytics Architectures (including Lakehouse), and API design. \n Bachelor's degree in Business (or Management), Computer Science, Engineering, related disciplines, or equivalent work experience. \n \n \n \n \n \n \n  Rewards and Benefits:\n  \n With benefits starting day one, Grainger is committed to your safety, health and wellbeing. Our programs provide choice and flexibility to meet our team members' individual needs. Check out some of the rewards available to you at Grainger \n \n Medical, dental, vision, and life insurance plans \n Paid time off (PTO) and 6 company holidays per year \n Automatic 6% 401(k) company contribution each pay period \n Employee discounts, parental leave, 3:1 match on donations and tuition reimbursement \n A comprehensive set of emotional, financial, physical and social wellbeing programs \n \n \n \n  DEI Statement\n  \n We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace. \n We are committed to fostering an inclusive, accessible environment that includes both providing reasonable accommodations to individuals with disabilities during the application and hiring process as well as throughout the course of one\u2019s employment. With this in mind, should you need a reasonable accommodation during the application and selection process, please advise us so that we can provide appropriate assistance. \n #LI-Hybrid \n #LI-Remote \n #LI-SM1",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "bc14cf4729cba157": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 121282.83,
        "salary_max": 153571.08,
        "title": "Founding Engineer (Full Stack Software)",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  Our client is looking for a Founding Engineer (Full Stack Software) to join our team! You will lead the development of our Core Product: a soil carbon measurement, reporting, and verification (MRV) platform. As the first technical hire, you will work directly with the founders and own the entire technology stack, including making product decisions. You will set the technical roadmap and have the opportunity to build out a world-class technical team and culture as you see best. \n  Ideal candidate traits \n  5+ years of experience building and owning a complete end-to-end technology stack (Frontend + Backend + Cloud + CI/CD) \n  A track record of shipping and going through the full product development cycle right from writing the first line of code to product in the hands of users and iterating quickly on feedback \n  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows \n \n  Proactive and collaborative self-starter with a strong ability to attract other top technical talent and lead them effectively \n \n \ufe0f Past experience working in climate/agriculture is not a requirement, but a passion for climate is a plus! \n \ufe0f Past multidisciplinary teamwork (i.e. e.g. working on software in healthcare) is a huge plus, as you will be working with an interdisciplinary team with expertise in AI, Remote Sensing, Carbon Markets, Soil Carbon Modeling, Sustainable Finance \n \n  Machine Learning and Remote Sensing experience is not required, but understanding how to support these workflows (e.g. setting up data pipelines, setting up infrastructure to parallelize model runs, automating the deployment of models to integrate with the core MRV product) is a huge bonus! \n  You care deeply about climate change and feel a strong moral responsibility to act now. This extends into all facets of your life: both personal and professional. No action is too small and no goal is too big. Whether you have turned vegan or swear by public transport, we are big believers in embracing sustainability as a mindset and would love to learn what this means for you! \n   \n mo1u0GKXja",
        "cleaned_desc": "  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows ",
        "techs": [
            "technology stack",
            "development infrastructure",
            "machine learning",
            "remote sensing workflows"
        ],
        "cleaned_techs": [
            "technology stack",
            "development infrastructure",
            "remote sensing workflows"
        ]
    },
    "b45652c4c5cb364c": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 145000.0,
        "salary_max": 185000.0,
        "title": "Software Infrastructure Architect",
        "company": "Bekhealth Corp",
        "desc": "About Us \n  BEKHealth Corporation is a leading clinical technology company that operates an AI-powered patient-matching software platform serving the clinical trial industry. Our platform allows life sciences and healthcare organizations to speed up trial feasibility, site selection, and patient recruitment by extracting data from electronic medical records (EMRs), which includes structured and unstructured clinical data that captures three times more trial criteria. Our software provides patient population analysis, site feasibility and selection, study participant identification, and study participant matching to site networks. \n \n  About the Opportunity \n  We are seeking an experienced and high-achieving Software Infrastructure Architect to build and enhance our application deployment infrastructure for the BEKHealth platform. The selected individual will play a critical role in driving the BEKHealth mission, developing and improving the BEKHealth Platform. Responsibilities include designing, building and enhancing the BEKHealth applications build and deployment processes, AWS infrastructure, Kubernetes Management, data integrity, and managing application and data security for terabytes of medical data. This position also collaborates across BEKHealth teams to support machine learning and trial recruitment efforts through product development and ensuring data quality and processing performance. \n \n  Responsibilities \n \n Architect and develop AWS infrastructure and deployment systems for the BEKHealth Applications and data processing pipelines. \n Collaborate and contribute to backend data processing applications. \n Produce high-quality, maintainable and well documented code. \n Collaborate with other developers, product owners, and stakeholders to gather requirements and develop solutions that meet business needs. \n Mentor and guide junior developers to improve their technical skills and knowledge. \n Be proactive and solution-oriented, and driven to get things done in high-complexity environments. \n \n \n Work with the Research Services team to launch the BEKHealth platform with new customers \n \n \n \n  Requirements \n \n Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar. \n 6+ years of professional experience as a software engineer \n Experience working with development teams to find cost Optimizations for AWS resources \n Senior level experience with Python and SQL required \n Familiarity with data processing optimization in the areas of   \n \n \n \n \n Memory usage and data query performance \n Parallelization \n Automated Testing Infrastructure \n \n Experience with data modeling and understanding of both relational and document-based databases \n Experience required with relational databases such as Postgres, MySQL, SQLServer, and Snowflake \n Experience working with REST APIs is required \n Experience working with distributed data processing frameworks required \n    \n Such as AWS Glue, AWS Step Functions, Airflow/Prefect \n \n Experience working in Linux and with Kubernetes and Docker or other container orchestration technologies \n Ability to work in a fast-paced, dynamic environment \n \n Personality \n  The ideal candidate is one whom is smart, gets things done and works well with other; and who has been described as focused and entrepreneurial, with great follow-through and attention to detail. Someone who exhibits character, and presence without arrogance, while also being highly credible both internally with the team and externally with customers will be an excellent fit. \n \n  Benefits \n  We offer competitive salary, bonus plan and equity packages, health insurance, and other benefits. You will have the opportunity to work with a talented and passionate team and make a significant impact on the healthcare industry. \n \n  Additional Information \n  Immigration sponsorship is  not  available for this position",
        "cleaned_desc": "About Us \n  BEKHealth Corporation is a leading clinical technology company that operates an AI-powered patient-matching software platform serving the clinical trial industry. Our platform allows life sciences and healthcare organizations to speed up trial feasibility, site selection, and patient recruitment by extracting data from electronic medical records (EMRs), which includes structured and unstructured clinical data that captures three times more trial criteria. Our software provides patient population analysis, site feasibility and selection, study participant identification, and study participant matching to site networks. \n \n  About the Opportunity \n  We are seeking an experienced and high-achieving Software Infrastructure Architect to build and enhance our application deployment infrastructure for the BEKHealth platform. The selected individual will play a critical role in driving the BEKHealth mission, developing and improving the BEKHealth Platform. Responsibilities include designing, building and enhancing the BEKHealth applications build and deployment processes, AWS infrastructure, Kubernetes Management, data integrity, and managing application and data security for terabytes of medical data. This position also collaborates across BEKHealth teams to support machine learning and trial recruitment efforts through product development and ensuring data quality and processing performance. \n \n  Responsibilities \n \n Architect and develop AWS infrastructure and deployment systems for the BEKHealth Applications and data processing pipelines. \n Collaborate and contribute to backend data processing applications.    Requirements \n \n Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar. \n 6+ years of professional experience as a software engineer \n Experience working with development teams to find cost Optimizations for AWS resources \n Senior level experience with Python and SQL required \n Familiarity with data processing optimization in the areas of   \n \n \n   \n Memory usage and data query performance \n Parallelization \n Automated Testing Infrastructure \n \n Experience with data modeling and understanding of both relational and document-based databases \n Experience required with relational databases such as Postgres, MySQL, SQLServer, and Snowflake \n Experience working with REST APIs is required \n Experience working with distributed data processing frameworks required \n    ",
        "techs": [
            "aws infrastructure",
            "kubernetes management",
            "python",
            "sql",
            "postgres",
            "mysql",
            "sqlserver",
            "snowflake",
            "rest apis."
        ],
        "cleaned_techs": [
            "aws",
            "kubernetes management",
            "python",
            "sql",
            "postgres",
            "mysql",
            "sqlserver",
            "snowflake",
            "rest apis."
        ]
    },
    "6666241969e85de2": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 131601.6,
        "salary_max": 190860.8,
        "title": "IT SR Software Engineer, Semantic Services Environment - Remote",
        "company": "Mayo Clinic",
        "desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  The Public and Content Services Section is seeking a Senior Engineer to join our team that supports Mayo's Semantic Services Environment (SSE) platform. This platform leverages a vended application: TopBraid \u2013 Enterprise Data Governance, an enterprise knowledge graph for data governance. Primary responsibilities include the development, configuration, documentation, testing, implementation, and maintenance of the SSE platform. \n  We are seeking a Senior Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. \n \n Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. \n Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. \n Participate in DevOps, Agile, continuous development and integration frameworks. \n Programming in high-level languages such as Go, Python, Java etc. \n Ensure all appropriate documentation of processes and source code is created and maintained. \n Communicate effectively with peers, leaders, and customers throughout the organization. \n Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. \n Contributes to design and architecture discussions with Principals and Architects. \n Leads targeted cross-functional improvement efforts and mentors more junior software engineers. \n Solves complex problems; takes a new perspective on existing solutions. \n Work independently with minimal guidance. You may lead projects or project steps within a broader project or have accountability for ongoing activities or objectives. \n Act as a resource for colleagues with less experience. \n \n During the selection process you may participate in an OnDemand (pre-recorded) interview that you can complete at your convenience. During the OnDemand interview, a question will appear on your screen, and you will have time to consider each question before responding. You will have the opportunity to re-record your answer to each question - Mayo Clinic will only see the final recording. The complete interview will be reviewed by a Mayo Clinic staff member and you will be notified of next steps. \n  Qualifications \n \n  Bachelor's Degree in Computer Science/Engineering or related field with 5 years of experience as noted below; OR an Associate\u2019s degree in Computer/Science/Engineering or related field with 7 years of experience.    Have in-depth knowledge of software engineering with experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.) and a basic knowledge of related fields. Demonstrated problem solving and time management skills. Possesses strong technical aptitude for designing and implementing software solutions. Experience with modern application development frameworks. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Deep hands-on technical expertise, excellent verbal and written communication skills. Experience with Agile software development techniques. \n  Preferred Qualifications: \n \n Master's degree in Computer Science/Engineering or related field. \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience writing software for the cloud (GCP, AWS, Azure). \n Experience in databases, analytics, big data systems or business intelligence products. \n Experience building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n \n Desired technical skills for this role include Linux/Unix, Oracle/MSSQL, JavaScript, HTML and CSS. The work includes developing services and query tools to retrieve/update the semantic data. This team also maintains integrations from several data sources. \n  Knowledge of ADO, GIT, Agile Methodologies (Scrum), Clinical Terminology (FHIR, SNOMED-CD, RxNorm, ICDx, LOINC) and Semantic standards (OWL, RDF, SHACL, SPARQL, GraphQL) are preferred \n  Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program. \n  Exemption Status \n \n  Exempt\n  \n \n Compensation Detail \n \n  $131,601.60 - $190,860.80 / year\n  \n \n Benefits Eligible \n \n  Yes\n  \n \n Schedule \n \n  Full Time\n  \n \n Hours/Pay Period \n \n  80\n  \n \n Schedule Details \n \n  Monday - Friday; 8:00 a.m. - 5:00 p.m. \n  \n \n Weekend Schedule \n \n  May be required to provide 24/7 on-call support\n  \n \n International Assignment \n \n  No\n  \n \n Site Description \n \n \n  Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.\n   \n \n \n \n \n Affirmative Action and Equal Opportunity Employer \n \n \n  As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.\n    \n \n \n \n \n Recruiter \n \n  Miranda Grabner",
        "cleaned_desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  The Public and Content Services Section is seeking a Senior Engineer to join our team that supports Mayo's Semantic Services Environment (SSE) platform. This platform leverages a vended application: TopBraid \u2013 Enterprise Data Governance, an enterprise knowledge graph for data governance. Primary responsibilities include the development, configuration, documentation, testing, implementation, and maintenance of the SSE platform. \n  We are seeking a Senior Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. \n \n Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. \n Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. \n Participate in DevOps, Agile, continuous development and integration frameworks. \n Programming in high-level languages such as Go, Python, Java etc. \n Ensure all appropriate documentation of processes and source code is created and maintained. \n Communicate effectively with peers, leaders, and customers throughout the organization. \n Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. \n Contributes to design and architecture discussions with Principals and Architects.   Leads targeted cross-functional improvement efforts and mentors more junior software engineers. \n Solves complex problems; takes a new perspective on existing solutions. \n Work independently with minimal guidance. You may lead projects or project steps within a broader project or have accountability for ongoing activities or objectives. \n Act as a resource for colleagues with less experience. \n \n During the selection process you may participate in an OnDemand (pre-recorded) interview that you can complete at your convenience. During the OnDemand interview, a question will appear on your screen, and you will have time to consider each question before responding. You will have the opportunity to re-record your answer to each question - Mayo Clinic will only see the final recording. The complete interview will be reviewed by a Mayo Clinic staff member and you will be notified of next steps. \n  Qualifications \n \n  Bachelor's Degree in Computer Science/Engineering or related field with 5 years of experience as noted below; OR an Associate\u2019s degree in Computer/Science/Engineering or related field with 7 years of experience.    Have in-depth knowledge of software engineering with experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.) and a basic knowledge of related fields. Demonstrated problem solving and time management skills. Possesses strong technical aptitude for designing and implementing software solutions. Experience with modern application development frameworks. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Deep hands-on technical expertise, excellent verbal and written communication skills. Experience with Agile software development techniques. \n  Preferred Qualifications: \n \n Master's degree in Computer Science/Engineering or related field. \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience writing software for the cloud (GCP, AWS, Azure). \n Experience in databases, analytics, big data systems or business intelligence products. \n Experience building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n \n Desired technical skills for this role include Linux/Unix, Oracle/MSSQL, JavaScript, HTML and CSS. The work includes developing services and query tools to retrieve/update the semantic data. This team also maintains integrations from several data sources. \n  Knowledge of ADO, GIT, Agile Methodologies (Scrum), Clinical Terminology (FHIR, SNOMED-CD, RxNorm, ICDx, LOINC) and Semantic standards (OWL, RDF, SHACL, SPARQL, GraphQL) are preferred ",
        "techs": [
            "topbraid - enterprise data governance",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "machine learning",
            "go",
            "python",
            "java",
            "devops",
            "agile",
            "continuous development",
            "integration frameworks",
            "high-level languages",
            "c",
            "c++",
            "golang",
            "java",
            "c#",
            "software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "linux/unix",
            "oracle/mssql",
            "javascript",
            "html",
            "css",
            "ado",
            "git",
            "scrum",
            "fhir",
            "snomed-cd",
            "rxnorm",
            "icdx",
            "loinc",
            "owl",
            "rdf",
            "shacl",
            "sparql",
            "graphql"
        ],
        "cleaned_techs": [
            "topbraid - enterprise data governance",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "go",
            "python",
            "java",
            "devops",
            "agile",
            "continuous development",
            "integration frameworks",
            "high-level languages",
            "c",
            "c++",
            "golang",
            "c#",
            "software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "linux/unix",
            "oracle",
            "javascript",
            "html",
            "css",
            "ado",
            "git",
            "scrum",
            "fhir",
            "snomed-cd",
            "rxnorm",
            "icdx",
            "loinc",
            "owl",
            "rdf",
            "shacl",
            "sparql",
            "graphql"
        ]
    },
    "9c203be6a2ab04dd": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 110000.0,
        "salary_max": 110000.0,
        "title": "Computer Engineer IV",
        "company": "Chenega Corporation",
        "desc": "Overview: \n  \n  Computer Engineer IV \n \n \n \n  Lorton, VA (Remote) \n \n \n \n  Are you ready to enhance your skills and build your career in a rapidly evolving business climate? Are you looking for a career where professional development is embedded in your employer\u2019s core culture? If so, Chenega Military, Intelligence & Operations Support (MIOS) could be the place for you! Join our team of professionals who support large-scale government operations by leveraging cutting-edge technology and take your career to the next level!\n  \n \n \n  Chenega Analytic Business Solutions (CABS) provides federal agencies and commercial customers with trusted insights into Records and Information Management, Administrative Solutions, Information Technology, Engineering, and Training. Formed in 2017 to serve federal and commercial customers, CABS is 8(a) certified and has grown quickly into a leader in the federal IT and Training environment.\n  \n \n \n  The \n   Computer Engineer IV  shall research, design, develop, and test computer hardware and software programs. \n  Responsibilities: \n  \n Maintain the current MyNavy Learning (MNL) ecosystem to support training content re-engineering with the incorporation of emerging learning technologies, integrate machine learning content validation pipeline for continuous improvement and continuous delivery, and capture the learner\u2019s data for analysis by intelligence algorithm. \n  Leverage the MNL-optimized DevSecOps environment. \n  Complete various stages of the engineering design, development, testing, evaluation, integration, and fielding of web-based training portals, embedded learning management systems, web-based distributed training technology enablers, mobile hybrid applications, and thousands of hours of Level I\u2013IV learning content for numerous customers throughout the DoD. \n  Coordinate, synchronize, lead, & facilitate MNL integration based on functional requirements (e.g., capability software integration, technical standards implementation + enforcement, capability LOE component integration, capability test + evaluation, capability integration with product owner environment, capability configuration management, continual capability functional + technical enhancements, & continual capability technical sustainment. \n  Conduct research, development, testing, and evaluation (RDT&E) of advanced distributed training technologies, advanced distributed learning technologies, and total learning architecture paradigm. \n  Coordinate, synchronize, manage, & technically integrate all required aspects of MNL DevSecOps environment (includes the MNL Product Owner and Developers Sandbox, MNL standalone/disconnected laptop, and Developers Oracle Virtual Box). \n  Develop new computer software systems and incorporate new technologies in a rapidly growing range of applications. \n  Apply the principles and techniques of computer science, engineering, and mathematical analysis to the design, development, testing, and evaluation of the software and systems that enable computers to perform their many applications. \n  Analyze users\u2019 needs and design, construct, test, and maintain computer applications software, or systems. \n  Solve technical problems that arise. Software engineers must possess strong programming skills but are more concerned with developing algorithms and analyzing and solving programming problems than with writing code. \n  Complete annual company and customer-required training, as required. \n  Complete timesheets daily in an online system according to company policies and procedures. \n  Travel up to 10% as required. \n  Other duties as assigned. \n  Qualifications: \n  \n Bachelor's level degree in Computer, Electrical or Electronics Engineering or Mathematics with field of concentration in computer science. \n  10+ years of professional experience in computer design, software development, or computer networks. \n  Must be a U.S. citizen. \n  Background check required. \n \n \n \n  Knowledge, Skills, and Abilities: \n \n \n  Ability to pass customer security requirements. \n  Advanced working knowledge of computer software applications, including Microsoft Office Suite and Outlook, Excel, and PowerPoint. \n  Proficient in programming languages C, C++, and Java, with Fortran \n  Knowledge of the programming language COBOL. \n  Excellent written, verbal, and interpersonal skills are required. \n  Ability to interact with all levels of staff, government personnel, and management. \n  Ability to attend all customer in-person meetings and conferences as requested. \n  Possess excellent organizational skills with the ability to prioritize. \n  Ability to multi-task in a high-performance-based environment. \n  Possess strong problem-solving skills. \n  Ability to self-start and work independently or as a team. \n  Travel up to 10% as required. \n \n \n  How you\u2019ll grow \n \n \n   At Chenega MIOS, our professional development plan focuses on helping our team members at every level of their careers to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there\u2019s always room to learn.\n  \n \n \n  We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their careers.\n  \n \n \n  Benefits \n \n \n   At Chenega MIOS, we know that great people make a great organization. We value our team members and offer them a broad range of benefits.\n  \n \n   Learn more about what working at Chenega MIOS can mean for you.\n  \n \n \n  Chenega MIOS\u2019s culture \n \n \n   Our positive and supportive culture encourages our team members to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them be healthy, centered, confident, and aware. We offer well-being programs and continuously look for new ways to maintain a culture where we excel and lead healthy, happy lives.\n  \n \n \n  Corporate citizenship \n \n \n   Chenega MIOS is led by a purpose to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our team members, and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities.\n  \n \n   Learn more about Chenega\u2019s impact on the world.\n  \n \n   Chenega MIOS News- https://chenegamios.com/news/\n  \n \n \n  Tips from your Talent Acquisition Team \n \n \n   We want job seekers exploring opportunities at Chenega MIOS to feel prepared and confident. To help you with your research, we suggest you review the following links:\n  \n \n   Chenega MIOS web site - www.chenegamios.com\n  \n \n   Glassdoor - https://www.glassdoor.com/Overview/Working-at-Chenega-MIOS-EI_IE369514.11,23.htm\n  \n \n   LinkedIn - https://www.linkedin.com/company/1472684/\n  \n \n   Facebook - https://www.facebook.com/chenegamios/\n  \n \n \n  #Chenega Analytic Business Solutions, LLC\n   Teleworking Permitted?: true Teleworking Details: Remote Estimated Salary/Wage: USD $110,000.00/Yr. Up to USD $140,000.00/Yr.",
        "cleaned_desc": "  Complete various stages of the engineering design, development, testing, evaluation, integration, and fielding of web-based training portals, embedded learning management systems, web-based distributed training technology enablers, mobile hybrid applications, and thousands of hours of Level I\u2013IV learning content for numerous customers throughout the DoD. \n  Coordinate, synchronize, lead, & facilitate MNL integration based on functional requirements (e.g., capability software integration, technical standards implementation + enforcement, capability LOE component integration, capability test + evaluation, capability integration with product owner environment, capability configuration management, continual capability functional + technical enhancements, & continual capability technical sustainment. \n  Conduct research, development, testing, and evaluation (RDT&E) of advanced distributed training technologies, advanced distributed learning technologies, and total learning architecture paradigm. \n  Coordinate, synchronize, manage, & technically integrate all required aspects of MNL DevSecOps environment (includes the MNL Product Owner and Developers Sandbox, MNL standalone/disconnected laptop, and Developers Oracle Virtual Box). \n  Develop new computer software systems and incorporate new technologies in a rapidly growing range of applications. \n  Apply the principles and techniques of computer science, engineering, and mathematical analysis to the design, development, testing, and evaluation of the software and systems that enable computers to perform their many applications. \n  Analyze users\u2019 needs and design, construct, test, and maintain computer applications software, or systems. \n  Solve technical problems that arise. Software engineers must possess strong programming skills but are more concerned with developing algorithms and analyzing and solving programming problems than with writing code. \n  Complete annual company and customer-required training, as required. \n  Complete timesheets daily in an online system according to company policies and procedures. \n  Travel up to 10% as required. \n  Other duties as assigned. \n  Qualifications: \n  \n Bachelor's level degree in Computer, Electrical or Electronics Engineering or Mathematics with field of concentration in computer science. \n  10+ years of professional experience in computer design, software development, or computer networks. \n  Must be a U.S. citizen. \n  Background check required. \n \n \n \n  Knowledge, Skills, and Abilities: \n \n    Ability to pass customer security requirements. \n  Advanced working knowledge of computer software applications, including Microsoft Office Suite and Outlook, Excel, and PowerPoint. \n  Proficient in programming languages C, C++, and Java, with Fortran \n  Knowledge of the programming language COBOL. \n  Excellent written, verbal, and interpersonal skills are required. \n  Ability to interact with all levels of staff, government personnel, and management. \n  Ability to attend all customer in-person meetings and conferences as requested. \n  Possess excellent organizational skills with the ability to prioritize. \n  Ability to multi-task in a high-performance-based environment. \n  Possess strong problem-solving skills. \n  Ability to self-start and work independently or as a team. \n  Travel up to 10% as required. \n \n \n  How you\u2019ll grow \n \n \n   At Chenega MIOS, our professional development plan focuses on helping our team members at every level of their careers to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there\u2019s always room to learn.\n  \n \n \n  We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their careers.\n  \n ",
        "techs": [
            "web-based training portals",
            "embedded learning management systems",
            "web-based distributed training technology enablers",
            "mobile hybrid applications",
            "level i\u2013iv learning content",
            "mnl integration",
            "capability software integration",
            "technical standards implementation",
            "capability loe component integration",
            "capability test and evaluation",
            "capability integration with product owner environment",
            "capability configuration management",
            "continual capability functional enhancements",
            "continual capability technical enhancements",
            "capability technical sustainment",
            "advanced distributed training technologies",
            "advanced distributed learning technologies",
            "total learning architecture paradigm",
            "mnl devsecops environment",
            "mnl product owner",
            "developers sandbox",
            "mnl standalone/disconnected laptop",
            "developers oracle virtual box",
            "computer software systems",
            "computer science",
            "engineering",
            "mathematical analysis",
            "computer applications software",
            "systems",
            "programming skills",
            "algorithms",
            "programming problems",
            "annual company-required training",
            "customer-required training",
            "customer security requirements",
            "computer software applications",
            "microsoft office suite",
            "outlook",
            "excel",
            "powerpoint",
            "programming languages c",
            "c++",
            "java",
            "fortran",
            "programming language cobol",
            "written skills",
            "verbal skills",
            "interpersonal skills",
            "organizational skills",
            "problem-solving skills",
            "self-starting ability",
            "teamwork",
            "professional development",
            "learning experiences",
            "formal development programs"
        ],
        "cleaned_techs": [
            "web-based training portals",
            "embedded learning management systems",
            "web-based distributed training technology enablers",
            "level i\u2013iv learning content",
            "mnl integration",
            "capability software integration",
            "technical standards implementation",
            "capability loe component integration",
            "capability test and evaluation",
            "capability integration with product owner environment",
            "capability configuration management",
            "continual capability functional enhancements",
            "continual capability technical enhancements",
            "capability technical sustainment",
            "advanced distributed training technologies",
            "advanced distributed learning technologies",
            "total learning architecture paradigm",
            "mnl devsecops environment",
            "mnl product owner",
            "developers sandbox",
            "mnl standalone/disconnected laptop",
            "developers oracle virtual box",
            "computer software systems",
            "computer science",
            "engineering",
            "mathematical analysis",
            "systems",
            "algorithms",
            "programming problems",
            "annual company-required training",
            "customer-required training",
            "microsoft",
            "outlook",
            "excel",
            "powerpoint",
            "programming languages c",
            "c++",
            "java",
            "fortran",
            "programming language cobol",
            "self-starting ability",
            "teamwork",
            "professional development",
            "learning experiences",
            "formal development programs"
        ]
    },
    "cff98dc88b6c6c0e": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 145101.0,
        "salary_max": 210413.0,
        "title": "Principal Software Engineer - Remote",
        "company": "Mayo Clinic",
        "desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  This is a full time remote position within the United States. \n  We are seeking a Principal Software Engineer to design and build back-end services that support our portfolio of process-centric/data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our business, our clients and their patients. \n \n Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. \n Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. \n Participate in DevOps, Agile, continuous development and integration frameworks. \n Programming in high-level languages such as Go, Python, Java etc. \n Ensure all appropriate documentation of processes and source code is created and maintained. \n Communicate effectively with peers, leaders, and customers throughout the organization. \n Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. \n Contributes to design and architecture discussions with Principals and Architects. \n Leads targeted cross-functional improvement efforts and mentors more junior software engineers. \n Interpret internal or external issues and recommend solutions/best practices, solving complex problems with a broad perspective to identify solutions. \n May lead functional teams or projects. \n Ability to works independently, with guidance in only the most complex situations \n \n During the selection process you may participate in an OnDemand (pre-recorded) interview that you can complete at your convenience. During the OnDemand interview, a question will appear on your screen, and you will have time to consider each question before responding. You will have the opportunity to re-record your answer to each question - Mayo Clinic will only see the final recording. The complete interview will be reviewed by a Mayo Clinic staff member and you will be notified of next steps. \n  Mayo Clinic will not sponsor or transfer visas for this position including F1 OPT STEM. \n  Qualifications \n \n \n   Required qualifications for this position include: Bachelor's Degree in Computer Science/Engineering or related field with 10 years of experience as noted below; or Associate\u2019s Degree in Computer Science / Engineering or related field with 12 years of experience as noted below. Have specialized depth and/or breadth of expertise in software engineering with coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.). Experience developing software services for the cloud with a preference for GCP experience. Demonstrated problem solving and time management skills. Possesses strong technical aptitude for designing and implementing software solutions. Experience with modern application development frameworks Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Deep hands-on technical expertise, excellent verbal and written communication skills. Experience with Agile software development techniques. Preferred qualifications for this position include:\n   \n \n Master's degree in Computer Science/Engineering or related field. \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience in databases, analytics, big data systems or business intelligence products. \n Experience building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n \n \n  Exemption Status \n \n  Exempt\n  \n \n Compensation Detail \n \n  $145,101 - $210,413 / year\n  \n \n Hours/Pay Period \n \n  80\n  \n \n Schedule Details \n \n  Monday - Friday, 8am - 5pm\n  \n \n Weekend Schedule \n \n  As needed\n  \n \n International Assignment \n \n  No\n  \n \n Site Description \n \n \n  Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.\n   \n \n \n \n \n Affirmative Action and Equal Opportunity Employer \n \n \n  As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.\n    \n \n \n \n \n Recruiter \n \n  Ted Keefe",
        "cleaned_desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  This is a full time remote position within the United States. \n  We are seeking a Principal Software Engineer to design and build back-end services that support our portfolio of process-centric/data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our business, our clients and their patients. \n \n Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. \n Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. \n Participate in DevOps, Agile, continuous development and integration frameworks. \n Programming in high-level languages such as Go, Python, Java etc. \n Ensure all appropriate documentation of processes and source code is created and maintained. \n Communicate effectively with peers, leaders, and customers throughout the organization.   Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. \n Contributes to design and architecture discussions with Principals and Architects. \n Leads targeted cross-functional improvement efforts and mentors more junior software engineers. \n Interpret internal or external issues and recommend solutions/best practices, solving complex problems with a broad perspective to identify solutions. \n May lead functional teams or projects. \n Ability to works independently, with guidance in only the most complex situations \n \n During the selection process you may participate in an OnDemand (pre-recorded) interview that you can complete at your convenience. During the OnDemand interview, a question will appear on your screen, and you will have time to consider each question before responding. You will have the opportunity to re-record your answer to each question - Mayo Clinic will only see the final recording. The complete interview will be reviewed by a Mayo Clinic staff member and you will be notified of next steps. \n  Mayo Clinic will not sponsor or transfer visas for this position including F1 OPT STEM. \n  Qualifications \n \n \n   Required qualifications for this position include: Bachelor's Degree in Computer Science/Engineering or related field with 10 years of experience as noted below; or Associate\u2019s Degree in Computer Science / Engineering or related field with 12 years of experience as noted below. Have specialized depth and/or breadth of expertise in software engineering with coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.). Experience developing software services for the cloud with a preference for GCP experience. Demonstrated problem solving and time management skills. Possesses strong technical aptitude for designing and implementing software solutions. Experience with modern application development frameworks Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Deep hands-on technical expertise, excellent verbal and written communication skills. Experience with Agile software development techniques. Preferred qualifications for this position include:\n   \n \n Master's degree in Computer Science/Engineering or related field. \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience in databases, analytics, big data systems or business intelligence products. ",
        "techs": [
            "mayo clinic",
            "u.s. news & world report",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "machine learning",
            "software development applications",
            "micro-services",
            "data engineering",
            "platform",
            "solutions teams",
            "devops",
            "agile",
            "high-level languages (go",
            "python",
            "java)",
            "documentation",
            "troubleshooting",
            "design and architecture discussions",
            "software engineers",
            "programming",
            "computer science/engineering",
            "associate's degree",
            "gcp experience",
            "problem solving",
            "time management",
            "application development frameworks",
            "professional software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "master's degree",
            "open-source technologies",
            "cloud-based services",
            "databases",
            "analytics",
            "business intelligence products."
        ],
        "cleaned_techs": [
            "mayo clinic",
            "u.s. news & world report",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "micro-services",
            "platform",
            "solutions teams",
            "devops",
            "agile",
            "high-level languages (go",
            "python",
            "java)",
            "troubleshooting",
            "design and architecture discussions",
            "software engineers",
            "programming",
            "computer science/engineering",
            "gcp",
            "problem solving",
            "time management",
            "application development frameworks",
            "professional software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "open-source technologies",
            "cloud-based services",
            "databases",
            "business intelligence products."
        ]
    },
    "592a1985318da754": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Director, Product",
        "company": "BOLD",
        "desc": "We are looking for a dynamic, hands-on product leader who is passionate about enabling transformative content experiences and leading BOLD into a future powered by the latest advancements in technology. You will manage a team of talented product and data managers who are building a robust, scalable platform that leverages LLMs, machine learning, manual content curation, and provision of services. Partnering with content experts, linguists, data scientists, engineers, and product managers, you will define and execute a strategy that will guide the development of content and data capabilities for our customers. \n  ABOUT THIS TEAM \n  As the Customer Experience Team at Bold, we believe technology has the power to transform the job search journey and we are always looking for ways to help job seekers reach their full career potential. Our team focuses on creating content and data capabilities that address the needs of our customers and build value and intellectual property for our business. Our platform powers multiple products in over 180 countries across all types of jobs and industries-from cashiers to nurses, teachers to graphic designers, construction workers to executives, and beyond. \n  WHAT YOU'LL DO \n \n Oversee global content delivery, service delivery, content tooling, and data tooling for all of BOLD's products across several portals and 8+ different languages. \n Achieve one of the highest revenue targets for any product team in the company. Define the roadmap for a content and data platform that will support millions of job seekers and achieve growth goals. \n Integrate and operationalize GPT/LLM into our content and data operations, managing change and innovation from a people, process, and execution perspective. \n Ensure utilization of career domain data in autocompletes, search & match and segmentation, and other product features and use cases. \n Manage and develop a high-performance team. Optimize resources to fully utilize our experimentation capacity and achieve customer and revenue goals \n Partner closely with engineering teams based in India to align workstreams and effectively leverage our graph-based data pipeline and content authoring capabilities and integrate LLM technologies and machine learning to deliver intelligent recommendations to job seekers \n Collaborate with internal partners that are distributed across the globe. Foster strong cross-functional teamwork with portal product leaders, data scientists, content experts, linguists, engineers, researchers \n \n   WHAT YOU'LL NEED \n \n 10+ years of professional experience in product management, preferably technical product management for platform services, APIs, search, data pipeline, internal tooling \n 5+ years of people management, preferably leading and developing product managers \n 3+ years building, delivering, and supporting large-scale, complex content or data tools, services and/or products \n Demonstrated ability to apply knowledge of machine learning, LLMs, and other Generative AI technologies to solve user problems and create delightful user experiences \n Business acumen and demonstrated track record of making data-driven decisions and driving growth and revenue \n Enjoys the challenge of executing against goals, within complex systems and rapidly evolving technology \n Ability to lead and motivate a team to high performance, teamwork, collaboration, and delivering on goals \n \n WHAT'S GOOD TO HAVE \n \n Experience with data management, ontology development, and natural language processing. \n Product Management experience in start-up, mid-size, and/or larger corporate organizations \n Experience in the human capital industry, recruiting, or educational technology, is a plus \n Master's degree in business or a technology-related field \n Experience with rapid experimentation and A/B Testing, analysis and related tools \n Experience with localization/globalization or foreign language proficiency in at least one of the following languages preferred: French, Spanish, Italian, German, Dutch, Polish, or Portuguese \n Strong analytical capability \n \n BENEFITS \n  OUTSTANDING COMPENSATION \n \n Competitive salary \n Bi-annual bonus \n 401(k) plan with match \n Equity in company \n Flexible spending accounts (health, dependent care) \n Internet and home office reimbursement \n \n 100% FULL HEALTH BENEFITS \n \n Medical, dental, and vision (optional plans for your family) \n Life & long term disability insurance (optional) \n Mental health support and resources \n Wellness reimbursement (gym, health apps, etc.) \n Pet Insurance (optional) \n \n FLEXIBLE TIME AWAY \n \n Flexible PTO \n Sick time policy \n Observed holidays \n 1-week PTO for the December holidays \n \n Under San Francisco's Fair Chance Ordinance, qualified applicants with arrest and conviction records will be considered for the position. \n  #LI-Remote \n \n \n    Individual pay is based on location, transferable skills, experience, and other relevant factors. This estimated range is based on the best available market data and factors, all of which are subject to change. This position may also be eligible for a bonus and medical, dental, vision, life, short and long-term disability insurance, 401(k), paid time off, sick leave, and paid holidays, all subject to applicable plan terms.\n   \n  Starting Hourly Pay \n \n    $192,000\u2014$260,000 USD\n   \n \n \n  ABOUT BOLD  As an established global organization (17 years and counting), BOLD helps people find jobs. Our story is one of growth, success, and professional fulfillment.  We create digital products that have empowered over three million people in 180 countries to build stronger resumes, cover letters, and CVs. The result of our work helps people interview confidently, finding the right job in less time.  Our employees are experts, learners, contributors, and creatives.     BOLD VALUES OUR POSITION AS AN EQUAL OPPORTUNITY EMPLOYER   WE VALUE, CELEBRATE, AND PROMOTE DIVERSITY AND INCLUSION.  We hire based on qualifications, merit, and our business needs. We don't discriminate regarding race, color, religion, gender, pregnancy, national origin or citizenship, ancestry, age, physical or mental disability, veteran status, sexual orientation, gender identity or expression, marital status, genetic information, or any other applicable characteristic protected by law.",
        "cleaned_desc": " \n 10+ years of professional experience in product management, preferably technical product management for platform services, APIs, search, data pipeline, internal tooling \n 5+ years of people management, preferably leading and developing product managers \n 3+ years building, delivering, and supporting large-scale, complex content or data tools, services and/or products \n Demonstrated ability to apply knowledge of machine learning, LLMs, and other Generative AI technologies to solve user problems and create delightful user experiences \n Business acumen and demonstrated track record of making data-driven decisions and driving growth and revenue \n Enjoys the challenge of executing against goals, within complex systems and rapidly evolving technology \n Ability to lead and motivate a team to high performance, teamwork, collaboration, and delivering on goals \n \n WHAT'S GOOD TO HAVE \n \n Experience with data management, ontology development, and natural language processing. \n Product Management experience in start-up, mid-size, and/or larger corporate organizations \n Experience in the human capital industry, recruiting, or educational technology, is a plus ",
        "techs": [
            "machine learning",
            "llms",
            "generative ai technologies",
            "data management",
            "ontology development",
            "natural language processing",
            "start-up experience",
            "mid-size experience",
            "larger corporate experience",
            "human capital industry experience",
            "recruiting experience",
            "educational technology experience"
        ],
        "cleaned_techs": [
            "llm",
            "generative ai technologies",
            "data management",
            "ontology development",
            "nlp",
            "start-up experience",
            "mid-size experience",
            "larger corporate experience",
            "human capital industry experience",
            "recruiting experience",
            "educational technology experience"
        ]
    },
    "59124a44b5f00f6c": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 81837.01,
        "salary_max": 103623.88,
        "title": "Controls Engineer",
        "company": "CW Bearing",
        "desc": "Our Success Formula: Global Network \u2013 Local Service. \n \n \n \n  CW Bearing USA, Inc. is a medium-sized manufacturing company poised for growth over the next few years. We are a globally operational, privately-owned company based in Ningbo, on China\u2019s east coast. The company was founded in 1984 by Hu Xiangen.\n  \n \n \n  We specialize in the development and production of a wide range of premium quality ball bearings for electrical motors, gearboxes, power tools and the automotive industry. We also specialize in ball nuts and ball screws for automotive and industrial customers.\n  \n \n \n  CIXING GROUP CO. LTD. is one of the 10 largest producers of ball bearings in China. We possess a worldwide sales and distribution network and have offices in Asia, Europe, North America and Latin America.\n  \n \n \n  Our ultra-modern production facilities enable us to serve both global customers and mid-sized companies. Regardless of the size of the delivery \u2013 small lots or serial production \u2013 we never lose sight of our customers\u2019 requirements. The establishment of good working partnerships is our highest priority.\n  \n \n \n We offer competitive wages, excellent benefits, 401k with annual employer match, flexible schedules (for applicable positions) clean temperature-controlled manufacturing facility, and much more! \n \n \n \n  We are currently seeking:\n  \n \n \n \n Position: Controls Engineer \n \n \n Reports to: Engineering Manager \n \n \n Classification: Salaried Exempt \n \n \n Work From Home Status: Does Not Apply \n \n \n \n   Job Summary:\n   \n \n   The Controls Engineer drives business profitability by performing machine electrical control design and programming of the Company\u2019s machines.\n    \n \n \n   Supervisory Responsibilities:\n   \n \n   None\n   \n \n \n   Duties & Responsibilities:\n   \n \n Provide key input into the development of departmental strategic goals along with identifying key measurable to support the departmental goals. \n Create PLC program and HMI Programs using Siemens and Omron. \n Maintain PLC based control systems for manufacturing automation and instrumentation. \n Program PLC ladder logic and improve logic to reduce cycle time, reduce downtime due to crashes \n Support machinery installations with electrical and control information as needed \n Lead projects and assist skilled trades in electrical disciplines. \n Manage control engineering projects from conception to final implementation. \n Configure and test PCs for use in material handling automation systems \n Support operations in electrical/controls troubleshooting and continuous improvement activities. \n Generate wiring schematics and control drawings with AutoCAD, maintain all plant electrical prints. \n Work closely with engineering team to define system control needs. \n Select industrial control components, assist with MRO crib. \n Assist corporate controls in engineering changes and new programs. \n Guide, design, develop and test electrical control methods, materials, processes and results. \n Champion assigned engineering changes communicate and coordinate accordingly to all departments. \n Train, coach and mentor the electrical controls process for controls engineers, manufacturing and skilled trades colleagues. \n Support plant activities towards achieving customer awards and Quality registration (ex. TS 16949, ISO 14001, etc.) \n Direct and/or participate in root cause analysis and team problem solving activities (ex. 8D reports, department meetings, etc.). \n Responsible for adhering to all internal and OSHA required safety procedures in performing daily work activities. \n Assure all safety devices are properly in place and utilized and verify individual usage of personal protective equipment (PPE) by the work team. \n Support the Company\u2019s mission vision and values in performance of daily activities \n Maintain a positive working relationship with all levels of the Organization \n Other tasks as assigned by management \n \n \n \n   Required Skills & Abilities:\n   \n \n Working knowledge of PLC hardware and Ladder Logic programming. \n     \n Siemens PLC's \n Siemens Step 7, Siemens TIA Portal \n Omron PLC's \n CX-One \n \n Excellent \"hands on\" electrical/mechanical aptitude. \n Computer literacy and good knowledge of Microsoft Office software. \n Understanding electrical/controls circuitry and schematics. \n Working knowledge of AutoCAD \n Knowledge of factory information system. \n Ability to work well with others in a team environment. \n Excellent organizational, analytical and communication skills \n Ability to Prioritize responsibilities in a fast-paced work environment. \n \n \n \n   Education & Experience:\n   \n \n Bachelor\u2019s Degree in Electrical Engineering \n 5+ year(s) of experience with integration of PLC and CNC controls on machine tool systems is highly desired \n Minimum 5 or more years of related technical, hands-on experience. \n Experienced controls engineer with working knowledge of appropriate electrical controls and safety engineering standards, and industry practices. \n \n \n \n \n    Physical Requirements\n    \n \n    Positions at CW may require the following: alternating between sitting and standing; climbing stairs, ladders, scaffolding or ramps; crouching/stooping; driving; near/far visual acuity; fine motor manipulation; gross motor manipulation; hearing; keyboarding; kneeling; lifting/carrying; moving objects; peripheral visual acuity; pushing or pulling; reaching overhead or below; repetitive task performance; sitting; speaking; standing; using foot or leg controls; walking.\n    \n \n \n    Environmental Requirements\n    \n \n    Our manufacturing facility is a climate-controlled environment. There is no long-term exposure to dangerously loud noise or extreme temperatures.\n    \n \n \n    Cognitive Requirements\n    \n \n    Cognitive abilities include executing tasks independently; learning and/or memorizing tasks; maintaining concentration/focus on tasks; working with/in close proximity to, other people.\n    \n \n \n    Attendance Requirements\n    \n \n    All hourly team members are expected to report to work and be ready to work at their scheduled start time. It is required that they adhere to and follow the attendance policy(ies).\n    \n \n \n    All salaried team members are expected to perform their duties/responsibilities in a timely manner. Although they may not have set schedules, they are expected to either be at work on a schedule agreed upon by their manager or be available via phone/text/Teams if working remotely (Remote work does not apply to CWM positions).\n    \n \n \n All CW entities are equal opportunity employers. \n \n \n \n    Employee Referral Eligible - Level 2/3",
        "cleaned_desc": " Siemens PLC's \n Siemens Step 7, Siemens TIA Portal \n Omron PLC's \n CX-One \n \n Excellent \"hands on\" electrical/mechanical aptitude. \n Computer literacy and good knowledge of Microsoft Office software. \n Understanding electrical/controls circuitry and schematics. \n Working knowledge of AutoCAD \n Knowledge of factory information system. \n Ability to work well with others in a team environment. \n Excellent organizational, analytical and communication skills \n Ability to Prioritize responsibilities in a fast-paced work environment. \n \n \n \n   Education & Experience:\n   \n \n Bachelor\u2019s Degree in Electrical Engineering \n 5+ year(s) of experience with integration of PLC and CNC controls on machine tool systems is highly desired \n Minimum 5 or more years of related technical, hands-on experience. \n Experienced controls engineer with working knowledge of appropriate electrical controls and safety engineering standards, and industry practices. \n \n \n \n \n    Physical Requirements\n    \n ",
        "techs": [
            "siemens plc's",
            "siemens step 7",
            "siemens tia portal",
            "omron plc's",
            "cx-one",
            "autocad"
        ],
        "cleaned_techs": [
            "siemens plc's",
            "siemens step 7",
            "siemens tia portal",
            "omron plc's",
            "cx-one",
            "autocad"
        ]
    },
    "6c5fe0f19f84baac": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 96300.0,
        "salary_max": 159800.0,
        "title": "Application Developer REMOTE",
        "company": "ManTech International Corporation",
        "desc": "Secure our Nation, Ignite your Future  \n \n Become an integral part of a diverse team while working at an Industry Leading Organization, where our employees come first. At ManTech International Corporation, you\u2019ll help protect our national security while working on innovative projects that offer opportunities for advancement.  \n \n Currently, ManTech is seeking a motivated, career and customer-oriented  Application Developer,  to join our team!  For this position the work is remote and candidate must be able to travel to Clarksburg WV site for a one time on-site processing visit as required by the customer.  \n \n Responsibilities include, but are not limited to  \n \n Developing applications using traditional SQL based database management systems (Postgres).  \n Unit testing and automated test development using tools such as Selenium, Protractor, SoapUI, Postman  \n Debugging, troubleshooting, and performance tuning.  \n HTML, CSS, Javascript and its frameworks (Dojo, JQuery, Node).  \n Experience writing reusable Java Libraries  \n Use of Relational databases (Oracle or PostgreSQL)  \n Developing code within Linux Systems  \n Developing applications using traditional SQL based database management systems.  \n Excellent oral and written communication skills to include preparing and delivering presentations and artifacts to customer management.  \n Implementing security controls required by Federal information systems.  \n Working with GIT, Jenkins, Maven/Gradle, Centos Linux, Python  \n Development using Agile Scrum methodologies.  \n Knowledge of SAFe  \n Understand and leverage common software architectural styles and patterns  \n \n \n Basic Qualifications:  \n \n 4 or more years' experience with Java Development in a Linux Environment  \n Requirement analysis; software design, development, integration, bug fixing, and testing  \n Java (Spring-boot), node, Javascript, Angular  \n RESTful API design and development  \n Java and scripting languages such as Python and JavaScript  \n Test case development; automated testing with SoapUI, LoadUI, Selenium, Groovy, etc.  \n Developing applications using traditional SQL based database management systems (Postgres).  \n Debugging, troubleshooting, and performance tuning  \n Excellent oral and written communication skills to include preparing and delivering presentations and artifacts to customer management.  \n Developing RESTful micro service architectures for web and application services using virtual instances, load balancing, automated surge capability, and integrated performance monitoring.  \n Development with Spring, Spring Boot, or Hibernate.  \n Developing applications using NoSQL data management systems and full text searching.  \n Implementing security controls required by Federal information systems.  \n Automating application deployments  \n Developing with Docker and Kubernetes.  \n Supporting development using Agile Scrum methodologies.  \n \n \n Preferred Qualifications:  \n \n Bachelor\u2019s degree (in Computer Science or related field) AND 4 or more years directly related experience  \n AWS Technologies  \n Amazon Web Services GovCloud , Atlassian Suite (Jira, Confluence, Bitbucket, Bamboo, etc.), CloudFormation, Data Analytics Tools (powerBI, Quicksight, Jasper), Docker, Eclipse IDE, Elastic Stack: (Elastic search, Kabana, Logstash, Beats), Git, Groovy  \n Team player willing to work under Senior Software Engineers.  \n Development using Agile Scrum methodologies.  \n Knowledge of SAFe  \n \n \n Security Clearance Requirements:  \n \n Applicants must have an active Top Secret clearance  \n \n \n Physical Requirements:  \n \n Must be able to remain in a stationary position 50%.  \n Needs to occasionally move about inside the office to access file cabinets, office machinery, etc.  \n Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.  \n Often positions self to maintain computers in the lab, including under the desks and in the server closet.  \n Frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.  \n May be asked to move Audio/Visual or Computer equipment weighing up to 50 pounds across and/or around a business campus or large facility.  \n \n The projected compensation range for this position is $96,300-$159,800. There are differentiating factors that can impact a final salary/hourly rate, including, but not limited to, Contract Wage Determination, relevant work experience, skills and competencies that align to the specified role, geographic location (For Remote Opportunities), education and certifications as well as Federal Government Contract Labor categories. In addition, ManTech invests in it\u2019s employees beyond just compensation. ManTech\u2019s benefits offerings include, dependent upon position, Health Insurance, Life Insurance, Paid Time Off, Holiday Pay, Short Term and Long Term Disability, Retirement and Savings, Learning and Development opportunities, wellness programs as well as other optional benefit elections. \n  \n For all positions requiring access to technology/software source code that is subject to export control laws, employment with the company is contingent on either verifying U.S.-person status or obtaining any necessary license. The applicant will be required to answer certain questions for export control purposes, and that information will be reviewed by compliance personnel to ensure compliance with federal law. ManTech may choose not to apply for a license for such individuals whose access to export-controlled technology or software source code may require authorization and may decline to proceed with an applicant on that basis alone.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n ManTech International Corporation, as well as its subsidiaries proactively fulfills its role as an equal opportunity employer. We do not discriminate against any employee or applicant for employment because of race, color, sex, religion, age, sexual orientation, gender identity and expression, national origin, marital status, physical or mental disability, status as a Disabled Veteran, Recently Separated Veteran, Active Duty Wartime or Campaign Badge Veteran, Armed Forces Services Medal, or any other characteristic protected by law.  \n \n If you require a reasonable accommodation to apply for a position with ManTech through its online applicant system, please contact ManTech's Corporate EEO Department at (703) 218-6000. ManTech is an affirmative action/equal opportunity employer - minorities, females, disabled and protected veterans are urged to apply. ManTech's utilization of any external recruitment or job placement agency is predicated upon its full compliance with our equal opportunity/affirmative action policies. ManTech does not accept resumes from unsolicited recruiting firms. We pay no fees for unsolicited services.  \n \n If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access",
        "cleaned_desc": "Secure our Nation, Ignite your Future  \n \n Become an integral part of a diverse team while working at an Industry Leading Organization, where our employees come first. At ManTech International Corporation, you\u2019ll help protect our national security while working on innovative projects that offer opportunities for advancement.  \n \n Currently, ManTech is seeking a motivated, career and customer-oriented  Application Developer,  to join our team!  For this position the work is remote and candidate must be able to travel to Clarksburg WV site for a one time on-site processing visit as required by the customer.  \n \n Responsibilities include, but are not limited to  \n \n Developing applications using traditional SQL based database management systems (Postgres).  \n Unit testing and automated test development using tools such as Selenium, Protractor, SoapUI, Postman  \n Debugging, troubleshooting, and performance tuning.  \n HTML, CSS, Javascript and its frameworks (Dojo, JQuery, Node).  \n Experience writing reusable Java Libraries  \n Use of Relational databases (Oracle or PostgreSQL)  \n Developing code within Linux Systems  \n Developing applications using traditional SQL based database management systems.  \n Excellent oral and written communication skills to include preparing and delivering presentations and artifacts to customer management.  \n Implementing security controls required by Federal information systems.  \n Working with GIT, Jenkins, Maven/Gradle, Centos Linux, Python    Development using Agile Scrum methodologies.  \n Knowledge of SAFe  \n Understand and leverage common software architectural styles and patterns  \n \n \n Basic Qualifications:  \n \n 4 or more years' experience with Java Development in a Linux Environment  \n Requirement analysis; software design, development, integration, bug fixing, and testing  \n Java (Spring-boot), node, Javascript, Angular  \n RESTful API design and development  \n Java and scripting languages such as Python and JavaScript  \n Test case development; automated testing with SoapUI, LoadUI, Selenium, Groovy, etc.  \n Developing applications using traditional SQL based database management systems (Postgres).  \n Debugging, troubleshooting, and performance tuning  \n Excellent oral and written communication skills to include preparing and delivering presentations and artifacts to customer management.  \n Developing RESTful micro service architectures for web and application services using virtual instances, load balancing, automated surge capability, and integrated performance monitoring.  \n Development with Spring, Spring Boot, or Hibernate.  \n Developing applications using NoSQL data management systems and full text searching.    Implementing security controls required by Federal information systems.  \n Automating application deployments  \n Developing with Docker and Kubernetes.  \n Supporting development using Agile Scrum methodologies.  \n \n \n Preferred Qualifications:  \n \n Bachelor\u2019s degree (in Computer Science or related field) AND 4 or more years directly related experience  \n AWS Technologies  \n Amazon Web Services GovCloud , Atlassian Suite (Jira, Confluence, Bitbucket, Bamboo, etc.), CloudFormation, Data Analytics Tools (powerBI, Quicksight, Jasper), Docker, Eclipse IDE, Elastic Stack: (Elastic search, Kabana, Logstash, Beats), Git, Groovy  \n Team player willing to work under Senior Software Engineers.  \n Development using Agile Scrum methodologies.  \n Knowledge of SAFe  \n \n \n Security Clearance Requirements:  \n \n Applicants must have an active Top Secret clearance  ",
        "techs": [
            "selenium",
            "protractor",
            "soapui",
            "postman",
            "dojo",
            "jquery",
            "node",
            "oracle",
            "postgresql",
            "linux",
            "git",
            "jenkins",
            "maven/gradle",
            "centos linux",
            "python",
            "agile scrum",
            "safe",
            "java (spring-boot)",
            "javascript",
            "angular",
            "restful api",
            "groovy",
            "spring",
            "spring boot",
            "hibernate",
            "nosql",
            "docker",
            "kubernetes",
            "aws technologies",
            "amazon web services govcloud",
            "atlassian suite (jira",
            "confluence",
            "bitbucket",
            "bamboo)",
            "cloudformation",
            "data analytics tools (powerbi",
            "quicksight",
            "jasper)",
            "elastic stack (elastic search",
            "kabana",
            "logstash",
            "beats)",
            "git",
            "groovy"
        ],
        "cleaned_techs": [
            "selenium",
            "protractor",
            "soapui",
            "postman",
            "dojo",
            "jquery",
            "node",
            "oracle",
            "postgresql",
            "linux",
            "git",
            "jenkins",
            "maven/gradle",
            "centos linux",
            "python",
            "agile scrum",
            "safe",
            "java (spring-boot)",
            "javascript",
            "angular",
            "restful api",
            "groovy",
            "spring",
            "spring boot",
            "hibernate",
            "nosql",
            "docker",
            "kubernetes",
            "aws",
            "atlassian suite (jira",
            "confluence",
            "bitbucket",
            "bamboo)",
            "cloudformation",
            "data analytics tools (powerbi",
            "quicksight",
            "jasper)",
            "elastic stack (elastic search",
            "kabana",
            "logstash",
            "beats)"
        ]
    },
    "1e5e73d8cc739a6b": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 131601.6,
        "salary_max": 190860.8,
        "title": "IT Senior Software Engineer - Remote",
        "company": "Mayo Clinic",
        "desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  We are seeking a Senior Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. \n \n Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. \n Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. \n Participate in DevOps, Agile, continuous development and integration frameworks. \n Programming in high-level languages such as Go, Python, Java etc. \n Ensure all appropriate documentation of processes and source code is created and maintained. \n Communicate effectively with peers, leaders, and customers throughout the organization. \n Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. \n Contributes to design and architecture discussions with Principals and Architects. \n Leads targeted cross-functional improvement efforts and mentors more junior software engineers. \n Solves complex problems; takes a new perspective on existing solutions. \n Work independently with minimal guidance. You may lead projects or project steps within a broader project or have accountability for ongoing activities or objectives. \n Act as a resource for colleagues with less experience. \n \n \n \n Qualifications \n \n  Bachelor's Degree in Computer Science/Engineering or related field with 5 years of experience as noted below; OR an Associate\u2019s degree in Computer/Science/Engineering or related field with 7 years of experience.    Have in-depth knowledge of software engineering with experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.) and a basic knowledge of related fields. Demonstrated problem solving and time management skills. Possesses strong technical aptitude for designing and implementing software solutions. Experience with modern application development frameworks. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Deep hands-on technical expertise, excellent verbal and written communication skills. Experience with Agile software development techniques. \n  Preferred Qualifications: \n \n Master's degree in Computer Science/Engineering or related field. \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience writing software for the cloud (GCP, AWS, Azure). \n Experience in databases, analytics, big data systems or business intelligence products. \n Experience building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n Experience developing server-side RESTful web services \n Experience in front-end development including Angular and/or React, JavaScript, and TypeScript \n \n Authorization to work and remain in the United States, without necessity for Mayo Clinic sponsorship now, or in the future (for example, be a U.S. Citizen, national, or permanent resident, refugee, or asylee). Also, Mayo Clinic does not participate in the F-1 STEM OPT extension program. \n  Exemption Status \n \n  Exempt\n  \n \n Compensation Detail \n \n  $131,601.60 - $190,860.80 / year\n  \n \n Benefits Eligible \n \n  Yes\n  \n \n Schedule \n \n  Full Time\n  \n \n Hours/Pay Period \n \n  80\n  \n \n Schedule Details \n \n  Monday - Friday; 8:00 AM - 5:00 PM\n  \n \n Weekend Schedule \n \n  As needed\n  \n \n International Assignment \n \n  No\n  \n \n Site Description \n \n \n  Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.\n   \n \n \n \n \n Affirmative Action and Equal Opportunity Employer \n \n \n  As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.\n    \n \n \n \n \n Recruiter \n \n  Miranda Grabner",
        "cleaned_desc": "Why Mayo Clinic \n \n \n  Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans \u2013 to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You\u2019ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.\n  \n \n \n Responsibilities \n \n  We are seeking a Senior Software Engineer to design and build back-end services that support our portfolio of data-centric clinical and analytic applications. These applications leverage cloud computing, big data, mobile, data science, data warehousing, machine learning using state of the art software development applications and frameworks. Our Software Engineers ensures that these cloud-based micro-services adhere to uptime and accuracy targets, are resilient, and scale as data volumes and traffic increase. They work closely with the data engineering, platform, and solutions teams to develop applications as required to benefit our practice and patients. \n \n Works closely with the Product Owners, Product Managers, Architects to translate requirements into code. \n Developing services around data warehousing, big data, cloud computing, business intelligence, analytics and machine learning. \n Participate in DevOps, Agile, continuous development and integration frameworks. \n Programming in high-level languages such as Go, Python, Java etc. \n Ensure all appropriate documentation of processes and source code is created and maintained. \n Communicate effectively with peers, leaders, and customers throughout the organization. \n Participate in expert level troubleshooting and resolve problems through root cause analysis, data and system investigation. \n Contributes to design and architecture discussions with Principals and Architects. \n Leads targeted cross-functional improvement efforts and mentors more junior software engineers.   Solves complex problems; takes a new perspective on existing solutions. \n Work independently with minimal guidance. You may lead projects or project steps within a broader project or have accountability for ongoing activities or objectives. \n Act as a resource for colleagues with less experience. \n \n \n \n Qualifications \n \n  Bachelor's Degree in Computer Science/Engineering or related field with 5 years of experience as noted below; OR an Associate\u2019s degree in Computer/Science/Engineering or related field with 7 years of experience.    Have in-depth knowledge of software engineering with experience coding applications or services in a high-level language (C, C++, Golang, Java, C# etc.) and a basic knowledge of related fields. Demonstrated problem solving and time management skills. Possesses strong technical aptitude for designing and implementing software solutions. Experience with modern application development frameworks. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Deep hands-on technical expertise, excellent verbal and written communication skills. Experience with Agile software development techniques. \n  Preferred Qualifications: \n \n Master's degree in Computer Science/Engineering or related field. \n Ability to use a wide variety of open-source technologies and cloud-based services. \n Experience writing software for the cloud (GCP, AWS, Azure). \n Experience in databases, analytics, big data systems or business intelligence products. \n Experience building high-performance, highly available and scalable distributed systems. \n Experience developing software for healthcare related industries. \n Experience developing server-side RESTful web services \n Experience in front-end development including Angular and/or React, JavaScript, and TypeScript \n ",
        "techs": [
            "mayo clinic",
            "u.s. news & world report",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "machine learning",
            "software development applications",
            "micro-services",
            "data engineering",
            "platform",
            "solutions teams",
            "go",
            "python",
            "java",
            "documentation",
            "troubleshooting",
            "root cause analysis",
            "design and architecture discussions",
            "improvement efforts",
            "projects",
            "bachelor's degree in computer science/engineering",
            "associate\u2019s degree in computer/science/engineering",
            "high-level language (c",
            "c++",
            "golang",
            "java",
            "c#)",
            "modern application development frameworks",
            "professional software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "agile software development",
            "master's degree in computer science/engineering",
            "open-source technologies",
            "cloud-based services",
            "gcp",
            "aws",
            "azure",
            "databases",
            "analytics",
            "business intelligence products",
            "high-performance",
            "highly available and scalable distributed systems",
            "healthcare-related industries",
            "server-side restful web services",
            "front-end development",
            "angular",
            "react",
            "javascript",
            "typescript"
        ],
        "cleaned_techs": [
            "mayo clinic",
            "u.s. news & world report",
            "cloud computing",
            "big data",
            "mobile",
            "data science",
            "data warehousing",
            "micro-services",
            "platform",
            "solutions teams",
            "go",
            "python",
            "java",
            "troubleshooting",
            "root cause analysis",
            "design and architecture discussions",
            "improvement efforts",
            "projects",
            "high-level language (c",
            "c++",
            "golang",
            "c#)",
            "modern application development frameworks",
            "professional software engineering practices",
            "coding standards",
            "code reviews",
            "source control management",
            "build processes",
            "testing",
            "operations",
            "agile software development",
            "open-source technologies",
            "cloud-based services",
            "gcp",
            "aws",
            "azure",
            "databases",
            "business intelligence products",
            "high-performance",
            "highly available and scalable distributed systems",
            "healthcare-related industries",
            "server-side restful web services",
            "front-end development",
            "angular",
            "react",
            "javascript",
            "typescript"
        ]
    },
    "b81a2b4c8496cffc": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 139215.69,
        "salary_max": 176278.1,
        "title": "Principal Data Scientist",
        "company": "Amplify Consulting Partners",
        "desc": "ABOUT THE COMPANY \n  Amplify Consulting Partners is a data-first consulting company trusted by Fortune 500 businesses to deliver high-impact professional services across the technology ecosystem\u2014from data engineering and visual analytics to data-driven marketing and program management. \n  We build and empower high-performing people by promoting growth and connection across our company culture. We don't just hang core values on the wall, we make every decision with them in mind\u2014developing trusted, long-term relationships on a foundation of transparency and accountability. \n  DEI STATEMENT \n  We hold ourselves accountable for creating an authentic workplace where every person feels heard and experiences a sense of belonging. \n  We believe that organizations can be an instrument for positive human impact when they champion a diverse, inclusive, and equitable environment. We do this at Amplify by enacting programs and policies that promote DEI\u2014and with humility, if we miss the mark, we rigorously amend our practices to better achieve our targeted outcomes.    Simply put, we turn our words into action.     ABOUT THE POSITION \n  We are seeking a detail-oriented and intellectually curious Data Engineer who is adept at navigating ambiguous situations. This role isn\u2019t simply about executing a task list; it demands proactive engagement, adaptability, and a deep understanding of our data-centric business objectives. While prior experience with a title such as 'Data Scientist' might be relevant, we emphasize the specific skills and experience outlined in this job description. Familiarity with Microsoft's tech stack is a plus. \n \n  RESPONSIBILITIES \n  As the Senior Data Scientist on the Analytics and Insights team, your work will include: \n \n Experience in R/Python (strong skills in at least 1 with a desire to know both) \n Experience with data management \n Experience with data analysis, data engineering, data visualization \n Ability to work from ambiguous requirements and navigate unclear situations \n Flexible working style \n Experience (or interest) working on analytical projects in the global health space \n Statistics and machine learning skills \n Intellectual curiosity to go out and learn new things to deliver results \n \n QUALIFICATIONS   \n \n Must be willing to commute to the Seattle office 2 days a week. \n Masters degree in Data Science, Data Engineering, Mathematics, Computer Engineering, Statistics, or related field, or equivalent working experience. \n 5+ years of experience in a Data Science role, with advanced work in Computer Science, Statistics, Informatics, Information Systems or another quantitative field preferred. \n 5+ years working in a customer-facing role interacting with business users, Data Analysts, and Data Scientists. \n 5+ years using R or Python to manipulate data and draw insights from large data sets. R programming is probably the most important skill. The individual will need to inherent an existing R end-to-end modeling framework that lives in GitHub \n Experience with Databricks for collaborative data science development workspaces and notebook-driven scripting is a plus. \n Proven track record of being part of a team delivering software solutions or services designed around customer needs. \n Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) as well as advanced statistical techniques (regression, properties of distributions, statistical tests and proper usage, etc.) and their real-world advantages and/or drawbacks. \n A drive to learn and master new technologies and techniques. Strong problem-solving skills with an emphasis on data and domain exploration. \n Experience working in cloud environments for data science workloads. \n SQL proficient \n PowerBI experience is a plus, or interest in doing so \n Azure Cloud experience \n \n SALARY AND BENEFIT HIGHLIGHTS \n \n  At Amplify we take a holistic approach to total rewards in order to invest in the satisfaction and success of our employees both now and in the future. We consider the whole person and want to support our employees in living full lives both personally and professionally. The following is an overview of what you\u2019ll get as a member of our team. \n  We consider a variety of factors when making compensation decisions and  do not hire employees at the highest point of the pay  range, targeting around the 50th percentile of the range. We share this to ensure transparency and set expectations for those considering opportunities with us. As you excel at Amplify, there is potential for salary increases and promotions. If you were to remain in this role, there is earning potential for this level of $175,000. The beginning salary range for this role is $130,000 - $160,000. \n \n 100% remote work option \n Flexible Time Off (time to recharge when you need it!) \n 11 observed holidays \n Medical/dental/vision \u2013 the employee is covered at 100%, dependents are subsidized \n Parental leave, short-term disability, long-term disability, and life insurance options \n \u2018Amplify You\u2019 program \u2013 $1,000 annually for your own development or investment in well-being after one year \n Student loan payback program \n Mentorship and training opportunities \n Business and employee referral bonus opportunities \n \n OUR HIRING PRACTICES \n  At Amplify, all qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. We are committed to creating a diverse and welcoming workplace that includes all employees with diverse backgrounds and experiences. We believe it enables us to better meet our mission and values while serving clients throughout our communities. People of color, women, LGBTQIA+, veterans, and persons with disabilities are encouraged to apply. Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Amplify is committed to offering reasonable accommodation to job applicants with disabilities. If you need assistance or accommodation due to a disability, please contact us at HR@amplifycp.com.",
        "cleaned_desc": " \n Experience in R/Python (strong skills in at least 1 with a desire to know both) \n Experience with data management \n Experience with data analysis, data engineering, data visualization \n Ability to work from ambiguous requirements and navigate unclear situations \n Flexible working style \n Experience (or interest) working on analytical projects in the global health space \n Statistics and machine learning skills \n Intellectual curiosity to go out and learn new things to deliver results \n   QUALIFICATIONS   \n \n Must be willing to commute to the Seattle office 2 days a week. \n Masters degree in Data Science, Data Engineering, Mathematics, Computer Engineering, Statistics, or related field, or equivalent working experience. \n 5+ years of experience in a Data Science role, with advanced work in Computer Science, Statistics, Informatics, Information Systems or another quantitative field preferred. \n 5+ years working in a customer-facing role interacting with business users, Data Analysts, and Data Scientists. \n 5+ years using R or Python to manipulate data and draw insights from large data sets. R programming is probably the most important skill. The individual will need to inherent an existing R end-to-end modeling framework that lives in GitHub \n Experience with Databricks for collaborative data science development workspaces and notebook-driven scripting is a plus. \n Proven track record of being part of a team delivering software solutions or services designed around customer needs. \n Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) as well as advanced statistical techniques (regression, properties of distributions, statistical tests and proper usage, etc.) and their real-world advantages and/or drawbacks. ",
        "techs": [
            "r",
            "python",
            "data management",
            "data analysis",
            "data engineering",
            "data visualization",
            "statistics",
            "machine learning",
            "seattle office",
            "masters degree in data science",
            "data engineering",
            "mathematics",
            "computer engineering",
            "statistics",
            "computer science",
            "informatics",
            "information systems",
            "quantitative field",
            "customer-facing role",
            "r programming",
            "github",
            "databricks",
            "software solutions",
            "machine learning techniques",
            "clustering",
            "decision tree learning",
            "artificial neural networks",
            "regression",
            "properties of distributions",
            "statistical tests."
        ],
        "cleaned_techs": [
            "r",
            "python",
            "data management",
            "data visualization",
            "statistics",
            "seattle office",
            "mathematics",
            "computer engineering",
            "computer science",
            "informatics",
            "information systems",
            "quantitative field",
            "customer-facing role",
            "r programming",
            "github",
            "databricks",
            "software solutions",
            "machine learning techniques",
            "clustering",
            "decision tree learning",
            "artificial neural networks",
            "regression",
            "properties of distributions",
            "statistical tests."
        ]
    },
    "9ac581ed4251ec20": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 145000.0,
        "salary_max": 185000.0,
        "title": "Sr. Software Implementation Engineer",
        "company": "Bekhealth Corp",
        "desc": "About Us \n  BEKHealth Corporation is a leading clinical technology company that operates an AI-powered patient-matching software platform serving the clinical trial industry. Our platform allows life sciences and healthcare organizations to speed up trial feasibility, site selection, and patient recruitment by extracting data from electronic medical records (EMRs), which includes structured and unstructured clinical data that captures three times more trial criteria. Our software provides patient population analysis, site feasibility and selection, study participant identification, and study participant matching to site networks. \n \n  About the Opportunity \n  We are seeking an experienced and high-achieving Sr. Software Implementation Engineer to work at the nexus of application development and client support service. This is a unique opportunity for a software engineer who desires to work closely with clients and directly help solve their problems using the BEKHealth platform and savvy technical solutions. The selected individual will play a critical role in driving the BEKHealth mission, developing and improving the BEKHealth Platform. Responsibilities include designing, building and enhancing the BEKHealth application platform, managing AWS infrastructure, ensuring data quality and integrity, working directly with clients to implement minor feature requests, solve defects and triage, manage, develop and test major platform enhancements for clients. This position also collaborates across BEKHealth teams to support machine learning and trial recruitment efforts through product development and ensuring data quality and processing performance. \n \n \n  We are looking for someone with solid technical chops, who's a quick learner that can demonstrate the ability to quickly build reapport with other technical stakeholders, and who can defuse conflict by redirecting emotional responses back to stating technical problems and providing solutions. \n \n  Responsibilities \n \n Work directly with clients and internal stakeholders to troubleshoot issues, implement solutions and verify fixes for clients. \n Collaborate with engineering teams and contribute to backend data processing applications. \n Produce high-quality, maintainable and well documented code. \n Document processes and manage triage of high priority issues for clients. \n Collaborate with other developers, product owners, and stakeholders to gather requirements and develop solutions that meet business needs. \n Mentor and guide junior developers to improve their technical skills and knowledge. \n Be proactive and solution-oriented, and driven to get things done in high-complexity environments. \n \n \n Work with the Research Services team to launch the BEKHealth platform with new customers \n \n \n \n  Requirements \n \n Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar. \n 8+ years of professional experience as a software engineer \n Experience in a client facing engineering role supporting software application teams \n Experience with Python and SQL required \n Familiarity with data processing optimization in the areas of   \n \n \n \n \n Memory usage and data query performance \n Parallelization \n Automated Testing Infrastructure \n \n Experience with data modeling \n Experience required with relational databases such as Postgres, MySQL, or SQLServer \n Experience working with REST APIs is required \n Experience working with distributed data processing frameworks required \n    \n Such as AWS Glue, AWS Step Functions, Airflow/Prefect \n \n Experience working in Linux and with Kubernetes and Docker or other container orchestration technologies \n Ability to work in a fast-paced, dynamic environment \n \n Personality \n  The ideal candidate is one whom is smart, gets things done and plays well with other! We are looking for candidates who have are focused and entrepreneurial with great follow-through and attention to detail. Someone who exhibits character, has fun at work and has presence without arrogance and who is credible both internally with the team and externally with customers will be an excellent fit. \n \n  Benefits \n  We offer competitive salary, bonus plan and equity packages, health insurance, and other benefits. You will have the opportunity to work with a talented and passionate team and make a significant impact on the healthcare industry. \n \n  Additional Information \n  Immigration sponsorship is  not  available for this position",
        "cleaned_desc": "About Us \n  BEKHealth Corporation is a leading clinical technology company that operates an AI-powered patient-matching software platform serving the clinical trial industry. Our platform allows life sciences and healthcare organizations to speed up trial feasibility, site selection, and patient recruitment by extracting data from electronic medical records (EMRs), which includes structured and unstructured clinical data that captures three times more trial criteria. Our software provides patient population analysis, site feasibility and selection, study participant identification, and study participant matching to site networks. \n \n  About the Opportunity \n  We are seeking an experienced and high-achieving Sr. Software Implementation Engineer to work at the nexus of application development and client support service. This is a unique opportunity for a software engineer who desires to work closely with clients and directly help solve their problems using the BEKHealth platform and savvy technical solutions. The selected individual will play a critical role in driving the BEKHealth mission, developing and improving the BEKHealth Platform. Responsibilities include designing, building and enhancing the BEKHealth application platform, managing AWS infrastructure, ensuring data quality and integrity, working directly with clients to implement minor feature requests, solve defects and triage, manage, develop and test major platform enhancements for clients. This position also collaborates across BEKHealth teams to support machine learning and trial recruitment efforts through product development and ensuring data quality and processing performance. \n \n \n  We are looking for someone with solid technical chops, who's a quick learner that can demonstrate the ability to quickly build reapport with other technical stakeholders, and who can defuse conflict by redirecting emotional responses back to stating technical problems and providing solutions. \n \n  Responsibilities \n   Work directly with clients and internal stakeholders to troubleshoot issues, implement solutions and verify fixes for clients. \n Collaborate with engineering teams and contribute to backend data processing applications. \n Produce high-quality, maintainable and well documented code. \n Document processes and manage triage of high priority issues for clients. \n Collaborate with other developers, product owners, and stakeholders to gather requirements and develop solutions that meet business needs. \n Mentor and guide junior developers to improve their technical skills and knowledge. \n Be proactive and solution-oriented, and driven to get things done in high-complexity environments. \n \n \n Work with the Research Services team to launch the BEKHealth platform with new customers \n   \n \n  Requirements \n \n Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar. \n 8+ years of professional experience as a software engineer \n Experience in a client facing engineering role supporting software application teams \n Experience with Python and SQL required \n Familiarity with data processing optimization in the areas of   \n \n   \n \n Memory usage and data query performance \n Parallelization \n Automated Testing Infrastructure \n \n Experience with data modeling \n Experience required with relational databases such as Postgres, MySQL, or SQLServer \n Experience working with REST APIs is required \n Experience working with distributed data processing frameworks required \n    ",
        "techs": [
            "python",
            "sql",
            "postgres",
            "mysql",
            "sqlserver",
            "rest apis"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "postgres",
            "mysql",
            "sqlserver",
            "rest apis"
        ]
    },
    "ce21896a521e5438": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 131278.53,
        "salary_max": 166227.88,
        "title": "Full Stack Software Engineer, Retention",
        "company": "Jerry",
        "desc": "We'd love to hear from you if you like: \n \n  Making a big impact with a Forbes Top Startup Employer \n  Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category) \n  Solving problems in a huge market ($2T market size) \n  Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc. \n \n \n  About the opportunity: \n  We are on a mission to disrupt the car ownership experience and help people who rely on their vehicles everyday save time and money on one of their most expensive, time-consuming and high-maintenance assets. Simplifying and democratizing car ownership and creating a world-class experience is what drives every decision we make as a company. Since launching our AllCar app in 2019, we have amassed over 4M customers, and expanded beyond insurance shopping to refinancing, safety and repairs. \n \n  We are looking for a Full Stack Engineer who is passionate about solving complex, meaningful problems to join our Core User Retention Team. Working closely with our brilliant product managers, software engineers, data scientists, designers, and operations teams, you will play a key role in improving customer retention for our core insurance shopping product and help make car ownership an effortless experience. If you are looking for an opportunity to make a measurable difference in the lives of millions and help us disrupt a massive industry, we'd love to hear from you! \n \n  How you will make an impact: \n \n  Partner closely with our product managers, engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product  \n Participate in new feature and automation development, write unit test, self test and QA software, continuously deliver high quality engineering results \n  Participate in code reviews on a daily basis, always hold an exceptionally high bar on code quality \n  Collaborate on product spec and engineering spec, and bring valuable insight from both a business and technical perspective \n  Leverage feedback from customers and our internal teams to continuously iterate on our core insurance shopping product  \n Monitor software errors and alerts on a daily basis, ensuring that critical issues are addressed with a sense of urgency \n  Create and maintain documentation for development, troubleshooting, and training purposes \n  Become a trusted expert on our suite of products, production systems, and production tools \n  Contribute across our entire product stack as well as be responsible for the integrity of our codebase  \n Help evolve our tech stack by providing continuous feedback and insight  \n \n \n What we're looking for: \n \n  You love tackling convoluted problems and coming up with clean, stable solutions that scale \n  You have a genuine passion for designing and implementing elegant software solutions \n  You are intimately familiar (and up to date) with the development ecosystem and make sound decisions when choosing the right tool or library for the job \n  You are self-motivated and able to work autonomously \n \n \n  Ideal profile: \n \n  Bachelor's, Master's, or PhD degree in Computer Science or related field \n  2+ years of production software engineering experience in consumer applications \n  Hands-on coding experience using Typescript/Javascript, Java, Python, C, C++, C#, or Golang \n  Sound understanding of data structures and algorithms, operating systems, databases and networking fundamentals \n  Ability to work flexibly in a variety of development environments and technologies \n  Solid understanding of performance implications and scalability of code \n  Keenness for writing good, meaningful tests and maintaining thorough test coverage \n \n \n  Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.  \n \n Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at  recruiting@getjerry.com \n \n  About Jerry: \n  Jerry is America\u2019s first and only AllCar app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets. \n \n  Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all. \n \n  We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u2014 and we\u2019re just getting started. \n \n  Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing. \n \n  Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u2019s disrupting a massive market.",
        "cleaned_desc": " \n \n  Ideal profile: \n \n  Bachelor's, Master's, or PhD degree in Computer Science or related field \n  2+ years of production software engineering experience in consumer applications \n  Hands-on coding experience using Typescript/Javascript, Java, Python, C, C++, C#, or Golang \n  Sound understanding of data structures and algorithms, operating systems, databases and networking fundamentals \n  Ability to work flexibly in a variety of development environments and technologies \n  Solid understanding of performance implications and scalability of code \n  Keenness for writing good, meaningful tests and maintaining thorough test coverage ",
        "techs": [
            "typescript/javascript",
            "java",
            "python",
            "c",
            "c++",
            "c#",
            "golang"
        ],
        "cleaned_techs": [
            "typescript/javascript",
            "java",
            "python",
            "c",
            "c++",
            "c#",
            "golang"
        ]
    },
    "06d964f22a8cf0b8": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 121767.95,
        "salary_max": 154185.36,
        "title": "Senior Data Scientist, Product Growth",
        "company": "Jerry",
        "desc": "We'd love to hear from you if you like: \n \n  Making a big impact with a Forbes Top Startup Employer \n  Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category) \n  Solving problems in a huge market ($2T market size) \n  Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc. \n \n \n  About the opportunity: \n  We are looking for a Senior Data Scientist to join our central data team and partner with one of our emerging product groups. Helping everyday, hard working Americans save time and money on their cars and creating a world class experience is what drives every decision we make as a company. Since launching our mobile app in 2019, we have amassed over 4M customers, expanded our product offerings to multiple categories and scaled our team 10X. Our data team fuels all of our business and product decisions through delivering analytical insights and building advanced models. \n \n  Reporting to our VP of Business Operations and Analytics, you will leverage data to drive growth and retention for one of our emerging product groups (car maintenance marketplace or chatbot). You will perform analytical deep dives, develop and analyze experiments, build predictive models, and make recommendations that inform our product roadmap. Working with a brilliant team of product managers, product designers, software engineers, and key business leaders, you will play a big role in accelerating our growth and taking our customer experience to the next level. \n \n  How you will make an impact: \n \n  Partner closely with our product managers, software engineers, product designers, and key business leaders to drive user growth and retention for our core insurance product  \n Design, run, and analyze A/B experiments on new and existing features; extract key insights, share learnings and make recommendations on next steps \n  Build key reports, dashboards, and predictive models to monitor the performance of our insurance business, and communicate analytical outcomes to our teams \n  Transform and refine raw production data for analytical needs \n  Continually improve our data governance and data consistency standards within our database \n  Work with data engineering team on data tracking, integrity, and security as needed \n  Work with other data scientists to evolve, optimize and integrate machine learning models \n \n \n  Who you are: \n \n  Intellectually curious: You're not satisfied with surface level insights. You dive deep to understand how systems work, why people behave in certain ways and are intrinsically motivated to uncover root causes for issues or underlying reasons behind decisions. \n  Creative problem-solver: No challenge is too complex, no issue is too hard. \n  Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited. \n  Strong communicator: Able to drive alignment and communicate effectively to different audiences. \n \n \n  Ideal profile: \n \n  Bachelor\u2019s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline \n  2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment \n  Experience designing and implementing A/B tests, and analyzing user experience \n  Hands-on experience with SQL (advanced proficiency) \n \n \n  Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.  \n \n Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at  recruiting@getjerry.com \n \n  About Jerry: \n  Jerry is America\u2019s first and only AllCar app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets. \n \n  Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all. \n \n  We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u2014 and we\u2019re just getting started. \n \n  Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing. \n \n  Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u2019s disrupting a massive market.",
        "cleaned_desc": " \n \n  Ideal profile: \n \n  Bachelor\u2019s degree in Mathematics, Statistics, Economics, Computer Science or a related discipline \n  2+ years of experience as a data scientist or product analyst in a consumer-facing web or mobile app environment \n  Experience designing and implementing A/B tests, and analyzing user experience \n  Hands-on experience with SQL (advanced proficiency) \n \n ",
        "techs": [
            "sql"
        ],
        "cleaned_techs": [
            "sql"
        ]
    },
    "c3a7596269167611": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 121655.61,
        "salary_max": 154043.11,
        "title": "Founding Engineer (Full Stack Software)",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Our client is looking for a Founding Engineer (Full Stack Software) to join our team! You will lead the development of our Core Product: a soil carbon measurement, reporting, and verification (MRV) platform. As the first technical hire, you will work directly with the founders and own the entire technology stack, including making product decisions. You will set the technical roadmap and have the opportunity to build out a world-class technical team and culture as you see best. \n  Ideal candidate traits \n  5+ years of experience building and owning a complete end-to-end technology stack (Frontend + Backend + Cloud + CI/CD) \n  A track record of shipping and going through the full product development cycle right from writing the first line of code to product in the hands of users and iterating quickly on feedback \n  Experience with setting up the technology stack and development infrastructure from Day 1 and scaling it with growth \n \n Ability to develop infrastructure/pipelines to support Machine Learning / Remote Sensing workflows \n \n  Proactive and collaborative self-starter with a strong ability to attract other top technical talent and lead them effectively \n \n \ufe0f Past experience working in climate/agriculture is not a requirement, but a passion for climate is a plus! \n \ufe0f Past multidisciplinary teamwork (i.e. e.g. working on software in healthcare) is a huge plus, as you will be working with an interdisciplinary team with expertise in AI, Remote Sensing, Carbon Markets, Soil Carbon Modeling, Sustainable Finance \n \n  Machine Learning and Remote Sensing experience is not required, but understanding how to support these workflows (e.g. setting up data pipelines, setting up infrastructure to parallelize model runs, automating the deployment of models to integrate with the core MRV product) is a huge bonus! \n  You care deeply about climate change and feel a strong moral responsibility to act now. This extends into all facets of your life: both personal and professional. No action is too small and no goal is too big. Whether you have turned vegan or swear by public transport, we are big believers in embracing sustainability as a mindset and would love to learn what this means for you! \n   \n rUpdnzgspq",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "1173698fd7d90d3f": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Product Manager, Retention",
        "company": "Jerry",
        "desc": "We'd love to hear from you if you like: \n \n  Making a big impact with a Forbes Top Startup Employer \n  Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category) \n  Solving problems in a huge market ($2T market size) \n  Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc. \n \n \n  About the opportunity: \n  We are on a mission to disrupt the car ownership experience and help people who rely on their vehicles everyday save time and money on one of their most expensive, time-consuming and high-maintenance assets. Simplifying and democratizing car ownership and creating a world-class experience is what drives every decision we make as a company. Since launching our AllCar app in 2019, we have amassed over 4M customers, and expanded beyond insurance shopping to refinancing, safety and repairs. \n \n  We are looking for a curious and data-driven Senior Product Manager who is passionate about solving complex, tangible problems to join our Retention Team. Reporting directly to our CFO and partnering closely with our brilliant product managers, software engineers, data scientists and designers, you will play a key role in improving customer retention for our core insurance shopping product and help make car ownership an effortless experience. If you are looking for an opportunity to make a measurable difference in the lives of millions and help us disrupt a massive industry, we'd love to hear from you! \n \n  How you will make an impact: \n \n  Optimize carrier integrations, payment integrations and leverage automation to drive retention for our insurance shopping product \n  Partner with retention product managers, engineers, data scientists, designers, operations, and biz dev teams to build and launch new features \n  Run deep dive analyses to identify opportunities to reduce customer churn \n  Conduct in-depth user research and think critically about how to solve for our customers\u2019 pain points \n \n \n  What we are looking for: \n \n  Creative problem-solver: No challenge is too complex, no issue is too hard \n  Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited \n  Tenacious: You\u2019re a hustler at heart and you thrive under pressure \n  Super organized: You balance a packed schedule, an endless to-do list, can manage a team, and never let anything drop \n \n \n  Ideal profile: \n \n  3+ years of consumer-facing product management experience \n  Comfortable conducting rigorous analyses, developing insightful hypotheses, and validating impact \n  A plus if you have weathered an early startup environment \n \n \n  Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.  \n \n Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at  recruiting@getjerry.com \n \n  About Jerry: \n  Jerry is America\u2019s first and only AllCar app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets. \n \n  Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all. \n \n  We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u2014 and we\u2019re just getting started. \n \n  Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing. \n \n  Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u2019s disrupting a massive market.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "80f18e807331a607": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Product Manager, Retention",
        "company": "Jerry",
        "desc": "We'd love to hear from you if you like: \n \n  Making a big impact with a Forbes Top Startup Employer \n  Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category) \n  Solving problems in a huge market ($2T market size) \n  Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc. \n \n \n  About the opportunity: \n  We are on a mission to disrupt the car ownership experience and help people who rely on their vehicles everyday save time and money on one of their most expensive, time-consuming and high-maintenance assets. Simplifying and democratizing car ownership and creating a world-class experience is what drives every decision we make as a company. Since launching our AllCar app in 2019, we have amassed over 4M customers, and expanded beyond insurance shopping to refinancing, safety and repairs. \n \n  We are looking for a curious and data-driven Senior Product Manager who is passionate about solving complex, tangible problems to join our Retention Team. Reporting directly to our CFO and partnering closely with our brilliant product managers, software engineers, data scientists and designers, you will play a key role in improving customer retention for our core insurance shopping product and help make car ownership an effortless experience. If you are looking for an opportunity to make a measurable difference in the lives of millions and help us disrupt a massive industry, we'd love to hear from you! \n \n  How you will make an impact: \n \n  Optimize carrier integrations, payment integrations and leverage automation to drive retention for our insurance shopping product \n  Partner with retention product managers, engineers, data scientists, designers, operations, and biz dev teams to build and launch new features \n  Run deep dive analyses to identify opportunities to reduce customer churn \n  Conduct in-depth user research and think critically about how to solve for our customers\u2019 pain points \n \n \n  What we are looking for: \n \n  Creative problem-solver: No challenge is too complex, no issue is too hard \n  Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited \n  Tenacious: You\u2019re a hustler at heart and you thrive under pressure \n  Super organized: You balance a packed schedule, an endless to-do list, can manage a team, and never let anything drop \n \n \n  Ideal profile: \n \n  3+ years of consumer-facing product management experience \n  Comfortable conducting rigorous analyses, developing insightful hypotheses, and validating impact \n  A plus if you have weathered an early startup environment \n \n \n  Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.  \n \n Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at  recruiting@getjerry.com \n \n  About Jerry: \n  Jerry is America\u2019s first and only AllCar app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets. \n \n  Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all. \n \n  We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u2014 and we\u2019re just getting started. \n \n  Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing. \n \n  Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u2019s disrupting a massive market.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a89c9fd20cc7bb2a": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Product Manager, Retention",
        "company": "Jerry",
        "desc": "We'd love to hear from you if you like: \n \n  Making a big impact with a Forbes Top Startup Employer \n  Working on products that have traction (40X revenue growth in 4 years | #1 rated app in the insurance comparison category) \n  Solving problems in a huge market ($2T market size) \n  Working closely with serial entrepreneurs and seasoned leaders who have scaled companies like Robinhood, Amazon, LinkedIn, Wayfair, SoFi, Microsoft, etc. \n \n \n  About the opportunity: \n  We are on a mission to disrupt the car ownership experience and help people who rely on their vehicles everyday save time and money on one of their most expensive, time-consuming and high-maintenance assets. Simplifying and democratizing car ownership and creating a world-class experience is what drives every decision we make as a company. Since launching our AllCar app in 2019, we have amassed over 4M customers, and expanded beyond insurance shopping to refinancing, safety and repairs. \n \n  We are looking for a curious and data-driven Senior Product Manager who is passionate about solving complex, tangible problems to join our Retention Team. Reporting directly to our CFO and partnering closely with our brilliant product managers, software engineers, data scientists and designers, you will play a key role in improving customer retention for our core insurance shopping product and help make car ownership an effortless experience. If you are looking for an opportunity to make a measurable difference in the lives of millions and help us disrupt a massive industry, we'd love to hear from you! \n \n  How you will make an impact: \n \n  Optimize carrier integrations, payment integrations and leverage automation to drive retention for our insurance shopping product \n  Partner with retention product managers, engineers, data scientists, designers, operations, and biz dev teams to build and launch new features \n  Run deep dive analyses to identify opportunities to reduce customer churn \n  Conduct in-depth user research and think critically about how to solve for our customers\u2019 pain points \n \n \n  What we are looking for: \n \n  Creative problem-solver: No challenge is too complex, no issue is too hard \n  Data-driven: You're extremely analytical and live in data. At the same time, you're confident enough to make decisions when the data is limited \n  Tenacious: You\u2019re a hustler at heart and you thrive under pressure \n  Super organized: You balance a packed schedule, an endless to-do list, can manage a team, and never let anything drop \n \n \n  Ideal profile: \n \n  3+ years of consumer-facing product management experience \n  Comfortable conducting rigorous analyses, developing insightful hypotheses, and validating impact \n  A plus if you have weathered an early startup environment \n \n \n  Jerry is proud to be an Equal Employment Opportunity employer. We prohibit discrimination based on race, religion, color, national origin, sex, pregnancy, reproductive health decisions or related medical conditions, sexual orientation, gender identity, gender expression, age, veteran status, disability, genetic information, or other characteristics protected by applicable local, state or federal laws.  \n \n Jerry is committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, please contact us at  recruiting@getjerry.com \n \n  About Jerry: \n  Jerry is America\u2019s first and only AllCar app. We are redefining and radically improving how people manage owning a car, one of their most expensive and time-consuming assets. \n \n  Backed by artificial intelligence and machine learning, Jerry simplifies and automates owning and maintaining a car while providing personalized services for all car owners' needs. We spend every day innovating and improving our AI-powered app to provide the best possible experience for our customers. From car insurance and financing to maintenance and safety, Jerry does it all. \n \n  We are the #1 rated and most downloaded app in our category with a 4.7 star rating in the App Store. We have more than 4 million customers \u2014 and we\u2019re just getting started. \n \n  Jerry was founded in 2017 by serial entrepreneurs and has raised more than $242 million in financing. \n \n  Join our team and work with passionate, curious and egoless people who love solving real-world problems. Help us build a revolutionary product that\u2019s disrupting a massive market.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a5ce54e9c52f6647": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 163200.0,
        "salary_max": 250920.0,
        "title": "Senior Technical Data Architect",
        "company": "Grainger",
        "desc": "About Grainger:\n  \n Grainger is a leading broad line distributor with operations primarily in North America, Japan and the United Kingdom. We achieve our purpose, We Keep the World Working\u00ae, by serving more than 4.5 million customers with a wide range of products that keep their operations running and their people safe. Grainger also delivers services and solutions, such as technical support and inventory management, to save customers time and money. \n We're looking for passionate people who can move our company forward. As one of the 100 Best Companies to Work For, we have a welcoming workplace where you can build a career for yourself while fulfilling our purpose to keep the world working. We embrace new ways of thinking and recognize everyone is an individual. Find your way with Grainger today. \n \n  Position Details:\n  \n Grainger is looking for a Senior Technical Data Architect (Director Level). You will influence data architecture across different applications, partner with product teams on data strategies, own architectural elements of our cloud-based data platform, strengthen data governance, and establish a data mesh architecture. You have experience building data solutions on the public cloud, establishing data governance, treating data as a product, enabling machine learning use cases, and success influencing data professionals, software engineers, and product managers. \n You will be reporting to the Sr. Director of Insights, Data Engineering, and Analytics. This can be a hybrid/remote role based in our Chicago office. \n This position is salaried and will pay $163,200 to $250,920. Total compensation will include annual bonus and long-term incentive. Target total compensation will be in the range of $280,000 - $400,000. \n The range provided is a guideline and not a guarantee of compensation. Other factors that are involved in offer decisions include, and are not limited to: a candidate's experience, qualifications, geographical area, and internal equity of the team. \n \n \n \n  You Will:\n  \n \n Establish, and enforce, best practices for data architecture and data governance among a variety of product teams that produce data which feeds Grainger\u2019s corporate data lake and data ecosystem. \n Partner with source system owners and data professionals to establish singular versions of the truth for given data domains. \n Aid in the acceleration of data product creation by resolving architectural challenges and establishing governance processes. \n Resolve cross cutting concerns, such as, when to integrate data from different product domains, where, and by whom. \n Help to promote ownership for data by proposing ownership solutions to data with otherwise unclear owners. \n Partner with domain-based software engineering teams to evolve toward a self-service data mesh. \n Partner with product teams to provide guidance on their underlying data models. \n Establish and oversee the architectural roadmaps for our data and analytic applications. \n \n \n \n \n \n  You Have:\n  \n \n 10+ years of related experience in information technology. \n Bachelor\u2019s degree in computer science, related field, or equivalent experience \n Experience architecting end-to-end data solutions from source applications and products through transformation layers and into final states of storage and use. \n Hands-on experience building on the public cloud. \n Prior experience using data governance to establish data ownership, discoverability, and singular versions of the truth. \n Meaningful experience employing modern data technologies, such as, Snowflake, Airflow, Databricks, Spark, Kafka, S3. \n Meaningful experience creating logical and physical data models and an understanding of relational modeling principles. \n Expertise in modern data engineering approaches and best practices \n Experience implementing machine learning/data science enabled use cases. \n Code in at least one modern programming language (Python, Scala, JavaScript, Java.) \n \n \n   \n \n  Rewards and Benefits:\n  \n With benefits starting day one, Grainger is committed to your safety, health and wellbeing. Our programs provide choice to meet our team members' individual needs. Check out some of the rewards available to you at Grainger. \n \n Medical, dental, vision, and life insurance coverage starts day one \n Paid time off (PTO) days and 6 company holidays per year \n 6% 401(k) company contribution each pay period \n Education assistance, including financial counseling, tuition reimbursement and low-cost degree option. \n Employee discounts, parental leave, and more \n \n \n \n \n \n  DEI Statement\n  \n We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace. \n We are committed to fostering an inclusive, accessible environment that includes both providing reasonable accommodations to individuals with disabilities during the application and hiring process as well as throughout the course of one\u2019s employment. With this in mind, should you need a reasonable accommodation during the application and selection process, please advise us so that we can provide appropriate assistance. \n \n  #LI-SM1\n  \n \n \n #LI-Hybrid \n #LI-Remote",
        "cleaned_desc": "  You Will:\n  \n \n Establish, and enforce, best practices for data architecture and data governance among a variety of product teams that produce data which feeds Grainger\u2019s corporate data lake and data ecosystem. \n Partner with source system owners and data professionals to establish singular versions of the truth for given data domains. \n Aid in the acceleration of data product creation by resolving architectural challenges and establishing governance processes. \n Resolve cross cutting concerns, such as, when to integrate data from different product domains, where, and by whom. \n Help to promote ownership for data by proposing ownership solutions to data with otherwise unclear owners. \n Partner with domain-based software engineering teams to evolve toward a self-service data mesh. \n Partner with product teams to provide guidance on their underlying data models. \n Establish and oversee the architectural roadmaps for our data and analytic applications. \n \n \n   \n \n  You Have:\n  \n \n 10+ years of related experience in information technology. \n Bachelor\u2019s degree in computer science, related field, or equivalent experience \n Experience architecting end-to-end data solutions from source applications and products through transformation layers and into final states of storage and use. \n Hands-on experience building on the public cloud. \n Prior experience using data governance to establish data ownership, discoverability, and singular versions of the truth. \n Meaningful experience employing modern data technologies, such as, Snowflake, Airflow, Databricks, Spark, Kafka, S3. \n Meaningful experience creating logical and physical data models and an understanding of relational modeling principles. \n Expertise in modern data engineering approaches and best practices \n Experience implementing machine learning/data science enabled use cases. ",
        "techs": [
            "snowflake",
            "airflow",
            "databricks",
            "spark",
            "kafka",
            "s3"
        ],
        "cleaned_techs": [
            "snowflake",
            "airflow",
            "databricks",
            "spark",
            "kafka",
            "s3"
        ]
    },
    "7b90226f200306cb": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 175921.36,
        "salary_max": 222755.64,
        "title": "Software Engineering Manager",
        "company": "Match Made Tech",
        "desc": "Software Engineering Manager  \n \n LOCATION:  Remote or San Francisco  \n \n ABOUT US:  We are on a mission to develop innovative AI solutions that will revolutionize our workforce. As we embark on an exciting new development, we are looking for a skilled and experienced Hands-On Engineering Manager to lead our engineering team.  \n \n JOB DESCRIPTION:  \n Position Overview:  As a Software Engineering Manager, you will play a critical role in shaping the future of our engineering. You will lead a team of talented engineers, guiding them in the development of robust and scalable systems, while actively contributing to the codebase. This is a unique opportunity to combine your leadership skills with hands-on technical expertise in a dynamic and forward-thinking environment.  \n \n RESPONSIBILITIES:  \n Technical Leadership:  \n \n Lead a team of backend, frontend, data, and machine learning engineers, providing mentorship, guidance, and technical expertise.  \n Collaborate with cross-functional teams to drive project success.  \n Design, develop, and maintain high-performance, reliable systems.  \n \n \n Hands-On Coding:  \n \n Actively participate in coding, code reviews, and debugging to maintain a deep understanding of the project's technical aspects.  \n Ensure code quality, scalability, and security standards are met throughout the development process.  \n \n \n Project Management:  \n \n Develop and execute project plans, timelines, and resource allocation strategies.  \n Foster a culture of accountability, innovation, and continuous improvement within the engineering team.  \n Monitor and report on project progress, identifying and mitigating risks as needed.  \n \n \n Team Development:  \n \n Onboard, and retain top-tier engineering talent.  \n Conduct regular performance evaluations and provide constructive feedback.  \n Facilitate professional growth and skill development among team members.  \n Evaluate and recommend new tools, frameworks, and technologies to enhance the project's capabilities.  \n \n \n QUALIFICATIONS:  \n \n Bachelor's or Master's degree in Computer Science or a related field.  \n Proven experience (7+ years) as a software engineer with a strong focus on Java backend development.  \n Previous leadership or management experience, preferably as a team lead or engineering manager.  \n In-depth knowledge of AI concepts, machine learning, or related fields is a significant plus.  \n Proficiency in Java, Python, AWS, along with experience with relevant frameworks and libraries.  \n Strong problem-solving skills and the ability to make data-driven decisions.  \n Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams.  \n A passion for innovation, AI, and a desire to work on a greenfield project.  \n \n \n Be part of an exciting and groundbreaking AI project with the potential to make a global impact.",
        "cleaned_desc": " Technical Leadership:  \n \n Lead a team of backend, frontend, data, and machine learning engineers, providing mentorship, guidance, and technical expertise.  \n Collaborate with cross-functional teams to drive project success.  \n Design, develop, and maintain high-performance, reliable systems.  \n \n \n Hands-On Coding:  \n \n Actively participate in coding, code reviews, and debugging to maintain a deep understanding of the project's technical aspects.    Bachelor's or Master's degree in Computer Science or a related field.  \n Proven experience (7+ years) as a software engineer with a strong focus on Java backend development.  \n Previous leadership or management experience, preferably as a team lead or engineering manager.  \n In-depth knowledge of AI concepts, machine learning, or related fields is a significant plus.  \n Proficiency in Java, Python, AWS, along with experience with relevant frameworks and libraries.  \n Strong problem-solving skills and the ability to make data-driven decisions.  \n Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams.  \n A passion for innovation, AI, and a desire to work on a greenfield project.  \n \n ",
        "techs": [
            "java",
            "python",
            "aws"
        ],
        "cleaned_techs": [
            "java",
            "python",
            "aws"
        ]
    },
    "3107c3d81e076d94": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 166087.44,
        "salary_max": 210303.72,
        "title": "Engineering Manager- Experimentation Platform",
        "company": "Discord",
        "desc": "At Discord, we believe everyone can find a place where they belong. Our mission is to help make it easy for everyone to find and join meaningful conversations and to make every part of our product feel smart and delightful. Discord is a rapidly scaling company that puts Data at the heart of its decision-making and future growth. The Experimentation team at Discord is responsible for building the tools, systems and processes that empower Discord employees to continually test hypotheses and improve our product in a data-informed way. \n We are looking for a technical, results-driven, hands-on Engineering Manager to lead our Experimentation platform team. \n What you'll be doing \n \n Use your technical expertise to build delightful user experience and high-scale data systems that power internal teams and product features used by many millions of users every day \n Build and lead a team of highly-engaged engineers by hiring, coaching, and instilling a sense of ownership and mission \n Partner with Product Manager to build vision, develop strategy and prioritize roadmaps. \n Deliver business results by collaborating with stakeholders across Discord to experiment on features, machine learning models and more. \n Work with other Engineering Managers to improve the Engineering organization and uphold our workplace philosophy \n \n What you should have \n \n You have 5+ years of experience as a full-stack engineer \n You have 2+ years of experience as an Engineering Manager \n You have built internal tools, and are familiar with with A/B testing and statistical frameworks. \n You have extensive experience leading complex technical projects with successful outcomes; you can take a high-level goal and achieve a shippable solution \n You've worked with complex distributed data systems deployed at scale and have built end-to-end solutions \n You have built systems with strong data governance controls that respect privacy and security principles. \n You have a strong product sense and take pride in understanding your customers \n You have strong communication skills and the ability to work well cross-functionally \n You are motivated to help your team members succeed and have experience developing engineers of multiple levels \n You keep up with the industry trends and identify new techniques to solve technical problems \n \n The US base salary range for this full-time position is $214,000 to $233,000 + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-related skills, experience, and relevant education or training. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include equity, or benefits. \n \n \n  Benefits and Perks \n \n Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures) \n Mental health resources and quarterly wellness stipends \n 14+ paid holidays, 4 weeks of PTO + use-what-you-need sick days \n Paid parental leave (plus fertility, adoption and other family planning benefits) \n Flexible long-term work options (remote and hybrid) \n Volunteer time off \n A diverse slate of Employee Resource Groups \n Plus commuter contributions and other perks for office-based employees \n \n About Us \n  Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests \u2014 from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations. \n  We're working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It's a mission that gives us the chance to positively impact millions of people all over the world.  So if this strikes a chord with you, come build belonging with us!",
        "cleaned_desc": " You have built internal tools, and are familiar with with A/B testing and statistical frameworks. \n You have extensive experience leading complex technical projects with successful outcomes; you can take a high-level goal and achieve a shippable solution \n You've worked with complex distributed data systems deployed at scale and have built end-to-end solutions \n You have built systems with strong data governance controls that respect privacy and security principles. \n You have a strong product sense and take pride in understanding your customers \n You have strong communication skills and the ability to work well cross-functionally \n You are motivated to help your team members succeed and have experience developing engineers of multiple levels ",
        "techs": [
            "a/b testing",
            "statistical frameworks"
        ],
        "cleaned_techs": [
            "a/b testing",
            "statistical frameworks"
        ]
    },
    "047fd326692b8b88": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Lead Engineer, Software Engineering",
        "company": "Sephora",
        "desc": "Job ID:  238570   Location Name:  FSC REMOTE SF/NY/DC -173(USA_0173)   Address:  FSC, Remote, CA 94105, United States (US)   Job Type:  Full Time   Position Type:  Regular   Job Function:  Information Technology   Remote Eligible: Yes \n \n  Company Overview: \n  At Sephora we inspire our customers, empower our teams, and help them become the best versions of themselves. We create an environment where people are valued, and differences are celebrated. Every day, our teams across the world bring to life our purpose: to expand the way the world sees beauty by empowering the Extra Ordinary in each of us. We are united by a common goal - to  reimagine the future of beauty . \n \n  The Opportunity: \n  Technology \n  Our technology team works fast and smart. With San Francisco as our home, we take bringing new tech to market seriously, developing the latest in mobile technologies, scalable architecture, and the coolest in-store client experience. We love what we do and we have fun doing it. The Technology group is comprised of motivated self-starters and true team players that are absolutely integral to the growth of Sephora and our future success. \n \n  Your role at Sephora:  \n As a Lead Software Engineer you will design and implement innovative analytical solutions and work alongside the product engineering team, evaluating new features and architecture. Reporting to the Engineering Director, Data Platform, you will work closely with other team members like architects, product owners and business analysts to understand what the business is trying to achieve, move data from source to target, and design optimal data models. You will be also responsible for building and maintaining the applications. This role also requires coordination with team members from Engineering Team and cross-functional teams (includes Shared Services). This hands-on technical role demands excellent knowledge and can demonstrate best practices in the industry. Come be a part of a team that is starting this new journey. \n \n  Responsibilities \n \n  Design and implement innovative microservices based applications and own end to end using Spring boot, ReactJS, NoSQL, or other UI and API related technologies \n  Lead, design and actively implement / develop code for full stack applications including UI, services, respective DBs, respective data platform components, track / resolve defects resulting from Testing (includes unit, QA, UAT, etc.), deploy application to production, create deployment runbooks and work with Support team to monitor high priority tickets / issues in production. \n  Build and scale services infrastructure to meet functional requirements and Non-Functional Requirements SLAs. \n  Work with product and engineering team to understand requirements, evaluate new features and architecture to help drive decisions \n  Build collaborative partnerships with architects, technical leads and key individuals within other functional groups \n  Perform detailed analysis of business problems and technical environments and use this in designing quality technical solution \n  Actively participate in code review and test solutions to ensure it meets best practice specifications \n  Ability to fix defects independent of team members, if / when there is a need to reduce the turn around time. \n  Build and foster a high performance engineering culture, mentor team members and provide team with the tools and motivation to make things happen \n  Work with stakeholders and cross-functional teams to develop new solutions or enhance existing solution \n  Demonstrate our Sephora values of Passion for Client Service, Innovation, Expertise, Balance, Respect for All, Teamwork, and Initiative \n \n \n  We\u2019re excited about you if you have:  \n \n 8-10 years of software development and deployment experience with at least 5 years of hands-on experience with Java, Spring Boot, Microservice applications with RDBMS (Oracle, MySQL or equivalent), NoSQL (Cassandra, GraphDB, DocumentDB or equivalent) e.g. developing, debugging, and performance tuning - required \n  Good experience in React, Angular or equivalent front end frameworks preferred. \n  Strong experience building data ingestion pipelines (simulating Extract, Transform, Load workload), data processing or database architecture \n  Good experience in logging, monitoring and troubleshooting (Splunk, Graffana, Dynatrace, Prometheus, or equivalent)  \n Strong experience with data modeling, design patterns, building highly scalable Solutions and distributed applications \n  Ability to build and troubleshoot high throughput systems with low response time. \n  Knowledge of cloud platforms, for example: \n \n \n  Experience with Azure, AWS or equivalent cloud platforms \n  Microsoft Azure: Experience designing, deploying, and administering scalable, available, and fault tolerant systems on Microsoft Azure : Preferred Experience with Azure Management Portal, Azure Machine Learning, and Azure SQL Server \n  Experience with storing, joining, filtering, and analyzing data using Spark, Hive, Python : Preferred but not required. \n \n \n  Experience working with continuous integration framework, building regression-able code within data world using GitHub, Jenkins and related applications \n  Experience with programming/scripting languages such as Scala/Java/Python/R etc. (any combination) \n  Analytical approach to problem-solving with an ability to work at an abstract level and gain consensus; excellent interpersonal, leadership and communication skills \n  Data-oriented personality. Motivated, independent, efficient and able to handle several projects; work under pressure with a solid sense for setting priorities \n  Ability to work in a fast-paced (startup like) agile development environment  \n Friendly, articulate, and interested in working in a fun, small team environment \n  Experience working in the retail industry with a large scale enterprise organization, ecommerce, marketing and CRM applications will be a plus \n  BS or MS in Computer Science or equivalent; MS preferred \n \n \n  You\u2019ll love working here because:  \n \n The people. You will be surrounded by some of the most talented, supportive, smart, and kind leaders and teams \u2013 people you can be proud to work with.  \n The product. Employees enjoy a product discount and receive free product (\u201cgratis\u201d) various times throughout the year. (Think your friends and family love you now? Just wait until you work at Sephora!) \n  The business. It feels good to win \u2013 and Sephora is a leader in the retail industry, defining experiential retail with a digital focus and creating the most loved beauty community in the world\u2026with the awards and accolades to back it up.  \n The perks. Sephora offers comprehensive medical benefits, generous vacation/holiday time off, commuter benefits, and \u201cSummer Fridays\u201d (half-days every Friday between Memorial and Labor Day)\u2026and so much more. \n  The LVMH family. Sephora\u2019s parent company, LVMH, is one of the largest luxury groups in the world, providing support to over 70 brands such as Louis Vuitton, Celine, Marc Jacobs, and Dior.  \n \n The annual base salary range for this position is $148,100.00 - $193,800.00 The actual base salary offered depends on a variety of factors, which may include, as applicable, the applicant\u2019s qualifications for the position; years of relevant experience; specific and unique skills; level of education attained; certifications or other professional licenses held; other legitimate, non-discriminatory business factors specific to the position; and the geographic location in which the applicant lives and/or from which they will perform the job. Individuals employed in this position may also be eligible to earn bonuses. Sephora offers a generous benefits package to full-time employees, which includes comprehensive health, dental and vision plans; a superior 401(k) plan, various paid time off programs; employee discount/perks; life insurance; disability insurance; flexible spending accounts; and an employee referral bonus program. \n \n  While at Sephora, you\u2019ll enjoy\u2026 \n \n \n  The people.  You will be surrounded by some of the most talented leaders and teams \u2013 people you can be proud to work with. \n  The learning . We invest in training and developing our teams, and you will continue evolving and building your skills through personalized career plans. \n  The culture . As a leading beauty retailer within the LVMH family, our reach is broad, and our impact is global. It is in our DNA to innovate and, at Sephora, all 40,000 passionate team members across 35 markets and 3,000+ stores, are united by a common goal - to reimagine the future of beauty. \n \n \n  You can  unleash your creativity , because we\u2019ve got disruptive spirit. You can  learn and evolve , because we empower you to be your best. You can  be yourself , because you are what sets us apart.  This , is the future of beauty. Reimagine your future, at Sephora. \n \n  Sephora is an equal opportunity employer and values diversity at our company.  We do not discriminate on the basis of race, religion, color, national origin, ancestry, citizenship, gender, gender identity, sexual orientation, age, marital status, military/veteran status, or disability status. Sephora is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities. \n \n  Sephora will consider for employment all qualified applicants with criminal histories in a manner consistent with applicable law.",
        "cleaned_desc": "  Lead, design and actively implement / develop code for full stack applications including UI, services, respective DBs, respective data platform components, track / resolve defects resulting from Testing (includes unit, QA, UAT, etc.), deploy application to production, create deployment runbooks and work with Support team to monitor high priority tickets / issues in production. \n  Build and scale services infrastructure to meet functional requirements and Non-Functional Requirements SLAs. \n  Work with product and engineering team to understand requirements, evaluate new features and architecture to help drive decisions \n  Build collaborative partnerships with architects, technical leads and key individuals within other functional groups \n  Perform detailed analysis of business problems and technical environments and use this in designing quality technical solution \n  Actively participate in code review and test solutions to ensure it meets best practice specifications \n  Ability to fix defects independent of team members, if / when there is a need to reduce the turn around time. \n  Build and foster a high performance engineering culture, mentor team members and provide team with the tools and motivation to make things happen \n  Work with stakeholders and cross-functional teams to develop new solutions or enhance existing solution \n  Demonstrate our Sephora values of Passion for Client Service, Innovation, Expertise, Balance, Respect for All, Teamwork, and Initiative \n \n \n  We\u2019re excited about you if you have:  \n \n 8-10 years of software development and deployment experience with at least 5 years of hands-on experience with Java, Spring Boot, Microservice applications with RDBMS (Oracle, MySQL or equivalent), NoSQL (Cassandra, GraphDB, DocumentDB or equivalent) e.g. developing, debugging, and performance tuning - required    Good experience in React, Angular or equivalent front end frameworks preferred. \n  Strong experience building data ingestion pipelines (simulating Extract, Transform, Load workload), data processing or database architecture \n  Good experience in logging, monitoring and troubleshooting (Splunk, Graffana, Dynatrace, Prometheus, or equivalent)  \n Strong experience with data modeling, design patterns, building highly scalable Solutions and distributed applications \n  Ability to build and troubleshoot high throughput systems with low response time. \n  Knowledge of cloud platforms, for example: \n \n \n  Experience with Azure, AWS or equivalent cloud platforms \n  Microsoft Azure: Experience designing, deploying, and administering scalable, available, and fault tolerant systems on Microsoft Azure : Preferred Experience with Azure Management Portal, Azure Machine Learning, and Azure SQL Server \n  Experience with storing, joining, filtering, and analyzing data using Spark, Hive, Python : Preferred but not required. \n \n \n  Experience working with continuous integration framework, building regression-able code within data world using GitHub, Jenkins and related applications \n  Experience with programming/scripting languages such as Scala/Java/Python/R etc. (any combination) ",
        "techs": [
            "java",
            "spring boot",
            "rdbms (oracle",
            "mysql)",
            "nosql (cassandra",
            "graphdb",
            "documentdb)",
            "react",
            "angular",
            "splunk",
            "grafana",
            "dynatrace",
            "prometheus",
            "azure",
            "aws",
            "azure management portal",
            "azure machine learning",
            "azure sql server",
            "spark",
            "hive",
            "python",
            "github",
            "jenkins",
            "scala"
        ],
        "cleaned_techs": [
            "java",
            "spring boot",
            "rdbms (oracle",
            "mysql",
            "nosql",
            "graphdb",
            "documentdb)",
            "react",
            "angular",
            "splunk",
            "grafana",
            "dynatrace",
            "prometheus",
            "azure",
            "aws",
            "spark",
            "hive",
            "python",
            "github",
            "jenkins",
            "scala"
        ]
    },
    "ef821a3bdc064d42": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 88688.266,
        "salary_max": 112299.11,
        "title": "Cyber Readiness Software Developer",
        "company": "Carnegie Mellon University",
        "desc": "What We Do\n  \n \n \n   The CERT Cyber Mission Readiness (CMR) directorate strengthens the U.S. and its partners against cyber threats. We devise large and small-scale exercises, coordinate tabletop scenarios, orchestrate cybersecurity contests, and engineer open-source tools to enhance cyber defense capabilities. Actively partnering with sponsors, CMR pinpoints and mitigates vulnerabilities to advanced cyber adversaries.\n  \n \n \n   Central to CMR is a culture of collaboration and dedication. Determined to equip our nation and allies with the cyber tools necessary, we invite tech-savvy individuals passionate about software development and eager to work in a team-centric environment. An attitude of innovation, paired with a continuous learning mindset, is essential. We champion professional advancement through intensive training, mentorship, and collaborative learning.\n  \n \n \n   The Operational Readiness and Evaluation (ORE) team, an integral part of the CMR directorate, reinforces the Cyber Workforce's defense strategies. In alliance with SEI teams and governmental entities, we gauge operational prowess against set standards, molding strategies to assure mission success. Using cutting-edge simulation technology, we produce immersive virtual training environments and devise complex software-driven scenarios, aiming for cyber excellence.\n  \n \n \n   ORE emphasizes a cohesive and forward-thinking culture. Intent on advancing the national cybersecurity workforce, we welcome individuals enthusiastic about technology, teamwork, and perpetual learning. Our core values are rooted in in-depth training, mentoring, and knowledge exchange.\n  \n \n \n   Position Summary\n  \n \n \n   Embark on a transformative role within the Operational Readiness and Evaluation (ORE) team of the CERT Cyber Mission Readiness (CMR) directorate. We're targeting software-savvy professionals with a knack for developing advanced cyber operational readiness applications and tools. If you have a penchant for addressing intricate challenges with state-of-the-art software solutions and value teamwork, this is your calling. Your proficiency in software development and understanding of modern programming paradigms will be pivotal in advancing our mission. Collaborate with us and immerse yourself in a culture that cherishes innovation, commitment, and perpetual learning.\n  \n \n \n   Requirements:\n  \n \n  BS in Computer Science or related fields with 8 years of applicable experience; MS with 5 years; PhD with 2 years; or equivalent training/experience. \n  Willingness to travel up to 25%, including international destinations, in support of SEI's initiatives. \n  Must undergo a background check and qualify for a Department of Defense security clearance. \n \n \n \n   Duties:\n  \n \n  Collaborate seamlessly with team members. \n  Grasp client challenges. \n  Define software requirements and set development goals. \n  Engineer scenario-driven software simulations. \n  Develop, test, and deploy software applications tailored for cybersecurity simulations, training modules, and competitions. \n  Regularly engage with diverse software technologies and platforms. \n  Design and maintain software solutions aligning with government cyberspace directives. \n  Overcome challenges in software-driven learning and human-machine collaboration. \n  Prototype software tools and events. \n \n \n \n   Knowledge, Skills, and Abilities:\n  \n \n  Joining ORE offers an opportunity to refine your software skills. While prior experience with the following is beneficial, it's not obligatory: \n  Effective communication. \n  Cybersecurity principles. \n  Problem-solving in software development. \n  Self-motivated and driven to achieve required solutions. \n  Proficiency in multiple programming languages and development frameworks. \n  Familiarity with modern software platforms, from web development, databases, to machine learning systems. \n \n \n \n   Desired Experience:\n  \n \n  Roles in government/military involving software development, IT, and cybersecurity. \n \n \n \n   Benefits:\n  \n \n \n   Our benefits philosophy encompasses three driving priorities: Choice, Control, and Well-being. Learn more at https://www.cmu.edu/jobs/benefits-at-a-glance/. You can join an institution and inspire innovations that change the world.\n  \n \n \n   Location\n   Arlington, VA, Pittsburgh, PA, Remote\n  \n   Job Function\n   Software/Applications Development/Engineering\n  \n   Position Type\n   Staff \u2013 Regular\n  \n   Full Time/Part time\n   Full time\n  \n   Pay Basis\n   Salary\n  \n   More Information:\n  \n \n \n \n \n \n \n \n         Please visit \u201c\n         \n         Why Carnegie Mellon\n         \u201d to learn more about becoming part of an institution inspiring innovations that change the world.\n        \n \n \n         Click \n         \n         here\n          to view a listing of employee benefits\n        \n \n \n         Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.\n        \n \n \n \n          Statement of Assurance",
        "cleaned_desc": "   Embark on a transformative role within the Operational Readiness and Evaluation (ORE) team of the CERT Cyber Mission Readiness (CMR) directorate. We're targeting software-savvy professionals with a knack for developing advanced cyber operational readiness applications and tools. If you have a penchant for addressing intricate challenges with state-of-the-art software solutions and value teamwork, this is your calling. Your proficiency in software development and understanding of modern programming paradigms will be pivotal in advancing our mission. Collaborate with us and immerse yourself in a culture that cherishes innovation, commitment, and perpetual learning.\n  \n \n \n   Requirements:\n  \n \n  BS in Computer Science or related fields with 8 years of applicable experience; MS with 5 years; PhD with 2 years; or equivalent training/experience. \n  Willingness to travel up to 25%, including international destinations, in support of SEI's initiatives. \n  Must undergo a background check and qualify for a Department of Defense security clearance. \n \n \n \n   Duties:\n  \n \n  Collaborate seamlessly with team members. \n  Grasp client challenges. \n  Define software requirements and set development goals. \n  Engineer scenario-driven software simulations. \n  Develop, test, and deploy software applications tailored for cybersecurity simulations, training modules, and competitions. \n  Regularly engage with diverse software technologies and platforms. \n  Design and maintain software solutions aligning with government cyberspace directives. \n  Overcome challenges in software-driven learning and human-machine collaboration.    Prototype software tools and events. \n \n \n \n   Knowledge, Skills, and Abilities:\n  \n \n  Joining ORE offers an opportunity to refine your software skills. While prior experience with the following is beneficial, it's not obligatory: \n  Effective communication. \n  Cybersecurity principles. \n  Problem-solving in software development. \n  Self-motivated and driven to achieve required solutions. \n  Proficiency in multiple programming languages and development frameworks. \n  Familiarity with modern software platforms, from web development, databases, to machine learning systems. \n \n \n \n   Desired Experience:\n  \n \n  Roles in government/military involving software development, IT, and cybersecurity. \n \n \n ",
        "techs": [
            "software development",
            "programming paradigms",
            "software solutions",
            "software simulations",
            "software applications",
            "cybersecurity simulations",
            "training modules",
            "competitions",
            "software technologies",
            "software solutions aligning with government cyberspace directives",
            "software-driven learning",
            "human-machine collaboration",
            "software tools",
            "events",
            "communication",
            "cybersecurity principles",
            "problem-solving in software development",
            "programming languages",
            "development frameworks",
            "web development",
            "databases",
            "machine learning systems",
            "government/military roles involving software development",
            "it",
            "cybersecurity"
        ],
        "cleaned_techs": [
            "software development",
            "programming paradigms",
            "software solutions",
            "software simulations",
            "cybersecurity simulations",
            "training modules",
            "competitions",
            "software technologies",
            "software solutions aligning with government cyberspace directives",
            "software-driven learning",
            "human-machine collaboration",
            "software tools",
            "events",
            "communication",
            "cybersecurity principles",
            "problem-solving in software development",
            "programming languages",
            "development frameworks",
            "web development",
            "databases",
            "machine learning systems",
            "government/military roles involving software development",
            "it",
            "cybersecurity"
        ]
    },
    "88e5b7cc99187e18": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 97666.55,
        "salary_max": 123667.61,
        "title": "Cyber Readiness Infrastructure Engineer",
        "company": "Carnegie Mellon University",
        "desc": "What We Do\n  \n \n \n   The CERT Cyber Mission Readiness (CMR) directorate fortifies the U.S. and its partners against cyber threats. We design large and small-scale exercises, facilitate tabletop scenarios, run cybersecurity contests, and create open-source tools to bolster cyber defense capabilities. Actively partnering with sponsors, CMR identifies and addresses vulnerabilities to advanced cyber adversaries.\n  \n \n \n   Central to CMR is a culture of collaboration and dedication. Committed to arming our nation and allies with the tools to combat cyber threats, we seek passionate individuals who are technologically inclined and value teamwork. The right attitude, coupled with a thirst for knowledge, is paramount. We foster continuous professional growth through extensive training, mentorship, and cross-learning.\n  \n \n \n   Within the CMR directorate is the Operational Readiness and Evaluation (ORE) team. ORE intensifies the Cyber Workforce's defense posture. Collaborating with SEI teams and governmental units, we assess operational capabilities against established benchmarks, shaping strategies for maximum mission assurance. Leveraging innovative simulation technology, we develop high-end virtual training arenas and design challenging scenarios, striving to be at the pinnacle of cyber readiness.\n  \n \n \n   ORE champions a unified and progressive culture. Driven to uplift the national cybersecurity workforce, we invite individuals with a zeal for technology, collaboration, and ongoing learning. Our ethos revolves around comprehensive training, mentorship, and skill-sharing.\n  \n \n \n   Position Summary\n  \n \n \n   Step into the pivotal role within the Operational Readiness and Evaluation (ORE) team, a key component of the CERT Cyber Mission Readiness (CMR) directorate. We're on the lookout for technical professionals, especially in the realms of networking and backend infrastructure. As a member of our team, you'll be tasked with architecting cyber operational readiness strategies for U.S. Government stakeholders. If you possess a knack for tackling intricate challenges with innovative solutions and place a premium on teamwork, this position awaits you. Your expertise in infrastructure management, coupled with a deep understanding of networking and virtualization, will be instrumental in elevating our mission. Join us, and be a part of a culture that values collaboration, dedication, and continuous learning.\n  \n \n \n   Requirements:\n  \n \n  BS in relevant fields with 8 years of applicable experience; MS with 5-years; PhD with 2-years; or equivalent training/experience. \n  Willingness to travel up to 25%, including international travel, supporting SEI's mission. \n  Must pass a background check and be eligible for a Department of Defense security clearance. \n \n \n   Duties:\n  \n \n  Collaborate effectively with team members. \n  Understand customer challenges. \n  Collect requirements and set objectives. \n  Develop engaging scenario-based simulations. \n  Build physical and virtualized networks; define and solve challenging problems for cybersecurity simulations, training programs, and competitions . \n  Manage cloud and on-premise networking infrastructure. \n  Work regularly with a wide range of software and hardware technologies . \n  Create and maintain solutions supporting government cyberspace roles. \n  Address challenges in learning and human-machine teaming. \n  Develop software and event prototypes. \n \n \n \n   Knowledge, Skills, and Abilities:\n  \n \n \n   Joining ORE provides a chance to enhance your skills. While prior experience with the following is advantageous, it's not mandatory:\n  \n \n  Clear communication. \n  Cybersecurity fundamentals. \n  Technical problem-solving. \n  Networking expertise. \n  System and cloud expertise. \n  Various technical platforms and tools, ranging from server platforms, network administration, and programming languages to artificial intelligence and learning systems. \n \n \n \n   Desired Experience:\n  \n \n  Roles in government/military related to IT, cybersecurity, and large-scale network management. \n \n \n \n   Benefits:\n  \n \n \n   Our benefits philosophy encompasses three driving priorities: Choice, Control, and Well-being. Learn more at https://www.cmu.edu/jobs/benefits-at-a-glance/. You can join an institution and inspire innovations that change the world.\n  \n \n \n   Location\n   Arlington, VA, Pittsburgh, PA, Remote\n  \n   Job Function\n   Software/Applications Development/Engineering\n  \n   Position Type\n   Staff \u2013 Regular\n  \n   Full Time/Part time\n   Full time\n  \n   Pay Basis\n   Salary\n  \n   More Information:\n  \n \n \n \n \n \n \n \n         Please visit \u201c\n         \n         Why Carnegie Mellon\n         \u201d to learn more about becoming part of an institution inspiring innovations that change the world.\n        \n \n \n         Click \n         \n         here\n          to view a listing of employee benefits\n        \n \n \n         Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.\n        \n \n \n \n          Statement of Assurance",
        "cleaned_desc": " \n \n   Knowledge, Skills, and Abilities:\n  \n \n \n   Joining ORE provides a chance to enhance your skills. While prior experience with the following is advantageous, it's not mandatory:\n  \n \n  Clear communication. \n  Cybersecurity fundamentals. \n  Technical problem-solving. \n  Networking expertise. \n  System and cloud expertise. \n  Various technical platforms and tools, ranging from server platforms, network administration, and programming languages to artificial intelligence and learning systems. \n \n \n \n   Desired Experience:\n  \n \n  Roles in government/military related to IT, cybersecurity, and large-scale network management. \n \n \n ",
        "techs": [
            "clear communication",
            "cybersecurity fundamentals",
            "technical problem-solving",
            "networking expertise",
            "system and cloud expertise",
            "various technical platforms and tools",
            "server platforms",
            "network administration",
            "programming languages",
            "artificial intelligence",
            "learning systems",
            "roles in government/military related to it",
            "cybersecurity",
            "large-scale network management"
        ],
        "cleaned_techs": [
            "clear communication",
            "cybersecurity fundamentals",
            "technical problem-solving",
            "networking expertise",
            "system and cloud expertise",
            "various technical platforms and tools",
            "server platforms",
            "network administration",
            "programming languages",
            "ai",
            "learning systems",
            "roles in government/military related to it",
            "cybersecurity",
            "large-scale network management"
        ]
    },
    "f408df5877bd38be": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 160000.0,
        "salary_max": 225000.0,
        "title": "Software Application Architect",
        "company": "Bekhealth Corp",
        "desc": "About Us \n  BEKHealth Corporation is a leading clinical technology company that operates an AI-powered patient-matching software platform serving the clinical trial industry. Our platform allows life sciences and healthcare organizations to speed up trial feasibility, site selection, and patient recruitment by extracting data from electronic medical records (EMRs), which includes structured and unstructured clinical data that captures three times more trial criteria. Our software provides patient population analysis, site feasibility and selection, study participant identification, and study participant matching to site networks. \n \n  About the Opportunity \n  We are seeking an experienced and high-achieving Software Architect to build and enhance applications in the BEKHealth platform, the leading AI-driven data processing platform for clinical trial acceleration. The selected individual will play a critical role in driving the BEKHealth mission, developing and improving the BEKHealth Platform. Responsibilities include designing, building and enhancing the BEKHealth Application suite, maintaining the reliability and performance of the platform, managing terabytes of medical data, collaborating across BEKHealth teams to support machine learning and trial recruitment efforts through product development and ensuring data quality and processing performance. \n \n  Responsibilities: \n \n Architect and develop backend systems for the BEKHealth Applications and data processing pipelines for processing patient health information from various 3rd party sources including EMRs and Data Warehouses.  \n Collaborate and contribute to frontend applications. \n Produce high-quality, maintainable and well documented code. \n Collaborate with other developers, product owners, and stakeholders to gather requirements and develop solutions that meet business needs. \n Mentor and guide junior developers to improve their technical skills and knowledge. \n Be proactive and solution-oriented, and driven to get things done in high-complexity environments. \n \n \n \n  Requirements : \n \n Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar. \n 8+ years of professional experience as a software engineer \n Experience designing and writing Python Applications and Data Pipelines \n    \n Senior level experience with Python Flask or Django applications with SQL data storage \n \n \n \n Experience developing and supporting REST APIs is required \n Experience with data presentation applications and an eye for creating a quality user experience is a plus \n Experience with data modeling and understanding of both relational and document-based databases - \n    \n MongoDB experience a plus   \n \n Experience working with Healthcare Data Systems \n    \n Experience with EMR systems is preferred \n Experience dealing with protected health information (PHI) is a plus \n Experience with medical terminology or medical ontologies/semantics is a plus \n \n AWS experience and familiarity with SaaS deployment models - Kubernetes experience a plus \n \n \n \n Personality: \n  The ideal candidate is one whom is smart, gets things done and works well with other; and who has been described as focused and entrepreneurial, with great follow-through and attention to detail. Someone who exhibits character, and presence without arrogance, while also being highly credible both internally with the team and externally with customers will be an excellent fit. \n \n  Benefits: \n  We offer competitive salary, bonus plan and equity packages, health insurance, and other benefits. You will have the opportunity to work with a talented and passionate team and make a significant impact on the healthcare industry. \n \n  Additional Information: \n  Immigration sponsorship is  not  available for this position",
        "cleaned_desc": "About Us \n  BEKHealth Corporation is a leading clinical technology company that operates an AI-powered patient-matching software platform serving the clinical trial industry. Our platform allows life sciences and healthcare organizations to speed up trial feasibility, site selection, and patient recruitment by extracting data from electronic medical records (EMRs), which includes structured and unstructured clinical data that captures three times more trial criteria. Our software provides patient population analysis, site feasibility and selection, study participant identification, and study participant matching to site networks. \n \n  About the Opportunity \n  We are seeking an experienced and high-achieving Software Architect to build and enhance applications in the BEKHealth platform, the leading AI-driven data processing platform for clinical trial acceleration. The selected individual will play a critical role in driving the BEKHealth mission, developing and improving the BEKHealth Platform. Responsibilities include designing, building and enhancing the BEKHealth Application suite, maintaining the reliability and performance of the platform, managing terabytes of medical data, collaborating across BEKHealth teams to support machine learning and trial recruitment efforts through product development and ensuring data quality and processing performance. \n \n  Responsibilities: \n \n Architect and develop backend systems for the BEKHealth Applications and data processing pipelines for processing patient health information from various 3rd party sources including EMRs and Data Warehouses.  \n Collaborate and contribute to frontend applications.   Produce high-quality, maintainable and well documented code. \n Collaborate with other developers, product owners, and stakeholders to gather requirements and develop solutions that meet business needs. \n Mentor and guide junior developers to improve their technical skills and knowledge. \n Be proactive and solution-oriented, and driven to get things done in high-complexity environments. \n \n \n \n  Requirements : \n \n Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar.   8+ years of professional experience as a software engineer \n Experience designing and writing Python Applications and Data Pipelines \n    \n Senior level experience with Python Flask or Django applications with SQL data storage \n \n \n \n Experience developing and supporting REST APIs is required \n Experience with data presentation applications and an eye for creating a quality user experience is a plus \n Experience with data modeling and understanding of both relational and document-based databases - ",
        "techs": [
            "python",
            "ai",
            "electronic medical records (emrs)",
            "structured and unstructured clinical data",
            "data processing",
            "data warehousing",
            "python flask",
            "django",
            "sql",
            "rest apis",
            "data modeling",
            "relational databases",
            "document-based databases"
        ],
        "cleaned_techs": [
            "python",
            "ai",
            "electronic medical records (emrs)",
            "structured and unstructured clinical data",
            "data warehousing",
            "django",
            "sql",
            "rest apis",
            "relational databases",
            "document-based databases"
        ]
    },
    "8f1602adaaf74f5f": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 110000.0,
        "salary_max": 110000.0,
        "title": "Computer Engineer IV",
        "company": "Chenega MIOS",
        "desc": "Summary \n Computer Engineer IV \n Lorton, VA (Remote) \n Are you ready to enhance your skills and build your career in a rapidly evolving business climate? Are you looking for a career where professional development is embedded in your employer\u2019s core culture? If so, Chenega Military, Intelligence & Operations Support (MIOS) could be the place for you! Join our team of professionals who support large-scale government operations by leveraging cutting-edge technology and take your career to the next level! \n Chenega Analytic Business Solutions (CABS) provides federal agencies and commercial customers with trusted insights into Records and Information Management, Administrative Solutions, Information Technology, Engineering, and Training. Formed in 2017 to serve federal and commercial customers, CABS is 8(a) certified and has grown quickly into a leader in the federal IT and Training environment. \n The  Computer Engineer IV  shall research, design, develop, and test computer hardware and software programs. \n Responsibilities \n \n Maintain the current MyNavy Learning (MNL) ecosystem to support training content re-engineering with the incorporation of emerging learning technologies, integrate machine learning content validation pipeline for continuous improvement and continuous delivery, and capture the learner\u2019s data for analysis by intelligence algorithm. \n Leverage the MNL-optimized DevSecOps environment. \n Complete various stages of the engineering design, development, testing, evaluation, integration, and fielding of web-based training portals, embedded learning management systems, web-based distributed training technology enablers, mobile hybrid applications, and thousands of hours of Level I\u2013IV learning content for numerous customers throughout the DoD. \n Coordinate, synchronize, lead, & facilitate MNL integration based on functional requirements (e.g., capability software integration, technical standards implementation + enforcement, capability LOE component integration, capability test + evaluation, capability integration with product owner environment, capability configuration management, continual capability functional + technical enhancements, & continual capability technical sustainment. \n Conduct research, development, testing, and evaluation (RDT&E) of advanced distributed training technologies, advanced distributed learning technologies, and total learning architecture paradigm. \n Coordinate, synchronize, manage, & technically integrate all required aspects of MNL DevSecOps environment (includes the MNL Product Owner and Developers Sandbox, MNL standalone/disconnected laptop, and Developers Oracle Virtual Box). \n Develop new computer software systems and incorporate new technologies in a rapidly growing range of applications. \n Apply the principles and techniques of computer science, engineering, and mathematical analysis to the design, development, testing, and evaluation of the software and systems that enable computers to perform their many applications. \n Analyze users\u2019 needs and design, construct, test, and maintain computer applications software, or systems. \n Solve technical problems that arise. Software engineers must possess strong programming skills but are more concerned with developing algorithms and analyzing and solving programming problems than with writing code. \n Complete annual company and customer-required training, as required. \n Complete timesheets daily in an online system according to company policies and procedures. \n Travel up to 10% as required. \n Other duties as assigned. \n \n Qualifications \n \n Bachelor's level degree in Computer, Electrical or Electronics Engineering or Mathematics with field of concentration in computer science. \n 10+ years of professional experience in computer design, software development, or computer networks. \n Must be a U.S. citizen. \n Background check required. \n \n Knowledge, Skills, and Abilities: \n \n Ability to pass customer security requirements. \n Advanced working knowledge of computer software applications, including Microsoft Office Suite and Outlook, Excel, and PowerPoint. \n Proficient in programming languages C, C++, and Java, with Fortran \n Knowledge of the programming language COBOL. \n Excellent written, verbal, and interpersonal skills are required. \n Ability to interact with all levels of staff, government personnel, and management. \n Ability to attend all customer in-person meetings and conferences as requested. \n Possess excellent organizational skills with the ability to prioritize. \n Ability to multi-task in a high-performance-based environment. \n Possess strong problem-solving skills. \n Ability to self-start and work independently or as a team. \n Travel up to 10% as required. \n \n How you\u2019ll grow \n At Chenega MIOS, our professional development plan focuses on helping our team members at every level of their careers to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there\u2019s always room to learn. \n We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their careers. \n Benefits \n At Chenega MIOS, we know that great people make a great organization. We value our team members and offer them a broad range of benefits. \n Learn more about what working at Chenega MIOS can mean for you. \n Chenega MIOS\u2019s culture \n Our positive and supportive culture encourages our team members to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them be healthy, centered, confident, and aware. We offer well-being programs and continuously look for new ways to maintain a culture where we excel and lead healthy, happy lives. \n Corporate citizenship \n Chenega MIOS is led by a purpose to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our team members, and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. \n Learn more about Chenega\u2019s impact on the world. \n Chenega MIOS News- https://chenegamios.com/news/ \n Tips from your Talent Acquisition Team \n We want job seekers exploring opportunities at Chenega MIOS to feel prepared and confident. To help you with your research, we suggest you review the following links: \n Chenega MIOS web site - www.chenegamios.com \n Glassdoor - https://www.glassdoor.com/Overview/Working-at-Chenega-MIOS-EI\\_IE369514.11,23.htm \n LinkedIn - https://www.linkedin.com/company/1472684/ \n Facebook - https://www.facebook.com/chenegamios/ \n \\#Chenega Analytic Business Solutions, LLC \n Teleworking Permitted? \n Yes \n Teleworking Details \n Remote \n Estimated Salary/Wage \n USD $110,000.00/Yr. Up to USD $140,000.00/Yr. \n Chenega Corporation and family of companies is an EOE. \n Equal Opportunity Employer/Veterans/Disabled \n Native preference under PL 93-638. \n We participate in the E-Verify Employment Verification Program",
        "cleaned_desc": " Develop new computer software systems and incorporate new technologies in a rapidly growing range of applications. \n Apply the principles and techniques of computer science, engineering, and mathematical analysis to the design, development, testing, and evaluation of the software and systems that enable computers to perform their many applications. \n Analyze users\u2019 needs and design, construct, test, and maintain computer applications software, or systems. \n Solve technical problems that arise. Software engineers must possess strong programming skills but are more concerned with developing algorithms and analyzing and solving programming problems than with writing code. \n Complete annual company and customer-required training, as required. \n Complete timesheets daily in an online system according to company policies and procedures. \n Travel up to 10% as required. \n Other duties as assigned. \n \n Qualifications \n \n Bachelor's level degree in Computer, Electrical or Electronics Engineering or Mathematics with field of concentration in computer science. \n 10+ years of professional experience in computer design, software development, or computer networks. \n Must be a U.S. citizen.   Background check required. \n \n Knowledge, Skills, and Abilities: \n \n Ability to pass customer security requirements. \n Advanced working knowledge of computer software applications, including Microsoft Office Suite and Outlook, Excel, and PowerPoint. \n Proficient in programming languages C, C++, and Java, with Fortran \n Knowledge of the programming language COBOL. \n Excellent written, verbal, and interpersonal skills are required. \n Ability to interact with all levels of staff, government personnel, and management. \n Ability to attend all customer in-person meetings and conferences as requested. \n Possess excellent organizational skills with the ability to prioritize. \n Ability to multi-task in a high-performance-based environment. \n Possess strong problem-solving skills. ",
        "techs": [
            "microsoft office suite",
            "outlook",
            "excel",
            "powerpoint",
            "c",
            "c++",
            "java",
            "fortran",
            "cobol"
        ],
        "cleaned_techs": [
            "microsoft",
            "outlook",
            "excel",
            "powerpoint",
            "c",
            "c++",
            "java",
            "fortran",
            "cobol"
        ]
    },
    "205e45de852ee617": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 192000.0,
        "salary_max": 260000.0,
        "title": "Director, Product",
        "company": "BOLD LLC",
        "desc": "United States (Remote) \n   \n \n We are looking for a dynamic, hands-on product leader who is passionate about enabling transformative content experiences and leading BOLD into a future powered by the latest advancements in technology. You will manage a team of talented product and data managers who are building a robust, scalable platform that leverages LLMs, machine learning, manual content curation, and provision of services. Partnering with content experts, linguists, data scientists, engineers, and product managers, you will define and execute a strategy that will guide the development of content and data capabilities for our customers. \n  ABOUT THIS TEAM \n  As the Customer Experience Team at Bold, we believe technology has the power to transform the job search journey and we are always looking for ways to help job seekers reach their full career potential. Our team focuses on creating content and data capabilities that address the needs of our customers and build value and intellectual property for our business. Our platform powers multiple products in over 180 countries across all types of jobs and industries-from cashiers to nurses, teachers to graphic designers, construction workers to executives, and beyond. \n  WHAT YOU\u2019LL DO \n \n Oversee global content delivery, service delivery, content tooling, and data tooling for all of BOLD\u2019s products across several portals and 8+ different languages. \n Achieve one of the highest revenue targets for any product team in the company. Define the roadmap for a content and data platform that will support millions of job seekers and achieve growth goals. \n Integrate and operationalize GPT/LLM into our content and data operations, managing change and innovation from a people, process, and execution perspective. \n Ensure utilization of career domain data in autocompletes, search & match and segmentation, and other product features and use cases. \n Manage and develop a high-performance team. Optimize resources to fully utilize our experimentation capacity and achieve customer and revenue goals \n Partner closely with engineering teams based in India to align workstreams and effectively leverage our graph-based data pipeline and content authoring capabilities and integrate LLM technologies and machine learning to deliver intelligent recommendations to job seekers \n Collaborate with internal partners that are distributed across the globe. Foster strong cross-functional teamwork with portal product leaders, data scientists, content experts, linguists, engineers, researchers \n \n   WHAT YOU\u2019LL NEED \n \n 10+ years of professional experience in product management, preferably technical product management for platform services, APIs, search, data pipeline, internal tooling \n 5+ years of people management, preferably leading and developing product managers \n 3+ years building, delivering, and supporting large-scale, complex content or data tools, services and/or products \n Demonstrated ability to apply knowledge of machine learning, LLMs, and other Generative AI technologies to solve user problems and create delightful user experiences \n Business acumen and demonstrated track record of making data-driven decisions and driving growth and revenue \n Enjoys the challenge of executing against goals, within complex systems and rapidly evolving technology \n Ability to lead and motivate a team to high performance, teamwork, collaboration, and delivering on goals \n \n WHAT\u2019S GOOD TO HAVE \n \n Experience with data management, ontology development, and natural language processing. \n Product Management experience in start-up, mid-size, and/or larger corporate organizations \n Experience in the human capital industry, recruiting, or educational technology, is a plus \n Master's degree in business or a technology-related field \n Experience with rapid experimentation and A/B Testing, analysis and related tools \n Experience with localization/globalization or foreign language proficiency in at least one of the following languages preferred: French, Spanish, Italian, German, Dutch, Polish, or Portuguese \n Strong analytical capability \n \n BENEFITS \n  OUTSTANDING COMPENSATION \n \n Competitive salary \n Bi-annual bonus \n 401(k) plan with match \n Equity in company \n Flexible spending accounts (health, dependent care) \n Internet and home office reimbursement \n \n 100% FULL HEALTH BENEFITS \n \n Medical, dental, and vision (optional plans for your family) \n Life & long term disability insurance (optional) \n Mental health support and resources \n Wellness reimbursement (gym, health apps, etc.) \n Pet Insurance (optional) \n \n FLEXIBLE TIME AWAY \n \n Flexible PTO \n Sick time policy \n Observed holidays \n 1-week PTO for the December holidays \n \n Under San Francisco's Fair Chance Ordinance, qualified applicants with arrest and conviction records will be considered for the position. \n \n \n \n \n  Individual pay is based on location, transferable skills, experience, and other relevant factors. This estimated range is based on the best available market data and factors, all of which are subject to change. This position may also be eligible for a bonus and medical, dental, vision, life, short and long-term disability insurance, 401(k), paid time off, sick leave, and paid holidays, all subject to applicable plan terms.\n    \n \n     Starting Hourly Pay\n    \n \n     $192,000\u2014$260,000 USD\n    \n \n \n \n  ABOUT BOLD  As an established global organization (17 years and counting), BOLD helps people find jobs. Our story is one of growth, success, and professional fulfillment.  We create digital products that have empowered over three million people in 180 countries to build stronger resumes, cover letters, and CVs. The result of our work helps people interview confidently, finding the right job in less time.  Our employees are experts, learners, contributors, and creatives.     BOLD VALUES OUR POSITION AS AN EQUAL OPPORTUNITY EMPLOYER   WE VALUE, CELEBRATE, AND PROMOTE DIVERSITY AND INCLUSION.  We hire based on qualifications, merit, and our business needs. We don't discriminate regarding race, color, religion, gender, pregnancy, national origin or citizenship, ancestry, age, physical or mental disability, veteran status, sexual orientation, gender identity or expression, marital status, genetic information, or any other applicable characteristic protected by law. \n \n \n \n \n   United States (Remote)\n    \n  Director, Product",
        "cleaned_desc": "   WHAT YOU\u2019LL NEED \n \n 10+ years of professional experience in product management, preferably technical product management for platform services, APIs, search, data pipeline, internal tooling \n 5+ years of people management, preferably leading and developing product managers \n 3+ years building, delivering, and supporting large-scale, complex content or data tools, services and/or products \n Demonstrated ability to apply knowledge of machine learning, LLMs, and other Generative AI technologies to solve user problems and create delightful user experiences \n Business acumen and demonstrated track record of making data-driven decisions and driving growth and revenue \n Enjoys the challenge of executing against goals, within complex systems and rapidly evolving technology \n Ability to lead and motivate a team to high performance, teamwork, collaboration, and delivering on goals \n \n WHAT\u2019S GOOD TO HAVE \n \n Experience with data management, ontology development, and natural language processing. \n Product Management experience in start-up, mid-size, and/or larger corporate organizations \n Experience in the human capital industry, recruiting, or educational technology, is a plus \n Master's degree in business or a technology-related field ",
        "techs": [
            "apis",
            "data pipeline",
            "internal tooling",
            "machine learning",
            "llms",
            "generative ai technologies",
            "data management",
            "ontology development",
            "natural language processing."
        ],
        "cleaned_techs": [
            "apis",
            "data pipeline",
            "internal tooling",
            "llm",
            "generative ai technologies",
            "data management",
            "ontology development",
            "nlp"
        ]
    },
    "452d4b9831d39565": {
        "terms": [
            "mlops"
        ],
        "salary_min": 110000.0,
        "salary_max": 150000.0,
        "title": "Senior Azure DevOps Engineer",
        "company": "Mechanicode.io",
        "desc": "We are looking for a DevOps engineer to enable efficient delivery of value to our customers at the CDC through effective infrastructure and CI/CD pipelines, empowering application developers to deliver at the speed of business. \n The DevOps Engineer will support operations of the cloud environment with observability, IAC, and cloud-native best practices. \n The engineer will be part of a larger effort to modernize the CDC DevOps enterprise framework by joining the team of 20 which is comprised of data scientists, software engineers, product owners, and DevOps engineers. \n Mechanicode  is a remote-first company, and this role will be 100% remote. \n \n 1099:  $80-90/hr \n Required \n \n Must be a U.S citizen or green-card holder \n 7-10 years of professional experience \n Ability to pass a background check and obtain a public trust security clearance \n \n Essential Skills, Experience, and Competencies : \n \n Experience with implementing cloud infrastructure on Azure. \n Proficient with Infrastructure as Code tools (Terraform, Pulumi, AWS CDK, etc) \n Experience with Linux, and Bash scripting. \n Substantial experience with programming languages like Python \n Experience with containerization technologies (e.g.Docker, containerD) \n Ability to develop the architecture for continuous integration and deployment as well as continuous monitoring \n Experience supporting scalable and elastic applications on distributed architectures. \n Strong ability and understanding of securing systems on the application, network, and infrastructure layers. \n Experience managing network/compute/database infrastructure with infrastructure-as-code. \n Experience with Observability in the cloud, building monitoring & alerting frameworks \n Expert in basic git actions like cloning, creating branches, navigating between branches, staging code for commit, committing code, resetting, and merging. \n Ability to mentor & support junior members \n Proven ability to work under pressure and in fast-paced environments. \n Understanding of interfacing with external APIs (REST, JSON, Auth Tokens). \n Ability to operate and manage work, strategically reason, build relationships and influence others. \n \n Nice to Have \n \n Azure Certifications \n \n Interview Steps \n \n Preliminary Screen \n CoderByte Assessment \n Technical review \n Client Review \n \n Why Mechanicode? \n Mechanicode's vision is to bring peace of mind with technology. \n We do so by building self-healing cloud infrastructure, resilient enough to withstand failures and sufficiently predictable to resolve issues without human intervention. \n We do that by having automation as the cornerstone of our cloud solutions, significantly improving workforce attrition, and introducing agile rapid development conventions that improve the developer's experience. \n About Mechanicode \n Mechanicode a Cloud Digital services firm providing comprehensive DevSecOps, Cloud Native Engineering, IT Modernization & Automation services. \n Founded by a former USDS engineer, Mechanicode has 12 years of experience developing innovative automation solutions improving the feedback loop in the developer experience, and using AWS/Azure Certified best practices for clients. \n Mechanicode has experience in both the public and private sectors, providing modernization services that engage Agile best practices, scalable cloud architectures, and continuous integration & deployment standards.",
        "cleaned_desc": " 7-10 years of professional experience \n Ability to pass a background check and obtain a public trust security clearance \n \n Essential Skills, Experience, and Competencies : \n \n Experience with implementing cloud infrastructure on Azure. \n Proficient with Infrastructure as Code tools (Terraform, Pulumi, AWS CDK, etc) \n Experience with Linux, and Bash scripting. \n Substantial experience with programming languages like Python   Experience with containerization technologies (e.g.Docker, containerD) \n Ability to develop the architecture for continuous integration and deployment as well as continuous monitoring \n Experience supporting scalable and elastic applications on distributed architectures. \n Strong ability and understanding of securing systems on the application, network, and infrastructure layers. \n Experience managing network/compute/database infrastructure with infrastructure-as-code. \n Experience with Observability in the cloud, building monitoring & alerting frameworks \n Expert in basic git actions like cloning, creating branches, navigating between branches, staging code for commit, committing code, resetting, and merging. \n Ability to mentor & support junior members \n Proven ability to work under pressure and in fast-paced environments. ",
        "techs": [
            "azure",
            "terraform",
            "pulumi",
            "aws cdk",
            "linux",
            "bash scripting",
            "python",
            "docker",
            "containerd",
            "continuous integration",
            "continuous deployment",
            "continuous monitoring",
            "scalable applications",
            "elastic applications",
            "network security",
            "infrastructure security",
            "infrastructure-as-code",
            "observability",
            "monitoring framework",
            "alerting framework",
            "git",
            "mentoring",
            "fast-paced environments"
        ],
        "cleaned_techs": [
            "azure",
            "terraform",
            "pulumi",
            "aws",
            "linux",
            "bash scripting",
            "python",
            "docker",
            "containerd",
            "continuous integration",
            "continuous deployment",
            "continuous monitoring",
            "infrastructure-as-code",
            "observability",
            "monitoring framework",
            "alerting framework",
            "git",
            "mentoring",
            "fast-paced environments"
        ]
    },
    "6f19655336e2f6b3": {
        "terms": [
            "mlops"
        ],
        "salary_min": 126729.68,
        "salary_max": 160468.02,
        "title": "DevOps Engineer",
        "company": "Intermedia.net, Inc.",
        "desc": "About Intermedia \n Are you looking for a company where  YOUR VOICE  is heard? Where you can  MAKE A DIFFERENCE ? Do you  THRIVE  in a  FAST-PACED  work environment? Do you wake every morning  EXCITED  to work with  GREAT   PEOPLE  and create  SUCCESS   TOGETHER ? Then Intermedia is the place for you. \n Intermedia has established itself as a leading provider of cloud communications and collaboration tech that allows companies to connect better. We have a strong track record of growth, profitability, and creating an environment where everyone matters. Everyone. While we are fast-paced and admittedly a bit intense, we promise that you won\u2019t be bored. You will find Intermedia is a place where you can indulge your passion for creating and supporting great cloud technology. What\u2019s more, we always look to promote from within and have many employees who have been with us 10, 15, and 20+ years! \n Culture at Intermedia is built on teamwork and transparency. We hold each other accountable and always have each other\u2019s back! \n Are you ready to make your mark? \n About the Role \n As part of the SecuriSync DevOps team you will be responsible for the support and maintenance of our applications through to the Kubernetes clusters which run them, ensuring an accurate and consistent approach is taken right from development through to production. \n What You'll Do: \n \n Work closely with the development team to deploy and maintain and understand application infrastructure \n \n \n Develop and support tooling to assist in the deployment and maintenance of products \n \n \n Develop Helm charts and deploy applications in development through to production \n \n \n Manage and support Kubernetes \n \n \n Support in-house and third-party applications \n \n \n Write clear, concise documentation of all processes and practices \n \n \n What you bring to the table: \n \n 5+ years related experience (Linux Systems Admin / DevOps / Site Reliability Engineer / Software Engineer) \n \n \n Experience managing Linux servers via the terminal \n \n \n Excellent communication skills \n \n \n Experience working with Kubernetes \n \n \n Experience with scripting Bash/Python \n \n \n Experience working with MySQL \n \n \n Experience with ElasticSearch, RabbitMQ \n \n \n Experience in managing and working with complex distributed systems \n \n Bonus Experience: \n \n Ansible \n \n \n Terraform \n \n \n Azure DevOps CI/CD \n \n \n CEPH \n \n \n Prometheus / Grafana dashboards and visualizations",
        "cleaned_desc": " \n \n Experience with scripting Bash/Python \n \n \n Experience working with MySQL \n \n \n Experience with ElasticSearch, RabbitMQ \n \n \n Experience in managing and working with complex distributed systems \n ",
        "techs": [
            "bash",
            "python",
            "mysql",
            "elasticsearch",
            "rabbitmq"
        ],
        "cleaned_techs": [
            "bash",
            "python",
            "mysql",
            "elasticsearch",
            "rabbitmq"
        ]
    },
    "415039e98d130a93": {
        "terms": [
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 120000.0,
        "title": "DevOps Engineer",
        "company": "American Logistics, LLC",
        "desc": "American Logistics is looking for a DevOps Engineer to be at the forefront of revolutionizing our next-generation transportation management software. As part of our dynamic team, you will collaborate closely with fellow DevOps Engineers, Developers, IT Ops staff and Architects. Your mission will be to craft and implement innovative automation tools within our cloud infrastructure. At American Logistics, our DevOps team is committed to accelerating development cycles while bolstering platform security and reliability. \n DevOps Engineer Duties: \n \n Collaborate with software developers, system operators, and IT staff to manage code releases and CI/CD workflows and optimize cloud architecture. \n Develop solutions bridging development and operations, utilizing a software engineering approach to enhance system engineering tasks. \n Create and maintain tools and processes to manage cloud infrastructure, systems, databases, and applications, focusing on security, availability, low latency, high performance, efficiency, and continuous monitoring. \n Ensure meticulous documentation of processes and tools. \n Proactively plan for future capacity requirements, aligning with business needs and cloud infrastructure objectives. \n Be available for emergency response and participate in an on-call rotation, ensuring system resilience and reliability. \n \n DevOps Engineer Requirements or Must Have Skills: \n \n In-depth knowledge of AWS is a requirement, with additional cloud experience desirable. \n Proficiency in developing, building, and deploying applications. \n Experience with CI/CD practices and theories. \n Skilled in observability tool management and configuration. \n Knowledge of testing frameworks and test automation. \n Familiarity with Docker containers, cloud platforms, and Kubernetes. \n Experience with identity management platforms and queuing/messaging systems. \n Understanding of SQL databases and proficiency in Node.js and .NET. \n Ability in scripting and markup languages such as JSON and YAML. \n \n DevOps Engineer Qualifications: \n \n A record of accomplishment in software or infrastructure development or a combined background in development and operations. \n Keen awareness of the latest industry trends, with the ability to communicate these trends clearly and confidently. \n Strong interpersonal and communication skills, comfortable interacting with all management levels. \n At least two years' experience in a relevant IT, computer, operations, or development and operations field. \n \n American Logistics offers a unique work culture that allows people to make a difference and thrive. We value our employees\u2019 feedback and ideas, and view them as critical to our success. \n Job Type: Full-time \n Pay: $100,000.00 - $120,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible schedule \n Flexible spending account \n Health insurance \n Life insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Please describe your experience with AWS, framework testing, and scripting. \n Please describe your experience with SQL databases. \n \n Experience: \n \n DevOps: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "American Logistics is looking for a DevOps Engineer to be at the forefront of revolutionizing our next-generation transportation management software. As part of our dynamic team, you will collaborate closely with fellow DevOps Engineers, Developers, IT Ops staff and Architects. Your mission will be to craft and implement innovative automation tools within our cloud infrastructure. At American Logistics, our DevOps team is committed to accelerating development cycles while bolstering platform security and reliability. \n DevOps Engineer Duties: \n \n Collaborate with software developers, system operators, and IT staff to manage code releases and CI/CD workflows and optimize cloud architecture. \n Develop solutions bridging development and operations, utilizing a software engineering approach to enhance system engineering tasks. \n Create and maintain tools and processes to manage cloud infrastructure, systems, databases, and applications, focusing on security, availability, low latency, high performance, efficiency, and continuous monitoring. \n Ensure meticulous documentation of processes and tools. \n Proactively plan for future capacity requirements, aligning with business needs and cloud infrastructure objectives. \n Be available for emergency response and participate in an on-call rotation, ensuring system resilience and reliability. \n \n DevOps Engineer Requirements or Must Have Skills: \n   In-depth knowledge of AWS is a requirement, with additional cloud experience desirable. \n Proficiency in developing, building, and deploying applications. \n Experience with CI/CD practices and theories. \n Skilled in observability tool management and configuration. \n Knowledge of testing frameworks and test automation. \n Familiarity with Docker containers, cloud platforms, and Kubernetes. \n Experience with identity management platforms and queuing/messaging systems. \n Understanding of SQL databases and proficiency in Node.js and .NET. \n Ability in scripting and markup languages such as JSON and YAML. \n \n DevOps Engineer Qualifications: \n ",
        "techs": [
            "aws",
            "ci/cd",
            "observability tool management",
            "docker",
            "kubernetes",
            "identity management platforms",
            "queuing/messaging systems",
            "sql databases",
            "node.js",
            ".net",
            "json",
            "yaml"
        ],
        "cleaned_techs": [
            "aws",
            "ci/cd",
            "observability tool management",
            "docker",
            "kubernetes",
            "identity management platforms",
            "queuing/messaging systems",
            "sql",
            "node.js",
            ".net",
            "json",
            "yaml"
        ]
    },
    "1890b4325d10fef9": {
        "terms": [
            "mlops"
        ],
        "salary_min": 104770.29,
        "salary_max": 132662.53,
        "title": "Mid-Level DevOps & Cloud Engineer",
        "company": "Acumen LLC",
        "desc": "Job description \n ABOUT THE COMPANY \n Direct Care Innovations (DCI) is a Software as a Service (SaaS) provider offering a state-of-the-art business management platform designed uniquely for Medicaid service providers. Our software gives providers the power of their data through automation to reduce overtime, increase utilization, and control their budget. This allows us to achieve our mission of providers being able to put money back in the hands of direct care workers. Among many benefits to working here, we offer medical, dental, and vision coverage, generous paid time off, and incentive bonuses to those who qualify. All of this makes DCI a great and fulfilling place to work. \n ROLE AND ESSENTIAL FUNCTIONS \n The Mid-Level DevOps & Cloud Engineer will be responsible for assisting in the management of the Azure infrastructure platform responsible for hosting solutions such as web API services, mobile applications, web applications, coding programs, and databases while also managing continued support of each resource. You will also assist in the implementation and management of the monitoring of the cloud environment. \n \n Collaborate with our development and operations teams to ensure that our applications are scalable, reliable, and secure \n Contribute to reusable automation scripts, libraries, services, and tools to increase system and process efficiencies \n Utilize Agile principles and practices to drive iterative development, continuous improvement, zero down-time and faster time-to-market \n Help promote DevOps across functional teams and disciplines through collaboration, tooling and best practices \n Manage, develop, and implement solutions to further expand our use of deployment and test automation technology across the organization following business objectives \n Mentor other junior level DevOps engineer, as well as collaborate effectively with other teams and stakeholders \n Strong understanding of implementing and managing disaster recovery within Azure \n Strong knowledge and experience with distributed tracing and Observability with n Azure \n Hands-on and consultative support for customers, including provisioning resources and modifying cloud environments, performing upgrades, addressing day-to-day customer issues, and participating in on-call support after hours \n \n ALL DCI employees will be vigilant to support the positive compliant cybersecurity company posture by familiarizing themselves with all policies, procedures, standards, and guidelines and act accordingly. In addition to the cybersecurity requirements of all positions at DCI, the DevOps team will support the secure design, development, security installation / configuration, and remediation of computer hardware, software, systems, networks, printers, scanners, and cloud properties. Additionally, these positions will support the proper conduct of incidents, responses, and investigations. \n MINIMUM QUALIFICATIONS \n \n Bachelor\u2019s or master\u2019s degree in CS/CE or equivalent \n 2+ years of experience developing enterprise or SaaS software products using .NET or at least 3 or more years of experience in a DevOps Engineering position \n Proficiency in SQL and general database architecture \n Strong proficiency in MS Azure \n Excellent verbal and written communication skills \n Full-stack development preferred with a focus on C# and .NET \n Understanding of static code analysis tools such as SonarQube & SonarCloud \n Extensive knowledge and experience with DevOps practices (continuous integration, continuous delivery, APM and configuration management) \n Identify and solve software and application problems related to performance scalability, and reliability objectives \n Experience researching, designing, and implementing monitoring systems to ensure high availability, performance, and security for applications and infrastructure \n Familiar with implementing zero-downtime deployment strategies using concepts such as blue-green pattern, rollbacks and feature flags \n Experience participating in the design and implementation of Azure disaster recovery solutions and failover procedure \n \n PREFERRED QUALIFICATIONS \n \n Azure certification \n \n Job Type: Full-time \n Benefits: \n \n 401(k) matching \n Dental insurance \n Health insurance \n Vision insurance \n \n Experience level: \n \n 2 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n .Net: 2 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Strong understanding of implementing and managing disaster recovery within Azure \n Strong knowledge and experience with distributed tracing and Observability with n Azure \n Hands-on and consultative support for customers, including provisioning resources and modifying cloud environments, performing upgrades, addressing day-to-day customer issues, and participating in on-call support after hours \n \n ALL DCI employees will be vigilant to support the positive compliant cybersecurity company posture by familiarizing themselves with all policies, procedures, standards, and guidelines and act accordingly. In addition to the cybersecurity requirements of all positions at DCI, the DevOps team will support the secure design, development, security installation / configuration, and remediation of computer hardware, software, systems, networks, printers, scanners, and cloud properties. Additionally, these positions will support the proper conduct of incidents, responses, and investigations. \n MINIMUM QUALIFICATIONS \n \n Bachelor\u2019s or master\u2019s degree in CS/CE or equivalent \n 2+ years of experience developing enterprise or SaaS software products using .NET or at least 3 or more years of experience in a DevOps Engineering position \n Proficiency in SQL and general database architecture \n Strong proficiency in MS Azure \n Excellent verbal and written communication skills   Full-stack development preferred with a focus on C# and .NET \n Understanding of static code analysis tools such as SonarQube & SonarCloud \n Extensive knowledge and experience with DevOps practices (continuous integration, continuous delivery, APM and configuration management) \n Identify and solve software and application problems related to performance scalability, and reliability objectives \n Experience researching, designing, and implementing monitoring systems to ensure high availability, performance, and security for applications and infrastructure \n Familiar with implementing zero-downtime deployment strategies using concepts such as blue-green pattern, rollbacks and feature flags \n Experience participating in the design and implementation of Azure disaster recovery solutions and failover procedure \n \n PREFERRED QUALIFICATIONS \n \n Azure certification \n ",
        "techs": [
            "azure",
            "distributed tracing",
            "observability",
            "provisioning resources",
            "modifying cloud environments",
            "upgrades",
            "on-call support",
            "cybersecurity",
            "secure design",
            "development",
            "security installation",
            "computer hardware",
            "software",
            "systems",
            "networks",
            "printers",
            "scanners",
            "cloud properties",
            "incidents",
            "responses",
            "investigations",
            "cs/ce",
            ".net",
            "sql",
            "ms azure",
            "c#",
            "sonarqube",
            "sonarcloud",
            "devops practices",
            "continuous integration",
            "continuous delivery",
            "apm",
            "configuration management",
            "performance scalability",
            "reliability objectives",
            "monitoring systems",
            "zero-downtime deployment strategies",
            "blue-green pattern",
            "rollbacks",
            "feature flags",
            "azure disaster recovery solutions",
            "failover procedure",
            "azure certification"
        ],
        "cleaned_techs": [
            "azure",
            "distributed tracing",
            "observability",
            "provisioning resources",
            "modifying cloud environments",
            "upgrades",
            "on-call support",
            "cybersecurity",
            "secure design",
            "development",
            "computer hardware",
            "software",
            "systems",
            "networks",
            "printers",
            "scanners",
            "cloud properties",
            "incidents",
            "responses",
            "investigations",
            "cs/ce",
            ".net",
            "sql",
            "ms azure",
            "c#",
            "sonarqube",
            "sonarcloud",
            "devops practices",
            "continuous integration",
            "continuous delivery",
            "apm",
            "configuration management",
            "performance scalability",
            "reliability objectives",
            "monitoring systems",
            "zero-downtime deployment strategies",
            "blue-green pattern",
            "rollbacks",
            "feature flags",
            "failover procedure"
        ]
    },
    "fecc693e6ee43bf2": {
        "terms": [
            "mlops"
        ],
        "salary_min": 122018.0,
        "salary_max": 140250.0,
        "title": "Senior DevOps Engineer",
        "company": "Wisk Aero",
        "desc": "REMOTE UNITED STATES / \n \n \n DEPARTMENTS \u2013 SOFTWARE CERTIFICATION / \n \n \n FULL TIME \n \n \n / HYBRID \n \n \n   \n \n \n \n \n \n  At Wisk, we're transforming the future of urban mobility through safe, all-electric, autonomous flight. We are a passionate team working together toward a sustainable future, solving high-impact problems that have never been solved before. By delivering everyday flight for everyone, we're making it possible to spend less time getting there and more time being there. If you want to be part of shaping the future of mobility, then read on! \n \n \n \n  We are looking for a Senior DevOps Engineer to join our DevOps team. The goal of a DevOps Engineer at Wisk is to ensure that the software team has the tools and resources they need to define/build software infrastructure, and efficiently develop, deploy and test our software products.\n    \n \n \n \n  Why we need you: \n \n \n  The DevOps Engineer is responsible for analyzing needs for custom or off-the-shelf tools to support all aspects of the product development process, designing and implementing the systems and associated automation to meet those needs and working with all teams within the company to leverage available tools and systems for maximum development efficiency. You will help to apply processes and best practices of GitOps to automate infrastructure in cloud platforms. \n \n \n \n \n \n \n  What you will do: \n \n \n  Develop tools and identify opportunities to improve the efficiency of embedded and Web application software development and verification through Gitlab automation \n  Support software development operations by maintaining and improving continuous integration, automated test and deployment systems in cloud-based development environments \n  Understand and apply DO-330 considerations to automation tools intended to aid in the software certification process \n  Closely collaborate with various software teams to understand their unique needs and procedures, recommend solutions and enable self-sufficiency. \n \n \n \n \n \n \n  What you have done: \n \n \n  BS or MS in CS or EE or equivalent with 5 years of prior experience in DevOps or tools development roles \n  Proficiency in at least one scripting language (Python, BASH, Javascript) \n  Familiar with highly automated software development processes and modern tools (git, Bitbucket/GitLab/GitHub, JIRA, Jenkins/Bamboo, etc.) \n  Interest in working with a variety of tools and technologies to solve the problems at hand \n  Experienced with configuration management, GitOps, and IaC tools (Puppet, Chef, Ansible, Terraform) \n  Proficiency in containerization and cloud infrastructure (Docker, Kubernetes, AWS/GCP) \n  Comfortable with Linux command line and Bash/Shell scripting \n \n \n \n \n \n \n  Desired: \n \n \n  Passionate about aviation and the future of transportation \n  Prior experience with software build systems (Bazel, Make, Scons) \n  Proficiency in C/C++, Go or other modern object oriented programming language \n  Previous projects developed in C/C++ \n  Understanding of source code statement coverage and static analysis tools \n  Full stack development experience (SPAs, Javascript, HTML/CSS, etc.) \n  Experience with certified, safety-critical software (e.g. DO-178B/C, ISO-26262 or equivalent) \n  Familiar with model-based design (MBD) using tools like Matlab and Simulink \n \n \n \n \n \n \n  Who you are: \n \n \n  You are a highly motivated, self starting individual with a broad set of skills and never afraid of facing complex technical challenges \n  You are a solution oriented individual with a strong analytical mindset \n  You have strong communication skills and can easily tailor your communications to suit the audience \n  You can adapt quickly or propose changes needed to achieve early results in a timely fashion \n  You embrace challenges and take commitments and deliver results within reasonable expectations \n  You are a positive team player \n \n \n \n \n \n \n     $122,018 - $140,250 a year\n    \n \n  Compensation and Benefits: \n \n \n     In addition to offering a great work environment and the opportunity to be part of the team making electric autonomous flight a reality, at Wisk, we offer excellent total rewards which include a competitive base salary, annual bonus, long term incentive, 401K, health benefits and much more.\n    \n \n \n  Job Type: Full-time\n    \n \n     Pay Range the Company expects to pay:\n       $122,018 - $140,250\n       per year - The starting base salary within this range for this role varies based on factors such as your geographical location, and your relevant job-related experience that is consistent with a business necessity.\n    \n \n \n \n     We are located in Mountain View just a couple of hundred feet from Shoreline Lake and its surrounding walking/jogging trails. We offer a comprehensive benefits package including medical, dental, vision and life insurance, alternative work schedule (9/80), flexible time off, 11 company holidays, a 401(k) plan with 50% company matching vested immediately, communication allowance, and education assistance. And on top of all that, we also offer a variety of perks such as flight lessons, wellness allowances, employee referral bonus, charitable giving match, and much more.\n    \n \n \n  Wisk Aero provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Wisk Aero abides by applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.\n    \n \n \n  Wisk Aero is an E-Verify employer.",
        "cleaned_desc": " \n \n  Why we need you: \n \n \n  The DevOps Engineer is responsible for analyzing needs for custom or off-the-shelf tools to support all aspects of the product development process, designing and implementing the systems and associated automation to meet those needs and working with all teams within the company to leverage available tools and systems for maximum development efficiency. You will help to apply processes and best practices of GitOps to automate infrastructure in cloud platforms. \n \n \n \n \n \n \n  What you will do: \n \n \n  Develop tools and identify opportunities to improve the efficiency of embedded and Web application software development and verification through Gitlab automation \n  Support software development operations by maintaining and improving continuous integration, automated test and deployment systems in cloud-based development environments \n  Understand and apply DO-330 considerations to automation tools intended to aid in the software certification process \n  Closely collaborate with various software teams to understand their unique needs and procedures, recommend solutions and enable self-sufficiency. \n \n \n \n \n \n    What you have done: \n \n \n  BS or MS in CS or EE or equivalent with 5 years of prior experience in DevOps or tools development roles \n  Proficiency in at least one scripting language (Python, BASH, Javascript) \n  Familiar with highly automated software development processes and modern tools (git, Bitbucket/GitLab/GitHub, JIRA, Jenkins/Bamboo, etc.) \n  Interest in working with a variety of tools and technologies to solve the problems at hand \n  Experienced with configuration management, GitOps, and IaC tools (Puppet, Chef, Ansible, Terraform) \n  Proficiency in containerization and cloud infrastructure (Docker, Kubernetes, AWS/GCP) \n  Comfortable with Linux command line and Bash/Shell scripting \n \n \n \n \n \n \n  Desired: \n \n \n  Passionate about aviation and the future of transportation \n  Prior experience with software build systems (Bazel, Make, Scons) \n  Proficiency in C/C++, Go or other modern object oriented programming language \n  Previous projects developed in C/C++ \n  Understanding of source code statement coverage and static analysis tools \n  Full stack development experience (SPAs, Javascript, HTML/CSS, etc.) ",
        "techs": [
            "gitlab",
            "git",
            "bitbucket",
            "gitlab",
            "github",
            "jira",
            "jenkins",
            "bamboo",
            "python",
            "bash",
            "javascript",
            "puppet",
            "chef",
            "ansible",
            "terraform",
            "docker",
            "kubernetes",
            "aws",
            "gcp",
            "linux",
            "bash",
            "shell script",
            "bazel",
            "make",
            "scons",
            "c",
            "c++",
            "go",
            "spas",
            "html/css"
        ],
        "cleaned_techs": [
            "gitlab",
            "git",
            "bitbucket",
            "github",
            "jira",
            "jenkins",
            "bamboo",
            "python",
            "bash",
            "javascript",
            "puppet",
            "chef",
            "ansible",
            "terraform",
            "docker",
            "kubernetes",
            "aws",
            "gcp",
            "linux",
            "shell script",
            "bazel",
            "make",
            "scons",
            "c",
            "c++",
            "go",
            "spas",
            "html/css"
        ]
    },
    "e5c370b43b2f44c9": {
        "terms": [
            "mlops"
        ],
        "salary_min": 55.0,
        "salary_max": 65.0,
        "title": "Remote DevOps Engineer (Mid-Level) - Temp-To-Hire",
        "company": "Gallagher",
        "desc": "About Us: \n  \n   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 45,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.\n  \n \n \n \n \n  As a member of our benefits and HR consulting team, you\u2019ll help our clients - employers of all sizes, across all industries - build workplaces that work better. \n  Overview: \n  \n   The Senior DevOps Engineer is responsible for the:\n  \n \n  Working with application developers to automate and accelerate application testing \n  Managing application deployment/releases to SDLC environments quickly and reliably \n  Ensuring that Gallagher\u2019s data is protected in accordance with IT Policy and organizational priorities \n  Ensuring that the standardized application development process, guidelines, and best practices are observed consistently \n  Coordinating infrastructure requests - requesting servers and cloud services (Paas and IaaS) and keeping track of all assets in GAGS (GBS Application Governance System). \n  Coordinating software license renewals \n \n \n   Please note additional position details below:\n  \n \n  This is a Temp-To-Hire, W-2 position. We are not able to do 1099 or C2C. \n  The salary for the position is $55 - 65/hr. \n  It is a fully remote role that will need to be based in the U.S. or Canada. \n  You must meet our U.S. Eligibility requirements for work authorization as noted under \"Additional Information\" at the bottom of the job description. \n  Responsibilities: \n  \n Oversee the adoption of SDLC \n  Oversee the implementation of quality gates \n  Enforce a consistent development environment across the team, e.g., same Visual IDE version and settings \n  Maintain and enforce standard code analysis rule sets (Minimum Recommended Rule Set and Security Rule Set) \n \n \n  Implement and oversee implementation of SAST and DAST \n  Implement and enforce unit testing \n  Implement and enforce code review (SonarCloud) to ensure maintainability (code smells are minimized), reliability (bugs are fixed), and security (vulnerabilities are remediated) \n  Analyze current technology utilized within the organization and develop steps and processes to improve and expand upon them \n  Ensure that the standard application development (Scrum) process is implemented and consistently followed by all development team \n \n \n  Establish milestones for scrum implementation and adoption by development teams \n  Provide training and guidance on the scrum process to development teams \n  Generate analytics from DevOps on error rate/trend, work item quality, productivity to measure adoption and drive improvement \n  Provide clear goals for all areas of a project and develop steps to oversee their timely execution \n  Work closely with the infrastructure teams to provision hardware and software needed for projects \n \n \n  Work alongside the project management teams to successfully monitor progress and implementation of initiatives \n  Qualifications: \n  \n  Qualifications \n \n \n  Bachelor's or master's degree in computer science or comparable experience \n  2+ years on DevOps \n  1+ Azure DevOps \n \n \n  2+ years of C# programming experience \n  Strong experience source code branching strategy \n  Strong experience in software development \n  Strong experience in the SDLC processes and best practices \n  Experience in Agile or Scrum software development methodology \n \n \n  Strong experience in CI/CD \n  Experience in Visual Studio \n  Strong experience with SQL Server database \n  Knowledge of application architecture and design patterns \n  Experience in Azure Cloud Services (Azure SQL, App Services, ADFS, etc.) \n \n \n  Experience in APM system (App Insight) \n  Experience in code reviews (manual and automated) \n  Strong experience in configuring Azure DevOps \n \n \n \n  Interpersonal Skills \n : \n \n \n \n \n  Must be self-motivated and goal oriented \n  Attention to detail and proven ability to follow through \n  Strong analytical, organizational, and problem-solving capabilities \n  Ability to work on multiple projects and priorities concurrently \n \n \n  Requires minimal supervision and motivation \n  Ability to work collaboratively on team-based projects \n  Proven relationship building skills and high energy level \n  Excellent oral and written communication skills \n  Additional Information: \n  \n   Click Here to review our U.S. Eligibility Requirements\n  \n \n \n  We offer competitive salaries and benefits, including: medical/dental/vision plans, life and accident insurance, 401(K), employee stock purchase plan, educational expense reimbursement, employee assistance program, flexible work hours (availability varies by office and job function), training programs, matching gift program, and more.",
        "cleaned_desc": " \n \n  2+ years of C# programming experience \n  Strong experience source code branching strategy \n  Strong experience in software development \n  Strong experience in the SDLC processes and best practices \n  Experience in Agile or Scrum software development methodology \n \n \n  Strong experience in CI/CD \n  Experience in Visual Studio \n  Strong experience with SQL Server database \n  Knowledge of application architecture and design patterns \n  Experience in Azure Cloud Services (Azure SQL, App Services, ADFS, etc.) \n \n \n  Experience in APM system (App Insight) \n  Experience in code reviews (manual and automated) \n  Strong experience in configuring Azure DevOps \n   \n \n  Interpersonal Skills \n : \n \n \n \n \n  Must be self-motivated and goal oriented \n  Attention to detail and proven ability to follow through \n  Strong analytical, organizational, and problem-solving capabilities \n  Ability to work on multiple projects and priorities concurrently \n \n \n  Requires minimal supervision and motivation \n  Ability to work collaboratively on team-based projects \n  Proven relationship building skills and high energy level \n  Excellent oral and written communication skills \n  Additional Information: \n  ",
        "techs": [
            "c#",
            "source code branching strategy",
            "software development",
            "sdlc processes",
            "agile",
            "scrum",
            "ci/cd",
            "visual studio",
            "sql server database",
            "application architecture",
            "design patterns",
            "azure cloud services",
            "azure sql",
            "app services",
            "adfs",
            "apm system",
            "app insight",
            "code reviews",
            "azure devops",
            "interpersonal skills",
            "self-motivated",
            "goal oriented",
            "attention to detail",
            "analytical skills",
            "organizational skills",
            "problem-solving capabilities",
            "ability to work on multiple projects",
            "minimal supervision",
            "motivation",
            "collaboration",
            "relationship building skills",
            "oral communication skills",
            "written communication skills."
        ],
        "cleaned_techs": [
            "c#",
            "source code branching strategy",
            "software development",
            "sdlc processes",
            "agile",
            "scrum",
            "ci/cd",
            "visual studio",
            "sql",
            "application architecture",
            "design patterns",
            "azure",
            "app services",
            "adfs",
            "apm system",
            "app insight",
            "code reviews",
            "self-motivated",
            "goal oriented",
            "attention to detail",
            "problem-solving capabilities",
            "minimal supervision",
            "motivation",
            "collaboration"
        ]
    },
    "979b9c303f42eb60": {
        "terms": [
            "mlops"
        ],
        "salary_min": 123782.4,
        "salary_max": 156736.1,
        "title": "DevOps Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid Role \n  Looking for a DevOps Engineer with prior experience with Big Data Solutions, Cloud technology, and strong working knowledge of Linux. Passionate about the concept of infrastructure as code and leverages modern tools to define, build and manage virtual infrastructure in the cloud. Work is performed in a hybrid environment with a great team. \n \n  Essential Job Responsibilities \n  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications \n  Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills. \n  Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. \n  Prior experience or familiarity with Unified Platform (UP) Big Data Platform (formerly owned by DISA) is a plus. \n  Data parsing/transforming techniques to include JSON, XML, CSV formats. \n  Understanding of AGILE software development methodologies and use of standard software development tool suites. (e.g., JIRA, Confluence, Github Enterprise, etc.) \n  Willing to do on-call/pager duty is a big plus. Possible rotating shift in the future for this role as the current team is full. \n   \n LmlzvuPqEm",
        "cleaned_desc": "  The ideal candidate believes in exploring alternatives and quickly prototyping to validate hypothetical architectures or solutions.  \n Will significantly contribute to the development of custom software components and integration of open source code to address complex time series analysis problems through the use of cutting edge Big Data/ Cloud technology. Design, implement, and maintain core architecture and capabilities for software from prototype to operational applications.  \n Must understand software engineering fundamentals, OO programming, relational and time series databases, scripting knowledge and a basic level of development operations (DevOps) skill set.  \n Minimum Qualifications    Security Clearance - A current Secret is required and therefore all candidates must be a U.S. citizen.  \n 5+ years of experience in DevOps Engineering or Software Development (Java preferred) and Bachelors in related field; or 3 years relevant experience with Masters in related field; or High School Diploma or equivalent and 9 years relevant experience. \n  Have a strong working knowledge of Linux systems, hosts, storage, networks, security, applications and proficiency in shell scripting (Shell/Bash, JavaScript, Python). \n  Excellent oral and written communication skills.    Must have a Security+ certification.  \n Must be able to work in a hybrid environment. \n  Preferred Requirements \n  Must have experience with big data technologies such as Hadoop and NoSQL Databases. Experience with AWS is highly desired. ",
        "techs": [
            "devops engineering",
            "software development",
            "java",
            "linux systems",
            "shell scripting",
            "shell/bash",
            "javascript",
            "python",
            "security+",
            "hadoop",
            "nosql databases",
            "aws"
        ],
        "cleaned_techs": [
            "devops engineering",
            "software development",
            "java",
            "linux systems",
            "shell scripting",
            "shell/bash",
            "javascript",
            "python",
            "hadoop",
            "nosql",
            "aws"
        ]
    },
    "d979d4003be2195e": {
        "terms": [
            "mlops"
        ],
        "salary_min": 65.0,
        "salary_max": 70.0,
        "title": "DevOps with Automation",
        "company": "Cloud Destinations",
        "desc": "My name is Muralidharan and I\u2019m working with Cloud Destinations LLC as a Technical Recruiter. \n Below are the job details as needed by the hiring manager. Kindly advise if you might be interested and qualified for the below opportunity and if we can discuss further on this \n Position: DevOps with Automation Duration: 6 months+ Contract Location: Remote - PST Hours \n Working times:  Candidates should be prepared to work mostly PST hours but candidates also need to own their tasks and sometimes that might mean working extra to meet an important deadline. \n Description: Client is looking for GoLang/Python Kubernetes developer that will be responsible for designing, implementing, and maintaining the Kubernetes infrastructure for a major client platform, with a focus on using GitLab CI/CD and supporting and enhancing applications developed in Golang, as well as developing automation scripts using tools such as Python and Terraform. The ideal candidate will have experience deploying large scale on-prem Kubernetes cluster solutions which have fixed physical storage limitations. \n How you'll make your mark:  \n You will write code that is maintainable, well documented, extensible and scalable You will write detailed design documents You must be proactive and aggressive in finding solutions to potential blockers. You will work closely with our Architects, Engineers, Product Managers and other clients and partners of our team to meet the needs of the organization to stay competitive - from the infrastructure up to the highest level of applications You will build CI/CD solutions to improve developer productivity and rapid deployments. You will refine/improve security, resiliency and performance. \n About you:  \n You have 6+ years of experience in DevOps Expert experience with Kubernetes, Jenkins, Spinnaker and Terraform Expert experience developing automation using GoLang and Python You have 6+ years of recent development expertise with Python, shell scripting, and databases in a production, customer-facing context You are proficient with configuration management technologies like ansible, chef, puppet, and salt You have a BS/MS degree in Computer Science, Engineering or related discipline \n Job Type: Contract \n Salary: $65.00 - $70.00 per hour \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Are you a United States citizen or Permanent Resident? \n \n Experience: \n \n Go: 4 years (Required) \n DevOps: 10 years (Required) \n Kubernetes: 4 years (Required) \n Python: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "784d6c607d83b9aa": {
        "terms": [
            "mlops"
        ],
        "salary_min": 70.0,
        "salary_max": 80.0,
        "title": "Azure Architect/ Devops Architect",
        "company": "Interaslabs",
        "desc": "Role: Azure Architect 12 months Remote Required Skill: \n \n Experience in a cloud administration, orchestrator role and understanding of cloud architecture and services in Microsoft Azure. \n Azure Certifications (e.g. AZ-104 Azure Administrator and higher) would be a significant asset \n Knowledge of and experience with \n Azure administration, policy, configuration, solution deployment \n Azure core services and management tools \n Azure general and network security \n Azure identity, governance, privacy, compliance \n Working experience and knowledge in Azure Kubernetes Service (AKS) is a must have \n PowerShell, CLI, Terraform, Ansible and other scripting languages \n Considered a Plus: \n Experience with Azure DevOps, and infrastructure as code CI/CD deployment practices. \n \n Job Type: Contract \n Pay: $70.00 - $80.00 per hour \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Azure: 4 years (Preferred) \n AWS: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Azure general and network security \n Azure identity, governance, privacy, compliance \n Working experience and knowledge in Azure Kubernetes Service (AKS) is a must have \n PowerShell, CLI, Terraform, Ansible and other scripting languages \n Considered a Plus: \n Experience with Azure DevOps, and infrastructure as code CI/CD deployment practices. \n ",
        "techs": [
            "azure general and network security",
            "azure identity",
            "governance",
            "privacy",
            "compliance",
            "azure kubernetes service (aks)",
            "powershell",
            "cli",
            "terraform",
            "ansible",
            "azure devops"
        ],
        "cleaned_techs": [
            "azure",
            "governance",
            "privacy",
            "compliance",
            "powershell",
            "cli",
            "terraform",
            "ansible"
        ]
    },
    "155a1ded44d68b97": {
        "terms": [
            "mlops"
        ],
        "salary_min": 111211.86,
        "salary_max": 140819.0,
        "title": "Senior DevOps Engineer",
        "company": "Luxoft",
        "desc": "Project  Description \n \n At Client, the Wealth Management Planning and Discovery development team is responsible for integrating with and extending a vendor-based financial planning tool. The system will be used by 19,000+ Financial Advisors to help clients in their financial planning needs. The system will also be integrated with various cloud and in-house applications to achieve the best users experience for the end users. \n \n \n \n \n Responsibilities \n \n \n \n       Manage timelines/deliverables within the team towards the successful delivery of projects.\n        \n \n Design software solutions by interacting with portfolio managers, traders, operations staff, and peers to understand requirements. \n Develop solutions that are in line with the client's technology biases, deliver efficiency and scalability, and enable new trading activities. \n Provide knowledge transfer to team members and support staff through application demos, walkthroughs, and documentation. \n Computing Services Platform (on-prem) Major Requirement \n Build automation for the Vmware environment  \n \n \n \n \n \n Skills \n \n Must have \n \n \n Bachelor's degree in Computer Science, Management Information Systems or related field, or relevant experience \n 6 or more years experience in Server, Storage, or other Infrastructure System Administration, with knowledge of both Linux and Windows OS \n Expertise with large and complex Infrastructure Automation initiatives using Ansible, PowerShell, and other common scripting/programming languages (Python, YAML, Bash, PowerCLI) \n Ability to develop complex technical requirements and system designs with an understanding of business and technical implications \n Formal training/Certification in Agile/DevOps practices (SAFe 5 Agile) and a general understanding of Application Development processes \n Excellent communication skills with business partners, vendors, technology peers, and across multiple levels of leadership \n Motivated Self Starter with the ability to work with limited guidance \n Continuous learner with the desire to develop and apply new skills  \n \n \n Nice to have \n \n \n Expertise in Service Now administration and ITOM \n Ability to demonstrate thought leadership and an innovation mindset \n Foundational experience with Cloud Computing/Cloud Server Administration/IaaS (Azure & AWS)  \n \n \n \n \n \n \n Languages \n \n English: C1 Advanced \n \n \n Seniority \n \n Senior \n \n \n Relocation package \n \n If needed, we can help you with relocation process. \n \n \n \n \n Vacancy Specialization  \n \n DevOps \n \n \n Ref Number \n \n VR-101187",
        "cleaned_desc": " Develop solutions that are in line with the client's technology biases, deliver efficiency and scalability, and enable new trading activities. \n Provide knowledge transfer to team members and support staff through application demos, walkthroughs, and documentation. \n Computing Services Platform (on-prem) Major Requirement \n Build automation for the Vmware environment  \n \n \n \n \n \n Skills \n \n Must have \n \n \n Bachelor's degree in Computer Science, Management Information Systems or related field, or relevant experience   6 or more years experience in Server, Storage, or other Infrastructure System Administration, with knowledge of both Linux and Windows OS \n Expertise with large and complex Infrastructure Automation initiatives using Ansible, PowerShell, and other common scripting/programming languages (Python, YAML, Bash, PowerCLI) \n Ability to develop complex technical requirements and system designs with an understanding of business and technical implications \n Formal training/Certification in Agile/DevOps practices (SAFe 5 Agile) and a general understanding of Application Development processes \n Excellent communication skills with business partners, vendors, technology peers, and across multiple levels of leadership \n Motivated Self Starter with the ability to work with limited guidance \n Continuous learner with the desire to develop and apply new skills  \n \n \n Nice to have \n \n \n Expertise in Service Now administration and ITOM \n Ability to demonstrate thought leadership and an innovation mindset \n Foundational experience with Cloud Computing/Cloud Server Administration/IaaS (Azure & AWS)  ",
        "techs": [
            "computing services platform (on-prem)",
            "vmware environment automation",
            "ansible",
            "powershell",
            "python",
            "yaml",
            "bash",
            "powercli",
            "agile/devops practices (safe 5 agile)",
            "application development processes",
            "service now administration",
            "itom",
            "cloud computing/cloud server administration/iaas (azure & aws)"
        ],
        "cleaned_techs": [
            "computing services platform (on-prem)",
            "vmware environment automation",
            "ansible",
            "powershell",
            "python",
            "yaml",
            "bash",
            "powercli",
            "agile/devops practices (safe 5 agile)",
            "application development processes",
            "service now administration",
            "itom",
            "cloud computing/cloud server administration/iaas (azure & aws)"
        ]
    },
    "2d5cc60b0bf34f60": {
        "terms": [
            "mlops"
        ],
        "salary_min": 60.0,
        "salary_max": 60.0,
        "title": "Devops Engineer",
        "company": "BayOne",
        "desc": "Client \n LAM \n \n  Job Title \n Devops Engineer \n \n  Job Type(C/CTH/FTE) \n Contract \n \n  Target Start \n 10/1/2023 \n \n  Reason Open \n New Role \n \n  Exciting/Role/Team \n Large Hight Tech \n \n  Work Hour/Days \n PST, M-F, 40hrs \n \n  Reports to/team size \n 4 \n \n  Bill Rate \n 80 \n \n  Pay Rate \n 60@c2c or 55@w2 \n \n \n Total Cost: \n  62 or 62 \n \n  Margin \n 18 \n \n  Visa Sponsorship \n Any \n \n  Location \n Fremont, CA \n \n  Remote Option \n Yes, support PST \n \n  Open Since \n 9/28 \n \n  Coding/Eng/Skills/Langu \n CI/CD Pipeline Development, Terraform, Ansible, or CloudFormation, GIT, Docker, Kubernetes \n \n  Interview Process \n 2 rounds video technical \n \n  Process Timeline \n 1 week \n \n  Sample/Past Hires \n NA \n \n  Must Have Skills \n CI/CD Pipeline Development, GIT, Docker, Kubernetes \n \n  Preferred Experience \n Terraform, Ansible, or CloudFormation, \n \n  Nice to Have \n latest CI/CD best practices \n \n  Job Description \n \n \n Responsibilities: \n \n CI/CD Pipeline Development:  Design, implement, and maintain robust CI/CD pipelines using Jenkins to automate code deployment, testing, and monitoring across various environments. \n \n \n Scripting Expertise:  Develop and maintain scripts (e.g., Bash, Python, PowerShell) to automate repetitive tasks, streamline operations, and improve efficiency. \n \n \n Release Management:  Coordinate and execute software releases, working closely with development teams to ensure smooth deployments and rollback strategies when necessary. \n \n \n Monitoring and Troubleshooting:  Implement monitoring and alerting solutions to proactively identify and resolve system issues. Troubleshoot technical problems in collaboration with cross-functional teams. \n \n \n Security Best Practices:  Implement security measures and follow best practices to safeguard the infrastructure and applications, ensuring compliance with industry standards. \n \n \n Collaboration:  Collaborate with development, testing, and operations teams to ensure successful integration of new features, bug fixes, and improvements into the CI/CD pipeline. \n \n \n Documentation:  Maintain comprehensive documentation for processes, configurations, and troubleshooting guides to facilitate knowledge sharing and onboarding. \n \n \n Stay Current:  Keep up-to-date with industry trends, emerging technologies, and best practices related to DevOps, CI/CD, and automation. \n \n \n Nice to Have Infrastructure as Code (IaC):  Utilize tools like Terraform, Ansible, or CloudFormation to provision and manage infrastructure, ensuring scalability, security, and reliability. \n \n \n Qualifications: \n  Bachelor's degree in Computer Science, Engineering, or related field (or equivalent experience). \n \n  At least 2 years' experience as a DevOps Engineer or related role. \n \n  Strong proficiency with Jenkins for building and managing CI/CD pipelines. \n \n  Proficiency in scripting languages like Bash, Python, or PowerShell. \n \n  Experience with version control systems (e.g., Git), containerization (e.g., Docker), and orchestration tools (e.g., Kubernetes) is a plus. \n \n  Solid understanding of software development practices and methodologies. \n \n  Strong problem-solving skills and a proactive attitude towards continuous improvement. \n \n  Excellent communication and teamwork skills. \n \n  Jenkins Certified Engineer is advantageous. \n \n  Familiarity with Infrastructure as Code (IaC) tools such as Terraform, Ansible, or CloudFormation.",
        "cleaned_desc": " \n Responsibilities: \n \n CI/CD Pipeline Development:  Design, implement, and maintain robust CI/CD pipelines using Jenkins to automate code deployment, testing, and monitoring across various environments. \n \n \n Scripting Expertise:  Develop and maintain scripts (e.g., Bash, Python, PowerShell) to automate repetitive tasks, streamline operations, and improve efficiency. \n \n \n Release Management:  Coordinate and execute software releases, working closely with development teams to ensure smooth deployments and rollback strategies when necessary. \n \n \n Monitoring and Troubleshooting:  Implement monitoring and alerting solutions to proactively identify and resolve system issues. Troubleshoot technical problems in collaboration with cross-functional teams. \n \n \n Security Best Practices:  Implement security measures and follow best practices to safeguard the infrastructure and applications, ensuring compliance with industry standards. \n \n \n Collaboration:  Collaborate with development, testing, and operations teams to ensure successful integration of new features, bug fixes, and improvements into the CI/CD pipeline. \n \n \n Documentation:  Maintain comprehensive documentation for processes, configurations, and troubleshooting guides to facilitate knowledge sharing and onboarding. \n \n   Stay Current:  Keep up-to-date with industry trends, emerging technologies, and best practices related to DevOps, CI/CD, and automation. \n \n \n Nice to Have Infrastructure as Code (IaC):  Utilize tools like Terraform, Ansible, or CloudFormation to provision and manage infrastructure, ensuring scalability, security, and reliability. \n \n \n Qualifications: \n  Bachelor's degree in Computer Science, Engineering, or related field (or equivalent experience). \n \n  At least 2 years' experience as a DevOps Engineer or related role. \n \n  Strong proficiency with Jenkins for building and managing CI/CD pipelines. \n \n  Proficiency in scripting languages like Bash, Python, or PowerShell. \n \n  Experience with version control systems (e.g., Git), containerization (e.g., Docker), and orchestration tools (e.g., Kubernetes) is a plus. \n \n  Solid understanding of software development practices and methodologies. \n \n  Strong problem-solving skills and a proactive attitude towards continuous improvement. \n \n  Excellent communication and teamwork skills. \n \n  Jenkins Certified Engineer is advantageous. ",
        "techs": [
            "jenkins",
            "bash",
            "python",
            "powershell",
            "terraform",
            "ansible",
            "cloudformation",
            "git",
            "docker",
            "kubernetes"
        ],
        "cleaned_techs": [
            "jenkins",
            "bash",
            "python",
            "powershell",
            "terraform",
            "ansible",
            "cloudformation",
            "git",
            "docker",
            "kubernetes"
        ]
    },
    "390f9810f506c8df": {
        "terms": [
            "mlops"
        ],
        "salary_min": 80.0,
        "salary_max": 80.0,
        "title": "AWS Devops Engineer",
        "company": "BayOne",
        "desc": "We have a Urgent requirement for a Devops engineer with AWS for Disney. \n \n \n Client :  Disney \n \n \n Location :  Ny City (Remote for now) \n \n \n Rate :  $ 80 an hour. \n \n  Below is the details Job Description \n \n  Potential candidate will be providing guidance and managing security permissions for our internal Development teams with a particular focus on AWS Security. \n \n  Should know the software development life cycle, and are familiar with DevOps working practices and tooling (inc. Docker, CI/CD etc.). \n \n  Should be able to improve our own internal Security-management tooling. \n \n  This position will require some familiarity with other DevOps tools such as Terraform, CloudFormation, Jenkins, GitHub, and Puppet. \n \n  Should be able to understand manage, articulate and define code/Repository management and branching strategies \n \n  Working knowledge for code deployment automation using skirting tools like Jenkins \n \n  5+ years' experience in a DevOps role that goes beyond traditional operations to enable building the right frameworks in AWS. \n \n  Should have AWS Security/IAM administration experience, particularly IAM Policies, in support of multiple teams. \n \n  We work with external partners, and with Cloud and Datacenter services, so familiarity with SSL Certificate management, VPC networking, Security Groups/Fire-walling and DNS would be useful. \n \n  Experience with AWS services, such as EC2, ELB, ECS, ACM, CloudFormation, IAM, VPC, Direct Connect / Networking, Data Analytics (Redshift), Kinesis, Lambda and API Gateway. \n \n  Management of continuous integration servers. \n \n  Knowledge of IP networking, VPN's, DNS, load balancing and firewalling. \n \n  Should have experience building and automating CICD pipelines, hands-on experience with AWS, and sufficient knowledge of Docker. The candidate should also have strong knowledge in spinning up containers and a broad knowledge of logging and monitoring concepts. \n \n  Should be able write/automate files to run arbitrary Groovy scripts within the Jenkins master runtime or in the runtime on agents. \n \n  Coding ability ( JavaScript, Python, Node.js, Go, Ruby, groovy or other modern server-side languages) \n \n  Should have experience working on hybrid Cloud- and On-prem based workload transformation projects \n \n  Should have deep, specialized domain knowledge and expertise (for example: nosql data storage design and utilization, asynchronous programming, effective caching / expiry design, etc. ). \n \n \n Preferred Qualifications: \n  You have had to work in teams within regulated environments such as PCI or HIPAA \n \n  Previous Systems Administration (Linux/Unix) experience \n \n  General AWS Support experience",
        "cleaned_desc": " \n  Should be able to understand manage, articulate and define code/Repository management and branching strategies \n \n  Working knowledge for code deployment automation using skirting tools like Jenkins \n \n  5+ years' experience in a DevOps role that goes beyond traditional operations to enable building the right frameworks in AWS. \n \n  Should have AWS Security/IAM administration experience, particularly IAM Policies, in support of multiple teams. \n \n  We work with external partners, and with Cloud and Datacenter services, so familiarity with SSL Certificate management, VPC networking, Security Groups/Fire-walling and DNS would be useful.   \n  Experience with AWS services, such as EC2, ELB, ECS, ACM, CloudFormation, IAM, VPC, Direct Connect / Networking, Data Analytics (Redshift), Kinesis, Lambda and API Gateway. \n \n  Management of continuous integration servers. \n \n  Knowledge of IP networking, VPN's, DNS, load balancing and firewalling. \n \n  Should have experience building and automating CICD pipelines, hands-on experience with AWS, and sufficient knowledge of Docker. The candidate should also have strong knowledge in spinning up containers and a broad knowledge of logging and monitoring concepts. \n \n  Should be able write/automate files to run arbitrary Groovy scripts within the Jenkins master runtime or in the runtime on agents.   \n  Coding ability ( JavaScript, Python, Node.js, Go, Ruby, groovy or other modern server-side languages) \n \n  Should have experience working on hybrid Cloud- and On-prem based workload transformation projects \n \n  Should have deep, specialized domain knowledge and expertise (for example: nosql data storage design and utilization, asynchronous programming, effective caching / expiry design, etc. ). \n \n \n Preferred Qualifications: \n  You have had to work in teams within regulated environments such as PCI or HIPAA ",
        "techs": [
            "jenkins",
            "aws",
            "iam policies",
            "ssl certificate management",
            "vpc networking",
            "security groups",
            "dns",
            "ec2",
            "elb",
            "ecs",
            "acm",
            "cloudformation",
            "iam",
            "vpc",
            "direct connect",
            "data analytics (redshift)",
            "kinesis",
            "lambda",
            "api gateway",
            "continuous integration servers",
            "ip networking",
            "vpns",
            "load balancing",
            "firewalling",
            "cicd pipelines",
            "docker",
            "groovy scripts",
            "javascript",
            "python",
            "node.js",
            "go",
            "ruby",
            "hybrid cloud",
            "on-prem workload transformation",
            "nosql data storage design",
            "asynchronous programming",
            "effective caching",
            "pci",
            "hipaa"
        ],
        "cleaned_techs": [
            "jenkins",
            "aws",
            "iam policies",
            "ssl certificate management",
            "vpc networking",
            "dns",
            "ec2",
            "elb",
            "ecs",
            "acm",
            "cloudformation",
            "iam",
            "vpc",
            "direct connect",
            "data analytics (redshift)",
            "kinesis",
            "lambda",
            "api gateway",
            "continuous integration servers",
            "ip networking",
            "vpns",
            "load balancing",
            "firewalling",
            "cicd pipelines",
            "docker",
            "groovy scripts",
            "javascript",
            "python",
            "node.js",
            "go",
            "ruby",
            "hybrid cloud",
            "on-prem workload transformation",
            "nosql",
            "asynchronous programming",
            "effective caching",
            "pci",
            "hipaa"
        ]
    },
    "b996186622455577": {
        "terms": [
            "mlops"
        ],
        "salary_min": 130000.0,
        "salary_max": 150000.0,
        "title": "DevOps/Azure Engineer",
        "company": "IStream Solutions",
        "desc": "Job Descriptions: \n \n \u200bScope, design, and build scalable, resilient distributed systems. \n \u200bBuild product definition and leverage your technical skills to drive towards the right solution \n Engage in cross-functional collaboration throughout the entire software lifecycle \n \u200bLead in design sessions and code reviews with peers to elevate the quality of engineering across the organization \n \u200bDefine, create, and support reusable application components/patterns from a business and technology perspective \n Utilize programming languages like Python, C# or other object-oriented languages, SQL, and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of Azure tools and services \n \u200bUtilizes developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) to perform advanced-level Mobile/Web/UI design, implementation, and maintenance activities under minimal direction \n Support triage calls at a tier 2 level with good technical problem solving, analytical skills, and logical thinking to provide resolutions to a diverse range of complex issues \n Provide 24/7 operations support for production, other critical environments, DevOps multi-tasking and with clear communication skills. \n Collaborate, support, and work with managed cloud vendor \n Establish and employ continuous integration practices and tools \n Build resilient services for extending and improving DevOps capabilities \n \n Qualifications \n \n \u200b\u200b\u200bAdvanced programming experience within Wiki (Atlassian), CI/CD Pipeline, Azure Just-in-Time, VM Access, Azure Cloud Services, Azure Active Directory, Azure Automation Accounts \n Advanced understanding of DevOps concepts including Azure DevOps framework and tools \n Experience and knowledge with Enterprise Cloud platforms, enterprise data center technologies including storage platforms, networks, security infrastructure \n Advanced PowerShell scripting skills \n Advanced understanding of monitoring concepts and tooling Experience with continuous delivery and infrastructure as code \n Knowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) \n Experience in security protocols and products: Understanding of Active Directory, Windows Authentication, SAML, OAuth \n Experience working as an Infrastructure, Middleware, DevOps engineer on Linux, Windows Operating Systems \n Experience with installation, configuration, administration of Web Servers, and Application Servers (Apache, JBoss EAP, Tomcat, IIS, Dot-Net, WebSphere) \n Experience on configuration and administration on messaging systems such as IBM MQ, and ActiveMQ \n Knowledge on DNS resolution, subnet masking, firewall concepts, and processes \n Knowledge of MuleSoft 4.x Platform Administration \n Ability to deploy application manually, change policies, enable application authentication through OAuth \n Experience managing user Access, Service management on Linux VM, upgrade patches, and change configuration are preferred \n Ability to understand System design from architecture topology diagrams \n Knowledge of on CI/CD pipelines to streamline software development and deployment \n Experience with software tools such as Microsoft ADO, SharePoint, PowerBI, Helix, Confluence or similar \n \n Education \n \n Bachelor\u2019s degree in Computer Science, Information Systems, or equivalent education or work experience \n \n Job Type: Full-time \n Pay: $130,000.00 - $150,000.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "Job Descriptions: \n \n \u200bScope, design, and build scalable, resilient distributed systems. \n \u200bBuild product definition and leverage your technical skills to drive towards the right solution \n Engage in cross-functional collaboration throughout the entire software lifecycle \n \u200bLead in design sessions and code reviews with peers to elevate the quality of engineering across the organization \n \u200bDefine, create, and support reusable application components/patterns from a business and technology perspective \n Utilize programming languages like Python, C# or other object-oriented languages, SQL, and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of Azure tools and services \n \u200bUtilizes developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) to perform advanced-level Mobile/Web/UI design, implementation, and maintenance activities under minimal direction \n Support triage calls at a tier 2 level with good technical problem solving, analytical skills, and logical thinking to provide resolutions to a diverse range of complex issues   Provide 24/7 operations support for production, other critical environments, DevOps multi-tasking and with clear communication skills. \n Collaborate, support, and work with managed cloud vendor \n Establish and employ continuous integration practices and tools \n Build resilient services for extending and improving DevOps capabilities \n \n Qualifications \n \n \u200b\u200b\u200bAdvanced programming experience within Wiki (Atlassian), CI/CD Pipeline, Azure Just-in-Time, VM Access, Azure Cloud Services, Azure Active Directory, Azure Automation Accounts \n Advanced understanding of DevOps concepts including Azure DevOps framework and tools \n Experience and knowledge with Enterprise Cloud platforms, enterprise data center technologies including storage platforms, networks, security infrastructure   Advanced PowerShell scripting skills \n Advanced understanding of monitoring concepts and tooling Experience with continuous delivery and infrastructure as code \n Knowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) \n Experience in security protocols and products: Understanding of Active Directory, Windows Authentication, SAML, OAuth \n Experience working as an Infrastructure, Middleware, DevOps engineer on Linux, Windows Operating Systems \n Experience with installation, configuration, administration of Web Servers, and Application Servers (Apache, JBoss EAP, Tomcat, IIS, Dot-Net, WebSphere) \n Experience on configuration and administration on messaging systems such as IBM MQ, and ActiveMQ \n Knowledge on DNS resolution, subnet masking, firewall concepts, and processes \n Knowledge of MuleSoft 4.x Platform Administration \n Ability to deploy application manually, change policies, enable application authentication through OAuth ",
        "techs": [
            "python",
            "c#",
            "sql",
            "nosql databases",
            "docker",
            "kubernetes",
            "azure tools and services",
            "wiki (atlassian)",
            "ci/cd pipeline",
            "azure just-in-time",
            "vm access",
            "azure cloud services",
            "azure active directory",
            "azure automation accounts",
            "powershell scripting",
            "monitoring tools",
            "active directory",
            "windows authentication",
            "saml",
            "oauth",
            "linux",
            "windows operating systems",
            "web servers (apache",
            "jboss eap",
            "tomcat",
            "iis",
            "dot-net",
            "websphere)",
            "messaging systems (ibm mq",
            "activemq)",
            "dns resolution",
            "subnet masking",
            "mulesoft 4.x platform administration"
        ],
        "cleaned_techs": [
            "python",
            "c#",
            "sql",
            "nosql",
            "docker",
            "kubernetes",
            "azure",
            "wiki (atlassian)",
            "ci/cd pipeline",
            "vm access",
            "powershell scripting",
            "monitoring tools",
            "active directory",
            "windows authentication",
            "saml",
            "oauth",
            "linux",
            "windows operating systems",
            "web servers (apache",
            "jboss eap",
            "tomcat",
            "iis",
            "dot-net",
            "websphere)",
            "messaging systems (ibm mq",
            "activemq)",
            "dns resolution",
            "subnet masking",
            "mulesoft 4.x platform administration"
        ]
    },
    "a278a575ffc70cf9": {
        "terms": [
            "mlops"
        ],
        "salary_min": 119419.484,
        "salary_max": 151211.67,
        "title": "DevOps Engineering Manager",
        "company": "Kin Insurance",
        "desc": "The world has changed. Why hasn't insurance? \n  Kin's mission is to reimagine home insurance  For Every New Normal.  While other insurers struggle to handle a fast-changing world, Kin is built for the future and is prepared to meet its challenges head on while helping our customers do the same. \n  Kin is proud to be one of BuiltIn Chicago's 2021 and 2022 Best Mid Sized Companies to work for, and Forbes 2021 Best Startup Employers in North America. Simply put, our people are what make us great, and we need forward-thinking, inspired game-changers like you to join us in our mission. \n \n  So, what's the role? \n  Kin is searching for an experienced, highly collaborative DevOps Engineering Manager with the skills and leadership to tackle new challenges and drive continuous improvement of our infrastructure, pipelines, and practices. \n  The DevOps Engineering Manager is responsible for steering our remote-first DevOps team and ensuring Kin's infrastructure is well-architected, highly observable, and cost-optimized. \n  This position requires the right mix of relevant experience and roll up your sleeves attitude, balancing tactics and strategy, outstanding verbal and written communication skills, action-oriented mindset, and the positivity and flexibility to help the DevOps team grow and thrive in a fast-paced environment. \n  A day in the life could include: \n \n Providing people and technical leadership for the DevOps team \n Engaging other teams to foster a culture of collaboration, innovation, and continuous improvement \n Guiding creation of innovative tooling and automations to enable engineering efficiencies \n Championing FinOps practices to accelerate cost transparency and optimization \n Building and maintaining CI/CD pipelines that enable rapid and reliable software releases \n Facilitating operational and tech ecosystem observability \n Partnering with teams across the org to test and improve Business Continuity/Disaster Recovery plans \n Developing and driving DevOps strategy that aligns with Kin's short and long term objectives \n Managing team talent, including hiring, skill development, and performance evaluations \n \n I've got the skills\u2026 but do I have the necessary ones? \n \n Advanced experience in engineering and operations roles, preferably in technical operations or similar infrastructure positions \n Leading operations-centric, strategic, and highly collaborative engineering teams \n Implementation and support of high-availability AWS infrastructure \n Managing technical operations with a service mindset and proactive stakeholder engagement \n CI/CD and Infrastructure as Code pipelines \n Implementing measures for optimal cloud cost management and oversight \n Comfortable navigating ambiguity and taking proactive ownership \n Strong organizational skills, and ability to adapt quickly to changing priorities, assignments, and roles \n Verbal, written, and presentation skills, communicating technical and business issues to multiple audiences \n Supporting work transparency and Agile practices \n \n Oh, and don't worry, we've got you covered! \n \n Medical, Dental, Vision, Disability and Life Insurance \n Flexible PTO policy \n Remote work \n Generous equity package \n 401K with company match \n Parental leave \n Continuing education and professional development \n The excitement of joining a high-growth Insurtech company and seeing your work make an impact \n \n \n About Kin \n  In an industry that hasn't budged in more than 100 years, our technology transforms the user experience, cuts inefficiencies that waste billions of consumer dollars, and customizes coverage homeowners want. We believe insurance was always meant to be a digital product \u2013 we're making that a reality. \n  Our approach to the industry makes us unique, and the people at Kin help us excel. We're a team of problem solvers, collaborators, builders, and dreamers who are passionate about creating positive change in the lives of our customers and in our industry. Kin is more than just our name \u2013 it's how we treat each other. That's one of the many reasons we've been recognized as a great place to work by Built In, Forbes, and Fast Company. \n \n \n  EEOC Statement \n  Kin is proud to be an Equal Employment Opportunity and Affirmative Action Employer. We don't just accept difference \u2013 we honor it, nurture it, and celebrate it. We don't discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. \n  Kin encourages applications from all backgrounds, communities and industries, and are committed to having a team that is made up of diverse skills, experiences and abilities. \n \n \n  #LI-Remote",
        "cleaned_desc": " Advanced experience in engineering and operations roles, preferably in technical operations or similar infrastructure positions \n Leading operations-centric, strategic, and highly collaborative engineering teams \n Implementation and support of high-availability AWS infrastructure \n Managing technical operations with a service mindset and proactive stakeholder engagement \n CI/CD and Infrastructure as Code pipelines \n Implementing measures for optimal cloud cost management and oversight \n Comfortable navigating ambiguity and taking proactive ownership \n Strong organizational skills, and ability to adapt quickly to changing priorities, assignments, and roles \n Verbal, written, and presentation skills, communicating technical and business issues to multiple audiences \n Supporting work transparency and Agile practices \n ",
        "techs": [
            "advanced experience in engineering and operations roles",
            "preferably in technical operations or similar infrastructure positions",
            "leading operations-centric",
            "strategic",
            "and highly collaborative engineering teams",
            "implementation and support of high-availability aws infrastructure",
            "managing technical operations with a service mindset and proactive stakeholder engagement",
            "ci/cd and infrastructure as code pipelines",
            "implementing measures for optimal cloud cost management and oversight",
            "comfortable navigating ambiguity and taking proactive ownership",
            "strong organizational skills",
            "and ability to adapt quickly to changing priorities",
            "assignments",
            "and roles",
            "verbal",
            "written",
            "and presentation skills",
            "communicating technical and business issues to multiple audiences",
            "supporting work transparency and agile practices"
        ],
        "cleaned_techs": [
            "advanced experience in engineering and operations roles",
            "preferably in technical operations or similar infrastructure positions",
            "leading operations-centric",
            "strategic",
            "and highly collaborative engineering teams",
            "implementation and support of high-availability aws infrastructure",
            "managing technical operations with a service mindset and proactive stakeholder engagement",
            "ci/cd and infrastructure as code pipelines",
            "implementing measures for optimal cloud cost management and oversight",
            "comfortable navigating ambiguity and taking proactive ownership",
            "assignments",
            "and roles",
            "verbal",
            "written",
            "communicating technical and business issues to multiple audiences",
            "supporting work transparency and agile practices"
        ]
    },
    "b4522986196b11a3": {
        "terms": [
            "mlops"
        ],
        "salary_min": 130000.0,
        "salary_max": 130000.0,
        "title": "Software Automation Engineer (DevOps)",
        "company": "CFONE, Inc.",
        "desc": "Software Automation Engineer (DevOps) \n We are looking for a Software Automation Engineer (DevOps) supporting development, design, modernization, and migration in support of a government multi-cloud environment with 30+ customer tenants and growing. Aside from technical qualifications, application should have effective communication skills, both written and verbal. \n The applicant must have engineering and design experience and extensive automation and cloud knowledge and experience with integration, system analysis or programming experience, including developing cloud systems requirements and design specification. A passion for performance, strong desire for quality conformance, and attention to detail are prerequisites for this position. \n Key Responsibilities \n \n Guide teams in designing, building, testing and deploying changes to existing software \n Enhance the company\u2019s IT infrastructure security protocols \n Identify manual processes that can be automated \n Consider the organization\u2019s entire IT infrastructure when making changes and improvements \n Maintain and improve the company\u2019s cloud infrastructure \n Application of activity and data modeling, transaction/workflow analysis, internal control, and risk analysis. \n Modern business methods and performance measurement techniques \n Provides technical direction to personnel performing systems analysis and system/ subsystem development tasks \n Understanding of REST APIs, automation standards, use of CI/CD Pipelines \n Prepares reports, studies, and documentation, delivers presentations, and participates in meetings. \n Be prepared to provide sound advice as to prioritizing projects or tasks and when to delay \n Change and Configuration Management best practices \n Enforce quality standards for engineered solutions and promote continuous improvement \n Cross functional communication. \n \n LOCATION: Remote (but must reside and perform all work within the United States) \n WORK HOURS: This position requires working online from 8:00 AM Eastern to 5:00 PM Eastern \n Requirements \n \n Required \n Ability to obtain a DHS Public Trust clearance \n CompTIA Security+ certification or other US DoD 8570.1 compliant certification \n Very strong Systems experience will include Windows Server and RHEL 8. \n Strong scripting experience with PowerShell or Python. \n Strong Terraform experience. \n Experience leveraging web API\u2019s including REST and SOAP. \n Familiarity with JSON, XML and YAML. \n Solid understanding of version control and using Git and tools such as Azure Repositories, Gitlab, Bitbucket, etc. \n Solid understanding of continuous integration concepts and CI/CD Tools \n Experience with remote system administration methods (WinRM, SSH). \n Knowledge of cloud platforms (Azure and AWS). \n Experience working in teams using Agile methodologies including scrum or Kanban. \n \n \n Preferred \n DevOps Certification in AWS or Azure \n AWS Certifications in specialty domains such as Advanced Networking or Security \n Other Certifications such as Red Hat Ansible \n \n \n 5+ years of integration, systems analysis, or programming experience \n 5+ years of developing cloud systems requirements and design specifications \n 3+ years of experience in automation \n Experience leading and collaborating with technical teams of diverse IT related skill sets \n Extensive knowledge and understanding of cloud technologies and deploying in Government environments. \n Exemplary communication, analytical skills, and technical knowledge across the client environment. \n Ability to produce concise and clear technical documentation. \n \n Security Level Required \n \n Public Trust \n \n Job Type: Full-time \n Pay: $130,000.00 per year \n Benefits: \n \n 401(k) matching \n Dental insurance \n Health insurance \n \n Compensation package: \n \n Yearly pay \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Do you have the following? \n \n Very strong Systems experience will include Windows Server and RHEL 8 \n \n Strong scripting experience with PowerShell or Python \n Strong Terraform experience \n Experience leveraging web API\u2019s including REST and SOAP \n Familiarity with JSON, XML and YAML \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Azure/AWS: 3 years (Preferred) \n integration, systems analysis, programming cloud systems: 5 years (Required) \n in automation: 3 years (Preferred) \n \n License/Certification: \n \n Ability to obtain a DHS Public Trust clearance? (Required) \n CompTIA Security+ certification or other US DoD 8570.1 cert (Required) \n DevOps Certification in AWS or Azure (Preferred) \n AWS Certifications in Advanced Networking or Security (Preferred) \n Other Certifications such as Red Hat Ansible (Preferred) \n \n Security clearance: \n \n Confidential (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "Software Automation Engineer (DevOps) \n We are looking for a Software Automation Engineer (DevOps) supporting development, design, modernization, and migration in support of a government multi-cloud environment with 30+ customer tenants and growing. Aside from technical qualifications, application should have effective communication skills, both written and verbal. \n The applicant must have engineering and design experience and extensive automation and cloud knowledge and experience with integration, system analysis or programming experience, including developing cloud systems requirements and design specification. A passion for performance, strong desire for quality conformance, and attention to detail are prerequisites for this position. \n Key Responsibilities \n \n Guide teams in designing, building, testing and deploying changes to existing software \n Enhance the company\u2019s IT infrastructure security protocols \n Identify manual processes that can be automated \n Consider the organization\u2019s entire IT infrastructure when making changes and improvements \n Maintain and improve the company\u2019s cloud infrastructure \n Application of activity and data modeling, transaction/workflow analysis, internal control, and risk analysis. \n Modern business methods and performance measurement techniques \n Provides technical direction to personnel performing systems analysis and system/ subsystem development tasks \n Understanding of REST APIs, automation standards, use of CI/CD Pipelines \n Prepares reports, studies, and documentation, delivers presentations, and participates in meetings. \n Be prepared to provide sound advice as to prioritizing projects or tasks and when to delay \n Change and Configuration Management best practices \n Enforce quality standards for engineered solutions and promote continuous improvement \n Cross functional communication. \n \n LOCATION: Remote (but must reside and perform all work within the United States) \n WORK HOURS: This position requires working online from 8:00 AM Eastern to 5:00 PM Eastern   Requirements \n \n Required \n Ability to obtain a DHS Public Trust clearance \n CompTIA Security+ certification or other US DoD 8570.1 compliant certification \n Very strong Systems experience will include Windows Server and RHEL 8. \n Strong scripting experience with PowerShell or Python. \n Strong Terraform experience. \n Experience leveraging web API\u2019s including REST and SOAP. \n Familiarity with JSON, XML and YAML. \n Solid understanding of version control and using Git and tools such as Azure Repositories, Gitlab, Bitbucket, etc. \n Solid understanding of continuous integration concepts and CI/CD Tools \n Experience with remote system administration methods (WinRM, SSH). \n Knowledge of cloud platforms (Azure and AWS). \n Experience working in teams using Agile methodologies including scrum or Kanban. \n \n \n Preferred \n DevOps Certification in AWS or Azure \n AWS Certifications in specialty domains such as Advanced Networking or Security \n Other Certifications such as Red Hat Ansible \n ",
        "techs": [
            "software automation engineer (devops)",
            "powershell",
            "python",
            "terraform",
            "rest",
            "soap",
            "json",
            "xml",
            "yaml",
            "git",
            "azure repositories",
            "gitlab",
            "bitbucket",
            "winrm",
            "ssh",
            "azure",
            "aws",
            "agile methodologies",
            "scrum",
            "kanban",
            "aws certifications",
            "advanced networking",
            "security",
            "red hat ansible"
        ],
        "cleaned_techs": [
            "software automation engineer (devops)",
            "powershell",
            "python",
            "terraform",
            "rest",
            "soap",
            "json",
            "xml",
            "yaml",
            "git",
            "azure",
            "gitlab",
            "bitbucket",
            "winrm",
            "ssh",
            "aws",
            "agile methodologies",
            "scrum",
            "kanban",
            "advanced networking",
            "red hat ansible"
        ]
    },
    "66b8fb4213cc67d6": {
        "terms": [
            "mlops"
        ],
        "salary_min": 55.0,
        "salary_max": 65.0,
        "title": "Remote DevOps Engineer (Mid-Level) - Temp-To-Hire",
        "company": "Gallagher",
        "desc": "About Us: \n  \n   Gallagher is a global leader in insurance, risk management and consulting services. We help businesses grow, communities thrive and people prosper. We live a culture defined by The Gallagher Way, our set of shared values and guiding tenets. A culture driven by our people, over 45,000 strong, serving our clients with customized solutions that will protect them and fuel their futures.\n  \n \n \n \n \n  As a member of our benefits and HR consulting team, you\u2019ll help our clients - employers of all sizes, across all industries - build workplaces that work better. \n  Overview: \n  \n   The Senior DevOps Engineer is responsible for the:\n  \n \n  Working with application developers to automate and accelerate application testing \n  Managing application deployment/releases to SDLC environments quickly and reliably \n  Ensuring that Gallagher\u2019s data is protected in accordance with IT Policy and organizational priorities \n  Ensuring that the standardized application development process, guidelines, and best practices are observed consistently \n  Coordinating infrastructure requests - requesting servers and cloud services (Paas and IaaS) and keeping track of all assets in GAGS (GBS Application Governance System). \n  Coordinating software license renewals \n \n \n   Please note additional position details below:\n  \n \n  This is a Temp-To-Hire, W-2 position. We are not able to do 1099 or C2C. \n  The salary for the position is $55 - 65/hr. \n  It is a fully remote role that will need to be based in the U.S. or Canada. \n  You must meet our U.S. Eligibility requirements for work authorization as noted under \"Additional Information\" at the bottom of the job description. \n  Responsibilities: \n  \n Oversee the adoption of SDLC \n  Oversee the implementation of quality gates \n  Enforce a consistent development environment across the team, e.g., same Visual IDE version and settings \n  Maintain and enforce standard code analysis rule sets (Minimum Recommended Rule Set and Security Rule Set) \n \n \n  Implement and oversee implementation of SAST and DAST \n  Implement and enforce unit testing \n  Implement and enforce code review (SonarCloud) to ensure maintainability (code smells are minimized), reliability (bugs are fixed), and security (vulnerabilities are remediated) \n  Analyze current technology utilized within the organization and develop steps and processes to improve and expand upon them \n  Ensure that the standard application development (Scrum) process is implemented and consistently followed by all development team \n \n \n  Establish milestones for scrum implementation and adoption by development teams \n  Provide training and guidance on the scrum process to development teams \n  Generate analytics from DevOps on error rate/trend, work item quality, productivity to measure adoption and drive improvement \n  Provide clear goals for all areas of a project and develop steps to oversee their timely execution \n  Work closely with the infrastructure teams to provision hardware and software needed for projects \n \n \n  Work alongside the project management teams to successfully monitor progress and implementation of initiatives \n  Qualifications: \n  \n  Qualifications \n \n \n  Bachelor's or master's degree in computer science or comparable experience \n  2+ years on DevOps \n  1+ Azure DevOps \n \n \n  2+ years of C# programming experience \n  Strong experience source code branching strategy \n  Strong experience in software development \n  Strong experience in the SDLC processes and best practices \n  Experience in Agile or Scrum software development methodology \n \n \n  Strong experience in CI/CD \n  Experience in Visual Studio \n  Strong experience with SQL Server database \n  Knowledge of application architecture and design patterns \n  Experience in Azure Cloud Services (Azure SQL, App Services, ADFS, etc.) \n \n \n  Experience in APM system (App Insight) \n  Experience in code reviews (manual and automated) \n  Strong experience in configuring Azure DevOps \n \n \n \n  Interpersonal Skills \n : \n \n \n \n \n  Must be self-motivated and goal oriented \n  Attention to detail and proven ability to follow through \n  Strong analytical, organizational, and problem-solving capabilities \n  Ability to work on multiple projects and priorities concurrently \n \n \n  Requires minimal supervision and motivation \n  Ability to work collaboratively on team-based projects \n  Proven relationship building skills and high energy level \n  Excellent oral and written communication skills",
        "cleaned_desc": "  Bachelor's or master's degree in computer science or comparable experience \n  2+ years on DevOps \n  1+ Azure DevOps \n \n \n  2+ years of C# programming experience \n  Strong experience source code branching strategy \n  Strong experience in software development \n  Strong experience in the SDLC processes and best practices \n  Experience in Agile or Scrum software development methodology \n \n \n  Strong experience in CI/CD \n  Experience in Visual Studio \n  Strong experience with SQL Server database \n  Knowledge of application architecture and design patterns \n  Experience in Azure Cloud Services (Azure SQL, App Services, ADFS, etc.) \n \n    Experience in APM system (App Insight) \n  Experience in code reviews (manual and automated) \n  Strong experience in configuring Azure DevOps \n \n \n \n  Interpersonal Skills \n : \n \n \n \n \n  Must be self-motivated and goal oriented \n  Attention to detail and proven ability to follow through \n  Strong analytical, organizational, and problem-solving capabilities \n  Ability to work on multiple projects and priorities concurrently \n \n \n  Requires minimal supervision and motivation ",
        "techs": [
            "devops",
            "azure devops",
            "c#",
            "source code branching strategy",
            "software development",
            "sdlc processes",
            "agile",
            "scrum",
            "ci/cd",
            "visual studio",
            "sql server",
            "application architecture",
            "design patterns",
            "azure cloud services",
            "apm system",
            "code reviews",
            "configuring azure devops"
        ],
        "cleaned_techs": [
            "devops",
            "azure",
            "c#",
            "source code branching strategy",
            "software development",
            "sdlc processes",
            "agile",
            "scrum",
            "ci/cd",
            "visual studio",
            "sql",
            "application architecture",
            "design patterns",
            "apm system",
            "code reviews",
            "configuring azure devops"
        ]
    },
    "9bf68481dcad84c3": {
        "terms": [
            "mlops"
        ],
        "salary_min": 78000.0,
        "salary_max": 176236.0,
        "title": "Senior Consultant- DevOps- Tech Modernization",
        "company": "Cognizant Technology Solutions",
        "desc": "Senior Consultant DevOps, Cognizant Consulting \n  Technology Modernization \n  Remote \n \n \n  ABOUT US \n  Cognizant is one of the world's leading professional services companies, transforming clients' business, operating, and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build, and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant, a member of the NASDAQ-100, is ranked 195 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com. \n \n \n  COGNIZANT CONSULTING \n  Within Cognizant is Cognizant Consulting, a global consulting organization delivering strategic and domain consulting through industry and technology expertise. With over 6,000 consultants worldwide, Cognizant offers high-value consulting services that improve business performance and operational productivity, lower operational expenses and enhance overall performance. Clients draw upon our deep industry expertise, program and change management capabilities, and analytical objectivity to help improve business productivity, drive technology-enabled business transformation and increase shareholder value. We provide a number of Business/IT Consulting Services including Business Strategy, IT Strategy & Roadmap Development, Process Re-Engineering & Transformation, Enterprise Architecture & Technology Selection, and Domain Solutions. The Cognizant Consulting team is a high performing organization that is continually expanding our client base and increasingly being recommended by analysts such as Forrester and Gartner. And we\u2019re growing! \n \n \n  The Role \n  Cognizant Technology Modernization is changing the game in DevOps, Cloud and Container based consultancy services. Tech Modernization, which is based on the Contino innovative solution solving approach, is almost like a boutique consultancy inside of Cognizant that creates change in how technology is used and fosters an innovative engineering culture. \n \n \n  We strategically align with modern engineering practices and ways of working, along with helping clients in all aspects of enterprise technology solutions modernization including Cloud, DevOps, Data and more. \n \n \n  We\u2019re looking for  Senior Consultants  who can deliver within Cognizant\u2019s Five Pillars of Consulting Excellence: 1) Project Execution, 2) Expertise, 3) Business Development, 4) Practice Development, & 5) People Development. As a Senior Consultant, this means partnering with clients and project stakeholders, colleagues creating high-quality client deliverables and taking ownership of producing client content and meeting client expectations; developing an expertise in your functional area, including obtaining certifications; contributing to Client Satisfaction and/or RFPs; supporting leadership and contributing to content development for service offerings; and participating in PeopleCare initiatives and exhibiting personal leadership at all times. In addition to enabling consulting excellence through the Five Pillars of Consulting, the specific requirements for this position are below. \n  Our solutions are in demand and we\u2019re passionate about making a difference. If you have experience with the above, are a selfless leader, and are committed to client-facing environment; if you want to grow your career with a team that wants to build something great together, we want to hear from you! Apply now! \n \n \n  Responsibilities \n \n Based on experience, support or own and manage one or more project workstream(s), including deliverables, while adhering to budget, timelines, and client engagement guidelines; \n \n \n Partner with clients and project stakeholders and apply technical and domain expertise to solve core client business challenges or inefficiencies; this may include leading and managing small solutioning teams to accomplish the above \n \n \n Elevate the Cognizant brand from mere solution vendor to business-focused transformation partner, based on earning the trust and confidence of clients; \n \n \n Ensure accurate understanding of a client\u2019s business challenges and their optimum alignment to engagements delivering Cognizant solutions; \n \n \n Capitalize on successful project outcomes in pursuit of further client business partnering and involvement with the client\u2019s development of strategic digital transformation roadmaps; \n \n \n Collaborate with and influence Cognizant project resources (e.g., service lines, SBUs, on/offshore delivery teams) and Partners on behalf of project goals, often-changing client needs, and ultimately client delight; \n \n \n Leverage specific engagement solutions as marketable Cognizant solution offerings; \n \n \n Develop practice capabilities and brand recognition by exercising thought leadership, establishing a consultative presence within Cognizant and the wider consulting community, and participating in professional organizations; \n \n \n Participate in PeopleCare activities; Mentor and support less experienced Consultants for the benefit of the practice. \n \n \n \n  Qualifications \n \n 5+ years of experience and a deep understanding of working within a DevOps environment \n \n \n Proven technical background/understanding in DevOps, Software Engineering or Infrastructure Engineering so that you're able to understand high level technical briefs, talks and ideas \n \n \n Experience of the full software delivery lifecycle and working in complex enterprise environments \n \n \n Enhances or develops processes and procedures that contribute to effective consulting (e.g., prioritizing backlogs, managing dependencies, developing tasks, validating solution stories) \n \n \n Based on experience, orchestrates the expertise required to deliver complex solutions seamlessly (internal, acquired companies, partners / alliances) \n \n \n Strong experience in AWS, Azure and/or GCP \n \n \n Experience with CI/CD \n \n \n Strong grasp of container technology including container orchestration with tools such as Kubernetes, Rancher, Docker Swarm, Nomad or similar \n \n \n Solid experience with either Puppet, Chef, Ansible or Saltstack \n \n \n Solid understanding of Microservices and APIs \n \n \n Experience and interest in working in an Agile environment \n \n \n Bonus points for experience with Terraform, Git, Ruby, Python, Lambda and Golang \n \n \n Demonstrates technical prowess, e.g.: Guide others across toolsets; demonstrate expertise with automation \n \n \n Demonstrates consulting skills, e.g.: Support the definition of stories and tasks to deliver on project/sprint goals; support the running of Agile ceremonies \n \n \n Continues the training and certification essential for consulting effectiveness \n \n \n Personal leadership and a desire to create a culture that enables exceptional outcomes \n \n \n The embodiment of Cognizant\u2019s Core Values of: Start with a point of view; Seek data, build knowledge; Always strive, never settle; Work as one; Create conditions for everyone to thrive; Do the right thing, the right way. \n \n \n Currently we are operating in remote and hybrid environments and will be for the foreseeable future. please note that this role requires up to 10% domestic travel. This role will not require relocation and you can be based anywhere in the US. \n \n \n \n  Work Authorization \n \n Cognizant will only consider applicants for this position who are legally authorized to work in the United States without company sponsorship (H-1B, L-1B, L-1A, etc.) \n \n \n \n  Salary and Other Compensation: \n  The annual salary for this position is between $78,000-176,236 depending on experience and other qualifications of the successful candidate. \n  This position is also eligible for Cognizant\u2019s discretionary annual incentive program and stock awards, based on performance and subject to the terms of Cognizant\u2019s applicable plans. \n  Benefits : Cognizant offers the following benefits for this position, subject to applicable eligibility requirements: \n \n Medical/Dental/Vision/Life Insurance \n Paid holidays plus Paid Time Off \n 401(k) plan and contributions \n Long-term/Short-term Disability \n Paid Parental Leave \n Employee Stock Purchase Plan \n \n Disclaimer:  The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law. \n  Employee Status :  Full Time Employee \n  Shift :  Day Job \n  Travel :  No \n  Job Posting :  Oct 27 2023 \n \n \n  About Cognizant \n  Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.\n  \n  Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview. \n \n  Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. \n  If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.",
        "cleaned_desc": " 5+ years of experience and a deep understanding of working within a DevOps environment \n \n \n Proven technical background/understanding in DevOps, Software Engineering or Infrastructure Engineering so that you're able to understand high level technical briefs, talks and ideas \n \n \n Experience of the full software delivery lifecycle and working in complex enterprise environments \n \n \n Enhances or develops processes and procedures that contribute to effective consulting (e.g., prioritizing backlogs, managing dependencies, developing tasks, validating solution stories) \n \n \n Based on experience, orchestrates the expertise required to deliver complex solutions seamlessly (internal, acquired companies, partners / alliances) \n \n \n Strong experience in AWS, Azure and/or GCP \n \n \n Experience with CI/CD \n \n \n Strong grasp of container technology including container orchestration with tools such as Kubernetes, Rancher, Docker Swarm, Nomad or similar \n \n \n Solid experience with either Puppet, Chef, Ansible or Saltstack \n \n \n Solid understanding of Microservices and APIs ",
        "techs": [
            "devops",
            "software engineering",
            "infrastructure engineering",
            "aws",
            "azure",
            "gcp",
            "ci/cd",
            "kubernetes",
            "rancher",
            "docker swarm",
            "nomad",
            "puppet",
            "chef",
            "ansible",
            "saltstack",
            "microservices",
            "apis"
        ],
        "cleaned_techs": [
            "devops",
            "software engineering",
            "infrastructure engineering",
            "aws",
            "azure",
            "gcp",
            "ci/cd",
            "kubernetes",
            "rancher",
            "docker swarm",
            "nomad",
            "puppet",
            "chef",
            "ansible",
            "saltstack",
            "microservices",
            "apis"
        ]
    },
    "be4eccd645a84f05": {
        "terms": [
            "mlops"
        ],
        "salary_min": 182658.38,
        "salary_max": 231286.19,
        "title": "Remote - Principal DevOps Engineer",
        "company": "SAP",
        "desc": "We help the world run better \n  Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. Apply now! \n \n  We are seeking an Expert DevOps Engineer to join our rapidly growing technology team. The successful candidate should have a minimum of 15 years of experience in a similar role, with a deep proficiency in managing cloud infrastructure and services. The candidate must be adept at using Git, Terraform, and Kubernetes. Knowledge in deploying SAP Ariba and familiarity with Kafka, Hadoop, and Cassandra are considered significant pluses. The candidate should be passionate about automation, system efficiency, and security. The individual in this role will be our guiding force in designing, automating, and optimizing scalable systems, and will solve complex system issues. \n \n  **Responsibilities:** \n \n  1. Lead the development, maintenance, and improvement of our continuous integration/continuous delivery (CI/CD) pipeline using cloud services and automation tools. \n  2. Use Terraform for advanced cloud resource provisioning and management. \n  3. Implement automated infrastructure capabilities like backups, security tools, monitoring. \n  4. Design and implement enterprise-grade, scalable cloud-based services to support our development teams. \n  5. Collaborate with developers to optimize the application development workflow. \n  6. Troubleshoot complex system issues and provide advanced technical support to the team. \n  7. Advocate for and implement industry best practices for system hardening and configuration management. \n  8. Deploy and manage containerized applications using Kubernetes. \n  9. If necessary, deploy and maintain SAP Ariba in cloud environments. \n  10. Stay current with industry trends, making recommendations as needed to help the company excel. \n \n  **Requirements:** \n \n  1. Bachelor's degree in Computer Science, Information Technology, or a related field or equivalent work experience. \n  2. 15+ years of experience as a DevOps Engineer or similar software engineering role. \n  3. Expert proficiency with Git, Terraform, Kubernetes, and other infrastructure automation toolsets. \n  4. Deep expertise with cloud services (e.g., AWS, Google Cloud, Azure) and an in-depth understanding of their offerings. \n  5. Significant experience in network, server, and application-status monitoring. \n  6. Proven ability to lead and improve software-automation production systems. \n  7. Exceptional problem-solving and troubleshooting skills. \n  8. Comprehensive understanding of scalable computing systems. \n  9. Excellent communication skills and ability to explain protocol and processes with team and management. \n \n  **Nice to Have:** \n \n  1. Experience with deploying and maintaining SAP Ariba. \n  2. Advanced knowledge of distributed data processing systems such as Kafka, Hadoop, Cassandra. \n  3. Certification in AWS, Google Cloud, or Azure. \n  4. Expertise in scripting languages such as Python, Bash. \n \n  At our company, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. \n \n  We build breakthroughs together \n \n  SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together. \n  We win with inclusion \n  SAP\u2019s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone \u2013 regardless of background \u2013 feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.  SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com.  For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training. \n  EOE AA M/F/Vet/Disability \n  Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. \n  Compensation Range Transparency : SAP believes the value of pay transparency contributes towards an honest and supportive culture and is a significant step toward demonstrating SAP\u2019s commitment to pay equity. SAP provides the annualized compensation range inclusive of base salary and variable incentive target for the career level applicable to the posted role. The targeted combined range for this position is #SAPCloudReq USD. The actual amount to be offered to the successful candidate will be within that range, dependent upon the key aspects of each case which may include education, skills, experience, scope of the role, location, etc. as determined through the selection process. Any SAP variable incentive includes a targeted dollar amount and any actual payout amount is dependent on company and personal performance. Please reference this link for a summary of SAP benefits and eligibility requirements: SAP North America Benefits. \n  Requisition ID: 382629 | Work Area: Software-Development Operations | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: #LI-Hybrid",
        "cleaned_desc": "  3. Implement automated infrastructure capabilities like backups, security tools, monitoring. \n  4. Design and implement enterprise-grade, scalable cloud-based services to support our development teams. \n  5. Collaborate with developers to optimize the application development workflow. \n  6. Troubleshoot complex system issues and provide advanced technical support to the team. \n  7. Advocate for and implement industry best practices for system hardening and configuration management. \n  8. Deploy and manage containerized applications using Kubernetes. \n  9. If necessary, deploy and maintain SAP Ariba in cloud environments. \n  10. Stay current with industry trends, making recommendations as needed to help the company excel. \n    **Requirements:** \n \n  1. Bachelor's degree in Computer Science, Information Technology, or a related field or equivalent work experience. \n  2. 15+ years of experience as a DevOps Engineer or similar software engineering role. \n  3. Expert proficiency with Git, Terraform, Kubernetes, and other infrastructure automation toolsets. \n  4. Deep expertise with cloud services (e.g., AWS, Google Cloud, Azure) and an in-depth understanding of their offerings. \n  5. Significant experience in network, server, and application-status monitoring. \n  6. Proven ability to lead and improve software-automation production systems. \n  7. Exceptional problem-solving and troubleshooting skills.    8. Comprehensive understanding of scalable computing systems. \n  9. Excellent communication skills and ability to explain protocol and processes with team and management. \n \n  **Nice to Have:** \n \n  1. Experience with deploying and maintaining SAP Ariba. \n  2. Advanced knowledge of distributed data processing systems such as Kafka, Hadoop, Cassandra. \n  3. Certification in AWS, Google Cloud, or Azure. \n  4. Expertise in scripting languages such as Python, Bash. ",
        "techs": [
            "git",
            "terraform",
            "kubernetes",
            "aws",
            "google cloud",
            "azure",
            "sap ariba",
            "kafka",
            "hadoop",
            "cassandra",
            "python",
            "bash"
        ],
        "cleaned_techs": [
            "git",
            "terraform",
            "kubernetes",
            "aws",
            "gcp",
            "azure",
            "sap ariba",
            "kafka",
            "hadoop",
            "cassandra",
            "python",
            "bash"
        ]
    },
    "47d9388193b00738": {
        "terms": [
            "mlops"
        ],
        "salary_min": 108992.86,
        "salary_max": 138009.25,
        "title": "Sr. DevOps",
        "company": "Gravity Infosolutions",
        "desc": "Sr. DevOps\n  \n \n  Remote\n  \n \n  Contract\n  \n \n \n \n \n \n \n \n \n \n Competitive   Salary \n Health   Insurance \n Performance-Based   Incentives  \n Work-Life   Balance  \n Maternity &   Paternity Benefits  \n Employee Recognition   and Appreciation \n \n \n \n \n \n \n       Global Perks & Benefits\n       \n \n Global Perks & Benefits is a comprehensive employee benefits program offered by Gravity Infosolutions. It includes health insurance, retirement plans, flexible work arrangements, and other perks to support the wellbeing of employees.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "metadata": {
        "keywords": [
            "data science",
            "data analyst",
            "data engineer",
            "machine learning engineer",
            "mlops"
        ],
        "locations": [
            "remote"
        ],
        "time_ran": "18:51:43-28-10-23",
        "num_jobs": 240,
        "timings": {
            "start_drivers": 44.71509337425232,
            "find_job_ids": 389.0034680366516,
            "get_job_descs": 95.45710444450378
        },
        "models": {
            "classifier": {
                "clf": "data/classifier_models/job_desc_classifier_v1.0.pkl",
                "tfidf": "data/classifier_models/job_desc_tfidf_vectorizer_v1.0.pkl"
            },
            "NER": "gpt-3.5-turbo"
        }
    }
}