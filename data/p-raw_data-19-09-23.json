{
    "154de6dcf59fe1f3": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 85885.08,
        "salary_max": 108749.64,
        "title": "Remote Data Analyst",
        "company": "Firebox Australia Pty Ltd",
        "desc": "Firebox Australia is seeking a Remote Data Analyst to join our team. As a Remote Data Analyst, you will work remotely to collect, analyze, and interpret complex data sets to identify trends, patterns, and insights for our clients. You will develop and maintain analytical frameworks and models, and communicate findings to both technical and non-technical stakeholders. The ideal candidate should be able to work independently, have excellent attention to detail, and possess strong critical-thinking skills. \n \n  Tasks \n \n \n \n Collect and analyze data from multiple sources to identify patterns and insights \n Develop analytical frameworks and models to support data analysis and visualization \n Communicate findings and insights to technical and non-technical stakeholders \n Perform data quality checks to ensure data accuracy and consistency \n Collaborate with cross-functional teams to drive business growth and strategy \n Present data-driven insights to senior management to inform decision-making \n Stay up-to-date with the latest industry trends and innovations to optimize data analysis methods \n  Requirements \n \n \n \n Bachelor's or Master's degree in Data Science, Computer Science, Mathematics or related field \n Proven experience as a Data Analyst or similar role \n Advanced skills in data analysis, data visualization and SQL \n Experience with data modeling, machine learning and predictive modeling \n Understanding of statistical concepts and techniques \n Excellent attention to detail and the ability to work independently \n Strong written and verbal communication skills to communicate findings to stakeholders \n  Benefits \n \n \n \n Health Care Plan (Medical, Dental & Vision) \n Retirement Plan (401k, IRA) \n Paid Time Off (Vacation, Sick & Public Holidays) \n Training & Development",
        "cleaned_desc": " Collect and analyze data from multiple sources to identify patterns and insights \n Develop analytical frameworks and models to support data analysis and visualization \n Communicate findings and insights to technical and non-technical stakeholders \n Perform data quality checks to ensure data accuracy and consistency \n Collaborate with cross-functional teams to drive business growth and strategy \n Present data-driven insights to senior management to inform decision-making   Proven experience as a Data Analyst or similar role \n Advanced skills in data analysis, data visualization and SQL \n Experience with data modeling, machine learning and predictive modeling \n Understanding of statistical concepts and techniques \n Excellent attention to detail and the ability to work independently \n Strong written and verbal communication skills to communicate findings to stakeholders ",
        "techs": [
            "data analysis",
            "data visualization",
            "sql",
            "data modeling",
            "machine learning",
            "predictive modeling",
            "statistical concepts",
            "statistical techniques"
        ],
        "cleaned_techs": [
            "data visualization",
            "sql",
            "predictive modeling",
            "statistical concepts",
            "statistical techniques"
        ]
    },
    "0948012de7adb867": {
        "terms": [
            "data science"
        ],
        "salary_min": 22.0,
        "salary_max": 26.0,
        "title": "Clinical Support Specialist",
        "company": "ROM Technologies, Inc.",
        "desc": "About Our Company:  ROMTech is a medical technology company that has created and patented a revolutionary medical device and telemedical platform which delivers in-home rehabilitative care. Our disruptive technology has proven to yield faster recoveries and better outcomes with unmatched patient compliance. We began in orthopedics and have entered scale-up of our orthopedic business. We are now leveraging our core technology, infrastructure, and first mover position to enter cardiology, followed by other adjacent markets. Having created this new lane, we have a unique opportunity to serve as the global leader in the business, technology, and science of recovery, and to bring life-changing help to many millions of people. \n Position Overview:  ROMTech, through its subsidiary ROMTherapyTM, delivers an innovative, first-in-kind Home-Based Cardiac Rehabilitation program through the use of telemedicine and connected medical devices. \n We are currently seeking a dedicated Clinical Support Specialist to handle all incoming technology requests from our remote Cardiac Rehab Specialists team. Our team requires immediate real-time support for multiple time-zones. The Clinical Support Specialist will work closely with the Senior Manager, Cardiac Rehab and will report directly to the VP, Clinical Services. This is a full-time opportunity, with a Monday-Friday, 11:00am EST - 7:00pm EST schedule. \n Responsibilities: \n \n Successfully provide timely resolutions to all IT support requests. \n Assist with the structuring of decision trees and flow charts for supporting common tech issues in the field. \n Log and regularly report on all field issues with managers. Communicate the nature of issues along with the resolution timeline and effectiveness. \n Continually discuss, collaborate, and provide program improvement initiatives & resolutions based on field tech issues reported with the product, engineering, software, and clinical team. \n \n Requirements: \n \n High EQ and people skills. \n Positive demeanor with a can-do attitude. No task is too big or too small. \n Natural sense of urgency. \n Experience providing high touch customer service. \n Wide breadth of experience with technical troubleshooting \u2013 both hardware and software issues. \n Experience supporting clinicians in patient-facing environments is strongly preferred. \n Ability to collaborate and provide thoughtful and actionable process improvements. \n Continually looking to improve on tech stack and ability to adapt to changing environments. \n \n If this sounds like an exciting opportunity to embark in the next chapter of your career, please respond and include: \n \n A cover letter detailing why you are an ideal fit for this job \n An up-to-date resume \n \n Candidates who send resumes without the requested cover letter will not be considered. \n The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to sit for extended periods of time and use hands to operate a computer and other office equipment. The employee is frequently required to reach with hands and arms, talk, and hear. Specific vision abilities required by this job include close vision and the ability to adjust focus. \n We are an equal opportunity employer. Qualified Applicants are considered for positions and are evaluated without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, marital status, or any other classification protected under applicable Federal, State or Local law. \n Job Type: Full-time \n Pay: $22.00 - $26.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible spending account \n Health insurance \n Life insurance \n Paid time off \n Referral program \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Computer hardware: 2 years (Required) \n Software: 2 years (Required) \n Technical troubleshooting: 2 years (Required) \n Customer service: 2 years (Required) \n Healthcare tech support: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Requirements: \n \n High EQ and people skills. \n Positive demeanor with a can-do attitude. No task is too big or too small. \n Natural sense of urgency. \n Experience providing high touch customer service. \n Wide breadth of experience with technical troubleshooting \u2013 both hardware and software issues. \n Experience supporting clinicians in patient-facing environments is strongly preferred. \n Ability to collaborate and provide thoughtful and actionable process improvements. \n Continually looking to improve on tech stack and ability to adapt to changing environments. ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "b180a287b3bf4ca6": {
        "terms": [
            "data science"
        ],
        "salary_min": 56951.566,
        "salary_max": 72113.375,
        "title": "Healthcare Communicator",
        "company": "Inizio Engage",
        "desc": "Inizio Engage has an immediate need for full time healthcare communicators to work from home across the nation and answer inbound calls from provider and patients on behalf of our client. This is an excellent opportunity to get into healthcare industry. Your day may include the following:\n  \n \n \n  Pre-screen potential volunteers for enrollment into clinical/medical research trials \n  Triage calls to appropriate personnel \n  Intake of product quality complaints \n  Handle DTC and patient Support programs \n  Provide drug/medical device product information \n  First level technical support \n  Enroll participants in educational seminars \n  Collect demographic data and disposition for product, sample and literature fulfillment \n \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Maintain excellent quality standards for all client programs; adhere to program scripts and guidelines. Accurately collect information required by individual programs and correctly capture in specific program databases. \n  Exhibit effective communication and tele-management skills. \n  Converse with callers in an empathetic manner and facilitate the callers in their ability to understand medical terminology, as needed. \n  Possess effective organizational skills, including working with multiple projects simultaneously. \n  Adhere to all company policies and Standard Operating Procedures. \n  Display flexibility within department to maximize utilization, including performing administrative and non-telecommunication duties as needed. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n   What do you need for this position?\n  \n \n \n  Customer service or equivalent work related experience is preferred \n  Excellent verbal, written and listening communication skills \n  Competency with a computer keyboard and mouse \n  Pleasant telephone manner \n \n \n \n   About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "e2c60a113e249bbe": {
        "terms": [
            "data science"
        ],
        "salary_min": 56951.566,
        "salary_max": 72113.375,
        "title": "Healthcare Communicator",
        "company": "Inizio Engage",
        "desc": "Inizio Engage has an immediate need for full time healthcare communicators to work from home across the nation and answer inbound calls from provider and patients on behalf of our client. This is an excellent opportunity to get into healthcare industry. Your day may include the following:\n  \n \n \n  Pre-screen potential volunteers for enrollment into clinical/medical research trials \n  Triage calls to appropriate personnel \n  Intake of product quality complaints \n  Handle DTC and patient Support programs \n  Provide drug/medical device product information \n  First level technical support \n  Enroll participants in educational seminars \n  Collect demographic data and disposition for product, sample and literature fulfillment \n \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Maintain excellent quality standards for all client programs; adhere to program scripts and guidelines. Accurately collect information required by individual programs and correctly capture in specific program databases. \n  Exhibit effective communication and tele-management skills. \n  Converse with callers in an empathetic manner and facilitate the callers in their ability to understand medical terminology, as needed. \n  Possess effective organizational skills, including working with multiple projects simultaneously. \n  Adhere to all company policies and Standard Operating Procedures. \n  Display flexibility within department to maximize utilization, including performing administrative and non-telecommunication duties as needed. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n   What do you need for this position?\n  \n \n \n  Customer service or equivalent work related experience is preferred \n  Excellent verbal, written and listening communication skills \n  Competency with a computer keyboard and mouse \n  Pleasant telephone manner \n \n \n \n   About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b4efb12f24d950a2": {
        "terms": [
            "data science"
        ],
        "salary_min": 25.49,
        "salary_max": 30.69,
        "title": "Senior BI Specialist",
        "company": "Kimball International",
        "desc": "Role Description: \n Are you someone who has the vision and passion for driving business outcomes backed by data-driven insights? Do you enjoy transforming transactional data into multi-dimensional Semantic modeling to provide business insights? Do you get excited about integrating sales, finance, and supply chain data and its results to achieve business goals? Do you get intrigued to explore new technology platforms? Then, we are looking for you, and here is an exclusive opportunity at Kimball International as a Sr. Business Intelligence Specialist. \n We are seeking for an energetic, creative, and analytical professional who can partner with multiple business functional leaders in the Sales, Finance, and Supply chain areas, understand their business challenges and co-create analytical solutions by transforming the non-integrated transactional data into integrated, meaningful information. You will be part of the global analytics team working alongside the external consultants and other internal Business Intelligence professionals. You will be part of the journey to activate operational analytics, explore data science capabilities in the cloud platform, and reposition existing integrated models to support changing source systems. \n Responsibilities: \n \n Manage the end-to-end process from business requirement gathering to customer satisfaction that include but not limited to leading sessions or workshops, driving PoC efforts, or training users. \n Partner closely with business users in Sales, Finance, and Supply chain functions to align on project timelines, deliverable, and priorities. \n To deliver complete solution package, collaborate with professionals in other I.T. functions \u2013 DBA, Security, and Transactional System analyst \n Responsible for the upkeep of existing Symantec models and data warehouse \n Own the end-to-end solution from data extraction to visualization \n \n Technical skills: \n \n Sound understanding of Semantic layer, data engineering, and database concepts \n Ability to architect, develop and deploy enterprise grade integrated model using Microsoft \n SSAS, and Power Bi platform. \n Ability to architect, develop and deploy data engineering solution using SQL, Power Query, etc. \n Proficiency in DAX and SQL language is must \n Exposure to SAP ERP data structure is a plus \n Experienced in with multiple data sources and databases \n \n Soft skills: \n \n Proven track record of delivering in a team environment \n Comfortable to play different roles in a project \n Flexibility to adopt to changes \n Excellent listening skills \n Excellent written and verbal communication with all levels in the organization \n Ability to articulate technical issues and solutions to non-technical people \n Adept at using influence and persuasion appropriately \n \n Educational Requirements: \n \n Min 3+ years of work experience in Data Analytics domain \n Bachelor\u2019s Degree in Information Systems, Business or related field \n Power Bi certification is a plus \n Data Analyst certification is a plus \n \n VISA Sponsorship \n Kimball International, Inc. will not sponsor applicants for this position for employment/work visa status (e.g.. H-1B) \n Job Type: Full-time \n Pay: $25.49 - $30.69 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Life insurance \n Paid holidays \n Paid time off \n Retirement plan \n Vision insurance \n \n Schedule: \n \n Day shift \n \n Work Location: Remote",
        "cleaned_desc": " Technical skills: \n \n Sound understanding of Semantic layer, data engineering, and database concepts \n Ability to architect, develop and deploy enterprise grade integrated model using Microsoft \n SSAS, and Power Bi platform. \n Ability to architect, develop and deploy data engineering solution using SQL, Power Query, etc. \n Proficiency in DAX and SQL language is must \n Exposure to SAP ERP data structure is a plus \n Experienced in with multiple data sources and databases \n \n Soft skills:   \n Proven track record of delivering in a team environment \n Comfortable to play different roles in a project \n Flexibility to adopt to changes \n Excellent listening skills \n Excellent written and verbal communication with all levels in the organization \n Ability to articulate technical issues and solutions to non-technical people \n Adept at using influence and persuasion appropriately \n \n Educational Requirements: \n ",
        "techs": [
            "semantic layer",
            "data engineering",
            "database concepts",
            "microsoft ssas",
            "power bi platform",
            "sql",
            "power query",
            "dax",
            "sap erp data structure"
        ],
        "cleaned_techs": [
            "semantic layer",
            "database concepts",
            "microsoft ssas",
            "powerbi",
            "sql",
            "power query",
            "dax",
            "sap erp data structure"
        ]
    },
    "cc6fdcc9db0e75c3": {
        "terms": [
            "data science"
        ],
        "salary_min": 53168.97,
        "salary_max": 67323.76,
        "title": "Associate Product Data Scientist",
        "company": "Treehouse Foods",
        "desc": "Employee Type:\n  \n  Full time\n  \n \n   Location:\n  \n  IL Works from Home\n  \n \n   Job Type:\n  \n  Research and Development\n  \n \n   Job Posting Title:\n  \n  Associate Product Data Scientist\n  \n \n   About Us:\n  \n \n   TreeHouse Foods (NYSE: THS) is a leading manufacturer of private label packaged foods and beverages, operating a network of production facilities across the United States and Canada. At TreeHouse Foods, our commitment to excellence extends beyond our products and revolves around our people. We are investing in talent and creating a performance-based culture where employees can do their best work, directly impacting our mission to make high quality, affordable food for our customers, communities and families. We hope you will consider joining the team and being part of our future.\n  \n \n \n  What You Gain:\n  \n \n  Competitive compensation and benefits program \n  Enrollment in our wellness and employee assistance programs \n  Paid holidays, vacation, and other competitive paid time off opportunities \n  An inclusive working environment where you can build meaningful work relationships with a diverse group of people \n  Leaders who are invested in supporting your career growth \n  Opportunities to be recognized for outstanding contributions to your team through our employee recognition programs \n \n \n \n   Job Description:\n  \n \n \n   About the Role:\n  \n \n   Under some supervision, assist in projects and technology initiatives. Responsible for the creation, maintenance and review of integrated corporate data related to food ingredients and products. Data types may include raw material, formula, packaging, finished-good specification, equipment info, quality and process parameters for R&D, manufacturing plant, co-packers and suppliers using established guidelines and procedures.\n  \n \n \n  Collect and analyze product data for select categories \n  Develop specifications in conjunction with integration, commercialization, and product inquiry. \n  Provide technical support to the business. \n  Compile/load product information into databases/systems-of-record \n  Understand how to develop range formulas and respond to questions requesting confidential and proprietary information in order to protect THS assets. \n  Maintain internal systems (SAP, PDM) with quality finished good data (e.g. allergen, kosher, sensitivity, Inspection types, positive release, lot code information, Inspection plans, etc.). Understand the impact and next steps on any product data changes, utilizing technical product knowledge \n \n \n \n   Important Details: This is a full-time permanent, remote position.\n  \n \n   About You:\n  \n \n   You\u2019ll fit right in if you have:\n  \n \n  Bachelor\u2019s Degree \u2013 Type: Food Science, Engineering, Culinary or related field \n  1+ years working with technical information in computer databases \n  Collaboration/ Teamwork: Flexible in managing multiple requests. Able to set expectations for recipients under limited supervision. \n  Customer Focus: Strong attention to detail and the ability to provide accurate and complete information to internal & external customers in a timely manner. Takes initiative and contacts resources to gather information necessary to complete task. \n  Drive for Results: Must be highly organized. Ability to be a change-agent and strive for continuous improvement. \n  Problem Solving: Ability to prioritize under heavy workload and ask for assistance when needed. \n  MS Office, word, excel, MS Teams, OneDrive, etc. \n  Microsoft Access, and SAP preferred \n  Customer database experience preferred \n \n \n \n  Your TreeHouse Foods Career is Just a Click Away!\n  \n \n   Click on the \u201cApply\u201d button or go directly to \n   \n   www.treehousefoods.com/careers\n    to let us know you\u2019re ready to join our team!\n  \n \n \n  TreeHouse Use Only: #IND1",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "339e88431ae08c4c": {
        "terms": [
            "data science"
        ],
        "salary_min": 10.0,
        "salary_max": 50.0,
        "title": "Private Data Science Tutor (Remote, California)",
        "company": "Lessonpal",
        "desc": "Teach what you love with the most flexible online tutoring platform out there and earn thousands of $$$. \n Are you passionate about Data Science? Do you want to share your knowledge of Data Science with others? \n Then come join us as an online Data Science tutor and help students who are eager to learn. \n Lessonpal was born as a Silicon Valley startup with a mission to democratize education. We believe in delivering high-quality, accessible, and affordable lessons to all our students, and we\u2019d love for you to join us! \n What\u2019s in it for you? \n \n You set your own rates. We never tell you what to charge. If your rates are attractive to students, you\u2019ll get lessons. It\u2019s all in your hands. \n All lessons are taught online and are easily accessible to everyone. We\u2019re in the digital age now! \n You have complete control of when and how much you teach. You control your schedule, availability, and how many students you take on. \n You keep the majority of your earnings! Compared to other platforms, Lessonpal tutors keep more of their earnings...90%! \n \n Job responsibilities \n \n Deliver online Data Science lessons to students of all ages (you choose what age groups you want to work with) \n Submit post-lesson summaries so that students and parents have access to a recap \n Respond to tutoring inquiries and messages from current and potential students \n Work with your students to schedule lessons efficiently \n Proactively communicate with Lessonpal support about any questions \n \n Job requirements \n \n Relevant experience and knowledge of Data Science \n Strong communication skills \n Patience and empathy for working with students \n Reliability, consistency, and punctuality in lesson delivery \n Stable internet connection \n Proficiency in using online meeting platforms such as Zoom \n Verified Paypal account (to receive payments for lessons) \n \n Duration:  Permanent, Independent Contractor \n Pay rate:  You set your own rates (average $15 - $30 per hour) \n Hours:  Flexible - you set your own schedule \n Ready to get started? Apply at www.lessonpal.com/teach-lessons \n EEO:  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, and any other protected class under state or federal law. \n Job Type: Part-time \n Pay: $10.00 - $50.00 per hour \n Schedule: \n \n Choose your own hours \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "0d2dec4de187f1fb": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 77915.91,
        "salary_max": 98658.89,
        "title": "Senior Data Analyst",
        "company": "Mindoula Health",
        "desc": "Mindoula is looking for a bold  Senior Data Analyst  with a passion to learn and deeply understand the complexities and dynamics of how behavioral health impacts physical health. In this position you will have autonomy to study interesting datasets and help identify patterns and predictions of how Mindoula can better serve and engage members through our programmatic interventions. You are a motivated self-starter that thrives on innovation, analytical curiosity and technology. \n  Location... \n  This is a 100% remote position in the United States. Applicants must be authorized to work for any employer in the US. We are unable to sponsor or take over sponsorship of an employment Visa at this time. \n What you'll do... \n \n  Collaborate closely with cross-functional teams to understand and define data requirements for adhoc queries and data validation requests. \n  Design and execute complex SQL queries and scripts to extract, transform, and analyze data from various sources, ensuring data accuracy and integrity. \n  Provide expert-level data validation to ensure data quality and consistency, identifying anomalies and inconsistencies in data sets. \n  Develop and maintain documentation for query and data validation processes, ensuring knowledge sharing and best practices across the team. \n  Perform exploratory data analysis to uncover trends, patterns, and insights that contribute to business and clinical objectives. \n  Collaborate with Data Engineers and BI Developers to optimize data pipelines and data warehousing processes for efficient data retrieval and analysis. \n  Create and present clear and actionable data visualizations and reports to communicate findings and insights to stakeholders. \n  Mentor and provide guidance to junior analysts, fostering a culture of continuous  \n \n What you'll need... \n \n  Bachelor's in a relevant field such as Statistics, Mathematics, Computer Science, or a related quantitative discipline. \n  Proven experience (5+ years) as a Data Analyst, preferably in a healthcare, technology, or related industry. \n  Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL). \n  Strong analytical and problem-solving skills, with the ability to translate complex data into meaningful insights. \n  Experience with data validation techniques and best practices to ensure data accuracy and integrity. \n  Proficiency in data visualization tools such as Tableau, Power BI, or similar tools. \n  Familiarity with scripting languages (e.g., Python) for data manipulation and analysis is a plus. \n  Excellent communication skills, with the ability to present findings and insights to both technical and non-technical stakeholders. \n  Detail-oriented mindset with the ability to manage multiple adhoc requests simultaneously. \n \n  About Mindoula... \n Mindoula is a next generation population health management company that identifies, engages, and serves populations with complex behavioral health, medical, and social challenges across the continuum of care. By using technology to \u201cscale the human connection,\u201d Mindoula helps health plans, health systems, hospitals, and provider groups extend their reach and achieve their value-based service delivery goals. At Mindoula, we address the full range of behavioral health challenges. We deploy tech-enabled teams of case managers, care managers, community health workers, peer support specialists, therapists, and psychiatrists to provide 24/7 support to even the most complex and underserved behavioral health populations. In addition, Mindoula provides direct care services including both the delivery of outpatient behavioral health services - in person and telehealth psychiatry, med management, and therapy - and the staffing and managing of inpatient psychiatric units in partnership with client hospitals. Mindoula is a market leader in managing the most complex Med/Psych and Speciality Populations, delivering a virtual Collaborative Care model, delivering telepsychiatry and teletherapy, and value based care.",
        "cleaned_desc": "  Collaborate closely with cross-functional teams to understand and define data requirements for adhoc queries and data validation requests. \n  Design and execute complex SQL queries and scripts to extract, transform, and analyze data from various sources, ensuring data accuracy and integrity. \n  Provide expert-level data validation to ensure data quality and consistency, identifying anomalies and inconsistencies in data sets. \n  Develop and maintain documentation for query and data validation processes, ensuring knowledge sharing and best practices across the team. \n  Perform exploratory data analysis to uncover trends, patterns, and insights that contribute to business and clinical objectives.    Collaborate with Data Engineers and BI Developers to optimize data pipelines and data warehousing processes for efficient data retrieval and analysis. \n  Create and present clear and actionable data visualizations and reports to communicate findings and insights to stakeholders. \n  Mentor and provide guidance to junior analysts, fostering a culture of continuous  \n \n What you'll need...   \n  Bachelor's in a relevant field such as Statistics, Mathematics, Computer Science, or a related quantitative discipline. \n  Proven experience (5+ years) as a Data Analyst, preferably in a healthcare, technology, or related industry. \n  Proficiency in SQL and experience with relational databases (e.g., MySQL, PostgreSQL). \n  Strong analytical and problem-solving skills, with the ability to translate complex data into meaningful insights.    Experience with data validation techniques and best practices to ensure data accuracy and integrity. \n  Proficiency in data visualization tools such as Tableau, Power BI, or similar tools. \n  Familiarity with scripting languages (e.g., Python) for data manipulation and analysis is a plus. \n  Excellent communication skills, with the ability to present findings and insights to both technical and non-technical stakeholders. \n  Detail-oriented mindset with the ability to manage multiple adhoc requests simultaneously. ",
        "techs": [
            "sql",
            "mysql",
            "postgresql",
            "tableau",
            "power bi",
            "python"
        ],
        "cleaned_techs": [
            "sql",
            "mysql",
            "postgresql",
            "tableau",
            "powerbi",
            "python"
        ]
    },
    "8461cc0f4a7471d6": {
        "terms": [
            "data science"
        ],
        "salary_min": 100000.0,
        "salary_max": 200000.0,
        "title": "Data Scientist",
        "company": "RenderWolf AI",
        "desc": "Who we are \n RenderWolf AI is on a mission to bring game creation to the masses. People of all ages across centuries have loved creating and playing games together. We believe that AI can empower everyone to create games for each other on the devices we use every day, using just their creative thinking and playful spirit. \n As an early member of our team, you will help build the future of how digital games are made using generative AI. The founders have over a decade of experience in tech. They previously worked together at AWS and Alexa building AI products for hundreds of millions of people, and built games played by millions worldwide at companies such as Zynga. \n What you will do in this role \n As an applied scientist at RenderWolf AI you will help us develop cutting-edge generative AI models to power creative products for game studios. Together, we will bring AI research to millions of users in the form of products and interfaces that were never possible before, and empower them to make entire games using simple natural language instructions. \n \n Apply cutting edge AI models and techniques to build product features that solve the needs of art teams at game studios \n Develop new generative AI models and techniques or improve existing models and techniques to help achieve our product vision \n Develop internal software tooling to automate mundane tasks, facilitate experimentation and prototyping of new models and techniques \n Stay tuned-in the the latest and greatest advancements in the field of generative AI \n \n What you need to excel in this role \n We are looking for candidates with a strong background building impactful and novel machine learning projects, strong software engineering skills and a desire to convert research into products that people love. \n \n BS or advanced degree in Computer Science; Computer Vision and/or AI research experience preferred \n Experience developing and executing major AI/ML project(s) at a company or as part of an academic research team \n Fluency with Python, C++, CUDA, and deep learning frameworks such as TensorFlow and PyTorch. \n Able to build simple software tools to improve research productivity through automation, experimentation, prototyping and evaluation. \n \n What we offer \n \n Compensation: Salary, options \n Remote work \n \n Job Types: Contract, Full-time \n Pay: $100,000.00 - $200,000.00 per year \n Supplemental pay types: \n \n Bonus opportunities \n Signing bonus \n \n Education: \n \n Master's (Preferred) \n \n Experience: \n \n Python: 5 years (Required) \n Natural language processing: 1 year (Preferred) \n Generative AI: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Develop internal software tooling to automate mundane tasks, facilitate experimentation and prototyping of new models and techniques \n Stay tuned-in the the latest and greatest advancements in the field of generative AI \n \n What you need to excel in this role \n We are looking for candidates with a strong background building impactful and novel machine learning projects, strong software engineering skills and a desire to convert research into products that people love. \n \n BS or advanced degree in Computer Science; Computer Vision and/or AI research experience preferred \n Experience developing and executing major AI/ML project(s) at a company or as part of an academic research team ",
        "techs": [
            "internal software tooling",
            "automation",
            "experimentation and prototyping",
            "machine learning projects",
            "software engineering",
            "research into products",
            "computer science",
            "computer vision",
            "ai research",
            "ai/ml projects"
        ],
        "cleaned_techs": [
            "internal software tooling",
            "automation",
            "experimentation and prototyping",
            "machine learning projects",
            "software engineering",
            "research into products",
            "computer science",
            "computer vision",
            "ai"
        ]
    },
    "b493abd39ed2bc85": {
        "terms": [
            "data science"
        ],
        "salary_min": 44849.9,
        "salary_max": 56789.97,
        "title": "Healthcare Communicator",
        "company": "Ashfield Nordic AB",
        "desc": "Inizio Engage has an immediate need for full time healthcare communicators to work from home across the nation and answer inbound calls from provider and patients on behalf of our client. This is an excellent opportunity to get into healthcare industry. Your day may include the following:\n  \n \n \n  Pre-screen potential volunteers for enrollment into clinical/medical research trials \n  Triage calls to appropriate personnel \n  Intake of product quality complaints \n  Handle DTC and patient Support programs \n  Provide drug/medical device product information \n  First level technical support \n  Enroll participants in educational seminars \n  Collect demographic data and disposition for product, sample and literature fulfillment \n \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Maintain excellent quality standards for all client programs; adhere to program scripts and guidelines. Accurately collect information required by individual programs and correctly capture in specific program databases. \n  Exhibit effective communication and tele-management skills. \n  Converse with callers in an empathetic manner and facilitate the callers in their ability to understand medical terminology, as needed. \n  Possess effective organizational skills, including working with multiple projects simultaneously. \n  Adhere to all company policies and Standard Operating Procedures. \n  Display flexibility within department to maximize utilization, including performing administrative and non-telecommunication duties as needed. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n   What do you need for this position?\n  \n \n \n  Customer service or equivalent work related experience is preferred \n  Excellent verbal, written and listening communication skills \n  Competency with a computer keyboard and mouse \n  Pleasant telephone manner \n \n \n \n   About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b70648c694589d9d": {
        "terms": [
            "data science"
        ],
        "salary_min": 44849.9,
        "salary_max": 56789.97,
        "title": "Healthcare Communicator",
        "company": "Ashfield Nordic AB",
        "desc": "Inizio Engage has an immediate need for full time healthcare communicators to work from home across the nation and answer inbound calls from provider and patients on behalf of our client. This is an excellent opportunity to get into healthcare industry. Your day may include the following:\n  \n \n \n  Pre-screen potential volunteers for enrollment into clinical/medical research trials \n  Triage calls to appropriate personnel \n  Intake of product quality complaints \n  Handle DTC and patient Support programs \n  Provide drug/medical device product information \n  First level technical support \n  Enroll participants in educational seminars \n  Collect demographic data and disposition for product, sample and literature fulfillment \n \n \n \n   This is your opportunity to join Inizio Engage and represent a top biotechnology company!\n  \n \n \n   What\u2019s in it for you?\n  \n \n \n  Competitive compensation \n  Excellent Benefits \u2013 accrued time off, medical, dental, vision, 401k, disability & life insurance, paid maternity and bonding time benefits, employee discounts/promotions \n  Generous performance-driven Incentive Compensation package \n  Competitive environment with company wide recognition, contests, and coveted awards \n  Exceptional company culture \n  Recognized as a Top Workplace USA 2021 \n  Awarded a \u201cGreat Place to Work\u201d award in 2022 and 2023 \n  Fortune Best Workplaces in Biopharma 2022 \n \n \n \n   What will you be doing?\n  \n \n \n  Maintain excellent quality standards for all client programs; adhere to program scripts and guidelines. Accurately collect information required by individual programs and correctly capture in specific program databases. \n  Exhibit effective communication and tele-management skills. \n  Converse with callers in an empathetic manner and facilitate the callers in their ability to understand medical terminology, as needed. \n  Possess effective organizational skills, including working with multiple projects simultaneously. \n  Adhere to all company policies and Standard Operating Procedures. \n  Display flexibility within department to maximize utilization, including performing administrative and non-telecommunication duties as needed. \n  Must safeguard patient privacy and confidentiality by following the guidelines set forth in the Privacy and Security Rules of the Health Insurance Portability and Accountability Act (HIPAA). \n \n \n \n   What do you need for this position?\n  \n \n \n  Customer service or equivalent work related experience is preferred \n  Excellent verbal, written and listening communication skills \n  Competency with a computer keyboard and mouse \n  Pleasant telephone manner \n \n \n \n   About Inizio Engage\n  \n \n \n  Inizio Engage is a strategic, commercial, and creative engagement partner that specializes in healthcare. Our passionate, global workforce augments local expertise and diverse mix of skills with data, science, and technology to deliver bespoke engagement solutions that help clients reimagine how they engage with their patients, payers, people and providers to improve treatment outcomes. Our mission is to partner with our clients, improving lives by helping healthcare professionals and patients get the medicines, knowledge and support they need.\n  \n \n \n   To learn more about Inizio Engage, visit us at: \n   \n   https://inizio.health/\n   \n \n \n \n   Inizio Engage is proud to be an equal opportunity employer. Individuals seeking employment at Inizio are considered without regards to age, ancestry, color, gender, gender identity or expression, genetic information, marital status, medical condition (including pregnancy, childbirth, or related medical conditions), mental or physical disability, national origin, protected family care or medical leave status, race, religion (including beliefs and practices or the absence thereof), sexual orientation, military or veteran status, or any other characteristic protected by federal, state, or local laws. Further, pursuant to applicable local ordinances, Inizio will consider for employment qualified applicants with arrest and conviction records.\n  \n \n \n   Inizio Engage is an equal opportunity employer M/F/V/D. We appreciate your interest in our company, however, only qualified candidates will be considered.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "0b276b36ba0cc4b5": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 35.0,
        "salary_max": 70.0,
        "title": "Freelance Data Analyst for Women's DTC Apparel and Accessories",
        "company": "lesley evers boutique co.",
        "desc": "Overview \n We are a growing women's Direct-to-Consumer (DTC) apparel and accessories brand seeking a Freelance Data Analyst with expertise in retail or e-commerce. Your role will involve observing and predicting sales demand, forecasting unit demand based on seasons, styles, and sizes, as well as analyzing sales by location. This position is critical for our business planning and strategy. \n Note:  A Non-Disclosure Agreement (NDA) is required  for this position. Although this is a remote role, we prefer the candidate to be based in US. \n Responsibilities \n Interpret data from various sources, such as sales, inventory, and customer databases, to identify trends and insights. \n Develop predictive models for sales demand, considering seasonal trends, styles, and size ratios. \n Conduct location-based analyses to identify market performance. \n Generate monthly reports to inform business decisions. \n Collaborate with cross-functional teams to implement data-driven strategies. \n Present findings to senior management in a clear and concise manner. \n Qualifications \n Bachelor\u2019s degree in Statistics, Mathematics, Computer Science, Business Analytics, or a related field. \n Minimum of 3 years of experience in data analysis, preferably in retail or e-commerce. \n Proficiency in SQL and Python or similar data analysis tools. \n Excellent analytical, problem-solving, and critical-thinking skills. \n Strong communication skills, both written and verbal. \n Ability to work independently and manage tasks effectively. \n Contract Terms \n This is a freelance, contract-based position. \n Payment will be project-based, to be negotiated based on experience and deliverables. \n Expected commitment of 5 hours per week. \n Job Type: Contract \n Pay: $35.00 - $70.00 per hour \n Expected hours: 5 per week \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n Choose your own hours \n \n Experience: \n \n Data science: 3 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Collaborate with cross-functional teams to implement data-driven strategies. \n Present findings to senior management in a clear and concise manner. \n Qualifications \n Bachelor\u2019s degree in Statistics, Mathematics, Computer Science, Business Analytics, or a related field. \n Minimum of 3 years of experience in data analysis, preferably in retail or e-commerce. \n Proficiency in SQL and Python or similar data analysis tools. \n Excellent analytical, problem-solving, and critical-thinking skills. \n Strong communication skills, both written and verbal. ",
        "techs": [
            "sql",
            "python"
        ],
        "cleaned_techs": [
            "sql",
            "python"
        ]
    },
    "d7c9950932199b08": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 95000.0,
        "salary_max": -1.0,
        "title": "Data Engineer",
        "company": "Ignite Digital Services",
        "desc": "Data Engineer \n Are you searching for an opportunity to take your career to the next level? Ignite Digital Services is a fast-growing small business delivering innovative business solutions to the national security sector. We bring data science and analytics together to optimize program integration and empower operational decisions for national security clients. \n Ignite Digital Services has a fantastic opportunity for a Data Engineer to support our client engagements within the federal government. The ideal candidate is a self-starter with strong analytical skills and a strong work ethic. This position serves an important role in supporting senior-level executive customers at Assistant Secretary of the Navy for Research, Development, and Acquisition (ASN/RDA) Research and Development to understand their business challenges within a multi-functional team and offer data centric solutions to enhance decision-making. \n Perks of Working at Ignite Digital Services: \n \n Competitive pay and benefits, including PTO \n Education stipends and referral bonuses \n Compelling work with the U.S. federal government \n Strong emphasis on volunteer and community engagement \n Opportunity to shape the future of our industry \n Supportive colleagues and management who invest in your growth \n \n Responsibilities: \n \n Develop, test, and deploy data pipelines within the Databricks platform to process, transform, and model data for use in analytic solutions leveraged by clients and end users for strategic decision making. \n Collaborate with SMEs to translate high-level business requirements into defined business rules and data transformations from source to target environments supporting key performance indicators & metrics. \n Data modeling and script development to support AI/ML models and Qlik dashboard solutions \n Identify methods to collect, analyze, and manage data with the goal of making recommendations to improve data quality and the efficiency of data processes \n Evaluate the performance and applicability of tools against customer and client requirements \n Foster collaborative business relationships with stakeholders, business partners, and team members \n \n Minimum Qualifications: \n \n Ability to obtain a DoD security clearance \n Bachelor\u2019s Degree in Computer Science, Information Technology, Data Science, Business, Economics or other related field \n 6+ years of technical experience with Business Intelligence and Data Analytics solutions \n 2+ years of experience implementing data pipelines supporting enterprise analytics and visualization platforms \n Experience with programming languages (R, Python, SQL, etc. ) for data transformation, modeling, and custom visualizations in cloud data platforms such as Databricks or Snowflake \n Hands on experience in performance tuning and optimizing code running in environments such as Apache Spark, Databricks, Snowflake, Cloudera, or Amazon EMR \n Experience working with a variety of stakeholders to translate business requirements into transformation logic and data schemas to support dashboards and analytics. \n Demonstrated experience in handling a variety of data formats such as JSON, CSV, Parquet, ORC, and Delta Lake. \n Ability to take initiative and work independently, and quickly transition to reassess priorities \n \n Preferred Qualifications: \n \n Active DoD security clearance \n Experience with DoD business practices and data management systems / processes like ADVANA/Jupiter tools including Databricks and Qlik \n Knowledge of the system development life cycle, software project management approaches and requirements, design and test techniques including experience working in a DevOps/DevSecOps delivery environment \n Experience in mentoring/training/coaching others in technical concepts \n Adapts quickly to new situations, is willing to learn new technologies and works well in a team environment, leading individual projects without the need for supervision \n \n *Ability to obtain a DoD Government Security Clearance is mandatory for this position* \n Salary: $95,000+ to align with education & experience \n Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information. \n Ignite Digital Services is a Small Business committed to providing exceptional service to government agencies at competitive prices. The capabilities and experience of our staff and our extensive industry relationships distinguish Ignite Digital Services among government contractors. \n Ignite Digital Services is an EEO/AA/Disability/VETS Employer. Hiring, promotion, transfer, compensation, benefits, discipline, termination, and all other employment decisions are made without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, citizenship/immigration status, veteran status, or any other protected status. \n For individuals who would like to request an accommodation, please visit https://bit.ly/2XqZoLM(CA) or https://bit.ly/3Eo922f(SC) or contact Human Resources. Ignite Digital Services will not make any posting or employment decision that does not comply with applicable laws relating to labor and employment, equal employment opportunity, employment eligibility requirements or related matters. Nor will Ignite Digital Services require, in a posting or otherwise, U.S. citizenship or lawful permanent residency in the U.S. as a condition of employment except as necessary to comply with law, regulation, executive order, or federal, state, or local government contract. \n AAP - Atlas Executive Consulting LLC (CA) 2022 Policy Statement \n OFCCP'S Pay Transparency Rule \n EEO is the Law Poster \n AAP - Atlas Executive Consulting LLC (SC) 2022 Policy Statement \n Job Type: Full-time \n Pay: From $95,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 6 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n SQL: 6 years (Preferred) \n Data warehouse: 6 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Develop, test, and deploy data pipelines within the Databricks platform to process, transform, and model data for use in analytic solutions leveraged by clients and end users for strategic decision making. \n Collaborate with SMEs to translate high-level business requirements into defined business rules and data transformations from source to target environments supporting key performance indicators & metrics. \n Data modeling and script development to support AI/ML models and Qlik dashboard solutions \n Identify methods to collect, analyze, and manage data with the goal of making recommendations to improve data quality and the efficiency of data processes \n Evaluate the performance and applicability of tools against customer and client requirements \n Foster collaborative business relationships with stakeholders, business partners, and team members \n \n Minimum Qualifications: \n \n Ability to obtain a DoD security clearance \n Bachelor\u2019s Degree in Computer Science, Information Technology, Data Science, Business, Economics or other related field \n 6+ years of technical experience with Business Intelligence and Data Analytics solutions \n 2+ years of experience implementing data pipelines supporting enterprise analytics and visualization platforms \n Experience with programming languages (R, Python, SQL, etc. ) for data transformation, modeling, and custom visualizations in cloud data platforms such as Databricks or Snowflake   Hands on experience in performance tuning and optimizing code running in environments such as Apache Spark, Databricks, Snowflake, Cloudera, or Amazon EMR \n Experience working with a variety of stakeholders to translate business requirements into transformation logic and data schemas to support dashboards and analytics. \n Demonstrated experience in handling a variety of data formats such as JSON, CSV, Parquet, ORC, and Delta Lake. \n Ability to take initiative and work independently, and quickly transition to reassess priorities \n \n Preferred Qualifications: \n \n Active DoD security clearance \n Experience with DoD business practices and data management systems / processes like ADVANA/Jupiter tools including Databricks and Qlik \n Knowledge of the system development life cycle, software project management approaches and requirements, design and test techniques including experience working in a DevOps/DevSecOps delivery environment \n Experience in mentoring/training/coaching others in technical concepts \n Adapts quickly to new situations, is willing to learn new technologies and works well in a team environment, leading individual projects without the need for supervision \n \n *Ability to obtain a DoD Government Security Clearance is mandatory for this position* ",
        "techs": [
            "databricks",
            "ai/ml models",
            "qlik",
            "r",
            "python",
            "sql",
            "snowflake",
            "apache spark",
            "cloudera",
            "amazon emr",
            "json",
            "csv",
            "parquet",
            "orc",
            "delta lake",
            "advana/jupiter",
            "devops/devsecops"
        ],
        "cleaned_techs": [
            "databricks",
            "ai",
            "qlik",
            "r",
            "python",
            "sql",
            "snowflake",
            "apache spark",
            "cloudera",
            "aws",
            "json",
            "csv",
            "parquet",
            "orc",
            "delta lake",
            "advana/jupiter",
            "devops/devsecops"
        ]
    },
    "a777331336a01f77": {
        "terms": [
            "data science"
        ],
        "salary_min": 122172.0,
        "salary_max": 167986.0,
        "title": "Senior Manager, Data Insights",
        "company": "ecoATM Gazelle",
        "desc": "At ecoATM the proof of our success is in our staggering growth, extraordinary impact on protecting the planet, and providing a work culture unlike any other. We are a technology company and a pioneer of device re-commerce. Through our 5000+ automated kiosks we enable people all over the world to join the mobile device re-use revolution, a revolution that will get billions of used smartphones out of the e-waste cycle and into the hands of people who don\u2019t have affordable access to the empowerment of the latest mobile technology. At ecoATM we know our employees are our greatest strength and the key to our continued growth and success. When you join our team, you will enjoy more than just a job, you will be empowered to develop and utilize your unique talents and skills to build a rewarding career while making a lasting, positive impact on the planet.\n     \n \n Position Details \n \n \n   We are seeking a talented, self-starter candidate for the role of \n     Sr. Manager, Data Insights , in a role that will proactively support the omni-channel ecoATM business teams and critical enterprise-wide projects through data driven insights. You will have the opportunity to work on a broad spectrum of areas which will include projects such as delivering insights on our kiosk network performance (hardware and software), growth initiative business case development and tracking, kiosk real estate deployment analytics, and seeking out efficiency opportunities across critical workstreams with third party vendors.\n      Responsibilities \n  The position requires an individual with demonstrated results identifying patterns, trends and correlations in data to deliver practical business insights that drive growth. As a key member of Planning and Analytics team, this individual will: \n \n  Leverage various statistical analysis techniques to help the organization make informed, data-driven decisions. This includes data mining, regression analysis, time-series analysis, optimization techniques, decision trees, etc. \n  Collaborate with stakeholders (at all levels) and team members to provide recommendations and implement operating best practices \n \n \n  Perform root cause analyses, remediation, and process improvements to strengthen operational controls and enhance business processes \n  Assist with improving current testing standards to drive data integrity, ensuring back-end data connections and workflows are efficient and stable while maintaining reliable and accurate front-end dashboard reports \n  Continuously seek out opportunities to streamline and standardize the business process and enhance operational controls and efficiencies \n  Lead cross-functional implementation of business case development to prioritize high ROI growth project investment opportunities \n  Interact with different levels of management and articulate/present issues clearly and succinctly \n \n  Education & Experience \n \n  Bachelor's degree with 8 plus years of experience in business, finance/economics, math, data science, or similar field \n  Demonstrated success in an omni-channel business of driving revenue and profitability with business process and analysis through strong analytical and problem-solving skills \n \n  Knowledge, Skills & Abilities \n \n  Demonstrated intellectual curiosity and comfort with large data sets where operational insights are not readily apparent; Experience building business case rational for new, revenue growth initiatives \n  Demonstrated success working as a trusted partner to operational business teams with an ability to set direction, ensuring working groups meet project deliverables, and arrive at aligned outcomes; Demonstrated ability to thrive in a complex environment \n  Proven, practical success working with various data types, both structured and unstructured, as well as experience leveraging SQL, R functions, Alteryx, and models in Tableau is preferred \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   \n Business Travel \n \n \n \n \n \n                   <5%\n                  \n \n \n \n \n   \n Location \n \n \n \n \n                   Remote, United States\n                  \n \n \n \n \n   \n Pay Range \n \n \n \n \n                   $122,172 - $167,986 (annually)\n                  \n \n \n \n \n  Base pay offered may vary depending on job-related knowledge, skills, and experience. This information is provided per CA SB 1162 (\u201cCA Pay Transparency Law\u201d). Base pay information is based on market location. This position may also be eligible for short-term and long-term incentives based on individual and company performance.\n                  \n \n \n \n \n  This job description is not intended to be all-inclusive. Employee may perform other related duties as assigned to meet the ongoing needs of the organization.",
        "cleaned_desc": "  Lead cross-functional implementation of business case development to prioritize high ROI growth project investment opportunities \n  Interact with different levels of management and articulate/present issues clearly and succinctly \n \n  Education & Experience \n \n  Bachelor's degree with 8 plus years of experience in business, finance/economics, math, data science, or similar field \n  Demonstrated success in an omni-channel business of driving revenue and profitability with business process and analysis through strong analytical and problem-solving skills \n \n  Knowledge, Skills & Abilities \n \n  Demonstrated intellectual curiosity and comfort with large data sets where operational insights are not readily apparent; Experience building business case rational for new, revenue growth initiatives \n  Demonstrated success working as a trusted partner to operational business teams with an ability to set direction, ensuring working groups meet project deliverables, and arrive at aligned outcomes; Demonstrated ability to thrive in a complex environment \n  Proven, practical success working with various data types, both structured and unstructured, as well as experience leveraging SQL, R functions, Alteryx, and models in Tableau is preferred \n \n \n \n \n ",
        "techs": [
            "sql",
            "r functions",
            "alteryx",
            "tableau"
        ],
        "cleaned_techs": [
            "sql",
            "r functions",
            "alteryx",
            "tableau"
        ]
    },
    "5924960c047a9bd1": {
        "terms": [
            "data science"
        ],
        "salary_min": 110350.56,
        "salary_max": 139728.4,
        "title": "Data Visualization Developer 4725",
        "company": "MetroStar",
        "desc": "As  Data Visualization Developer , you'll possess a deep understanding of data visualization best practices, along with technical proficiency in various visualization tools and programming languages. You will also have a proven track record of creating impactful and interactive visualizations. \n  We know that you can't have great technology services without amazing people. At MetroStar, we are  obsessed  with   our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers. \n  If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below! \n  What you'll do: \n \n Collaborate with cross-functional teams including data analysts, engineers, and designers to understand data requirements and visualization objectives. \n Design and develop interactive and intuitive data visualizations, dashboards, and reports that effectively communicate insights and trends. \n Transform complex datasets into visually compelling stories that provide clear and actionable insights for internal stakeholders and clients. \n Utilize data visualization tools such as Tableau, Power BI, D3.js, or others to create a wide range of visualizations including charts, graphs, maps, and custom visual elements. \n Write custom code and scripts to enhance visualization capabilities and ensure optimal performance. \n Stay up-to-date with the latest trends and advancements in data visualization techniques, tools, and technologies. \n Optimize visualizations for different devices and screen sizes to ensure a seamless user experience. \n Ensure data accuracy, consistency, and integrity in visualizations, collaborating closely with data engineers to validate results. \n Participate in design reviews, provide constructive feedback, and contribute to the evolution of the visualization development process. \n \n What you'll need to succeed: \n \n Bachelor's degree in Computer Science, Data Science, Information Design, or a related field. \n Minimum of 5 years of professional experience as a Data Visualization Developer or in a similar role. \n Proficiency in data visualization tools such as Tableau, Power BI, Pentaho, and BIRT. \n Strong programming skills in languages like JavaScript, Python, or R for creating custom visualizations and interactions. \n Solid understanding of data manipulation, transformation, and cleaning techniques. \n Experience with database systems and SQL for extracting and transforming data. \n Demonstrated portfolio of successful data visualizations that showcase a keen eye for design and effective communication of insights. \n Strong analytical and problem-solving skills, with the ability to grasp complex data sets and distill them into meaningful visual stories. \n Excellent communication and collaboration skills, with the ability to translate business requirements into visual solutions. \n Knowledge of UX/UI design principles and best practices for creating user-friendly interfaces. \n Familiarity with version control systems (e.g., Git) and collaborative development workflows. \n \n Like we said,  we are  big fans of our people. That's why  we offer  a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades. \n  Don't meet every single requirement?  \n Studies have shown that women, people of color and the LGBTQ+ community are less likely to apply to jobs unless they meet every single qualification. At MetroStar we are dedicated to building a diverse, inclusive, and authentic culture, so, if you're excited about this role, but your previous experience doesn't align perfectly with every qualification in the job description, we encourage you to go ahead and apply. We pride ourselves on making great matches, and you may be the perfect match for this role or another one we have. Best of luck! \u2013 The MetroStar People & Culture Team \n  What we want you to know: \n  In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. \n  MetroStar Systems is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of MetroStar Systems. \n  Not ready to apply now? \n  Sign up to join our newsletter here.",
        "cleaned_desc": " Transform complex datasets into visually compelling stories that provide clear and actionable insights for internal stakeholders and clients. \n Utilize data visualization tools such as Tableau, Power BI, D3.js, or others to create a wide range of visualizations including charts, graphs, maps, and custom visual elements. \n Write custom code and scripts to enhance visualization capabilities and ensure optimal performance. \n Stay up-to-date with the latest trends and advancements in data visualization techniques, tools, and technologies. \n Optimize visualizations for different devices and screen sizes to ensure a seamless user experience. \n Ensure data accuracy, consistency, and integrity in visualizations, collaborating closely with data engineers to validate results. \n Participate in design reviews, provide constructive feedback, and contribute to the evolution of the visualization development process.   \n What you'll need to succeed: \n \n Bachelor's degree in Computer Science, Data Science, Information Design, or a related field. \n Minimum of 5 years of professional experience as a Data Visualization Developer or in a similar role. \n Proficiency in data visualization tools such as Tableau, Power BI, Pentaho, and BIRT. \n Strong programming skills in languages like JavaScript, Python, or R for creating custom visualizations and interactions.   Solid understanding of data manipulation, transformation, and cleaning techniques. \n Experience with database systems and SQL for extracting and transforming data. \n Demonstrated portfolio of successful data visualizations that showcase a keen eye for design and effective communication of insights. \n Strong analytical and problem-solving skills, with the ability to grasp complex data sets and distill them into meaningful visual stories. \n Excellent communication and collaboration skills, with the ability to translate business requirements into visual solutions. \n Knowledge of UX/UI design principles and best practices for creating user-friendly interfaces. \n Familiarity with version control systems (e.g., Git) and collaborative development workflows. ",
        "techs": [
            "tableau",
            "power bi",
            "d3.js",
            "javascript",
            "python",
            "r",
            "sql",
            "git"
        ],
        "cleaned_techs": [
            "tableau",
            "powerbi",
            "d3.js",
            "javascript",
            "python",
            "r",
            "sql",
            "git"
        ]
    },
    "09e5ea8e97a37194": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 127000.0,
        "salary_max": 211600.0,
        "title": "Principal Data Engineer",
        "company": "Blueprint Technologies",
        "desc": "Principal Date Engineer Remote \n  Who is Blueprint? \n  We are a technology solutions firm headquartered in Bellevue, Washington, with a strong presence across the United States. Unified by a shared passion for solving complicated problems, our people are our greatest asset. We use technology as a tool to bridge the gap between strategy and execution, powered by the knowledge, skills, and the expertise of our teams, who all have unique perspectives and years of experience across multiple industries. We're bold, smart, agile, and fun. \n  What does Blueprint do? \n  Blueprint helps organizations unlock value from existing assets by leveraging cutting-edge technology to create additional revenue streams and new lines of business. We connect strategy, business solutions, products, and services to transform and grow companies. \n  Why Blueprint? \n  At Blueprint, we believe in the power of possibility and are passionate about bringing it to life. Whether you join our bustling product division, our multifaceted services team or you want to grow your career in human resources, your ability to make an impact is amplified when you join one of our teams. You'll focus on solving unique business problems while gaining hands-on experience with the world's best technology. We believe in unique perspectives and build teams of people with diverse skillsets and backgrounds. At Blueprint, you'll have the opportunity to work with multiple clients and teams, such as data science and product development, all while learning, growing, and developing new solutions. We guarantee you won't find a better place to work and thrive than at Blueprint. \n  What will I be doing? \n  Blueprint is looking for a  Principal Data Engineer  to join us as we build cutting-edge technology solutions! The ideal candidate will have a solid background in consulting, with demonstrated experience leading clients through the process of building modern data estates. As a Principal Data Engineer, you will spend a majority of your time working directly with clients to develop their advanced modern data estates, warehouses, and analytical environments. You will also be responsible for overseeing and mentoring junior developers within the organization. \n  Responsibilities: \n \n Develop and implement effective data architecture solutions using Databricks and Lakehouse \n Optimize and tune data pipelines for performance and scalability \n Monitor and troubleshoot data pipelines to ensure data availability and reliability \n Collaborate with data scientists, analysts, and other stakeholders to understand their data needs and build solutions that enable them to extract insights from data \n Implement best practices for data governance, data security, and data quality to ensure data integrity across all data sources \n Create and maintain documentation related to data architecture, data pipelines, and data models \n Stay up to date with emerging technologies and best practices in data engineering and big data processing \n Mentor and train other data engineers on best practices for data engineering and Databricks usage \n Provide thought leadership in the Databricks and Lakehouse space, both within the organization and externally \n \n Qualifications: \n \n Bachelor's or Master's degree in Computer Science, Computer Engineering, or a related field \n 8+ years of experience in data engineering \n 3+ years of experience working with Databricks and PySpark \n 6-8+ years of experience with SQL \n Appreciation for the Lakehouse medallion data architecture \u2013 bronze, silver, gold \u2013 and how those data stages are used \n Working knowledge of DLT(Delta Live Tables) and Unity Catalog a plus \n Strong understanding of ETL and ELT data ingestion, acquisition, and data processing patterns \n Experience with cloud-based data warehousing platforms such as Synapse, AWS Redshift, Google BigQuery, or Snowflake \n Strong understanding of data engineering, data warehousing, data modeling, data governance, and data security best practices \n Excellent problem-solving and troubleshooting skills \n Strong communication and collaboration skills, with the ability to work effectively in a team environment \n Experience mentoring and training other data engineers \n \n Salary Range \n  Pay ranges vary based on multiple factors including, without limitation, skill sets, education, responsibilities, experience, and geographical market. The pay range for this position reflects geographic based ranges for Washington state: $127,000 to $211,600 USD/annually. The salary/wage and job title for this opening will be based on the selected candidate's qualifications and experience and may be outside this range. \n \n \n  Equal Opportunity Employer \n  Blueprint Technologies, LLC is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, age, disability, sex, gender identity or expression, orientation, veteran/military status, religion, national origin, ancestry, marital, or familial status, genetic information, citizenship, or any other status protected by law. \n  If you need assistance or a reasonable accommodation to complete the application process, please reach out to: recruiting@bpcs.com \n  Blueprint believe in the importance of a healthy and happy team, which is why our comprehensive benefits package includes: \n \n Medical, dental, and vision coverage \n Flexible Spending Account \n 401k program \n Competitive PTO offerings \n Parental Leave \n Opportunities for professional growth and development \n \n Location:  Remote",
        "cleaned_desc": " \n Develop and implement effective data architecture solutions using Databricks and Lakehouse \n Optimize and tune data pipelines for performance and scalability \n Monitor and troubleshoot data pipelines to ensure data availability and reliability \n Collaborate with data scientists, analysts, and other stakeholders to understand their data needs and build solutions that enable them to extract insights from data \n Implement best practices for data governance, data security, and data quality to ensure data integrity across all data sources \n Create and maintain documentation related to data architecture, data pipelines, and data models \n Stay up to date with emerging technologies and best practices in data engineering and big data processing \n Mentor and train other data engineers on best practices for data engineering and Databricks usage \n Provide thought leadership in the Databricks and Lakehouse space, both within the organization and externally   \n Qualifications: \n \n Bachelor's or Master's degree in Computer Science, Computer Engineering, or a related field \n 8+ years of experience in data engineering \n 3+ years of experience working with Databricks and PySpark \n 6-8+ years of experience with SQL \n Appreciation for the Lakehouse medallion data architecture \u2013 bronze, silver, gold \u2013 and how those data stages are used \n Working knowledge of DLT(Delta Live Tables) and Unity Catalog a plus \n Strong understanding of ETL and ELT data ingestion, acquisition, and data processing patterns   Experience with cloud-based data warehousing platforms such as Synapse, AWS Redshift, Google BigQuery, or Snowflake \n Strong understanding of data engineering, data warehousing, data modeling, data governance, and data security best practices \n Excellent problem-solving and troubleshooting skills \n Strong communication and collaboration skills, with the ability to work effectively in a team environment \n Experience mentoring and training other data engineers \n \n Salary Range \n  Pay ranges vary based on multiple factors including, without limitation, skill sets, education, responsibilities, experience, and geographical market. The pay range for this position reflects geographic based ranges for Washington state: $127,000 to $211,600 USD/annually. The salary/wage and job title for this opening will be based on the selected candidate's qualifications and experience and may be outside this range. \n \n ",
        "techs": [
            "databricks",
            "lakehouse",
            "pyspark",
            "sql",
            "dlt (delta live tables)",
            "unity catalog",
            "synapse",
            "aws redshift",
            "google bigquery",
            "snowflake"
        ],
        "cleaned_techs": [
            "databricks",
            "lakehouse",
            "pyspark",
            "sql",
            "dlt (delta live tables)",
            "unity catalog",
            "synapse",
            "aws",
            "google bigquery",
            "snowflake"
        ]
    },
    "dfc339ef619f07f4": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Data Scientist",
        "company": "RR Donnelley",
        "desc": "RRD is seeking a Senior Data Scientist to join our team! \n \n   \n The qualified candidate must be an experienced data scientist with strong communication skills- able to blend technical skills, analytical expertise, and business acumen. The Senior Data Scientist will assist with the design, execution, and delivery of strategic analytics and insights for RRD\u2019s clients and select internal constituencies. \n \n \n  The position will have a broad scope of responsibility, including statistical analysis, strategy development, testing, and ROI optimization. He or she will gain experience across a variety of clients and applications and interact with various functional areas (Business Units, Marketing and Technology) and industries. The Senior Data Scientist must be comfortable both performing and presenting analysis at all levels of detail. The position will be charged with the effective management of client marketing strategy, deepening and strengthening performance, and RRD\u2019s relationships with clients. \n \n \n  Primary Responsibilities \n \n \n \n Design and scope analytical projects: formulate methodology, establish data requirements, identify client deliverables, determine tasks and timing \n Work with internal teams to address client business problems, set expectations, communicate progress and issues, produce results, and deliver findings to clients in a highly professional manner \n Apply statistical methods and execute analyses, such as: build targeting models, develop segmentation schemes, create test designs, develop trigger programs, measure program performance, identify and implement optimization techniques, compute performance lift and ROI \n Acquire and aggregate data from a variety of sources; audit contents and ensure proper usage of data fields; merge, summarize, and transform data as required for analysis \n Keep informed of leading-edge techniques and technologies; acquire training and new skills/knowledge to support development of analytical offering \n Identify growths opportunities within existing clients \n Responsible for helping to identify industry trends and opportunities to strengthen the Analytics and Business Intelligence teams \n Assist in the guidance and mentorship of junior analysts on the team \n Gain \u201cworking knowledge\u201d of technologies required to keep RRD \u201cleading\u2010edge\u201d \n Travel as necessary \n \n \n \n  Required Skills\n  \n \n Strong understanding of marketing strategy and analysis, campaign targeting, test design and measurement \n Expert level familiarity with statistical techniques such as multivariate regression, linear regression, logistic regression, cluster analysis, and CHAID/CART modeling and basic experimental design \n Exposure to advanced analytic techniques such as machine learning, pattern recognition, sentiment analysis, network analysis, graph analysis, simulation, complex event processing, boosting models, ensemble models, keras/tensorflow, etc. \n Capable of working in a dynamic environment, handling multiple projects, meeting deadlines, able to prioritize appropriately and respond to issues quickly and creatively \n Demonstrated strength in effective written and oral communication. Ability to present technical/statistical findings to non-technical audiences \n \n \n \n \n  Required Experience\n  \n \n Bachelor's degree in a quantitative discipline required. Higher education in statistics, mathematics, data sciences, economics, analytic MBA or other quantitative graduate degree strongly preferred \n Qualified candidates need to possess 5+ years of analytic consulting experience \n Hands-on experience using data query and analytic tools such as SAS, R, SQL, and Python. Must be able to work with large databases (querying, joining, summarizing) to create analytic datasets and execute analyses \n Experience with noSQL; streaming data, big data, Python data structures, tuples, dictionaries, etc. \n Experience with data visualization (e.g., Tableau, R, Python), machine learning (e.g., Weka, mlpy), cloud platforms (e.g., AWS) a plus \n Experience with advanced experimental design, time series forecasting, media mix modeling, text mining, web analytics, natural language processing and/or pricing experience is a plus \n Experience with direct client contact and presentations is strongly preferred. \n \n \n \n  The national pay range for this role is $109,800 to $222,000 / year. The pay range may be slightly lower or higher based on the geographic location of the hired employee. The actual pay offered may vary based upon, but not limited to: education, skills, experience, proficiency, performance, shift and location. In addition to base salary, depending on the role, the total compensation package may also include participation in a bonus, commission or incentive program. RRD offers benefits including medical, dental, and vision coverage, paid time off, disability insurance, 401(k) with match, life insurance and other voluntary supplemental insurance coverages, plus tuition assistance, maternity leave, adoption assistance, and employer/partner discounts.",
        "cleaned_desc": " \n \n \n Design and scope analytical projects: formulate methodology, establish data requirements, identify client deliverables, determine tasks and timing \n Work with internal teams to address client business problems, set expectations, communicate progress and issues, produce results, and deliver findings to clients in a highly professional manner \n Apply statistical methods and execute analyses, such as: build targeting models, develop segmentation schemes, create test designs, develop trigger programs, measure program performance, identify and implement optimization techniques, compute performance lift and ROI \n Acquire and aggregate data from a variety of sources; audit contents and ensure proper usage of data fields; merge, summarize, and transform data as required for analysis \n Keep informed of leading-edge techniques and technologies; acquire training and new skills/knowledge to support development of analytical offering \n Identify growths opportunities within existing clients \n Responsible for helping to identify industry trends and opportunities to strengthen the Analytics and Business Intelligence teams   Expert level familiarity with statistical techniques such as multivariate regression, linear regression, logistic regression, cluster analysis, and CHAID/CART modeling and basic experimental design \n Exposure to advanced analytic techniques such as machine learning, pattern recognition, sentiment analysis, network analysis, graph analysis, simulation, complex event processing, boosting models, ensemble models, keras/tensorflow, etc. \n Capable of working in a dynamic environment, handling multiple projects, meeting deadlines, able to prioritize appropriately and respond to issues quickly and creatively \n Demonstrated strength in effective written and oral communication. Ability to present technical/statistical findings to non-technical audiences \n \n \n \n \n  Required Experience\n    \n Bachelor's degree in a quantitative discipline required. Higher education in statistics, mathematics, data sciences, economics, analytic MBA or other quantitative graduate degree strongly preferred \n Qualified candidates need to possess 5+ years of analytic consulting experience \n Hands-on experience using data query and analytic tools such as SAS, R, SQL, and Python. Must be able to work with large databases (querying, joining, summarizing) to create analytic datasets and execute analyses \n Experience with noSQL; streaming data, big data, Python data structures, tuples, dictionaries, etc. \n Experience with data visualization (e.g., Tableau, R, Python), machine learning (e.g., Weka, mlpy), cloud platforms (e.g., AWS) a plus \n Experience with advanced experimental design, time series forecasting, media mix modeling, text mining, web analytics, natural language processing and/or pricing experience is a plus \n Experience with direct client contact and presentations is strongly preferred. \n \n ",
        "techs": [
            "formulate methodology",
            "establish data requirements",
            "identify client deliverables",
            "determine tasks and timing",
            "sas",
            "r",
            "sql",
            "python",
            "nosql",
            "tableau",
            "aws",
            "weka",
            "mlpy"
        ],
        "cleaned_techs": [
            "formulate methodology",
            "establish data requirements",
            "identify client deliverables",
            "determine tasks and timing",
            "sas",
            "r",
            "sql",
            "python",
            "nosql",
            "tableau",
            "aws",
            "weka",
            "mlpy"
        ]
    },
    "0436b02197abe5c8": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "8a65065d00bfedb6": {
        "terms": [
            "data science"
        ],
        "salary_min": 60.0,
        "salary_max": 65.0,
        "title": "Data Science Lead Trainer",
        "company": "Institute of Data",
        "desc": "About the Institute of Data \n The Institute of Data is a Professional Network of Data Scientists, Cyber Security Analysts and Software Engineering. In partnership with leading universities in Australia, New Zealand & America, the government of Singapore and hundreds of employers, we transform careers for a data-driven world. \n About the role \n We are looking for Lead Trainers to lead this transformative experience in partnership with  University of Louisiana Layafette and Virginia Commonwealth University . The work is  remote  in virtual classroom and with classes of up to 15 students. \n Next cohort:  Mondays & Wednesdays 6-9pm  and  fortnightly Saturdays 9am-5pm from 6 November 2023 to 4 May 2024.  Note this is Louisiana Central time. \n The content is provided and covers how to apply machine learning and AI techniques for businesses and government organisations including business consulting and simulating commercial projects. Assessment is in the form of labs and project work. Students graduating from the course are well-equipped to take on junior data analyst roles. \n \n Deliver cirriculum and support students to enter the industry \n Provide students with meaningful and prompt feedback on their progress \n Guide students through the development of real-world projects that will showcase their abilities to hiring managers \n Facilitate a dynamic and collaborative classroom community \n Inspire students to persevere through the challenges of learning complex subjects. \n Work with and guide Assistant Trainer to provide support to students. \n \n About you \n \n Minimum 5 years of professional data science experience. \n Expert in SQL, Python, and related Python libraries (pandas, numpy). \n Domain expertise in statistics, mathematics, and probability. \n Ability to build and apply statistical models in python using machine learning libraries, such as scikit-learn and statsmodels. \n Deep understanding of statistical hypothesis testing and experimental design, data visualisation techniques and tools (i.e. matplotlib, bokeh, etc), and manipulation of large data sets. \n Demonstrate and explain the function of machine learning algorithms such as regularised regression, naive bayes, decision trees, ensemble methods, KNN, K-means clustering, and neural networks. \n Excellent verbal communication with the ability to express technical material in an accessible way \n Desire to help others learn and grow and comfortable in a classroom environment. \n \n Culture & Benefits \n \n Remote work \n Contract opportunities outside of business hours \n Work in a fun supportive virtual environment \n Make a life-changing impact by doing what you know and love \n Speaking opportunities at industry events \n \n Job Types: Contract, Part-time \n Salary: $60.00 - $65.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n Evening shift \n Weekends as needed \n \n Application Question(s): \n \n The hours required are in Central Time: Mondays and Wednesdays 6-9pm and fortnightly Saturdays 9am-5pm. Are you able to commit to this? \n The dates are 6 November 2023 to 4 May 2024. Are you able to commit to this? \n \n Experience: \n \n Data science: 10 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Facilitate a dynamic and collaborative classroom community \n Inspire students to persevere through the challenges of learning complex subjects. \n Work with and guide Assistant Trainer to provide support to students. \n \n About you \n \n Minimum 5 years of professional data science experience. \n Expert in SQL, Python, and related Python libraries (pandas, numpy). \n Domain expertise in statistics, mathematics, and probability. \n Ability to build and apply statistical models in python using machine learning libraries, such as scikit-learn and statsmodels.   Deep understanding of statistical hypothesis testing and experimental design, data visualisation techniques and tools (i.e. matplotlib, bokeh, etc), and manipulation of large data sets. \n Demonstrate and explain the function of machine learning algorithms such as regularised regression, naive bayes, decision trees, ensemble methods, KNN, K-means clustering, and neural networks. \n Excellent verbal communication with the ability to express technical material in an accessible way \n Desire to help others learn and grow and comfortable in a classroom environment. \n \n Culture & Benefits \n \n Remote work \n Contract opportunities outside of business hours \n Work in a fun supportive virtual environment ",
        "techs": [
            "sql",
            "python",
            "pandas",
            "numpy",
            "scikit-learn",
            "statsmodels",
            "matplotlib",
            "bokeh",
            "regularised regression",
            "naive bayes",
            "decision trees",
            "ensemble methods",
            "knn",
            "k-means clustering",
            "neural networks"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "pandas",
            "numpy",
            "scikit-learn",
            "statsmodels",
            "matplotlib",
            "bokeh",
            "regularised regression",
            "naive bayes",
            "decision trees",
            "ensemble methods",
            "knn",
            "k-means clustering",
            "neural networks"
        ]
    },
    "9a1f47dbbd0904d6": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "25b4167edd42bac6": {
        "terms": [
            "data science"
        ],
        "salary_min": 93349.34,
        "salary_max": 118201.08,
        "title": "Data Scientist (II) \u2013 Generative AI",
        "company": "HP",
        "desc": "** Locations include Spring, Texas (preferred location), and US remote.   ** Typically need at least Master's degree and minimum 0-2 years full-time relevant work experience. \n \n  The Team \n  We are a growing centralized team helping HP take advantage of new AI/ML technology, especially around Generative AI and large language models. We engage with business units to advise and prototype solutions, and we develop and run software applications for internal use. \n \n  The Role \n  As a Data Scientist with a focus on Generative AI you will work on multiple engagements across HP involving large language models and other new Generative AI capabilities. Beyond our team, you will work with business stakeholders and developers from other business units. Your primary focus and mindset is to help deliver business solutions to our (mostly internal) customers. You are expected to stay up to date on important new Gen AI papers and releases, but note that this is not an AI research role. \n \n  Skills and Profile \n \n Knowledge of data science and machine learning core skills. \n Experience with NLP, Large Language Models, LLM prompt engineering, vector databases, Retrieval Augmented Generation (RAG), and search engines. \n Good computer science skills. Experience in a software development team is a big plus, especially with business applications in a cloud environment. \n Tools you may use include Azure services such as Azure Machine Learning and Azure prompt flow, as well as python, langchain, streamlit, docker, git, and elastic search. \n Some experience from a large complex organization is a plus. \n Ability to participate in meetings with a multitude of stakeholders and communicate in a crisp manner. Mastery in English is required. \n You enjoy explaining technical concepts (such as LLM's) to a non-technical audience. \n You propose pragmatic solutions that are as simple as possible, which sometimes mean that no Gen AI component is necessary. \n Interest in working in a distributed team with diverse backgrounds. \n The recent AI progress is disruptive, and our team is in the midst of it. As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value \"business as usual\". \n \n \n  Education and Length of Experience  For this position, we prefer at least a relevant Master's degree (e.g. Computer Science) or demonstrated competence, and a minimum of 0-2 years experience. \n \n  About HP \n \n \n \n \n \n  You\u2019re out to reimagine and reinvent what\u2019s possible\u2014in your career as well as the world around you.\n  \n \n   So are we. We love taking on tough challenges, disrupting the status quo, and creating what\u2019s next. We\u2019re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n  \n \n \n \n   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n  \n \n \n \n   Our history: HP\u2019s commitment to diversity, equity and inclusion \u2013 it's just who we are.\n  \n \n   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u2019re more innovative and that helps grow our bottom line. Come to HP and thrive!",
        "cleaned_desc": " \n Knowledge of data science and machine learning core skills. \n Experience with NLP, Large Language Models, LLM prompt engineering, vector databases, Retrieval Augmented Generation (RAG), and search engines. \n Good computer science skills. Experience in a software development team is a big plus, especially with business applications in a cloud environment. \n Tools you may use include Azure services such as Azure Machine Learning and Azure prompt flow, as well as python, langchain, streamlit, docker, git, and elastic search. \n Some experience from a large complex organization is a plus. \n Ability to participate in meetings with a multitude of stakeholders and communicate in a crisp manner. Mastery in English is required. \n You enjoy explaining technical concepts (such as LLM's) to a non-technical audience. \n You propose pragmatic solutions that are as simple as possible, which sometimes mean that no Gen AI component is necessary. ",
        "techs": [
            "nlp",
            "large language models",
            "llm prompt engineering",
            "vector databases",
            "retrieval augmented generation (rag)",
            "search engines",
            "azure machine learning",
            "azure prompt flow",
            "python",
            "langchain",
            "streamlit",
            "docker",
            "git",
            "elastic search."
        ],
        "cleaned_techs": [
            "nlp",
            "large language models",
            "llm",
            "vector databases",
            "retrieval augmented generation (rag)",
            "search engines",
            "azure",
            "python",
            "langchain",
            "streamlit",
            "docker",
            "git",
            "elastic search."
        ]
    },
    "904f116bbf2e0652": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "bf8e7c796b5e239c": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 150000.0,
        "salary_max": 165000.0,
        "title": "Lead Data Engineer - Direct Hire [Remote]",
        "company": "Braintrust",
        "desc": "ABOUT US : \n  Braintrust is a user-owned talent network that connects you with great jobs with no fees or membership costs\u2014so you keep 100% of what you earn. \n  Our promise is to give you the opportunity to uniquely differentiate yourself as a top performer. \n  Our promise to our clients is to help them efficiently discover and hire highly qualified talent like you. \n  ABOUT THE HIRING PROCESS: \n  The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match. \n  Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies. \n \n \n \n \n JOB TYPE : Direct Hire/ FTE Position (no agencies/C2C - see notes below) \n LOCATION : Remote - United States only - PST/PDT/CIST, CST/CDT, MST/MDT, EST/EDT | Full day overlap \n SALARY RANGE : $150,000 \u2013 $165,000/yr \n ESTIMATED DURATION : 40hr/week - Long term \n EXPERIENCE : 5-10 years \n BRAINTRUST JOB ID:  9331 \n \n THE OPPORTUNITY \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Requirements \n \n \n Job Description Summary \n  Make Your Mark. Shape Your Future.  It takes great people to achieve greatness. People with a sense of purpose and integrity. People with a relentless pursuit of excellence. People who care about making things better For Those Who Make The World\u2122. Sound like you? Join our top-notch team of 54,000+ professionals in 60 countries who are making their mark on some of the world's most beloved brands.     About You  We are seeking a highly motivated Senior Data Engineer to join the Power Tools Construction Technology team. If you are a results-driven individual who thrives in a fast-paced and dynamic environment, with a passion for developing and managing world-class data platforms, then we want to hear from you. \n  PTG Platforming Investment \n \n \n \n \n \n \n What you'll be working on \n \n \n Things you will do  We are a small and nimble team, so you'll likely get to experience and participate on many projects. However, you should broadly expect the following set of responsibilities: \n \n Using judgement and expertise to define [responsibility]   \n Collaborate with cross-functional teams, including product, hardware engineering, design, data science, and business stakeholders, to ensure successful delivery of product features.   \n Navigate complex problems and determine resolutions against current processes and direction based on software product understanding and expertise. \n \n   Your Professional Experience  As an ideal candidate you would have following key qualifications: \n \n 5+ years of hands-on experience of building and maintaining large scale ETL pipelines and in-depth knowledge of big data frameworks and architectures including Spark, Hadoop/MapReduce, Airflow, Streaming (Kafka or similar message bus).   \n A solid experience and understanding of architecting, designing, and operationalization of large-scale data and analytics solutions on cloud Data Warehouse such as Snowflake, Google BigQuery, or AWS Redshift is a must.   \n Lead cross-functional technical discussions that drive decisions and actionable implementation approaches.   \n Perform POCs on new technology, architecture patterns.   \n Excellent SQL knowledge and hands-on experience with the ability to create efficient data models (applied to data warehousing in particular)   \n Experience with automating end to end data lifecycle on the big data ecosystem.   \n Experience with managing automated schema evolution within data pipelines.   \n Prior experience with connected devices/IoT-based applications , Construction Tech is a plus.   \n Experience in leading & mentoring junior team members   \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Apply Now! \n \n \n \n \n \n \n \n \n \n \n \n Notes: \n  Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we'd welcome your application. \n  Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.",
        "cleaned_desc": "  Make Your Mark. Shape Your Future.  It takes great people to achieve greatness. People with a sense of purpose and integrity. People with a relentless pursuit of excellence. People who care about making things better For Those Who Make The World\u2122. Sound like you? Join our top-notch team of 54,000+ professionals in 60 countries who are making their mark on some of the world's most beloved brands.     About You  We are seeking a highly motivated Senior Data Engineer to join the Power Tools Construction Technology team. If you are a results-driven individual who thrives in a fast-paced and dynamic environment, with a passion for developing and managing world-class data platforms, then we want to hear from you. \n  PTG Platforming Investment \n \n \n \n \n \n \n What you'll be working on \n \n \n Things you will do  We are a small and nimble team, so you'll likely get to experience and participate on many projects. However, you should broadly expect the following set of responsibilities: \n \n Using judgement and expertise to define [responsibility]   \n Collaborate with cross-functional teams, including product, hardware engineering, design, data science, and business stakeholders, to ensure successful delivery of product features.   \n Navigate complex problems and determine resolutions against current processes and direction based on software product understanding and expertise. \n \n   Your Professional Experience  As an ideal candidate you would have following key qualifications: \n \n 5+ years of hands-on experience of building and maintaining large scale ETL pipelines and in-depth knowledge of big data frameworks and architectures including Spark, Hadoop/MapReduce, Airflow, Streaming (Kafka or similar message bus).   \n A solid experience and understanding of architecting, designing, and operationalization of large-scale data and analytics solutions on cloud Data Warehouse such as Snowflake, Google BigQuery, or AWS Redshift is a must.   \n Lead cross-functional technical discussions that drive decisions and actionable implementation approaches.   \n Perform POCs on new technology, architecture patterns.   \n Excellent SQL knowledge and hands-on experience with the ability to create efficient data models (applied to data warehousing in particular)   \n Experience with automating end to end data lifecycle on the big data ecosystem.   \n Experience with managing automated schema evolution within data pipelines.   \n Prior experience with connected devices/IoT-based applications , Construction Tech is a plus.   \n Experience in leading & mentoring junior team members   \n \n \n \n ",
        "techs": [
            "spark",
            "hadoop/mapreduce",
            "airflow",
            "kafka",
            "snowflake",
            "google bigquery",
            "aws redshift",
            "sql"
        ],
        "cleaned_techs": [
            "spark",
            "hadoop/mapreduce",
            "airflow",
            "kafka",
            "snowflake",
            "google bigquery",
            "aws",
            "sql"
        ]
    },
    "358b5a698d6460df": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 152282.58,
        "salary_max": 192823.67,
        "title": "Sr Data Scientist",
        "company": "Market America Inc",
        "desc": "Market America Worldwide \u2013 Shop.com, a global e-commerce and digital marketing company that specializes in one-to-one marketing, is seeking a top-notch Senior Data Scientist to join our team. Remote opportunity can be available to candidates based in states of CA, NC, FL, NY, CT, or WI. \n \n  Position Summary \n \n  As Data Scientist you will have an important role in helping millions of customers on our SHOP.COM and Market America Worldwide multi-country and multi-language global eCommerce websites. \n \n  We are seeking an experienced data scientist that could help in doing statistical analysis of a/b tests, build machine learning ranking models for search result ranking and personalized recommendations, build models for category classifiers in predicting categories for a product or search keyword, fine tune some of the out of box models such as word2vec or Bert, text embedding, customer segmentations models, and help support various business decision making processes. \n \n  If you are passionate about Machine Learning / Artificial Intelligence, this is a highly visible role that will provide you the opportunity to make a huge impact in our business and a difference to millions of customers worldwide. \n \n  Job Duties and Responsibilities \n \n  Work through all phases of development including data analysis, model prototyping, model evaluation (offline / online), training data set, automation, and maintenance \n \n  Collaborate with other teams including search and data engineering, web and marketing analysts, data analysts, project managers, systems team, and other contractors/consultants \n \n  Write code in Python / R using various statistical techniques and machine learning models, maintain all the code in repository such as Git / Bitbucket \n \n  Develop visualization of data with tools such as Jupyter notebooks and integrations with Tableau \n \n  A/B test evaluation, share the findings with the team. Ability to communicate summarized results to technical and non-technical stakeholders to help them make decisions. \n \n  Work with search engineers and data engineers in integrating ML models, analytics pipeline, work with ML Engineers/Data Engineers in deploying models to production, participate in MLOps processes \n \n  Work with stakeholders throughout the organization to identify opportunities for leveraging machine learning techniques across other business verticals \n \n  Mentor junior team members, define architecture, code review, hands-on development and deliver the work in sprint cycle \n \n  Take complete ownership from requirements, solution design, development, production launch and post launch production support. Participate in code reviews and regular on-call rotations. \n \n  Desire to learn ML best practices, participate in other forums / conferences, and continue to bring latest trends in Machine Learning / Artificial Intelligence \n \n  Education and Experience \n \n  BS / Masters / PhD in Computer Science (or related field) with 5+ years of hands-on experience in statistical and machine learning algorithms on real world problems \n \n  Experience in using ML friendly tech stack, PyTorch, Tensorflow, scikit-learn, pandas, Python / R, deep learning frameworks, comfortable with database SQL queries, AWS Athena, BigQuery and Google Analytics tagging/integration, ML models for information retrieval algorithms, transformers/encoders, ANN/KNN search \n \n  Hands-on industry experience in building real time ranking and recommendations models, text embedding, neural networks, deep learning, and other NLP techniques for search query understanding \n \n  Strong programming skills, statistical techniques, clustering techniques, predictive modeling, AI/ML/NLP, architecture diagramming, problem-solving and debugging skills \n \n  A team player, willingness to learn new technologies, phenomenal communication and influencing skills \n \n  Nice to have \n \n  Prior industry experience in e-Commerce domain \n \n  Experience in deploying ML models to production, familiarity with MLOps \n \n  Experience in utilizing ML platforms such as Amazon SageMaker, AWS Lambda or others \n \n  Experience in performing vector search, image search / visual search \n \n  Familiarity in using search engines like Elasticsearch or other vector search engines \n \n  Market America offers competitive salary and generous benefits, including health, dental, vision, life, short and long-term disability insurance, and a 401(k) retirement plan with company match. \n \n  Qualified candidates should apply online. This position will work remotely based from our California offices. \n \n  Market America is proud to be an equal opportunity employer. \n \n  Market America | SHOP.COM is changing the way people shop and changing the economic paradigm so anyone can become financially independent by creating their own economy and converting their spending into earning with the Shopping Annuity\u00ae. \n \n  ABOUT MARKET AMERICA, INC. & SHOP.COM \n \n  Market America Worldwide | SHOP.COM is a global e-commerce and digital marketing company that specializes in one-to-one marketing and is the creator of the Shopping Annuity . Its mission is to provide a robust business system for entrepreneurs, while providing consumers a better way to shop. Headquartered in Greensboro, North Carolina, and with eight sites around the globe, including the U.S., Market America Worldwide was founded in 1992 by Founder, Chairman & CEO JR Ridinger. Through the company's primary, award-winning shopping website, SHOP.COM, consumers have access to millions of products, including Market America Worldwide exclusive brands and thousands of top retail brands. Further, SHOP.COM ranks 19th in Newsweek magazine's 2021 Best Online Shops, No. 52 in Digital Commerce 360's (formerly Internet Retailer) 2021 Top 1,000 Online Marketplaces, No. 79 in Digital Commerce 360's 2021 Top 1,000 Online Retailers and No. 11 in the 2021 Digital Commerce 360 Primary Merchandise Category Top 500. The company is also a two-time winner of the Better Business Bureau's Torch Award for Marketplace Ethics and was ranked No. 15 in The Business North Carolina Top 125 Private Companies for 2021. By combining Market America Worldwide's entrepreneurial business model with SHOP.COM's powerful comparative shopping engine, Cashback program, Hot Deals, ShopBuddy\u00ae, Express Pay checkout, social shopping integration and countless other features, the company has become the ultimate online shopping destination. \n \n \n For more information about Market America Worldwide:  MarketAmerica.com \n \n \n For more information on SHOP.COM, please visit:  SHOP.COM",
        "cleaned_desc": "  Collaborate with other teams including search and data engineering, web and marketing analysts, data analysts, project managers, systems team, and other contractors/consultants \n \n  Write code in Python / R using various statistical techniques and machine learning models, maintain all the code in repository such as Git / Bitbucket \n \n  Develop visualization of data with tools such as Jupyter notebooks and integrations with Tableau \n \n  A/B test evaluation, share the findings with the team. Ability to communicate summarized results to technical and non-technical stakeholders to help them make decisions. \n \n  Work with search engineers and data engineers in integrating ML models, analytics pipeline, work with ML Engineers/Data Engineers in deploying models to production, participate in MLOps processes \n \n  Work with stakeholders throughout the organization to identify opportunities for leveraging machine learning techniques across other business verticals \n \n  Mentor junior team members, define architecture, code review, hands-on development and deliver the work in sprint cycle \n    Take complete ownership from requirements, solution design, development, production launch and post launch production support. Participate in code reviews and regular on-call rotations. \n \n  Desire to learn ML best practices, participate in other forums / conferences, and continue to bring latest trends in Machine Learning / Artificial Intelligence \n \n  Education and Experience \n \n  BS / Masters / PhD in Computer Science (or related field) with 5+ years of hands-on experience in statistical and machine learning algorithms on real world problems \n \n  Experience in using ML friendly tech stack, PyTorch, Tensorflow, scikit-learn, pandas, Python / R, deep learning frameworks, comfortable with database SQL queries, AWS Athena, BigQuery and Google Analytics tagging/integration, ML models for information retrieval algorithms, transformers/encoders, ANN/KNN search \n \n  Hands-on industry experience in building real time ranking and recommendations models, text embedding, neural networks, deep learning, and other NLP techniques for search query understanding \n \n  Strong programming skills, statistical techniques, clustering techniques, predictive modeling, AI/ML/NLP, architecture diagramming, problem-solving and debugging skills \n    A team player, willingness to learn new technologies, phenomenal communication and influencing skills \n \n  Nice to have \n \n  Prior industry experience in e-Commerce domain \n \n  Experience in deploying ML models to production, familiarity with MLOps \n \n  Experience in utilizing ML platforms such as Amazon SageMaker, AWS Lambda or others \n \n  Experience in performing vector search, image search / visual search \n \n  Familiarity in using search engines like Elasticsearch or other vector search engines \n ",
        "techs": [
            "python",
            "r",
            "git",
            "bitbucket",
            "jupyter notebooks",
            "tableau",
            "ml models",
            "a/b test evaluation",
            "ml engineers",
            "data engineers",
            "mlops",
            "stakeholders",
            "machine learning",
            "artificial intelligence",
            "pytorch",
            "tensorflow",
            "scikit-learn",
            "pandas",
            "deep learning frameworks",
            "sql queries",
            "aws athena",
            "bigquery",
            "google analytics",
            "information retrieval algorithms",
            "transformers/encoders",
            "ann/knn search",
            "ranking models",
            "recommendations models",
            "text embedding",
            "neural networks",
            "nlp techniques",
            "programming skills",
            "statistical techniques",
            "clustering techniques",
            "predictive modeling",
            "ai/ml/nlp",
            "architecture diagramming",
            "problem-solving",
            "debugging skills",
            "e-commerce",
            "amazon sagemaker",
            "aws lambda",
            "vector search",
            "image search",
            "visual search",
            "elasticsearch"
        ],
        "cleaned_techs": [
            "python",
            "r",
            "git",
            "bitbucket",
            "jupyter notebooks",
            "tableau",
            "ml models",
            "a/b test evaluation",
            "ml engineers",
            "data engineers",
            "mlops",
            "stakeholders",
            "ai",
            "pytorch",
            "tensorflow",
            "scikit-learn",
            "pandas",
            "deep learning frameworks",
            "aws",
            "bigquery",
            "google analytics",
            "information retrieval algorithms",
            "transformers/encoders",
            "ann/knn search",
            "ranking models",
            "recommendations models",
            "text embedding",
            "neural networks",
            "nlp",
            "statistical techniques",
            "clustering techniques",
            "predictive modeling",
            "architecture diagramming",
            "problem-solving",
            "e-commerce",
            "vector search",
            "image search",
            "visual search",
            "elasticsearch"
        ]
    },
    "4e91af2aabd2c2c4": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 116777.984,
        "salary_max": 147866.95,
        "title": "Machine Learning Engineer",
        "company": "Iris Technology Inc.",
        "desc": "Machine Learning Engineer \n \n \n \n  We are seeking a talented and experienced Machine Learning Engineer to join our team! As a Machine Learning Engineer at webAI, you garner experience developing and deploying ML models alongside our researchers to bolster our platform. An ideal candidate will have experience with both unstructured and structured data machine learning use-cases.\n  \n \n \n Responsibilities: \n \n \n Research, design, implement, and fine-tune machine learning models, including deep learning architectures, to be included in or to advance our platform. \n Compile/pre-process datasets for training purposes \n Extract meaningful features from data through feature engineering to improve model performance \n Extend and develop the organizations existing ML libraries and proprietary frameworks \n Collaborate with R&D and systems software engineering teams \n Promote and adhere to MLOps best practices within the organization \n Ensure production intent code is properly documented and tested \n Stay up to date on latest AI trends and research papers \n \n \n Qualifications: \n \n \n Proven experience as a Machine Learning Engineer or similar role \n Batchelor's (Master's prefered) in Computer Science, Machine Learning, Data Science, or a related field \n Understanding of data structures, data modeling and software architecture \n Deep knowledge of math, probability, statistics and algorithms \n Ability to write robust code in Python (Rust, C/C++, Cuda, or MPS experience a plus) \n Expertise in data preprocessing, feature engineering, and model evaluation technique \n Experience working with Tensorflow and/or PyTorch along with scikit-learn, numpy, pandas, and opencv \n Experience with cloud computing platforms and model deployment techniques using Docker containerization \n Experience with MLOps tools like, MLFlow, KubeFlow, Airflow or similar \n Passionate about learning \n Strong verbal and written communication skills",
        "cleaned_desc": " Proven experience as a Machine Learning Engineer or similar role \n Batchelor's (Master's prefered) in Computer Science, Machine Learning, Data Science, or a related field \n Understanding of data structures, data modeling and software architecture \n Deep knowledge of math, probability, statistics and algorithms \n Ability to write robust code in Python (Rust, C/C++, Cuda, or MPS experience a plus) \n Expertise in data preprocessing, feature engineering, and model evaluation technique ",
        "techs": [
            "python",
            "rust",
            "c/c++",
            "cuda",
            "mps"
        ],
        "cleaned_techs": [
            "python",
            "rust",
            "c/c++",
            "cuda",
            "mps"
        ]
    },
    "10283099c3d91d6e": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "4314661f73a7d3f2": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Product Owner OCR and Data Science Focus (Remote)",
        "company": "iBusiness Funding",
        "desc": "iBusiness Funding is a technology company focused on our mission to provide working capital to small and medium sized businesses in an efficient and transparent manner. We are committed to our four values of success: innovation, integrity, enjoyment, and family. \n \n  Our parent company is a top 15 SBA 7(a) preferred lender with SBA express and small loan capabilities. \n \n  Position Description: \n  Do you want to develop technology that reshapes our financial landscape? Do you have a passion for supporting businesses and for helping them achieve their dreams? So do we! IBusiness Funding is the Fintech arm of publicly traded Ready Capital Corporation, located in sunny Ft. Lauderdale, Florida. \n \n \n  We build software that is used by internal staff, external partners and our software clients. Our platforms help business gain access to capital in fast frictionless ways. The iBusiness Funding Product department is looking for a technical project manager (Product Owner) to lead a team of software engineers focused on OCR and Data Science. \n \n  Essential Duties and Responsibilities: \n \n \n \n  Plan, define and prioritize the product backlog and product roadmap \n Clarify requirements and make timely decisions on execution details \n Work with stakeholders to evaluate best the approach when solving business problems \n Maintain development and production environments and properly deploy changes \n Establish timelines and product benchmarks, holds team accountable to deadlines \n Conduct daily standup meetings with Development team \n Coach developers to achieve high performance \n \n \n \n  Required Knowledge, Skills, and Abilities: \n \n \n \n 3+ years in technical project management role \n Strong understanding and prior experience working with OCR - Optical Character Recognition (Tesseract, OpenCV or similar) \n Strong understanding and prior experience working with Data Science (Python, Spark, TensorFlow or similar) \n Solid understanding of web technologies, such as JavaScript and JSON \n Solid knowledge of Database technologies such as MySQL, PostgreSQL, Dynamo and relational/non-relational database schema design and development \n Experience with Cloud development tools like AWS, Azure, GCP \n Excellent interpersonal and communication skills \n Thrive in an agile, fast-paced and constantly changing environment \n Team focused \n Extremely detailed oriented \n \n \n \n  Physical Demands: \n  The physical demands of the position are typical of those found in a traditional office environment. Employee will not need to walk significant distances nor lift substantial weight. Employee will need to be able to remain seated at a desk for 8-9 hours in a typical workday. \n \n  Conclusion: \n  This job description is intended to convey information essential to understanding the scope of the job and the general nature and level of work performed by job holders within this job. This job description is not intended to be an exhaustive list of qualifications, skills, efforts, duties, responsibilities or working conditions associated with the position. \n \n  The company is an equal opportunity employer and will consider all applications without regard to race, sex, age, color, religion, national origin, veteran status, disability, genetic information or any other characteristic protected by law.",
        "cleaned_desc": " \n 3+ years in technical project management role \n Strong understanding and prior experience working with OCR - Optical Character Recognition (Tesseract, OpenCV or similar) \n Strong understanding and prior experience working with Data Science (Python, Spark, TensorFlow or similar) \n Solid understanding of web technologies, such as JavaScript and JSON \n Solid knowledge of Database technologies such as MySQL, PostgreSQL, Dynamo and relational/non-relational database schema design and development \n Experience with Cloud development tools like AWS, Azure, GCP \n Excellent interpersonal and communication skills \n Thrive in an agile, fast-paced and constantly changing environment ",
        "techs": [
            "tesseract",
            "opencv",
            "python",
            "spark",
            "tensorflow",
            "javascript",
            "json",
            "mysql",
            "postgresql",
            "dynamo",
            "aws",
            "azure",
            "gcp."
        ],
        "cleaned_techs": [
            "tesseract",
            "opencv",
            "python",
            "spark",
            "tensorflow",
            "javascript",
            "json",
            "mysql",
            "postgresql",
            "dynamo",
            "aws",
            "azure",
            "gcp"
        ]
    },
    "9c4aaa999f3e24a3": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "EA Outcomes Specialist",
        "company": "AmeriHealth Caritas",
        "desc": "Your career starts now. We\u2019re looking for the next generation of health care leaders. \n  At AmeriHealth Caritas, we\u2019re passionate about helping people get care, stay well and build healthy communities. As one of the nation's leaders in health care solutions, we offer our associates the opportunity to impact the lives of millions of people through our national footprint of products, services and award-winning programs. AmeriHealth Caritas is seeking talented, passionate individuals to join our team. Together we can build healthier communities. If you want to make a difference, we\u2019d like to hear from you. \n  Headquartered in Newtown Square, AmeriHealth Caritas is a mission-driven organization with more than 30 years of experience. We deliver comprehensive, outcomes-driven care to those who need it most. We offer integrated managed care products, pharmaceutical benefit management and specialty pharmacy services, behavioral health services, and other administrative services. Discover more about us at  www.amerihealthcaritas.com . \n \n \n \n \n \n \n Must be permanently authorized to work in the U.S. as a precondition of employment. \n  Responsibilities: \n  Under the leadership of the Manager Outcomes Evaluation \u2013 Business Insights, the Outcomes Specialist is responsible for sharing insights in a way that is easy to grasp and actionable, build relationships to help drive adoption of data- and insights-driven decision making across a variety of subject matters including, but not limited to Medicare, medical and quality management, authorizations, claims, SIU, statutory/regulatory, non-HEDIS, Jiva/eLTSS and population health. Be a key stakeholder at the table of leadership and support strategic vision and goals. The candidate will become their go-to source for data, reporting, insights, and guidance. This team will work with business owners in preparing business requirement documents, engage in data mining, analytics to present reporting or BI dashboards to solve business questions / needs. Prepare and assist with the peers in analysis, reporting, process and program evaluation with results in a manner that\u2019s accepted by a diverse group of stakeholders. \n \n Support corporate, plan-level, and departmental strategies and goals by effectively applying both business knowledge and technical expertise to develop and implement data-driven solutions. \n Define business problems, assess relevant variables and forces that impact the issue, recognize relevant patterns in data, and provide solutions and information to solve business problems and needs; including BI dashboard development. \n Drive management, operations units, stakeholders and the reporting staff to prepare clear, sound, accurate and informative reports containing findings, analysis, conclusions, and recommendations. \n Generates data analytics to identify recovery opportunities for fraud, waste and abuse. \n Conduct and document QA testing for analytic and reporting solutions. \n Cross-pollinate across multiple corporate areas to understand workflows, document processes and ensure highest quality product delivery. \n Work on a fast paced team, with minimal direction focusing on understanding the application/product/area in detail, while delivering high-quality outputs and actionable solutions. \n Serve as thought leader for technical business processes, developing forward-thinking prototypes that promote increased efficiency and productivity on multiple levels. \n Learn rapidly and enthusiastically, focusing on understanding the application/product/area in detail \n Calculate return on invest (ROI), evaluate potential operational changes. \n Assist with designing new approaches and methodologies. \n Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems. \n Collaborate across multiple corporate areas to understand workflows, document processes and ensure highest quality product delivery. \n Work on a fast paced team, with minimal direction focusing on understanding the application/product/area in detail, while delivering high-quality outputs and actionable solutions. \n Perform other duties as assigned by Management. \n \n Education/Experience: \n \n Bachelor\u2019s Degree in computer science, healthcare analytics, mathematics, or sociology \n  Advanced analytical and quantitative skills with experience collecting, organizing, mining, analyzing, visualizing, and disseminating abundant information with the utmost accuracy and presentation. \n Superior technical writing skills in business requirements, queries, reports, and presentations. \n Advanced Data Science skills in SQL, PySpark, Databricks, SAS, Tableau, Power BI or related tools. \n Strong working knowledge with data visualization and geographic data analysis tools such as Tableau and ArcGIS. \n Advanced proficiency with data mining. \n Advanced organizational, technical, analytical, and written/oral communication skills. \n Advanced technical writing skills in business requirements, queries, reports, and presentations \n Advanced analytical and quantitative skills with experience collecting, organizing, mining, analyzing, visualizing and disseminating abundant information with the utmost accuracy and presentation. \n Efficiently manages time-based on the continual evaluation of priorities, meets deadlines with high-quality deliverable reflecting complete understanding of expectations, able to multi-task. \n Experience using mathematics, modeling, business analysis, and technology to transform high volumes of complex data into advanced analytic solutions.",
        "cleaned_desc": "  Advanced analytical and quantitative skills with experience collecting, organizing, mining, analyzing, visualizing, and disseminating abundant information with the utmost accuracy and presentation. \n Superior technical writing skills in business requirements, queries, reports, and presentations. \n Advanced Data Science skills in SQL, PySpark, Databricks, SAS, Tableau, Power BI or related tools. \n Strong working knowledge with data visualization and geographic data analysis tools such as Tableau and ArcGIS. \n Advanced proficiency with data mining. \n Advanced organizational, technical, analytical, and written/oral communication skills. \n Advanced technical writing skills in business requirements, queries, reports, and presentations \n Advanced analytical and quantitative skills with experience collecting, organizing, mining, analyzing, visualizing and disseminating abundant information with the utmost accuracy and presentation. ",
        "techs": [
            "sql",
            "pyspark",
            "databricks",
            "sas",
            "tableau",
            "power bi",
            "arcgis"
        ],
        "cleaned_techs": [
            "sql",
            "pyspark",
            "databricks",
            "sas",
            "tableau",
            "powerbi",
            "arcgis"
        ]
    },
    "db540c31d2c4f4bf": {
        "terms": [
            "data science"
        ],
        "salary_min": 72558.73,
        "salary_max": 91875.52,
        "title": "Product Analyst",
        "company": "MyFitnessPal",
        "desc": "At MyFitnessPal, our vision is to be the global catalyst for every \"body\" to achieve their healthy. We believe good health starts with what you eat. We provide the tools and resources to reach your fitness goals. \n  We are looking for a Product Analyst to help us further understand user behavior in the MyFitnessPal App via actionable data insights that help reveal or clarify strategic choices, and enhance product features and make better data-driven decisions. You will monitor and analyze product experimentation to assess and quantify the impact of product changes. You will also collaborate with data, design, and engineering teams to drive consistent and scalable data event tracking. You will report to the Senior Manager, Business Intelligence. \n  What you'll be doing: \n \n Daily and Weekly metrics monitoring, KPIs refresh, and dashboard and reports development \n Gather, analyze, and interpret data to inform product strategy and inform the product roadmap \n Test setup recommendation, estimating timeline to reach significance, test data Q&A and validation \n Conduct A/B test data analysis and Pre/Post analysts for feature rollouts to estimate the impact and offer recommendations \n New event names approval, supporting product team in taxonomy and maintaining data governance documentation \n Live our core values in all you do: \n \n Be Kind and Care \n Live Good Health \n Be Data-Inspired \n Champion Change \n Leave it Better than You Found It \n Make It Happen \n \n \n Qualifications to be successful in this role: \n \n 1-3 years experience in product analytics, data analytics, data science, or equivalent analytical roles \n 1+ years experience with SQL, Python, Tableau, and Excel/Google Sheets \n Strong knowledge and hands-on experience with statistical testing such as A/B, multivariate, and Bayesian testing \n Proficiency in applied statistics skills, such as statistical testing, regression modeling, etc \n Experience with digital analytical tools such as Amplitude, Mixpanel, Heap, etc. \n Cross-functional communication skills, ability to influence and partner with business and product stakeholders \n \n \n \n  Please consider applying even if you don't meet 100% of the qualifications. Research shows you can still be considered for a position if you meet some of the requirements. At MyFitnessPal, we're building a fitness product for everyone and believe our team should reflect that. We encourage people of different backgrounds, experiences, abilities, and perspectives to apply. \n \n  Exciting Full-Time Employee Benefits, Perks and Culture \n  Embrace the Freedom:  Be a digital nomad, work from anywhere we have operations within the continental U.S. \n  Office Vibes:  If you prefer working in an office, we've got you covered, our HQ is in vibrant Austin, TX. \n  Face-to-Face Connections :  We value personal connections. Enjoy opportunities to meet and connect with your team members in person to help forge meaningful relationships that extend beyond the virtual realm. Teams meet as often as needed and all of MyFitnessPal gathers annually. \n  Flexibility At Its Best:  Achieve the work-life balance you deserve. Enjoy a flexible time-off policy and work on your own terms with our  Responsible Time Off  benefit. \n  Give Back:  Use your volunteer days off to support what matters most to you. Each full time teammate receives 2 days per calendar year to give back to their community through service. \n  Mentorship Program:  Take control of your career through our mentorship program where, if you'd like, you will be matched with a teammate who can help you scale your skills and propel your growth. \n  Family-Friendly Support :  Embrace the journey with confidence and care. Enjoy our paid maternity and paternity leave, to provide time to balance family responsibilities with your career and take the time needed to strengthen family relationships. We understand the complexities of starting or expanding a family, which is why we provide best-in-class comprehensive assistance for fertility-related matters. \n  Wellness Comes First :  Live Good Health is one of our core values. Receive a monthly Wellness Allowance, empowering you to focus on your physical and mental well-being by choosing from a range of wellness initiatives, including dedicated mental health days. \n  Celebrate Greatness:   Your hard work deserves recognition! Our reward and recognition platform empowers peers to acknowledge and reward each other for the exceptional contributions they make. \n  Elevate Your Health & Fitness:  Get access to MyFitnessPal Premium, allowing you to take your fitness, health and wellness journey to new heights. \n  Unlock Your Potential:  Access our virtual learning and development library, and participate in training opportunities to continuously grow and enhance your skills. \n  Championing Inclusion : Our dedicated DEI Committee actively fosters a diverse and inclusive workplace by setting actionable goals and evaluating progress across the organization. \n  Healthcare Matters:  Your well-being is our priority. Take advantage of our competitive medical, dental, and vision benefits that cater to your holistic healthcare needs. Feel secure and supported on your wellness journey. \n  Secure Your Future:  Benefit from our retirement savings program, giving you peace of mind for your financial goals. Reach them sooner with MyFitnessPal's competitive employer match. \n \n \n  At MyFitnessPal, our mission is to enable people to make healthy choices. And it wouldn't be possible without our team. We celebrate the unique POV that each person brings to the table and believe in a collaborative and inclusive environment. As an equal opportunity employer, we prohibit any unlawful discrimination on the basis of race, religion, military or veteran status, sex, gender, marital status, gender identity or expression, sexual orientation, national origin, age, or disability. These are our guiding ideologies and apply across all aspects of employment. \n \n \n  MyFitnessPal participates in E-Verify.",
        "cleaned_desc": " \n 1-3 years experience in product analytics, data analytics, data science, or equivalent analytical roles \n 1+ years experience with SQL, Python, Tableau, and Excel/Google Sheets \n Strong knowledge and hands-on experience with statistical testing such as A/B, multivariate, and Bayesian testing \n Proficiency in applied statistics skills, such as statistical testing, regression modeling, etc \n Experience with digital analytical tools such as Amplitude, Mixpanel, Heap, etc. \n Cross-functional communication skills, ability to influence and partner with business and product stakeholders \n \n \n ",
        "techs": [
            "sql",
            "python",
            "tableau",
            "excel/google sheets",
            "statistical testing",
            "a/b testing",
            "multivariate testing",
            "bayesian testing",
            "applied statistics skills",
            "regression modeling",
            "amplitude",
            "mixpanel",
            "heap."
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "tableau",
            "excel",
            "statistical testing",
            "a/b testing",
            "multivariate testing",
            "bayesian testing",
            "regression modeling",
            "amplitude",
            "mixpanel",
            "heap."
        ]
    },
    "398709eea176588d": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 124043.2,
        "salary_max": 157066.33,
        "title": "Senior Data Engineer",
        "company": "MasterControl",
        "desc": "Summary \n  At MasterControl we are building our next generation data platform that will leverage AI/ML techniques to help redefine how our customers bring life-saving and life-changing products to market. To enable this, we are looking for a Senior Data Engineer to support our Data Science and Machine Learning teams.\n  \n \n \n Key Qualifications \n \n \n Expertise working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines. \n Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent). \n Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others. \n Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models. \n Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimizations like bucketing,aggregating, sharding. \n Expertise in one or more NoSQL database (Neo4J, Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.). \n \n \n Personal Qualities \n \n \n You are tenacious, relentless, & determined. \n You are curious: always learning new technologies, rapidly synthesizing new information, and understanding \"the why\" before \"the what.\" \n You are self-directed and capable of operating amid ambiguity. \n You are poised and display excellent judgment in prioritizing across difficult tradeoffs. \n You are pragmatic: not letting \"the perfect\" be the enemy of \"the good.\" \n You are humble, continually growing in self-awareness and possessing a growth mindset \n \n \n Education and Experience Qualifications \n \n \n 7+ years in a Data Engineering role \n CS Bachelor's degree + \n \n The US base salary range for this full-time position is $180,000-$220,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.",
        "cleaned_desc": " \n \n Expertise working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines. \n Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent). \n Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others. \n Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models. ",
        "techs": [
            "hadoop",
            "mapreduce",
            "spark",
            "flink",
            "kafka",
            "java",
            "scala",
            "python",
            "apache flink",
            "spark-streaming",
            "apache storm",
            "kafka streams"
        ],
        "cleaned_techs": [
            "hadoop",
            "mapreduce",
            "spark",
            "flink",
            "kafka",
            "java",
            "scala",
            "python",
            "apache flink",
            "spark-streaming",
            "apache storm",
            "kafka streams"
        ]
    },
    "3eaa0e8f5d2a9f19": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "cfc06647bcc499d0": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Claims Data Analyst",
        "company": "JAMES RIVER MANAGEMENT CO INC",
        "desc": "James River Group Holdings, Ltd. is a Bermuda-based insurance holding company which owns and operates a group of specialty insurance and reinsurance companies. The Company operates in three specialty property-casualty insurance and reinsurance segments: Excess and Surplus Lines, Specialty Admitted Insurance and Casualty Reinsurance. The Company tends to focus on accounts associated with small or medium-sized businesses in each of its segments. Each of the Company's regulated insurance subsidiaries are rated \"A-\" (Excellent) by A.M. Best Company. \n  Job Summary \n  The Senior Claims Data Analyst provides reporting and analytics support to the VP, Claims Operations and SVP, Chief Claims Officer. Working closely with Claims Management and Actuarial Leadership, this individual will gather and analyze claims data, develop an understanding of the key drivers of financial and actuarial data, and share insights while ensuring alignment of data trends and processes. This role is integral in ensuring the Claims department adheres to reserving best practices and continuously improves claim resolution efficiency and effectiveness. \n  Duties and Responsibilities \n \n  Continuously exhibit and uphold Core Values of Integrity, Accountability, Communication and Teamwork, Innovation and Customer Service \n  Manage processes, reports, and analytics related to claim reserving functions \n  Work with Accounting/Finance, Actuarial and Internal Audit departments to ensure adequate claim financial controls are in place and being adhered to \n  Perform monthly operational reporting, dashboards, metrics, and KPIs including reserve committees and portfolio reviews \n  Assist with interdepartmental projects, processes, and reports between Accounting/Finance, Actuarial, Reinsurance and Claims \n  Assist in the presentation and delivery of observations, areas of concerns, and recommendations to Claims Management and employees \n  Work in conjunction with Claims and Actuarial Departments to gather Claims data, derive actionable and meaningful insights, and develop strategy \n  Perform analyses of reserve trending in all LOB\u2019s in collaboration with Actuarial \n  Analyze financial data, develop metrics, and test case reserve adequacy to ensure their financial strength \n  Monitor case reserves of product line or segment to ensure present and future reserving strategies to achieve financial strength \n  Review and analyze claim cases reserving patterns to foster claim case reserve adequacy \n \n  Knowledge, Skills and Abilities \n \n  Advanced technical knowledge of reserving and actuarial theories \n  Advanced statistical modeling skills \n  Knowledge of a variety of product lines within P&C as it relates to reserving \n  Proficiency in managing complex datasets and ability to analyze and interpret complex claims data concepts \n  Experience in using statistical modeling and/or machine learning techniques to build models that drive decision making \n  Advanced proficiency in SQL and other query and automation languages (Power Query M, DAX, python) \n  Advanced proficiency in visualization tools (PowerBI, Tableau, Qlik Sense) \n  Advanced proficiency in MS Office (Word, Excel, Outlook, PowerPoint) \n  Understanding of claims case reserving practices \n  Ability to effectively communicate with all levels of the organization \n  Advanced proficiency in insurance claims reporting \n  Excellent written and verbal communication skills \n  Ability to demonstrate business acumen and forward-thinking skills \n  Strong analytical skills \n  Skilled in collecting and analyzing complex data \n  Ability to organize complex information and pay close attention to detail \n  Ability to work successfully as an individual contributor and in a team environment \n \n  Experience and Education \n \n  Bachelor\u2019s Degree in Math, Actuarial Science or related field required \n  Master\u2019s Degree in related field preferred \n  Minimum of five years of claims, data analysis, or actuarial experience, in the insurance industry, required \n  Minimum of three years of predictive modeling experience preferred \n \n \n  #LI-KS1 \n  #LI-Remote",
        "cleaned_desc": " \n  Advanced technical knowledge of reserving and actuarial theories \n  Advanced statistical modeling skills \n  Knowledge of a variety of product lines within P&C as it relates to reserving \n  Proficiency in managing complex datasets and ability to analyze and interpret complex claims data concepts \n  Experience in using statistical modeling and/or machine learning techniques to build models that drive decision making \n  Advanced proficiency in SQL and other query and automation languages (Power Query M, DAX, python) \n  Advanced proficiency in visualization tools (PowerBI, Tableau, Qlik Sense) \n  Advanced proficiency in MS Office (Word, Excel, Outlook, PowerPoint)    Understanding of claims case reserving practices \n  Ability to effectively communicate with all levels of the organization \n  Advanced proficiency in insurance claims reporting \n  Excellent written and verbal communication skills \n  Ability to demonstrate business acumen and forward-thinking skills \n  Strong analytical skills \n  Skilled in collecting and analyzing complex data \n  Ability to organize complex information and pay close attention to detail \n  Ability to work successfully as an individual contributor and in a team environment ",
        "techs": [
            "reserving theories",
            "actuarial theories",
            "statistical modeling",
            "product lines",
            "complex datasets",
            "claims data concepts",
            "statistical modeling techniques",
            "machine learning techniques",
            "sql",
            "power query m",
            "dax",
            "python",
            "visualization tools",
            "powerbi",
            "tableau",
            "qlik sense",
            "ms office",
            "claims case reserving practices",
            "communication skills",
            "insurance claims reporting",
            "business acumen",
            "analytical skills",
            "data collection and analysis",
            "organizational skills",
            "attention to detail",
            "teamwork"
        ],
        "cleaned_techs": [
            "actuarial theories",
            "statistical modeling",
            "product lines",
            "complex datasets",
            "claims data concepts",
            "statistical modeling techniques",
            "machine learning techniques",
            "sql",
            "power query m",
            "dax",
            "python",
            "visualization tools",
            "powerbi",
            "tableau",
            "qlik sense",
            "microsoft",
            "claims case reserving practices",
            "insurance claims reporting",
            "business acumen",
            "data collection and analysis",
            "attention to detail",
            "teamwork"
        ]
    },
    "7f675370f8aadad3": {
        "terms": [
            "data science"
        ],
        "salary_min": 160000.0,
        "salary_max": 195000.0,
        "title": "Senior Technical Product Manager, Data & Insights",
        "company": "UrbanFootprint",
        "desc": "Taking the next step in your career with UrbanFootprint will set you on the path to revolutionizing how organizations make decisions. \n  UrbanFootprint is the world's first Urban Intelligence Platform \u2013 trusted by some of the largest energy utilities, financial institutions, government agencies, urban planning firms, and mobility companies in the US to provide geospatial insights and find signal through noise to inform site selection, infrastructure investment, resource distribution, and much more. We do this by unifying and normalizing previously siloed data on climate, environmental, urban, and socio-economic factors to surface powerful and actionable data insights. \n  UrbanFootprint's mission is to  Build Resilience  by empowering organizations with critical data insights to drive decision making and allow them to  Never Wonder Where . Our customers answer complex  'where'  questions in minutes versus weeks, months, or years, such as: \n \n \"Where does the energy sector need to invest in electrification, decarbonization, and asset hardening in the face of climate threats?\"\u2026 \n \"Where should cities and businesses invest to catch up with e-commerce, last-mile delivery, and new mobility?\"\u2026 \n \"Where do governments deploy relief and new infrastructure to combat record hunger, homelessness, and hazard vulnerability?\"\u2026 \n \n Led by our co-founders, Joe DiStefano and Peter Calthorpe, we are tackling a $22B market opportunity. We've won awards including Inc. Magazine's Best in Business and have been named one of Fast Company's World's Most Innovative Companies. We raised a $25M Series B and our investors include Social Capital, Citi Ventures, Valo Ventures, 2150.VC, A/O Proptech, Assured Guaranty, and Radicle Impact. \n  Don't wonder where to go next, we've got the perfect spot for you! \n \n  The role \n  As Senior Technical Product Manager - Data & Insights, your objective is to build effective data & insights products that meet the needs of our customers and their use cases. \n  Your focus is on designing the best possible data insights by answering: What is needed to address the use case? How can it be constructed from our platform? What are the constraints? Where can new data be sourced from? How will it be used by customers? \n  You will determine the best possible solution to the market need, and then work backwards to how we can build it. \n  You will work predominantly with technology-facing team members; data scientists, data engineers, product managers, solutions analysts, and leadership to: \n \n Champion the vision for our Resilience Insights, Data Foundations, and Data Core \n Define product strategy & multi-quarter roadmap for how we achieve our vision \n Drive execution on a quarterly and week to week basis \n Write product requirements and work with product & engineering counterparts to specify precisely what we will build and influence how we will build it \n Workshop the design of Insights to meet market needs with sales, marketing, solutions, and leadership \n Understand the opportunities and constraints of our architecture and collaborate with engineering architects to make the best decisions for how we build on technical roadmaps for our platform \n Identify, vet, and make the case for integrating new datasets \n Champion quality at every turn \n Conduct user research \n Conduct competitive analysis \n Support the customer delivery process with solutions analysts and technical project managers \n Distill all of the above into product strategy, including \n \n What the opportunity for our Resilience Insights are and how they are valuable and differentiated \n What do we build to empower end-users and our customers \n How should our capabilities evolve in a multi-quarter roadmap \n What should we productize and what should be delivered by solutions \n How do we drive scale, repeatability, and leverage to ensure we meet our company goals and investor expectations. \n \n Relentlessly work to align the strategy with our company goals and constraints and communicate the strategy to all team members to drive focus and deliver impact \n \n A secondary focus is to work with market-facing team members; account executives, product marketing, and technical pre-sales to: \n \n Guide positioning and how we communicate and connect our product with our target market segments \n Support the sales process by providing subject matter expertise and being the 'technical representative' \n Support in the development of Scope of Work documents and ensure that customers are set up for success from the point a contract is signed \n Connect your technical knowledge with our customers and market to ensure what is tactically being delivered sprint to sprint is aligned with customer needs \n Gather feedback from customers, both directly (such as through participation in QBRs or attending recurring customer meetings) as well as indirectly from colleagues in sales, solutions, and support \n \n At the end of the day your role is to put forward, and execute on a product strategy that has the support of the company, which will credibly seize the opportunity in front of us. \n  Our Resilience Insights \n  Today we offer a number of Resilience Insights data packages to our customers to meet the needs of use cases across climate, infrastructure, real estate, capital markets and more. \n  Our Resilience Insights are constructed by combining data from disparate sources. Generally these sources fall into the themes of Built Environment, Climate & Hazards, and People & Vulnerabilities, together they provide a unique perspective on how to analyze and solve some of the most challenging problems facing today's world. \n  Skills & Knowledge \n  The right candidate will possess or be able to rapidly acquire the following skills & knowledge: \n  Leadership \n  Product Management is a position of leadership. You are expected to put forth a plan, a well reasoned opinion, provide answers, give direction, set the course such that it is clear to all what we are doing, and why we are doing it. And then getting it done. \n  Above all, your leadership must be credible, respectful, and set an example for others to follow. \n  To do this you will likely be adept at: \n \n Gathering information; you listen, ask great questions, build trust, dive in deep. \n Organizational awareness; you know the team's strengths and weaknesses, who's crushing it, who is stretched, who is frustrated, who is under-utilized, who's checked out. You have your finger on the pulse. \n Proactivity; you're out in front, identifying the next thing that needs to happen, and getting it moving, you know that action creates results and you're the catalyst. \n Setting goals and creating accountability; for yourself and others, creating organizational alignment and ferreting out points of disconnect, supporting others to meet targets, getting results. \n Clearing the path; you rapidly identify points of confusion or ambiguity and remove them. Processes are well defined and enable us to work together efficiently and effectively. \n Getting leverage; you are constantly asking \"how can I scale this\", \"is this the highest and best use of my time & talents\", \"how can this be automated\" \n Prioritization; you have strong mental models that enable you to quickly discern the most important task in any given moment. You are rarely overwhelmed. \n \n Communication \n  Strong communication is essential to learn, convince, persuade, empathize. \n \n You listen, ask clarifying questions, get to the heart of what's important \n You write - whether it be meeting notes, product requirements, slides, slack messages. Writing forces out ambiguity, and enables others to build on your foundation \n You structure and organize massive amounts of information into frameworks that enable you and others to see 'the forest for the trees', draw out core themes, work at different levels of abstraction (from the plan for the next sprint to the plan for the next year) \n You are confident and gracious in saying 'no'. Most of the information you receive, or questions asked, or user requests will not support your product strategy. You are able to maintain focus by saying \"no\" and have others support you in this decision. \n \n Your Background Most Likely Includes \n  To be successful in the role, it is highly likely that you have prior direct experience with some or all of the following: \n \n 7+ years of combined technical experience in a professional setting. You've been hands on with data and have immediate empathy and credibility with data scientists, data engineers, and software engineers \n 5+ years of data product management experience in a startup environment. You know what it means to move fast and deliver for end-users. You get things done. \n Domain experience in one of more of GIS, climate, real estate, capital markets, urban planning \n Experience with GIS applications such as qGIS, ArcGIS, and Carto, and data warehouse technologies such as BigQuery, and Airflow (or their equivalents) \n A BS or equivalent experience in engineering, urban planning, GIS, data science, or similar technical field \n Experience with agile development practices, in particular managing scrums and planning sprints. \n \n \n \n  Target compensation is $160,000 - $195,000, plus equity. Compensation is flexible based on experience; all candidates at various levels will be considered. \n \n  UrbanFootprint is committed to diversity in its workforce. We are committed to equal employment opportunity regardless of race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.",
        "cleaned_desc": " You listen, ask clarifying questions, get to the heart of what's important \n You write - whether it be meeting notes, product requirements, slides, slack messages. Writing forces out ambiguity, and enables others to build on your foundation \n You structure and organize massive amounts of information into frameworks that enable you and others to see 'the forest for the trees', draw out core themes, work at different levels of abstraction (from the plan for the next sprint to the plan for the next year) \n You are confident and gracious in saying 'no'. Most of the information you receive, or questions asked, or user requests will not support your product strategy. You are able to maintain focus by saying \"no\" and have others support you in this decision. \n \n Your Background Most Likely Includes \n  To be successful in the role, it is highly likely that you have prior direct experience with some or all of the following: \n \n 7+ years of combined technical experience in a professional setting. You've been hands on with data and have immediate empathy and credibility with data scientists, data engineers, and software engineers \n 5+ years of data product management experience in a startup environment. You know what it means to move fast and deliver for end-users. You get things done. \n Domain experience in one of more of GIS, climate, real estate, capital markets, urban planning \n Experience with GIS applications such as qGIS, ArcGIS, and Carto, and data warehouse technologies such as BigQuery, and Airflow (or their equivalents) \n A BS or equivalent experience in engineering, urban planning, GIS, data science, or similar technical field \n Experience with agile development practices, in particular managing scrums and planning sprints. \n \n \n ",
        "techs": [
            "qgis",
            "arcgis",
            "carto",
            "bigquery",
            "airflow"
        ],
        "cleaned_techs": [
            "qgis",
            "arcgis",
            "carto",
            "bigquery",
            "airflow"
        ]
    },
    "ac78e19db87b60c9": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "b8ee9d6de8305d07": {
        "terms": [
            "data science"
        ],
        "salary_min": 68640.0,
        "salary_max": 75000.0,
        "title": "Court Research Associate",
        "company": "NCSC",
        "desc": "Job Summary \n \n \n The National Center for State Courts (NCSC) is an independent, non-profit court improvement organization. NCSC's services-research, information services, education, consulting, association management and technical assistance-are focused on helping courts plan, make decisions, and implement improvements that save time and money, while ensuring judicial administration that supports fair and impartial decision-making. For additional information, visit NCSC.org    NCSC is looking for an experienced Court Research Associate to join our Research & Design Group. The Court Research Associate is responsible for contributing to all aspects of planning, organizing, and conducting research for improving various aspects of state court administration, including the development of research initiatives and proposal for grant funding, designing and conducting the research, and disseminating results through written and online products and presentations targeted to a variety of practitioner and scholarly audiences. \n \n \n \n Duties and Responsibilities \n \n \n \n \n Demonstrates conduct that upholds the basic Core Values of NCSC \n  Comprehends and assesses the impact of contemporary issues on the state courts. \n  Conducts empirical and applied research and program evaluations, including the design of qualitative and quantitative data collection instruments and protocols. \n  Compiles and maintains project databases for multiple projects, taking responsibility for accuracy, comparability, and completeness of data records. \n  Documents data collection methods and instruments and archives data sets according to funding agency instructions. \n  Conducts site visits (e.g., for conducting interviews, focus groups, observations) with constituents. \n  Contributes to building infrastructure (e.g., data visualizations, web-based story boarding, data dashboards, reference materials, practitioner publications, project reports) to effectively communicate research findings to a diverse audience of end users. \n  Presents research findings (e.g., conferences, facilitated workgroups, publications) to diverse audiences (e.g., court-related leadership organizations, practitioners, and lay people) \n  Serves as a resource for staff of state court systems, government agencies, academic institutions, media, and other organizations as requested. \n  Authors various documents, such as: research reports, policy memoranda, and journal articles that convey information in an easily understood and accessible manner. Reviews written materials of other projects for clarity; coordinates activities associated with publishing, disseminating, and marketing research deliverables. \n  Assists in the business development of a proposal idea, conducts research on topics/literature reviews, works on the preparation of proposals/RFPs/concept papers from federal, state, and private funding sources. \n \n \n \n \n Qualifications \n \n \n \n \n Master's degree and/or J.D. with 3+ years of experience in conducting applied social science research, or data science techniques that demonstrates the knowledge, skills and ability to perform the duties of the position,  OR  a Ph.D. in social sciences, public policy, or related field \n  Project management experience \n  Ability to travel \n  Grant writing experience, preferred \n  Additional Skills & Abilities\n    \n \n  Excellent communication skills \u2013 written, verbal, interpersonal, presentation, and facilitation and the ability to communicate complex ideas effectively both orally and written. \n  Proficiency in MS Office: Word, Excel, Outlook, and PowerPoint \n  Ability to design research studies and conduct statistical analyses using multiple techniques. \n  Ability to comprehend and assess the impact of contemporary issues on the state courts. \n  Experience conducting applied social science research including inferential statistics, using advanced analytical techniques, and creating data visualizations. \n  Maintains knowledge of a variety of current statistical and analytic techniques \n  Thinks conceptually, synthesizes data, and draws conclusions relevant for the court community \n \n \n \n \n Additional Information \n \n \n \n \n    The annual starting salary for this role is between $68,640 - $75,000 factors which affect starting pay within the range include skills, education and experience and other qualifications as it relates to the position.\n    \n \n \n  This position closes on October 1, 2023. Please submit your resume and cover letter in addition to your completed NCSC application. For the reference section, include professional references only with at least one previous or current supervisor.\n    \n \n \n  Trusted Leadership. Proven Solutions. Better Courts. Come join the NCSC Team.\n    \n \n \n  NCSC is an equal opportunity/disability/veteran employer. \n \n \n  Committed to Diversity, Equity & Inclusion",
        "cleaned_desc": " \n \n \n \n Master's degree and/or J.D. with 3+ years of experience in conducting applied social science research, or data science techniques that demonstrates the knowledge, skills and ability to perform the duties of the position,  OR  a Ph.D. in social sciences, public policy, or related field \n  Project management experience \n  Ability to travel \n  Grant writing experience, preferred \n  Additional Skills & Abilities\n    \n \n  Excellent communication skills \u2013 written, verbal, interpersonal, presentation, and facilitation and the ability to communicate complex ideas effectively both orally and written. \n  Proficiency in MS Office: Word, Excel, Outlook, and PowerPoint \n  Ability to design research studies and conduct statistical analyses using multiple techniques. ",
        "techs": [
            "ms office: word",
            "excel",
            "outlook",
            "powerpoint"
        ],
        "cleaned_techs": [
            "microsoft",
            "excel",
            "outlook",
            "powerpoint"
        ]
    },
    "4b80c831312c041c": {
        "terms": [
            "data science",
            "data engineer"
        ],
        "salary_min": 80000.0,
        "salary_max": 135000.0,
        "title": "Senior Data Engineer",
        "company": "VSP Global",
        "desc": "The Senior Data Engineer designs, builds and optimizes data pipelines for key data and analytics capabilities in the enterprise. This position works in collaboration with analytics and data warehousing staff, DBAs and subject matter experts to create reliable processes that load targeted data with integrity and quality, enabling it for strategic use by the business.\n  \n \n   Collaborate within an agile, multi-disciplinary team to deliver optimal data integration and transformation solutions\n  \n \n \n   Analyze data requirements (functional and non-functional) to develop and design robust scalable automated, fault-tolerant data pipeline solutions for business and technology initiatives\n  \n \n \n   Profile data to assess the accuracy and completeness of data sources and provide feedback in data-gathering sessions\n  \n \n \n   Design, build, maintain, and operationalize data pipelines for high volume and complex data using appropriate tools and practices in development, test, and production environments. Design with modularity to leverage reuse of code wherever possible\n  \n \n \n   Develop and design data mappings, programs, routines, and SQL to acquire data from legacy, web, cloud, and purchased package environments into the analytics environment\n  \n \n \n   Understand and apply the appropriate use of ELT, ETL, data virtualization, and other methods to optimize the balance of minimal data movement against performance, and mentor others on their appropriate use\n  \n \n \n   Drive automation of data pipeline preparation and integration tasks to minimize manual and error-prone processes and improve productivity using modern data preparation, integration, and AI-enabled metadata management tools and techniques\n  \n \n \n   Leverage auditing facilities that will enable monitoring of data quality to detect emerging issues. Deploy transformation rules to cleanse against defined rules and standards\n  \n \n \n   Participate in architecture, governance, and design reviews, identifying opportunities and making recommendations\n  \n \n \n   Participate in health check assessments of the existing environment and evaluations of emerging technologies\n  \n \n \n   Collaborate with architects to design and model application data structures, storage, and integration in accordance with enterprise-wide architecture standards across legacy, web, cloud, and purchased package environments\n  \n \n \n   Job Specifications\n  \n \n \n  Typically has the following skills or abilities: \n \n \n \n   Bachelor\u2019s degree in computer science, data science, statistics, economics, or related functional area; or equivalent experience\n  \n \n \n   Excellent written and verbal communication skills with the ability to gather requirements and effectively communicate technical concepts and ideas to all levels of employees and management\n  \n \n \n   6+ years\u2019 experience working in development team providing analytical capabilities\n  \n \n \n   6+ years of hands-on experience in the data space spanning data preparation, SQL, integration tools, ETL/ELT/data pipeline design\n  \n \n \n   SQL coding experience\n  \n \n \n   Experience working in an agile development environment (Scrum, Kanban) with a focus on Continuous Integration and Delivery\n  \n \n \n   Knowledge about various data architectures, patterns and capabilities such as event-driven architecture, real-time data flows, non-relational repositories, data virtualization, cloud storage, etc.\n  \n \n \n   Knowledge of and experience with multiple data integration platforms (IBM InfoSphere DataStage, Oracle Data Integrator, Informatica PowerCenter, MS SSIS, AWS Glue, Denodo), and data warehouse MPP platforms such Snowflake, Netezza, Teradata, Redshift, etc.\n  \n \n \n   Familiarity with DataOps practices and their application within analytics environments as well as their ability to extend data and analytics capabilities to other operational systems and consumers\n  \n \n \n   Familiarity with event store and stream processing (Apache Kafka and platforms like Confluent) and with API development and management platforms (MuleSoft, Axway) is beneficial\n  \n \n \n   Capable of focusing on a specific set of tasks while also ensuring alignment to a broader strategic design\n  \n \n \n   Preferred Skills\n  \n \n \n   Experience in Azure, Azure Pipelines, Azure Devops\n  \n \n \n   Excellent understanding of T-SQL programming\n  \n \n \n   Critical thinker and problem-solving skills and analyze data issues\n  \n \n \n   Knowledge of testing and unit testing\n  \n \n \n   Knowledge of medical, insurance, and optical systems/industry\n  \n \n \n   #LI-REMOTE\n  \n \n   #LI-VISIONCARE\n  \n \n \n   Compensation range for the role is listed below. Applicable salary ranges may differ across markets.\n     Actual pay will be determined based on experience and other job-related factors permitted by law. As a part of the compensation package, this role may include eligible bonuses, equity and commissions. For more information regarding VSP Vision benefits, please \n   \n   click here\n   .\n  \n  Salary Ranges: $80,000.00 - $135,000.00\n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                        VSP Vision is an equal opportunity employer and gives consideration for employment to qualified applicants without regard to age, gender, race, color, religion, sex, national origin, gender identity, sexual orientation, disability or protected veteran status. We maintain a drug-free workplace and perform pre-employment substance abuse testing.\n                       \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n   Notice to Candidates: Fraud Alert - Fake Job Opportunity Solicitations Used to Collect Fees/Personal Information.\n  \n \n  We have been made aware that fake job opportunities are being offered by individuals posing as VSP Vision and affiliate recruiters. \n   \n   Click here \n   to learn about our application process and what to watch for regarding false job opportunities.\n  \n \n \n   As a regular part of doing business, VSP Vision (\u201cVSP\u201d) collects many different types of personal information, including protected health information, about our audiences, including members, doctors, clients, brokers, business partners, and employees. VSP Vision employees will have access to this sensitive personal information and are subject to follow Information Security and Privacy Policies.",
        "cleaned_desc": "The Senior Data Engineer designs, builds and optimizes data pipelines for key data and analytics capabilities in the enterprise. This position works in collaboration with analytics and data warehousing staff, DBAs and subject matter experts to create reliable processes that load targeted data with integrity and quality, enabling it for strategic use by the business.\n  \n \n   Collaborate within an agile, multi-disciplinary team to deliver optimal data integration and transformation solutions\n  \n \n \n   Analyze data requirements (functional and non-functional) to develop and design robust scalable automated, fault-tolerant data pipeline solutions for business and technology initiatives\n  \n \n \n   Profile data to assess the accuracy and completeness of data sources and provide feedback in data-gathering sessions\n  \n \n \n   Design, build, maintain, and operationalize data pipelines for high volume and complex data using appropriate tools and practices in development, test, and production environments. Design with modularity to leverage reuse of code wherever possible\n  \n \n \n   Develop and design data mappings, programs, routines, and SQL to acquire data from legacy, web, cloud, and purchased package environments into the analytics environment\n  \n \n \n   Understand and apply the appropriate use of ELT, ETL, data virtualization, and other methods to optimize the balance of minimal data movement against performance, and mentor others on their appropriate use\n  \n \n \n   Drive automation of data pipeline preparation and integration tasks to minimize manual and error-prone processes and improve productivity using modern data preparation, integration, and AI-enabled metadata management tools and techniques\n  \n \n \n   Leverage auditing facilities that will enable monitoring of data quality to detect emerging issues. Deploy transformation rules to cleanse against defined rules and standards\n  \n \n \n   Participate in architecture, governance, and design reviews, identifying opportunities and making recommendations\n  \n \n     Participate in health check assessments of the existing environment and evaluations of emerging technologies\n  \n \n \n   Collaborate with architects to design and model application data structures, storage, and integration in accordance with enterprise-wide architecture standards across legacy, web, cloud, and purchased package environments\n  \n \n \n   Job Specifications\n  \n \n \n  Typically has the following skills or abilities: \n \n \n \n   Bachelor\u2019s degree in computer science, data science, statistics, economics, or related functional area; or equivalent experience\n  \n \n \n   Excellent written and verbal communication skills with the ability to gather requirements and effectively communicate technical concepts and ideas to all levels of employees and management\n  \n \n \n   6+ years\u2019 experience working in development team providing analytical capabilities\n  \n \n \n   6+ years of hands-on experience in the data space spanning data preparation, SQL, integration tools, ETL/ELT/data pipeline design\n  \n \n \n   SQL coding experience\n  \n \n \n   Experience working in an agile development environment (Scrum, Kanban) with a focus on Continuous Integration and Delivery\n  \n   \n   Knowledge about various data architectures, patterns and capabilities such as event-driven architecture, real-time data flows, non-relational repositories, data virtualization, cloud storage, etc.\n  \n \n \n   Knowledge of and experience with multiple data integration platforms (IBM InfoSphere DataStage, Oracle Data Integrator, Informatica PowerCenter, MS SSIS, AWS Glue, Denodo), and data warehouse MPP platforms such Snowflake, Netezza, Teradata, Redshift, etc.\n  \n \n \n   Familiarity with DataOps practices and their application within analytics environments as well as their ability to extend data and analytics capabilities to other operational systems and consumers\n  \n \n \n   Familiarity with event store and stream processing (Apache Kafka and platforms like Confluent) and with API development and management platforms (MuleSoft, Axway) is beneficial\n  \n \n \n   Capable of focusing on a specific set of tasks while also ensuring alignment to a broader strategic design\n  \n \n \n   Preferred Skills\n  \n \n \n   Experience in Azure, Azure Pipelines, Azure Devops\n  \n \n \n   Excellent understanding of T-SQL programming\n  \n \n \n   Critical thinker and problem-solving skills and analyze data issues\n  \n \n \n   Knowledge of testing and unit testing\n  ",
        "techs": [
            "ibm infosphere datastage",
            "oracle data integrator",
            "informatica powercenter",
            "ms ssis",
            "aws glue",
            "denodo",
            "snowflake",
            "netezza",
            "teradata",
            "redshift",
            "apache kafka",
            "confluent",
            "mulesoft",
            "axway"
        ],
        "cleaned_techs": [
            "ibm infosphere datastage",
            "oracle",
            "informatica powercenter",
            "ms ssis",
            "aws",
            "denodo",
            "snowflake",
            "netezza",
            "teradata",
            "redshift",
            "apache kafka",
            "confluent",
            "mulesoft",
            "axway"
        ]
    },
    "39dbeb5fcc9497a2": {
        "terms": [
            "data science"
        ],
        "salary_min": 133804.8,
        "salary_max": 169426.7,
        "title": "Solutions Specialist, Verily Workbench",
        "company": "Verily",
        "desc": "Remote-US \n  Solutions Specialist, Verily Workbench \n \n \n \n  Who We Are \n  Verily is a subsidiary of Alphabet  that is using a data-driven approach to change the way people manage their health and the way healthcare is delivered. Launched from Google X in 2015, our purpose is to bring the promise of precision health to everyone, every day. We are focused on generating and activating data from a variety of sources, including clinical, social, behavioral and the real world, to arrive at the best solutions for a person based on a comprehensive view of the evidence. Our unique expertise and capabilities in technology, data science and healthcare enable the entire healthcare ecosystem to drive better health outcomes. \n \n  DESCRIPTION \n  Verily\u2019s Clinical Research business is focused on transforming evidence generation within clinical research. Our portfolio of solutions is focused on: 1) participant engagement to optimize and diversify recruitment and retention, 2) longitudinal registries and communities to support the continuous evaluation of medical products over their lifetime, 3) solutions to support participant centric, multi-modal clinical trials, and 4) digital biomarkers for generating new types of data and insights. With Verily Workbench, we aim to enable the next generation of collaborative biomedical research by building an open platform that connects researchers to each other and to the datasets and tools they need to achieve scientific breakthroughs. \n  As a Solution Specialist for Verily Workbench, you will be responsible for managing the sales process to bring the solution to existing and new life sciences customers. This will include understanding customer needs, acting as a trusted advisor to match the solution, driving pricing and contracting and ensuring that the implementation team is set up for success. You will work cross functionally within the Clinical Research Commercial team and with colleagues across Verily. This role will require you to be flexible and nimble and aggressively grow the business to help establish Verily as the premier solution partner in the space. \n  RESPONSIBILITIES \n \n Build and maintain strong relationships with customers and partners. \n Focus on transformational outcomes that make an impact for patients, clinical investigators and the life sciences companies we serve. \n Lead strategic sales processes from lead generation to close, including presenting value propositions, identifying and addressing customer needs, negotiating business terms and executing contracts. \n Gather valuable feedback from customers and partners on pricing, market challenges, innovation and the competitive landscape. \n Collaborate across the Verily organization to achieve personal goals, team objectives and company milestones. \n \n QUALIFICATIONS \n  Minimum Qualifications: \n \n Bachelor\u2019s degree in business, healthcare or related fields. \n Deep understanding of clinical research for biopharma companies. \n 10+ years of relevant experience in Enterprise sales focused on research data platforms, SaaS, Real Word Data and scientific services. \n 3+ years selling clinical research data platform solutions. \n Experience selling complex solutions and driving significant revenue growth. \n Highly consultative, hands on and collaborative. \n Excellent communication, presentation and analytical skills. \n \n Preferred Qualifications: \n \n Proven ability to work with complex, technical software and service offerings, and processes involving multiple stakeholders. \n Ability to take initiative, work efficiently and respond quickly to changes and a dynamic environment. \n A positive attitude, open mind, entrepreneurial mindset and a desire to collaborate and learn. \n Connection to Verily\u2019s corporate purpose \u2026 to bring the promise of precision health to everyone, every day. \n Experience with Salesforce.com and Google suite of productivity applications (gMail, gCalendar, Sheets, Slides, Docs). \n \n The US base salary range for this full-time position is $145,000 - $170,000 + bonus + equity + benefits. Our salary ranges are determined by role, level and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. \n  #LI-REMOTE \n  #LI-MM1 \n  #LI-TB1 \n  #LI-Remote \n \n  Why Join Us \n  Build What\u2019s Vital. \n  At Verily, you are a part of something bigger. We are a diverse team of builders innovating at the intersection of health and technology\u2014united by a shared spirit of curiosity, resilience and determination to make better health possible for all. This builder mindset means your fingerprints will be on the work that shapes the future of health. \n  Fulfilling our precision health purpose starts with the health of our Veeps, which is why we offer flexibility, resources, and competitive benefits to support you in your whole-person well being. \n  Our culture reflects the behaviors that stem from living our values every day in how we Innovate Healthcare and Technology, Gain Velocity as One Verily, and Respect Individuals. As One Verily, we uphold our collective accountability to sustain this culture and to create a VIBE (Verily\u2019s Culture of Inclusion, Belonging, and Equitability) where all Veeps feel included, a sense of belonging, and have opportunities to grow. \n  If this sounds exciting to you, we would love to hear from you.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b28d405c34f86a83": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "59fecb9de7cc2d02": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "795f69df685286e5": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 112875.03,
        "salary_max": 142924.94,
        "title": "Machine Learning Infra Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n rS7VWRESBg",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "da35edea63f2f0f0": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Insurance Product Manager (Remote, US)",
        "company": "Openly",
        "desc": "Openly is rebuilding insurance from the ground up. We are re-envisioning and enhancing every aspect of the customer experience. Doing this requires a rapidly growing team of exceptional, curious, empathetic people with a wide range of skill sets, spanning technology, data science, product, marketing, sales, service, claims handling, finance, etc. \n  Now is the perfect time to join the journey. Here's why \n \n It's working . We're in multiple states and on our way to operating countrywide. We have thousands of agents selling our product and millions of dollars of annual customer premiums. \n We're well-backed & stable.  We closed our $75M Series C fundraise. We are supported by some of the top investors globally, including Google's \"Gradient\" AI-focused fund, Obvious Ventures (Beyond Meat, etc.), and Advance Venture Partners. \n It's not too late!  Despite this traction and stability, we're still early enough in the journey that there's time to make a real difference during Openly's formative period. \n \n If you'd like to understand more about Openly's mission, consider checking out this video (https://vimeo.com/267654520) from a company pitch we gave several years ago at Techstars. \n \n  We are seeking an  Insurance Product Manager  to help drive our state expansion efforts and bring Openly insurance products to independent agents across the country. Reporting to the Senior Manager of Insurance Product Management, this highly visible role offers the opportunity to lead key insurance product management initiatives and interact with business leaders across Technology and Operations Teams. This role requires a self-motivated, high-energy individual who can efficiently function in a fast-paced, performance-driven environment. \n \n \n  Key Responsibilities \n \n Developing and calibrating Openly's homeowners program for established states and new state entries including UW eligibility, coverage offerings, premium rates, and Openly proprietary models \n Assisting with rate filings and DOI correspondence to ensure timely regulatory approval \n Collaborating with our Technology and Operations teams to successfully implement and launch the product in new states \n Analyzing key performance indicators and drivers of profitability, including loss ratios, actuarial indications, frequency/severity trends, sales conversion, persistency, and other data as we continue to grow our geographic footprint \n Leading other product management initiatives, such as external data evaluations, market/competitor intelligence, and new product development \n \n Requirements \n \n 3-5 years of experience in insurance product management and product development roles \n A degree in Mathematics, Actuarial Science, Economics, Statistics, or similar study \n Solid technical (SQL) and analytical skills, capable of developing quantitative analyses through data manipulation \n Ability to identify and define complex business problems and develop relevant analytical frameworks to deliver solutions, often operating in ambiguity and leveraging creativity \n Strong communication and project management skills, and the ability to collaborate effectively with people at all levels across the company \n Strong decision-making skills \n P&C insurance experience is required, and homeowners insurance experience is a plus \n Insurance product compliance and/or state launch experience is a plus \n \n \n \n  Benefits & Perks \n \n Competitive salary, corporate bonus program, equity position in a start-up company \n Company-sponsored medical, dental, vision insurance plans, short-term and long-term disability, life insurance, 401k with corporate contribution, and FSA plan \n Company-paid 12 weeks parental leave policy \n The company fully embraces the \"work-from-anywhere in the US\" mentality, even before COVID restrictions. \n Paid Time Off \n Fun, fast-paced, startup environment \n \n U.S. Citizens, Green Card Holders, and those authorized to work in the U.S. for any employer and currently residing in the US will be considered. \n  Openly is committed to equal employment opportunity and non-discrimination for all employees and qualified applicants without regard to a person's race, color, sex, gender identity or expression, age, religion, national origin, ancestry, ethnicity, disability, veteran status, genetic information, sexual orientation, marital status, or any characteristic protected under applicable law. Openly is an E-Verify Employer in the United States. Openly will make reasonable accommodations for qualified individuals with known disabilities under applicable law.",
        "cleaned_desc": " Solid technical (SQL) and analytical skills, capable of developing quantitative analyses through data manipulation \n Ability to identify and define complex business problems and develop relevant analytical frameworks to deliver solutions, often operating in ambiguity and leveraging creativity \n Strong communication and project management skills, and the ability to collaborate effectively with people at all levels across the company \n Strong decision-making skills \n P&C insurance experience is required, and homeowners insurance experience is a plus \n Insurance product compliance and/or state launch experience is a plus \n \n ",
        "techs": [
            "sql",
            "data manipulation",
            "quantitative analyses",
            "business problems",
            "analytical frameworks",
            "communication skills",
            "project management skills",
            "decision-making skills",
            "p&c insurance",
            "homeowners insurance",
            "insurance product compliance",
            "state launch experience"
        ],
        "cleaned_techs": [
            "sql",
            "data manipulation",
            "quantitative analyses",
            "business problems",
            "analytical frameworks",
            "p&c insurance",
            "homeowners insurance",
            "insurance product compliance",
            "state launch experience"
        ]
    },
    "6372e4511954c30b": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "6ec7536772937e63": {
        "terms": [
            "data science"
        ],
        "salary_min": 68640.0,
        "salary_max": 75000.0,
        "title": "Court Research Associate",
        "company": "National Center for State Courts",
        "desc": "Job Summary \n \n \n The National Center for State Courts (NCSC) is an independent, non-profit court improvement organization. NCSC's services-research, information services, education, consulting, association management and technical assistance-are focused on helping courts plan, make decisions, and implement improvements that save time and money, while ensuring judicial administration that supports fair and impartial decision-making. For additional information, visit NCSC.org    NCSC is looking for an experienced Court Research Associate to join our Research & Design Group. The Court Research Associate is responsible for contributing to all aspects of planning, organizing, and conducting research for improving various aspects of state court administration, including the development of research initiatives and proposal for grant funding, designing and conducting the research, and disseminating results through written and online products and presentations targeted to a variety of practitioner and scholarly audiences. \n \n \n \n Duties and Responsibilities \n \n \n \n \n Demonstrates conduct that upholds the basic Core Values of NCSC \n  Comprehends and assesses the impact of contemporary issues on the state courts. \n  Conducts empirical and applied research and program evaluations, including the design of qualitative and quantitative data collection instruments and protocols. \n  Compiles and maintains project databases for multiple projects, taking responsibility for accuracy, comparability, and completeness of data records. \n  Documents data collection methods and instruments and archives data sets according to funding agency instructions. \n  Conducts site visits (e.g., for conducting interviews, focus groups, observations) with constituents. \n  Contributes to building infrastructure (e.g., data visualizations, web-based story boarding, data dashboards, reference materials, practitioner publications, project reports) to effectively communicate research findings to a diverse audience of end users. \n  Presents research findings (e.g., conferences, facilitated workgroups, publications) to diverse audiences (e.g., court-related leadership organizations, practitioners, and lay people) \n  Serves as a resource for staff of state court systems, government agencies, academic institutions, media, and other organizations as requested. \n  Authors various documents, such as: research reports, policy memoranda, and journal articles that convey information in an easily understood and accessible manner. Reviews written materials of other projects for clarity; coordinates activities associated with publishing, disseminating, and marketing research deliverables. \n  Assists in the business development of a proposal idea, conducts research on topics/literature reviews, works on the preparation of proposals/RFPs/concept papers from federal, state, and private funding sources. \n \n \n \n \n Qualifications \n \n \n \n \n Master's degree and/or J.D. with 3+ years of experience in conducting applied social science research, or data science techniques that demonstrates the knowledge, skills and ability to perform the duties of the position,  OR  a Ph.D. in social sciences, public policy, or related field \n  Project management experience \n  Ability to travel \n  Grant writing experience, preferred \n  Additional Skills & Abilities\n    \n \n  Excellent communication skills \u2013 written, verbal, interpersonal, presentation, and facilitation and the ability to communicate complex ideas effectively both orally and written. \n  Proficiency in MS Office: Word, Excel, Outlook, and PowerPoint \n  Ability to design research studies and conduct statistical analyses using multiple techniques. \n  Ability to comprehend and assess the impact of contemporary issues on the state courts. \n  Experience conducting applied social science research including inferential statistics, using advanced analytical techniques, and creating data visualizations. \n  Maintains knowledge of a variety of current statistical and analytic techniques \n  Thinks conceptually, synthesizes data, and draws conclusions relevant for the court community \n \n \n \n \n Additional Information \n \n \n \n \n    The annual starting salary for this role is between $68,640 - $75,000 factors which affect starting pay within the range include skills, education and experience and other qualifications as it relates to the position.\n    \n \n \n  This position closes on October 1, 2023. Please submit your resume and cover letter in addition to your completed NCSC application. For the reference section, include professional references only with at least one previous or current supervisor.\n    \n \n \n  Trusted Leadership. Proven Solutions. Better Courts. Come join the NCSC Team.\n    \n \n \n  NCSC is an equal opportunity/disability/veteran employer. \n \n \n  Committed to Diversity, Equity & Inclusion \n \n \n \n \n \n \n \n \n \n NCSC provides a comprehensive benefit package for  Regular Full-time and Regular Part-Time employees  consisting of: \n \n All Purpose Leave (APL): Paid time off for vacation, sick, and other types of personal absences.  \n Holidays: NCSC observes ten (10) paid holidays  \n Medical Insurance, Dental and Vision Insurance  \n Short-term & Long-term Disability coverage at no cost to the employee  \n Life & Accidental Death Insurance: NCSC provides life insurance for employees and fully pays the premium. Employees are covered at three times their salary for the life policy and the accidental death policy. NCSC also provides Insurance for spouses in the amount of $5,000 and $2,500 for children.  \n Retirement/Pension: NCSC contributes 9% of salary to a Money Purchase Plan Pension account for each employee (no deductions from salary)",
        "cleaned_desc": "  Ability to travel \n  Grant writing experience, preferred \n  Additional Skills & Abilities\n    \n \n  Excellent communication skills \u2013 written, verbal, interpersonal, presentation, and facilitation and the ability to communicate complex ideas effectively both orally and written. \n  Proficiency in MS Office: Word, Excel, Outlook, and PowerPoint \n  Ability to design research studies and conduct statistical analyses using multiple techniques. \n  Ability to comprehend and assess the impact of contemporary issues on the state courts. \n  Experience conducting applied social science research including inferential statistics, using advanced analytical techniques, and creating data visualizations. \n  Maintains knowledge of a variety of current statistical and analytic techniques \n  Thinks conceptually, synthesizes data, and draws conclusions relevant for the court community \n \n \n \n \n Additional Information ",
        "techs": [
            "ability to travel",
            "grant writing experience",
            "excellent communication skills",
            "proficiency in ms office (word",
            "excel",
            "outlook",
            "powerpoint)",
            "ability to design research studies and conduct statistical analyses",
            "ability to comprehend and assess the impact of contemporary issues on the state courts",
            "experience conducting applied social science research including inferential statistics",
            "maintains knowledge of a variety of current statistical and analytic techniques",
            "thinks conceptually",
            "synthesizes data",
            "and draws conclusions relevant for the court community"
        ],
        "cleaned_techs": [
            "grant writing experience",
            "proficiency in ms office (word",
            "excel",
            "outlook",
            "powerpoint)",
            "experience conducting applied social science research including inferential statistics",
            "maintains knowledge of a variety of current statistical and analytic techniques",
            "thinks conceptually",
            "synthesizes data",
            "and draws conclusions relevant for the court community"
        ]
    },
    "34cfac0355d32c72": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "faa80dbc10247ecf": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "381b76705ecad879": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 112309.37,
        "salary_max": 142208.69,
        "title": "Machine Learning Infra Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Ideal candidate traits: \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n \n   \n   \n v4b0OHso1x",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6156776f7f7749d2": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 120107.0,
        "salary_max": 133527.0,
        "title": "Machine Learning Imaging Scientist",
        "company": "Hoth Intelligence",
        "desc": "Machine Learning Engineer \n Duties: - Develop and implement machine learning algorithms and models - Collaborate with cross-functional teams to gather requirements and define project objectives - Collect, clean, and preprocess large datasets for analysis - Apply statistical analysis and data mining techniques to extract insights from complex datasets - Design and optimize machine learning models for accuracy and efficiency - Evaluate and validate model performance using appropriate metrics - Stay up-to-date with the latest advancements in machine learning and data science - Communicate findings and insights to stakeholders in a clear and concise manner \n Skills: - Strong programming skills in languages such as Python, R, or Java - Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn - Proficiency in data manipulation and analysis using SQL, Pandas, or NumPy - Knowledge of big data technologies like Hadoop or Spark - Familiarity with VBA (Visual Basic for Applications) for automation tasks - Understanding of quantum engineering principles is a plus - Excellent problem-solving and analytical thinking abilities - Strong communication skills to collaborate effectively with team members \n Join our team as a Machine Learning Engineer and contribute to cutting-edge projects in the field of data analytics. As a key member of our team, you will have the opportunity to work on challenging problems and make a significant impact on our business. \n We offer competitive compensation packages, including benefits such as health insurance, retirement plans, and professional development opportunities. Don't miss this exciting opportunity to be part of our innovative team! \n Apply now by submitting your resume and highlighting your relevant experience in machine learning engineering. \n Job Type: Full-time \n Pay: $120,107.00 - $133,527.00 per year \n Benefits: \n \n Flexible schedule \n Health insurance \n Paid time off \n \n Supplemental pay types: \n \n Signing bonus \n \n Experience: \n \n Python: 3 years (Required) \n C++: 3 years (Required) \n C#: 1 year (Preferred) \n PyTorch: 2 years (Preferred) \n image segmentation: 3 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Machine Learning Engineer \n Duties: - Develop and implement machine learning algorithms and models - Collaborate with cross-functional teams to gather requirements and define project objectives - Collect, clean, and preprocess large datasets for analysis - Apply statistical analysis and data mining techniques to extract insights from complex datasets - Design and optimize machine learning models for accuracy and efficiency - Evaluate and validate model performance using appropriate metrics - Stay up-to-date with the latest advancements in machine learning and data science - Communicate findings and insights to stakeholders in a clear and concise manner \n Skills: - Strong programming skills in languages such as Python, R, or Java - Experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn - Proficiency in data manipulation and analysis using SQL, Pandas, or NumPy - Knowledge of big data technologies like Hadoop or Spark - Familiarity with VBA (Visual Basic for Applications) for automation tasks - Understanding of quantum engineering principles is a plus - Excellent problem-solving and analytical thinking abilities - Strong communication skills to collaborate effectively with team members \n Join our team as a Machine Learning Engineer and contribute to cutting-edge projects in the field of data analytics. As a key member of our team, you will have the opportunity to work on challenging problems and make a significant impact on our business. \n We offer competitive compensation packages, including benefits such as health insurance, retirement plans, and professional development opportunities. Don't miss this exciting opportunity to be part of our innovative team! ",
        "techs": [
            "machine learning engineer",
            "python",
            "r",
            "java",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "sql",
            "pandas",
            "numpy",
            "hadoop",
            "spark",
            "vba (visual basic for applications)"
        ],
        "cleaned_techs": [
            "python",
            "r",
            "java",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "sql",
            "pandas",
            "numpy",
            "hadoop",
            "spark"
        ]
    },
    "188f5f301243afe9": {
        "terms": [
            "data science"
        ],
        "salary_min": 245523.0,
        "salary_max": 250000.0,
        "title": "Senior Actuarial Data Scientist",
        "company": "Ledger Investing",
        "desc": "the This notice is being provided as the result of the filing of a permanent labor certification application for the position of Senior Actuarial Data Scientist. The position will report to the NYC office and can work remotely from anywhere in the continental U.S. Use cutting-edge statistical techniques to stochastically model the underwriting performance of insurance programs for the purposes of securitization. Draw on a combination of statistical, actuarial, and business experience to formulate new statistical models that can be used to better forecast future performance of insurance portfolios. Rigorously backtest potential new models on corpora of historical data to validate whether the new models perform significantly better in practice. \n Help implement new statistical models in software in a robust, audited verifiable manner in a production environment. Clearly document and organize all work, including providing written and oral reports to key stakeholders inside and outside of the organization. Duties may involve leading small teams of peers and/or subordinates on specific projects. Masters' degree or foreign equivalent in Data Science, Statistics, Actuarial Science, or a similar quantitative field + 3 years\u2019 experience in position or as Actuarial Associate/Actuarial Consultant. 3 years\u2019 experience to include 3 years with actuarial science and/or data science, demonstrating a progressive increase in scope of responsibilities. 3 years\u2019 experience to include 3 years\u2019 experience in Python and/or R programming skills. ACAS from the Casualty Actuarial Society or equivalent required. Travel domestically 5% of the year. Salary $245,523.00 to $250,000/year. Contact: Georgena Frazier at georgena.frazier@ledgerinvesting.com \n THIS POSITION QUALIFIES FOR LEDGER INVESTING\u2019S EMPLOYEE REFERRAL INCENTIVE PROGRAM Any person may provide documentary evidence bearing on the application to the Certifying Officer of the U.S. Department of Labor as follows: U.S. Department of Labor, Employment and Training Administration, Office of Foreign Labor Certification, 200 Constitution Avenue NW, Room N-5311, Washington, DC 20210 \n Job Type: Full-time \n Pay: $245,523.00 - $250,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Tuition reimbursement \n Vision insurance \n \n Physical setting: \n \n Office \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Supplemental pay types: \n \n Bonus opportunities \n \n Application Question(s): \n \n ACAS from the Casualty Actuarial Society or equivalent required \n \n Experience: \n \n Python and/or R: 3 years (Required) \n \n Willingness to travel: \n \n 25% (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "5d26e39d9d2ea891": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 112309.37,
        "salary_max": 142208.69,
        "title": "Machine Learning Infra Engineer",
        "company": "Cyberjin",
        "desc": "Remote Position \n  Our client is looking for a Machine Learning Engineer (infra hacker) who has scaled ML systems to 1M + users, is willing to go deep in the weeds on r&d, cares a ton about how backend systems work, has worked on large systems but executes like a startup, fast, ships and iterates.  \n Additional: \n  Ideal candidate traits \n  Previously scaled ML systems to 1M + users \n  Willing to go deep in the weeds on research & development \n \n \ufe0f Cares a ton about how backend systems work \n \n  Has worked on large systems but executes like a startup, fast, ships and iterates \n   \n 5o7uS72FJd",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "9105bfce513d45f3": {
        "terms": [
            "data science"
        ],
        "salary_min": 107392.484,
        "salary_max": 135982.81,
        "title": "Machine Learning Developer",
        "company": "Absorb Software",
        "desc": "\"We're transforming the educational landscape by incorporating machine learning into our products. My team and I are a crucial part of Absorb's growth story, contributing to solutions that make learning personalized and impactful. If you're passionate about machine learning and want to join a team of innovators, this role is for you.\" Ju An Park - ML Developer \n About the role: \n The Machine Learning Developer will be responsible for development and maintenance of machine learning models and services at Absorb. You will work closely with cross-functional teams to implement, deploy and support machine learning features that enhance user experience, engagement, and learning outcomes. \n \n Absorb Software: Remote Work Culture \n What you'll do \n \n Develop, deploy and support machine learning models and associated services of the organization. \n Develop REST APIs in Python with best coding and engineering practices for scalability and availability. \n Develop and improve CI/CD pipelines associated with machine learning projects. \n Stay up-to-date with the latest advancements in machine learning and AI. \n \n What you'll bring \n \n Bachelor's degree or above in Computer Science, Data Science, or a related field; Master's preferred. \n Strong understanding of data analysis, machine learning algorithms, and performance optimization techniques. \n Proficient in Python and machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. \n Proficient in using scientific computing libraries such as numpy, SciPy and Pandas. \n Experience in backend web development using Python. \n Experience with cloud services like AWS, Azure, or Google Cloud. \n Experience in Natural Language Processing (NLP) is a plus. \n \n Are you ready to become an Absorber? \n What we offer: \n \n Fully remote-first work with flexible work arrangements. \n Comprehensive Health and Wellness Benefits including retirement savings. programs, eligibility for two different bonus plans, generous time off, comprehensive medical and dental benefits based on your country of location. \n New Hire Equipment Allowance and monthly Flex Allowance to support your success. \n Endless opportunity for career growth and internal mobility. \n Employee driven DE&I programs. \n \n Who are we? \n Absorb Software is a remote-first company that provides online training solutions to leading organizations around the world. Absorb is a cloud-based learning management system (LMS) engineered to inspire learning and fuel business productivity. Our online learning platform combines forward-thinking technology built to scale as our customer\u2019s organizations grow. We empower learners to enrich their lives, workplaces and communities. \n Our values are simple: \n \n We achieve exceptional results by genuinely caring about each other and the work we do \n We\u2019re united, and we grow through our commitment to elevating continual learning! \n \n Absorb is proud to be an equal opportunity employer, we celebrate diversity and are committed to creating a safe and inclusive environment for all our people. All employment decisions are based on business needs, job requirements and individual qualifications. In the event a current Absorb employee would like to apply for this role they will inform their supervisor prior to submitting their application. Successful candidates for this position will be subject to pre-employment background screening, including a criminal record check and must be able to show proof of legal eligibility to work in the country they have applied to without sponsorship. \n Should you require any accommodation during the recruitment process, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, please contact us at accessiblecareers@absorblms.com",
        "cleaned_desc": " Develop, deploy and support machine learning models and associated services of the organization. \n Develop REST APIs in Python with best coding and engineering practices for scalability and availability. \n Develop and improve CI/CD pipelines associated with machine learning projects. \n Stay up-to-date with the latest advancements in machine learning and AI. \n \n What you'll bring \n   Bachelor's degree or above in Computer Science, Data Science, or a related field; Master's preferred. \n Strong understanding of data analysis, machine learning algorithms, and performance optimization techniques. \n Proficient in Python and machine learning libraries such as TensorFlow, PyTorch, or scikit-learn. \n Proficient in using scientific computing libraries such as numpy, SciPy and Pandas. \n Experience in backend web development using Python. \n Experience with cloud services like AWS, Azure, or Google Cloud. \n Experience in Natural Language Processing (NLP) is a plus. ",
        "techs": [
            "machine learning models",
            "rest apis",
            "python",
            "coding and engineering practices",
            "scalability",
            "availability",
            "ci/cd pipelines",
            "computer science",
            "data science",
            "bachelor's degree",
            "master's degree",
            "data analysis",
            "machine learning algorithms",
            "performance optimization techniques",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "scientific computing libraries",
            "numpy",
            "scipy",
            "pandas",
            "backend web development",
            "cloud services",
            "aws",
            "azure",
            "google cloud",
            "natural language processing (nlp)"
        ],
        "cleaned_techs": [
            "rest apis",
            "python",
            "coding and engineering practices",
            "scalability",
            "availability",
            "ci/cd pipelines",
            "computer science",
            "data science",
            "machine learning algorithms",
            "performance optimization techniques",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "scientific computing libraries",
            "numpy",
            "scipy",
            "pandas",
            "backend web development",
            "cloud services",
            "aws",
            "azure",
            "gcp",
            "nlp"
        ]
    },
    "27af42d1485501ec": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 60.0,
        "salary_max": -1.0,
        "title": "Machine Learning Engineer",
        "company": "Zenotis Technologies Inc",
        "desc": "Key Responsibilities: \n \n Fine-tune and serve LLMs to help build best-in-class solutions on NLP and Generative AI \n Stay up-to-date with recent advancements in NLP and large language models, applying novel techniques and methodologies to improve our models. \n Be curious with new industry learnings, startups utilizing LLMs in novel ways, and other ways the real world is utilizing LLMs. \n Conduct experiments and benchmarking to assess the performance of various model architectures and optimize hyperparameters. \n Apply, discover and research techniques to optimize existing LLM training and serving, as well as improving the model quality. \n Generate comprehensive client corpus data from various systems for LLM use cases \n Build and maintain production ready ML pipelines \n Build and maintain a production-ready platform to run models in parallel and A/B test \n Prepare and preprocess data in collaboration with the data engineering team \n \n Required Job Qualifications \n Required: \n \n Bachelor\u2019s degree or equivalent experience in MIS, Computer Science, Mathematics, Machine Learning, Data science or related field \n 5+ years of experience in Machine learning related field including prior lead experience \n Hands-on experience in developing models, in optimizing model training and tuning and in deploying Large Language Models such as GPT, LLaMA, BERT, or Transformer-based architectures with strong knowledge in tokenization and embeddings. \n Knowledge on Natural Language Processing, Information Retrieval, Machine Comprehension, Question Answering/Conversational AI, Reinforcement Learning and Inference \n 2+ plus years of experience in developing deep learning models as a Data Scientist and experience in building products backed up ML /AI using NLP algorithms \n Advanced in-depth knowledge of Predictive Analytics, Statistical modeling, advanced mathematics, data integration concepts and tools \n Strong organizational, analytical, critical thinking and leadership skills \n Demonstrated leadership on mid-large-scale project impacting strategic partners \n Background in Machine Learning frameworks such as TensorFlow, SparkML or Keras, Scikit Learn \n Proficiency in Scala, Python or an equivalent language \n Familiarity with Statistical Machine Learning models, Machine Learning concepts like Natural Language Processing, Image Processing, Recommendation Systems, etc. \n Deep knowledge of math, probability, statistics, and algorithms, Machine Learning Development Lifecycle, Model monitoring, Data Exploration, Bias detection/removal, Explainable AI \n Experience with AWS DevOps tools (e.g. Sagemaker, Lambda) \n Experience with CI/CD tools (e.g. github, bamboo) and best practices \n \n Job Type: Contract \n Salary: From $60.00 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": " \n Bachelor\u2019s degree or equivalent experience in MIS, Computer Science, Mathematics, Machine Learning, Data science or related field \n 5+ years of experience in Machine learning related field including prior lead experience \n Hands-on experience in developing models, in optimizing model training and tuning and in deploying Large Language Models such as GPT, LLaMA, BERT, or Transformer-based architectures with strong knowledge in tokenization and embeddings. \n Knowledge on Natural Language Processing, Information Retrieval, Machine Comprehension, Question Answering/Conversational AI, Reinforcement Learning and Inference \n 2+ plus years of experience in developing deep learning models as a Data Scientist and experience in building products backed up ML /AI using NLP algorithms \n Advanced in-depth knowledge of Predictive Analytics, Statistical modeling, advanced mathematics, data integration concepts and tools   Strong organizational, analytical, critical thinking and leadership skills \n Demonstrated leadership on mid-large-scale project impacting strategic partners \n Background in Machine Learning frameworks such as TensorFlow, SparkML or Keras, Scikit Learn \n Proficiency in Scala, Python or an equivalent language \n Familiarity with Statistical Machine Learning models, Machine Learning concepts like Natural Language Processing, Image Processing, Recommendation Systems, etc. \n Deep knowledge of math, probability, statistics, and algorithms, Machine Learning Development Lifecycle, Model monitoring, Data Exploration, Bias detection/removal, Explainable AI \n Experience with AWS DevOps tools (e.g. Sagemaker, Lambda) ",
        "techs": [
            "mis",
            "computer science",
            "mathematics",
            "machine learning",
            "data science",
            "lead experience",
            "large language models",
            "gpt",
            "llama",
            "bert",
            "transformer-based architectures",
            "tokenization",
            "embeddings",
            "natural language processing",
            "information retrieval",
            "machine comprehension",
            "question answering/conversational ai",
            "reinforcement learning",
            "inference",
            "deep learning models",
            "data scientist",
            "ml/ai",
            "nlp algorithms",
            "predictive analytics",
            "statistical modeling",
            "advanced mathematics",
            "data integration concepts",
            "tools",
            "organizational skills",
            "analytical skills",
            "critical thinking skills",
            "leadership skills",
            "machine learning frameworks",
            "tensorflow",
            "sparkml",
            "keras",
            "scikit learn",
            "scala",
            "python",
            "statistical machine learning models",
            "natural language processing",
            "image processing",
            "recommendation systems",
            "math",
            "probability",
            "statistics",
            "algorithms",
            "machine learning development lifecycle",
            "model monitoring",
            "data exploration",
            "bias detection/removal",
            "explainable ai",
            "aws devops tools",
            "sagemaker",
            "lambda."
        ],
        "cleaned_techs": [
            "mis",
            "computer science",
            "mathematics",
            "data science",
            "lead experience",
            "large language models",
            "gpt",
            "llama",
            "bert",
            "transformer-based architectures",
            "tokenization",
            "embeddings",
            "nlp",
            "information retrieval",
            "machine comprehension",
            "question answering/conversational ai",
            "reinforcement learning",
            "inference",
            "deep learning models",
            "data scientist",
            "ml/ai",
            "predictive analytics",
            "statistical modeling",
            "advanced mathematics",
            "data integration concepts",
            "tools",
            "machine learning frameworks",
            "tensorflow",
            "sparkml",
            "keras",
            "scikit learn",
            "scala",
            "python",
            "statistical machine learning models",
            "image processing",
            "recommendation systems",
            "math",
            "probability",
            "statistics",
            "algorithms",
            "model monitoring",
            "bias detection/removal",
            "explainable ai",
            "aws",
            "sagemaker",
            "lambda."
        ]
    },
    "8c87a78eeac36a1a": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "1efc4455f455bc0a": {
        "terms": [
            "data science"
        ],
        "salary_min": 96000.0,
        "salary_max": 143000.0,
        "title": "Business Systems Analyst (Remote)",
        "company": "Sumitomo Mitsui Banking Corporation",
        "desc": "Join us on our mission to create a completely new, 100% digital bank that truly serves customers' best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch - and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience). \n \n  The anticipated salary range for this role is between $96,000.00 and $143,000.00. The specific salary offered to an applicant will be based on their individual qualifications, experiences, and an analysis of the current compensation paid in their geography and the market for similar roles at the time of hire. The role may also be eligible for an annual discretionary incentive award. In addition to cash compensation, SMBC offers a competitive portfolio of benefits to its employees. \n \n  We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the second largest bank in Japan and the 12th largest bank in the world with operations in over forty countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products. \n \n  It is the best of both worlds, and we are seeking proven marketing leaders to propel us towards a national launch. We have both the ambitious growth plans and the 'patient capital' necessary to execute a multi-year plan. Join us on the journey to deliver an exciting concept of evolved banking. \n \n \n \n  General Summary: \n \n \n  We are a dynamic startup bank on a mission to revolutionize the financial industry through data-driven insights and innovation. We are seeking a proactive and highly skilled Business Systems Analyst to join our data program team and drive technical requirement development. As a Business Systems Analyst, you will play a critical role in understanding data program needs, translating them into technical specifications, and collaborating with the engineering team, which operates as an outsourced contractor, to deliver successful data solutions. This is an exciting opportunity to contribute to the growth and success of our startup bank by leveraging the power of data. \n \n \n \n \n  Principal Duties and Responsibilities: \n \n \n  Data Program Needs Analysis: \n \n  Collaborate with stakeholders in the data program to understand their requirements and objectives. \n  Conduct comprehensive analysis of existing data systems and processes to identify areas of improvement. \n  Work with product owner to gather and document functional and technical requirements to guide data solution development. \n \n  Technical Requirement Development: \n \n  Translate data program requirements into clear and detailed technical specifications. \n  Collaborate with the product owner and engineering team to define data architecture and design innovative solutions. \n  Ensure technical requirements align with data program goals and overall project objectives. \n \n  Requirements Documentation: \n \n  Prepare well-organized requirement documents, including data use cases, user stories, and data flow diagrams. \n  Maintain thorough documentation of technical specifications for future reference and knowledge sharing. \n  Conduct regular reviews and updates of requirements based on project progress and changes. \n \n  Stakeholder Communication: \n \n  Work with the Product Owner to assist in translation of communication between data program stakeholders and the engineering team. \n  Clarify technical concepts to non-technical stakeholders and ensure alignment with data program goals. \n  Act as a bridge between data program needs and technical implementation, ensuring seamless coordination. \n \n  Quality Assurance and Testing Support: \n \n  Collaborate with QA and testing teams to develop data test cases based on technical requirements. \n  Review test results and provide feedback to ensure compliance with technical specifications. \n  Assist in troubleshooting and resolving technical issues during testing and implementation. \n \n  Continuous Improvement: \n \n  Monitor project progress and identify opportunities for process improvement and optimization. \n  Stay updated with industry trends and best practices in business analysis and data solution development. \n  Proactively propose innovative data solutions to enhance the efficiency and effectiveness of data projects. \n \n \n \n \n \n \n  Job Specifications: \n \n \n \n  Bachelor's degree in Computer Science, Data Science, Information Technology, or a related field. \n  3+ years of proven experience as a Business Systems Analyst with a focus on data programs and technical requirement development. \n  Strong technical background with a solid understanding of data management principles and data architecture. \n  Proficiency in requirement gathering and documentation techniques, including data use cases and data flow diagrams. \n  Excellent communication skills with the ability to convey complex technical concepts to non-technical stakeholders. \n  Strong analytical and problem-solving skills to identify and address data project challenges. \n  Familiarity with Agile methodologies and experience working in cross-functional data teams. \n  Detail-oriented with a focus on producing accurate and high-quality data deliverables. \n  Proactive and self-motivated, with the ability to take ownership of data tasks and drive results. \n \n \n \n \n  EOE STATEMENT  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n \n  CCPA DISCLOSURE  Personal Information Collection Notice: This notice contains information under the California Consumer Privacy Act (CCPA) about the categories of personal information (PI) of California residents that Manufacturers Bank collects and the business or commercial purpose(s) for which the PI may be used. We do not sell PI. More information about our collection and use of PI may be found in our CCPA Privacy Policy at https://www.manufacturersbank.com/CCPA-Privacy. Persons with disabilities may contact our Customer Contact Center toll-free at (877) 560-9812 to request the information in this Notice in an alternative format.",
        "cleaned_desc": " \n  Requirements Documentation: \n \n  Prepare well-organized requirement documents, including data use cases, user stories, and data flow diagrams. \n  Maintain thorough documentation of technical specifications for future reference and knowledge sharing. \n  Conduct regular reviews and updates of requirements based on project progress and changes. \n \n  Stakeholder Communication: \n \n  Work with the Product Owner to assist in translation of communication between data program stakeholders and the engineering team. \n  Clarify technical concepts to non-technical stakeholders and ensure alignment with data program goals. \n  Act as a bridge between data program needs and technical implementation, ensuring seamless coordination. \n \n  Quality Assurance and Testing Support: \n \n  Collaborate with QA and testing teams to develop data test cases based on technical requirements.   \n \n  Bachelor's degree in Computer Science, Data Science, Information Technology, or a related field. \n  3+ years of proven experience as a Business Systems Analyst with a focus on data programs and technical requirement development. \n  Strong technical background with a solid understanding of data management principles and data architecture. \n  Proficiency in requirement gathering and documentation techniques, including data use cases and data flow diagrams. \n  Excellent communication skills with the ability to convey complex technical concepts to non-technical stakeholders. \n  Strong analytical and problem-solving skills to identify and address data project challenges. \n  Familiarity with Agile methodologies and experience working in cross-functional data teams. \n  Detail-oriented with a focus on producing accurate and high-quality data deliverables. \n  Proactive and self-motivated, with the ability to take ownership of data tasks and drive results. \n \n \n \n \n  EOE STATEMENT  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. ",
        "techs": [
            "data use cases",
            "user stories",
            "data flow diagrams",
            "technical specifications",
            "product owner",
            "qa and testing teams",
            "data test cases",
            "computer science",
            "data science",
            "information technology",
            "business systems analyst",
            "data management principles",
            "data architecture",
            "requirement gathering",
            "communication skills",
            "analytical skills",
            "problem-solving skills",
            "agile methodologies",
            "cross-functional data teams",
            "detail-oriented"
        ],
        "cleaned_techs": [
            "data use cases",
            "user stories",
            "data flow diagrams",
            "technical specifications",
            "qa and testing teams",
            "data test cases",
            "computer science",
            "data science",
            "information technology",
            "data management principles",
            "data architecture",
            "requirement gathering",
            "agile methodologies",
            "cross-functional data teams",
            "detail-oriented"
        ]
    },
    "54c5e6126a8a63aa": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "11b1ced8289c7201": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "436c4002a8048cb4": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "f302d5d563af2e37": {
        "terms": [
            "data science"
        ],
        "salary_min": 25.0,
        "salary_max": 30.0,
        "title": "PRODUCT MANAGEMENT ANALYST",
        "company": "Cella",
        "desc": "Location: Remote   Job Type: Contract   Compensation Range: $25 - 30 per hour \n  We are looking for a talented and motivated  Product Management Analyst  to join our client's dynamic team and contribute to their ongoing success!    As a Product Management Analyst, you will play a crucial role in supporting the product management team in the development, enhancement, and optimization of products. You will work closely with cross-functional teams to gather data, analyze market trends, and provide valuable insights that will guide product decision-making. This role offers a unique opportunity to be at the forefront of shaping product offerings and driving our client's growth.     Responsibilities: \n \n Deliver professional activities in the Product Management job family. \n Provide basic support for product/brand management activities through their lifecycle. \n Support the development of various marketing activities for the product, development and updates of new sales tools, and support for product line assessments and business reviews. \n Handle a limited or specialized professional caseload. \n Work on small/routine assignments of limited scope and complexity while learning more advanced techniques. \n Apply standard techniques and procedures to routine instructions that require professional knowledge in specialist areas. \n Provide standard professional advice and create initial reports/analyses for review. \n May provide guidance, coaching, and direction to more junior members of the team in Product Management. \n May include a blend of Product Management/Product Development responsibilities. \n \n Qualifications: \n \n Experience level: Experienced \n Minimum 2 years of experience \n Bachelor's degree in business, marketing, computer science, or a related field. \n Proven experience in data analysis, market research, or product management. \n Strong analytical and problem-solving skills. \n Excellent communication and presentation abilities. \n Proficiency in data analysis tools and techniques. \n Familiarity with Agile development methodologies is a plus. \n Ability to work collaboratively in a fast-paced, cross-functional team environment. \n Skills: \n    \n Product Management (2 years of experience is preferred) \n Data Science \n Excel \n Sales \n \n \n \n JOBID: 1027216  #LI-CELLA  #LI-SJ1  #LI-REMOTE \n  Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.    At Cella, a randstad digital company, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.    Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Cella by randstad digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).",
        "cleaned_desc": " Proven experience in data analysis, market research, or product management. \n Strong analytical and problem-solving skills. \n Excellent communication and presentation abilities. \n Proficiency in data analysis tools and techniques. \n Familiarity with Agile development methodologies is a plus. \n Ability to work collaboratively in a fast-paced, cross-functional team environment. ",
        "techs": [
            "data analysis",
            "market research",
            "product management",
            "analytical and problem-solving skills",
            "communication and presentation abilities",
            "data analysis tools and techniques",
            "agile development methodologies"
        ],
        "cleaned_techs": [
            "market research",
            "product management",
            "communication and presentation abilities",
            "data analysis tools and techniques",
            "agile development methodologies"
        ]
    },
    "8f7bb255c97b2400": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "f9df0ab5b6ba8ac5": {
        "terms": [
            "data science"
        ],
        "salary_min": 120000.0,
        "salary_max": 200000.0,
        "title": "Remote Bioinformatics Data Scientist",
        "company": "CyberCoders",
        "desc": "Remote Bioinformatics Data Scientist \n  \n  If you are a Bioinformatics Data Scientist with Python experience, please read on!\n   \n  -Remote in US w/ Bi-Monthly visits to Saint Louis | Full-Time/Permanent-\n   \n  We are focused on improving the early detection and prevention of colorectal cancer, the second leading cause of cancer-related deaths in the United States. Our company conducts research to better comprehend the molecular underpinnings of colorectal cancer formation and progression in addition to creating diagnostic tools!\n  \n  What You Need for this Position \n \n Ph.D. OR M.A. + 2 years industry experience OR B.A. + 4 yrs industry experience in informatics, or machine-learning or biostatistics or related discipline \n Bioinformatics \n Python/R \n DNA/RNA \n Statistics \n Machine Learning(plus skills) \n \n  What You Will Be Doing \n \n Create Pipelines for Automating Data Analysis: Data trending, data assembly, and graphical analysis. \n Statistical Modeling: Novel approaches for understanding how drugs act on biological systems and how the body responds to the drug \n Design and oversee test applications of clinical trial simulations and their respective drug candidates \n Develop and maintain quality reporting and CAPAs for regulatory and client audits. \n \n  What's In It for You \n \n Competitive base salary \n 401k  \n PTO \n Full benefits including medical, dental, and vision \n Opportunity for professional growth \n Awesome Glassdoor review \n Great company culture and work-life balance! \n Much more! \n \n \n   So, if you are a Remote Bioinformatics Data Scientist with experience, please apply today!\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact James Shramek\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "9679075d7a29f4c5": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "9cc4df72e61b8b26": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "8da985dfb9482794": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "fb8a6401bb1d6be4": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 145000.0,
        "salary_max": 189000.0,
        "title": "Business Information Architect (Remote)",
        "company": "Sumitomo Mitsui Banking Corporation",
        "desc": "Join us on our mission to create a completely new, 100% digital bank that truly serves customers' best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch - and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience). \n \n  The anticipated salary range for this role is between $145,000.00 and $189,000.00. The specific salary offered to an applicant will be based on their individual qualifications, experiences, and an analysis of the current compensation paid in their geography and the market for similar roles at the time of hire. The role may also be eligible for an annual discretionary incentive award. In addition to cash compensation, SMBC offers a competitive portfolio of benefits to its employees. \n \n  We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the second largest bank in Japan and the 12th largest bank in the world with operations in over forty countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products. \n \n  It is the best of both worlds, and we are seeking proven marketing leaders to propel us towards a national launch. We have both the ambitious growth plans and the 'patient capital' necessary to execute a multi-year plan. Join us on the journey to deliver an exciting concept of evolved banking. \n \n \n \n  General Summary: \n \n \n  As a Business Information Architect, you\u2019ll work to optimize data feeds and enable self-service data to drive the Data & Analytics strategy across the business. This position holds responsibility for the development and implementation of the information architecture to support the measuring and monitoring of enterprise business needs. Maintains the design around the full set of Enterprise information capabilities that support existing and strategic business capabilities. You\u2019ll be working with data feeds and reporting pipelines supporting multiple product lines, making them available to leaders across the company. You will be responsible for creating strategic roadmaps for individual data feeds and generating specific requirements for the Data Engineering team to address defects and optimize data consumption. You\u2019ll own the enablement of core data feeds and design their Data Warehouse integrations. The ideal candidate is a tech-savvy strong communicator who understands how to make data understandable by everyone. This role includes regular opportunities to partner closely with stakeholders across domains and at all levels. \n \n \n \n \n  Principal Duties and Responsibilities: \n \n \n  Data Profiling Team Leadership: \n \n  Lead and oversee the Data Profiling Team, fostering a collaborative and results-driven culture. \n  Collaborate with IT Data Engineering partners to design and implement architectural data solutions. \n  Construct business-ready data models and develop complex SQL queries to support analytical needs. \n \n  Data Warehouse Ownership: \n \n  Take full ownership of the Data Warehouse environment, ensuring its reliability and performance. \n  Work closely with cross-functional teams to optimize data models and schema structures. \n  Identify and address existing and emerging risks related to data activities and the job role. \n \n  Information Architecture and Strategy: \n \n  Utilize information architecture tools, including data catalogs and entity relationship diagrams. \n  Assess and improve the health and maturity of information capabilities within the domain. \n  Identify and recommend new information capabilities to support business objectives. \n \n  Collaborative Leadership: \n \n  Collaborate with other architectural disciplines to influence information architecture direction. \n  Recommend appropriate data sources for solution development and delivery. \n  Encourage internal adoption and self-sufficiency of stakeholders on the data platform. \n \n  Data Management and Analysis: \n \n  Own data tools, pipelines, and cataloging to ensure data availability and accuracy. \n  Develop and maintain datasets representing the source of truth for key metrics. \n  Address data quality issues and perform exploratory data analysis using Python. \n \n \n \n \n \n  Job Specifications: \n \n \n \n  Bachelor\u2019s degree in computer science, Applied Statistics, or a related field. \n  8 years experience in building data warehouses \n  Expert knowledge of SQL, including writing and optimizing queries. \n  Proficiency in Python and the Data Science Stack (Pandas, Matplotlib, etc.). \n  Strong skills in multiple database technologies and data tools. \n  Exceptional organizational skills and attention to detail. \n  Effective presentation and data visualization abilities for diverse audiences. \n  Highly proficient in MS Office and other relevant software. \n  Ability to work independently and prioritize tasks efficiently. \n  Strong problem-solving skills from both technical and business perspectives. \n  Excellent communication skills with stakeholders at all levels. \n  Eagerness to learn and expand knowledge in the data domain. \n  Ability to document work and support team members. \n \n  Preferred Qualifications: \n \n  Familiarity with FIS core banking. \n  GCP Data Certification. \n  Experience with ETL/ELT pipelines. \n  Familiarity with writing and reviewing version-controlled code (GitHub). \n  Experience in an agile Kanban workflow. \n  Clean and intuitive coding practices. \n  Experience in a distributed/remote workplace. \n \n \n \n \n  EOE STATEMENT  We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law. \n \n  CCPA DISCLOSURE  Personal Information Collection Notice: This notice contains information under the California Consumer Privacy Act (CCPA) about the categories of personal information (PI) of California residents that Manufacturers Bank collects and the business or commercial purpose(s) for which the PI may be used. We do not sell PI. More information about our collection and use of PI may be found in our CCPA Privacy Policy at https://www.manufacturersbank.com/CCPA-Privacy. Persons with disabilities may contact our Customer Contact Center toll-free at (877) 560-9812 to request the information in this Notice in an alternative format.",
        "cleaned_desc": " \n  Principal Duties and Responsibilities: \n \n \n  Data Profiling Team Leadership: \n \n  Lead and oversee the Data Profiling Team, fostering a collaborative and results-driven culture. \n  Collaborate with IT Data Engineering partners to design and implement architectural data solutions. \n  Construct business-ready data models and develop complex SQL queries to support analytical needs. \n \n  Data Warehouse Ownership: \n \n  Take full ownership of the Data Warehouse environment, ensuring its reliability and performance. \n  Work closely with cross-functional teams to optimize data models and schema structures. \n  Identify and address existing and emerging risks related to data activities and the job role. \n \n  Information Architecture and Strategy:   \n  Utilize information architecture tools, including data catalogs and entity relationship diagrams. \n  Assess and improve the health and maturity of information capabilities within the domain. \n  Identify and recommend new information capabilities to support business objectives. \n \n  Collaborative Leadership: \n \n  Collaborate with other architectural disciplines to influence information architecture direction. \n  Recommend appropriate data sources for solution development and delivery. \n  Encourage internal adoption and self-sufficiency of stakeholders on the data platform. \n \n  Data Management and Analysis: \n \n  Own data tools, pipelines, and cataloging to ensure data availability and accuracy. \n  Develop and maintain datasets representing the source of truth for key metrics. \n  Address data quality issues and perform exploratory data analysis using Python. \n   \n \n \n \n  Job Specifications: \n \n \n \n  Bachelor\u2019s degree in computer science, Applied Statistics, or a related field. \n  8 years experience in building data warehouses \n  Expert knowledge of SQL, including writing and optimizing queries. \n  Proficiency in Python and the Data Science Stack (Pandas, Matplotlib, etc.). \n  Strong skills in multiple database technologies and data tools. \n  Exceptional organizational skills and attention to detail. \n  Effective presentation and data visualization abilities for diverse audiences. \n  Highly proficient in MS Office and other relevant software. \n  Ability to work independently and prioritize tasks efficiently.    Strong problem-solving skills from both technical and business perspectives. \n  Excellent communication skills with stakeholders at all levels. \n  Eagerness to learn and expand knowledge in the data domain. \n  Ability to document work and support team members. \n \n  Preferred Qualifications: \n \n  Familiarity with FIS core banking. \n  GCP Data Certification. \n  Experience with ETL/ELT pipelines. \n  Familiarity with writing and reviewing version-controlled code (GitHub). \n  Experience in an agile Kanban workflow. \n  Clean and intuitive coding practices. \n  Experience in a distributed/remote workplace. \n \n \n ",
        "techs": [
            "data profiling",
            "it data engineering",
            "architectural data solutions",
            "complex sql queries",
            "data warehouse",
            "cross-functional teams",
            "data models",
            "schema structures",
            "information architecture",
            "data catalogs",
            "entity relationship diagrams",
            "information capabilities",
            "data sources",
            "data management",
            "data tools",
            "data pipelines",
            "data cataloging",
            "data availability",
            "data accuracy",
            "exploratory data analysis",
            "python",
            "data warehouses",
            "sql",
            "pandas",
            "matplotlib",
            "database technologies",
            "organizational skills",
            "attention to detail",
            "presentation skills",
            "data visualization",
            "ms office",
            "problem-solving skills",
            "communication skills",
            "fis core banking",
            "gcp data certification",
            "etl/elt pipelines",
            "github",
            "agile kanban workflow",
            "coding practices",
            "distributed/remote workplace."
        ],
        "cleaned_techs": [
            "it data engineering",
            "architectural data solutions",
            "complex sql queries",
            "data warehouse",
            "cross-functional teams",
            "data models",
            "schema structures",
            "information architecture",
            "data catalogs",
            "entity relationship diagrams",
            "information capabilities",
            "data sources",
            "data management",
            "data tools",
            "data pipelines",
            "data cataloging",
            "data availability",
            "data accuracy",
            "exploratory data analysis",
            "python",
            "data warehouses",
            "sql",
            "pandas",
            "matplotlib",
            "database technologies",
            "attention to detail",
            "data visualization",
            "microsoft",
            "fis core banking",
            "gcp",
            "etl/elt pipelines",
            "github",
            "agile kanban workflow",
            "coding practices",
            "distributed/remote workplace."
        ]
    },
    "84f0bb89c112045b": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "20d3222fef6a3a1a": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "7b06afd476d8bf63": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "e90a73db5921c2f8": {
        "terms": [
            "data science"
        ],
        "salary_min": 142350.0,
        "salary_max": 257325.0,
        "title": "Senior Generative AI Data Scientist",
        "company": "Leidos",
        "desc": "Description   \n Leidos has a career opening for a  Senior Generative AI Data Scientist . \n \n  We are looking for a motivated Sr. Generative AI Data Scientist that wants to work on challenging problems in a variety of domains - including health, defense, intelligence, and energy \u2013 to get results that apply and go beyond the state of the art for measurably better outcomes. We apply our knowledge, capabilities, and experience to develop and deploy Trusted AI \u2013 AI that deserves to be trusted by system owners, end users, and the public \u2013 to be accurate, fair, ethical, reliable, and adaptable. We are looking for a researcher that is expert in NLP and interested in adapting new technologies to significantly transform human workflows, especially using new applications of transformer-based models. \n \n  Working at Leidos would give you the chance to do genuinely important work. But don\u2019t just ask us. Here\u2019s what ChatGPT has to say on the subject: \n  \u201cOh sure, working in AI research for the commercial sector is just the ultimate thrill. Who wouldn't want to spend their days building algorithms to recommend cat videos to stream and optimizing ad targeting to boost click-through rates? I mean, those are the kinds of problems that really make you feel like you're changing the world, right? On the other hand, working in AI research at a company like Leidos, you're stuck with jobs like supporting the next generation of lunar missions and building computer vision algorithms that help keep air travel safe and efficient. I mean, who cares about finding cures for cancer, delivering healthcare to veterans, or helping defend our nation? So boring. But hey, at least we can say we're using our AI skills for a greater good.\u201d \n \n  Primary Responsibilities:  The Senior Generative AI Data Scientist will be customizing and creating various machine learning algorithms to operate over multi-domain data and optimizing the performance of those algorithms on the data. They will develop automation to extract and prepare features from multi-domain datasets. They will employ NLP libraries/toolkits that include transformer models like BERT and ChatGPT, as well as Stanford CoreNLP, Spacy, NLTK, Word2Vec, and Gensim. \n  As a member of the Leidos AI/ML Accelerator, they will be performing research and development, and need hands-on experience training and optimizing generative models. With those models and libraries, they will explore subjects like domain adaptation with supervised and unsupervised approaches. They will also build domain adaptive prototypes to examine the operational capabilities of bi-directional learning. They should be a self-starter while also being part of a team, collaborating and sharing discoveries and seeking feedback. They must be prepared to conduct research, document it, submit their research for publication, and present their research at conferences and other public forums. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Data Science or related field and 15+ years\u2019 experience or master\u2019s degree at 13+ years of experience. \n  Good understanding of machine learning algorithms, tools and platforms \n  Experience in at least three of these Toolkits: NumPy, SciPy, scikit-learn, TensorFlow, Pytorch, Keras, Genism, vow pal wabbit, Stanford CoreNLP, etc. \n  Experience researching and applying large language and generative AI models, including transformers, foundation models, and GPT models. \n  Python proficiency \n  Self-starter with high intellectual curiosity \n  Great communication skills, able to explain language model results to a non-technical audience \n  Proficient in data exploration techniques and tools \n  Must be a US Citizen and be able to obtain TS/SCI with CI Poly security clearance. \n \n \n  Preferred Qualifications: \n \n  Practical understanding of generative models \n  Experience programming machine learning algorithms for GPUs \n  Understanding of Convolutional Neural Nets \n  Working knowledge of Word2Vec and/or NLTK \n  Discernment of when and how to use machine learning regulation \n \n \n  Pay Range:  Pay Range $142,350.00 - $257,325.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote",
        "cleaned_desc": " \n  Primary Responsibilities:  The Senior Generative AI Data Scientist will be customizing and creating various machine learning algorithms to operate over multi-domain data and optimizing the performance of those algorithms on the data. They will develop automation to extract and prepare features from multi-domain datasets. They will employ NLP libraries/toolkits that include transformer models like BERT and ChatGPT, as well as Stanford CoreNLP, Spacy, NLTK, Word2Vec, and Gensim. \n  As a member of the Leidos AI/ML Accelerator, they will be performing research and development, and need hands-on experience training and optimizing generative models. With those models and libraries, they will explore subjects like domain adaptation with supervised and unsupervised approaches. They will also build domain adaptive prototypes to examine the operational capabilities of bi-directional learning. They should be a self-starter while also being part of a team, collaborating and sharing discoveries and seeking feedback. They must be prepared to conduct research, document it, submit their research for publication, and present their research at conferences and other public forums. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Data Science or related field and 15+ years\u2019 experience or master\u2019s degree at 13+ years of experience.    Good understanding of machine learning algorithms, tools and platforms \n  Experience in at least three of these Toolkits: NumPy, SciPy, scikit-learn, TensorFlow, Pytorch, Keras, Genism, vow pal wabbit, Stanford CoreNLP, etc. \n  Experience researching and applying large language and generative AI models, including transformers, foundation models, and GPT models. \n  Python proficiency \n  Self-starter with high intellectual curiosity \n  Great communication skills, able to explain language model results to a non-technical audience \n  Proficient in data exploration techniques and tools ",
        "techs": [
            "nlp libraries/toolkits like bert",
            "chatgpt",
            "stanford corenlp",
            "spacy",
            "nltk",
            "word2vec",
            "and gensim. numpy",
            "scipy",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "keras",
            "genism",
            "vow pal wabbit"
        ],
        "cleaned_techs": [
            "nlp",
            "chatgpt",
            "stanford corenlp",
            "spacy",
            "nltk",
            "word2vec",
            "and gensim. numpy",
            "scipy",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "keras",
            "genism",
            "vow pal wabbit"
        ]
    },
    "9fb88e41706223a7": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 193900.0,
        "salary_max": 285000.0,
        "title": "Staff Technical Product Manager, Applied AI",
        "company": "Cruise",
        "desc": "We're Cruise, a self-driving service designed for the cities we love. \n  We're building the world's most advanced self-driving vehicles to safely connect people to the places, things, and experiences they care about. We believe self-driving vehicles will help save lives, reshape cities, give back time in transit, and restore freedom of movement for many. \n  In our cars, you're free to be yourself. It's the same here at Cruise. We're creating a culture that values the experiences and contributions of all of the unique individuals who collectively make up Cruise, so that every employee can do their best work. \n  Cruise is committed to building a diverse, equitable, and inclusive environment, both in our workplace and in our products. If you are looking to play a part in making a positive impact in the world by advancing the revolutionary work of self-driving cars, come join us. Even if you might not meet every requirement, we strongly encourage you to apply. You might just be the right candidate for us.  \n \n About the Applied AI Product group:  Our group leads product strategy for Cruise's core technology - the AI capabilities that run on Cruise's vehicles enabling them to drive autonomously and safely. We chart the course toward launching and scaling our AVs globally, and are responsible for leading the company to fulfill this mission by partnering closely with engineering, data science, program, operations and commercial teams. Do you want to work with products that change the world for better? Our team is at the forefront of making autonomous vehicles a reality! \n  About the Staff Technical PM role in Applied AI:  As a Staff Technical Product Manager in autonomous vehicle software, you will be responsible for owning the development of Cruise's most crucial Perception and Prediction autonomous driving capabilities and also serve as a senior leader within the AI product team, evolving our innovation practice as we go to market. Collaborating broadly across engineering departments, you'll apply cutting-edge technology to increase the in-market performance of the AV across geo-spatial domains as we scale from initial public launch to global expansion. \n  What you'll be doing: \n \n  Define the vision, strategy and roadmap for your product areas \n  Lead executives and key partners through sophisticated decisions to drive progress toward our strategic goals \n  Synthesize technical and analytical insights with product intuition to formulate compelling roadmap investments and adjust quickly to new information \n  Secure commitment and support for your roadmap through detailed and thoughtful communication with engineering teams, key partners and executive leaders \n  Consistently deliver results through coordinated execution across AV engineering teams in an applied research setting with significant experimentation \n  Identify and lead improvements to the team's innovation and approach enabling us to scale our team and impact \n \n \n  What you have: \n \n  5+ years of proven success leading highly technical (machine learning, computer vision or robotics) products \n  Ability to generate crucial product insights through quantitative and qualitative analysis \n  In-depth knowledge of modern software development and machine learning engineering practices \n  BS or MS in science, engineering, math or equivalent technical experience \n  Outstanding communication skills: verbal and written, with engineers, non-technical partners, and executives \n  Thrive in ambiguity, crafting simplicity and order \n  Creativity and curiosity: you're driven to find novel solutions and push forward an entire industry \n \n  Bonus points! \n \n  Technical experience with autonomous vehicles, robotics or safety-critical systems \n  MBA, management consulting or equivalent business strategy experience \n \n \n  The salary range for this position is  $193,900 - $285,000 .  Compensation will vary depending on location, job-related knowledge, skills, and experience. You may also be offered a bonus, restricted stock units, and benefits. These ranges are subject to change. \n \n  Why Cruise? \n \n Our benefits are here to support the whole you:   \n \n \n \n Competitive salary and benefits \n 401(k) Cruise matching program \n Medical / dental / vision, AD+D and Life \n Subsidized mental health benefits \n Flexible vacation and company paid holidays \n Healthy meals and snacks available for non-remote employees \n Paid parental, jury duty, bereavement, family care, and medical leave \n Fertility Benefits \n Dependent Care Flexible Spending Account \n Flexible Spending Account \n Pre-tax Commuter Benefit Plan for non-remote employees \n CruiseFlex, a working policy for US-Based Cruisers, lets you and your manager find the working style that's best for you, whether it's primarily in-person, primarily at home, or a combination of home and in-office time. - learn more about CruiseFlex here \n \n \n \n We're Integrated   \n \n \n \n Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.   \n \n \n \n We're Funded   \n \n \n \n GM, Honda, Microsoft, T. Rowe Price, and Walmart have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed. \n \n \n \n We're Independent   \n \n \n \n We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the edge of technology, but also define it. \n \n \n \n We're Vested   \n \n \n \n You won't just own your work here, you'll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow. We offer a new kind of equity program called Recurring Liquidity Opportunity (RLO), which combines IPO-like liquidity with the stability of remaining private - learn more about RLO here \n \n \n \n We're Safety Conscious \n \n We integrate #staysafe, our top priority at Cruise, into our everyday work. Through our Safety Management System, every Cruiser is asked to do their part by reporting any potential issues or hazards they observe and making continuous improvements. You'll be able to contribute to safety at Cruise, no matter your job function or title. \n   \n \n Cruise LLC is an equal opportunity employer. We strive to create a supportive and inclusive workplace where contributions are valued and celebrated, and our employees thrive by being themselves and are inspired to do the best work of their lives. We seek applicants of all backgrounds and identities, across race, color, caste, ethnicity, national origin or ancestry, citizenship, religion, sex, sexual orientation, gender identity or expression, veteran status, marital status, pregnancy or parental status, or disability. Applicants will not be discriminated against based on these or other protected categories or social identities. Cruise will consider for employment qualified applicants with arrest and conviction records, in accordance with applicable laws. \n  Cruise is committed to the full inclusion of all applicants. If reasonable accommodation is needed to participate in the job application or interview process please let our recruiting team know or email  HR@getcruise.com . \n  We proactively work to design hiring processes that promote equity and inclusion while mitigating bias. To help us track the effectiveness and inclusivity of our recruiting efforts, please consider answering the following demographic questions. Answering these questions is entirely voluntary. Your answers to these questions will not be shared with the hiring decision makers and will not impact the hiring decision in any way. Instead, Cruise will use this information not only to comply with any government reporting obligations but also to track our progress toward meeting our diversity, equity, inclusion, and belonging objectives. \n  Candidates applying for roles that operate and remotely operate the AV:  Licensed to drive a motor vehicle in the U.S. for the three years immediately preceding your application, currently holding an active in-state regular driver's license or equivalent, and no more than one point on driving record. A successful completion of a background check, drug screen and DMV Motor Vehicle Record check is also required. \n  Note to Recruitment Agencies:  Cruise does not accept unsolicited agency resumes. Furthermore, Cruise does not pay placement fees for candidates submitted by any agency other than its approved partners.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a0c5f0e59a7f3676": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "b47394cc2854d61f": {
        "terms": [
            "data science"
        ],
        "salary_min": 120363.016,
        "salary_max": 152406.39,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Hybrid/Remote role \n  Locations in multiple States \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n Zmyclxr23x",
        "cleaned_desc": "  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred ",
        "techs": [
            "python",
            "deep learning",
            "tensorflow"
        ],
        "cleaned_techs": [
            "python",
            "tensorflow"
        ]
    },
    "0a45b644b85f122e": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "5b4de047a5fa0579": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Claims Data Analyst",
        "company": "JAMES RIVER MANAGEMENT CO INC",
        "desc": "James River Group Holdings, Ltd. is a Bermuda-based insurance holding company which owns and operates a group of specialty insurance and reinsurance companies. The Company operates in three specialty property-casualty insurance and reinsurance segments: Excess and Surplus Lines, Specialty Admitted Insurance and Casualty Reinsurance. The Company tends to focus on accounts associated with small or medium-sized businesses in each of its segments. Each of the Company's regulated insurance subsidiaries are rated \"A-\" (Excellent) by A.M. Best Company. \n  Job Summary \n  The Senior Claims Data Analyst provides reporting and analytics support to the VP, Claims Operations and SVP, Chief Claims Officer. Working closely with Claims Management and Actuarial Leadership, this individual will gather and analyze claims data, develop an understanding of the key drivers of financial and actuarial data, and share insights while ensuring alignment of data trends and processes. This role is integral in ensuring the Claims department adheres to reserving best practices and continuously improves claim resolution efficiency and effectiveness. \n  Duties and Responsibilities \n \n  Continuously exhibit and uphold Core Values of Integrity, Accountability, Communication and Teamwork, Innovation and Customer Service \n  Manage processes, reports, and analytics related to claim reserving functions \n  Work with Accounting/Finance, Actuarial and Internal Audit departments to ensure adequate claim financial controls are in place and being adhered to \n  Perform monthly operational reporting, dashboards, metrics, and KPIs including reserve committees and portfolio reviews \n  Assist with interdepartmental projects, processes, and reports between Accounting/Finance, Actuarial, Reinsurance and Claims \n  Assist in the presentation and delivery of observations, areas of concerns, and recommendations to Claims Management and employees \n  Work in conjunction with Claims and Actuarial Departments to gather Claims data, derive actionable and meaningful insights, and develop strategy \n  Perform analyses of reserve trending in all LOB\u2019s in collaboration with Actuarial \n  Analyze financial data, develop metrics, and test case reserve adequacy to ensure their financial strength \n  Monitor case reserves of product line or segment to ensure present and future reserving strategies to achieve financial strength \n  Review and analyze claim cases reserving patterns to foster claim case reserve adequacy \n \n  Knowledge, Skills and Abilities \n \n  Advanced technical knowledge of reserving and actuarial theories \n  Advanced statistical modeling skills \n  Knowledge of a variety of product lines within P&C as it relates to reserving \n  Proficiency in managing complex datasets and ability to analyze and interpret complex claims data concepts \n  Experience in using statistical modeling and/or machine learning techniques to build models that drive decision making \n  Advanced proficiency in SQL and other query and automation languages (Power Query M, DAX, python) \n  Advanced proficiency in visualization tools (PowerBI, Tableau, Qlik Sense) \n  Advanced proficiency in MS Office (Word, Excel, Outlook, PowerPoint) \n  Understanding of claims case reserving practices \n  Ability to effectively communicate with all levels of the organization \n  Advanced proficiency in insurance claims reporting \n  Excellent written and verbal communication skills \n  Ability to demonstrate business acumen and forward-thinking skills \n  Strong analytical skills \n  Skilled in collecting and analyzing complex data \n  Ability to organize complex information and pay close attention to detail \n  Ability to work successfully as an individual contributor and in a team environment \n \n  Experience and Education \n \n  Bachelor\u2019s Degree in Math, Actuarial Science or related field required \n  Master\u2019s Degree in related field preferred \n  Minimum of five years of claims, data analysis, or actuarial experience, in the insurance industry, required \n  Minimum of three years of predictive modeling experience preferred \n \n \n  #LI-KS1 \n  #LI-Remote",
        "cleaned_desc": " \n  Advanced technical knowledge of reserving and actuarial theories \n  Advanced statistical modeling skills \n  Knowledge of a variety of product lines within P&C as it relates to reserving \n  Proficiency in managing complex datasets and ability to analyze and interpret complex claims data concepts \n  Experience in using statistical modeling and/or machine learning techniques to build models that drive decision making \n  Advanced proficiency in SQL and other query and automation languages (Power Query M, DAX, python) \n  Advanced proficiency in visualization tools (PowerBI, Tableau, Qlik Sense) \n  Advanced proficiency in MS Office (Word, Excel, Outlook, PowerPoint)    Understanding of claims case reserving practices \n  Ability to effectively communicate with all levels of the organization \n  Advanced proficiency in insurance claims reporting \n  Excellent written and verbal communication skills \n  Ability to demonstrate business acumen and forward-thinking skills \n  Strong analytical skills \n  Skilled in collecting and analyzing complex data \n  Ability to organize complex information and pay close attention to detail \n  Ability to work successfully as an individual contributor and in a team environment ",
        "techs": [
            "reserving and actuarial theories",
            "statistical modeling skills",
            "managing complex datasets",
            "analyzing and interpreting complex claims data concepts",
            "statistical modeling and machine learning techniques",
            "sql",
            "power query m",
            "dax",
            "python",
            "powerbi",
            "tableau",
            "qlik sense",
            "ms office (word",
            "excel",
            "outlook",
            "powerpoint)",
            "claims case reserving practices",
            "insurance claims reporting",
            "written and verbal communication skills",
            "business acumen",
            "analytical skills",
            "collecting and analyzing complex data",
            "organizing complex information",
            "attention to detail",
            "working as an individual contributor and in a team environment"
        ],
        "cleaned_techs": [
            "reserving and actuarial theories",
            "managing complex datasets",
            "analyzing and interpreting complex claims data concepts",
            "statistical modeling and machine learning techniques",
            "sql",
            "power query m",
            "dax",
            "python",
            "powerbi",
            "tableau",
            "qlik sense",
            "microsoft",
            "excel",
            "outlook",
            "powerpoint)",
            "claims case reserving practices",
            "insurance claims reporting",
            "business acumen",
            "collecting and analyzing complex data",
            "organizing complex information",
            "attention to detail",
            "working as an individual contributor and in a team environment"
        ]
    },
    "3b6e78cd730887e5": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "8eb62c7408ea3079": {
        "terms": [
            "data science"
        ],
        "salary_min": 97132.29,
        "salary_max": 122991.12,
        "title": "Data Scientist",
        "company": "MX Technologies Inc.",
        "desc": "Life at MX\n    \n  We are driven by our moral imperative to advance mankind - and it all starts with our people, product and purpose. We always carry a deep sense of drive and passion with us. If you thrive in a challenging work environment, surrounded by incredible team members who will help you grow, MX is the right place for you.\n    \n  Come build with us and be part of an award-winning company that\u2019s helping create meaningful and lasting change in the financial industry.\n   \n \n \n \n   As a Data Scientist, you will have the opportunity to analyze and extract insights from a world-class financial data asset. You\u2019ll perform in-depth, consumer-level analytics, lead big data research and discovery projects, increase overall system accuracy, and automate important (but repetitive) tasks. In addition, you\u2019ll design and execute operational tests and provide recommendations based on careful analysis, solid business acumen, and superior problem-solving skills. The ability to turn complicated analytic results into digestible and engaging stories will be important for success, as will superior ambiguity tolerance. Your strong analytic training and background, desire to create new and unique perspectives about consumer financial behavior, collaborative spirit, and hands-on approach to solving problems will mark you as an ideal candidate for this role.\n  \n \n \n   Job Duties\n  \n \n \n \n     Ask, refine, and answer critical business questions that bolster MX\u2019s capabilities and competitive position through the application of advanced analytic methods, logical inference, and creative problem solving\n    \n \n \n     Build, enhance, and maintain predictive models and analytic strategies focused on consumer financial behavior\n    \n \n \n     Contribute to, or lead, modeling projects, operational tests (e.g., A/B and multivariate), and data mining and exploratory work to produce actionable and novel insights and recommendations\n    \n \n \n     Partner with stakeholder groups to understand market needs and drive data initiatives beyond our current product portfolio\n    \n \n \n     Engage in independent research projects to uncover and understand new tools, methods, and approaches that can strengthen MX\u2019s data science platform\n    \n \n \n     Create new data assets to support data science project work\n    \n \n \n     Develop short presentations to communicate key messages and findings to colleagues and senior leaders\n    \n \n \n \n   Job Requirements\n  \n \n \n \n     Master\u2019s degree (Ph.D. preferred) in a quantitative discipline, with coursework in statistics, econometrics, or a related field\n    \n \n \n     3+ years of advanced analytics experience focused on improving core business metrics (e.g., revenue, EBITDA, or net income); extra points for work focused on customer satisfaction and engagement and/or product quality\n    \n \n \n     Eighteen months of practical experience building a variety of predictive/machine learning/statistical models and tools from complex, specialized, or large data pools; familiarity with the logic of credit scoring would also be helpful\n    \n \n \n     Experience with one or more structured programming languages for statistical and/or numeric computing (e.g., Python, R, or Scala) and database query languages (e.g., SQL)\n    \n \n \n     Demonstrated competence with (a) one or more of logistic regression, generalized linear models, or categorical data analysis and (b) multiple machine learning approaches (e.g., k-means clustering, SVM, random forest, or PCA)\n    \n \n \n     Critical thinking skills, intellectual curiosity, and a willingness to keep looking for better solutions\n    \n \n \n     Drive to tackle demanding goals with enthusiasm, tenacity in the face of stubborn obstacles, and interest in pursuing personal and technical development alongside other commitments\n    \n \n \n     Commitment to client needs and satisfaction, humility in the face of constructive, well-meaning feedback, and production of high-quality work that builds trust and confidence with stakeholders\n    \n \n \n     Ability to follow analytical frameworks and project plans to achieve shared goals\n    \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n              Please note that this position does not accept sponsorship candidates at this time. Only US-based candidates who are authorized to work in US without sponsorship now or in the future will be considered for this role.\n             \n \n \n \n \n \n \n \n \n \n \n \n \n \n   Work Environment\n  \n \n   At MX, we prioritize flexible working arrangements, which allows us to attract top talent, provide improved work-life balance, and increase productivity. Our flex philosophy is centered on trust, responsibility, and communication. Our team members enjoy a balance of remote work and monthly in-person collaboration meetings. Travel expectations are about 15%, and the company covers travel expenses for remote employees. Local employees are encouraged to utilize in-office time on a weekly basis.\n  \n \n \n   Both local and remote employees can take advantage of our incredible office space with onsite perks like company-paid meals, onsite massage therapist, golf simulator, and meditation room to name a few.\n  \n \n \n   Compensation\n  \n \n   The expected on-target earnings (OTE), which is comprised of a base salary and other forms of cash compensation, such as bonus or commissions is currently $113,500 to $136,000.\n  \n \n \n   This pay range is just one component of MX's total rewards package. MX takes a number of factors into account when determining individual starting pay, including job and level they are hired into, location, skillset, peer compensation.\n  \n \n \n   #LI-Remote\n  \n \n   #LI-EF1\n  \n \n  MX is proudly committed to recruiting and retaining a diverse and inclusive workforce. As an Equal Opportunity Employer, we never discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, military or veteran status, status as an individual with a disability, or other applicable legally protected characteristics. We particularly welcome applications from veterans and military spouses. All your information will be kept confidential according to EEO guidelines. You may request reasonable accommodations by sending an email to hr@mx.com.",
        "cleaned_desc": "     3+ years of advanced analytics experience focused on improving core business metrics (e.g., revenue, EBITDA, or net income); extra points for work focused on customer satisfaction and engagement and/or product quality\n    \n \n \n     Eighteen months of practical experience building a variety of predictive/machine learning/statistical models and tools from complex, specialized, or large data pools; familiarity with the logic of credit scoring would also be helpful\n    \n \n \n     Experience with one or more structured programming languages for statistical and/or numeric computing (e.g., Python, R, or Scala) and database query languages (e.g., SQL)\n    \n \n \n     Demonstrated competence with (a) one or more of logistic regression, generalized linear models, or categorical data analysis and (b) multiple machine learning approaches (e.g., k-means clustering, SVM, random forest, or PCA)\n    \n \n \n     Critical thinking skills, intellectual curiosity, and a willingness to keep looking for better solutions\n    \n \n \n     Drive to tackle demanding goals with enthusiasm, tenacity in the face of stubborn obstacles, and interest in pursuing personal and technical development alongside other commitments\n    \n \n \n     Commitment to client needs and satisfaction, humility in the face of constructive, well-meaning feedback, and production of high-quality work that builds trust and confidence with stakeholders\n    \n \n ",
        "techs": [
            "advanced analytics",
            "revenue",
            "ebitda",
            "net income",
            "customer satisfaction",
            "engagement",
            "product quality",
            "predictive models",
            "machine learning",
            "statistical models",
            "credit scoring",
            "structured programming languages",
            "python",
            "r",
            "scala",
            "sql",
            "logistic regression",
            "generalized linear models",
            "categorical data analysis",
            "k-means clustering",
            "svm",
            "random forest",
            "pca",
            "critical thinking",
            "intellectual curiosity",
            "personal and technical development",
            "client needs",
            "humility",
            "high-quality work."
        ],
        "cleaned_techs": [
            "advanced analytics",
            "revenue",
            "ebitda",
            "net income",
            "customer satisfaction",
            "engagement",
            "product quality",
            "predictive models",
            "statistical models",
            "credit scoring",
            "structured programming languages",
            "python",
            "r",
            "scala",
            "sql",
            "logistic regression",
            "generalized linear models",
            "categorical data analysis",
            "k-means clustering",
            "svm",
            "random forest",
            "pca",
            "critical thinking",
            "intellectual curiosity",
            "personal and technical development",
            "client needs",
            "humility",
            "high-quality work."
        ]
    },
    "7e60dd098f335450": {
        "terms": [
            "data science"
        ],
        "salary_min": 128181.555,
        "salary_max": 162306.4,
        "title": "Business Intelligence Team Lead",
        "company": "Notarize",
        "desc": "What is Notarize? \n \n \n \n  There are 1.25 billion notarizations a year in the US alone. Home purchase, designation of beneficiaries, medical authorization for minors, powers of attorney, vehicle certification of ownership, notarizations power life\u2019s most important transactions. At Notarize we\u2019re leveraging industry best practices, to make these transactions easy, secure, and available. Above all Notarize is the platform that customers can trust. It is why Notarize is the industry leader in Online Notarization.\n   \n \n \n  It is why we were able to grow over 600% the last year, raise $160M in series D funding from investors like Capitol G (Google), Citi, and Wells Fargo, why Forbes named us to their next billion dollar startup list.\n    \n \n \n \n \n Summary \n \n \n \n  As the Business Intelligence Team Lead reporting to the Head of Engineering, you will play a crucial role in shaping our data-driven culture and driving actionable insights across the organization. You will lead a small team of BI analysts and work closely with stakeholders from various departments to understand their data needs, develop analytical solutions, and facilitate data-driven decision-making. This role offers an exciting opportunity to make a significant impact on the company's success by leveraging data to drive business growth and efficiency.\n   \n \n \n \n What you'll do as our Business Intelligence Team Lead:  \n \n \n Team Leadership : Manage and mentor a team of Business Intelligence Analysts, providing guidance, support, and training to ensure the team's success and professional growth. \n  Data Strategy : Collaborate with senior management to define and execute the company's data strategy, aligning BI initiatives with overall business objectives. \n  Data Analysis and Forecasting : Lead and participate in data analysis activities, including data mining, reporting, and dashboard development, to provide actionable insights and support data-driven decision-making; help develop financial and other forecasting models. \n  Stakeholder Collaboration : Work closely with stakeholders from various departments, including Sales, Marketing, Finance, Product and Operations, to understand their data requirements and deliver timely and relevant insights. \n  Tool and Technology Management : Stay current with BI tools and technologies, evaluating and recommending new tools to enhance the team's capabilities and productivity. \n  Data Governance : Ensure data quality, consistency, and security by implementing data governance practices and standards across the organization. \n  Project Management : Plan, prioritize, and oversee BI projects, ensuring on-time delivery and effective communication with project stakeholders. \n  Continuous Improvement : Continuously evaluate and improve BI processes, tools and methodologies to enhance efficiency and effectiveness. \n \n \n \n \n \n \n Qualifications: \n \n \n  Bachelor's degree in Business, Computer Science, Data Science, or a related field (Master's degree preferred). \n  Proven experience (5+ years) in business intelligence, data analysis, or a related field. \n  Previous leadership experience and team management skills. \n  Proficiency in BI tools such as Metabase, Tableau, Power BI, or similar. \n  Excellent data visualization skills. \n  Solid understanding of data warehousing and ETL processes. \n  Strong SQL and database management skills. \n  Hands on coding skills, preferably with Python. \n  Exceptional problem-solving and analytical abilities. \n  Excellent communication and interpersonal skills. \n  Project management experience is a plus. \n  Experience with NLP and ML technologies is a plus.",
        "cleaned_desc": "  Tool and Technology Management : Stay current with BI tools and technologies, evaluating and recommending new tools to enhance the team's capabilities and productivity. \n  Data Governance : Ensure data quality, consistency, and security by implementing data governance practices and standards across the organization. \n  Project Management : Plan, prioritize, and oversee BI projects, ensuring on-time delivery and effective communication with project stakeholders. \n  Continuous Improvement : Continuously evaluate and improve BI processes, tools and methodologies to enhance efficiency and effectiveness. \n \n \n \n \n \n   Qualifications: \n \n \n  Bachelor's degree in Business, Computer Science, Data Science, or a related field (Master's degree preferred). \n  Proven experience (5+ years) in business intelligence, data analysis, or a related field. \n  Previous leadership experience and team management skills. \n  Proficiency in BI tools such as Metabase, Tableau, Power BI, or similar. \n  Excellent data visualization skills. \n  Solid understanding of data warehousing and ETL processes. \n  Strong SQL and database management skills. ",
        "techs": [
            "metabase",
            "tableau",
            "power bi",
            "sql"
        ],
        "cleaned_techs": [
            "metabase",
            "tableau",
            "powerbi",
            "sql"
        ]
    },
    "41888e71255a4d73": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "f54b8a93374a5967": {
        "terms": [
            "data science"
        ],
        "salary_min": 120675.25,
        "salary_max": 152801.75,
        "title": "Deep Learning Engineer",
        "company": "Cyberjin",
        "desc": "Remote Position \n  We're looking for a Deep Learning Engineer to join Dyneti as part of the founding engineering team. You will have the opportunity to work closely with the CEO to build new features and roll out new products - all in the deep learning on mobile space. \n \n  Ideal candidate traits \n  Enjoys significant ownership over user-facing product \n  \u200d Can work independently \n  Is comfortable turning research papers into product \n  Has 2 - 10 years experience with deep learning or has a PhD in a STEM field \n  Builds with a product-first approach. You ship code quickly and care about the real world impact of your code. \n  Python expertise strongly preferred - however, candidates with deep learning experience in a different language will be considered \n  Familiarity with Tensorflow preferred \n   \n 45aH804Ni7",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c448fca85bf3aaa7": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "0c94c594cedcfcfc": {
        "terms": [
            "data science"
        ],
        "salary_min": 88443.23,
        "salary_max": 111988.836,
        "title": "Enablement Manager",
        "company": "Infor",
        "desc": "The Global Enablement and Education team is looking for you to be proficient in Project Management processes and delivery, in order to transfer pm-related knowledge to our employees. As a trainer, your top priority will be training our employees on the Infor Methodology, in-house tools and processes to navigate the internal eco-system and incorporating PM leadership and professional skills as needed. You will effectively use a variety of education methods, deliverables, and activities including, but not limited to instructor-led (classroom and virtual) training. You will help develop content and help us grow the expertise in the company.\n  \n \n \n  A Day in The Life Typically Includes:\n  \n \n \n \n \n \n  Manage the Infor / IIL PMP prep program. \n \n \n \n  Manage PM onboarding and Building Blocks training. \n \n \n \n  Deliver training either virtual or on-site as aligned with our Program Strategy to serve multiple Stakeholders across their Learning Lifecycle related to project management and professional skills. \n \n \n \n  Recognize the learners and their problems to ensure the program is delivered in a cohesive manner. \n \n \n \n  Leverage your understanding of the processes to drive comprehensive, end-to-end learning programs. \n \n \n \n  Collaborate with Education on meaningful assessments and certifications to ensure effective learning has occurred. \n \n \n \n  Partner with the respective Learning Operations to identify gaps in existing programs and make recommendations to the learning programs managers to align with the needs of the business. \n \n \n \n  Basic Qualifications:\n  \n \n \n  Experience in delivering training. \n \n \n \n  Interpersonal communication skills and demonstrable command of the English language, both verbal and written. \n \n \n \n  Positive attitude towards others and ability to adapt your communication style to suit the situation. \n \n \n \n  Very comfortable and confident in delivering training sessions virtually. \n \n \n \n  Preferred Qualifications:\n  \n \n \n  Experience in project management and related disciplines. \n \n \n \n  Proven presentation and people skills enabling you to deliver engaging and effective in-person and virtual training. \n \n \n \n  Location: Candidate may be Remote Based (Alpharetta, GA, Dallas, TX, Saint Paul, MN) or situated in EMEA.\n  \n \n \n \n  About Infor \n \n \n \n  Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.\n   \n \n    For more information visit www.infor.com\n   \n \n \n \n \n  Our Values \n \n \n \n  At Infor, we strive for an environment that is founded on a business philosophy called Principle Based Management\u2122 (PBM\u2122) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization. Increasing diversity is important to reflect our markets, customers, partners, and communities we serve in now and in the future.\n   \n \n \n  We have a relentless commitment to a culture based on PBM. Informed by the principles that allow a free and open society to flourish, PBM\u2122 prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.\n   \n \n \n  Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law.\n   \n \n \n  At Infor we value your privacy that\u2019s why we created a policy that you can read here.",
        "cleaned_desc": " \n  Experience in delivering training. \n \n \n \n  Interpersonal communication skills and demonstrable command of the English language, both verbal and written. \n \n \n \n  Positive attitude towards others and ability to adapt your communication style to suit the situation. \n \n \n \n  Very comfortable and confident in delivering training sessions virtually. \n \n \n \n  Preferred Qualifications:\n  \n \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "ad2e6d3c84aa4bed": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": 98650.586,
        "salary_max": 124913.62,
        "title": "Lead Business Intelligence Analyst",
        "company": "Verizon",
        "desc": "When you join Verizon \n  Verizon is one of the world\u2019s leading providers of technology and communications services, transforming the way we connect around the world. We\u2019re a human network that reaches across the globe and works behind the scenes. We anticipate, lead, and believe that listening is where learning begins. In crisis and in celebration, we come together\u2014lifting up our communities and striving to make an impact to move the world forward. If you\u2019re fueled by purpose, and powered by persistence, explore a career with us. Here, you\u2019ll discover the rigor it takes to make a difference and the fulfillment that comes with living the #NetworkLife. \n \n  What you\u2019ll be doing... \n  We constantly seek to improve the customer experience for our government discount program subscribers. That\u2019s where you come in. You\u2019ll coordinate systems analysis and testing to ensure that customers\u2019 issues are resolved faster and more efficiently. Your role will involve maintaining our new and existing reporting practices to ensure subscribe activity is properly and timely managed. \n \n  Develop and deploy reporting structures to support the Government Discount Program. \n  Maintain and create new financial reporting for transactional activity. \n  Performing fallout management to ensure customer issues are timely mitigated. \n  Maintaining commission procedures up-to-date and perform changes to support new commission changes. \n  Develop and maintain documentation for procedures for reporting data, and managing fall out. \n  Collaborate with various Agile teams in support of system design and solutions to solve root causes for problems affecting customer experience (consumers or third parties). \n \n \n  What we\u2019re looking for... \n  As an independent thinker, you enjoy applying theories, concepts, and technologies to solve complex challenges. You have positive relationship building skills and work well with diverse teams. You\u2019re known for your superb communication skills and ability to convey difficult technical information in a way that everyone can understand. No stranger to a fast-paced, pressure-packed, high demand 24x7 operations environment, you can balance competing priorities and keep a laser-sharp focus on work priorities and timelines. \n \n  You\u2019ll need to have: \n \n  Bachelor\u2019s degree or four or more years of work experience. \n  Four or more years of relevant work experience. \n  Experience with programming skills like SQL and/or Oracle, Python, Postgres, etc. \n  Experience with business intelligence tools like Tableau and/or ThoughtSpot. \n  Willingness to work weekends and holidays and to undertake work in changing seasonal conditions. \n \n \n  Even better if you have one or more of the following: \n \n  Master Degree in Business Analytics or Data Science. \n  Experience in prepaid wireless services and government programs such as Lifeline, Affordable Connectivity Program. \n  Scrum/Agile experience working with product team. \n \n \n  If Verizon and this role sound like a fit for you, we encourage you to apply even if you don\u2019t meet every \u201ceven better\u201d qualification listed above. \n \n \n \n \n \n \n \n \n  Where you\u2019ll be working \n \n \n \n \n \n \n  In this hybrid role, you'll have a defined work location that includes work from home and assigned office days set by your manager.\n  \n  Scheduled Weekly Hours  40\n  \n  Equal Employment Opportunity \n  We\u2019re proud to be an equal opportunity employer - and celebrate our employees\u2019 differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. At Verizon, we know that diversity makes us stronger. We are committed to a collaborative, inclusive environment that encourages authenticity and fosters a sense of belonging. We strive for everyone to feel valued, connected, and empowered to reach their potential and contribute their best. Check out our diversity and inclusion page to learn more.",
        "cleaned_desc": "  Develop and maintain documentation for procedures for reporting data, and managing fall out. \n  Collaborate with various Agile teams in support of system design and solutions to solve root causes for problems affecting customer experience (consumers or third parties). \n \n \n  What we\u2019re looking for... \n  As an independent thinker, you enjoy applying theories, concepts, and technologies to solve complex challenges. You have positive relationship building skills and work well with diverse teams. You\u2019re known for your superb communication skills and ability to convey difficult technical information in a way that everyone can understand. No stranger to a fast-paced, pressure-packed, high demand 24x7 operations environment, you can balance competing priorities and keep a laser-sharp focus on work priorities and timelines. \n \n  You\u2019ll need to have: \n \n  Bachelor\u2019s degree or four or more years of work experience.    Four or more years of relevant work experience. \n  Experience with programming skills like SQL and/or Oracle, Python, Postgres, etc. \n  Experience with business intelligence tools like Tableau and/or ThoughtSpot. \n  Willingness to work weekends and holidays and to undertake work in changing seasonal conditions. \n \n \n  Even better if you have one or more of the following: \n \n  Master Degree in Business Analytics or Data Science. \n  Experience in prepaid wireless services and government programs such as Lifeline, Affordable Connectivity Program. ",
        "techs": [
            "sql",
            "oracle",
            "python",
            "postgres",
            "tableau",
            "thoughtspot"
        ],
        "cleaned_techs": [
            "sql",
            "oracle",
            "python",
            "postgres",
            "tableau",
            "thoughtspot"
        ]
    },
    "f2ec83695ea360bb": {
        "terms": [
            "data science",
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Claims Data Analyst",
        "company": "JAMES RIVER MANAGEMENT CO INC",
        "desc": "James River Group Holdings, Ltd. is a Bermuda-based insurance holding company which owns and operates a group of specialty insurance and reinsurance companies. The Company operates in three specialty property-casualty insurance and reinsurance segments: Excess and Surplus Lines, Specialty Admitted Insurance and Casualty Reinsurance. The Company tends to focus on accounts associated with small or medium-sized businesses in each of its segments. Each of the Company's regulated insurance subsidiaries are rated \"A-\" (Excellent) by A.M. Best Company. \n  Job Summary \n  The Senior Claims Data Analyst provides reporting and analytics support to the VP, Claims Operations and SVP, Chief Claims Officer. Working closely with Claims Management and Actuarial Leadership, this individual will gather and analyze claims data, develop an understanding of the key drivers of financial and actuarial data, and share insights while ensuring alignment of data trends and processes. This role is integral in ensuring the Claims department adheres to reserving best practices and continuously improves claim resolution efficiency and effectiveness. \n  Duties and Responsibilities \n \n  Continuously exhibit and uphold Core Values of Integrity, Accountability, Communication and Teamwork, Innovation and Customer Service \n  Manage processes, reports, and analytics related to claim reserving functions \n  Work with Accounting/Finance, Actuarial and Internal Audit departments to ensure adequate claim financial controls are in place and being adhered to \n  Perform monthly operational reporting, dashboards, metrics, and KPIs including reserve committees and portfolio reviews \n  Assist with interdepartmental projects, processes, and reports between Accounting/Finance, Actuarial, Reinsurance and Claims \n  Assist in the presentation and delivery of observations, areas of concerns, and recommendations to Claims Management and employees \n  Work in conjunction with Claims and Actuarial Departments to gather Claims data, derive actionable and meaningful insights, and develop strategy \n  Perform analyses of reserve trending in all LOB\u2019s in collaboration with Actuarial \n  Analyze financial data, develop metrics, and test case reserve adequacy to ensure their financial strength \n  Monitor case reserves of product line or segment to ensure present and future reserving strategies to achieve financial strength \n  Review and analyze claim cases reserving patterns to foster claim case reserve adequacy \n \n  Knowledge, Skills and Abilities \n \n  Advanced technical knowledge of reserving and actuarial theories \n  Advanced statistical modeling skills \n  Knowledge of a variety of product lines within P&C as it relates to reserving \n  Proficiency in managing complex datasets and ability to analyze and interpret complex claims data concepts \n  Experience in using statistical modeling and/or machine learning techniques to build models that drive decision making \n  Advanced proficiency in SQL and other query and automation languages (Power Query M, DAX, python) \n  Advanced proficiency in visualization tools (PowerBI, Tableau, Qlik Sense) \n  Advanced proficiency in MS Office (Word, Excel, Outlook, PowerPoint) \n  Understanding of claims case reserving practices \n  Ability to effectively communicate with all levels of the organization \n  Advanced proficiency in insurance claims reporting \n  Excellent written and verbal communication skills \n  Ability to demonstrate business acumen and forward-thinking skills \n  Strong analytical skills \n  Skilled in collecting and analyzing complex data \n  Ability to organize complex information and pay close attention to detail \n  Ability to work successfully as an individual contributor and in a team environment \n \n  Experience and Education \n \n  Bachelor\u2019s Degree in Math, Actuarial Science or related field required \n  Master\u2019s Degree in related field preferred \n  Minimum of five years of claims, data analysis, or actuarial experience, in the insurance industry, required \n  Minimum of three years of predictive modeling experience preferred \n \n \n  #LI-KS1 \n  #LI-Remote",
        "cleaned_desc": " \n  Advanced technical knowledge of reserving and actuarial theories \n  Advanced statistical modeling skills \n  Knowledge of a variety of product lines within P&C as it relates to reserving \n  Proficiency in managing complex datasets and ability to analyze and interpret complex claims data concepts \n  Experience in using statistical modeling and/or machine learning techniques to build models that drive decision making \n  Advanced proficiency in SQL and other query and automation languages (Power Query M, DAX, python) \n  Advanced proficiency in visualization tools (PowerBI, Tableau, Qlik Sense) \n  Advanced proficiency in MS Office (Word, Excel, Outlook, PowerPoint)    Understanding of claims case reserving practices \n  Ability to effectively communicate with all levels of the organization \n  Advanced proficiency in insurance claims reporting \n  Excellent written and verbal communication skills \n  Ability to demonstrate business acumen and forward-thinking skills \n  Strong analytical skills \n  Skilled in collecting and analyzing complex data \n  Ability to organize complex information and pay close attention to detail \n  Ability to work successfully as an individual contributor and in a team environment ",
        "techs": [
            "reserving theories",
            "actuarial theories",
            "statistical modeling",
            "product lines",
            "complex datasets",
            "claims data concepts",
            "statistical modeling techniques",
            "machine learning techniques",
            "sql",
            "power query m",
            "dax",
            "python",
            "powerbi",
            "tableau",
            "qlik sense",
            "ms office",
            "claims case reserving practices",
            "communication skills",
            "insurance claims reporting",
            "business acumen",
            "analytical skills",
            "data analysis",
            "organizational skills",
            "teamwork"
        ],
        "cleaned_techs": [
            "actuarial theories",
            "statistical modeling",
            "product lines",
            "complex datasets",
            "claims data concepts",
            "statistical modeling techniques",
            "machine learning techniques",
            "sql",
            "power query m",
            "dax",
            "python",
            "powerbi",
            "tableau",
            "qlik sense",
            "microsoft",
            "claims case reserving practices",
            "insurance claims reporting",
            "business acumen",
            "teamwork"
        ]
    },
    "afcb44f14008f275": {
        "terms": [
            "data science"
        ],
        "salary_min": 106200.0,
        "salary_max": 242000.0,
        "title": "Data Scientist, Lead",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Norfolk,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180119\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Scientist, Lead\n           The Opportunity: \n  As a data scientist, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors\u2014from fraud detection to cancer research to national intelligence\u2014we need a seasoned data scientist like you to help find the answers in the data. \n \n  On our team, you\u2019ll use your leadership skills and data science expertise to create real-world impact. You\u2019ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You\u2019ll guide and mentor your team as you oversee the development of algorithms and systems. You\u2019ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. As a technical leader, you\u2019ll identify new opportunities to use data science solutions to help your clients meet their toughest challenges. Ultimately, you\u2019ll provide a deep understanding of the data, what it all means, and how it can be used. \n \n  Work with us as we use data science for good. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  8+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining \n  8+ years of experience with statistical and general-purpose programming languages for data analysis \n  8+ years of experience analyzing structured and unstructured data sources \n  Experience developing predictive data models, quantitative analyses, and visualization of targeted data sources \n  Experience leading a team, including projects and deliverables \n  Experience leading the development of solutions to complex programs \n  Experience with natural language processing, text mining, or machine learning techniques \n  Secret clearance \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with the development of algorithms leveraging R, Python, or SQL and NoSQL \n  Experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL \n  Experience with Machine Learning, AI, or NLP \n  Experience with visualization packages, including Plotly, Seaborn, or ggplot2 \n  TS/SCI clearance \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $106,200.00 to $242,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": " \n \n \n \n \n \n         Data Scientist, Lead\n           The Opportunity: \n  As a data scientist, you\u2019re excited at the prospect of unlocking the secrets held by a data set, and you\u2019re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors\u2014from fraud detection to cancer research to national intelligence\u2014we need a seasoned data scientist like you to help find the answers in the data. \n \n  On our team, you\u2019ll use your leadership skills and data science expertise to create real-world impact. You\u2019ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You\u2019ll guide and mentor your team as you oversee the development of algorithms and systems. You\u2019ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. As a technical leader, you\u2019ll identify new opportunities to use data science solutions to help your clients meet their toughest challenges. Ultimately, you\u2019ll provide a deep understanding of the data, what it all means, and how it can be used. \n \n  Work with us as we use data science for good. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  8+ years of experience with data exploration, data cleaning, data analysis, data visualization, or data mining \n  8+ years of experience with statistical and general-purpose programming languages for data analysis \n  8+ years of experience analyzing structured and unstructured data sources \n  Experience developing predictive data models, quantitative analyses, and visualization of targeted data sources    Experience leading a team, including projects and deliverables \n  Experience leading the development of solutions to complex programs \n  Experience with natural language processing, text mining, or machine learning techniques \n  Secret clearance \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with the development of algorithms leveraging R, Python, or SQL and NoSQL \n  Experience with distributed data and computing tools, including MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL \n  Experience with Machine Learning, AI, or NLP \n  Experience with visualization packages, including Plotly, Seaborn, or ggplot2 \n  TS/SCI clearance \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us ",
        "techs": [
            "data exploration",
            "data cleaning",
            "data analysis",
            "data visualization",
            "data mining",
            "statistical programming languages",
            "general-purpose programming languages",
            "structured data",
            "unstructured data",
            "predictive data models",
            "quantitative analyses",
            "visualization of targeted data sources",
            "natural language processing",
            "text mining",
            "machine learning techniques",
            "r",
            "python",
            "sql",
            "nosql",
            "distributed data tools",
            "mapreduce",
            "hadoop",
            "hive",
            "emr",
            "kafka",
            "spark",
            "gurobi",
            "mysql",
            "machine learning",
            "ai",
            "nlp",
            "visualization packages",
            "plotly",
            "seaborn",
            "ggplot2"
        ],
        "cleaned_techs": [
            "data cleaning",
            "data visualization",
            "data mining",
            "statistical programming languages",
            "general-purpose programming languages",
            "structured data",
            "unstructured data",
            "predictive data models",
            "quantitative analyses",
            "visualization of targeted data sources",
            "nlp",
            "text mining",
            "machine learning techniques",
            "r",
            "python",
            "sql",
            "nosql",
            "distributed data tools",
            "mapreduce",
            "hadoop",
            "hive",
            "emr",
            "kafka",
            "spark",
            "gurobi",
            "mysql",
            "ai",
            "visualization packages",
            "plotly",
            "seaborn",
            "ggplot2"
        ]
    },
    "d5f9cafe02a2dc5b": {
        "terms": [
            "data science"
        ],
        "salary_min": 161700.0,
        "salary_max": 258300.0,
        "title": "Principal Product Designer, Artificial Intelligence",
        "company": "Zillow",
        "desc": "About the team  The Zillow Experience Design (ZxD) team is a fast-paced, collaborative, and driven product design team. We\u2019re a tight-knit, fun-loving, and upbeat group. Meet us and learn more: https://www.zillow.com/careers/design/\n  \n  We are a multidisciplinary team. Our roles include product design, content design, experience research, design systems, and design operations.\n  \n  We build useful, usable, and innovative experiences for Zillow customers. These experiences live across web, mobile, and internal software platforms.\n  \n  Our team cares deeply about solving problems for real people \u2013 customers, co-workers, and everyone else. We seek to make everything a little better than we found it.\n  \n  About the role \n  As a Principal Product Designer on the Design Technology and Artificial Intelligence team, you\u2019re responsible for understanding customer needs, developing ideas and direction, and working with a cross-functional team to explore new applications of emerging technology. With a continuous learning and entrepreneurial approach, you\u2019ll work to prove early signals on customer behavior and empower customers with new ways to find their next home. As principal, you\u2019ll work strategically across functional areas, including applied science, mobile development, research, and behavioral science. Ultimately, you\u2019ll explore how to bring more delight and authenticity to an emotional part of our user\u2019s journey as part of our mission to make Zillow the most-loved place to discover, buy, sell, or rent a home. \n \n  Responsibilities: \n \n  Design digital experiences for web, iOS, Android, and operator platforms \n  Advocate for customer needs and ensure that designs address customer goals \n  Work with product managers, researchers, content designers, applied scientists, and engineers \n  Lead design activities like problem definition, storytelling, journey mapping, co-design sessions, prototyping, design critique, and user testing \n  Propose, test, and evaluate ideas that improve Zillow customer experiences \n  Build detailed information architecture, interaction models, and UI patterns \n  Present design work and regularly engage with partners for feedback \n  Lead multiple projects independently and deliver high-quality work on time \n  Partner with other designers to ensure design consistency and excellence \n  Share expertise and mentorship to help others develop skills \n  Contribute, learn, grow, and have fun! \n \n  This role has been categorized as a Remote position. \u201cRemote\u201d employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.\n   In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $161,700.00 - $258,300.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.\n   In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.\n  \n  Who you are \n \n  7+ years as a product designer, user experience designer, design lead, or similar role \n  Strong understanding of Emerging Technology trends and the proven ability to translate complex AI concepts into intuitive and engaging user experiences \n  Ability to prototype and iterate on AI-driven interactions and interfaces \n  Ability to collaborate with data scientists, engineers, and other stakeholders to ensure the successful implementation of AI features \n  Ability to balance the ethical considerations and potential biases associated with AI algorithms \n  Understanding of the limitations and challenges of AI technology and its implications for user experience design \n  Experience working with emerging technology to develop new customer experiences \n  Strong communication and collaboration skills \n  Experience building relationships and working optimally with diverse, cross-functional teams \n  Experience developing tools and frameworks to help teams work better together \n  Experience providing direction that helps designers grow their skills and deliver their best work \n  Experience identifying customer insights through user research and discovery activities \n  Experience crafting products and services using human-centered design principles \n  Experience shipping products that get meaningful results for customers and businesses \n  Examples of high-quality interaction and visual design work in a design portfolio \n  Examples of critical thinking, creativity, and risk-taking in design projects \n  Expertise in interaction design, visual design, and other user experience fields \n  Expertise with Figma, Sketch, Adobe XD, or similar design and prototyping tools \n  Please submit a portfolio and resume with your application \n \n \n  Get to know us \n  Zillow is reimagining real estate to make home a reality for more and more people. \n \n  As the most-visited real estate website in the United States, Zillow\u00ae and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people. \n \n  Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We\u2019re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don\u2019t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees\u2019 Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list. \n \n  Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com. \n \n  Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.",
        "cleaned_desc": " \n  Design digital experiences for web, iOS, Android, and operator platforms \n  Advocate for customer needs and ensure that designs address customer goals \n  Work with product managers, researchers, content designers, applied scientists, and engineers \n  Lead design activities like problem definition, storytelling, journey mapping, co-design sessions, prototyping, design critique, and user testing \n  Propose, test, and evaluate ideas that improve Zillow customer experiences \n  Build detailed information architecture, interaction models, and UI patterns \n  Present design work and regularly engage with partners for feedback \n  Lead multiple projects independently and deliver high-quality work on time \n  Partner with other designers to ensure design consistency and excellence \n  Share expertise and mentorship to help others develop skills \n  Contribute, learn, grow, and have fun!    Understanding of the limitations and challenges of AI technology and its implications for user experience design \n  Experience working with emerging technology to develop new customer experiences \n  Strong communication and collaboration skills \n  Experience building relationships and working optimally with diverse, cross-functional teams \n  Experience developing tools and frameworks to help teams work better together \n  Experience providing direction that helps designers grow their skills and deliver their best work \n  Experience identifying customer insights through user research and discovery activities \n  Experience crafting products and services using human-centered design principles \n  Experience shipping products that get meaningful results for customers and businesses \n  Examples of high-quality interaction and visual design work in a design portfolio \n  Examples of critical thinking, creativity, and risk-taking in design projects \n  Expertise in interaction design, visual design, and other user experience fields ",
        "techs": [
            "web design",
            "ios design",
            "android design",
            "operator platform design",
            "product management",
            "research",
            "content design",
            "applied science",
            "engineering",
            "problem definition",
            "storytelling",
            "journey mapping",
            "co-design sessions",
            "prototyping",
            "design critique",
            "user testing",
            "information architecture",
            "interaction models",
            "ui patterns",
            "design presentation",
            "design feedback",
            "project management",
            "design consistency",
            "mentorship",
            "ai technology",
            "user experience design",
            "emerging technology",
            "communication skills",
            "collaboration skills",
            "relationship building",
            "cross-functional teamwork",
            "tool and framework development",
            "designer skill development",
            "user research",
            "human-centered design",
            "product shipping",
            "interaction design",
            "visual design",
            "user experience expertise."
        ],
        "cleaned_techs": [
            "web design",
            "ios design",
            "android design",
            "operator platform design",
            "product management",
            "research",
            "content design",
            "applied science",
            "engineering",
            "problem definition",
            "storytelling",
            "journey mapping",
            "co-design sessions",
            "prototyping",
            "design critique",
            "user testing",
            "information architecture",
            "interaction models",
            "ui patterns",
            "design presentation",
            "design feedback",
            "project management",
            "design consistency",
            "mentorship",
            "ai",
            "user experience design",
            "emerging technology",
            "relationship building",
            "cross-functional teamwork",
            "tool and framework development",
            "designer skill development",
            "user research",
            "human-centered design",
            "product shipping",
            "interaction design",
            "visual design",
            "user experience expertise."
        ]
    },
    "6a50db2d6d1441a1": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 117000.0,
        "salary_max": 117000.0,
        "title": "AI Software Engineer",
        "company": "Zoom Video Communications, Inc.",
        "desc": "About The Team \n \n  We are seeking a highly passionate AI Software Engineer to join our AI team. As a AI Software Engineer at Zoom, you will play a pivotal role in developing and enhancing our AI-powered software solutions. You will work closely with our cross-functional teams to design, implement, and optimize AI algorithms and software applications. This position presents an exhilarating chance to actively participate in pioneering software development while playing a crucial role in influencing the direction of AI, utilizing your expertise in both of these domains. \n \n  About the Role: \n \n  Responsibilities: \n \n  Collaborate with multidisciplinary teams to understand project requirements and objectives. \n  Design, develop, and maintain AI algorithms, models, and software applications. \n  Implement AI solutions to solve complex problems in [mention specific applications, e.g., computer vision, natural language processing, recommendation systems, etc.]. \n  Optimize and fine-tune AI models for improved performance and efficiency. \n  Conduct research to stay updated with the latest advancements in AI and related technologies. \n  Participate in code reviews, testing, and debugging to ensure the reliability and quality of software products. \n  Document code, algorithms, and technical processes for internal and external reference. \n  Mentor and provide guidance to junior members of the AI and software engineering team. \n  Collaborate with product managers and stakeholders to translate business requirements into technical solutions. \n \n \n  About You \n  Basic Qualifications: \n \n  Master's degree in Computer Science, AI, or a related field. \n  3 years of professional experience in software engineering, AI, or machine learning. \n  Proficiency in programming languages such as Python, Java, or C++. \n  Strong understanding of AI concepts, algorithms, and frameworks (e.g., TensorFlow, PyTorch, scikit-learn). \n  Experience with deep learning, neural networks, and data preprocessing. \n  Knowledge of software development best practices and version control systems (e.g., Git). \n  Excellent problem-solving and analytical skills. \n  Strong communication and collaboration skills. \n  Ability to work effectively in a fast-paced and dynamic environment. \n  Collaborative Spirit: Illustrate your ability to work within a collaborative team environment and your eagerness to contribute fresh ideas. \n  Problem-Solving: Highlight your problem-solving skills and your capability to approach research challenges with creativity and critical thinking. \n  Fast-Paced Agility: Embrace a fast-paced, dynamic work environment, showcasing your ability to manage multiple projects and meet deadlines. \n  Communication Skills: Exhibit strong written and verbal communication skills, enabling you to effectively share your ideas and insights with various audiences. \n \n \n  Preferred Qualifications: \n \n  Knowledge of cloud computing platforms (e.g., AWS, Azure, Google Cloud). \n  Previous contributions to open-source AI or software projects. \n  Familiarity with agile development methodologies. \n \n \n  This is your opportunity to join an innovative AI team, learn from experienced researchers, and contribute to transformative AI projects. If you're a curious and dedicated recent or soon-to-be graduate with a passion for AI, we encourage you to apply and be part of shaping the future of artificial intelligence. \n \n  Salary Range or On Target Earnings: \n \n  Minimum:  $117,000.00\n  \n  Maximum:  $233,900.00\n  \n  In addition to the base salary and/or OTE listed Zoom has a Total Direct Compensation philosophy that takes into consideration; base salary, bonus and equity value. \n \n  Note: Starting pay will be based on a number of factors and commensurate with qualifications & experience. \n \n  We also have a location based compensation structure; there may be a different range for candidates in this and other locations. \n \n  About Us \n \n  Zoomies help people stay connected so they can get more done together. We set out to build the best video product for the enterprise, and today help people communicate better with products like Zoom Contact Center, Zoom Phone, Zoom Events, Zoom Apps, Zoom Rooms, and Zoom Webinars. \n \n  We\u2019re problem-solvers, working at a fast pace to design solutions with our customers and users in mind. Here, you\u2019ll work across teams to deliver impactful projects that are changing the way people communicate and enjoy opportunities to advance your career in a diverse, inclusive environment. \n \n  Explore Zoom: \n \n  Hear from our leadership team \n  Browse Awards and Employee Reviews on Comparably \n  Visit our Blog \n  Zoom with us! \n \n \n \n  We believe that the unique contributions of all Zoomies is the driver of our success. To make sure that our products and culture continue to incorporate everyone's perspectives and experience we never discriminate on the basis of race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. Zoom is proud to be an equal opportunity workplace and is an affirmative action employer. All your information will be kept confidential according to EEO guidelines. \n \n  We welcome people of different backgrounds, experiences, abilities and perspectives including qualified applicants with arrest and conviction records and any qualified applicants requiring reasonable accommodations in accordance with the law. If you need any assistance or accommodations due to a medical condition, or if you need assistance accessing our website or completing the application process, please let us know by emailing us at careers@zoom.us. \n  #LI-Remote",
        "cleaned_desc": "About The Team \n \n  We are seeking a highly passionate AI Software Engineer to join our AI team. As a AI Software Engineer at Zoom, you will play a pivotal role in developing and enhancing our AI-powered software solutions. You will work closely with our cross-functional teams to design, implement, and optimize AI algorithms and software applications. This position presents an exhilarating chance to actively participate in pioneering software development while playing a crucial role in influencing the direction of AI, utilizing your expertise in both of these domains. \n \n  About the Role: \n \n  Responsibilities: \n \n  Collaborate with multidisciplinary teams to understand project requirements and objectives. \n  Design, develop, and maintain AI algorithms, models, and software applications. \n  Implement AI solutions to solve complex problems in [mention specific applications, e.g., computer vision, natural language processing, recommendation systems, etc.]. \n  Optimize and fine-tune AI models for improved performance and efficiency. \n  Conduct research to stay updated with the latest advancements in AI and related technologies. \n  Participate in code reviews, testing, and debugging to ensure the reliability and quality of software products. \n  Document code, algorithms, and technical processes for internal and external reference.    Mentor and provide guidance to junior members of the AI and software engineering team. \n  Collaborate with product managers and stakeholders to translate business requirements into technical solutions. \n \n \n  About You \n  Basic Qualifications: \n \n  Master's degree in Computer Science, AI, or a related field. \n  3 years of professional experience in software engineering, AI, or machine learning. \n  Proficiency in programming languages such as Python, Java, or C++. \n  Strong understanding of AI concepts, algorithms, and frameworks (e.g., TensorFlow, PyTorch, scikit-learn). \n  Experience with deep learning, neural networks, and data preprocessing. \n  Knowledge of software development best practices and version control systems (e.g., Git). \n  Excellent problem-solving and analytical skills. \n  Strong communication and collaboration skills.    Ability to work effectively in a fast-paced and dynamic environment. \n  Collaborative Spirit: Illustrate your ability to work within a collaborative team environment and your eagerness to contribute fresh ideas. \n  Problem-Solving: Highlight your problem-solving skills and your capability to approach research challenges with creativity and critical thinking. \n  Fast-Paced Agility: Embrace a fast-paced, dynamic work environment, showcasing your ability to manage multiple projects and meet deadlines. \n  Communication Skills: Exhibit strong written and verbal communication skills, enabling you to effectively share your ideas and insights with various audiences. \n \n \n  Preferred Qualifications: \n \n  Knowledge of cloud computing platforms (e.g., AWS, Azure, Google Cloud). \n  Previous contributions to open-source AI or software projects. \n  Familiarity with agile development methodologies. \n \n \n  This is your opportunity to join an innovative AI team, learn from experienced researchers, and contribute to transformative AI projects. If you're a curious and dedicated recent or soon-to-be graduate with a passion for AI, we encourage you to apply and be part of shaping the future of artificial intelligence. ",
        "techs": [
            "zoom",
            "python",
            "java",
            "c++",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "git",
            "aws",
            "azure",
            "google cloud",
            "agile development methodologies"
        ],
        "cleaned_techs": [
            "zoom",
            "python",
            "java",
            "c++",
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "git",
            "aws",
            "azure",
            "gcp",
            "agile development methodologies"
        ]
    },
    "b3ef8518a1c43eb2": {
        "terms": [
            "data science"
        ],
        "salary_min": 66000.0,
        "salary_max": 127000.0,
        "title": "Lead Specialist, NA Portfolio Development",
        "company": "Viatris",
        "desc": "1100 Mylan Pharmaceuticals Inc.\n  \n \n   At VIATRIS, we see healthcare not as it is but as it should be. We act courageously and are uniquely positioned to be a source of stability in a world of evolving healthcare needs.\n   \n  Viatris empowers people worldwide to live healthier at every stage of life.\n   \n  We do so via:\n  \n \n \n \n  Access  \u2013 Providing high quality trusted medicines regardless of geography or circumstance;\n    \n \n \n  Leadership  \u2013 Advancing sustainable operations and innovative solutions to improve patient health; and\n    \n \n \n  Partnership  \u2013 Leveraging our collective expertise to connect people to products and services.\n    \n \n \n \n   Every day, we rise to the challenge to make a difference and here\u2019s how the Lead Specialist, NA Portfolio Development role will make an impact:\n  \n \n \n   Key responsibilities for this role include:\n  \n \n \n \n     Provides support to the organization in the processing and validation of various pharmaceutical data sources like IMS/iQVIA Prescription data (NMTA, Managed Care) utilized by various business units and leadership teams.\n    \n \n \n     Develop and maintain weekly, monthly and quarterly reporting of market data & trends utilizing Alteryx and Tableau. Audit and analyze data to ensure that information is being accurately represented to the business. Conduct continual assessment of reports including platform capabilities, audience, utilization and cadence to ensure that we are maximizing our deliveries to our internal business partners.\n    \n \n \n     Conduct comprehensive monthly analysis of total pharmaceutical market for US and Canada to support portfolio pipeline evaluations and forecasting activities. Meet with the Director and provide an overview of meaningful market changes. Ensure changes recommended by departmental leadership are incorporated into the reporting & analysis. Present relevant high-level summary data and reports identifying and illustrating market trends and competitive landscape data.\n    \n \n \n     Work as the subject matter expert to address inquiries and resolve issues received from internal business partners. Cultivate relationship with IQVIA support in order to accurately convey data inquiries and propose solutions. Coordinate results and provide timely feedback and guidance to internal business partners in order to bridge the gap between the business and technical solutions.\n    \n \n \n     Complete an annual analysis of pharmaceutical trends including launch data, product conversion, pricing analysis and market share assessments to validate standard assumptions utilized by the business to support forecasting and Strategic Planning activities.\n    \n \n \n     Provide ideas for and implement process improvement recommendations for data workflows and reporting activities. Incorporate input received from internal business partners into analytics technology roadmap. Ensure new technologies and services being considered are well aligned to the strategic direction of the commercial business.\n    \n \n \n     Manage departmental requests for Ad Hoc analysis and reports. Guides the methodology and timelines. Work with Director to assign priority and monitor progress.\n    \n \n \n     Lead in the creation of various departmental presentations to support internal business partners, including Strategic Plans, Gx Industry Reports and Product Specific Dashboards. Review presentations, reports and analysis for accuracy, cohesive strategic vision, and appropriate communication of market trends and portfolio direction.\n    \n \n \n \n   The minimum qualifications for this role are:\n  \n \n \n \n     Minimum of a Bachelor\u2019s Degree, a Master\u2019s Degree is a plus. However, a combination of experience and/or education will be taken into consideration.\n    \n \n \n     Knowledge of pharmaceutical market landscape, Viatris product portfolio, lifecycle of generic pharmaceutical products, Viatris customer base and understanding of the potential impact of business events is preferred.\n    \n \n \n     Required: Analytical ability. Proficient use of Microsoft Excel and Access at a high level of competence is required. Experience with Tableau and Alteryx is desired. Ability to learn, solve complex problems, understand and utilize standard accounting and financial concepts. Ability to learn and understand brand and generic product markets. Must be organized and detail oriented.\n    \n \n \n     Position functions semi-autonomously under the direction of the Director.\n    \n \n \n     Ability to read and interpret complex business and/or technical documents. Ability to write comprehensive reports and detailed business correspondence. Ability to work with groups of people such as other departments and communicate known concepts. Ability to present to a group of departments.\n    \n \n \n     Ability to add, subtract, multiply, and divide in all units of measure, using whole numbers, common fractions and decimals. Ability to compute rate, ratio and percent and to draw and interpret bar graphs. Ability to work with statistical, financial and accounting concepts and calculations.\n    \n \n \n     Ability to solve problems with a variety of concrete as well as non-concrete variables through semi-standardized solutions that require ingenuity and analysis. Ability to draw inferences and follow loosely defined decision trees in order to solve complex problems.\n    \n \n \n     The work environment characteristics described here are representative of those an employee encounters while performing the essential duties of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform essential duties.\n    \n \n \n     Normal office environment. Typically sitting at a desk.\n    \n \n \n     Proficiency in speaking, comprehending, reading and writing English is required.\n    \n \n \n \n   Exact compensation may vary based on skills, experience, and location. The salary range for this position is $66,000.00 - $127,000.00 USD.\n  \n \n \n   At Viatris, we offer competitive salaries, benefits and an inclusive environment where you can use your experiences, perspectives and skills to help make an impact on the lives of others.\n  \n \n \n   Viatris is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, gender expression, disability, or protected veteran status, or any other characteristic protected by local, state, or federal laws, rules, or regulations.\n  \n  #LI-Remote",
        "cleaned_desc": "     Minimum of a Bachelor\u2019s Degree, a Master\u2019s Degree is a plus. However, a combination of experience and/or education will be taken into consideration.\n    \n \n \n     Knowledge of pharmaceutical market landscape, Viatris product portfolio, lifecycle of generic pharmaceutical products, Viatris customer base and understanding of the potential impact of business events is preferred.\n    \n \n \n     Required: Analytical ability. Proficient use of Microsoft Excel and Access at a high level of competence is required. Experience with Tableau and Alteryx is desired. Ability to learn, solve complex problems, understand and utilize standard accounting and financial concepts. Ability to learn and understand brand and generic product markets. Must be organized and detail oriented.\n    \n \n \n     Position functions semi-autonomously under the direction of the Director.\n    \n \n \n     Ability to read and interpret complex business and/or technical documents. Ability to write comprehensive reports and detailed business correspondence. Ability to work with groups of people such as other departments and communicate known concepts. Ability to present to a group of departments.\n    \n \n \n     Ability to add, subtract, multiply, and divide in all units of measure, using whole numbers, common fractions and decimals. Ability to compute rate, ratio and percent and to draw and interpret bar graphs. Ability to work with statistical, financial and accounting concepts and calculations.\n    \n \n ",
        "techs": [
            "microsoft excel",
            "microsoft access",
            "tableau",
            "alteryx"
        ],
        "cleaned_techs": [
            "excel",
            "microsoft access",
            "tableau",
            "alteryx"
        ]
    },
    "2804564acb1f8db9": {
        "terms": [
            "data science"
        ],
        "salary_min": 110867.58,
        "salary_max": 140383.06,
        "title": "ANALYTICS TEAM LEAD",
        "company": "Acadia.io",
        "desc": "Acadia is a team of creative minds and driven marketing professionals. Our mission is to be an elite digital growth platform, for the mid-market disrupter, in order to create opportunity, meaning, & connection for the communities we serve. \n \n  Our Core Values \n \n  Can-do:  We dedicate ourselves to helping our clients and co-workers reach their fullest potential. We demonstrate courage and urgency to find and take ownership. \n  Community:  We show genuine interest. We are the first to ask why, the first to research, and the first to understand. We ask questions until we find the path to conquer obstacles and build solutions \n  Candor:  We are honest and transparent in all our actions. We strive to foster positive and mutually beneficial relationships \u2014 where respect and humanity thrive. \n  Curiosity:  We will make lives better for those people, clients, and other deserving causes that we care deeply about. \n \n \n  We are seeking a highly skilled and experienced Analytics Team Lead to join our team. As the Analytics Team Lead, you will be responsible for guiding and supporting a cross-functional team of 6-10 members to deliver successful analytical projects for our clients. Your superpowers in team leadership, project management, technical expertise, and client relationship management will be crucial in driving the team's performance and achieving desired outcomes. You will play a vital role in ensuring the team's growth, optimizing resources, and aligning project work with clients' objectives. \n \n  Responsibilities \n \n  Team Leadership: \n \n  Lead and inspire a cross-functional team of 6-10 members, fostering collaboration and driving analytical excellence. \n  Coach, mentor, and provide guidance to team members, helping them develop their skills and achieve professional growth. \n  Demonstrate previous experience in leading teams. \n \n \n  Analytics Project Management: \n \n  Possess a solid understanding of the entire analytics project lifecycle, including data warehousing, descriptive analytics, and data science. \n  Utilize your technical background to provide guidance and support to the team without requiring hands-on coding or data visualization skills. \n  Prioritize tasks, allocate resources, and manage project timelines to ensure successful project delivery within budgetary constraints. \n  Present analytical work to the team, providing clear and concise insights and recommendations. \n \n \n  Strategy Lead: \n \n  Collaborate with clients to understand their overall objectives and ensure that project work aligns with their goals and strategic vision. \n  Utilize your knowledge of marketing tactics for modern digital marketers to identify how data and analytics can support client initiatives, such as paid social, paid search, programmatic advertising, email marketing, etc. \n \n \n  Client Relationship Management: \n \n  Demonstrate exceptional interpersonal and communication skills to build strong relationships with clients. \n  Handle challenging situations, negotiate effectively, and act as an advocate for your team while maintaining a respectful and professional approach with clients. \n  Strive to understand clients' needs, provide strategic recommendations, and deliver exceptional customer service to ensure client satisfaction. \n \n \n  Financial Acumen: \n \n  Understand key financial concepts and work within budgetary constraints. \n  Prioritize hiring decisions and resource allocation based on profitability and project requirements. \n \n  Qualifications \n \n  Bachelor's degree in a related field (e.g., Analytics, Data Science, Business, Marketing) or equivalent practical experience. \n  7-10 years of relevant experience in analytics or a related field. \n  Strong familiarity with data warehouse tools and SQL. \n  Experience with data visualization tools such as PowerBI and Tableau. \n  Proven experience as a team lead or manager, with direct reports in your current or previous roles. \n  Extensive knowledge of analytics project management methodologies and best practices. \n  Excellent presentation skills and the ability to communicate complex analytical concepts effectively. \n  Demonstrated ability to prioritize tasks, focus on critical objectives, and accurately estimate the level of effort required for different tasks. \n  Experience in services, consulting, or agency environments is preferred. \n  A growth mindset, with a passion for new challenges and motivating team members to achieve their best. \n \n \n  If you are a dynamic leader with a passion for analytics, thrive in a collaborative environment, and are excited about delivering impactful solutions for clients, we would love to hear from you. \n  Please submit your resume and a cover letter outlining your relevant experience and why you are interested in this position. \n \n  What we offer - The Perks \n \n  A work environment that enthusiastically encourages creativity, risk-taking and growth. \n  16 Paid Holidays \n  Paid vacation and sick time \n  We are closed Christmas Eve through New Year's Day \n  Solid Health Benefits (medical, dental, and vision insurance) \n  401k and Equity Grants \n  Education Reimbursements \n  Opportunity for growth that is second to none in the industry \n  Flexible working hours (EST) \n \n \n  Acadia is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. We believe that the more diverse we are, the more creative our work will be! \n \n  Industry \n \n  Marketing & Advertising \n \n  Employment Type \n  Full-time",
        "cleaned_desc": "  Lead and inspire a cross-functional team of 6-10 members, fostering collaboration and driving analytical excellence. \n  Coach, mentor, and provide guidance to team members, helping them develop their skills and achieve professional growth. \n  Demonstrate previous experience in leading teams. \n \n \n  Analytics Project Management: \n \n  Possess a solid understanding of the entire analytics project lifecycle, including data warehousing, descriptive analytics, and data science. \n  Utilize your technical background to provide guidance and support to the team without requiring hands-on coding or data visualization skills. \n  Prioritize tasks, allocate resources, and manage project timelines to ensure successful project delivery within budgetary constraints. \n  Present analytical work to the team, providing clear and concise insights and recommendations. \n \n \n  Strategy Lead: \n \n  Collaborate with clients to understand their overall objectives and ensure that project work aligns with their goals and strategic vision.   \n  Bachelor's degree in a related field (e.g., Analytics, Data Science, Business, Marketing) or equivalent practical experience. \n  7-10 years of relevant experience in analytics or a related field. \n  Strong familiarity with data warehouse tools and SQL. \n  Experience with data visualization tools such as PowerBI and Tableau. \n  Proven experience as a team lead or manager, with direct reports in your current or previous roles. \n  Extensive knowledge of analytics project management methodologies and best practices. \n  Excellent presentation skills and the ability to communicate complex analytical concepts effectively. \n  Demonstrated ability to prioritize tasks, focus on critical objectives, and accurately estimate the level of effort required for different tasks. \n  Experience in services, consulting, or agency environments is preferred. \n  A growth mindset, with a passion for new challenges and motivating team members to achieve their best. \n \n \n  If you are a dynamic leader with a passion for analytics, thrive in a collaborative environment, and are excited about delivering impactful solutions for clients, we would love to hear from you. \n  Please submit your resume and a cover letter outlining your relevant experience and why you are interested in this position. \n ",
        "techs": [
            "data warehousing",
            "descriptive analytics",
            "data science",
            "sql",
            "powerbi",
            "tableau",
            "analytics project management methodologies"
        ],
        "cleaned_techs": [
            "data warehousing",
            "descriptive analytics",
            "data science",
            "sql",
            "powerbi",
            "tableau",
            "analytics project management methodologies"
        ]
    },
    "f0caa55d5781d7b3": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 58300.0,
        "salary_max": 133000.0,
        "title": "Data Engineer, Mid",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Norfolk,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0180122\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Data Engineer, Mid\n           The Opportunity: \n  Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there\u2019s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it\u2019s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions\u2014from fraud detection to cancer research to national intelligence. \n \n  As a big data engineer at Booz Allen, you\u2019ll use your skills and experience to implement data engineering activities on some of the most mission-driven projects in the industry. You\u2019ll develop and deploy the pipelines and platforms that organize and make disparate data meaningful. Here, you\u2019ll work with a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, Agile environment. You\u2019ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, developing, and maintenance of scalable platforms for your clients. Work with us to use big data for good. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  2+ years of experience writing software in programming languages, including Python \n  1+ year of experience with source control and collaboration software, including Git or Atlassian tools \n  1+ year of experience with extract, transform, and load (ETL) operations, including on-premise or Cloud infrastructure \n  Knowledge of relational and non-relational database technologies, including SQL or GraphQL \n  Knowledge of automation and scripting on Linux or Windows operating systems \n  Ability to obtain a security clearance \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience deploying analytics workloads on platform as a service (PaaS) and software as a service (SaaS), including AWS EMR, Redshift, or SageMaker or Azure Databricks, SQL Data Warehouse, or Machine Learning service \n  Experience with distributed or parallel programming frameworks, including Apache Spark or NVIDIA CUDA, and infrastructure as code (IaC) frameworks and services, including Terraform or CloudFormation \n  Experience with developing and presenting complex technical information for technical and non-technical audiences and senior leaders \n  Experience with developing and deploying large-scale batch and stream analytics pipelines \n  Experience in working with integrated groups composed of customer success managers, infrastructure engineers, data scientists, and software engineers \n  Experience with Agile engineering practices \n  Experience with DoD information systems \n  Secret clearance \n  Master's degree \n  Cloud development certification, including AWS Solutions Architect or Azure certification, and Information Security certification, including Security+ or CISSP certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": " \n \n \n \n \n \n         Data Engineer, Mid\n           The Opportunity: \n  Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there\u2019s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it\u2019s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions\u2014from fraud detection to cancer research to national intelligence. \n \n  As a big data engineer at Booz Allen, you\u2019ll use your skills and experience to implement data engineering activities on some of the most mission-driven projects in the industry. You\u2019ll develop and deploy the pipelines and platforms that organize and make disparate data meaningful. Here, you\u2019ll work with a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, Agile environment. You\u2019ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, developing, and maintenance of scalable platforms for your clients. Work with us to use big data for good. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  2+ years of experience writing software in programming languages, including Python \n  1+ year of experience with source control and collaboration software, including Git or Atlassian tools \n  1+ year of experience with extract, transform, and load (ETL) operations, including on-premise or Cloud infrastructure \n  Knowledge of relational and non-relational database technologies, including SQL or GraphQL \n  Knowledge of automation and scripting on Linux or Windows operating systems \n  Ability to obtain a security clearance    Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience deploying analytics workloads on platform as a service (PaaS) and software as a service (SaaS), including AWS EMR, Redshift, or SageMaker or Azure Databricks, SQL Data Warehouse, or Machine Learning service \n  Experience with distributed or parallel programming frameworks, including Apache Spark or NVIDIA CUDA, and infrastructure as code (IaC) frameworks and services, including Terraform or CloudFormation \n  Experience with developing and presenting complex technical information for technical and non-technical audiences and senior leaders \n  Experience with developing and deploying large-scale batch and stream analytics pipelines \n  Experience in working with integrated groups composed of customer success managers, infrastructure engineers, data scientists, and software engineers \n  Experience with Agile engineering practices \n  Experience with DoD information systems \n  Secret clearance \n  Master's degree \n  Cloud development certification, including AWS Solutions Architect or Azure certification, and Information Security certification, including Security+ or CISSP certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n  Grow With Us ",
        "techs": [
            "iot",
            "machine learning",
            "artificial intelligence",
            "big data",
            "data engineering",
            "python",
            "git",
            "atlassian tools",
            "extract",
            "transform",
            "and load (etl)",
            "sql",
            "graphql",
            "linux",
            "windows",
            "aws emr",
            "redshift",
            "sagemaker",
            "azure databricks",
            "sql data warehouse",
            "machine learning service",
            "apache spark",
            "nvidia cuda",
            "terraform",
            "cloudformation",
            "batch and stream analytics pipelines",
            "agile engineering practices",
            "dod information systems",
            "aws solutions architect",
            "azure certification",
            "security+ certification",
            "cissp certification"
        ],
        "cleaned_techs": [
            "iot",
            "ai",
            "big data",
            "python",
            "git",
            "atlassian tools",
            "extract",
            "transform",
            "and load (etl)",
            "sql",
            "graphql",
            "linux",
            "windows",
            "aws",
            "redshift",
            "sagemaker",
            "azure",
            "machine learning service",
            "apache spark",
            "nvidia cuda",
            "terraform",
            "cloudformation",
            "batch and stream analytics pipelines",
            "agile engineering practices",
            "dod information systems",
            "cissp certification"
        ]
    },
    "398f078741242701": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 154114.36,
        "salary_max": 195143.11,
        "title": "Lead Machine Learning Engineer",
        "company": "Janus: Shape the Future of Healthcare",
        "desc": "At Janus, we believe in a world where healthcare functions efficiently. Join us on our mission to improve the lives of administrative workers and fundamentally change the way work is done. Our team is building a world-class process improvement platform to help healthcare providers generate more cash with fewer resources. \n \n  Summary \n  The Lead Machine Learning Engineer collaborates closely with Data Scientists and other engineering teams to design, implement, and maintain systems that operationalize and scale our data and machine learning pipelines. Expertise in machine learning operations and cloud infrastructure will be crucial in ensuring the successful deployment and management of our production machine learning systems. This person will help manage a growing team and provide critical mentorship and guidance to junior team members. If you have a passion for cutting-edge technology, complex problem-solving, and delivering high-quality solutions, this is an exciting opportunity to make a significant impact in our organization. \n  Responsibilities \n \n Collaborate with Data Scientists and product teams to understand user stories and convert them into technical requirements for machine learning solutions. \n Manage, mentor, and provide technical guidance to junior team members, promoting knowledge sharing and professional growth. \n Design, build, and deploy production machine learning systems on AWS cloud infrastructure. \n Develop and maintain robust data and machine learning pipelines, ensuring scalability, reliability, and efficiency. \n Implement and optimize monitoring, logging, and alerting systems to ensure the health and performance of deployed machine learning models. \n Work closely with DevOps and infrastructure teams to ensure seamless integration and deployment of machine learning pipelines. \n Automate and streamline the end-to-end machine learning workflow, including data ingestion, feature engineering, model training, evaluation, and deployment. \n Implement best practices for version control, model reproducibility, and model deployment. \n Collaborate with cross-functional teams to identify and address performance bottlenecks, scalability challenges, and data quality issues. \n Continuously evaluate and adopt emerging technologies and tools to improve the efficiency and effectiveness of machine learning operations. \n \n Qualifications \n \n 5+ years of relevant work experience in ML, including designing, building, and deploying production machine learning systems. \n Strong expertise in deploying machine learning models on AWS cloud infrastructure. \n Proficiency in Python and SQL for data manipulation, analysis, and model development. \n Strong knowledge of Linux, Docker, and Kubernetes for containerization and orchestration of machine learning applications. \n Strong knowledge of PySpark, Airflow, and data pipelines; strong knowledge of Sagemaker and machine learning pipelines. \n Passion for learning and staying updated with the latest advancements in machine learning, MLOps, and cloud technologies. \n Excellent communication skills, with the ability to effectively communicate complex technical concepts to both technical and non-technical stakeholders. \n Bachelor's degree in Computer Science, related field, or equivalent experience. \n Familiarity with Computer Vision, NLP, or Reinforcement Learning is a plus. \n Experience working at a health system or healthcare technology company is preferred. \n Experience working at a software as a service (SaaS) company is preferred. \n Experience working in a high-growth environment is preferred. \n \n \n \n  We know that potential candidates are often less likely to apply to a position if they don't match 100% of the job qualifications. Don't let that be why you miss out on this opportunity! We encourage you to apply if you can demonstrate many of these skills and competencies. \n \n \n  Care for the Whole Person \n  At Janus, our commitment is to provide each employee with what they need to be successful. Our benefits package has been designed in a thoughtful way that allows our employees to be happy, healthy and whole. Here are a few things we offer: \n \n We contribute 100% of base plan (HDHP) medical premiums for employees and 50% of premiums for family members. There are other options available as well. \n We contribute 75% of premiums for dental and vision insurance for employee-only plans. \n We have an employee assistance program that allows you the chance to work through any issues that may arise with the appropriate professional. \n We have a 401k plan with minimal portfolio fees, traditional and roth options, as well as rollovers and loan capabilities. \n We offer stock options to share in the value we create and in the ownership of Janus, so let's make it something that we are proud of. \n We offer unlimited PTO because we want our employees to take the time they need to rejuvenate and relax. At minimum, encourage all employees to take at least 15 fully unplugged days off each year. \n We encourage sacred moments that are free from distractions and allow you to create a connection with someone or something that is meaningful to you. \n We provide a monthly allowance to cover the cost related to working in a remote environment like upgraded internet or to offset your cell phone bill. \n We offer parental leave because bonding with your newest addition is so important! \n We have caregiving leave for our employees that are the primary caregiver for a loved one and needs time to care for that person. \n We want you to look for personal enrichment opportunities and will give you up to $500 per year to invest in yourself. We want you to be the best version of you and take time to do things you enjoy! \n We encourage on-going training, additional certifications and professional development related to your role and will review all requests for additional growth (including travel). \n We have committees focused on organizational initiatives to increase employee happiness and the recruitment and retention of a broad, inclusive workforce that represents a diverse range of interests, abilities, talents, and cultures. You are welcome to join! \n \n We have a benefits summary for you to review and will send more comprehensive information with your offer letter. If you want to review it sooner, just let us know! \n \n \n  Equal Opportunity Statement \n  Janus is an equal opportunity employer. We hire great people from a wide variety of backgrounds and appreciate our differences. We welcome the unique contributions that you can bring in terms of your education, opinions, culture, ethnicity, race, ancestry, sex, gender identity and expression, national origin, citizenship, marital status, age, languages spoken, veteran status, color, religion, disability, sexual orientation, and beliefs. \n  We consider qualified applicants regardless of criminal histories, consistent with legal requirements. \n  Further, consistent with applicable federal and state law, Janus provides reasonable accommodations when requested by qualified applicants or employees with disabilities, unless doing so would cause an undue hardship. Janus' policy regarding requests for reasonable accommodation applies to all aspects of employment, including the application process. If you require reasonable accommodation, please contact the People team. \n \n \n  E-Verify \n  This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S. If E-Verify cannot confirm that you are authorized to work, this employer is required to give you written instructions and an opportunity to contact Department of Homeland Security (DHS) or Social Security Administration (SSA) so you can begin to resolve the issue before the employer can take any action against you, including terminating your employment. Employers can only use E-Verify once you have accepted a job offer and completed the I-9 Form. \n  #LI-REMOTE",
        "cleaned_desc": "At Janus, we believe in a world where healthcare functions efficiently. Join us on our mission to improve the lives of administrative workers and fundamentally change the way work is done. Our team is building a world-class process improvement platform to help healthcare providers generate more cash with fewer resources. \n \n  Summary \n  The Lead Machine Learning Engineer collaborates closely with Data Scientists and other engineering teams to design, implement, and maintain systems that operationalize and scale our data and machine learning pipelines. Expertise in machine learning operations and cloud infrastructure will be crucial in ensuring the successful deployment and management of our production machine learning systems. This person will help manage a growing team and provide critical mentorship and guidance to junior team members. If you have a passion for cutting-edge technology, complex problem-solving, and delivering high-quality solutions, this is an exciting opportunity to make a significant impact in our organization. \n  Responsibilities \n \n Collaborate with Data Scientists and product teams to understand user stories and convert them into technical requirements for machine learning solutions. \n Manage, mentor, and provide technical guidance to junior team members, promoting knowledge sharing and professional growth. \n Design, build, and deploy production machine learning systems on AWS cloud infrastructure. \n Develop and maintain robust data and machine learning pipelines, ensuring scalability, reliability, and efficiency. \n Implement and optimize monitoring, logging, and alerting systems to ensure the health and performance of deployed machine learning models. \n Work closely with DevOps and infrastructure teams to ensure seamless integration and deployment of machine learning pipelines. \n Automate and streamline the end-to-end machine learning workflow, including data ingestion, feature engineering, model training, evaluation, and deployment.   Implement best practices for version control, model reproducibility, and model deployment. \n Collaborate with cross-functional teams to identify and address performance bottlenecks, scalability challenges, and data quality issues. \n Continuously evaluate and adopt emerging technologies and tools to improve the efficiency and effectiveness of machine learning operations. \n \n Qualifications \n \n 5+ years of relevant work experience in ML, including designing, building, and deploying production machine learning systems. \n Strong expertise in deploying machine learning models on AWS cloud infrastructure. \n Proficiency in Python and SQL for data manipulation, analysis, and model development. \n Strong knowledge of Linux, Docker, and Kubernetes for containerization and orchestration of machine learning applications. \n Strong knowledge of PySpark, Airflow, and data pipelines; strong knowledge of Sagemaker and machine learning pipelines. \n Passion for learning and staying updated with the latest advancements in machine learning, MLOps, and cloud technologies. \n Excellent communication skills, with the ability to effectively communicate complex technical concepts to both technical and non-technical stakeholders. ",
        "techs": [
            "janus",
            "aws",
            "python",
            "sql",
            "linux",
            "docker",
            "kubernetes",
            "pyspark",
            "airflow",
            "sagemaker"
        ],
        "cleaned_techs": [
            "janus",
            "aws",
            "python",
            "sql",
            "linux",
            "docker",
            "kubernetes",
            "pyspark",
            "airflow",
            "sagemaker"
        ]
    },
    "a7ca5cd17d43153b": {
        "terms": [
            "data science"
        ],
        "salary_min": 142350.0,
        "salary_max": 257325.0,
        "title": "Senior Generative AI Data Scientist",
        "company": "Leidos",
        "desc": "Description   \n Leidos has a career opening for a  Senior Generative AI Data Scientist . \n \n  We are looking for a motivated Sr. Generative AI Data Scientist that wants to work on challenging problems in a variety of domains - including health, defense, intelligence, and energy \u2013 to get results that apply and go beyond the state of the art for measurably better outcomes. We apply our knowledge, capabilities, and experience to develop and deploy Trusted AI \u2013 AI that deserves to be trusted by system owners, end users, and the public \u2013 to be accurate, fair, ethical, reliable, and adaptable. We are looking for a researcher that is expert in NLP and interested in adapting new technologies to significantly transform human workflows, especially using new applications of transformer-based models. \n \n  Working at Leidos would give you the chance to do genuinely important work. But don\u2019t just ask us. Here\u2019s what ChatGPT has to say on the subject: \n  \u201cOh sure, working in AI research for the commercial sector is just the ultimate thrill. Who wouldn't want to spend their days building algorithms to recommend cat videos to stream and optimizing ad targeting to boost click-through rates? I mean, those are the kinds of problems that really make you feel like you're changing the world, right? On the other hand, working in AI research at a company like Leidos, you're stuck with jobs like supporting the next generation of lunar missions and building computer vision algorithms that help keep air travel safe and efficient. I mean, who cares about finding cures for cancer, delivering healthcare to veterans, or helping defend our nation? So boring. But hey, at least we can say we're using our AI skills for a greater good.\u201d \n \n  Primary Responsibilities:  The Senior Generative AI Data Scientist will be customizing and creating various machine learning algorithms to operate over multi-domain data and optimizing the performance of those algorithms on the data. They will develop automation to extract and prepare features from multi-domain datasets. They will employ NLP libraries/toolkits that include transformer models like BERT and ChatGPT, as well as Stanford CoreNLP, Spacy, NLTK, Word2Vec, and Gensim. \n  As a member of the Leidos AI/ML Accelerator, they will be performing research and development, and need hands-on experience training and optimizing generative models. With those models and libraries, they will explore subjects like domain adaptation with supervised and unsupervised approaches. They will also build domain adaptive prototypes to examine the operational capabilities of bi-directional learning. They should be a self-starter while also being part of a team, collaborating and sharing discoveries and seeking feedback. They must be prepared to conduct research, document it, submit their research for publication, and present their research at conferences and other public forums. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Data Science or related field and 15+ years\u2019 experience or master\u2019s degree at 13+ years of experience. \n  Good understanding of machine learning algorithms, tools and platforms \n  Experience in at least three of these Toolkits: NumPy, SciPy, scikit-learn, TensorFlow, Pytorch, Keras, Genism, vow pal wabbit, Stanford CoreNLP, etc. \n  Experience researching and applying large language and generative AI models, including transformers, foundation models, and GPT models. \n  Python proficiency \n  Self-starter with high intellectual curiosity \n  Great communication skills, able to explain language model results to a non-technical audience \n  Proficient in data exploration techniques and tools \n  Must be a US Citizen and be able to obtain TS/SCI with CI Poly security clearance. \n \n \n  Preferred Qualifications: \n \n  Practical understanding of generative models \n  Experience programming machine learning algorithms for GPUs \n  Understanding of Convolutional Neural Nets \n  Working knowledge of Word2Vec and/or NLTK \n  Discernment of when and how to use machine learning regulation \n \n \n  Pay Range:  Pay Range $142,350.00 - $257,325.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote",
        "cleaned_desc": " \n  Primary Responsibilities:  The Senior Generative AI Data Scientist will be customizing and creating various machine learning algorithms to operate over multi-domain data and optimizing the performance of those algorithms on the data. They will develop automation to extract and prepare features from multi-domain datasets. They will employ NLP libraries/toolkits that include transformer models like BERT and ChatGPT, as well as Stanford CoreNLP, Spacy, NLTK, Word2Vec, and Gensim. \n  As a member of the Leidos AI/ML Accelerator, they will be performing research and development, and need hands-on experience training and optimizing generative models. With those models and libraries, they will explore subjects like domain adaptation with supervised and unsupervised approaches. They will also build domain adaptive prototypes to examine the operational capabilities of bi-directional learning. They should be a self-starter while also being part of a team, collaborating and sharing discoveries and seeking feedback. They must be prepared to conduct research, document it, submit their research for publication, and present their research at conferences and other public forums. \n \n  Basic Qualifications: \n \n  Bachelor's degree in Computer Science, Data Science or related field and 15+ years\u2019 experience or master\u2019s degree at 13+ years of experience.    Good understanding of machine learning algorithms, tools and platforms \n  Experience in at least three of these Toolkits: NumPy, SciPy, scikit-learn, TensorFlow, Pytorch, Keras, Genism, vow pal wabbit, Stanford CoreNLP, etc. \n  Experience researching and applying large language and generative AI models, including transformers, foundation models, and GPT models. \n  Python proficiency \n  Self-starter with high intellectual curiosity \n  Great communication skills, able to explain language model results to a non-technical audience \n  Proficient in data exploration techniques and tools ",
        "techs": [
            "bert",
            "chatgpt",
            "stanford corenlp",
            "spacy",
            "nltk",
            "word2vec",
            "gensim",
            "numpy",
            "scipy",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "keras",
            "vow pal wabbit"
        ],
        "cleaned_techs": [
            "bert",
            "chatgpt",
            "stanford corenlp",
            "spacy",
            "nltk",
            "word2vec",
            "gensim",
            "numpy",
            "scipy",
            "scikit-learn",
            "tensorflow",
            "pytorch",
            "keras",
            "vow pal wabbit"
        ]
    },
    "7e26ce1ed9900b67": {
        "terms": [
            "data science"
        ],
        "salary_min": 154530.0,
        "salary_max": -1.0,
        "title": "Product Analytics Lead",
        "company": "SurveyMonkey",
        "desc": "SurveyMonkey  is a global leader in online surveys and forms that empowers people with the insights they need to make decisions with speed and confidence.  Our fast, intuitive feedback management platform connects millions of users worldwide with real-time AI-powered insights that drive meaningful decisions. We provide answers to more than 20 million questions every day so that people and organizations can attract new audiences, delight customers, create advocates, and extend their competitive advantage in the marketplace. Our vision is to raise the bar for human experiences by amplifying individual voices. Learn more at surveymonkey.com. \n \n  What we're looking for \n  We're looking for a Product Analytics Lead who's curious about data and passionate about building customer-centrics products. You will be an integral member of our product led growth strategy, working with teams that span across our Self-Serve and Enterprise products. This is an opportunity for the right person to help evolve our product data and infrastructure in order for our product teams to make data-driven decisions. You will report to the Director of Product Growth & Analytics. \n  What you'll be working on \n \n Use SurveyMonkey's data to create statistical inference and/or modeling techniques to help identify key patterns in user behavior in order for us to inform product and business recommendations \n Create models that will help design the right set of product led growth (PLG) experiments or analyses to evaluate the success of new features, and other products \n Build and optimize virality models to guide our PLG experiments \n Work with the BI and Data Engineering teams to build out our data pipeline and feedback loops \n Own data models, dashboards, and other data artifacts with a responsibility to keep them up-to-date \n Uncover insights that help us understand our customers better \n Build collaborative, influential relationships and processes with cross functional teams such as Business Intelligence (BI), Business Systems, Data Engineering, Finance, and more. \n \n We'd love to hear from people with \n \n 6+ years of work experience in data analytics/science or other relevant fields \n Experience with data querying languages (e.g. SQL) scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) \n Experience with tools such as Amplitude, Tableau, Salesforce, etc. \n Experience in building predictive models \n Comfortable in transforming raw data to build new data sets \n Familiarity with optimizing product funnels, running experiments, building dashboards that share meaningful results and outcomes. \n Have a bias for using the right tools to get the job done with efficiency. You have experience making tradeoffs between speed and accuracy. \n Have worked in a fast-growing start-up \n Have experience at a PLG environment (a plus if you've build virality models) \n Strong communicator, verbally and written, with the ability to break down complex topics into simple solutions and ideas \n \n The base pay provided for this position ranges from $154,530 / year - $261,280 / year depending on the geographic market and assuming a full-time schedule. Actual base pay is based on a number of factors including market location, job-related knowledge, education or training, skills, and experience.    Bonuses and commissions may also be offered as part of the total compensation package, in addition to a competitive benefits package including medical, dental, vision, life, and disability insurance; 401(k) retirement plan; flexible spending & health savings account; paid holidays; paid time off; employee assistance program; and other company benefits. \n  #LI-remote \n \n  Why SurveyMonkey? We're glad you asked \n  SurveyMonkey is a place where the curious come to grow. We're building an inclusive workplace where people of every background can excel no matter their time zone. At SurveyMonkey, we weave employee feedback into everything we do to create forward-looking benefits policies, employee programs, and an award-winning culture, including best workplace for parents, our annual holiday refresh, our annual week of service, and our C.H.O.I.C.E Fund. In addition, we've reimagined the way we work to allow employees to choose what works best for them - working in-person, fully remote, or a hybrid model that combines the two through our Choice Model. \n  Our commitment to an inclusive workplace \n  SurveyMonkey is an equal opportunity employer committed to providing a workplace free from harassment and discrimination. We celebrate the unique differences of our employees because that is what drives curiosity, innovation, and the success of our business. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, gender identity or expression, age, marital status, veteran status, disability status, pregnancy, parental status, genetic information, political affiliation, or any other status protected by the laws or regulations in the locations where we operate. Accommodations are available for applicants with disabilities.",
        "cleaned_desc": " Use SurveyMonkey's data to create statistical inference and/or modeling techniques to help identify key patterns in user behavior in order for us to inform product and business recommendations \n Create models that will help design the right set of product led growth (PLG) experiments or analyses to evaluate the success of new features, and other products \n Build and optimize virality models to guide our PLG experiments \n Work with the BI and Data Engineering teams to build out our data pipeline and feedback loops \n Own data models, dashboards, and other data artifacts with a responsibility to keep them up-to-date \n Uncover insights that help us understand our customers better   Build collaborative, influential relationships and processes with cross functional teams such as Business Intelligence (BI), Business Systems, Data Engineering, Finance, and more. \n \n We'd love to hear from people with \n \n 6+ years of work experience in data analytics/science or other relevant fields \n Experience with data querying languages (e.g. SQL) scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R)   Experience with tools such as Amplitude, Tableau, Salesforce, etc. \n Experience in building predictive models \n Comfortable in transforming raw data to build new data sets \n Familiarity with optimizing product funnels, running experiments, building dashboards that share meaningful results and outcomes. \n Have a bias for using the right tools to get the job done with efficiency. You have experience making tradeoffs between speed and accuracy. \n Have worked in a fast-growing start-up ",
        "techs": [
            "surveymonkey",
            "sql",
            "python",
            "r",
            "amplitude",
            "tableau",
            "salesforce"
        ],
        "cleaned_techs": [
            "surveymonkey",
            "sql",
            "python",
            "r",
            "amplitude",
            "tableau",
            "salesforce"
        ]
    },
    "ab45dd1e6c453c12": {
        "terms": [
            "data science"
        ],
        "salary_min": 88020.63,
        "salary_max": 111453.73,
        "title": "Enablement Manager",
        "company": "Infor",
        "desc": "General information \n       \n \n \n \n \n \n \n        Country \n        \n United States  \n \n \n \n        City \n        \n Remote Location  \n \n \n \n        Department \n        \n Sales  \n \n \n \n        Job ID \n        \n 36530  \n \n \n \n \n \n \n \n \n \n       Description & Requirements\n        \n \n \n \n \n \n \n \n \n \n \n         The Global Enablement and Education team is looking for you to be proficient in Project Management processes and delivery, in order to transfer pm-related knowledge to our employees. As a trainer, your top priority will be training our employees on the Infor Methodology, in-house tools and processes to navigate the internal eco-system and incorporating PM leadership and professional skills as needed. You will effectively use a variety of education methods, deliverables, and activities including, but not limited to instructor-led (classroom and virtual) training. You will help develop content and help us grow the expertise in the company.\n         \n \n \n  A Day in The Life Typically Includes:\n         \n \n \n \n \n \n  Manage the Infor / IIL PMP prep program. \n \n \n \n  Manage PM onboarding and Building Blocks training. \n \n \n \n  Deliver training either virtual or on-site as aligned with our Program Strategy to serve multiple Stakeholders across their Learning Lifecycle related to project management and professional skills. \n \n \n \n  Recognize the learners and their problems to ensure the program is delivered in a cohesive manner. \n \n \n \n  Leverage your understanding of the processes to drive comprehensive, end-to-end learning programs. \n \n \n \n  Collaborate with Education on meaningful assessments and certifications to ensure effective learning has occurred. \n \n \n \n  Partner with the respective Learning Operations to identify gaps in existing programs and make recommendations to the learning programs managers to align with the needs of the business. \n \n \n \n  Basic Qualifications:\n         \n \n \n  Experience in delivering training. \n \n \n \n  Interpersonal communication skills and demonstrable command of the English language, both verbal and written. \n \n \n \n  Positive attitude towards others and ability to adapt your communication style to suit the situation. \n \n \n \n  Very comfortable and confident in delivering training sessions virtually. \n \n \n \n  Preferred Qualifications:\n         \n \n \n  Experience in project management and related disciplines. \n \n \n \n  Proven presentation and people skills enabling you to deliver engaging and effective in-person and virtual training. \n \n \n \n  Location: Candidate may be Remote Based (Alpharetta, GA, Dallas, TX, Saint Paul, MN) or situated in EMEA.\n         \n \n \n \n \n \n \n \n \n         About Infor\n         \n \n \n  Infor is a global leader in business cloud software products for companies in industry specific markets. Infor builds complete industry suites in the cloud and efficiently deploys technology that puts the user experience first, leverages data science, and integrates easily into existing systems. Over 60,000 organizations worldwide rely on Infor to help overcome market disruptions and achieve business-wide digital transformation.\n         \n \n          For more information visit www.infor.com\n         \n \n \n \n \n \n \n \n         Our Values\n         \n \n \n  At Infor, we strive for an environment that is founded on a business philosophy called Principle Based Management\u2122 (PBM\u2122) and eight Guiding Principles: integrity, stewardship & compliance, transformation, principled entrepreneurship, knowledge, humility, respect, self-actualization. Increasing diversity is important to reflect our markets, customers, partners, and communities we serve in now and in the future.\n         \n \n \n  We have a relentless commitment to a culture based on PBM. Informed by the principles that allow a free and open society to flourish, PBM\u2122 prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.\n         \n \n \n  Infor is an Equal Opportunity Employer. We are committed to creating a diverse and inclusive work environment. Infor does not discriminate against candidates or employees because of their sex, race, gender identity, disability, age, sexual orientation, religion, national origin, veteran status, or any other protected status under the law.\n          \n \n \n \n \n         At Infor we value your privacy that\u2019s why we created a policy that you can read here.\n         \n \n \n \n \n \n \n \n \n         This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "67b67048b1a9be34": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Financial Analyst",
        "company": "InCharge",
        "desc": "Description: \n   This position will collaborate with and support business unit managers and executives in creating, measuring, reporting, forecasting, monitoring and automating key performance indicators & processes for the finance & accounting team, and provide variance analyses to help guide management decision-making. \n  Essential Duties and Responsibilities: \n \n  Work with all levels of management to create and provide statistical and financial results and analysis to support weekly and monthly operations, ad-hoc reporting, budgeting, forecasting and modeling through the use of: Tableau; Maestro (our FP&A software); Excel Macros and other appropriate reporting tools. \n  Manage the development and creation of surplus/(deficit) modeling, projections, and executive level presentations. \n  Prepare and analyze board level reports. \n  Analyze and streamline current finance & accounting data sets, reports, trends and processes to determine and create new, meaningful and automated reports/analysis to help management make business decisions. \n  Any other duties as assigned by management. \n  Requirements: \n   Required Experience: \n \n  1-3 years of experience in a financial analyst or business analyst role. \n  Proficient knowledge in accounting: namely, Profit & Loss, Balance Sheet and Cash Flow analytics and debits and credits. \n  1-2 years developing, maintaining, modifying, automating and monitoring key performance measurements and processes for reporting to management. \n  Advanced knowledge of Business Intelligence tools (namely Tableau) and Microsoft Office, particularly Excel Macros. \n  An emphasis on accuracy, quality, timeliness, and productivity. \n  Skills and abilities in analytical and strategic thinking, economic valuation, presentation, process automations and the ability to communicate effectively with all levels of the organization. \n  Self-motivated, organized, and able to balance multiple priorities to meet critical and sometimes conflicting deadlines. \n  Ability to maintain confidentiality and exercise discretion with information acquired while performing job duties. \n  Ability to work with all levels of management including taking complex analysis and tailoring the summarized message appropriately based on the audience. Preferred: \n  Ability to work with programming languages, primarily Python and SQL. Advanced knowledge in call center systems and databases Experience in a call center/ customer service, financial services, and/or non-profit industry. \n  Required: BA or BS degree with a concentration in accounting/finance, statistics, economics, mathematics, data science, information systems or business administration. Preferred: MBA or Masters Degree in Business, Accounting Finance, Data Science or related field \n \n  Job Type: Full-time",
        "cleaned_desc": "  Ability to work with all levels of management including taking complex analysis and tailoring the summarized message appropriately based on the audience. Preferred: \n  Ability to work with programming languages, primarily Python and SQL. Advanced knowledge in call center systems and databases Experience in a call center/ customer service, financial services, and/or non-profit industry. \n  Required: BA or BS degree with a concentration in accounting/finance, statistics, economics, mathematics, data science, information systems or business administration. Preferred: MBA or Masters Degree in Business, Accounting Finance, Data Science or related field \n ",
        "techs": [
            "python",
            "sql",
            "call center systems",
            "databases"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "call center systems",
            "databases"
        ]
    },
    "27873c667208544e": {
        "terms": [
            "data science"
        ],
        "salary_min": 133600.0,
        "salary_max": 256800.0,
        "title": "Principal Product Manager, Manager",
        "company": "Microsoft",
        "desc": "Microsoft 365 (M365 \n ) is the fastest growing cloud services business in Microsoft. M365 brings together cloud versions of our most trusted communications and collaboration products like Exchange, SharePoint, OneDrive and Skype with the desktop suite of Office products in an always up-to-date integrated service offering. Since its launch, the service has made it easier for millions of information workers across the world in small, medium, and large enterprises to use the best of Microsoft\u2019s business productivity solutions via the cloud. The service now extends the same capability to consumer communication and collaboration products. \n \n \n \n  Are you passionate about cutting edge cloud technologies? Are you someone who is deeply interested in sustainability? Do you get excited about making our cloud services work more efficiently and help save the planet? Are you passionate about building resilient, performant services. Are you an experienced product manager leader looking for an opportunity to have outsized impact across multiple products? \n \n \n \n \n \n  If yes, the \n   M365 Core Platform team  is just the place for you. We are looking for an experienced \n   Principal Product Manager, Manager  who would drive next generation designs to build efficient, performant, resilient services. This position will bring in a balanced set of incubation, design, growth engineering, data informed decision making, customer focus, partner engagement, and execution skills. The position requires you to work with product leaders and architects across the company, has executive exposure, and has and has unlimited opportunities for growth and impact. An ideal candidate should be able to demonstrate the following:\n  \n \n \n  Collaborate \u2013 Build and grow the brain trust of experts on performance, efficiency, sustainability, resilience across the company. Strive to understand the motivations and goals of the teams we\u2019re working with and work towards a better solution together.\n  \n \n \n \n \n  Innovate \u2013 Care deeply about Cloud Technology, sustainability, costs, efficiencies of the critical 5-9s service we are running. Be excited about making major changes to the service to improve Quality of Service (QoS). Drive technology innovations and optimizations for achieving higher utilization and scale.\n  \n \n \n  Guide \u2013 Define the business goals for the team then create and execute on a plan to meet those goals. Build a vision for changing the underlying technology of the service and guide the team through landing it.\n  \n \n \n \n \n  Coach \u2013 Mentor Individial Contributors on the team to help them to do their best work. Model being an excellent product manager.\n  \n \n \n  Location:  By applying to this U.S. based position, while remote work is possible, relocation does not apply/is not provided for the role.\n  \n  Responsibilities \n \n   You will be the Principal Product Manager, Manager that helps drive M365\u2019s investments in areas of Cloud Computing, Efficiency, Performance & Resilience \n  \n \n Help set product & technical vision and strategy for systems to help developers build efficient, performant & resilient services. \n  Translate business requirements into a strategy for systems solutions \n  Set up durable partnerships with other products, Finance and engineering groups across Office and Azure to drive execution and demonstrate end to end ownership of complex, cross group projects to successful completion \n  Influence partner teams, get alignment on technology direction and the steps to achieve them \n  Foster a healthy and inclusive team environment and help the IC\u2019s on the team grow \n \n \n \n  Ideal candidate will\n  \n \n  Have passion for Quality of Service (QoS resilience, performance & efficiency. \n  Be able to build vision and roadmap for complex areas \n  Establish excellent network of partnerships with technical architects across the company \n  Be able to learn quickly with a growth mindset \n  Have experience as a Product manager \n \n  Qualifications \n \n \n  Required/Minimum Qualifications: \n \n \n  Bachelor's Degree AND 8+ years experience in product/service/project/program management or software development \n \n \n   o OR equivalent experience.\n  \n \n \n \n  4+ years people management experience. \n \n \n  Preferred Qualifications: \n \n \n  Bachelor's Degree AND 10+ years experience in product/service/project/program management or software development \n \n \n   o OR equivalent experience.\n  \n \n  6+ years people management experience. \n  10+ years\u2019 experience and shipping products in a tech company \n  Demonstrated problem-solving skills with technical proficiency and strategic thinking \n  Demonstrated written and verbal communication skills \n  Demonstrated ability to drive for results and influence for impact \n  Demonstrated ability to navigate ambiguity and adapt quickly to new technology and processes \n  Knowledge of Cloud service fabric, including hardware \n  Knowledge on Cloud COGS (Cost Of Goods Sold), efficiency  \n Familiarity with Kubernetes \n  Familiarity with Data Science/Machine Learning a plus \n \n \n   Product Management M5 - The typical base pay range for this role across the U.S. is USD $133,600 - $256,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $173,200 - $282,200 per year.\n   \n  Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay\n  \n \n  Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "1c3f415782c14bd1": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 110000.0,
        "salary_max": 120000.0,
        "title": "General AI Prompt Engineer",
        "company": "EXL Services",
        "desc": "Full Stack Developer/Solution Architect Job Description \n \n \n Company Overview And Culture EXL (NASDAQ:  EXLS) is a global analytics and digital solutions company that partners with clients to improve business outcomes and unlock growth. Bringing together deep domain expertise with robust data, powerful analytics, cloud, and AI, we create agile, scalable solutions and execute complex operations for the world\u2019s leading corporations in industries including insurance, healthcare, banking and financial services, media, and retail, among others. Focused on creating value from data for driving faster decision-making and transforming operating models, EXL was founded on the core values of innovation, collaboration, excellence, integrity and respect. Headquartered in New York, our team is over 40,000 strong, with more than 50 offices spanning six continents. For information, visit www.exlservice.com . For the past 20 years, EXL has worked as a strategic partner and won awards in its approach to helping its clients solve business challenges such as digital transformation, improving customer experience, streamlining business operations, taking products to market faster, improving corporate finance, building models to become compliant more quickly with new regulations, turning volumes of data into business opportunities, creating new channels for growth and better adapting to change. The business operates within four business units: Insurance, Health, Analytics, and Emerging businesses. EXL is hiring a Full Stack Developer and Solution Architect for its IT solutioning business. This position is fulltime remote for US location. \n \n  Responsibilities \n \n  \u2022 \n \n  Hands on experience on multi cloud like GCP, Azure. \n \n \n \n Experience in PyTorch, Python, Keras etc. Prompt engineering, fine tuning of Deep neural networks such as GenAI models and data vectorization \n Staying abreast of developments in web applications and programming languages. \n  Ideal Personal Profile \n \n \n \n Bachelor\u2019s degree in Engineering/Computer Science/Data Science or related quantitative field \n 2+ years of relevant experience \n Cloud experience on Azure/GCP/AWS \n GenAI Prompt Engineering \n Data Science and Machine learning experience \n Familiarity with database technology such as MySQL, Oracle, and MongoDB. \n Excellent verbal communication skills. \n Good problem-solving skills. \n  \u2022 \n \n  Experience in Agile development \n \n  \u2022 \n \n  Healthcare domain knowledge is plus. What we offer \n \n \n \n EXL Health offers an exciting, fast-paced, and innovative environment, which brings together a group of sharp and entrepreneurial professionals who are eager to influence business decisions. From your very first day, you get an opportunity to work closely with highly experienced, world-class Healthcare consultants. \n You can expect to learn many aspects of businesses that our clients engage in. You will also learn effective teamwork and time-management skills - key aspects for personal and professional growth \n The sky is the limit for our team members. The unique experiences gathered at EXL Health sets the stage for further growth and development in our company and beyond. \n Competitive benefit package including medical, dental, vision and 401(k) plans",
        "cleaned_desc": " \n  Hands on experience on multi cloud like GCP, Azure. \n \n \n \n Experience in PyTorch, Python, Keras etc. Prompt engineering, fine tuning of Deep neural networks such as GenAI models and data vectorization \n Staying abreast of developments in web applications and programming languages. \n  Ideal Personal Profile   \n \n \n Bachelor\u2019s degree in Engineering/Computer Science/Data Science or related quantitative field \n 2+ years of relevant experience \n Cloud experience on Azure/GCP/AWS \n GenAI Prompt Engineering \n Data Science and Machine learning experience   Familiarity with database technology such as MySQL, Oracle, and MongoDB. \n Excellent verbal communication skills. \n Good problem-solving skills. \n  \u2022 \n \n  Experience in Agile development \n \n  \u2022 ",
        "techs": [
            "gcp",
            "azure",
            "pytorch",
            "python",
            "keras",
            "genai",
            "mysql",
            "oracle",
            "mongodb",
            "agile development"
        ],
        "cleaned_techs": [
            "gcp",
            "azure",
            "pytorch",
            "python",
            "keras",
            "genai",
            "mysql",
            "oracle",
            "mongodb",
            "agile development"
        ]
    },
    "4dd2a18866104960": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "4d52d708678d521b": {
        "terms": [
            "data science"
        ],
        "salary_min": 91590.88,
        "salary_max": 115974.46,
        "title": "Statistician 3",
        "company": "Yale University",
        "desc": "Statistician 3 \n \n \n \n    Internal Medicine - Cardiology \n    \n \n \n \n    84383BR\n    \n \n \n University Job Title \n \n    Statistician 3\n    \n \n \n Bargaining Unit \n \n    None - Not included in the union (Yale Union Group) \n    \n \n \n Time Type \n \n    Full time \n    \n \n \n Duration Type \n \n    Regular \n    \n \n \n Compensation Grade \n \n    Administration & Operations \n    \n \n \n Compensation Grade Profile \n \n    Senior Manager; Senior Program Leader (27) \n    \n \n \n Wage Ranges \n \n    Click here to see our Wage Ranges \n    \n \n \n Searchable Job Family \n \n    Research/Support \n    \n \n \n Total # of hours to be worked: \n \n    37.5\n    \n \n \n Work Week \n \n    Standard (M-F equal number of hours per day) \n    \n \n \n Work Location \n \n    Medical School Campus \n    \n \n \n Worksite Address \n \n    1 Church Street\n      New Haven, CT 06510 \n    \n \n \n Work Model \n \n    Remote\n    \n \n \n Position Focus: \n \n    The Yale/Yale New Haven Hospital Center for Outcomes Research and Evaluation (CORE) is a leading national outcomes research center dedicated to transforming healthcare for the betterment of people and society by leveraging data, analytics, and technology. We have assembled a talented, multidisciplinary group who are committed to developing solutions to the practical needs of medicine and healthcare. Our organization combines the highest academic ideals with a pragmatic approach that emphasizes the production of useful knowledge. We are distinguished by our creativity, dedication, experience, and skills \u2013 and our commitment to having our work make a tangible difference to patients, the public, and society. For additional information on CORE, please visit our website: www.medicine.yale.edu/core.\n     \n  CORE is seeking a Statistician III who will work under the direction of the Senior Director of Data Management and Analytics to develop analytic plans and lead the statistical analyses in support of quality of care and outcomes research studies. They will provide analytic expertise and a wide array of statistical methods to investigate, analyze, and evaluate complex statistical and programming problems. Additionally, they will provide statistical oversight and mentorship to other data analysts.\n     \n  The Statistician III will serve as a lead data analyst and work under the Senior Director of Data Management and Analytics to develop analytic plans and lead the statistical analyses in support of quality of care and outcomes research studies. They will provide analytic expertise and a wide array of statistical methods to investigate, analyze, and evaluate complex statistical and programming problems. Additionally, they will provide statistical oversight and mentorship to other data analysts.\n    \n \n \n Essential Duties \n \n    1. Work with the leadership of Data Management and Analytics to lead other data and analytics specialists in providing data and analytics support to various CORE projects, including data acquisition, data integration, data curation, data analysis, results summarization and interpretation, technical write up, and other relevant activities. 2. Participate in recruiting, developing, and managing analytics talents to build and grow a team of talented data specialists. Foster a success-oriented environment of accountability and a culture of diversity, respect, and inclusion. 3. Provide leadership in developing systematic and efficient approaches to projects to ensure successful outcomes. Champion high standards and best practice. 4. Provide directions on study design, analysis plan, timeline and reporting of information on assigned projects to ensure successful completion of the projects according to CORE business plan. 5. Provide guidance to other analysts on design and development of analytic approaches tailored to the unique needs of various CORE projects to ensure success. Provide effective leadership and project management to ensure high quality and timely completion of projects. 6. Identify research and analytics initiatives to support CORE\u2019s strategic development, proactively adopting new and better analytical approaches to address problems at hand. 7. Provide statistical training and mentorship to CORE statisticians/analysts and other CORE members. 8. Prepare analytic deliverables, including presentations, reports, research papers, etc. 9. Interface with both internal and external collaborators to achieve CORE project objectives. 10. Participate in preparing and reviewing research grant and/or contract proposals. 11. Work with the leadership of Data Management and Analytics to build and maintain an efficient, reliable, and high-capacity data management and computing infrastructure.\n    \n \n \n Required Education and Experience \n \n    Master\u2019s degree or higher in Biostatistics, Statistics, or relevant field. At least 5 years of experience, or an equivalent combination of education and experience. Proficiency in data management and analysis processes and documentation, familiarity with a wide variety of health care data, expertise with multiple statistical analysis techniques and software packages, demonstrated ability to lead projects and analyses of moderate to high complexity, and learn and apply new technologies, techniques and strategies.\n    \n \n \n Required Skill/Ability 1: \n \n    Expertise in statistical methods such as causal inference, program evaluation, experimental design, Bayesian data analysis, hierarchical/multilevel modeling, predictive modeling, and machine learning.\n    \n \n \n Required Skill/Ability 2: \n \n    Advanced knowledge and related work experience utilizing SAS, R, or Python in research investigations and biostatistical data analysis. Proficiency in fitting generalized linear models and mixed effects models.\n    \n \n \n Required Skill/Ability 3: \n \n    Ability to lead, supervise, implement, and monitor statistical projects and analyses. Ability to summarize and interpret complex data analyses. Ability to communicate complex analytical concepts and results to audiences with varying degrees of technical understanding in written, oral and visual forms. Ability to maintain high degree of confidentiality and integrity.\n    \n \n \n Required Skill/Ability 4: \n \n    Must to work collaboratively and effectively with colleagues and others to create a results driven, team-oriented environment. Must be able to solve and troubleshoot problems, handle conflict, and anticipate issues/concerns.\n    \n \n \n Required Skill/Ability 5: \n \n    Strong decision-making skills with the ability to work effectively under pressure. Ability to evaluate problems or issues from multiple perspectives and develop scientifically sound practical solutions.\n    \n \n \n Preferred Education, Experience and Skills: \n \n    PhD degree in Biostatistics or Statistics preferred. Publishing history as co-author and primary data analyst. Experience working with administrative claims data, with specific experience with CMS claims databases. Demonstrated experience leading a team in a matrixed research and or contract organization environment.\n    \n \n \n Drug Screen \n \n    No\n    \n \n \n Health Screening \n \n    No\n    \n \n \n Background Check Requirements \n \n    All candidates for employment will be subject to pre-employment background screening for this position, which may include motor vehicle, DOT certification, drug testing and credit checks based on the position description and job requirements. All offers are contingent upon the successful completion of the background check. For additional information on the background check requirements and process visit \"Learn about background checks\" under the Applicant Support Resources section of Careers on the It's Your Yale website.\n    \n \n \n COVID-19 Vaccine Requirement \n \n    The University maintains policies pertaining to COVID-19. All faculty, staff, students, and trainees are required to comply with these policies, which may be found here:\n      https://covid19.yale.edu/health-guidelines\n     \n \n \n \n \n Posting Disclaimer \n \n    The intent of this job description is to provide a representative summary of the essential functions that will be required of the position and should not be construed as a declaration of specific duties and responsibilities of the particular position. Employees will be assigned specific job-related duties through their hiring departments.\n    \n \n \n EEO Statement: \n \n University policy is committed to affirmative action under law in employment of women, minority group members, individuals with disabilities, and protected veterans. Additionally, in accordance with Yale\u2019s Policy Against Discrimination and Harassment, and as delineated by federal and Connecticut law, Yale does not discriminate in admissions, educational programs, or employment against any individual on account of that individual\u2019s sex, sexual orientation, gender identity or expression, race, color, national or ethnic origin, religion, age, disability, status as a special disabled veteran, veteran of the Vietnam era or other covered veteran. \n Inquiries concerning Yale\u2019s Policy Against Discrimination and Harassment may be referred to the Office of Institutional Equity and Accessibility (OIEA). \n \n \n \n Note \n \n    Yale University is a tobacco-free campus",
        "cleaned_desc": "    \n \n \n Worksite Address \n \n    1 Church Street\n      New Haven, CT 06510 \n    \n \n \n Work Model \n \n    Remote\n    \n \n \n Position Focus: \n \n    The Yale/Yale New Haven Hospital Center for Outcomes Research and Evaluation (CORE) is a leading national outcomes research center dedicated to transforming healthcare for the betterment of people and society by leveraging data, analytics, and technology. We have assembled a talented, multidisciplinary group who are committed to developing solutions to the practical needs of medicine and healthcare. Our organization combines the highest academic ideals with a pragmatic approach that emphasizes the production of useful knowledge. We are distinguished by our creativity, dedication, experience, and skills \u2013 and our commitment to having our work make a tangible difference to patients, the public, and society. For additional information on CORE, please visit our website: www.medicine.yale.edu/core.\n     \n  CORE is seeking a Statistician III who will work under the direction of the Senior Director of Data Management and Analytics to develop analytic plans and lead the statistical analyses in support of quality of care and outcomes research studies. They will provide analytic expertise and a wide array of statistical methods to investigate, analyze, and evaluate complex statistical and programming problems. Additionally, they will provide statistical oversight and mentorship to other data analysts.\n     \n  The Statistician III will serve as a lead data analyst and work under the Senior Director of Data Management and Analytics to develop analytic plans and lead the statistical analyses in support of quality of care and outcomes research studies. They will provide analytic expertise and a wide array of statistical methods to investigate, analyze, and evaluate complex statistical and programming problems. Additionally, they will provide statistical oversight and mentorship to other data analysts.\n    \n \n \n Essential Duties \n \n    1. Work with the leadership of Data Management and Analytics to lead other data and analytics specialists in providing data and analytics support to various CORE projects, including data acquisition, data integration, data curation, data analysis, results summarization and interpretation, technical write up, and other relevant activities. 2. Participate in recruiting, developing, and managing analytics talents to build and grow a team of talented data specialists. Foster a success-oriented environment of accountability and a culture of diversity, respect, and inclusion. 3. Provide leadership in developing systematic and efficient approaches to projects to ensure successful outcomes. Champion high standards and best practice. 4. Provide directions on study design, analysis plan, timeline and reporting of information on assigned projects to ensure successful completion of the projects according to CORE business plan. 5. Provide guidance to other analysts on design and development of analytic approaches tailored to the unique needs of various CORE projects to ensure success. Provide effective leadership and project management to ensure high quality and timely completion of projects. 6. Identify research and analytics initiatives to support CORE\u2019s strategic development, proactively adopting new and better analytical approaches to address problems at hand. 7. Provide statistical training and mentorship to CORE statisticians/analysts and other CORE members. 8. Prepare analytic deliverables, including presentations, reports, research papers, etc. 9. Interface with both internal and external collaborators to achieve CORE project objectives. 10. Participate in preparing and reviewing research grant and/or contract proposals. 11. Work with the leadership of Data Management and Analytics to build and maintain an efficient, reliable, and high-capacity data management and computing infrastructure.\n    \n \n \n Required Education and Experience \n \n    Master\u2019s degree or higher in Biostatistics, Statistics, or relevant field. At least 5 years of experience, or an equivalent combination of education and experience. Proficiency in data management and analysis processes and documentation, familiarity with a wide variety of health care data, expertise with multiple statistical analysis techniques and software packages, demonstrated ability to lead projects and analyses of moderate to high complexity, and learn and apply new technologies, techniques and strategies.\n    \n \n   Required Skill/Ability 1: \n \n    Expertise in statistical methods such as causal inference, program evaluation, experimental design, Bayesian data analysis, hierarchical/multilevel modeling, predictive modeling, and machine learning.\n    \n \n \n Required Skill/Ability 2: \n \n    Advanced knowledge and related work experience utilizing SAS, R, or Python in research investigations and biostatistical data analysis. Proficiency in fitting generalized linear models and mixed effects models.\n    \n \n \n Required Skill/Ability 3: \n \n    Ability to lead, supervise, implement, and monitor statistical projects and analyses. Ability to summarize and interpret complex data analyses. Ability to communicate complex analytical concepts and results to audiences with varying degrees of technical understanding in written, oral and visual forms. Ability to maintain high degree of confidentiality and integrity.\n    \n \n \n Required Skill/Ability 4: \n \n    Must to work collaboratively and effectively with colleagues and others to create a results driven, team-oriented environment. Must be able to solve and troubleshoot problems, handle conflict, and anticipate issues/concerns.\n    \n \n \n Required Skill/Ability 5: \n \n    Strong decision-making skills with the ability to work effectively under pressure. Ability to evaluate problems or issues from multiple perspectives and develop scientifically sound practical solutions.\n    \n \n \n Preferred Education, Experience and Skills: \n \n    PhD degree in Biostatistics or Statistics preferred. Publishing history as co-author and primary data analyst. Experience working with administrative claims data, with specific experience with CMS claims databases. Demonstrated experience leading a team in a matrixed research and or contract organization environment.\n    \n \n \n Drug Screen \n ",
        "techs": [
            "sas",
            "r",
            "python"
        ],
        "cleaned_techs": [
            "sas",
            "r",
            "python"
        ]
    },
    "2f7d4338c40278a8": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 140000.0,
        "title": "Qlik Developer",
        "company": "Gov Solutions Group",
        "desc": "Scope of Responsibilities: \n \n  Manage all tasks related to Qlik Sense, including development, maintenance, and troubleshooting \n  Collaborate with cross-functional teams to implement and optimize Qlik Sense solutions  \n Stay up-to-date with Qlik Sense best practices and industry trends \n  Develop algorithms for data analysis \n  Write scripts to process and manipulate data efficiently \n  Operationalize predictive analytics model results to visually forecast future trends \n  Maximize automation to streamline data processing workflows \n  Collaborate with machine learning engineers & data scientists to extract insights from data \n  Combine various tools and frameworks to integrate and analyze diverse data sources \n  Transform disparate data points into objective answers \n  Perform data modeling and data visualization tasks \n  Adapt to fast-paced operational requirements \n \n \n  Required Qualifications: \n \n  Ability to obtain DoD Security clearance \n  6+ years of technical experience with Business Intelligence and Data Analytics solutions  \n 2+ years of experience implementing Qlik solutions  \n Strong data analysis skills \n  Strong collaboration skills with the ability to work with integrated teams \n  Experience with data lakes, data warehouses, or data lake houses \n  Experience with cloud services, including AWS, Azure \n  Experience with Agile development \n \n  Desired Qualifications: \n \n  Experience with data migrations and ETL process \n  Experience with Data Bricks, Tableau, Power BI, and Power Apps \n  Experience with enterprise DataOps, DevSecOps and MLOps processes to operationalize and monitor data science models \n  Experience with DoD/DON ADVANA/Jupiter platform \n \n \n  Special Requirements:  Must be a US Citizen and have the ability to possess an active DoD secret clearance at the start date. \n \n  Salary:  $100,000-$140,000. Actual compensation offer to candidate may vary from posted hiring range based upon geographic location, work experience, education, and/or skill level. The pay ratio between base pay and target incentive (if applicable) will be finalized at offer. \n \n  Why You\u2019ll Want to Work at GovSG:  \n \n Competitive pay and benefits, including PTO and company matched 401k  \n Development opportunities through comprehensive training suite  \n Ability to make an impact supporting the warfighter  Opportunities to engage with the community through volunteering \n  \n  The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.  \n GovSG is an Equal Opportunity Employer, including Minorities/Females/Veterans/Disabled. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.  \n GovSG participates in E-Verify. \n   \n   \n ZnhVbBCKUt",
        "cleaned_desc": "Scope of Responsibilities: \n \n  Manage all tasks related to Qlik Sense, including development, maintenance, and troubleshooting \n  Collaborate with cross-functional teams to implement and optimize Qlik Sense solutions  \n Stay up-to-date with Qlik Sense best practices and industry trends \n  Develop algorithms for data analysis \n  Write scripts to process and manipulate data efficiently \n  Operationalize predictive analytics model results to visually forecast future trends \n  Maximize automation to streamline data processing workflows \n  Collaborate with machine learning engineers & data scientists to extract insights from data    Combine various tools and frameworks to integrate and analyze diverse data sources \n  Transform disparate data points into objective answers \n  Perform data modeling and data visualization tasks \n  Adapt to fast-paced operational requirements \n \n \n  Required Qualifications: \n \n  Ability to obtain DoD Security clearance \n  6+ years of technical experience with Business Intelligence and Data Analytics solutions    2+ years of experience implementing Qlik solutions  \n Strong data analysis skills \n  Strong collaboration skills with the ability to work with integrated teams \n  Experience with data lakes, data warehouses, or data lake houses \n  Experience with cloud services, including AWS, Azure \n  Experience with Agile development \n \n  Desired Qualifications: \n \n  Experience with data migrations and ETL process ",
        "techs": [
            "qlik sense",
            "algorithms",
            "scripts",
            "predictive analytics",
            "automation",
            "machine learning",
            "data modeling",
            "data visualization",
            "dod security clearance",
            "business intelligence",
            "data analytics",
            "data lakes",
            "data warehouses",
            "data lake houses",
            "cloud services",
            "aws",
            "azure",
            "agile development",
            "data migrations",
            "etl process"
        ],
        "cleaned_techs": [
            "qlik sense",
            "algorithms",
            "scripts",
            "predictive analytics",
            "automation",
            "data visualization",
            "business intelligence",
            "data analytics",
            "data lakes",
            "data warehouses",
            "data lake houses",
            "cloud services",
            "aws",
            "azure",
            "agile development",
            "data migrations",
            "etl process"
        ]
    },
    "8fbf27ec0641d3a5": {
        "terms": [
            "data science"
        ],
        "salary_min": 60000.0,
        "salary_max": 80000.0,
        "title": "Scientific Programs Manager (Remote)",
        "company": "Susan G. Komen",
        "desc": "ABOUT SUSAN G. KOMEN \n  Susan G. Komen brings a 100% virtual working environment, and you can work anywhere within the U.S. We are a force united by a promise to end breast cancer forever. For over 40 years, we've led the way funding groundbreaking research, community health initiatives and advocacy programs in local communities across the U.S. Susan G. Komen is the ONLY organization that addresses breast cancer on multiple fronts such as research, community health, global outreach, and public policy initiatives to make the biggest impact against this disease. \n  Komen strives to have a culture of passionate, growth-minded professionals who thrive in a team environment, and work collaboratively to inspire greatness in others! We take an ongoing approach to ensure open communication from all levels throughout the organization. It\u2019s encouraged to give and receive feedback to ensure two-way accountability with a focus on continual improvement both personally and professionally! \n \n  What you will be doing in the role of Scientific Programs Manager \n  The Scientific Strategy and Programs (SSP) team works at the intersection of science and patient advocacy, translating scientific strategy and patient insights into programs that will accelerate research discoveries to save lives. The Scientific Programs Manager works closely with the Director, along with Komen\u2019s scientific advisors, patient advocates and other internal and external stakeholders to: \n \n  advance strategies for Komen\u2019s investment in innovative and impactful research and scientific programs \n  develop and implement programs and initiatives in priority areas, including clinical trials, metastatic and aggressive breast cancers, breast cancer disparities, and big data \n  position Komen as a thought leader in breast cancer research. \n \n  What you will bring to the table \n  The Scientific Programs Manager will serve as a subject matter expert in breast cancer biology/oncology to provide guidance and thought leadership internally as well as to partners, donors, and other external stakeholders. \n  Additionally, the Scientific Programs Manager will: \n \n  Develop, implement, and manage scientific programs, initiatives, and events to advance priority areas \n  Clinical Trials: metastatic and aggressive breast cancers, breast cancer disparities and big data. These may include programs co-created with strategic partners and cross-disciplinary projects and initiatives (e.g., science reviews, think tanks) to convene key opinion leaders, explore critical issues in breast health/breast cancer, and/or develop evidence-based strategies for Komen involvement. \n  Build strategic relationships and drive collaborative activities with industry, other non-profit organizations, coalitions and partners to advance areas of common interest. \n  Obtain and curate knowledge of other organizations\u2019 activities relevant to breast cancer, and community perspectives. \n  Identify emerging issues/trends and potential opportunities for collaboration sponsorship, position statements and/or policy development. \n  Build strong relationships with Komen\u2019s scientific advisory bodies (e.g., Scientific Advisory Board; Komen Scholars). Manage their operations and facilitate their participation in research/mission programs, development events, media opportunities and other activities to advance Komen\u2019s mission and demonstrate Komen\u2019s thought leadership, as assigned. \n  Manage contracts, grants and sponsorships related to assigned projects and programs. \n  Apply strong program management skills to develop project plans, ensure timelines are being adhered to and prioritize projects accordingly across the multiple programs. \n  Monitor and manage project budgets, liaising with accounting and other departments as needed. \n  Work collaboratively with other teams, including Mission, Development, Evaluation & Outcomes, Communications, Marketing, IT and others to define and deliver on specific programmatic needs. This includes coordinating ongoing communications internally and externally, as appropriate, to ensure everyone is aware of progress. \n  Leverage relationships and expertise to support fundraising and enhance marketing and communications efforts. \n  All other duties as assigned. \n \n  We know you will have \n \n  Demonstrated experience (>3 years) in non-profit program management. \n  Demonstrated expertise in cancer research, health disparities, public health, health data and similar. \n  Knowledge of breast cancer, current literature, and advances in breast cancer research, with an understanding of agencies/regulatory bodies that regulate drug development and/or health care. \n  Ability to communicate complex ideas in a clear and straightforward manner, for both technical and general audiences. Excellent writing skills, particularly for general audiences. Active listening skills and proactive communicator. \n  Self-starter willing and able to take responsibility and ownership for producing timely and high-quality work with limited supervision. Ability to deconstruct complex problems and develop actionable plans. \n  A team-oriented attitude, strong cross-functional collaboration skills and proven ability to advance and drive tactics in a matrixed, global organization. \n  Strong organizational and project management skills; detail oriented. Proven ability to manage multiple projects simultaneously. \n  High degree of professionalism, maturity, executive presence, business understanding and confidentiality. \n  Work Experience 2 \u2013 5 years. \n  Doctoral Degree: Life Science, Oncology, Health Disparities, Public Health, Data Science/Bioinformatics. \n \n  Preferred experience includes: \n \n  Expertise in breast cancer research, breast cancer oncology, breast cancer health disparities, and/or data science/bioinformatics (oncology) with publications history. \n  Demonstrated experience with a health-related nonprofit organization preferred. \n  Understanding of best practices used in research funding/grant-making operations a plus. \n  Intermediate level of computer/technical skills, including proficiency with Microsoft Office Suite required. \n  Proficiency with collaboration tools such as Asana preferred. \n  Proficiency in another language, particularly Spanish, a plus. \n  Occasional travel up to 5%. \n \n  So, what's in it for you? \n  Komen believes in the importance of taking care of our employees so that in turn they can be committed to supporting our critical mission to support those impacted by breast cancer and to help find cures. This is what Komen provides away from the computer: \n \n  Competitive salary 60k-80k; exact compensation ranges are based on various factors including but not limited to the labor market, job level, internal equity, and budget. Offers given will take into consideration candidate's skills, education, experience, geographic location and other necessary credentials. \n  Health, dental, vision and a retirement plan with a 6% employer match \n  Generous Paid Time Off Plan \n  Flexible work arrangement in a fully remote working environment \n  Bi-weekly work from home stipend \n  Parental leave \n  Tuition Reimbursement \n  A culture of learning and development \n  And so much more! \n \n  Komen provides a remote and/or home-based working environment for all active employees. Komen defines remote as the ability to work from any physical location within the U.S. where an employee can perform specified work duties without disruption or distraction. Komen defines home-based roles as positions that are required to reside in a specific market. Work schedules for both remote and home based are determined by the organizational needs of each department. \n  Susan G. Komen is fair and equal in all its employment practices for persons without regard to age, race, color, religion, gender, national origin, disability, veteran status, or sexual orientation. Additionally, we embrace Diverse Teams & Perspective, and we find strength in the diversity of cultural backgrounds, ideas, and experiences. \n  SORRY NO AGENCIES \n  #LI-REMOTE",
        "cleaned_desc": "  All other duties as assigned. \n \n  We know you will have \n \n  Demonstrated experience (>3 years) in non-profit program management. \n  Demonstrated expertise in cancer research, health disparities, public health, health data and similar. \n  Knowledge of breast cancer, current literature, and advances in breast cancer research, with an understanding of agencies/regulatory bodies that regulate drug development and/or health care. \n  Ability to communicate complex ideas in a clear and straightforward manner, for both technical and general audiences. Excellent writing skills, particularly for general audiences. Active listening skills and proactive communicator. \n  Self-starter willing and able to take responsibility and ownership for producing timely and high-quality work with limited supervision. Ability to deconstruct complex problems and develop actionable plans. \n  A team-oriented attitude, strong cross-functional collaboration skills and proven ability to advance and drive tactics in a matrixed, global organization. \n  Strong organizational and project management skills; detail oriented. Proven ability to manage multiple projects simultaneously. \n  High degree of professionalism, maturity, executive presence, business understanding and confidentiality. \n  Work Experience 2 \u2013 5 years. ",
        "techs": [
            "non-profit program management",
            "cancer research",
            "health disparities",
            "public health",
            "health data",
            "breast cancer",
            "current literature",
            "advances in breast cancer research",
            "agencies/regulatory bodies",
            "drug development",
            "health care",
            "communication",
            "writing skills",
            "active listening skills",
            "self-starter",
            "responsibility",
            "ownership",
            "complex problem deconstruction",
            "actionable plans",
            "team-oriented attitude",
            "cross-functional collaboration skills",
            "project management skills",
            "organizational skills",
            "detail oriented",
            "professionalism",
            "maturity",
            "executive presence",
            "business understanding",
            "confidentiality."
        ],
        "cleaned_techs": [
            "non-profit program management",
            "cancer research",
            "health disparities",
            "public health",
            "health data",
            "breast cancer",
            "current literature",
            "advances in breast cancer research",
            "drug development",
            "health care",
            "communication",
            "self-starter",
            "responsibility",
            "ownership",
            "complex problem deconstruction",
            "actionable plans",
            "team-oriented attitude",
            "detail oriented",
            "professionalism",
            "maturity",
            "executive presence",
            "business understanding",
            "confidentiality."
        ]
    },
    "7040f12947779b36": {
        "terms": [
            "data science"
        ],
        "salary_min": 79088.766,
        "salary_max": 100144.0,
        "title": "Senior Account Analyst",
        "company": "24G",
        "desc": "RiverGuide LLC, part of the 24G Agency based outside of Detroit, is seeking an experienced Senior Account Manager (Senior Analyst) who is self-motivated and has a passion for business strategy, marketing, data analysis and advertising. This role will allow you to work directly with 1 or 2 high profile clients in Amazon Seller and/or Vendor Central and to help implement strategy and drive sales growth and brand success. You will be responsible for all levels of the business from profitability and inventory to brand, product and advertising strategy - working in conjunction with our Merchandising & Branding and Advertising Teams. You will work directly with Account Managers and other teams to analyze business, inventory and advertising data, as well as help to create decks and data visualizations to share with clients. \n  If you have experience with Excel, Advertising and projects that deliver and surpass company business goals & expectations, let\u2019s talk! \n \n  What You\u2019ll Do (Hands-On Training Provided) \n \n  Serve as the main point of contact for 1-2 high profile clients, to start, driving strategy and working cross-departmentally to execute tasks and achieve the clients goals. \n  Provide updates to clients that communicate key success metrics and tell the story behind their data. \n  Work with other Account Managers to assess profitability and viability of brands, products and market. \n  Build sales forecasts and communicate progress towards the sales goal to ensure we are on pace to hit our targets each month. \n  Manage the advertising budget for Amazon Marketing Services (AMS), DSP, Coupons/Promotions, and additional off-Amazon marketing spend. Monitor pacing and efficiency (ACoS/TACoS) to ensure the ROI is aligned with the client\u2019s expectations. \n  Provide strategic recommendations for expanding product assortment. \n  Have a robust understanding of Amazon Retail Readiness and provide recommendations for optimizing the variations and content on detail pages to improve the organic ranking of Amazon listings for key customer search queries. \n  Leverage CRMs, Pacvue, Google Analytics and other technology to problem solve, find narrative and explain data. \n  Build tools to help automate tasks and reporting in Excel or Google Sheets and dashboard creation and data visualizations in PowerBI. \n  Advanced reporting, leveraging AMS data. Work cross-functionally to invent and simplify reporting processes. \n  Create dashboards and reports on advertising campaign effectiveness, ASIN level profitability, growth and market share, budget tracking, operational performance, organic rank, etc. \n  Analyze aspects of Pay Per Click Amazon Marketing Services (AMS) campaigns for multiple brands. \n  Campaign Keyword Analysis, including complete negative keyword selection and implementation into campaigns. \n  Ongoing ad copy analysis and A/B Testing. \n  Work with the internal advertising team to choose the right Cost Per Click (CPC) based on market competition and strategic bid management to optimize our budget and reduce unnecessary costs. Also assist with campaign keyword analysis, ad copy analysis, A/B testing, and other advertising tasks as needed. \n  Provide guidance to account managers and coordinators on the accounts, including task delegation. \n  (Optional) Develop, train and manage a team of account managers and coordinators across multiple accounts, in personal and professional growth. \n \n \n  Job Requirements \n  In Addition To Experience In The Tasks Above, Here\u2019s a Few More Things We Need From You: \n \n  Bachelor\u2019s degree in Business, Marketing, Data Science, Statistics, Computer Science, Economics, Math, Advertising or related experience. \n  Examples of experience with problem solving and business strategy or data analysis/digital marketing with measurable results. \n  Advanced Excel skills required. Must be comfortable with V-lookups, pivot tables, macros, formulas and more advanced functionality. \n  SQL, PowerBI, Python, VBA Preferred. \n  Demonstrate a desire to keep current and innovate with the latest developments in the PPC/SEO and eComm environments. \n  Direct Amazon experience managing clients or accounts. \n  Looking for advanced industry knowledge and a proven track record of process improvement and high level analysis. \n \n \n  Related Skills \n \n  Problem Solving \u2013 The ability to think creatively about problems and ideas to find solutions that will add maximum value for clients. \n  Strategic Thinking \u2013 Innovative, data focused client solutions. \n  Self-Motivated and Self-Directed Learning. \n  Results and Detail Oriented. \n  Great Communication Skills - Written and verbal. \n  Experience with Amazon Marketing Services, Vendor and Seller Management. \n \n  Nice to Haves \n \n  Experience with Google AdWords and Analytics. \n  Google AdWords and/or Google Analytics Certifications \n  Experience working with CRMs. \n  Management/Leadership Experience \n \n \n  Additional Perks: \n \n  Options to work in-person, Hybrid, or remote \n  Free Drinks and Coffee \n  Free Onsite Bowling for employees, friends and family \n  Open environment optimal for cross departmental collaboration \n  Onsite Golf Simulator \n  Dog friendly - Bring your pet to the office \n  HAP Medical \n  BCBS Dental and Vision \n  Guardian Life Insurance, long-term disability, short-term disability \n  Voya 401(k) \n  401(k) Matching \n  Unlimited Paid Time Off \n \n  This job description is intended to outline those functions typically performed by individuals assigned to this classification. This description is not intended to be all - inclusive or to limit the discretionary authority of supervisors to assign other tasks of similar nature or level of responsibility. Riverguide reserves the right to change or assign to this position as required. \n  W2 only. We are not offering sponsorship at this time. \n  Riverguide, LLC is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, religion, sex, national origin, Veteran status, gender, sexual orientation or disability. \n   \n mvUZIuWPKF",
        "cleaned_desc": "  Examples of experience with problem solving and business strategy or data analysis/digital marketing with measurable results. \n  Advanced Excel skills required. Must be comfortable with V-lookups, pivot tables, macros, formulas and more advanced functionality. \n  SQL, PowerBI, Python, VBA Preferred. \n  Demonstrate a desire to keep current and innovate with the latest developments in the PPC/SEO and eComm environments. \n  Direct Amazon experience managing clients or accounts. \n  Looking for advanced industry knowledge and a proven track record of process improvement and high level analysis. \n \n \n  Related Skills \n \n  Problem Solving \u2013 The ability to think creatively about problems and ideas to find solutions that will add maximum value for clients. \n  Strategic Thinking \u2013 Innovative, data focused client solutions. \n  Self-Motivated and Self-Directed Learning. \n  Results and Detail Oriented. ",
        "techs": [
            "advanced excel skills",
            "v-lookups",
            "pivot tables",
            "macros",
            "formulas",
            "sql",
            "powerbi",
            "python",
            "vba",
            "ppc/seo",
            "ecomm",
            "amazon experience"
        ],
        "cleaned_techs": [
            "v-lookups",
            "pivot tables",
            "macros",
            "formulas",
            "sql",
            "powerbi",
            "python",
            "vba",
            "ppc/seo",
            "ecomm",
            "aws"
        ]
    },
    "5eb3be0763e03815": {
        "terms": [
            "data science"
        ],
        "salary_min": 103989.07,
        "salary_max": 131673.33,
        "title": "UI/UX Software Engineer (III) \u2013 AI Applications",
        "company": "HP",
        "desc": "Possible locations Spring TX, Corvallis OR, as well as remote work within the United States. \n \n  The Team \n  We are a growing centralized team helping HP take advantage of new AI/ML technology, especially around Generative AI and large language models. We engage with business units to advise and prototype solutions, and we also develop and run software applications. \n \n  The Role \n  We are looking for somebody who enjoys the dual work of UX design and UI development. Wearing your UX hat, you are passionate about creating simple and aesthetically pleasing user interfaces. You stay up to date with the UX of new AI-powered consumer and business products (e.g. ChatGPT). Wearing your UI engineering hat you take your design to a product working closely with the rest of the software team. AI will fundamentally change how users interacts with business applications and you will play a role in bringing this change to HP\u2019s internal applications. \n \n  Skills and Profile \n \n Ability and desire to work both with UX and UI software development.  \n Solid experience working as software UI developer in a development team \n Experience defining UX for web applications, considering both usability and aesthetics. \n A plus for any of the following: chatbots, analytical applications, search engine UX, A/B testing in consumer apps. \n We currently use React for web UI although this is not set in stone. Other technologies the team is using include Azure, python, langchain, micro services, docker, CI/CD, Elastic Search, SQL and NoSQL. \n The recent AI progress is disruptive, and our team is in the midst of it! As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value \"business as usual\". \n Experience working in a distributed team containing a variety of cultural backgrounds. Ability to engage in discussions in a respectful manner. \n Mastery in English is required. \n \n \n  Education and Length of Experience  Bachelor's degree in Computer Science or similar, or demonstrated competence, plus a minimum of 4-6 years of relevant experience. \n \n  About HP \n \n \n \n \n \n  You\u2019re out to reimagine and reinvent what\u2019s possible\u2014in your career as well as the world around you.\n  \n \n   So are we. We love taking on tough challenges, disrupting the status quo, and creating what\u2019s next. We\u2019re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n  \n \n \n \n   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n  \n \n \n \n   Our history: HP\u2019s commitment to diversity, equity and inclusion \u2013 it's just who we are.\n  \n \n   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u2019re more innovative and that helps grow our bottom line. Come to HP and thrive!",
        "cleaned_desc": "  Skills and Profile \n \n Ability and desire to work both with UX and UI software development.  \n Solid experience working as software UI developer in a development team \n Experience defining UX for web applications, considering both usability and aesthetics. \n A plus for any of the following: chatbots, analytical applications, search engine UX, A/B testing in consumer apps. \n We currently use React for web UI although this is not set in stone. Other technologies the team is using include Azure, python, langchain, micro services, docker, CI/CD, Elastic Search, SQL and NoSQL. \n The recent AI progress is disruptive, and our team is in the midst of it! As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value \"business as usual\". ",
        "techs": [
            "ux software development",
            "ui software development",
            "react",
            "azure",
            "python",
            "langchain",
            "micro services",
            "docker",
            "ci/cd",
            "elastic search",
            "sql",
            "nosql",
            "chatbots",
            "analytical applications",
            "search engine ux",
            "a/b testing"
        ],
        "cleaned_techs": [
            "ux software development",
            "ui software development",
            "react",
            "azure",
            "python",
            "langchain",
            "micro services",
            "docker",
            "ci/cd",
            "elastic search",
            "sql",
            "nosql",
            "chatbots",
            "search engine ux",
            "a/b testing"
        ]
    },
    "818167f35c689269": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 124170.93,
        "salary_max": 157228.06,
        "title": "Software Engineer (IV) \u2013 AI Applications",
        "company": "HP",
        "desc": "** Locations include Spring, Texas (preferred location), and US remote. \n \n  The Team \n  We are a growing centralized team helping HP take advantage of new AI/ML technology, especially around Generative AI and large language models. We engage with business units to advise and prototype solutions, and we develop and run software applications for internal use. \n \n  The Role \n  As a Software Engineer you will work to rapidly develop AI-powered software applications, especially internal business applications powered by large language models. You will work closely with data scientists, machine learning engineers, and other software engineers, and your voice will be important in shaping the work the team does. \n \n  Skills and Profile \n \n Solid software engineering background, especially with business applications in a cloud environment. \n You move the team from proof-of-concept code into a scalable full-stack software application, collaborating with the solution architect. \n Full-stack ability is a plus. We are hiring a dedicated Lead UI Software Engineer, but it is a plus if you can assist with front-end contributions when needed. \n In this team we value a start-up mindset and a sense of urgency to deliver to our internal customers. The ideal candidate will have experience from a fast-moving SaaS start-up in addition to experience from a large complex organization. \n Technologies you may use include Azure services, python, langchain, micro services, docker, CI/CD, React, Elastic Search, SQL and NoSQL. \n Plus for: Azure DevOps and platform, user & account administration, document search technologies, vector databases, and LLM-prompt engineering. \n The recent AI progress is disruptive, and our team is in the midst of it! As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value \"business as usual\". \n We are doing multiple hires, and so your role can be somewhat tailored to your special skills and interests. \n Experience working in a distributed team containing a variety of cultural backgrounds. Ability to engage in discussions in a respectful manner. \n Mastery in English is required. \n \n \n  Education and Length of Experience  For this position, we require a Bachelor's degree in Computer Science or similar, or demonstrated competence. A Master's degree is a plus. In addition, typically a minimum of 7-10 years of relevant experience. \n \n \n  About HP \n \n \n \n \n \n  You\u2019re out to reimagine and reinvent what\u2019s possible\u2014in your career as well as the world around you.\n  \n \n   So are we. We love taking on tough challenges, disrupting the status quo, and creating what\u2019s next. We\u2019re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n  \n \n \n \n   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n  \n \n \n \n   Our history: HP\u2019s commitment to diversity, equity and inclusion \u2013 it's just who we are.\n  \n \n   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u2019re more innovative and that helps grow our bottom line. Come to HP and thrive!",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "93ed2d146b39d838": {
        "terms": [
            "data science"
        ],
        "salary_min": 260000.0,
        "salary_max": 270000.0,
        "title": "Senior Director Professional Services",
        "company": "DNAnexus",
        "desc": "Company Description\n   DNAnexus is a leading provider of secure, scalable, and intuitive biomedical data analysis software and bioinformatics applications for the life sciences and healthcare communities. The company actively manages and supports more than 80 petabytes of complex genomic, multi-omic, and clinical datasets on behalf of a growing network of collaborations with large-scale biobanks, as well as leading pharmaceutical, clinical diagnostic, academic research, and government organizations. Over 40,000 scientists across 48 countries are now using the highly collaborative, cloud-based, end-to-end platform to gain data-driven insights that can advance scientific discovery, accelerate precision medicine, and improve patient care. \n \n \n \n Job Description\n   The DNAnexus Professional Services group is passionate about partnerships and client success. Our partnership culture is as important as the technology we provide our clients. Our mission is to help our clients achieve their research and clinical goals with the DNAnexus solutions and services. Our team includes highly sought after experts including data scientists, bioinformaticians, cloud computing experts, and software engineers. Our headquarters is in Silicon Valley and we have a rapidly growing center in Prague, the Czech Republic, and elsewhere across the globe. \n  The Professional Services team is responsible for the design and development of scientific and software solutions. Some notable implementations include the Precision FDA (https://precision.fda.gov/) and St Jude Cloud (https://www.stjude.cloud/), and City of Hope Precision Medicine Platform. \n  The Senior Director of Professional Services leads Data Science, Data Analysis, Translational Informatics, and Software Engineering, as well as manages a number of special projects. This can be a remote position. \n  The Senior Director of Professional Services ensures we deliver quality implementations across the entire client lifecycle, from ideation and design to acceptance and support. This experienced leader shall work closely with the Program Management team to increase annual recurring bookings and manage services revenue generation, utilization, gross margin, and customer satisfaction targets. \n  The Senior Director of Professional Services has overall responsibility for streamlining development methodologies to ensure consistently predictable and high quality deliverables. In addition, they must demonstrate leadership skills, teamwork, mentoring, conflict resolution, negotiating, partnering, decision-making and be accountable for creating an environment fostering the development of multiple functional areas. The ideal candidate has experience creating strategies and plans to meet organizational goals, including financial, scientific, technical, client satisfaction and, critically, employee satisfaction. They are able to stay ahead of the field and be the expert our clients expect us to be. The ability to work in a dynamic environment and a passion to help our employees grow and our clients succeed are essential. \n \n \n \n \n Qualifications\n  \n \n  Responsible for achievement of KPIs and report regular progress to SVP of Services and Solutions \n  Champion Professional Services best practice development to maximize the creation of repeatable solutions \n  Provide leadership, coaching, and mentoring to optimize team performance \n  Able to recruit top performers and achieve employee satisfaction objectives \n  Capture and share knowledge across DNAnexus \n  Mitigate risks through the development of new strategies and through active risk management \n  Collaborate with other departments, including Product Management, Product Engineering, Program Management, Sales, Customer Success, etc to improve service offerings and overall customer satisfaction \n \n  Skills Required \n \n  10+ years experience in bioinformatics, data science, software engineering or a related field \n  Experience in a dynamic, client-centric setting \n  Excellent communication skills, both oral and written; able to communicate complex topics at various \u201caltitudes\u201d \n  Mentorship skills for helping to grow and manage a team \n  Highly organized with ability to manage concurrent deadlines and priorities \n  Self-starter, highly proactive with the ability to work with minimal guidance \n  Excellent interpersonal skills \n \n  Skills Desired \n \n  Experience managing a team of 20+ people \n  Proficient with programming languages and tools such as Python, R, Java, and Jupyter Notebook \n  Experience working in a high-growth environment \n \n  Salary and Other Compensation : \n  The annual starting salary for this position is between $260,000 \u2013 $270,000. Factors which may affect starting pay within this range may include geography/market, skills, education, experience and other qualifications of the successful candidate. \n  Benefits : \n  The Company offers the following benefits for this position, subject to applicable eligibility requirements: medical insurance, dental insurance, vision insurance, 401(k) retirement plan, life insurance, long-term disability insurance, short-term disability insurance, flexible paid time off, 12 weeks of paid parental leave, and national holidays paid. \n  Additional Information\n   Headquartered in Mountain View, California, with over 220 team members across the United States and Europe, DNAnexus is experiencing rapid growth and market adoption. With the support of leading investors including Google Ventures and Blackstone, and trusted by hundreds of the world's biomedical leaders, the company is at the innovative forefront with our precision health data cloud to drive scientific breakthroughs. If you are interested in joining our team, please apply today!",
        "cleaned_desc": " \n  10+ years experience in bioinformatics, data science, software engineering or a related field \n  Experience in a dynamic, client-centric setting \n  Excellent communication skills, both oral and written; able to communicate complex topics at various \u201caltitudes\u201d \n  Mentorship skills for helping to grow and manage a team \n  Highly organized with ability to manage concurrent deadlines and priorities \n  Self-starter, highly proactive with the ability to work with minimal guidance \n  Excellent interpersonal skills \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "cd66777663ae472b": {
        "terms": [
            "data science"
        ],
        "salary_min": 107871.38,
        "salary_max": 136589.2,
        "title": "Senior Statistical Programmer",
        "company": "ACME Business Solutions Pvt Ltd",
        "desc": "Responsibilities: \n \n Work with Leads statistical programmer on activities for assigned clinical development studies and programs. \n Ensures timely statistical analyses of clinical data per protocols and Statistical Analysis Plans; either directly or through CRO oversight develops statistical programs and produces programmed outputs used to create integrated scientific reports for clinical trial results \n Interacts with CROs involved in data management/analysis activities to ensure that their statistical analyses and resulting outputs are accurate and consistent with the contractually agreed upon deliverables; works with vendor staff to characterize and resolve issues related to data analysis. \n Creates/Reviews derived dataset specifications and the related analysis datasets. \n Performs other tasks and assignments as needed and specified by management. \n \n Requirements: \n \n Minimum of 6 years of experience in statistics or statistical programming in a pharmaceutical, biotechnology, CRO or related environment. \n Demonstrated and applied SAS programming skills (e.g., Base SAS, SAS/Stat, SAS/Graph, SAS macros, ODS) and a good understanding of database systems. \n Clinical Data Interchange Standards Consortium (CDISC) experience \n Knowledge of clinical data analysis and reporting process as it relates to drug development. \n Excellent verbal and written communication and skills. \n Ability to work independently and collaboratively, as required, in a fast-paced, matrixed, team environment consisting of internal and external team members. \n \n Job Type: Contract \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 6 years \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Preferred) \n \n Experience: \n \n Informatica: 3 years (Required) \n SQL: 5 years (Required) \n Data warehouse: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Requirements: \n \n Minimum of 6 years of experience in statistics or statistical programming in a pharmaceutical, biotechnology, CRO or related environment. \n Demonstrated and applied SAS programming skills (e.g., Base SAS, SAS/Stat, SAS/Graph, SAS macros, ODS) and a good understanding of database systems. \n Clinical Data Interchange Standards Consortium (CDISC) experience \n Knowledge of clinical data analysis and reporting process as it relates to drug development. \n Excellent verbal and written communication and skills. \n Ability to work independently and collaboratively, as required, in a fast-paced, matrixed, team environment consisting of internal and external team members. ",
        "techs": [
            "sas programming",
            "base sas",
            "sas/stat",
            "sas/graph",
            "sas macros",
            "ods",
            "cdisc"
        ],
        "cleaned_techs": [
            "sas",
            "base sas",
            "ods",
            "cdisc"
        ]
    },
    "c7721ebb31f92ecc": {
        "terms": [
            "data science"
        ],
        "salary_min": 58400.0,
        "salary_max": 133000.0,
        "title": "Enterprise Software Engineer",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         McLean,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180079\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Enterprise Software Engineer\n           The Opportunity: \n \n  Are you looking for an opportunity to not just develop software but create complex AI systems for the Federal government and Commercial Organizations? Are you an innovator and thought leader that thrives on making positive impacts creating a digital, modern, diverse, and resilient future for consumers? As a software engineer, you can solve a problem with a complete end-to-end AI solution in a fast-paced, Agile environment that focuses on empowering engineers to realize their vision as we build our nation\u2019s most mission-critical, sophisticated AI systems. We\u2019re looking for a developer, leader, and innovator with the skills needed to build software from vision to production-ready system. \n \n  This role is more than just coding. We need a software engineer to join Booz Allen\u2019s development team who will use their passion to learn new tools and techniques and identify needed system improvements. You\u2019ll analyze the needs and the environment to help the solution team consider the architecture and operating environment, including future functionality and enhancements, then engineer the right solution to realize high-impact and client success. You'll have the unique opportunity to learn all phases of software development and touch all levels of modern technology stacks. Client innovation is about movement into the future, together, so join us as we build AI systems today that positively change the world of tomorrow. \n \n  Join us. The world can't wait. \n \n  You Have: \n \n  4+ years of experience as a software developer and engineer working with Java \n  Experience with Python \n  Experience working in Kanban or Agile development processes \n  Experience with open-source products, including Jackson, Hibernate, Angular, or Maven \n  Experience with application servers, including Tomcat or Wildfly \n  Experience with Git and collaboration tools, including Jenkins, JIRA, Confluence, Nexus, or Bitbucket \n  Experience with facing clients and requirements gathering \n  Ability to obtain a security clearance \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with using message broker, including Kafka or RabbitMQ \n  Experience with containerization and Kubernetes \n  Experience with Apache Spark and big data technologies \n  Experience with Cloud services, including AWS, Azure, or GCP \n  Experience with software architecture and design \n  Knowledge of basic data science concepts and developing data pipelines \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law. \n  #LI-AH1",
        "cleaned_desc": "  Experience with Git and collaboration tools, including Jenkins, JIRA, Confluence, Nexus, or Bitbucket \n  Experience with facing clients and requirements gathering \n  Ability to obtain a security clearance \n  Bachelor\u2019s degree \n \n \n  Nice If You Have: \n \n  Experience with using message broker, including Kafka or RabbitMQ \n  Experience with containerization and Kubernetes \n  Experience with Apache Spark and big data technologies \n  Experience with Cloud services, including AWS, Azure, or GCP \n  Experience with software architecture and design \n  Knowledge of basic data science concepts and developing data pipelines \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Create Your Career: \n \n  Grow With Us ",
        "techs": [
            "git",
            "jenkins",
            "jira",
            "confluence",
            "nexus",
            "bitbucket",
            "kafka",
            "rabbitmq",
            "kubernetes",
            "apache spark",
            "aws",
            "azure",
            "gcp"
        ],
        "cleaned_techs": [
            "git",
            "jenkins",
            "jira",
            "confluence",
            "nexus",
            "bitbucket",
            "kafka",
            "rabbitmq",
            "kubernetes",
            "apache spark",
            "aws",
            "azure",
            "gcp"
        ]
    },
    "82711a64e27cb904": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Medical Director",
        "company": "Cogitativo, Inc.",
        "desc": "Our Mission and Background: \n  Spanish for meditative and contemplating,  Cogitativo  was created with the purpose of thinking deeply about the issues affecting our healthcare system. \n  WE ARE A DIFFERENT KIND OF DATA SCIENCE COMPANY \n  We are singularly focused on improving our healthcare system for all stakeholders \u2013 especially patients - by helping our clients make sense of complex data answering their most challenging questions. \n  Trained and educated at some of the world's top academic institutions, our data science team uses advanced analytical and machine learning methods. These methods, combined with nationally recognized healthcare operators, provide our clients unbiased, scientific insights into their operational performance. These insights enable our clients to understand actionable opportunities for improving systems of care and healthcare affordability. \n  Cogitativo is fast-paced, and in this role, you'll be expected to make decisions independently by weighing many needs and priorities. The role and its surrounding organization aren't rigidly defined; successful candidates will accel in a creative, fast-paced, results-oriented environment. We are looking for mission-driven teammates who can jump into any situation with enthusiasm and deliver on tight timelines. \n  Here's an overview of what you will do: \n  The Medical Director utilizes their expertise and insights to aid in aligning and advancing our ML pipeline to enhance patient clinical outcomes. Your responsibilities include leveraging your clinical expertise, experience and knowledge of standard ontologies and data models to transform electronic health records (EHR), bio waveforms, claims, and other Real-World Evidence (RWE) sources into high-quality databases accessible for our ML pipeline. Additionally, you will collaborate with data scientists to assist in feature engineering and review model predictions. \n  You will work closely with a team of highly skilled Machine Learning Engineers and Data Scientists who specialize in applying deep learning and machine learning to extract insights from massive data sets. Your role will bridge the gap between Data Science, Data Engineering, Clinical Experts, and Product Development. Your contributions will be essential in scaling these computational models into tangible products or services that contribute to healthcare improvement. \n  Detailed responsibilities: \n  The Medical Director will support Cogitativo\u2019s hyper-growth in the following ways: \n \n  Provide clinical and informatics expertise to inform the design, buildout, and operations of our ML/DL pipeline. \n  Collaborate with clinical experts in specific therapeutic areas to translate clinical knowledge into codes, logics, rules for feature engineering of ML models. \n  Assist in the development and maintenance of data models and other product development and commercialization efforts. \n  Collaborate with our clinical, data science, and data engineering teams to define data requirements and mapping process from EMR and claim data to features, risk factors, outcomes, and interventions for the ML/DL pipeline. \n  Design data processing policies and procedures to guide manual and automated efforts, including: (i) SOPs for unstructured content abstraction and curation, (ii) Data models and rules for transforming and deriving clinical data, (iii) SOPs for reviewing validity of clinical predictions. \n  Support clinical review and validation of model predictions. \n \n  Required qualifications: \n \n  MD with at least five (5) years of closely related clinical training. \n  At least five (5) years of experience in clinical informatics, including experience with EHR and claims data, applying RWD to clinical research. \n  Deep knowledge of ontologies commonly used by health systems and payers, including ICD-10, HCPCS, CPT, LOINC, RxNorm. \n  Experience with Epic and/or Cerner EHRs. \n  Experience with biomarker data sets such as; clinical imaging, proteomics, metabolomics, and transcriptomics. \n  Experience with waveform data such as EEG, ECG, PPG \n  An entrepreneurial and solutions-oriented mentality - you are comfortable with ambiguity, self-directed, and have outstanding problem-solving skills. \n  Ability to thrive and demonstrate constant applied learning in a highly complex, interdisciplinary, and dynamic work environment. \n \n  Preferred qualifications: \n \n  Certification in Epic and/or Cerner EHRs. \n  Familiarity with OMOP, FHIR. \n  Experience in supporting data science pipeline using EHR data to measure outcomes and report quality metrics. \n  Familiarity with machine learning concepts and practices.",
        "cleaned_desc": "  The Medical Director utilizes their expertise and insights to aid in aligning and advancing our ML pipeline to enhance patient clinical outcomes. Your responsibilities include leveraging your clinical expertise, experience and knowledge of standard ontologies and data models to transform electronic health records (EHR), bio waveforms, claims, and other Real-World Evidence (RWE) sources into high-quality databases accessible for our ML pipeline. Additionally, you will collaborate with data scientists to assist in feature engineering and review model predictions. \n  You will work closely with a team of highly skilled Machine Learning Engineers and Data Scientists who specialize in applying deep learning and machine learning to extract insights from massive data sets. Your role will bridge the gap between Data Science, Data Engineering, Clinical Experts, and Product Development. Your contributions will be essential in scaling these computational models into tangible products or services that contribute to healthcare improvement. \n  Detailed responsibilities: \n  The Medical Director will support Cogitativo\u2019s hyper-growth in the following ways: \n \n  Provide clinical and informatics expertise to inform the design, buildout, and operations of our ML/DL pipeline. \n  Collaborate with clinical experts in specific therapeutic areas to translate clinical knowledge into codes, logics, rules for feature engineering of ML models.    Assist in the development and maintenance of data models and other product development and commercialization efforts. \n  Collaborate with our clinical, data science, and data engineering teams to define data requirements and mapping process from EMR and claim data to features, risk factors, outcomes, and interventions for the ML/DL pipeline. \n  Design data processing policies and procedures to guide manual and automated efforts, including: (i) SOPs for unstructured content abstraction and curation, (ii) Data models and rules for transforming and deriving clinical data, (iii) SOPs for reviewing validity of clinical predictions. \n  Support clinical review and validation of model predictions. \n \n  Required qualifications: \n    MD with at least five (5) years of closely related clinical training. \n  At least five (5) years of experience in clinical informatics, including experience with EHR and claims data, applying RWD to clinical research. \n  Deep knowledge of ontologies commonly used by health systems and payers, including ICD-10, HCPCS, CPT, LOINC, RxNorm. \n  Experience with Epic and/or Cerner EHRs. \n  Experience with biomarker data sets such as; clinical imaging, proteomics, metabolomics, and transcriptomics. \n  Experience with waveform data such as EEG, ECG, PPG \n  An entrepreneurial and solutions-oriented mentality - you are comfortable with ambiguity, self-directed, and have outstanding problem-solving skills.    Ability to thrive and demonstrate constant applied learning in a highly complex, interdisciplinary, and dynamic work environment. \n \n  Preferred qualifications: \n \n  Certification in Epic and/or Cerner EHRs. \n  Familiarity with OMOP, FHIR. \n  Experience in supporting data science pipeline using EHR data to measure outcomes and report quality metrics. ",
        "techs": [
            "ml/dl pipeline",
            "standard ontologies",
            "data models",
            "electronic health records (ehr)",
            "bio waveforms",
            "claims",
            "real-world evidence (rwe)",
            "databases",
            "feature engineering",
            "model predictions",
            "machine learning engineers",
            "data scientists",
            "deep learning",
            "massive data sets",
            "data science",
            "data engineering",
            "clinical experts",
            "product development",
            "computational models",
            "clinical and informatics expertise",
            "clinical knowledge",
            "codes",
            "logics",
            "rules",
            "data requirements",
            "mapping process",
            "emr",
            "claim data",
            "risk factors",
            "outcomes",
            "interventions",
            "data processing policies and procedures",
            "unstructured content abstraction and curation",
            "clinical predictions",
            "clinical review",
            "validation",
            "closely related clinical training",
            "clinical informatics",
            "ehr and claims data",
            "rwd",
            "ontologies",
            "icd-10",
            "hcpcs",
            "cpt",
            "loinc",
            "rxnorm",
            "epic ehr",
            "cerner ehr",
            "biomarker data sets",
            "clinical imaging",
            "proteomics",
            "metabolomics",
            "transcriptomics",
            "waveform data",
            "eeg",
            "ecg",
            "ppg",
            "entrepreneurial and solutions-oriented mentality",
            "problem-solving skills",
            "certification in epic and/or cerner ehrs",
            "omop",
            "fhir",
            "data science pipeline",
            "quality metrics."
        ],
        "cleaned_techs": [
            "ml/dl pipeline",
            "standard ontologies",
            "data models",
            "electronic health records (ehr)",
            "bio waveforms",
            "claims",
            "real-world evidence (rwe)",
            "databases",
            "feature engineering",
            "model predictions",
            "machine learning engineers",
            "data scientists",
            "massive data sets",
            "data science",
            "clinical experts",
            "product development",
            "computational models",
            "clinical and informatics expertise",
            "clinical knowledge",
            "codes",
            "logics",
            "rules",
            "data requirements",
            "mapping process",
            "emr",
            "claim data",
            "risk factors",
            "outcomes",
            "interventions",
            "data processing policies and procedures",
            "unstructured content abstraction and curation",
            "clinical predictions",
            "clinical review",
            "validation",
            "closely related clinical training",
            "clinical informatics",
            "ehr and claims data",
            "rwd",
            "ontologies",
            "icd-10",
            "hcpcs",
            "cpt",
            "loinc",
            "rxnorm",
            "epic ehr",
            "cerner ehr",
            "biomarker data sets",
            "clinical imaging",
            "proteomics",
            "metabolomics",
            "transcriptomics",
            "waveform data",
            "eeg",
            "ecg",
            "ppg",
            "entrepreneurial and solutions-oriented mentality",
            "certification in epic and/or cerner ehrs",
            "omop",
            "fhir",
            "data science pipeline",
            "quality metrics."
        ]
    },
    "b42282a00d87e483": {
        "terms": [
            "data science"
        ],
        "salary_min": 61340.89,
        "salary_max": 77671.234,
        "title": "Sales Operations Associate",
        "company": "ModelOp",
        "desc": "Job Description \n  Join the world\u2019s leading AI Governance company. \n \n  Are you looking for an opportunity to gain experience in sales operations, marketing operations, and business development at a technology leader in the AI market? \n  Are you eager to learn, motivated, and possess a high say/do ratio? \n  Are you emotionally intelligent with strong interpersonal and communications skills and a growth mindset? \n  Are you looking for a fast-track career progression? \n \n  If this is you, apply for ModelOp\u2019s Sales Associate Role. \n \n \n \n \n \n       We\u2019re looking for a Sales Operations Associate to join our go-to-market team and support our Account Executives and VP of Marketing to ensure we hit our pipeline targets and revenue goals. Sales Operations responsibilities include supporting our CRM and GTM tech stack operations, finding and managing lead/contact/account data, developing and operating sales engagement campaigns, conducting research and analyzing data, and overseeing various administrative tasks required to ensure our GTM team reaches its goals. You\u2019ll report into the VP of Marketing and will work directly with our Account Executives, Executive Team, and Marketing Operations lead. \n       \n \n \n \n \n \n \n \n \n \n \n \n \n Employment Type \n \n            Full-time \n            \n \n \n \n \n \n \n \n \n \n \n \n \n \n Location \n \n            Remote, but preferably Chicago, IL or Salt Lake City, UT metro areas, as we have offices there and encourage a hybrid work schedule. \n            \n \n \n \n \n \n \n \n \n \n \n \n \n \n About ModelOp \n \n            ModelOp, the pioneer of ModelOps software, enables enterprises to address the critical governance and scale challenges necessary to fully unlock the transformational value of enterprise AI and Machine Learning investments. Core to any AI orchestration platform, G2000 companies use ModelOp Center to manage, govern and monitor models across the enterprise and deliver reliable, compliant and scalable AI initiatives.\n            \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Responsibilities \n \n \n  Work with the Sales and Marketing team to build target lead lists and validate contact data \n  Support lead generation projects \u2014 including developing and executing outbound sales and marketing campaigns to generate qualified leads and build sales pipeline \n  Support, manage and execute sales and marketing projects \n  Support and manage sales operations processes related to our CRM (Salesforce), Sales Engagement platform (Salesloft), and Marketing Automation platform (Pardot) \n  Increase Account Executives efficiency with leads, data, and time management \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Qualifications \n \n \n \n \n  Demonstrable interest in technology sales and marketing \n  Willingness to learn sales and marketing skills, processes, and technology \n  Excellent communication (verbal, written, and presentation) and interpersonal skills (high emotional intelligence and personable) \n  Strong analytical skills to interpret data , ensure fidelity, and make suggestions on how to improve the processes \n  Comfortable working and communicating across teams \n  Competent digital skillset using software tools such as Microsoft or Google\u2019s Office products \n  Thrive on working in a fast-paced environment \n  Desire to work in the tech industry with a growing company \n  Intelligent, motivated, competitive and organized with a roll-up-the-sleeves and get-the-job done attitude \n  Bachelor\u2019s degree \n  0 to 1 years of professional experience \n  US work authorization is required \n  Pluses, but not required: \n \n \n \n  Marketing, sales, business, engineering, or data science background \n  Demonstrable experience with Salesforce, Pardot, Salesloft, LinkedIn Sales Navigator, 6Sense, and Spreadsheets \n \n \n \n \n \n \n  Benefits \n  ModelOp offers a full benefits, including a retirement package and comprehensive health insurance \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Apply Now \n \n  Please email your resume to  Careers@modelop.com \n  ModelOp. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, gender identity, sexual orientation, appearance, national origin, age, disability, genetic information, carrier status, marital status, veteran status, or any other protected status in accordance with applicable federal, state and local laws.",
        "cleaned_desc": " \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Qualifications \n \n \n \n \n  Demonstrable interest in technology sales and marketing \n  Willingness to learn sales and marketing skills, processes, and technology \n  Excellent communication (verbal, written, and presentation) and interpersonal skills (high emotional intelligence and personable) \n  Strong analytical skills to interpret data , ensure fidelity, and make suggestions on how to improve the processes \n  Comfortable working and communicating across teams \n  Competent digital skillset using software tools such as Microsoft or Google\u2019s Office products \n  Thrive on working in a fast-paced environment \n  Desire to work in the tech industry with a growing company \n  Intelligent, motivated, competitive and organized with a roll-up-the-sleeves and get-the-job done attitude \n  Bachelor\u2019s degree \n  0 to 1 years of professional experience ",
        "techs": [
            "microsoft office",
            "google office products"
        ],
        "cleaned_techs": [
            "microsoft",
            "google office products"
        ]
    },
    "4c942c4c5698494b": {
        "terms": [
            "data science"
        ],
        "salary_min": 170130.0,
        "salary_max": 234272.5,
        "title": "Sr Director, Product Management",
        "company": "Blue Yonder",
        "desc": "Role : Sr Dir Product Management\n  \n \n   Location: Dallas TX or Remote\n  \n \n \n   Overview:\n  \n \n   Blue Yonder, a leading supply chain software company, is seeking a talented individual to join our team as a Product Manager for AI/ML products. In this role, you will be responsible for defining the vision, strategy, and roadmap for our AI/ML products, aligning them with the overall business objectives. By leveraging your expertise in market research, competitor analysis, and customer insights, you will identify market opportunities and drive product innovation to maintain our competitive edge.\n  \n \n \n   Responsibilities:\n  \n \n  Acts as PMG Representative to key customers by providing thought leadership on solutions to business problems. \n  Back-fills for the Product Manager and VP of Product Management role, as required. \n  Cares for and develops key customer and industry relationships by conducting customer and prospect needs research and maintaining key industry contacts. \n  Collaborates with product teams to translate strategic direction into clear product objectives and roadmaps. \n  Communicates product strategies and direction in a compelling manner. . \n  Provides a clear vision and compelling leadership to all product stakeholders on product strategies and solutions to business problems. \n  Provides strategic product/solution leadership by collaborating with Industry team to set product strategic direction and communicating this direction to all stakeholders. \n  Researches, evaluates and recommends product packaging/bundling/pricing alternatives and third-party partnerships to Executive team. Seeks and follows through on opportunities to improve inter-team relationships and understanding. \n  Ensures that product strategy drives revenue growth, competitive differentiation and customer value. \n  Coordinates across product lines to ensure alignment of individual roadmaps to strategic and corporate objectives. \n \n \n \n   Strategy and Planning:\n  \n \n  Define the vision, strategy, and roadmap for AI/ML products in alignment with the overall business objectives. \n  Conduct market research, competitor analysis, and customer insights to identify market opportunities and drive product innovation. \n  Collaborate with stakeholders to define product requirements, prioritize features, and set measurable goals for product success. \n  Define go to market strategy, pricing models for maximum penetration at highest levels of profitability \n \n \n \n   Product Development and Management:\n  \n \n  Lead a team of product managers and data scientists in the development of AI/ML products, ensuring timely and high-quality deliverables. \n  Drive the end-to-end product development process, including ideation, prototyping, testing, and launch. \n  Work closely with engineering teams to translate product requirements into technical specifications and ensure the successful implementation of AI/ML algorithms and models. \n  Monitor and analyze product performance, user feedback, and market trends to continuously improve the product and enhance user experience. \n \n \n \n   Cross-functional Collaboration:\n  \n \n  Collaborate with engineering, data science, and design teams to ensure seamless integration of AI/ML technologies into the product ecosystem. \n  Partner with marketing and sales teams to develop go-to-market strategies, positioning, and messaging for AI/ML products. \n  Support sales enablement activities by providing product training, documentation, and competitive insights. \n  Engage with customers, prospects, and industry experts to gather feedback, understand user needs, and identify opportunities for product enhancements. \n \n \n \n   Leadership and Team Development:\n  \n \n  Provide strategic leadership and mentorship to the product team, fostering a culture of innovation, collaboration, and accountability. \n  Recruit, develop, and retain top talent, ensuring a skilled and motivated team capable of delivering exceptional AI/ML products. \n  Stay up-to-date with the latest trends and advancements in AI/ML technologies, and guide the team in adopting emerging practices and methodologies. \n \n \n \n   Qualifications:\n  \n \n  Bachelor's or Master's degree in Computer Science, Engineering, Data Science, or a related field. An MBA or business-related degree is a plus. \n  Extensive experience (10+ years) in product management, with a focus on AI/ML products and technologies. \n  Deep understanding of AI/ML concepts, algorithms, and techniques, with a proven track record of delivering successful AI/ML products. \n  Strong business acumen and ability to align AI/ML products with strategic business goals. \n  Experience working in an agile development environment, with proficiency in agile methodologies and tools. \n  Excellent leadership and communication skills, with the ability to influence and collaborate effectively across cross-functional teams. \n  Strong analytical and problem-solving abilities, with a data-driven approach to decision-making. \n \n \n \n LI- SR1 \n \n \n \n   -\n  \n \n The salary range for this role - $170,130.00 - $ 234,272.50 \n \n \n \n   The salary range information provided, reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual salary will be commensurate with skills, experience, certifications or licenses and other relevant factors. In addition, this role will be eligible to participate in either the annual performance bonus or commission program, determined by the nature of the position.\n  \n \n \n   At Blue Yonder, we care about the wellbeing of our employees and those most important to them. This is reflected in our robust benefits package and options that includes:\n  \n \n \n \n     Comprehensive Medical, Dental and Vision\n    \n \n \n     401K with Matching\n    \n \n \n     Flexible Time Off\n    \n \n \n     Corporate Fitness Program\n    \n \n \n     Wellbeing Days\n    \n \n \n     A variety of voluntary benefits such as; Legal Plans, Accident and Hospital Indemnity, Pet Insurance and much more\n    \n \n \n \n   At Blue Yonder, we are committed to a workplace that genuinely fosters inclusion and belonging in which everyone can share their unique voices and talents in a safe space. We continue to be guided by our core values and are proud of our diverse culture as an equal opportunity employer. We understand that your career search may look different than others, and embrace the professional, personal, educational, and volunteer opportunities through which people gain experience.\n  \n \n \n   Our Values\n  \n \n  If you want to know the heart of a company, take a look at their values. Ours unite us. They are what drive our success \u2013 and the success of our customers. Does your heart beat like ours? Find out here: \n   \n   Core Values\n   \n \n \n \n \n    Diversity, Inclusion, Value & Equality (DIVE)\n    is our strategy for fostering an inclusive environment we can be proud of. Check out Blue Yonder's inaugural \n   \n   Diversity Report\n    which outlines our commitment to change, and our \n   \n   video\n    celebrating the differences in all of us in the words of some of our associates from around the world.\n  \n \n \n   All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.",
        "cleaned_desc": "   Leadership and Team Development:\n  \n \n  Provide strategic leadership and mentorship to the product team, fostering a culture of innovation, collaboration, and accountability. \n  Recruit, develop, and retain top talent, ensuring a skilled and motivated team capable of delivering exceptional AI/ML products. \n  Stay up-to-date with the latest trends and advancements in AI/ML technologies, and guide the team in adopting emerging practices and methodologies. \n \n \n \n   Qualifications:\n  \n \n  Bachelor's or Master's degree in Computer Science, Engineering, Data Science, or a related field. An MBA or business-related degree is a plus. \n  Extensive experience (10+ years) in product management, with a focus on AI/ML products and technologies. \n  Deep understanding of AI/ML concepts, algorithms, and techniques, with a proven track record of delivering successful AI/ML products. \n  Strong business acumen and ability to align AI/ML products with strategic business goals. \n  Experience working in an agile development environment, with proficiency in agile methodologies and tools. \n  Excellent leadership and communication skills, with the ability to influence and collaborate effectively across cross-functional teams. \n  Strong analytical and problem-solving abilities, with a data-driven approach to decision-making. \n \n \n \n LI- SR1 \n \n \n \n   -\n  \n \n The salary range for this role - $170,130.00 - $ 234,272.50 ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "ab09e070143021f2": {
        "terms": [
            "data science"
        ],
        "salary_min": 58400.0,
        "salary_max": 133000.0,
        "title": "Supply Chain Risk Management Analyst",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Arlington,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0180070\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Supply Chain Risk Management Analyst\n           Key Role: \n  Support senior-level acquisition customers at a federal agency in the areas of supply chain risk management (SCRM) and policy analysis. Develop and draft formal documents. Comprehend threats and vulnerabilities to systems. Identify supply chain risks and recommend risk mitigation. \n \n  Basic Qualifications: \n \n  Experience with the staffing and coordination process at a federal agency, including the DoD \n  Experience with assisting with policy development and analysis \n  Knowledge of Microsoft Office tools, including PowerPoint and Word \n  Knowledge of the defense industrial base (DIB), including supply chains and how the broader DIB ecosystem makes impacts and affects \n  Secret clearance \n  Bachelor's degree \n \n \n  Additional Qualifications: \n \n  3+ years of experience with SCRM in either the private or public sectors, including identification, assessment, prioritization, mitigation, and monitoring activities \n  Experience with risk management principles \n  Experience with data science or artificial intelligence \n  Experience in the DoD, another federal agency, or as an action officer \n  Knowledge of the DIB and the federal procurement process \n  Knowledge of the DoD acquisition life cycle \n  Ability to multitask and work on both long-term and short-term projects with constantly evolving deadlines \n  Ability to operate in high-pressure environments supporting executive leadership \n  TS/SCI clearance \n  Master's degree in Supply Chain, Risk Management, Industrial Psychology, Organizational Psychology, or Change Management \n \n \n  Clearance:  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law. \n  #LI-AH1",
        "cleaned_desc": "  Basic Qualifications: \n \n  Experience with the staffing and coordination process at a federal agency, including the DoD \n  Experience with assisting with policy development and analysis \n  Knowledge of Microsoft Office tools, including PowerPoint and Word \n  Knowledge of the defense industrial base (DIB), including supply chains and how the broader DIB ecosystem makes impacts and affects \n  Secret clearance \n  Bachelor's degree \n \n \n  Additional Qualifications: \n \n  3+ years of experience with SCRM in either the private or public sectors, including identification, assessment, prioritization, mitigation, and monitoring activities \n  Experience with risk management principles \n  Experience with data science or artificial intelligence \n  Experience in the DoD, another federal agency, or as an action officer \n  Knowledge of the DIB and the federal procurement process \n  Knowledge of the DoD acquisition life cycle ",
        "techs": [
            "microsoft office tools",
            "powerpoint",
            "word",
            "defense industrial base (dib)",
            "supply chains",
            "scrm",
            "risk management principles",
            "data science",
            "artificial intelligence",
            "dod acquisition life cycle"
        ],
        "cleaned_techs": [
            "microsoft",
            "powerpoint",
            "word",
            "defense industrial base (dib)",
            "supply chains",
            "scrm",
            "risk management principles",
            "data science",
            "ai",
            "dod acquisition life cycle"
        ]
    },
    "a011ae4a9a5d3294": {
        "terms": [
            "data science",
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 121815.65,
        "salary_max": 154245.75,
        "title": "Lead Data Engineer (Remote)",
        "company": "Blue Cross Blue Shield of Louisiana",
        "desc": "We take great strides to ensure our employees have the resources to live well, be healthy, continue learning, develop skills, grow professionally and serve our local communities. We invite you to apply for a career with Blue Cross. \n Please note that effective Jan. 4, 2022, Blue Cross and Blue Shield of Louisiana implemented a policy requiring any employee who enters any of our offices or who interacts in person with anyone for company business purposes to be fully vaccinated for COVID 19, unless legally entitled to a reasonable accommodation related to religious or medical exemptions. At this time, that policy is suspended and vaccination is not required to enter our facilities. Please note this is subject to change at any point in time to ensure compliance with company policy or government mandates and certain client facing roles may have separate protocols. \n Residency in or relocation to Louisiana is preferred for all positions. \n We will consider remote work in the following states:   LA, AL, AR, DE, FL, GA, ID, IN, IA, KS, KY, MS, MO, NE, NH, NC, OK, PA (limited counties), SC, SD, TN, TX, UT, VA, WV, WI. \n POSITION PURPOSE \n This position develops data integration solutions using data integration tools or other means with some direction provided by the manager as well as more senior team members such as the Principal Data Engineer. Accountable for complying with all laws and regulations associated with duties and responsibilities. \n NATURE AND SCOPE \n \n This role does not manage people \n \n Necessary Contacts: INSIDE RELATIONSHIPS: \n Make presentations to EIM management. \n Must be able to understand the requirements of multiple agile teams, identify and negotiate trade-offs to gain management agreement with proposed recommendations. \n Meets regularly with program management, product data management, and EIM management to resolve product and project problems and issues. \n OUTSIDE RELATIONSHIPS: \n Attends technical meetings and conferences with the intent of improving the processes and procedures of the Enterprise Data Warehouse and/or Data Lake \n May participate in vendor negotiations. \n Meets with business owners and stakeholders to refine technical requiremen \n QUALIFICATIONS \n Education \n \n Bachelor's in computer science or related field is required \n Four years of related experience can be used in lieu of a Bachelor\u2019s degree. \n \n Work Experience \n \n Must have a minimum of seven years of professional information technology experience to include a minimum of three years\u2019 experience with deployment and support of ETL, software applications, or web services solutions. \n Requires knowledge in such areas as data mart data warehouse, data lake development, SSISETL/ELT data integration patterns, web and cloud-oriented systems integration and communication-based systems, languages such as C#, Python or Java. Additional training for integration tools used will be supplied. \n Experience in one of the following areas is required: Support of a data warehousing, data mart, data lake, and/or business intelligence environment; Strong ETL development background with Informatica PowerCenter, DataStage, or SSIS; Strong development experience with TeraData, Oracle, SQL Server, Data Lake, or Sybase repositories; Other programming language such as C#, Python, PL/SQL, T-SQL, SparkSQL, NoSQL; Shared API for web or cloud applications development background; Big Data technologies such as Hadoop, Spark, Artificial Intelligence (AI), Machine Learning (ML), Natural Language Processing (NLP); Strong background in software development for applications \n Massively Parallel Processing (MPP) DBMS preferred \n Visualization, Business Intelligence tools or reporting experience with tools such as Tableau, Power BI, SSRS, SSAS, Cognos or BOE preferred \n Project management experience preferred \n Healthcare Payer Software Development experience preferred \n Experience working in an agile development methodology preferred \n DevOps experience (automation of code or workflow through release pipeline) preferred \n Data warehousing development lifecycle preferred \n \n Skills and Abilities \n \n Ability to independently design, develop and debug ETL/ELT, software, or API solutions based on business requirements. \n Ability to independently evaluate the test results of others \n Self-sufficient in ETL/ELT software development with the ability to become self-sufficient in integration tool within one month of completing the training \n Ability to independently create complex integrations to build dimensional databases, data marts, data lake, and cubes \n Ability to create design patterns \n Strong analytical, problem-solving and decision-making skills along with the ability to react quickly to changing requirements due to product limitation or driven by enterprise need \n Ability to independently develop Unit Test Plans and Test Data \n Ability to independently diagnose and resolve the issues found in workflows, mappings, stored procedures, and data pipelines \n Provide guidance to fellow team members in the data analysis effort necessary in following all data integration standards and architecture \n Provide guidance to team members in performing root cause analysis and resolving issues related to data/workflows \n Provide guidance to team members in the development of system and integration test plans \n Provide guidance to team members for executing test plans and documenting the results and discrepancies \n \n Licenses and Certifications \n \n None Required \n \n ACCOUNTABILITIES AND ESSENTIAL FUNCTIONS \n \n Independently analyzes the team\u2019s data integration requirements and creates integration solutions that support the application development efforts. \n Works with senior team members such as the Principal Data Engineers to refine the information architectures and complex data models needed for the team\u2019s work. In addition, guides others on the modification and implementation of database integration solutions built around these models to support business requirements. \n Responsible for the data integration metadata, lineage, and catalog through configuration and parameterization. \n Independently develops, executes and evaluates data quality test plans such that the results and quality of the data assure compliance with corporate expectations. Guides and reviews the work of other team members in this process to ensure accuracy. \n Provides guidance and training to junior team members on data warehousing processes and procedures to junior team members. \n Follows the software development life-cycle as required to ensure that the company meets regulatory requirements. \n \n Additional Accountabilities and Essential Functions \n The Physical Demands described here are representative of those that must be met by an employee to successfully perform the Accountabilities and Essential Functions of the job. Reasonable accommodations may be made to enable an individual with disabilities to perform the essential functions \n \n Perform other job-related duties as assigned, within your scope of responsibilities. \n Job duties are performed in a normal and clean office environment with normal noise levels. \n Work is predominately done while standing or sitting. \n The ability to comprehend, document, calculate, visualize, and analyze are required. \n \n \\#LI_DB1 \n \\#LI-Remote \n An Equal Opportunity Employer \n All BCBSLA EMPLOYEES please apply through Workday Careers. \n PLEASE USE A WEB BROWSER OTHER THAN INTERNET EXPLORER IF YOU ENCOUNTER ISSUES (CHROME, FIREFOX, SAFARI) \n Additional Information \n Please be sure to monitor your email frequently for communications you may receive during the recruiting process. Due to the high volume of applications we receive, only those most qualified will be contacted. To monitor the status of your application, please visit the \"My Applications\" section in the Candidate Home section of your Workday account. \n If you are an individual with a disability and require a reasonable accommodation to complete an application, please contact recruiting@bcbsla.com for assistance. \n In support of our mission to improve the health and lives of Louisianians, Blue Cross encourages the good health of its employees and visitors. We want to ensure that our employees have a work environment that will optimize personal health and well-being. Due to the acknowledged hazards from exposure to environmental tobacco smoke, and in order to promote good health, our company properties are smoke and tobacco free. \n Blue Cross and Blue Shield of Louisiana performs background and pre-employment drug screening after an offer has been extended and prior to hire for all positions. As part of this process records may be verified and information checked with agencies including but not limited to the Social Security Administration, criminal courts, federal, state, and county repositories of criminal records, Department of Motor Vehicles and credit bureaus. Pursuant with sec 1033 of the Violent Crime Control and Law Enforcement Act of 1994, individuals who have been convicted of a felony crime involving dishonesty or breach of trust are prohibited from working in the insurance industry unless they obtain written consent from their state insurance commissioner. \n Additionally, Blue Cross and Blue Shield of Louisiana is a Drug Free Workplace. A pre-employment drug screen will be required and any offer is contingent upon satisfactory drug testing results. \n JOB CATEGORY:   Data Analytics/Warehousing, & Business Intelligence",
        "cleaned_desc": " May participate in vendor negotiations. \n Meets with business owners and stakeholders to refine technical requiremen \n QUALIFICATIONS \n Education \n \n Bachelor's in computer science or related field is required \n Four years of related experience can be used in lieu of a Bachelor\u2019s degree. \n \n Work Experience \n \n Must have a minimum of seven years of professional information technology experience to include a minimum of three years\u2019 experience with deployment and support of ETL, software applications, or web services solutions. \n Requires knowledge in such areas as data mart data warehouse, data lake development, SSISETL/ELT data integration patterns, web and cloud-oriented systems integration and communication-based systems, languages such as C#, Python or Java. Additional training for integration tools used will be supplied. \n Experience in one of the following areas is required: Support of a data warehousing, data mart, data lake, and/or business intelligence environment; Strong ETL development background with Informatica PowerCenter, DataStage, or SSIS; Strong development experience with TeraData, Oracle, SQL Server, Data Lake, or Sybase repositories; Other programming language such as C#, Python, PL/SQL, T-SQL, SparkSQL, NoSQL; Shared API for web or cloud applications development background; Big Data technologies such as Hadoop, Spark, Artificial Intelligence (AI), Machine Learning (ML), Natural Language Processing (NLP); Strong background in software development for applications \n Massively Parallel Processing (MPP) DBMS preferred \n Visualization, Business Intelligence tools or reporting experience with tools such as Tableau, Power BI, SSRS, SSAS, Cognos or BOE preferred \n Project management experience preferred   Healthcare Payer Software Development experience preferred \n Experience working in an agile development methodology preferred \n DevOps experience (automation of code or workflow through release pipeline) preferred \n Data warehousing development lifecycle preferred \n \n Skills and Abilities \n \n Ability to independently design, develop and debug ETL/ELT, software, or API solutions based on business requirements. \n Ability to independently evaluate the test results of others \n Self-sufficient in ETL/ELT software development with the ability to become self-sufficient in integration tool within one month of completing the training \n Ability to independently create complex integrations to build dimensional databases, data marts, data lake, and cubes \n Ability to create design patterns \n Strong analytical, problem-solving and decision-making skills along with the ability to react quickly to changing requirements due to product limitation or driven by enterprise need \n Ability to independently develop Unit Test Plans and Test Data \n Ability to independently diagnose and resolve the issues found in workflows, mappings, stored procedures, and data pipelines \n Provide guidance to fellow team members in the data analysis effort necessary in following all data integration standards and architecture ",
        "techs": [
            "informatica powercenter",
            "datastage",
            "ssis",
            "teradata",
            "oracle",
            "sql server",
            "data lake",
            "sybase",
            "c#",
            "python",
            "pl/sql",
            "t-sql",
            "sparksql",
            "nosql",
            "hadoop",
            "spark",
            "artificial intelligence (ai)",
            "machine learning (ml)",
            "natural language processing (nlp)",
            "tableau",
            "power bi",
            "ssrs",
            "ssas",
            "cognos",
            "boe",
            "agile development methodology",
            "devops"
        ],
        "cleaned_techs": [
            "informatica powercenter",
            "datastage",
            "ssis",
            "teradata",
            "oracle",
            "sql",
            "data lake",
            "sybase",
            "c#",
            "python",
            "pl/sql",
            "t-sql",
            "sparksql",
            "nosql",
            "hadoop",
            "spark",
            "ai",
            "machine learning (ml)",
            "nlp",
            "tableau",
            "powerbi",
            "ssrs",
            "ssas",
            "cognos",
            "boe",
            "agile development methodology",
            "devops"
        ]
    },
    "682785aea274c554": {
        "terms": [
            "data science"
        ],
        "salary_min": 122400.0,
        "salary_max": 162400.0,
        "title": "Program Manager, Strategy and Portfolio Management (SPM)",
        "company": "BeiGene",
        "desc": "BeiGene continues to grow at a rapid pace with challenging and exciting opportunities for experienced professionals. When considering candidates, we look for scientific and business professionals who are highly motivated, collaborative, and most importantly, share our passionate interest in fighting cancer.\n  \n \n \n   General Description:\n  \n \n \n   The team of Strategy and Portfolio Management (SPM) will be responsible for setting feasible DSDI goals, planning business operations, managing DSDI\u2019s data and digital products with focus on the long-term success and ensure the project\u2019s goals match the GSDS and company\u2019s vision and mission.\n  \n \n \n   The SPM members will work with the head of SPM to manage a mix of interrelated, dependent, and connected products and projects within DSDI. The SPM considers the big picture of all projects grouped together-past, present and future to optimize department resources, drive communication, execution and management efficiency. The SPM group is responsible for closely following up on portfolio/program-level key progress, proactively identify major main points and recommend portfolio optimization proposal to DSDI leadership team, followed by actions led by the SPM member via cross-program/function joint efforts.\n  \n \n \n   The member within SPM is responsible to oversee respective program management work and responsible for working with product manager to plan, execute and manage program progress to completion. The member is also encouraged to actively propose new ideas and lead the endorsed program as the team leader.\n  \n \n \n   Essential Functions of the job:\n  \n \n \n \n     Organize meetings for regular program review or program priority and resource allocation review to drive the efficiency of portfolio level communication, discussion and decision making\n    \n \n \n     Support global head of DSDI and/or DSDI leadership team in portfolio management through activities to collect regular program updates, identify key bottleneck and workout feasible issue-addressing proposals and lead follow-up actions\n    \n \n \n     Support to review and recommend proposals from cross-functional teams and product managers to support sustainable growth of DSDI data and digital products\n    \n \n \n     Support to streamline and centralize usage of project management tools to manage dependencies and transparent delivery milestones for data and digital products\n    \n \n \n     Support to create processes to ensure the integrity of information disseminate to portfolio and risk management systems.\n    \n \n \n     Scope and define tasks that fulfill the project vision; manage and document scope using a project management ticketing system such as Jira, Atlassian, Smartsheet\n    \n \n \n     Support or lead communication to cross functionally to ensure understanding of department projects in DSDI teams and other cross-functional stakeholders\n    \n \n \n     Design, manage, and evangelize effective agile workflows; often using Kanban, Scrum, and Data Driven Scrum\n    \n \n \n     Provides regular updates on project status including risks sharing with potential mitigation strategies\n    \n \n \n     May support to review other departments projects for overlap, impact, and consistency\n    \n \n \n     Partners with all functional areas (e.g., R&D, pre-clinical, regulatory, safety, data management, operations, and finance) to refine and build innovative solutions\n    \n \n \n     Outcome driven product mindset to architect technical solutions for complex business problems\n    \n \n \n \n   Supervisory Responsibilities:\n  \n \n \n \n     Not expected\n    \n \n \n \n   Education and Experience Required\n  \n \n \n \n     Bachelors degree required\n    \n \n \n     MS or MBA preferred\n    \n \n \n     4-year degree from an accredited university in Data Analytics, Computer Science, Engineering, Information Systems, or similar quantitative discipline required\n    \n \n \n \n   Computer Skills:\n  \n \n \n \n     Understanding of Software Development Life Cycle (SDLC), Strong communications skills, able to manage a technical data science project.\n    \n \n \n     Understanding of R, Programming languages, (Java, Python), Clinical Trials domain: Electronic Data Capture (EDC), Spotfire\n    \n \n \n     Working knowledge of databases, analytics, AI/ML, engineering, cloud systems, and the data science life cycle.\n    \n \n \n     JIRA, MS project, Smartsheet, Advance power point, MS Visio, Power BI,\n    \n \n \n     Hands-on experience in all or either of the below project management methodologies: Kanban, Scrum/Agile, Data driven Scrum\n    \n \n \n \n   Other Qualifications:\n  \n \n \n \n     Works with independence to lead or support global, cross-functional matrixed teams.\n    \n \n \n     Proven ability for innovation, non-traditional and strategic thinking, proven ability to challenge the status quo and drive change in an organization\n    \n \n \n     Strong organizational, analytical, planning, and decision-making skills\n    \n \n \n     Ability to effectively manage conflicts and negotiations, and influence outcomes without direct authority\n    \n \n \n     Fluent in written and verbal English\n    \n \n \n     Strong analytical and problem-solving skills\n    \n \n \n     Experience in the pharmaceutical/biotechnology portfolio and project management\n    \n \n \n     Experience working in cross-functional team-oriented environments\n    \n \n \n     Understanding of the global drug development with ability to lead or support program management processes.\n    \n \n \n     Understanding of ICH and regulatory environment as it pertains to Statistics and Data Science\n    \n \n \n     Working knowledge of one or more EDC systems, SAS and R preferred\n    \n \n \n \n   Travel:\n  \n \n \n \n     No significant travel expected\n    \n \n \n \n   Education Required:\n  \n \n \n \n     4-year degree from an accredited university in Data Analytics, Computer Science, Engineering, Information Systems, or similar quantitative discipline required\n    \n \n \n     MS or MBA preferred\n    \n \n \n \n   BeiGene Global Competencies\n  \n \n   When we exhibit our values of Patients First, Collaborative Spirit, Bold Ingenuity and Driving Excellence, through our twelve global competencies below, we help get more affordable medicines to more patients around the world.\n  \n \n  Fosters Teamwork \n  Provides and Solicits Honest and Actionable Feedback \n  Self-Awareness \n  Acts Inclusively \n  Demonstrates Initiative \n  Entrepreneurial Mindset \n  Continuous Learning \n  Embraces Change \n  Results-Oriented \n  Analytical Thinking/Data Analysis \n  Financial Excellence \n  Communicates with Clarity \n \n  Salary Range: $122,400.00 - $162,400.00 annually\n  \n   BeiGene is committed to fair and equitable compensation practices. Actual compensation packages are determined by several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, certifications, relevant education or training, and specific work location. Packages may vary by location due to differences in the cost of labor. The recruiter can share more about the specific salary range for a preferred location during the hiring process. Please note that the listed range reflects the base salary or hourly range only. Non-Commercial roles are eligible to participate in the annual bonus plan, and Commercial roles are eligible to participate in an incentive compensation plan. All Company employees have the opportunity to own shares of BeiGene Ltd. stock because all employees are eligible for discretionary equity awards and to voluntarily participate in the Employee Stock Purchase Plan. The Company has a comprehensive benefits package that includes Medical, Dental, Vision, 401(k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness.\n  \n \n \n   We are proud to be an equal opportunity employer and we value diversity. BeiGene does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.",
        "cleaned_desc": "     Scope and define tasks that fulfill the project vision; manage and document scope using a project management ticketing system such as Jira, Atlassian, Smartsheet\n    \n \n \n     Support or lead communication to cross functionally to ensure understanding of department projects in DSDI teams and other cross-functional stakeholders\n    \n \n \n     Design, manage, and evangelize effective agile workflows; often using Kanban, Scrum, and Data Driven Scrum\n    \n \n \n     Provides regular updates on project status including risks sharing with potential mitigation strategies\n    \n \n \n     May support to review other departments projects for overlap, impact, and consistency\n    \n \n \n     Partners with all functional areas (e.g., R&D, pre-clinical, regulatory, safety, data management, operations, and finance) to refine and build innovative solutions\n    \n \n \n     Outcome driven product mindset to architect technical solutions for complex business problems\n    \n \n \n \n   Supervisory Responsibilities:\n  \n \n \n \n     Not expected\n    \n \n \n \n   Education and Experience Required\n  \n \n \n \n     Bachelors degree required     \n \n \n     MS or MBA preferred\n    \n \n \n     4-year degree from an accredited university in Data Analytics, Computer Science, Engineering, Information Systems, or similar quantitative discipline required\n    \n \n \n \n   Computer Skills:\n  \n \n \n \n     Understanding of Software Development Life Cycle (SDLC), Strong communications skills, able to manage a technical data science project.\n    \n \n \n     Understanding of R, Programming languages, (Java, Python), Clinical Trials domain: Electronic Data Capture (EDC), Spotfire\n    \n \n \n     Working knowledge of databases, analytics, AI/ML, engineering, cloud systems, and the data science life cycle.\n    \n \n \n     JIRA, MS project, Smartsheet, Advance power point, MS Visio, Power BI,\n    \n \n \n     Hands-on experience in all or either of the below project management methodologies: Kanban, Scrum/Agile, Data driven Scrum\n    \n \n \n \n   Other Qualifications:\n  \n \n \n \n     Works with independence to lead or support global, cross-functional matrixed teams.\n      \n \n     Proven ability for innovation, non-traditional and strategic thinking, proven ability to challenge the status quo and drive change in an organization\n    \n \n \n     Strong organizational, analytical, planning, and decision-making skills\n    \n \n \n     Ability to effectively manage conflicts and negotiations, and influence outcomes without direct authority\n    \n \n \n     Fluent in written and verbal English\n    \n \n \n     Strong analytical and problem-solving skills\n    \n \n \n     Experience in the pharmaceutical/biotechnology portfolio and project management\n    \n \n \n     Experience working in cross-functional team-oriented environments\n    \n \n \n     Understanding of the global drug development with ability to lead or support program management processes.\n    \n \n \n     Understanding of ICH and regulatory environment as it pertains to Statistics and Data Science\n    \n \n \n     Working knowledge of one or more EDC systems, SAS and R preferred\n    \n \n \n \n   Travel:\n  ",
        "techs": [
            "jira",
            "atlassian",
            "smartsheet",
            "kanban",
            "scrum",
            "data driven scrum",
            "r",
            "java",
            "python",
            "electronic data capture (edc)",
            "spotfire",
            "jira",
            "ms project",
            "smartsheet",
            "advance power point",
            "ms visio",
            "power bi"
        ],
        "cleaned_techs": [
            "jira",
            "atlassian",
            "smartsheet",
            "kanban",
            "scrum",
            "data driven scrum",
            "r",
            "java",
            "python",
            "electronic data capture (edc)",
            "spotfire",
            "ms project",
            "advance power point",
            "ms visio",
            "powerbi"
        ]
    },
    "5cdadde1a9b4d551": {
        "terms": [
            "data science"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Product Manager - Embedded and Data Analytics (Remote)",
        "company": "insightsoftware",
        "desc": "Company Description\n   insightsoftware is a growing, dynamic computer software company that helps businesses achieve greater levels of financial intelligence across their organization with our world-class data driven solutions. At insightsoftware, you will learn and grow in a fast-paced, supportive environment that will take your career to the next level. We are looking for future insighters who can demonstrate teamwork, results orientation, a growth mindset, disciplined execution, and a winning attitude to join our growing team! \n \n \n \n Job Description\n   We are seeking a highly motivated Senior Product Manager within the Global Embedded and Data Analytics team. This new role will be responsible for driving the overall product vision and market strategy, business cases, roadmap, and the achievement of financial and customer experience goals. You are the market, customer, and product expert for your product to the rest of the organization. As a leader for your product, you will develop and execute the commercialization strategy across functions for the products with responsibility for bookings, revenue, retention, and margin. This includes ensuring that all departments are prepared for successful product launches and go-to-market execution. \n  You are also responsible for the overall product life cycle which includes gathering and prioritizing market requirements, determining the right mix of product initiatives that will maximize portfolio ROI, working with the development team on the delivery of capabilities, and confirming that the result meets the specified requirements and objectives. \n  The successful candidate has a blend of visionary and analytical skills, and can account for every dollar we invest in products, how it benefits the customer and creates value, and how/when we make a return on investment. \n  It presents an ideal opportunity for someone with a strong technical background, knowledge and experience working with data analytics tools, who is excited to stay on top of industry trends, business, and customer needs, and create a strategic plan for driving exceptional revenue growth. \n  Responsibilities \n  1. Product knowledge and strategy for the future \u2013  Technical and business understanding \n  a)  Mastery of Your product  \n \n Serve as an expert going deep on how your products work. Understand the data ingest, transform, load, table structures -both inbound and outbound \n  Understand the technical components of your products and be able to identify key stakeholders \n  Recognize product performance from an end-user standpoint including data quality, responsiveness, reliability, etc. \n  Be able to engage in a conversation on all facets of your products, and require others\u2019 input only to go particularly deep \n \n  b)  Mastery of the technology involved in your product  \n \n Be able to engage in discussions regarding whether your product is using the right solutions, and always looking forward to continuously evolve and improve \n  Be able to understand the issues involved in major decisions and provide feedback on architecture, even in areas you are not an expert in \n \n  c)  Mastery of the innovations in your product and the customer domain  \n \n Form and constantly update a viewpoint on how your product fits into the broader domain \n  Constantly re-evaluate how your product is delivering value to the customer/end user/etc. and pivot as needed \n \n \n  2. Stakeholder / Customer Obsession  \u2013 Keeping customers top of mind \n  a)  Own the product roadmaps \n \n  Continually manage the product roadmaps to support product vision and to deliver on key business priorities \n  Map the product roadmaps to a single product release plan and provide visibility to markets and other business stakeholders \n  Maintain documentation of product roadmap and provide visibility to the markets and other business stakeholders \n \n  b)  Be customer obsessed \u2013 ensure your products are working well and evolving appropriately \n \n  Ensure features are built for global functions and markets \n  Conduct business acceptance of features and epics according to the definition of done \n  Conduct regular end-user product feedback sessions and enhance products accordingly \n  Be an advocate for the end-user experience \n  Leverage your team to ensure these aspects are being accounted for \n \n \n  3. Collaboration Capability \u2013  Working with others across the organization \n  a)  Be the catalyst for collaboration \n \n  Join forces with other Product Managers across the organization to ensure alignment and coordination across products as necessary for multi-product work and initiatives \n  Partner with Initiative Leads & Stakeholders to maximize value delivery \n \n  b)  Own the product backlogs \n \n  Participate in Intake Product Triage and decompose ideation tickets into Epics & Features with the help of the product team, Project managers and deployment managers \n  Prioritize the product backlog for all products \n \n \n  4. Capacity and Resource Management \u2013  Managing your product team \n  a)  Manage capacity and demand for team \n \n  Manage allocated resource and capacity including development, market enablement, bug resolution, and testing and reevaluate based on prioritized roadmap \n  Leveraging the product roadmap and release plan, provide capacity forecasting to the rest of the business to ensure end-to-end readiness in support a release/major new feature \n \n \n \n \n Qualifications\n  \n \n  15+ years working with BI and data analytics products in B2B market \n  5+ years of product management or similar experience, especially with business intelligence products in the mid-market to enterprise space \n  Working knowledge of API and cloud-based driven solutions \n  Working knowledge of ML, NLP and data science technologies. AI knowledge is a nice-to-have. \n  Working knowledge of containerized and microservices architecture \n  Skilled at defining and prioritizing product opportunities, building feedback loops, and creating product metrics \n  Experience working with Agile methodology \n  Experience working within a highly distributed, global team \n  Ability to balance growth, innovation and retention \n  Ability to manage product P&L is a nice-to-have \n  Strong presentation and communication skills \n  Ability to work collaboratively with others and navigate complex decision making \n  Ability to interact with customers at a variety of levels and across function \n \n  Additional Information\n   All your information will be kept confidential according to EEO guidelines.    **  At this time insightsoftware is not able to offer sponsorship to candidates who are not eligible to work in the stated work location . ** \n \n  **  At this time insightsoftware is not able to offer sponsorship to candidates who are not eligible to work in the country where the position is located . ** \n  insightsoftware About Us: Hear From Our Team - InsightSoftware (wistia.com)",
        "cleaned_desc": "  \n \n  15+ years working with BI and data analytics products in B2B market \n  5+ years of product management or similar experience, especially with business intelligence products in the mid-market to enterprise space \n  Working knowledge of API and cloud-based driven solutions \n  Working knowledge of ML, NLP and data science technologies. AI knowledge is a nice-to-have. \n  Working knowledge of containerized and microservices architecture \n  Skilled at defining and prioritizing product opportunities, building feedback loops, and creating product metrics \n  Experience working with Agile methodology \n  Experience working within a highly distributed, global team \n  Ability to balance growth, innovation and retention \n  Ability to manage product P&L is a nice-to-have \n  Strong presentation and communication skills \n  Ability to work collaboratively with others and navigate complex decision making \n  Ability to interact with customers at a variety of levels and across function \n \n  Additional Information",
        "techs": [
            "bi and data analytics products",
            "business intelligence products",
            "api",
            "cloud-based driven solutions",
            "ml",
            "nlp",
            "data science technologies",
            "containerized and microservices architecture",
            "agile methodology"
        ],
        "cleaned_techs": [
            "bi and data analytics products",
            "business intelligence products",
            "api",
            "cloud-based driven solutions",
            "ml",
            "nlp",
            "data science technologies",
            "containerized and microservices architecture",
            "agile methodology"
        ]
    },
    "fda20f603a9cd03c": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 187600.0,
        "salary_max": 291500.0,
        "title": "Principal Engineer - Responsible AI",
        "company": "eBay",
        "desc": "Looking for a company that inspires passion, courage and creativity, where you will be on the team shaping the future of global commerce? Want to shape how millions of people buy, sell, connect, and share around the world? If you\u2019re interested in joining a purpose driven community that is dedicated to crafting an ambitious and inclusive work environment, join eBay \u2013 a company you can be proud to be with. \n  We are seeking a highly skilled and experienced Principal Applied Researcher in Responsible AI to join our team. In this role, you will lead the development of our AI products and services, ensuring they align with the company's values and ethical standards. You will work closely with cross-functional teams to drive innovation and deliver high-quality AI products to our customers. \n  Responsibilities: \n \n  Lead end-to-end research to understand how AI systems can be designed with fairness, interpretability, privacy, security, safety, and robustness as first-class concerns alongside business performance. \n  Collaborate with applied researchers and applied engineering teams to drive multiple research projects. \n  Formulate problems, gather data, generate hypotheses, develop models and algorithms, conduct experiments, synthesize results, and build prototype applications to deliver high-impact business applications. \n  Participate in top-tier academic conferences to broaden the impact of your contributions, both in general AI and Machine Learning conferences as well as specialized conferences on responsible AI, fairness, ethics, and/or eCommerce. \n  Collaborate with senior leaders to help define, build, and transform our businesses with a long-term goal of eliminating structural inequality and potential systemic racism in our services. \n  Act as a subject matter expert and thought leader in responsible AI, presenting at industry conferences, and contributing to publications and thought leadership content. \n \n  Preferred Qualifications: \n \n  PhD in Computer Science (especially AI/ML) or related fields \n  Research publications in prominent AI/ML venues such as conference or journals, especially in the area of responsible AI such as ACM FAccT; AAAI AI, Ethics and Society; or similar \n  Strong expertise in fairness, ethics, interpretability, safety, robustness, and/or privacy in the context of AI/ML. \n  Deep understanding of responsible AI topics such as formal verification techniques for machine learning models; statistical measures of fairness and their relationship with legal, philosophical and socio-technical concerns; differential privacy; robust machine learning; causal inference; moral ambiguity; strategic classification; and counterfactual analysis. \n  Practical experience with ML platforms such as PyTorch, Tensorflow, Keras, etc. \n  Comfort with rapid prototyping and disciplined software development processes \n  Practical software engineering experience in collaborative project settings. \n \n  Minimum Requirements: \n \n  Masters degree or PhD with relevant work experience in Computer Science, Statistics, Engineering or related fields \n  Extensive programming skills in Python, Julia, Java, C++, or similar programming languages used in production machine learning and data science \n  Proficient understanding of fundamental AI and ML techniques; e.g., optimization, regularization, as well as fairness concepts such as fairness-performance trade-offs and statistical metrics of fairness \n  Practical data science experience with real world data \n \n \n  The pay range for this position at commencement of employment in California, Washington, or New York is expected in the range below.  $187,600 - $291,500\n   Base pay offered may vary depending on multiple individualized factors, including location, skills, and experience. The total compensation package for this position may also include other elements, including a target bonus and restricted stock units (as applicable) in addition to a full range of medical, financial, and/or other benefits (including 401(k) eligibility and various paid time off benefits, such as PTO and parental leave). Details of participation in these benefit plans will be provided if an employee receives an offer of employment. \n  If hired, employees will be in an \u201cat-will position\u201d and the Company reserves the right to modify base salary (as well as any other discretionary payment or compensation program) at any time, including for reasons related to individual performance, Company or individual department/team performance, and market factors. \n \n  eBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible. View our accessibility info to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities. For more information see: EEO is the Law Poster and EEO is the Law Poster Supplement. \n \n  Jobs posted with location as \"Remote - United States (Excludes: HI, NM)\" excludes residents of Hawaii and New Mexico.",
        "cleaned_desc": "  Research publications in prominent AI/ML venues such as conference or journals, especially in the area of responsible AI such as ACM FAccT; AAAI AI, Ethics and Society; or similar \n  Strong expertise in fairness, ethics, interpretability, safety, robustness, and/or privacy in the context of AI/ML. \n  Deep understanding of responsible AI topics such as formal verification techniques for machine learning models; statistical measures of fairness and their relationship with legal, philosophical and socio-technical concerns; differential privacy; robust machine learning; causal inference; moral ambiguity; strategic classification; and counterfactual analysis. \n  Practical experience with ML platforms such as PyTorch, Tensorflow, Keras, etc. \n  Comfort with rapid prototyping and disciplined software development processes \n  Practical software engineering experience in collaborative project settings. \n    Minimum Requirements: \n \n  Masters degree or PhD with relevant work experience in Computer Science, Statistics, Engineering or related fields \n  Extensive programming skills in Python, Julia, Java, C++, or similar programming languages used in production machine learning and data science \n  Proficient understanding of fundamental AI and ML techniques; e.g., optimization, regularization, as well as fairness concepts such as fairness-performance trade-offs and statistical metrics of fairness \n  Practical data science experience with real world data \n ",
        "techs": [
            "acm facct",
            "aaai ai ethics and society",
            "responsible ai",
            "formal verification techniques",
            "statistical measures of fairness",
            "differential privacy",
            "robust machine learning",
            "causal inference",
            "moral ambiguity",
            "strategic classification",
            "counterfactual analysis",
            "pytorch",
            "tensorflow",
            "keras",
            "python",
            "julia",
            "java",
            "c++",
            "optimization",
            "regularization."
        ],
        "cleaned_techs": [
            "acm facct",
            "aaai ai ethics and society",
            "responsible ai",
            "formal verification techniques",
            "statistical measures of fairness",
            "differential privacy",
            "robust machine learning",
            "causal inference",
            "moral ambiguity",
            "strategic classification",
            "counterfactual analysis",
            "pytorch",
            "tensorflow",
            "keras",
            "python",
            "julia",
            "java",
            "c++",
            "optimization",
            "regularization."
        ]
    },
    "7b6fe4456f9dcada": {
        "terms": [
            "data science",
            "machine learning engineer"
        ],
        "salary_min": 95300.0,
        "salary_max": 138200.0,
        "title": "Senior Engineer / Machine Learning - Remote",
        "company": "Gap Inc.",
        "desc": "About Gap Inc. \n Our brands bridge the gaps we see in the world. Old Navy democratizes style to ensure everyone has access to quality fashion at every price point. Athleta unleashes the potential of every woman, regardless of body size, age or ethnicity. Banana Republic believes in sustainable luxury for all. And Gap inspires the world to bring individuality to modern, responsibly made essentials.  \n This simple idea\u2014that we all deserve to belong, and on our own terms\u2014is core to who we are as a company and how we make decisions. Our team   is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet. Ready to learn fast, create with audacity and lead boldly? Join our team. \n  About the Role \n  In this role, you will design highly scalable and high performing technology solutions in an Agile work environment and produce and deliver code and/or test cases using your knowledge of software development and Agile practice. You will collaborate closely with business support teams, product managers, security and architecture to assist in resolving critical production issues to help simplify and improve business processes through the latest in technology and automation. You are a technical expert that will lead through the requirements gathering, design, development, deployment, and support phases of a product. You are proficient in at least one core programming languages or packages. \n  What You'll Do \n \n  Define technical specifications and development requirements that result in high performing technologies that are also domain specific. \n  Develop and enhance product and/or applications with limited direction to solve business problems of medium complexity by keeping customer experience at the forefront. \n  Adopt and model a DevOps mindset by applying automation, continuous integration and continuous delivery in everything we do. \n  Foster innovation by applying best practices and learning from emerging technologies and through collaboration with cross functional stakeholders. \n  Serve as application expert in support of domain areas. \n  Communicate difficult concepts, providing technical and professional interpretations and recommendations. \n  Advise and mentor junior team members and enable collaboration to help teams achieve their best. \n \n  Who You Are \n \n  Software Development experience and understanding of security, secure coding/testing and data structures and aware of industry and competitor practices. \n  Comprehensive knowledge of software development, practice, concepts and technology. \n  Proficiency with various software languages and platforms such as Java, Oracle, Azure etc. \n  Experience with related technology stack and platforms. \n  Experience with building and sustaining effective relationships with immediate team and stakeholders. \n \n  Benefits at Gap Inc. \n \n Merchandise discount for our brands: 50% off regular-priced merchandise at Old Navy, Gap, Banana Republic and Athleta, and 30% off at Outlet for all employees. \n One of the most competitive Paid Time Off plans in the industry.* \n Employees can take up to five \u201con the clock\u201d hours each month to volunteer at a charity of their choice.* \n Extensive 401(k) plan with company matching for contributions up to four percent of an employee\u2019s base pay.* \n Employee stock purchase plan.* \n Medical, dental, vision and life insurance.* \n See more of the benefits we offer. \n \n \n For eligible employees \n \n  Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. In 2022, we were recognized by Forbes as one of the World's Best Employers and one of the Best Employers for Diversity.    Salary Range: $95,300 - $138,200 USD  Employee pay will vary based on factors such as qualifications, experience, skill level, competencies and work location. We will meet minimum wage or minimum of the pay range (whichever is higher) based on city, county and state requirements.     US Candidates  Please note that effective, June 30, 2022, Gap Inc. will no longer require any of its employees to wear face masks or require proof of COVID vaccination, unless required by local or state/provincial mandates or as part of Gap Inc\u2019s quarantine guidelines after being exposed to or testing positive for COVID. Therefore, please disregard any language in any job posting that refers to Gap Inc.\u2019s face mask and proof of vaccination policy as said policy is no longer effective.",
        "cleaned_desc": " \n  Who You Are \n \n  Software Development experience and understanding of security, secure coding/testing and data structures and aware of industry and competitor practices. \n  Comprehensive knowledge of software development, practice, concepts and technology. \n  Proficiency with various software languages and platforms such as Java, Oracle, Azure etc. \n  Experience with related technology stack and platforms. ",
        "techs": [
            "java",
            "oracle",
            "azure"
        ],
        "cleaned_techs": [
            "java",
            "oracle",
            "azure"
        ]
    },
    "94a28e4276f8bf2c": {
        "terms": [
            "data science",
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 124785.82,
        "salary_max": 158006.66,
        "title": "Machine Learning Ops/DevOps Senior Engineer",
        "company": "Dell Technologies",
        "desc": "Machine Learning Ops/DevOps Senior Engineer \n  Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What\u2019s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data. \n  Our data scientists & engineers are helping to shape our marketing strategy for a digital world and at scale. We are looking for a DevOps Engineer to take care of our Machine Learning Models in production. \n  What you'll achieve: \n  This position will merge DevOps, software engineering, data science, and data engineering to deploy machine learning models that can optimize business and customer experiences at scale. You will use your technical knowledge and software development to build technology-centric solutions that accelerate the development of Artificial Intelligence and Machine Learning capabilities across the company. \n  You will take out the debate of what can be launched and when. The models that we build are essential ingredients to supply our customers & sales with relevant product recommendations and creative breakthroughs to our business. You & your team are critical for our success! \n  You will: \n \n  Develop high availability and highly scalable applications which will be used by both internal and external customers. \n  Participate in product development in all stages from planning and design to development, testing and documentation of ML solutions and data products. \n  Generate technical documentation as well as unit and functional tests. \n  Adhere to DevSecOps practices to protect underlying data/infrastructure assets. \n  Utilize a range of applicable technologies across the entire Model Lifecycle (e.g., data science packages, statistical and machine learning techniques, distributed computing, Big Data, CI/CD). \n \n  Take the first step towards your dream career  \n Every Dell Technologies team member brings something unique to the table. Here\u2019s what we are looking for with this role: \n  Essential Requirements: \n \n  Engineering Degree in Computer Science/Engineering and relevant professional experience in the field \n  Strong hands-on experience in Linux/Cloud environment and scripting languages as Python (including unittest or pytest) and Shell \n  Experience designing and developing APIs in Python (FastAPI, Flask or Django) \n  Excellent knowledge of software development and software testing methodologies along with configuration management practices in Linux-based environments. \n  Experience working with Docker, Kubernetes in a microservices architecture. \n \n  Desirable Requirements: \n \n  Experience in automating Continuous Integration, Continuous Delivery and Agile practices for highly scalable systems \n  Machine Learning or Artificial Intelligence experience \n \n  Who we are \n  We believe that each of us has the power to make an impact. That\u2019s why we put our team members at the center of everything we do. If you\u2019re looking for an opportunity to grow your career with some of the best minds and most advanced tech in the industry, we\u2019re looking for you. \n  Dell Technologies is a unique family of businesses that helps individuals and organizations transform how they work, live and play. Join us to build a future that works for everyone because Progress Takes All of Us. \n  Application closing date:  September 27th - 2023 \n  Dell Technologies is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.",
        "cleaned_desc": "  You will: \n \n  Develop high availability and highly scalable applications which will be used by both internal and external customers. \n  Participate in product development in all stages from planning and design to development, testing and documentation of ML solutions and data products. \n  Generate technical documentation as well as unit and functional tests. \n  Adhere to DevSecOps practices to protect underlying data/infrastructure assets.    Engineering Degree in Computer Science/Engineering and relevant professional experience in the field \n  Strong hands-on experience in Linux/Cloud environment and scripting languages as Python (including unittest or pytest) and Shell \n  Experience designing and developing APIs in Python (FastAPI, Flask or Django) \n  Excellent knowledge of software development and software testing methodologies along with configuration management practices in Linux-based environments. \n  Experience working with Docker, Kubernetes in a microservices architecture. \n ",
        "techs": [
            "fastapi",
            "flask",
            "django",
            "python",
            "linux",
            "shell",
            "unittest",
            "pytest",
            "docker",
            "kubernetes"
        ],
        "cleaned_techs": [
            "fastapi",
            "flask",
            "django",
            "python",
            "linux",
            "shell",
            "unittest",
            "pytest",
            "docker",
            "kubernetes"
        ]
    },
    "d5d962943d8592a9": {
        "terms": [
            "data science"
        ],
        "salary_min": 71900.23,
        "salary_max": 91041.71,
        "title": "US CX Analytics Manager",
        "company": "Carenet Health",
        "desc": "Overview: \n  \n   Are you passionate about enhancing the customer experience in the rapidly evolving telehealth industry? Do you have a knack for extracting actionable insights from data to drive improvements? If so, we have an exciting opportunity for you! Carenet Health is looking for a Customer Experience Analytics Manager to join our dynamic team and help us elevate the quality of care and service we provide to our patients.\n  \n \n \n  As the \n   CX Analytics Manager,  you will play a pivotal role in shaping and enhancing our customer experience by leveraging data and analytics to derive actionable insights. You will lead a team of analysts, working closely with cross-functional departments to identify opportunities for improvement, optimize customer interactions, and drive business growth. The CX Analytics Manager is tasked to design and develop new, breakthrough methods in data analysis that can be utilized to positively impact Operations metrics, save costs, and earn \u201csoft dollars\u201d in relationship points that establish Carenet as a trusted partner of our strategic clients. This position requires a combination of strong analytical skills, leadership abilities, and a deep understanding of customer experience strategies.\n  \n \n \n  Why Carenet? \n \n \n   For more than 30 years, Carenet Health has pioneered advancements for an experience that touches all points across the healthcare consumer journey. In fact, we interact with 1 in 3 Americans every day, delivering positive healthcare experiences and improving outcomes. From best-in-class clinical expertise to personalized and automated solutions, we integrate the power of human touch with data-driven technology in our mission to make healthcare \n   better for all. \n \n \n  Responsibilities: \n  \n Conduct in-depth analysis of customer data to identify trends, patterns, and opportunities for improvement. \n  Develop and maintain key performance indicators (KPIs) related to customer experience. \n  Translate data findings into actionable insights and recommendations for the organization. \n  Lead at least three projects and participate in three projects as the backup analyst per calendar year.  \n Lead and support domestic/global Professional Services and CX Analytics projects \n  Foster a culture of continuous learning and professional development within the team. \n  Identifies training opportunities through CX Analytics projects and works with VP of Training to operationalize project findings \n  Set performance goals and provide regular feedback to team members. \n  Collaborate with various departments, including marketing, product development, and customer support, operations and sales to implement CX initiatives. \n  Work closely with data scientists, IT, and business intelligence teams to ensure data accuracy and availability. \n  Identify and prioritize initiatives aimed at enhancing the overall customer experience. \n  Monitor the impact of implemented changes and make adjustments as necessary. \n  Ensure data privacy and compliance with relevant regulations (e.g., GDPR, CCPA) in all CX analytics activities. \n  Qualifications: \n  \n Bachelor's degree in Business, Analytics, Data Science, or a related field (Master's degree preferred). \n  Minimum 3-5 years\u2019 experience in working with customers of varied technical knowledge and business needs, of which one to two years were spent in Customer-Experience-related roles \n  Minimum 1 year in data analysis and data interpretation \n  Ability to work through difficult situations with professionalism and diplomacy, strong ability to indirectly influence others.  \n Demonstrated ability in team building, coaching, and remote training.  \n High level of energy and ability to function in a fast-paced environment \n  Excellent organization, project management, presentation, and interpersonal skills \n  Strong proficiency in data analytics tools such as SQL, Tableau, Power BI, or similar. \n  Superior Microsoft Word, Excel, and PowerPoint skills, with an emphasis on Excel Pivot Tables \n  Can interface effectively and professionally with all levels of management both internally, and with key Client/Prospect contacts \n  Be able to work on-site at the San Antonio Corporate office a minimum of 4 days per week. \n \n \n  We\u2019re searching for the market\u2019s strongest candidate to join our group of innovators, collaborators, and builders in pioneering the next phase of Carenet\u2019s place in healthcare history. If this sounds like you, we need to connect! \n \n \n \n  More About Carenet Health \n \n \n  Carenet Health delivers multi-dimensional value to healthcare organizations in areas such as revenue optimization, cost containment and consumer experience. Our clients choose us\u2014and stay with us for an average of seven years or more\u2014because of our clinical expertise and our experience creating meaningful connections that deliver impact and ROI. \n \n \n  Our solutions include multi-channel consumer engagement programs that support quality and satisfaction performance metrics, as well as on-demand clinical engagement and telehealth services that improve care and lower costs. Intelligent contact strategies, empathy-focused interactions, high-touch navigation assistance and best-in-class partners are a few of the key factors in our success. \n \n \n   Learn more at carenethealthcare.com",
        "cleaned_desc": " Lead and support domestic/global Professional Services and CX Analytics projects \n  Foster a culture of continuous learning and professional development within the team. \n  Identifies training opportunities through CX Analytics projects and works with VP of Training to operationalize project findings \n  Set performance goals and provide regular feedback to team members. \n  Collaborate with various departments, including marketing, product development, and customer support, operations and sales to implement CX initiatives. \n  Work closely with data scientists, IT, and business intelligence teams to ensure data accuracy and availability. \n  Identify and prioritize initiatives aimed at enhancing the overall customer experience. \n  Monitor the impact of implemented changes and make adjustments as necessary. \n  Ensure data privacy and compliance with relevant regulations (e.g., GDPR, CCPA) in all CX analytics activities. \n  Qualifications: \n  \n Bachelor's degree in Business, Analytics, Data Science, or a related field (Master's degree preferred).    Minimum 3-5 years\u2019 experience in working with customers of varied technical knowledge and business needs, of which one to two years were spent in Customer-Experience-related roles \n  Minimum 1 year in data analysis and data interpretation \n  Ability to work through difficult situations with professionalism and diplomacy, strong ability to indirectly influence others.  \n Demonstrated ability in team building, coaching, and remote training.  \n High level of energy and ability to function in a fast-paced environment \n  Excellent organization, project management, presentation, and interpersonal skills \n  Strong proficiency in data analytics tools such as SQL, Tableau, Power BI, or similar. \n  Superior Microsoft Word, Excel, and PowerPoint skills, with an emphasis on Excel Pivot Tables \n  Can interface effectively and professionally with all levels of management both internally, and with key Client/Prospect contacts \n  Be able to work on-site at the San Antonio Corporate office a minimum of 4 days per week. \n \n ",
        "techs": [
            "sql",
            "tableau",
            "power bi",
            "microsoft word",
            "excel",
            "powerpoint"
        ],
        "cleaned_techs": [
            "sql",
            "tableau",
            "powerbi",
            "microsoft",
            "excel",
            "powerpoint"
        ]
    },
    "cc63864bc25d907c": {
        "terms": [
            "data science"
        ],
        "salary_min": 75.0,
        "salary_max": -1.0,
        "title": "Computer Vision/Deep Learning Scientist(Remote, w2 / 1099 candidates)",
        "company": "Aptonet Inc.",
        "desc": "Computer Vision/Deep Learning Scientist(Remote, w2 / 1099 candidates) 100% Remote Long term contract \n Computer Vision/Deep Learning Scientists work with various product teams across various business units to define high-impact business problems, solve them using novel techniques, and execute and monitor them throughout their lifecycle. \n 1. Design, develop, and implement novel computer vision algorithms for unique use cases. \n 2. Evaluate accuracy and quality of the designed models as well as data sources. \n 3. Conduct research to stay up to date with the latest technologies/algorithms. They are very collaborative. \n 4. Work on dedicated GPU machines and run your models in parallel on GPU Clusters. \n Required Experience: \n 1. Advanced skills with computers and proficiency with Open-Source tools and technologies such as Tensorflow, Keras, PyTorch, and MXNet for Deep Learning, and OpenCV for traditional Computer Vision. \n 2.  5+ years of Python expertise and experience with TensorFlow and PyTorch   is a MUST. This role requires heavy Python coding. \n 3.  Experience with Computer Vision (image) processing using Deep Learning (Image classification, semantic segmentation, object detection, classification, localization, etc.). \n 4. Familiar with cutting-edge deep learning model architecture, like YOLO, SSD, ResNet, FastRCNN, etc. \n 5. Familiarity with various CNN architectures (VGG16, ResNet, MobileNet, etc.). \n 6. Experience with traditional image processing techniques (e.g., use of OpenCV, skimage). \n 7. Experience with Deep Learning \u201cImage and Video\u201d Processing/Analytics, not text or numerical data. \n Education Bachelor\u2019s, Master\u2019s or Ph.D. in Computer Science, Electrical Engineering, Machine Learning, ECE, Statistics, Physics. Math. \n Benefits (employee contribution): \n \n Health insurance \n Health savings account \n Dental insurance \n Vision insurance \n Flexible spending accounts \n Life insurance \n Retirement plan \n \n All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \n Job Type: Contract \n Pay: From $75.00 per hour \n Benefits: \n \n 401(k) matching \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Retirement plan \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": " 2.  5+ years of Python expertise and experience with TensorFlow and PyTorch   is a MUST. This role requires heavy Python coding. \n 3.  Experience with Computer Vision (image) processing using Deep Learning (Image classification, semantic segmentation, object detection, classification, localization, etc.). \n 4. Familiar with cutting-edge deep learning model architecture, like YOLO, SSD, ResNet, FastRCNN, etc. \n 5. Familiarity with various CNN architectures (VGG16, ResNet, MobileNet, etc.). \n 6. Experience with traditional image processing techniques (e.g., use of OpenCV, skimage). \n 7. Experience with Deep Learning \u201cImage and Video\u201d Processing/Analytics, not text or numerical data. \n Education Bachelor\u2019s, Master\u2019s or Ph.D. in Computer Science, Electrical Engineering, Machine Learning, ECE, Statistics, Physics. Math. \n Benefits (employee contribution): ",
        "techs": [
            "tensorflow",
            "pytorch",
            "yolo",
            "ssd",
            "resnet",
            "fastrcnn",
            "vgg16",
            "mobilenet",
            "opencv",
            "skimage"
        ],
        "cleaned_techs": [
            "tensorflow",
            "pytorch",
            "yolo",
            "ssd",
            "resnet",
            "fastrcnn",
            "vgg16",
            "mobilenet",
            "opencv",
            "skimage"
        ]
    },
    "537cbc7f6b4f1fc0": {
        "terms": [
            "data science"
        ],
        "salary_min": 100000.0,
        "salary_max": 150000.0,
        "title": "Senior Systems Analyst - Cloud FinOps",
        "company": "CyberCoders",
        "desc": "Senior Systems Analyst - Cloud FinOps \n  \n  If you are a Senior Systems Analyst with Cloud FinOps experience, please read on!\n   \n  Headquartered in beautiful Austin TX with remote teams across the nation, we are a booming tech company with a proprietary FinOps platform! Due to growth and demand for our services, we are urgently looking to add several Senior Systems Analysts to our diverse and growing team!\n  \n  Top Reasons to Work with Us \n \n HUGE opportunity for growth! \n Competitive base salary + Equity + Benefits! \n Cutting-edge tech! \n Fully remote opportunity! \n \n  What You Will Be Doing \n \n Evolving a cutting-edge autonomous cloud cost optimization platform  \n Solving complex operational problems \n Working cross-organizationally with world-class teams in engineering, product, and data science \n \n  What You Need for this Position \n \n BS in Mathematics, Computer Science, or equivalent technical degree preferred \n 4+ years of professional experience in financial analysis and cost optimization, preferably with AWS and/or Azure costs \n Strong understanding of Reserved Instances \n Not afraid of math, spreadsheets, and problem solving \n \n  What's In It for You \n \n Competitive base salary ($100-150k DOE) \n Comprehensive benefits package (Medical, Dental, Vision) \n 401k \n Equity \n Unlimited PTO  \n Excellent work/life balance \n Small team culture with no corporate overhead, red tape, or unnecessary meetings \n Extremely well-funded and profitable start-up at critical stage of growth  \n Fun and innovative company culture with strong collaboration and personal ownership \n \n \n   So, if you are a Senior Systems Analyst with experience, please apply today!\n  \n \n   Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Noah Gjertsen-Illig\n  \n \n Applicants must be authorized to work in the U.S. \n  CyberCoders is proud to be an Equal Opportunity Employer \n \n  All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.\n  \n \n Your Right to Work  \u2013 In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "bcbfabf555e998d4": {
        "terms": [
            "data science"
        ],
        "salary_min": 65.0,
        "salary_max": 70.0,
        "title": "Sr. Data Analyst",
        "company": "The Judge Group",
        "desc": "Our client is currently seeking a \n  Sr. Data Analyst   \n \n \n \n Job Description: \n The Data Analyst is responsible for reviewing data for quality, looking for patterns and trends as well as creation and automation of jobs that make it easier to find data problems and review quality of data as needed. The tools will span from Azure to on-prem as well as the data itself. \n Top 3 Skills:   \n \n Various backgrounds in data acquisition,  \n Data modeling  \n Data manipulation \n \n Essential Job Functions: \n \n Articulate and/or translate business problem statements to data requirements to proactively work on design and analysis prior to system design for timely delivery. \n Create and maintain reports and automation of data quality under purview. \n Understand and review existing data models and patterns to identify improvements, recommend improvements in functionality, performance, etc. \n Ideate and develop multiple options for any given problem and present with sound logic and reasoning. \n Learn and work in a fast-changing technology landscape to design retail systems of the future. \n Become familiar with store and supply chain systems and sources of truth for various master data. \n Recommend and present analysis on data as required. \n Coordinate and align all other technology teams to ensure operational delivery processes are governed and monitored to expedite issue remediation. \n Ability to interact well in a team environment. \n Optional : Proficient in using and designing with ERwin Data Modeler for SQL Server, Cassandra, Kafka, MS Azure Databases and Data Stores, or other similar technologies. \n Well-versed with the concepts and application of entity definition, idempotency, normalization/de-normalization of relational models, naming convention, data types, dimensional modeling and modeling for key-value based databases. \n Demonstrates solid understanding of architectural components and system design principles for effective contribution to all design discussions. \n \n Key Responsibilities: \n \n Standardize and solidify Kroger?s data processes and quality. \n Assist in developing business reporting. \n Increase data availability, standardization, and automation processes. \n Problem solve and investigate issues. \n Participate in all phases of system testing Work successfully in an Agile Project across multiple feature and component teams. \n Complete estimates and work plans in Program Increments (PI) Meetings as appropriate for design, development, implementation, and rollout tasks.",
        "cleaned_desc": " \n Articulate and/or translate business problem statements to data requirements to proactively work on design and analysis prior to system design for timely delivery. \n Create and maintain reports and automation of data quality under purview. \n Understand and review existing data models and patterns to identify improvements, recommend improvements in functionality, performance, etc. \n Ideate and develop multiple options for any given problem and present with sound logic and reasoning. \n Learn and work in a fast-changing technology landscape to design retail systems of the future. \n Become familiar with store and supply chain systems and sources of truth for various master data.   Recommend and present analysis on data as required. \n Coordinate and align all other technology teams to ensure operational delivery processes are governed and monitored to expedite issue remediation. \n Ability to interact well in a team environment. \n Optional : Proficient in using and designing with ERwin Data Modeler for SQL Server, Cassandra, Kafka, MS Azure Databases and Data Stores, or other similar technologies. \n Well-versed with the concepts and application of entity definition, idempotency, normalization/de-normalization of relational models, naming convention, data types, dimensional modeling and modeling for key-value based databases. \n Demonstrates solid understanding of architectural components and system design principles for effective contribution to all design discussions. \n ",
        "techs": [
            "erwin data modeler",
            "sql server",
            "cassandra",
            "kafka",
            "ms azure databases and data stores"
        ],
        "cleaned_techs": [
            "erwin data modeler",
            "sql",
            "cassandra",
            "kafka",
            "ms azure databases and data stores"
        ]
    },
    "dd64f770f2184f09": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 66940.305,
        "salary_max": 84761.336,
        "title": "Data Analyst - Part Time Contract",
        "company": "Origin",
        "desc": "Description: \n  Do You Love Spreadsheets? \n  Have you been wondering why no one seems to appreciate a good macro or the symphony of seamless databases? \n  Do you dream about data and the story it tells? \n  Are you interrupted during that first sip of coffee by a creative idea on how two streams of data can connect to become... one? \n  Are you trying to find that missing puzzle piece of new work that you can't quite put your finger on? \n  Have you even maybe worked in the health industry, with software called Dr. Chrono? (or maybe not that specifically, but you know what we mean when we say EMR) \n  If you've gotten this far, you might be the exact person we're looking for! \n  Origin is seeking a part-time, contract Data Analyst (possible opportunity to grow into a full-time role in 2024 for the right candidate). \n  About You \n  This is not your first data analyst rodeo . You're familiar with startups (ie. messy data that isn't always easy to work with), spreadsheets, gsheets, formulas, macros, databases. You've done this before. For at least 4-5 years if not longer. With an early stage company. Where nothing about the process is plug and play. \n  You're detail-oriented.  REALLY detail oriented. You can quickly see the anomalies in a data-set after working with it just a couple of times. \n  You're proactive, and recognize that not everyone moves as fast as you do . You can see everything that can be fixed and improved, but also understand that they'll need to understand, that change management takes time, and that there's an end-user to receives that data that you put together (who will need to have the bandwidth to assimilate the change too). \n  You believe in leaving things better than you found them . You know that a few tweaks can make some drastic improvements, and are happy to do the work after making sure it's cool to do so and you have the whole picture of everything that's impacted. \n  If you see something, you say something . Often, in the process of collecting, looking at and verifying data, you identify things that are not, technically, your problem. And maybe not even a problem. But better to say something and make sure that there isn't a double charge or double booking, or things were meant to be that way. \n  You're not afraid of the old school manual stuff eithe r. Sometimes we're not in control of all of the technology and reports we need, and must resort to the tried and true manual work. And you're ok with that. \n  About Us \n  Defy the Status Quo \n  Join the team that's setting a new standard for women\u2019s health. \n  Who We Are \n  We're working to raise the standard of care for women and all individuals with vaginal anatomy and to make the highest quality pelvic floor physical therapy as accessible as possible. Every member of our team is critical to this mission. \n  Including you. \n  How we work \n \n  Own it.  We show up with our best work. We\u2019re creative, focused, proactive, and get the details right. \n  Go big.  We have a big vision for women\u2019s health and are energized by our potential impact. We act with urgency, yet remember it\u2019s a long game. \n  Stretch.  Growth can be uncomfortable and progress isn\u2019t always linear. We create a safe space for honest learning, taking risks, and understanding failure. \n  Be generous.  We\u2019re kind, high integrity, and assume the best. We celebrate wins and build each other up. \n \n  What you'll do \n  The team:  The Data Analyst is a new role joining our Finance team. The Finance Dept supports our executive, leadership, clinical, hr, and brand teams with effective reporting on business metrics week to week and month to month. \n  The role:  You\u2019ll undertake data collection from several sources, primarily our Electronic Medical Records (EMR) platform, Dr Chrono. Data is then sorted through different databases and spreadsheets to create reports by type (and a few by function).  Requirements: \n  \n Expert level Microsoft Excel \n  Expert level GSheets \n  Proficiency to expert in data analytics \n  Awesome communication skills \n  Healthcare experience a BIG plus \n  Experience working with an EMR a big BIG plus \n  Experience working with Dr. Chrono makes you a unicorn!",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4df21867db1c03a8": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55.0,
        "salary_max": 60.0,
        "title": "Data Analyst",
        "company": "eTeam Inc.",
        "desc": "Title:  Data Engineer to Build Advanced Search Capability using the Elasticsearch stack Applicant MUST have the following skills: Elasticsearch stack knowledge (demonstrable experience in building search capability tooling using Elasticsearch). Python programming knowledge and experience. Apache Spark, in particular with PySpark API, knowledge and experience. Data pipeline experience. \n \n  Excellent communication skills What Project/Projects will the candidate be working on while on assignment? This data engineer will primarily be building/architecting and upgrading/augmenting a search tool using the Elasticsearch stack to search a big data volume of text documents. This person will be tasked to build a production level search application. We need to build and keep up-to-date Elastic indices to allow users external to our group to be able to search the notes. \n \n \n Primary Responsibilities:  Design and develop production level search application for easy searching of content within a big data medical free text data asset. Work with EHR data across teams with ETL, NLP engineers and data scientists, researchers and clinicians to provide searching services with a high data quality control standard Team Description: You would be part of a small core NLP Team with 15 core team members (data scientists, project manager, medical informaticists, data analysts) with support from 12 clinical annotators integrated into the team via a 3rd party vendor What are the top 5-10 responsibilities for this position? Demonstrable senior proficiency level and knowledge of the Elasticsearch stack. Programming experience, including solid Python experience, following software engineering best practices. \n \n  Experience building and maintaining data pipelines and data assets. Experience Building dashboards and user interfaces using Kibana or other visualization tools. Experience with distributed data processing frameworks such as Spark or MapReduce. Experience as an individual contributor, hands-on developer, non-manager role executing on engineering projects as a primary job responsibility. \n \n  Demonstrated knowledge of data management best practices Main Technologies: Currently the main technologies we are using are Apache Spark, Hadoop, Hive, Luigi, Python (and a little bit of Scala) and the platform we use is the on-prem Hadoop cluster. Candidates should be solid with at least some of these technologies, and follow good engineering practices, such as testing, code reviews and putting in place monitoring systems like dashboards or alerts. Preferred Qualifications: Experience with dashboard development in Elasticsearch Experience with data pipeline frameworks such as Airflow, Luigi or Oozie Experience with cloud-based computing (AWS or Azure) Familiarity with EHR data and standards (HL7 or FHIR) Experience with non-relational data bases Experience with code and process documentation Experience with explaining, educating, presenting and/or training non-engineers on engineering concepts and processes Experience with continuous integration and delivery Where is the work to be performed? remote work We are seeking a Data Engineer who is eager to tackle the challenges of processing vast amounts of EHR data originating from multiple sources. \n \n  You will need to develop a deep understanding of the data and drive efforts to maintain and improve data quality and usability. You should understand the importance and value of writing maintainable, documented, and well-tested code throughout the entire product lifecycle. Above all, you should be curious about what is possible in healthcare with the right tools and infrastructure.",
        "cleaned_desc": "Title:  Data Engineer to Build Advanced Search Capability using the Elasticsearch stack Applicant MUST have the following skills: Elasticsearch stack knowledge (demonstrable experience in building search capability tooling using Elasticsearch). Python programming knowledge and experience. Apache Spark, in particular with PySpark API, knowledge and experience. Data pipeline experience. \n   \n Primary Responsibilities:  Design and develop production level search application for easy searching of content within a big data medical free text data asset. Work with EHR data across teams with ETL, NLP engineers and data scientists, researchers and clinicians to provide searching services with a high data quality control standard Team Description: You would be part of a small core NLP Team with 15 core team members (data scientists, project manager, medical informaticists, data analysts) with support from 12 clinical annotators integrated into the team via a 3rd party vendor What are the top 5-10 responsibilities for this position? Demonstrable senior proficiency level and knowledge of the Elasticsearch stack. Programming experience, including solid Python experience, following software engineering best practices.   \n  Experience building and maintaining data pipelines and data assets. Experience Building dashboards and user interfaces using Kibana or other visualization tools. Experience with distributed data processing frameworks such as Spark or MapReduce. Experience as an individual contributor, hands-on developer, non-manager role executing on engineering projects as a primary job responsibility.   \n  Demonstrated knowledge of data management best practices Main Technologies: Currently the main technologies we are using are Apache Spark, Hadoop, Hive, Luigi, Python (and a little bit of Scala) and the platform we use is the on-prem Hadoop cluster. Candidates should be solid with at least some of these technologies, and follow good engineering practices, such as testing, code reviews and putting in place monitoring systems like dashboards or alerts. Preferred Qualifications: Experience with dashboard development in Elasticsearch Experience with data pipeline frameworks such as Airflow, Luigi or Oozie Experience with cloud-based computing (AWS or Azure) Familiarity with EHR data and standards (HL7 or FHIR) Experience with non-relational data bases Experience with code and process documentation Experience with explaining, educating, presenting and/or training non-engineers on engineering concepts and processes Experience with continuous integration and delivery Where is the work to be performed? remote work We are seeking a Data Engineer who is eager to tackle the challenges of processing vast amounts of EHR data originating from multiple sources.   \n  You will need to develop a deep understanding of the data and drive efforts to maintain and improve data quality and usability. You should understand the importance and value of writing maintainable, documented, and well-tested code throughout the entire product lifecycle. Above all, you should be curious about what is possible in healthcare with the right tools and infrastructure.",
        "techs": [
            "elasticsearch stack",
            "python",
            "apache spark",
            "pyspark api",
            "data pipeline",
            "kibana",
            "hadoop",
            "hive",
            "luigi",
            "scala",
            "elasticsearch",
            "airflow",
            "luigi",
            "oozie",
            "aws",
            "azure",
            "hl7",
            "fhir",
            "non-relational databases",
            "continuous integration and delivery."
        ],
        "cleaned_techs": [
            "elasticsearch stack",
            "python",
            "apache spark",
            "pyspark api",
            "data pipeline",
            "kibana",
            "hadoop",
            "hive",
            "luigi",
            "scala",
            "elasticsearch",
            "airflow",
            "oozie",
            "aws",
            "azure",
            "hl7",
            "fhir",
            "non-relational databases",
            "continuous integration and delivery."
        ]
    },
    "640092e3128b9c12": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 25.0,
        "salary_max": 45.0,
        "title": "Data Analyst - Contract (Part Time)",
        "company": "Origin",
        "desc": "Defy the status quo. \n Join the team that's setting a new standard for women\u2019s health. \n Do You Love Spreadsheets? \n Have you been wondering why no one seems to appreciate a good macro or the symphony of seamless databases? \n Do you dream about data and the story it tells? \n Are you interrupted during that first sip of coffee by a creative idea on how two streams of data can connect to become... one? \n Are you trying to find that missing puzzle piece of new work that you can't quite put your finger on? \n Have you even maybe worked in the health industry, with software called Dr. Chrono? (or maybe not that specifically, but you know what we mean when we say EMR) \n If you've gotten this far, you might be the exact person we're looking for! \n Origin is seeking a part-time, contract Data Analyst (possible opportunity to grow into a full-time role in 2024 for the right candidate). \n About You \n This is not your first data analyst rodeo . You're familiar with startups (ie. messy data that isn't always easy to work with), spreadsheets, gsheets, formulas, macros, databases. You've done this before. For at least 4-5 years if not longer. With an early stage company. Where nothing about the process is plug and play. \n You're detail-oriented.  REALLY detail oriented. You can quickly see the anomalies in a data-set after working with it just a couple of times. \n You're proactive, and recognize that not everyone moves as fast as you do . You can see everything that can be fixed and improved, but also understand that they'll need to understand, that change management takes time, and that there's an end-user to receives that data that you put together (who will need to have the bandwidth to assimilate the change too). \n You believe in leaving things better than you found them . You know that a few tweaks can make some drastic improvements, and are happy to do the work after making sure it's cool to do so and you have the whole picture of everything that's impacted. \n If you see something, you say something . Often, in the process of collecting, looking at and verifying data, you identify things that are not, technically, your problem. And maybe not even a problem. But better to say something and make sure that there isn't a double charge or double booking, or things were meant to be that way. \n You're not afraid of the old school manual stuff eithe r. Sometimes we're not in control of all of the technology and reports we need, and must resort to the tried and true manual work. And you're ok with that. \n About Us \n We're working to raise the standard of care for women and all individuals with vaginal anatomy and to make the highest quality pelvic floor physical therapy as accessible as possible. Every member of our team is critical to this mission. \n Including you. \n How we work \n \n Own it.  We show up with our best work. We\u2019re creative, focused, proactive, and get the details right. \n Go big.  We have a big vision for women\u2019s health and are energized by our potential impact. We act with urgency, yet remember it\u2019s a long game. \n Stretch.  Growth can be uncomfortable and progress isn\u2019t always linear. We create a safe space for honest learning, taking risks, and understanding failure. \n Be generous.  We\u2019re kind, high integrity, and assume the best. We celebrate wins and build each other up. \n \n What you'll do \n The team:  The Data Analyst is a new role joining our Finance team. The Finance Dept supports our executive, leadership, clinical, hr, and brand teams with effective reporting on business metrics week to week and month to month. \n The role:  You\u2019ll undertake data collection from several sources, primarily our Electronic Medical Records (EMR) platform, Dr Chrono. Data is then sorted through different databases and spreadsheets to create reports by type (and a few by function). \n Requirements \n \n Expert level Microsoft Excel \n Expert level GSheets \n Proficiency to expert in data analytics \n Awesome communication skills \n Healthcare experience a BIG plus \n Experience working with an EMR a big BIG plus \n Experience working with Dr. Chrono makes you a unicorn! \n \n Job Types: Temporary, Contract, Part-time \n Pay: $25.00 - $45.00 per hour \n Expected hours: 5 \u2013 15 per week \n Experience level: \n \n 4 years \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "66b0aa82b680dbcb": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 95181.24,
        "salary_max": 120520.664,
        "title": "BI/Data Visualization Analyst",
        "company": "KYM Advisors, Inc",
        "desc": "As the  BI/Data Visualization Analyst , you will play a pivotal role in translating complex data into visually compelling and easy-to-understand dashboards and reports. You will work closely with stakeholders across the organization to gather requirements, design Tableau solutions, and provide insights that drive business growth and efficiency. \n  Key Responsibilities:   \n \n \n Collaborate with business stakeholders to understand data requirements and objectives, and perform data analysis to identify trends, patterns, and insights.  \n \n \n Create interactive and intuitive Tableau dashboards and reports that enable end-users to make data-driven decisions.  \n \n \n Extract, transform, and load (ETL) data from various sources into Tableau, ensuring data accuracy and consistency.  \n \n \n Apply best practices in data visualization to ensure that reports and dashboards are user-friendly and effective.  \n \n \n Identify and implement optimizations for Tableau workbooks and dashboards to enhance performance and responsiveness.  \n \n \n Provide training and support to end-users to help them effectively navigate and utilize Tableau dashboards.  \n \n \n Maintain documentation of Tableau reports, data sources, and ETL processes.  \n \n \n Ensure compliance with data governance and security policies.  \n \n \n Stay up-to-date with Tableau advancements, industry trends, and best practices in BI and data visualization.  \n \n \n Qualifications:   \n \n \n Bachelor's degree in a related field (e.g., Computer Science, Business Analytics) or equivalent work experience.  \n \n \n 7 years of proven experience in data visualization and dashboard development using Tableau Desktop and/or Tableau Server.  \n \n \n Tableau certification, such as Tableau Desktop Specialist, Tableau Desktop Certified Associate, or similar, is preferred.   \n \n \n Proficiency in SQL for data extraction and manipulation.  \n \n \n Strong data analysis and problem-solving skills.  \n \n \n Excellent communication and collaboration abilities.  \n \n \n Familiarity with data warehousing concepts is a plus.",
        "cleaned_desc": " \n \n Maintain documentation of Tableau reports, data sources, and ETL processes.  \n \n \n Ensure compliance with data governance and security policies.  \n \n \n Stay up-to-date with Tableau advancements, industry trends, and best practices in BI and data visualization.  \n   \n Qualifications:   \n \n \n Bachelor's degree in a related field (e.g., Computer Science, Business Analytics) or equivalent work experience.  \n \n \n 7 years of proven experience in data visualization and dashboard development using Tableau Desktop and/or Tableau Server.  \n \n   Tableau certification, such as Tableau Desktop Specialist, Tableau Desktop Certified Associate, or similar, is preferred.   \n \n \n Proficiency in SQL for data extraction and manipulation.  \n \n \n Strong data analysis and problem-solving skills.  \n \n \n Excellent communication and collaboration abilities.  ",
        "techs": [
            "tableau reports",
            "tableau desktop",
            "tableau server",
            "tableau advancements",
            "tableau certification",
            "sql"
        ],
        "cleaned_techs": [
            "tableau reports",
            "tableau desktop",
            "tableau server",
            "tableau advancements",
            "tableau certification",
            "sql"
        ]
    },
    "6a101b24836f0090": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 70800.0,
        "salary_max": 99100.0,
        "title": "Data Analyst II",
        "company": "Wisetack",
        "desc": "At Wisetack, we're building financially responsible consumer lending products that help service-based businesses thrive. \n  Wisetack is a well-funded growing startup founded in 2018 with a leadership team that comes from Lending Club, Affirm, Varo Money and other top FinTech companies. We're backed by leading VCs, including Insight Partners, Greylock, and Bain Capital Ventures, (investors in Airbnb, LinkedIn, Instagram, Dropbox, and many more). \n  We raised a $45M Series B and have invested in our people and technology while growing our partnerships. We grew 10x in 2021, and exceeded the goal of growing 4x in 2022. This is a fun stage in any company's lifecycle where we've got the core foundation built, a healthy growth rate, and a clear path to success, but you'd still be joining early enough to help shape the future of the company. \n  Most recently, we were recognized as the Best Consumer Lending Solution by Finovate Awards and have been selected by LendIt as a 2022 winner in the Best Emerging Lending Platform category for their Fintech Industry Awards. The external recognition is great, but we're equally \u2014 if not more \u2014 happy with the recognition from our customers. Our current NPS rating is a sky-high 78 (industry average hovers around the 40s or 50s, depending on who you ask). We're proud that we're building a product that customers love as well as being recognized as a Great Place to Work by our team members. \n  The Role \n  Wisetack's Treasury Team is engineering the Treasury function of tomorrow through automation ( scaling the business ) and analytics/data insights ( shaping the business) . We are keenly focused on the design and methodology with which we conduct our business. If you get satisfaction out of making something cost-effective, elegant, and efficient, then this might be the role for you. \n  We are seeking a Data Analyst who has strong business acumen with technical aptitude. In this role you will work with large datasets, design and build processes, perform analyses to drive business decisions, develop controls, and mitigate risk. Our team is critical to conducting Wisetack's financial operations. \n  Responsibilities \n \n Run finance-related daily operations, some examples include: \n     \n Validation of loan originations \n Secondary market transactions \n Automation tasks \n \n Strategically design, thoughtfully build and efficiently maintain new solutions to business initiatives in a scalable way \n Embrace and enhance the data-driven culture of the company by providing new and useful data solutions via different mediums (dashboards, automated reports, automated Slack messages etc) \n Empower customer support, product, partnerships and other finance team members by being a subject matter expert and resource for Treasury related items \n Work cross-functionally with Finance, Analytics, Risk, Product, Engineering and Customer Operations \n Develop and maintain Treasury specific datasets and data pipelines \n Support the business and handle ad hoc requests \n Drive adoption of new processes and standard methodologies \n Identify, document and implement changes to enhance controls and mitigate risk \n \n Requirements \n \n A solutions-oriented mindset \n Strong critical thinking and analytical capabilities \n A passion for data and automation \n Keen attention to detail \n Knowledge of SQL \n Python experience or desire to learn relatively quickly \n Excellent communication skills with the ability to simplify and explain complex problems to stakeholders of all levels across multiple functions \n Ability to work on your own and identify value through ambiguity \n Self motivated with a strong curiosity to learn \n Avid team player who delights in helping others and collaborates seamlessly across both technical and non-technical teams \n 3+ years professional experience (role will be calibrated to experience) \n \n Bonus points \n \n Financial Services and/or Fintech experience is a plus \n \n \n \n The range of base salary for the position is between $ 70,800 - $99,100 , plus equity, and  benefits . Please note that the base salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level and competencies. \n  Spend a little time on our About Us page researching our team and our values, and check out our Press page and our blog for more background on what we do. If you think this might be a fit, we'd love to hear from you!",
        "cleaned_desc": " Strong critical thinking and analytical capabilities \n A passion for data and automation \n Keen attention to detail \n Knowledge of SQL \n Python experience or desire to learn relatively quickly \n Excellent communication skills with the ability to simplify and explain complex problems to stakeholders of all levels across multiple functions \n Ability to work on your own and identify value through ambiguity \n Self motivated with a strong curiosity to learn \n Avid team player who delights in helping others and collaborates seamlessly across both technical and non-technical teams ",
        "techs": [
            "strong critical thinking and analytical capabilities",
            "passion for data and automation",
            "keen attention to detail",
            "knowledge of sql",
            "python experience or desire to learn relatively quickly",
            "excellent communication skills",
            "ability to simplify and explain complex problems",
            "ability to work independently and identify value through ambiguity",
            "self-motivated with a strong curiosity to learn",
            "avid team player who collaborates seamlessly."
        ],
        "cleaned_techs": [
            "strong critical thinking and analytical capabilities",
            "passion for data and automation",
            "keen attention to detail",
            "knowledge of sql",
            "python",
            "self-motivated with a strong curiosity to learn",
            "avid team player who collaborates seamlessly."
        ]
    },
    "a7fadda4b5611dcd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40000.0,
        "salary_max": 45000.0,
        "title": "Junior Data Analyst",
        "company": "Utilisave",
        "desc": "Small Team, Huge Impact \n \n \n \n \n      We are a small family, but we encourage initiatives to uncover new business opportunities. \n      \n \n \n \n \n \n \n \n \n Innovation Is Key \n \n \n \n \n      We create a culture of innovation. We promote openness, transparency, and collaboration. \n      \n \n \n \n \n \n \n \n \n Customer Centric \n \n \n \n \n      Our efforts are always focused towards delivering value to our customers.\n      \n \n \n \n \n \n \n \n \n \n \n \n \n \n Professional Development  \n \n \n \n \n      We provide introduction to the industry, offer complete training and continuous support. \n      \n \n \n \n \n \n \n \n \n Recognition \n \n \n \n \n      We acknowledge the efforts of our employees and offer bonuses and commission plans. \n      \n \n \n \n \n \n \n \n \n Benefits \n \n \n \n \n      We offer a competitive salary, excellent health, dental and vision benefits and also a 401K plan.\n      \n \n \n \n \n \n \n \n UtiliSave is seeking qualified candidates for Junior Data Analyst position. This is a business critical hands-on role and the ideal candidate will have a record of success in a role focused on gathering data, cost analysis, analyzing complicated laws and regulations, and identifying cases, opportunities and solutions. This position interfaces directly with customers, so strong communication, presentation and client management skills are also essential. Previous familiarity with utility regulations, rates and billing is a must. \n  Job Type:  Full-Time \n  Location:  Remote, US only \n  Salary:  $40,000 \u2013 $45,000 \n  Responsibilities \n \n  Apply your analytical skills and general business knowledge to identify cost savings opportunities for clients. \n  Use UtiliSave\u2019s proprietary software applications, conduct financial, utility and business analysis of clients\u2019 operations, and initiate action to obtain cost savings for clients. \n  Interface with clients, utility companies, tax authorities, regulatory authorities and government agencies to obtain appropriate information to successfully implement savings opportunities. \n  Match details in complex utility tariff codes against our clients\u2019 usage and practices to identify new savings. \n  Collaborate with our IT group in implementing tools to improve our clients\u2019 accounts review process. \n \n  Requirements \n \n  Working knowledge of one or more programming skills: R, Python, SQL. \n  The ability to grasp and explain technical and legal concepts and business issues. \n  Preferred: 1-2 years of experience in a relevant auditing or analyst role. \n  Preferred: previous experience working with or for a regulated public utility, especially dealing with rate billing analysis and customer interaction. \n  Preferred: college degree in business, finance, mathematics, or other related field. \n \n  Benefits \n \n  401(k) matching \n  Dental insurance \n  Health insurance \n  Life insurance \n  Vision insurance \n  Paid time off \n  Paid sick leave \n  Paid holidays \n  Professional development assistance \n \n  Apply via email to  recruit@utilisave.com . Please include a resume and optional cover letter.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "050fcc5b931eb9d7": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55.0,
        "salary_max": 65.0,
        "title": "Data Analyst",
        "company": "Leadstack Inc",
        "desc": "Job Description \n LeadStack Inc. is an award winning, one of the nation\u2019s fastest growing, certified minority owned (MBE) staffing services provider of contingent workforce. As a recognized industry leader in contingent workforce solutions and Certified as a Great Place to Work, we\u2019re proud to partner with some of the most admired Fortune 500 brands in the world. \n Job Title: Data Analyst (Warehousing Domain Data Interfaces) Location: 100% Remote  Duration: 6+ Months with possible extension  Job ID: 23-01611 \n Pay Range: $55/hr-65/hr. on W2 (DOE) \n Job Description- \n The Data Analyst is responsible for reviewing data for quality, looking for patterns and trends as well as creation and automation of jobs that make it easier to find data problems and review quality of data as needed. The tools will span from Azure to on-prem as well as the data itself. \n Accountable for developing and delivering technological responses to targeted business outcomes. \n \n 3 or more years\u2019 experience with data review, report generation or data related fields. \n Proven communication and presentation skills to effectively communicate information to stakeholders at all levels within the organization. \n Ability to interact well in a team environment. \n Proficient in using and designing with ERwin Data Modeler for SQL Server, Cassandra, Kafka, MS Azure Databases and Data Stores, or other similar technologies. \n Well-versed with the concepts and application of entity definition, idempotency, normalization/de-normalization of relational models, naming convention, data types, dimensional modeling, and modeling for key-value based databases. \n Demonstrates solid understanding of architectural components and system design principles for effective contribution to all design discussions. \n Computer Sciences, IT or IS related associate degree, or a bachelor's degree, mathematics or comparable work experience in an Information Systems position or related business position. \n \n Key Responsibilities: \n \n Articulate and/or translate business problem statements to data requirements to proactively work on design and analysis prior to system design for timely delivery. \n Create and maintain reports and automation of data quality under purview. \n Understand and review existing data models and patterns to identify improvements, recommend improvements in functionality, performance, etc. \n Ideate and develop multiple options for any given problem and present with sound logic and reasoning. \n Learn and work in a fast-changing technology landscape to design retail systems of the future. \n Become familiar with client store and supply chain systems and sources of truth for various master data. \n Recommend and present analysis on data as required. \n Coordinate and align all other technology teams to ensure operational delivery processes are governed and monitored to expedite issue remediation. \n \n To know more about current opportunities at LeadStack, please visit us on https://leadstackinc.com/careers/ \n Should you have any questions, feel free to call me at 628.210.3003 or send an email on nikhil.saxena@leadstackinc.com \n Best, \n Nikhil Kumar Saxena \n Job Type: Contract \n Salary: $55.00 - $65.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Data warehouse: 5 years (Required) \n ERwin Data Modeler: 5 years (Required) \n Microsoft SQL Server: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " Ability to interact well in a team environment. \n Proficient in using and designing with ERwin Data Modeler for SQL Server, Cassandra, Kafka, MS Azure Databases and Data Stores, or other similar technologies. \n Well-versed with the concepts and application of entity definition, idempotency, normalization/de-normalization of relational models, naming convention, data types, dimensional modeling, and modeling for key-value based databases. \n Demonstrates solid understanding of architectural components and system design principles for effective contribution to all design discussions. \n Computer Sciences, IT or IS related associate degree, or a bachelor's degree, mathematics or comparable work experience in an Information Systems position or related business position. \n \n Key Responsibilities: \n \n Articulate and/or translate business problem statements to data requirements to proactively work on design and analysis prior to system design for timely delivery. \n Create and maintain reports and automation of data quality under purview. ",
        "techs": [
            "erwin data modeler",
            "sql server",
            "cassandra",
            "kafka",
            "ms azure databases",
            "ms azure data stores"
        ],
        "cleaned_techs": [
            "erwin data modeler",
            "sql",
            "cassandra",
            "kafka",
            "ms azure databases",
            "ms azure data stores"
        ]
    },
    "9147f60d66feb6bf": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 33.0,
        "salary_max": 37.0,
        "title": "Business Data Analyst",
        "company": "Harvey Nash",
        "desc": "Position: \n Business Data Analyst \n Location: \n Frankfort, KY \n Status: \n Contract \n Estimated Duration: \n Long-term Indefinite \n Starts \n READY TO HIRE \n Job Description Business Analyst (Data Stewardship) who will be housed within the Data Management Branch. The main duties for this position are to help match and maintain data quality for data received from different sources using the IBM  InfoSphere MDM Inspector  application. \n Primary Responsibilities: \n \n Analyze and resolve tasks associated with partially matched information using pre-defined business rules. \n Prioritize and maintain personal workload in the Master Patient Index according to customer requirements . \n Identify and assist on the resolution of data quality issues, such as uniqueness, integrity and accuracy \n Keep KHIE engaged by providing feedback on data quality trends, making sure that they're part of the resolution process. \n Keep management informed on day-to-day activities and potential risks found. \n \n Required Skills: \n \n Ability to deal with ambiguous situations \n Ability to triage and prioritize tasks based on the business needs. \n Knowledge of data quality, data management, and master data management concepts. \n Strong analytical and problem-solving skills; Display strong skills to objectively analyze and evaluate issues. \n Experience reviewing information for accuracy and reporting inconsistencies found. \n Strong Communication Skills. \n Experience in Microsoft Office tools such as Excel, Word, Outlook, etc. \n \n Preferred/Additional (non-required) Skills: \n \n Experience with any tools for  Data Management  capabilities including Data Governance, Data Quality and Master Data Management. \n Detail-oriented. \n \n Job Type: Contract \n Salary: $33.00 - $37.00 per hour \n Benefits: \n \n 401(k) \n Health insurance \n Paid time off \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Master data management: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": " \n Ability to deal with ambiguous situations \n Ability to triage and prioritize tasks based on the business needs. \n Knowledge of data quality, data management, and master data management concepts. \n Strong analytical and problem-solving skills; Display strong skills to objectively analyze and evaluate issues. \n Experience reviewing information for accuracy and reporting inconsistencies found. \n Strong Communication Skills. \n Experience in Microsoft Office tools such as Excel, Word, Outlook, etc. \n \n Preferred/Additional (non-required) Skills: ",
        "techs": [
            "microsoft sql server",
            "tableau",
            "power bi",
            "alteryx",
            "python",
            "r",
            "hadoop",
            "amazon web services (aws)",
            "google cloud platform (gcp)",
            "azure"
        ],
        "cleaned_techs": [
            "microsoft sql server",
            "tableau",
            "powerbi",
            "alteryx",
            "python",
            "r",
            "hadoop",
            "aws",
            "gcp",
            "azure"
        ]
    },
    "ac6d700812e73876": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 64988.168,
        "salary_max": 82289.5,
        "title": "Data Analysis Analyst",
        "company": "HarmonyCares",
        "desc": "Overview: \n  \n   HarmonyCares is one of the nation\u2019s largest home-based primary care practices. HarmonyCares is a family of companies all dedicated to providing high-quality, coordinated health care in the home. This includes HarmonyCares, HarmonyCares Medical Group, HarmonyCares Home Health and HarmonyCares Hospice.\n  \n \n \n  Our Mission \u2013 \u201cThrough Compassionate Patient-Centered Care in the Home; We will Provide Exceptional Outcomes across our Continuum of Services\u201d\n  \n \n \n  Our Values \u2013 Respect, Integrity, Teamwork and Excellence - are leading us to a better tomorrow for patient care.\n  \n \n \n  Why You Should Want to Work with Us \n \n \n  Health, Dental, Vision, Disability & Life Insurance, and much more \n  401K Retirement Plan (with company match) \n  Tuition, Professional License and Certification Reimbursement \n  Paid Time Off, Holidays and Volunteer Time \n  Paid Orientation and Training \n  Great Place to Work Certified  \n Established in 11 states  \n Largest home-based primary care practice in the US for over 28 years, making a huge impact in healthcare today! \n  Responsibilities: \n  \n   The Data Analysis Analyst is responsible for the orchestrating timely, consistent, and accurate inflow/outflow of enterprise data. This includes data-related interaction with clients, business units, and analysts. The DAA is also responsible for locating, making available, and optimizing data for use in downstream analytics or system consumption working in conjunction with Data Engineers.\n  \n \n  Collaborate with extended team members to understand the use-cases around data utilization  and create/document plans that lead to the desired outcome \n  Coordinate the inflow/outflows of data for the organization adhering to data privacy and other  policies \n  Work with Data Engineers and other developers to build both simple and complex data structures  to meet utilization requirements \n  Collaborate with other teams in analytics to develop and implement databases, processes, and  other strategies that optimize efficiency and quality \n  Query raw data as part of discovery and data- quality assessment activities \n  Structure large data sets to find and organize usable information \n  Perform data cleansing to identify erroneous data and initiate corrections needed \n  Creation of rules and other configuration elements within the Enterprise Data Warehouse \n  Direct work and interaction with Data Engineers, DBA\u2019s, Data Analysts, Data Scientists along with  other staff members \n  Perform additional duties as needed \n  Qualifications: \n  \n  Required Knowledge, Skills and Experience \n \n \n  Bachelor\u2019s degree in Computer Science, MIS, Statistics or related field of study \n  2 years or more of experience with supporting clients via data feeds and other inbound/outbound  data exchanges \n  2 years or more of experience with supporting the development of reusable datasets leveraging  TSQL \n  Healthcare experience with a focus on Medicare populations and plans \n  Understanding of Data Governance principles \n  Understanding of Data Modeling concepts \n  Understanding of Data-Privacy Standards (HIPAA/HITRUST) \n  Strong documentation and illustration capabilities related to data and related process flows \n  Strong SQL coding skills including creation/optimization of complex queries, stored procedures,  and views \n  Ability to travel as occasionally needed (up to 3%) \n \n \n \n  Preferred Knowledge, Skills and Experience \n \n \n  Experience in healthcare industry with a focus on risk related data and engagements \n  Experience in healthcare industry with a focus on Quality metrics \n  Experience interacting with large amounts of healthcare data \n  Pay Transparency: Individual compensation packages are based on various factors unique to each candidate, including skill set, experience, qualifications, and other job-related considerations.",
        "cleaned_desc": " Largest home-based primary care practice in the US for over 28 years, making a huge impact in healthcare today! \n  Responsibilities: \n  \n   The Data Analysis Analyst is responsible for the orchestrating timely, consistent, and accurate inflow/outflow of enterprise data. This includes data-related interaction with clients, business units, and analysts. The DAA is also responsible for locating, making available, and optimizing data for use in downstream analytics or system consumption working in conjunction with Data Engineers.\n  \n \n  Collaborate with extended team members to understand the use-cases around data utilization  and create/document plans that lead to the desired outcome \n  Coordinate the inflow/outflows of data for the organization adhering to data privacy and other  policies \n  Work with Data Engineers and other developers to build both simple and complex data structures  to meet utilization requirements \n  Collaborate with other teams in analytics to develop and implement databases, processes, and  other strategies that optimize efficiency and quality \n  Query raw data as part of discovery and data- quality assessment activities \n  Structure large data sets to find and organize usable information    Perform data cleansing to identify erroneous data and initiate corrections needed \n  Creation of rules and other configuration elements within the Enterprise Data Warehouse \n  Direct work and interaction with Data Engineers, DBA\u2019s, Data Analysts, Data Scientists along with  other staff members \n  Perform additional duties as needed \n  Qualifications: \n  \n  Required Knowledge, Skills and Experience \n \n \n  Bachelor\u2019s degree in Computer Science, MIS, Statistics or related field of study \n  2 years or more of experience with supporting clients via data feeds and other inbound/outbound  data exchanges \n  2 years or more of experience with supporting the development of reusable datasets leveraging  TSQL    Healthcare experience with a focus on Medicare populations and plans \n  Understanding of Data Governance principles \n  Understanding of Data Modeling concepts \n  Understanding of Data-Privacy Standards (HIPAA/HITRUST) \n  Strong documentation and illustration capabilities related to data and related process flows \n  Strong SQL coding skills including creation/optimization of complex queries, stored procedures,  and views \n  Ability to travel as occasionally needed (up to 3%) \n \n \n \n  Preferred Knowledge, Skills and Experience \n ",
        "techs": [
            "tsql coding skills",
            "hipaa/hitrust data privacy standards",
            "data modeling concepts"
        ],
        "cleaned_techs": [
            "hipaa/hitrust data privacy standards",
            "data modeling concepts"
        ]
    },
    "b61e50d579e297b5": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 106200.0,
        "salary_max": 242000.0,
        "title": "MUMPS Data Analyst",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Melbourne,FL,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180081\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         MUMPS Data Analyst\n           The Opportunity:  \n As a back-end developer, you know that a good site or system needs the right combination of clean code, APIs, analytics, and infrastructure to develop a user-focused solution. We\u2019re looking for an experienced back-end developer with the software engineering expertise it takes to identify potential risks, contribute to solution development, and create efficient and effective systems for our clients. \n \n  As a back-end developer at Booz Allen, you\u2019ll use the latest architectural approaches and open-source frameworks and tools to deliver solutions. Using your software engineering experience, you\u2019ll work with the development team to create custom tools, systems, and sites with consistent performance and scalability. \n \n  In this role, you\u2019ll make a mission-forward impact as you further your skillset and career. Work with us as we shape systems for the better. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with implementing, maintaining, and supporting agile software development to modernize systems \n  5+ years of experience with software development using basic programming languages, technologies, tools, or web development stacks \n  Experience with Agile methodology, extreme programming, software engineering, product management, and software products \n  Experience with developing and maintaining the technology needed to power the components which enable the user-facing side of enterprise applications databases, conceptualizing and implementing data storage solutions, running performance testing and benchmarking, and optimizing data performance \n  Experience with creating solutions to complex problems in a collaborative, cross-functional team \n  Public Trust \n  Bachelor's degree or 8+ years of experience with software engineering in lieu of a degree \n \n \n   Nice If You Have: \n \n  Experience with Java, JavaScript, SQL, Python, Server-Side Development, Middleware, Application or Data Integration, API Development, Core Application Systems, Node.js, Groovy, Scala, Spring Cloud, Spring Core, Spring-Boot, or Spring Data \n  Experience with writing source code for new applications or generating and enhancing code samples for existing applications \n  Experience with acquiring client requirements and resolving workflow problems through automation optimization \n  Ability to work with automated testing tools to perform testing and maintenance \n  Secret clearance \n  Master\u2019s degree \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $106,200.00 to $242,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  5+ years of experience with software development using basic programming languages, technologies, tools, or web development stacks \n  Experience with Agile methodology, extreme programming, software engineering, product management, and software products \n  Experience with developing and maintaining the technology needed to power the components which enable the user-facing side of enterprise applications databases, conceptualizing and implementing data storage solutions, running performance testing and benchmarking, and optimizing data performance \n  Experience with creating solutions to complex problems in a collaborative, cross-functional team \n  Public Trust \n  Bachelor's degree or 8+ years of experience with software engineering in lieu of a degree \n \n \n   Nice If You Have: \n \n  Experience with Java, JavaScript, SQL, Python, Server-Side Development, Middleware, Application or Data Integration, API Development, Core Application Systems, Node.js, Groovy, Scala, Spring Cloud, Spring Core, Spring-Boot, or Spring Data \n  Experience with writing source code for new applications or generating and enhancing code samples for existing applications \n  Experience with acquiring client requirements and resolving workflow problems through automation optimization \n  Ability to work with automated testing tools to perform testing and maintenance \n  Secret clearance \n  Master\u2019s degree \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n ",
        "techs": [
            "java",
            "javascript",
            "sql",
            "python",
            "server-side development",
            "middleware",
            "application or data integration",
            "api development",
            "core application systems",
            "node.js",
            "groovy",
            "scala",
            "spring cloud",
            "spring core",
            "spring-boot",
            "spring data"
        ],
        "cleaned_techs": [
            "java",
            "javascript",
            "sql",
            "python",
            "server-side development",
            "middleware",
            "application or data integration",
            "api development",
            "core application systems",
            "node.js",
            "groovy",
            "scala",
            "spring cloud",
            "spring core",
            "spring-boot",
            "spring data"
        ]
    },
    "238eb3da8fa5af91": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 41.0,
        "salary_max": 54.0,
        "title": "Business Analyst II",
        "company": "Redwood Credit Union",
        "desc": "Redwood Credit Union is a not-for-profit financial institution that believes in people over profits. Our mission is to passionately serve the best interests of our Members, team members, and communities. Sticking to that vision has made us one of the most loved financial partners in the many communities we serve. In fact, RCU is the 8th largest credit union in California\u2014and growing. Due to this growth, we recently completed construction on our new, 8-acre campus in Napa and are ready to welcome more than 500 valued team members!\n  \n \n \n  Since 1950, Redwood Credit Union has been helping people reach their financial goals and dreams with a focus on helping others. That people-first approach holds true for our employees, too. Our work environment is built on service and trust. It's all possible with a leadership team committed to hiring talented people and helping them develop their careers.\n  \n \n \n  If this sounds like a place you\u2019d like to be, we\u2019re eager to meet you!\n  \n \n \n  Play a key role in technology projects across Redwood Credit Union, working closely with business stakeholders and internal IT team to deliver technology and achieve strategic goals. Use understanding of business processes and technology, critical thinking skills, and ability to collaborate with a diverse set of business partners to design, develop, and deliver solutions for Members, internal team members, and the communities served. The ideal candidate must have a minimum of three (3) years' experience as a Business Analyst to be considered for this role. \n  \n Essential Functions: \n \n  Partner with internal stakeholders of all levels, from front-line team members to senior leadership, to gain understanding and elicit business requirements for project scope. \n  Use NPS and other sources of Member feedback to develop user requirements for public-facing systems (such as RCU website, digital banking, and loan applications). \n  Analyze requirements and develop success criteria and KPIs for technical and process solutions. \n  Manage requirements in multiple SDLCs, including Scrum, Agile, and Waterfall. \n  Conduct impact analysis of process and technical changes. \n  Develop conceptual design for technical solutions. \n  Partner with internal developers and vendor teams to develop detailed designs that meet requirements. \n  Ensure effective security measures are in place and meet RCU and regulatory standards. \n  Document, measure, and analyze as-is processes to determine pain points. \n  Partner with process performers and owners to develop proposed improvements to pain points. \n  Develop success metrics and monitoring procedures for quantifying improvement process improvement benefits. \n  Build and maintain strong relationships with diverse business stakeholders. \n  Facilitate discussions between business leadership and IT. \n  Train and educate staff on technological understanding. \n  Participate in community events. \n  Perform other duties as assigned. \n \n  Minimum Qualifications: \n \n  Knowledge of current business analysis techniques. \n  Knowledge of multiple SDLCs, including Scrum, Agile, and Waterfall. \n  Knowledge of process management techniques. \n  Knowledge of project management techniques. \n  Ability to quickly analyze information and make recommendations. \n  Ability to effectively manage multiple tasks and deadlines simultaneously. \n  Ability to manage, develop, and implement technology related projects. \n  Ability to interact and communicate with outside vendors. \n  Ability to establish and maintain effective working relationships with a diverse group of people. \n  Ability and desire to work in a team environment. \n  Ability to communicate and collaborate with both onshore and offshore vendors. \n  Ability to work weekends and late nights when needed. \n \n  Licenses and Certifications: \n \n  Must maintain a valid California driver\u2019s license. \n  IIBA certification in one or more of the following areas is preferred but not required: Certified Business Analyst Professional (CBAP), Agile Analysis Certification (AAC), Certificate in Product Ownership Analysis (CPOA), Certified Cybersecurity Analyst (CCA), or Certification in Business Data Analytics (CBDA). \n \n  Education/Experience: \n \n  A combination of education and experience equivalent to a bachelor\u2019s degree in Computer Information System, Management Information System, Project Management, or closely related field, with a minimum of three (3) years\u2019 of experience in business analysis, process analysis, system design and integration, or similar. Prior experience in programming and / or financial services is a plus. \n \n \n \n  Base starting hour range: $41. 00 to $54.00 per hour commensurate with experience.\n  \n \n \n  Redwood Credit Union offers a robust benefits package to our eligible employees including:  \n \n \n  Competitive medical, dental, and vision insurance, mental health offerings  \n  Employee performance incentive plan \n  Salary Advancement\u2013 Merit increase based on performance \n  401(k) program with employer match \n  Time Off- Competitive PTO accrual plus 11 paid company holidays and your birthday off! \n \n \n RCU Discounts and Perks-  \n \n \n RCU employees are eligible for a .75% discount off RCU standard collateral auto loans \n RCU employees are eligible for a 1% discount on all recreational or boat loan products \n 2% discount off Visas and LOC Loans through RCU \n 0% interest on garment, fitness, or home office equipment loan of up to $500  \n 100% financing for employee purchased homes! \n \n \n \n \n  Why work for Redwood Credit Union? \n \n \n  Local financial institution, providing unparalleled service since 1950 \n  Top 5 Healthiest Credit Union in the USA, rated by Glatt Consulting \n  Voted Best Places to Work in the North Bay 18 years in a row \n  World-class employee engagement scores \n  Rated Superior in Service by more than 90% of Members, surveyed by SF Gate \n  Recognized by Forbes as one of \u201cAmerica\u2019s Best Small Employers 2023\" \n \n \n \n \n  Internal Team Members \n \n \n   If you are a current Team Member, please apply through the internal careers page located in RCUNET. \n  \n \n   \n \n \n  Service ~ Trust ~ People ~ Cooperation \n \n \n  We are an Equal Opportunity Employer",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "12635f8092ce2603": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 112500.0,
        "salary_max": 137500.0,
        "title": "Data Analyst",
        "company": "Redcloud Consulting",
        "desc": "RedCloud Consulting is a business and IT consulting company with local Puget Sound Enterprise and Mid-sized clients. RedCloud seeks a \n  Data Analyst  to support immediate client operations. Seattle Business Magazine has recognized us, ranked #1 on their \"Best Companies to Work for in Washington\" for Mid-Sized Businesses list, awarded #1 Fastest Growing Company in Washington by Puget Sound Business Journal, and named on the Inc. 500/5000 list.\n  \n \n Responsibilities include but are not limited to: \n \n Gather different data sources (company-wide and product-specific) and create automated extractions and aggregations.  \n Collection and reporting of established KPIs.  \n Define, implement, and further develop metrics and key performance indicators.  \n Co-ordinate with feature engineering teams and partner teams to determine telemetry collection and design requirements.  \n \n Required Knowledge, Skills, and Abilities: \n \n Working knowledge of SQL and/or Kusto. (Azure Data Explorer or Synapse)  \n At minimum foundation knowledge of C#.  \n Experience working with large data sets.  \n Experience with Big Data analytics tools and platforms.  \n Basic knowledge of handling unstructured data formats.  \n Understanding of SCOPE and Cosmos are desirable.  \n Experience with industry analysis packages such as Tableau/Omniture/Power BI etc.  \n Adept at identifying sources of error or bias that would lead to inappropriate recommendation.  \n Experience in correcting for partial or distorted data sets.  \n Ability to identify inconsistencies and redundancies between different data sources.  \n Understanding of basic statistical concepts (sampling, bias, correlation, statistical significance, different distribution types).  \n Basic knowledge of software experimentation.  \n \n  Compensation range for position is $112,500 \u2013 137,500 DOE.\n   Benefits and bonus information can be found at \n  https://www.redcloudconsulting.com/careers.html \n \n  RedCloud requires employees maintain permanent residency within the United States during their employment period. During onboarding, proof of eligibility to work in the United States will be requested. RedCloud does not provide visa sponsorship.\n  \n \n About Us: \n  RedCloud is a boutique, business and technology consulting firm providing local companies with expert-level support for over two decades. Whether it\u2019s to solve a specific business challenge or to provide additional support for an ambitious project, we can help bring even the most visionary endeavors to fruition.\n  \n  Anchored by a foundation of \"integrity-based consulting\", the RedCloud team of subject matter experts collaborate closely with clients to develop and implement high-level solutions, bringing stability, growth, and innovation together for long-term success. We provide a broad array of business and technology consulting services through RedCloud\u2019s core services: Empower Operations, Empower Sales and Marketing, Empower Customers, Empower Security and Privacy. \n  \n  Visit \n  http://www.redcloudconsulting.com/  for more info. \n   #LI-Remote",
        "cleaned_desc": " Define, implement, and further develop metrics and key performance indicators.  \n Co-ordinate with feature engineering teams and partner teams to determine telemetry collection and design requirements.  \n \n Required Knowledge, Skills, and Abilities: \n \n Working knowledge of SQL and/or Kusto. (Azure Data Explorer or Synapse)  \n At minimum foundation knowledge of C#.  \n Experience working with large data sets.    Experience with Big Data analytics tools and platforms.  \n Basic knowledge of handling unstructured data formats.  \n Understanding of SCOPE and Cosmos are desirable.  \n Experience with industry analysis packages such as Tableau/Omniture/Power BI etc.  \n Adept at identifying sources of error or bias that would lead to inappropriate recommendation.  \n Experience in correcting for partial or distorted data sets.  \n Ability to identify inconsistencies and redundancies between different data sources.  \n Understanding of basic statistical concepts (sampling, bias, correlation, statistical significance, different distribution types).  ",
        "techs": [
            "define",
            "implement",
            "and further develop metrics and key performance indicators",
            "sql",
            "kusto",
            "azure data explorer",
            "synapse",
            "c#",
            "big data analytics tools and platforms",
            "handling unstructured data formats",
            "scope",
            "cosmos",
            "tableau",
            "omniture",
            "power bi",
            "error correction in data sets",
            "identifying inconsistencies and redundancies between data sources",
            "basic statistical concepts"
        ],
        "cleaned_techs": [
            "define",
            "implement",
            "and further develop metrics and key performance indicators",
            "sql",
            "kusto",
            "azure",
            "synapse",
            "c#",
            "big data analytics tools and platforms",
            "handling unstructured data formats",
            "scope",
            "cosmos",
            "tableau",
            "omniture",
            "powerbi",
            "error correction in data sets",
            "identifying inconsistencies and redundancies between data sources",
            "basic statistical concepts"
        ]
    },
    "d89f83275cba70e7": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 93478.3,
        "salary_max": 118364.36,
        "title": "Data Analyst Lotus Notes",
        "company": "SMK Soft Inc",
        "desc": "Greetings \n I am seeking for technical consultant like you or someone in your network who may be interested in the opportunity below. \n I am currently seeking to fill  IT Analyst \u2013 Lotus Notes  with one of our direct client and this position is a  REMOTE  role. \n Consultant Support Proven Experience Liaises between product team and business areas to obtain disposition of Lotus Notes ( Previously IBM But Now HCL Domino ) Databases, conducts requirements analysis and validation, ensuring requirements are complete, consistent, concise, comprehensible, traceable, feasible, unambiguous, and verifiable, and that they conform to standards. \n If you are a team player that is eager to support a growing organization while contributing to company success, apply today! \n If you are interested in this opportunity, please send me your updated resume and a good time to connect. today! \n Required Minimum 15 + Years of expert level Leadership experience Consultant. \n Job Title: IT Analyst \u2013 Lotus Notes \n Duration: 12 Months (HYBRID) \n Location: REMOTE \n Job Description: \n \n Liaises between product team and business areas to obtain disposition of Lotus Notes (HCL Domino) Databases. \n Conducts requirements analysis and validation, ensuring requirements are complete, consistent, concise, comprehensible, traceable, feasible, unambiguous, and verifiable, and that they conform to standards. \n Work with business areas to validate and obtain sign off on archived data to proceed with decommission of databases. \n Tracks requirements status throughout project / product lifecycle; manages changes to requirements via board/backlog management and maintenance. \n Creates and communicates artifacts translating business needs into executable requirements. \n \n Pls Fill the Required Skill Matrix: \n JP00011570-IT Analyst \n Experience (Years) \n Self-Rating (1 - 10) 10 being highest \n Lotus Notes Databases \n Requirements analysis \n Validate and obtain sign off on archived data \n Personal Details: \n First Name: \n Middle Name: \n Last Name: \n Mobile #:/ Alternate Contact #: \n Email ID: \n Work Authorization: \n DOB (MM/DD): \n Current Location: \n Willing to relocate: (Y/N) \n LinkedIn ID: \n Currently on Project (Y/N): \n Last date of employment: \n Reason for change: \n Interview preferred timing: \n Availability to join: \n Expected Rate/ Salary: \n Job Type: Full-time \n Experience: \n \n Data Analyst: 10 years (Required) \n Lotus Notes: 10 years (Required) \n Data Archive: 7 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "128abd8d94fed7ea": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 58.0,
        "salary_max": 65.0,
        "title": "Data Analyst/Form Developer - LPLI2126",
        "company": "TechData Service Company, LLC",
        "desc": "Company : Large Pharmaceutical Company \n Title : Data Analyst/Form Developer \n Contract Position : 6 months with potential extensions up to 18 months. \n Type : 100% Remote \n Description : \n \n Extensive experience with Microsoft Excel \n Working knowledge of Adobe Acrobat (Required) \n Form creation \n Implementing JavaScript in Acrobat forms (Required) \n \n \n Working knowledge of computer programming languages including, but not limited to: \n VBA or VB6 (highly desirable) \n Python \n C/C# \n Javascript \n \n \n Some knowledge of Adobe Illustrator (optional) \n Desire to learn and use new software/application \n \n Additional Details: \n \n 3-5 Years of experience \n Possess the ability to hit the ground running \n Prior Life Science/Pharma Industry Preferred \n CMC experience is Highly Preferred \n The ability to hit the ground running with limited training \n Looking for a 1 stop shop for Computer System Validations \n \n Job Type: Contract \n Pay: $58.00 - $65.00 per hour \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n SQL: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "45c361db9f87aa03": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 82627.18,
        "salary_max": 104624.43,
        "title": "Business Analyst Senior",
        "company": "Blue Cross and Blue Shield of Minnesota",
        "desc": "Business Analyst Senior  Remote \n  \n Req ID: R0003888 \n Career Area: Project/Program Mgmt \n Date Posted: 09/18/2023 \n \n \n \n \n \n About Blue Cross \n \n  Blue Cross and Blue Shield of Minnesota is one of the most recognized and trusted health care brands in the world with 2.5 million members. We\u2019re committed to reinventing health care to improve health for our members and the community. We hope you'll join us.\n   \n \n    How Is This Role Important to Our Work?\n   \n  This position is responsible for the analysis, development, support, reporting and coordination of business workflow automation and to implement efficient business processes at an enterprise level. \n  This role is in the payment integrity department and works collaboratively with team members and department/ enterprise associates to support efforts to identify aberrant provider billing. This role conducts programming and development, such as creating and updating claims queries and stored procedures. The role also conducts other technical and development requirements, standing processes (e.g., monthly), and has attention to detail to validate outcomes. \n \n    A Day in the Life:\n   \n \n  Conducts in-depth research and analysis. \n  Identifies trends, emerging issues and recommends best practices to ensure maximum results and develops metrics. \n  Documents metrics and process changes. \n  Effectively analyzes, designs, develops, tests, debugs, implements, maintains and/or enhances new or existing systems through reporting and documentation. \n  Participate in and coordinate individual projects and related activities to ensure project progresses on schedule. \n  Maintains adequate communication regarding project status, risks, issues, and priorities with project sponsors and leadership. \n  Acts as a liaison with internal partners and external partners to identify opportunities and needs and researches/develops implementation plans for meeting these needs. \n  Responsible for representing the customer and/or stakeholder (internal/external) while collaborating with business and technical units. \n  Serves as senior subject matter expert associated with content, processes, and procedures. \n  May lead project teams and may provide training to lower level staff to achieve project milestones and objectives. \n \n \n  Nice to Have:\n   \n \n  Bachelor's degree. \n  Working knowledge of SAP, Visio, or other software programs. \n  2 years of experience using various statistical software and computer programming (e.g., SAS, R, Python, SQL, Visual Basic, DB2, Oracle, etc.) - OR- requires sophisticated understanding/experience with multiple programming languages, systems, systems design and/or software development methodologies. \n  Proven ability to design, evaluate and interpret complex data sets. \n  Ability to perform validation techniques, as well as perform and interpret a variety of statistical analyses. \n  Knowledge of Power BI or other data visualization software preferred, with expertise or an interest in developing programming skills. \n  Sophisticated proficiency in MS Office (Excel, PowerPoint) and virtual platforms such as Skype, Zoom, Microsoft Teams. \n  Ability to interact and communicate optimally with individuals at all levels throughout the company and externally with business leads/ providers at the medical group. \n \n \n    Required Skills and Experiences:\n   \n \n  5+ years of related professional experience. All relevant experience including work, education, transferable skills, and military experience will be considered. \n  Advanced collaborative, interpersonal, oral and written communication skills and demonstrated ability to develop accurate and appropriate communications. \n  Advanced ability to communicate to all levels of management. \n  Advanced research, analytical and problem-solving skills. \n  Advanced skills in Microsoft Excel, Word, and Access. \n  Strong ability to make decisions based on analysis and business needs. \n  Advanced ability to bring a different perspective to situations and challenge the status quo. \n  Project management skills. \n  Proven ability to work independently with guidance in only the most complex situations. \n \n  Make A Difference \n \n  Blue Cross is an Equal Opportunity and Affirmative Action employer that values diversity. All qualified applicants will receive consideration for employment without regard to, and will not be discriminated against based on race, color, creed, religion, sex, national origin, genetic information, marital status, status with regard to public assistance, disability, age, veteran status, sexual orientation, gender identity, gender expression, or any other legally protected characteristic.\n   \n  Reasonable Accommodation for Job Seekers with a Disability: If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to talent.acquisition@bluecrossmn.com.\n   \n  All roles require a high school diploma (or equivalency) and legal authorization to work in the U.S.\n   \n  Blue Cross\u00ae and Blue Shield\u00ae of Minnesota and Blue Plus\u00ae are nonprofit independent licensees of the Blue Cross and Blue Shield Association.",
        "cleaned_desc": "  Working knowledge of SAP, Visio, or other software programs. \n  2 years of experience using various statistical software and computer programming (e.g., SAS, R, Python, SQL, Visual Basic, DB2, Oracle, etc.) - OR- requires sophisticated understanding/experience with multiple programming languages, systems, systems design and/or software development methodologies. \n  Proven ability to design, evaluate and interpret complex data sets. \n  Ability to perform validation techniques, as well as perform and interpret a variety of statistical analyses. \n  Knowledge of Power BI or other data visualization software preferred, with expertise or an interest in developing programming skills. \n  Sophisticated proficiency in MS Office (Excel, PowerPoint) and virtual platforms such as Skype, Zoom, Microsoft Teams. \n  Ability to interact and communicate optimally with individuals at all levels throughout the company and externally with business leads/ providers at the medical group. \n \n \n    Required Skills and Experiences:\n   \n \n  5+ years of related professional experience. All relevant experience including work, education, transferable skills, and military experience will be considered. ",
        "techs": [
            "sap",
            "visio",
            "sas",
            "r",
            "python",
            "sql",
            "visual basic",
            "db2",
            "oracle",
            "power bi",
            "ms office (excel",
            "powerpoint)",
            "skype",
            "zoom",
            "microsoft teams"
        ],
        "cleaned_techs": [
            "sap",
            "visio",
            "sas",
            "r",
            "python",
            "sql",
            "visual basic",
            "db2",
            "oracle",
            "powerbi",
            "microsoft",
            "powerpoint)",
            "skype",
            "zoom",
            "microsoft teams"
        ]
    },
    "261cf7ac41299fa5": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 69450.11,
        "salary_max": 87939.31,
        "title": "Data Analyst",
        "company": "Concurrent Technologies Corporation",
        "desc": "DATA ANALYST (Part Time) \n Concurrent Technologies Corporation \n Remote \n \n Minimum Clearance Required:  Secret  \n Clearance Level Must Be Able to Obtain:  Secret \n Employee Background Check Required \n \n \n \n Key Responsibilities: \n \n Collect, clean, interpret and analyze data for new and ongoing drug trend and drug threat projects and studies.  \n Create data visualizations that clearly communicate and drive data-driven processes. \n Conduct analytical report writing for presentations and policy memoranda. \n Collaborate with Office of Drug Demand Reduction (ODDR) on formation of statistical research designs that create a synthesized strategy for both data collection and analysis for a DoD leadership audience. \n \n \n \n Basic Qualifications: \n \n Bachelor's degree (or higher) in Statistics, Biostatistics, Computer Science, Mathematics, Geospatial Science, or related field and a minimum of 4 years' experience in data analysis. \n  Ability to manipulate and extract data while maintaining utmost confidentiality. \n  Professional knowledge of and skill in applying a wide range of complex analytical and statistical theories, principles, and practices \n  Knowledge of programming languages SQL, python or R and software such as Qlik, Tableau, Power BI, Microsoft Excel, or similar statistical software packages \n  Proficient in the English language in speech, writing, and personal interactions  \n Excellent analytical, organizational and time management skills \n  Strong communication skills, both oral and written \n  U.S. Citizen and able to acquire a DoD Common Access Card (CAC). \n \n \n \n \n Why CTC? \n \n Our teams at CTC are passionate and thrive on collaboration in a team environment \n When we encounter a difficult problem, we have a variety of talented and diverse employees that work together to solve the toughest challenges \n Competitive salary and benefits package \n Although our work at CTC is extremely important, we also recognize the need for our employees to maintain a proper mix of work and personal life \n Visit www.ctc.com (http://www.ctc.com/) to learn more \n \n \n \n Join us!  CTC offers exceptional career growth, cutting edge technology, educational opportunities, and recognition for quality work. \n \n https://concurrent-technologies-corporation.breezy.hr/ \n Staffing Requisition:  SR# 2023-0127 \n \n \u201cWe are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability status, protected veteran status, or any other characteristic protected by law.\u201d",
        "cleaned_desc": " \n Basic Qualifications: \n \n Bachelor's degree (or higher) in Statistics, Biostatistics, Computer Science, Mathematics, Geospatial Science, or related field and a minimum of 4 years' experience in data analysis. \n  Ability to manipulate and extract data while maintaining utmost confidentiality. \n  Professional knowledge of and skill in applying a wide range of complex analytical and statistical theories, principles, and practices \n  Knowledge of programming languages SQL, python or R and software such as Qlik, Tableau, Power BI, Microsoft Excel, or similar statistical software packages \n  Proficient in the English language in speech, writing, and personal interactions  \n Excellent analytical, organizational and time management skills ",
        "techs": [
            "sql",
            "python",
            "r",
            "qlik",
            "tableau",
            "power bi",
            "microsoft excel"
        ],
        "cleaned_techs": [
            "sql",
            "python",
            "r",
            "qlik",
            "tableau",
            "powerbi",
            "excel"
        ]
    },
    "747e80e62dc251b2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 100000.0,
        "salary_max": 110000.0,
        "title": "Sr Business Analyst - big data analytics SaaS, 100% remote, finance data",
        "company": "Relentless Talent",
        "desc": "One of my long term clients is growing again and looking to add a Business Analyst. They are a 16 person company, whom has been steadily growing and looking to add key players. \n For the Business Analyst role they are seeking someone: \n Degree in computer science, information management or related field. \n Experience with system integrations, ETL processes, network security and structure, cloud storage and processing fundamentals, file transmission methods, AWS and Azure environments. \n Strong analytical and problem-solving skills \n Bias towards action \n 5+ years experience, background in data operations systems in an agile environment is a plus \n Proven background participating in large scale initiatives and being self-motivated with little need for oversight \n Comfortable working in a 100% remote distributed team setting \n Please note, as a company they get together 2 times per year for 2 to 3 days. \n Core duties of the role \n \u00b7 Work with current data warehousing vendor and our new managed services provider to gain deep understanding of the current and planned technical infrastructures \n \u00b7 Coordinate with members of the Information Governance & Management team to assess operational system needs during the transformation period and after project completion \n \u00b7 Partner with the Operational Transformation team and new managed services provider to establish roles and responsibilities for support and maintenance of all new and existing systems that are part of the new operational model \n \u00b7 Collaborate with Analytics resources to determine new and expanded systems needs to enable organizational analytic function \n \u00b7 Serve as lead during implementation and integration phase for internal systems \n \u00b7 Support internal information systems and serve as point of contact for users \n \u00b7 Partner with internal resources and/or managed services provider to plan ongoing development efforts \n \u00b7 Coordinate with Senior Manager, Exchange Management on system enhancement and replacement projects \n \u00b7 Collaborate with Senior Manager, Information Quality to ensure systems continually support organizational information management needs \n \u00b7 Serve as the SME on structure and function of the Information Management environment \n Base salary with a 10%+ bonus which has been paid for a number of years, full benefits, 401k and PTO. You will support clients on east coast business hours. \n Feel free to reach out directly if you are qualified: https://www.linkedin.com/in/lou-russo-2ba5006/ \n Job Type: Full-time \n Pay: $100,000.00 - $110,000.00 per year \n Benefits: \n \n 401(k) 3% Match \n Dental insurance \n Health insurance \n \n Compensation package: \n \n Bonus opportunities \n \n Experience level: \n \n 8 years \n \n Schedule: \n \n Monday to Friday \n \n Work Location: Remote",
        "cleaned_desc": "One of my long term clients is growing again and looking to add a Business Analyst. They are a 16 person company, whom has been steadily growing and looking to add key players. \n For the Business Analyst role they are seeking someone: \n Degree in computer science, information management or related field. \n Experience with system integrations, ETL processes, network security and structure, cloud storage and processing fundamentals, file transmission methods, AWS and Azure environments. \n Strong analytical and problem-solving skills \n Bias towards action \n 5+ years experience, background in data operations systems in an agile environment is a plus \n Proven background participating in large scale initiatives and being self-motivated with little need for oversight ",
        "techs": [
            "system integrations",
            "etl processes",
            "network security and structure",
            "cloud storage",
            "processing fundamentals",
            "file transmission methods",
            "aws",
            "azure"
        ],
        "cleaned_techs": [
            "system integrations",
            "etl processes",
            "cloud storage",
            "processing fundamentals",
            "file transmission methods",
            "aws",
            "azure"
        ]
    },
    "7d40b7cd50453e61": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 52554.418,
        "salary_max": 66545.6,
        "title": "Business Analyst",
        "company": "Cognize tech solutions",
        "desc": "Gather data, analyze, and make recommendations to meet project objectives, prepare client presentations, and assist in pre-call planning \uf0b7 Maintain client relationships by consulting on customer and competitor strategies, business solutions, and management decisions. \uf0b7 Create reports and presentations utilizing qualitative analysis regarding companies, markets, and industry trends \uf0b7 Compile and maintain company profiles and reports \uf0b7 Conduct weekly client updates on progress of research both in-person and over the phone \uf0b7 Stay informed of current business and industry trends relevant to your client's business \uf0b7 end-to-end delivery of requirements throughout the life-cycle of the project in alignment with the business and/or enterprise needs and strategies. \uf0b7 Provides leadership and works collaboratively with stakeholders including business, technology and finance partners to support project benefits and changes to business processes, policies and systems across single or multiple Lines of Business (LoB). \n Job Types: Temporary, Internship, Part-time, Full-time \n Pay: $65,000.00 - $80,000.00 per hour \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n SQL: 1 year (Required) \n Business analysis: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4b1235d9a9baed11": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 85000.0,
        "salary_max": 100000.0,
        "title": "Ria Compliance Analyst",
        "company": "My RIA Lawyer",
        "desc": "The compliance analyst is a nerd that LOVES all things compliance and helping firms improve their compliance programs. The ideal candidate will have experience performing compliance testing for broker-dealers and RIAs. The ideal candidate loves working in the background, collaborating when needed, and holds themselves to a high standard of work product and professionalism. \n  Compensation: \n  $85,000 - $100,000 yearly \n  Responsibilities: \n  The successful candidate will: \n \n \n  Support compliance manager \n  Handle amendments to Form ADV and other IARD/CRD filings (e.g U4, U5) and Edgar-based filings (e.g. 13F, 13 H) \n  Work with regulators to achieve registration for RIAs and, as needed, their advisory personnel \n  Review disciplinary matters to ensure that DRPs (Disclosure Reporting Pages) contain proper disclosure \n  Assist with the RIA annual updating amendment/renewal process \n  Coordinate with colleagues (including those in client-facing roles) and directly with RIA clients (as needed) \n  Conduct RIA compliance tasks and testing- best execution review, trading review, billing review, email review, advertising review, social media review, testing archiving, auditing books and records, branch office reviews, risk assessments, etc. \n  Drafts compliance manuals, code of ethics, business continuity plans, and cybersecurity policies and can review and analyze them for required updating \n  Understand SEC rules and regulations and how they apply to advisers \n  Adequately compiles and organizes materials, and compiles relevant documents in databases and network drives to maintain an accessible file \n  Register new firms as independent investment advisers \n  Performs other duties and projects as needed \n \n \n  Qualifications: \n  Experience and Qualifications Required: \n \n \n  Extensive previous experience with Form ADV and other regulatory documents \n  Someone fanatical about client experience with dedication to client responsiveness \n  Passion for working in a fast-paced, small company environment \n  Solution-oriented mindset \n  RIA regulatory and/or NASAA experience \n  Excellent written, organizational, and follow-up skills \n  At least 4 to 7 years working for an RIA or law firm serving RIAs \n \n \n  Other Skills Required: \n \n \n  Attention to detail, with the ability to analyze data, identify trends and escalate matters appropriately \n  Must demonstrate strong critical thinking skills and curiosity \n  Excellent independent follow-up skills \n  Organizational and time management skills; ability to multitask \n  Strong written and oral communication skills among different business audiences \n  Customer service-oriented \n  Accountability is not a problem and consistently meets and surpasses expectations \n \n \n  BENEFITS: \n  We offer a competitive benefits package including medical, dental, and vision coverage, 401(k) with employer match, permanently remote position, all-expense paid firm retreats, and robust PTO and time off policy. \n  About Company \n  About Us : \n \n  We are a forward-thinking and innovative law firm that believes in making a meaningful impact on our clients' lives. Our team is like family, and we're committed to creating a positive and supportive work culture. \n \n  Join Our Growing Family: \n \n  At our law firm, you won't just be an employee; you'll be part of a family that values growth, learning, and camaraderie. We take pride in the work we do and the difference we make in our clients' lives. \n \n  Don't Miss Out: \n \n  Seize the opportunity to be part of something extraordinary! Apply now and take your career to new heights. Let's make a difference together!",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "7937d73de770db04": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 73200.51,
        "salary_max": 92688.15,
        "title": "Data Quality Analyst II",
        "company": "Invicro",
        "desc": "Location : Remote \n  Benefits : At Invicro you will be learning, challenging yourself, and having fun while collaborating with teammates through the open exchange of ideas. Our outstanding benefits program includes medical, dental, vision, 401k with a 4% employer match, FSA, paid sick leave, and generous paid time off (PTO) program. You can learn more about the benefits here. \n  Overview:  \n Make an impact at a dynamic and growing life sciences company! Data Quality Analysts are responsible for examining complex data for quality of the data being collected, facilitating resolution of data quality issues, and delivering clean data sets to sponsors. \n  Essential Job Functions \n \n Review specification material needed to conduct clinical data management activities such as Data Management Plans, Data Transfer Agreements, Image Review Charters, etc. \n Perform quality review of test transfer outputs and verify compliance with project specification material prior to external delivery. \n Develop quality control templates and support tools to verify the data in programmed outputs are accurate and formatted per sponsor specification requirements. \n Participate in User Acceptance Testing (UAT) and data quality control review of data outputs generated in both automated and manual fashions to verify the integrity of the data generated. \n Perform ongoing data reconciliation and facilitate tracking issues identified, triaging resolution requests to the responsible parties, and verifying resolution actions have been completed as appropriate throughout study conduct and close-out. \n Review and cross-check deliverable outputs against project documentation and original data origins to ensure data are accurate and being delivered per the project requirements and sponsor specifications. \n Identify workflow processing efficiencies and improvements to optimize deliverable commitments. \n Collaborate with data managers to define, document and implement automated data quality checks based on project and specification documentation requirements. \n Perform review of automated data processing workflows to ensure database configurations are functioning as expected per study documentation. \n Develop prototypes and demonstrations of data quality and data integration practices. \n Participate in data quality investigations and analyses, and diagnose root causes and make recommendations. \n Develop, implement, and evaluate data quality management policies and practices. \n \n Qualifications and Skills: \n \n 3-5 years of experience in Data Management or related experience. \n Bachelor\u2019s degree in STEM or equivalent demonstrated technical and analytical experience. \n Microsoft Excel expertise required. \n Image analysis experience preferred. \n SQL proficiency preferred. \n Oncology and/or Neurology experience preferred. \n Working knowledge of the clinical drug development process, FDA regulatory requirements, ICH, GCP and 21 CFR Part 11 guidelines, CDISC SDTM standards, and Data Management industry standard practices. \n \n What We Offer: \n \n Competitive salary \n Full Benefits \n 401k with generous matching \n Flexible vacation policy \n \n \n \n  Invicro is an Equal Opportunity Employer. We maintain a drug-free work environment. All qualified applicants will receive consideration for employment without regard to actual or perceived race (and traits historically associated with race, including, but not limited to hair texture and protective hairstyles such as braids, locks, and twists), color, creed, religion, citizenship status, sex or gender (including pregnancy, childbirth and related medical conditions), parental status, sexual orientation, gender identity, gender expression (including transgender status), national origin, ancestry, age, marital status or protected veteran status and will not be discriminated against on the basis of physical or mental disability, protected medical condition as defined by applicable state or local law, genetic information, political affiliation or any other characteristic protected by applicable federal, state, or local laws and ordinances. \n  Invicro does not accept unsolicited resumes from individual recruiters, third party recruiting agencies, outside recruiters or firms without an executed contract in place. We are not responsible for any fees related to resumes that are unsolicited or are received by Invicro. Such resumes will be deemed the sole property of Invicro and will be processed accordingly. \n \n \n  #LI-MK1 #LI-Remote",
        "cleaned_desc": " Develop quality control templates and support tools to verify the data in programmed outputs are accurate and formatted per sponsor specification requirements. \n Participate in User Acceptance Testing (UAT) and data quality control review of data outputs generated in both automated and manual fashions to verify the integrity of the data generated. \n Perform ongoing data reconciliation and facilitate tracking issues identified, triaging resolution requests to the responsible parties, and verifying resolution actions have been completed as appropriate throughout study conduct and close-out. \n Review and cross-check deliverable outputs against project documentation and original data origins to ensure data are accurate and being delivered per the project requirements and sponsor specifications. \n Identify workflow processing efficiencies and improvements to optimize deliverable commitments. \n Collaborate with data managers to define, document and implement automated data quality checks based on project and specification documentation requirements. \n Perform review of automated data processing workflows to ensure database configurations are functioning as expected per study documentation. \n Develop prototypes and demonstrations of data quality and data integration practices.   Participate in data quality investigations and analyses, and diagnose root causes and make recommendations. \n Develop, implement, and evaluate data quality management policies and practices. \n \n Qualifications and Skills: \n \n 3-5 years of experience in Data Management or related experience. \n Bachelor\u2019s degree in STEM or equivalent demonstrated technical and analytical experience. \n Microsoft Excel expertise required. ",
        "techs": [
            "quality control templates",
            "support tools",
            "user acceptance testing (uat)",
            "data reconciliation",
            "tracking issues",
            "resolution requests",
            "deliverable outputs",
            "project documentation",
            "original data origins",
            "workflow processing efficiencies",
            "data managers",
            "automated data quality checks",
            "data processing workflows",
            "database configurations",
            "prototypes",
            "demonstrations",
            "data integration practices",
            "data quality investigations",
            "data quality management policies",
            "microsoft excel expertise"
        ],
        "cleaned_techs": [
            "quality control templates",
            "support tools",
            "user acceptance testing (uat)",
            "data reconciliation",
            "tracking issues",
            "resolution requests",
            "deliverable outputs",
            "original data origins",
            "workflow processing efficiencies",
            "data managers",
            "automated data quality checks",
            "data processing workflows",
            "database configurations",
            "prototypes",
            "demonstrations",
            "data integration practices",
            "data quality investigations",
            "data quality management policies",
            "excel"
        ]
    },
    "0dd9d39fec7ee6bb": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55000.0,
        "salary_max": 75000.0,
        "title": "Business Analyst ll",
        "company": "AbsenceSoft LLC",
        "desc": "We\u2019re looking for an ambitious and detail-oriented Business Analyst ll \u2013 someone that is passionate about interacting with customers and helping to deliver implementation projects in support of our new and existing customers. You will join a dynamic and fast-paced environment and work with cross-functional teams to design and launch AbsenceSoft\u2019s product to new and existing customers. This is a great role to learn about our product, work in a growing business, and advance in a quickly growing software organization. \n \n  Who We Are \n  AbsenceSoft is elevating the leave and accommodations experience and is looking to hire amazing people like you! We create user-friendly technology that empowers employers to bring humanity, certainty and efficiency to the leave and accommodations experience. Made by HR Professionals for HR Professionals, we're proud of where we've been and excited about where we're headed. We value creative, innovative people who are passionate about their work and who believe there is always a better way. \n \n  Leading With Our Core Values \n  Make a Difference. \n  We are inspired to make an impact through our hard work, talent and passion. We push ourselves each day to better serve our teams, our clients, and our community. \n  Team First. \n \n  We are driven by team spirit not by self-interest. We value collaboration and approach our work with humility and a desire to win together. \n  Own it. \n \n  If we say it, we mean it. We follow through on our commitments, step up to deliver, and grow from our successes and failures. \n  Everyone Matters. \n \n  No matter your background or experience, everyone's voice holds value here. \n \n  What You\u2019ll Do \n \n  Work closely with the project team and other cross functional team members to deliver on implementation projects for both new and existing client initiatives \n  Work directly with customers to support the implementation of AbsenceSoft software, including:\n    \n  System demonstrations \n  Discovery sessions \n  Solution Design & Documentation \n  Feature configuration \n  Data and system integrations \n  Unit and user acceptance testing and remediation sessions \n  System training sessions (remotely or onsite with clients) \n  Go-live and post go-live activities \n \n  Work with customers to advise them on best practices for implementing the AbsenceSoft software \n  Become a subject matter expert with the AbsenceSoft software, configurations, and capabilities and use your knowledge to set up and configure our clients\u2019 environment \n \n \n  What\u2019ll Set You Up for Success \n \n  2-3 years work experience as a business analyst or in a technology business with hands on experience with a SaaS system \n  Hands on experience with the following:\n    \n  Saas platform configuration experience \n  Data mapping experience \n  System integration experience \n \n  Ability to communicate effectively with customers \u2013 in a virtual environment \n  Ability to learn and become an expert in a new system \n  Strong problem-solving skills \n  Excellent written and verbal communication skills \n  Ability to \u2018roll-up your sleeves\u2019 to help get the job done \n  Undergraduate degree \n  Be willing to travel\n    \n  Travel is generally limited and many meetings with customers are virtual \u2013 but travel can be up to 15-25% \n  Our implementation projects typically require travel at key milestones such as User Acceptance Testing, Project Go-Live, etc. \n \n \n \n  What To Know Before You Apply \n \n  We\u2019re located in beautiful Golden, Colorado. (Remote) \n  This is a full-time, salaried position + bonus. \n  AbsenceSoft provides a wide variety of perks and benefits. Including full medical, dental, vision, 401K, and life insurance. We support your professional growth including industry training and CLMS Certification; opportunities for additional industry and technology certifications, and continuing education. \n  The salary range for this position is between $55,000 - $75,000. \n \n \n  At AbsenceSoft, we are committed to building a team that represents a variety of diverse backgrounds, perspectives, and skills. We are proud to be an equal opportunity workplace that celebrates and supports diversity and inclusion. We make all employment and related decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.",
        "cleaned_desc": "  Hands on experience with the following:\n    \n  Saas platform configuration experience \n  Data mapping experience \n  System integration experience \n \n  Ability to communicate effectively with customers \u2013 in a virtual environment \n  Ability to learn and become an expert in a new system \n  Strong problem-solving skills \n  Excellent written and verbal communication skills \n  Ability to \u2018roll-up your sleeves\u2019 to help get the job done \n  Undergraduate degree \n  Be willing to travel",
        "techs": [
            "saas platform configuration",
            "data mapping",
            "system integration"
        ],
        "cleaned_techs": [
            "saas platform configuration",
            "data mapping",
            "system integration"
        ]
    },
    "d073ded71ffe861b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55.0,
        "salary_max": 70.0,
        "title": "Tapestry Business Analyst",
        "company": "Tekshapers Inc",
        "desc": "Role : Tapestry Business Analyst \n Location : Remote \n Type : Contract \n Job Description : \n Project: Tapestry Configuration Support \n Responsibilities: \n Review/Interpret Contract Language for BRD Creation and Business Config Support. \n Good To Have Skills: \n Epic: Tapestry, Business Requirements Documentation, Certification: Epic: Tapestry AP Claims and Contracts Administration, Written Communication, Verbal Communication . \n Job Type: Contract \n Salary: $55.00 - $70.00 per hour \n Expected hours: 40 per week \n Experience level: \n \n 9 years \n \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Experience working with Epic Tapestry . \n \n Experience: \n \n Epic: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "2c7fa4d2ec003f0e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 34.62,
        "salary_max": 43.27,
        "title": "Payroll Analyst",
        "company": "GOAT Group",
        "desc": "About the Team \n  Our People Team is key to the growth of GOAT Group as the company continues to expand globally. Through our innovative programs and data-driven strategies, the company is committed to building a culture that is inclusive, cooperative and motivating. As a member of this team, you will play an indispensable part in our company's future by matching talent to the right roles as well as cultivating an environment in which all of our employees \u2013 across our warehouses, Flight Club retail stores and corporate teams \u2013 are able to thrive. \n  Role Overview \n  GOAT Group is seeking a Payroll Analyst to join our Global Payroll team. This position will be responsible for payroll and time system configuration in addition to payroll activities related to bi-weekly and monthly payroll processing cycles. The ideal candidate will have a strong technical background in payroll, with experience analyzing and interpreting data. \n  This role will report to the Associate Director, Global Payroll within the Total Rewards & People Operations team. \n  In this role you will: \n \n Partner with cross functional stakeholders in order to maximize efficiencies across payroll processes and technology as we continue to scale \n Audit data to identify and resolve discrepancies before, during and after payroll processing cycles \n Provide day-to-day support and issue resolution related to payroll, timesheet and system inquiries for internal employees and people managers \n Partner with People Operations to ensure all new hires, terminations, and payroll related changes are adequately accounted for \n Build and maintain payroll and timekeeping system setup, reports, and dataflows \n Analyze data from various systems to identify trends, patterns, and areas for improvement \n Document the payroll process end to end and help identify improvements to current practices and policies \n Assist with requirements and set up of new state and local jurisdictions, tax amendments, and year end validation activities \n Ensure adherence to internal controls and audit requirements for workforce management and payroll processes \n Assist with communication and/or education related to payroll, time and attendance, and payroll systems navigation \n Assist in annual audits related to payroll, benefits, and taxation as needed \n Support payroll processing and other projects as necessary \n \n We are looking for: \n \n 5+ years of combined multi-state payroll and/or human resources experience, preferably at a company with over 1k employees \n Experience working with an hourly population of over 700 employees \n Global experience is a plus \n Extensive experience as a Payroll Analyst, or similar role \n Ability to juggle various tasks in a fast-paced, ever-changing environment \n Ability to work autonomously with a proven track record of driving projects to completion \n Outstanding attention to detail with ability to analyze and draw conclusions from payroll data \n Ability to act with discretion in managing confidential information \n A communicator and collaborator who will partner with cross-functional teams at different levels within the organization \n Service oriented individual with outstanding verbal and written communication skills \n \n \n \n The hiring range for this position is below, plus benefits (401K, paid time off, dental, medical, vision, disability, life insurance options). To determine starting pay within the hiring range, we carefully consider a variety of factors, including primary work location, role/level, a candidate\u2019s skills, experience, market demands, and internal parity. You may reach out to a recruiter for additional information. \n \n  Hiring Range: \n \n    $34.62\u2014$43.27 USD\n   \n \n \n  GOAT Group represents the leading platforms for authentic sneakers, apparel and accessories. Operating four distinct brands\u2013GOAT, Flight Club, Grailed and alias\u2013GOAT Group has a global community of over 50M members across 170 countries. \n  GOAT is the global platform for the greatest products from the past, present and future. Since its founding in 2015, GOAT has become the leading and most trusted sneaker marketplace in the world, and has expanded to offer apparel and accessories from select emerging, contemporary and iconic brands. Through its unique positioning between the primary and resale markets, the company offers styles across various time periods on its digital platforms and in its retail locations, while delivering products to over 50 million members across 170 countries. \n  Established in New York City over 15 years ago, Flight Club revolutionized sneaker retail as the original consignment store for rare shoes. Carrying the rarest exclusives and collectible sneakers, Flight Club has evolved from a one-stop sneaker destination, to a cultural hub for sneaker enthusiasts and novices alike. With three brick-and-mortar locations in New York City, Los Angeles and Miami, Flight Club remains the premier source for authentic, rare sneakers. \n  Founded in 2013, Grailed is the leading community-driven marketplace for rare luxury, streetwear and vintage fashion. The marketplace was built for enthusiasts, by enthusiasts, and features products from brands including Supreme, Raf Simons, Gucci, Saint Laurent, Balenciaga, Prada and more. With a highly curated selection of resale pieces including inventory exclusive to the platform, Grailed makes fashion accessible. \n  The company is backed by strategic investor Foot Locker, Inc. as well as some of the leading names in venture capital including Park West Asset Management, T. Rowe Price Associates, Inc., Franklin Templeton, Adage Capital Management, Ulysses Management, D1 Capital Partners, Accel, Andreessen Horowitz, Index Ventures, Matrix Partners, Upfront Ventures, Webb Investment Network and Y Combinator. \n  GOAT Group will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance, if applicable. By applying, you authorize GOAT Group to send you text messages regarding your job application, interview and/or onboarding process, and other job opportunities at GOAT Group.  If you are a California resident, please review our  California Privacy Rights Notice for Job Applicants .  If you are an EU or UK resident, please review our  EU / UK Candidate & Employee Privacy Notice.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6a2a42651be343db": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81009.76,
        "salary_max": 102576.4,
        "title": "Business Analyst, IT",
        "company": "CIEE Inc",
        "desc": "Position : Business Analyst\n                 \n Reports to : Product Manager\n                 \n Department : IT\n                 \n Location : US Remote (see location requirements below), Canada Remote\n                 \n  Who we are: \n  CIEE is a non-profit study abroad and intercultural exchange organization that transforms lives and builds bridges between individuals and nations through study abroad and international exchange experiences that help people develop skills for living in a globally interdependent and culturally diverse world. \n \n \n  Why work with us: \n \n \n  You will change the world . CIEE builds bridges between different people, different countries, and different cultures. We help young people participate in high-quality international exchange and study abroad programs that bring the world together. We change lives, our alumni change the world. Be part of the change! \n  You will receive a competitive total rewards package (only applicable for U.S. employees).  CIEE provides all employees with exceptional benefits offerings that increase total compensation by up to 25%. Our top-tier benefits include: \n \n \n \n  Paid time off and Parental leave \n  Gym Reimbursement Program \n  Employee Assistance Program \n  Short-term & Long-term Disability \n  6 floating Fridays (based on our eligibility rules) \n  CIEE Study Abroad and TEFL Program discounts \n  403(b) Retirement Plan with employer contribution \n  Insurance Coverage (life, travel, medical, dental, and vision) \n  Flexible Spending Accounts/Health Savings Accounts (medical and dependent) \n  Voluntary Benefits (identity theft protection, pet insurance, accident, and critical illness) \n \n \n \n  You will be part of a fast-paced, international, diverse, and collaborative team of professionals.  CIEE operates the largest nonprofit network of study-abroad locations, with facilities and staff in 26 countries. Additionally, we help international participants from over 130 countries come to the USA each year. Committed to excellence and solving whatever problem the world throws at them, CIEE professionals work on international teams and are dedicated to advancing our 75-year-old mission to make the world a more peaceful place. \n \n  Who you are: \n  CIEE\u2019s Business Analysts are a crucial link between our engineering teams and business units. They support all functions involved in the design, development, documentation, training, testing, and maintenance of our software applications. These applications are used to market to, acquire, and support on-program CIEE participants. With a commitment to innovation, CIEE\u2019s Business Analysts are constantly finding ways to improve our business processes and systems. \n  The Business Analyst is expected to have excellent communication skills, a knack for troubleshooting and tracking down elusive issues, and a desire to work in collaboration with Product Managers. \n  What you\u2019ll do : \n \n \n  Be an active member of an agile team(s) and follow the Scrum framework \n  Work side by side with engineering as well as multiple business units \n  Assist in translating roadmap features to epics and stories \n  Assist in developing and documenting business requirements \n  Create reports, dashboards, and metrics to showcase outcomes \n  Work closely with Product Managers on planning, refinement, and prioritization \n  Test and document systems, software, and services \n  Identify opportunities to improve efficiencies and performance with our systems, software, services, and ways of working \n \n  What you\u2019ll bring: \n \n \n  A minimum of 3 years of relevant experience \n  Excellent written and oral communication skills \u2013 including the ability to summarize and present complex information to all levels of the business \n  A driving curiosity to understand why and how things work (or don\u2019t) \n  An analytical mindset and strong problem-solving skills \n  Extreme attention to detail \n  Experience and competence in the analysis and comprehension of data \n  2 years of experience working with Salesforce \n  International Education/Exchange experience preferred \n  Readiness to grow and develop yourself, our client group, and our Company \n  Ability to embrace CIEE\u2019s Core Values (Excellence, Integrity, Respect, Inclusion, and Problem-Solving) and culture \n \n \n \n  Location Requirements: \n \n \n                   The position is available to candidates in the United States, \n                   except for candidates residing in :\n                  \n \n  New York (State and City) \n  Washington (State) \n  Colorado \n  California \n  Jersey City, NJ \n \n \n \n  Diversity Matters: \n  CIEE believes that diversity matters and that professionals with diverse backgrounds provide diverse approaches and ideas to solving problems and finding ways to advance our mission to bring the world together. Candidates from underrepresented groups with diverse backgrounds and experiences are strongly encouraged to apply. \n \n  Due to federal regulations, a background check will be conducted as a condition of employment.",
        "cleaned_desc": "  Identify opportunities to improve efficiencies and performance with our systems, software, services, and ways of working \n \n  What you\u2019ll bring: \n \n \n  A minimum of 3 years of relevant experience \n  Excellent written and oral communication skills \u2013 including the ability to summarize and present complex information to all levels of the business \n  A driving curiosity to understand why and how things work (or don\u2019t) \n  An analytical mindset and strong problem-solving skills \n  Extreme attention to detail \n  Experience and competence in the analysis and comprehension of data \n  2 years of experience working with Salesforce \n  International Education/Exchange experience preferred \n  Readiness to grow and develop yourself, our client group, and our Company \n  Ability to embrace CIEE\u2019s Core Values (Excellence, Integrity, Respect, Inclusion, and Problem-Solving) and culture \n ",
        "techs": [
            "salesforce"
        ],
        "cleaned_techs": [
            "salesforce"
        ]
    },
    "ca971afaefe301a6": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 93790.92,
        "salary_max": 118760.2,
        "title": "Senior Business Analyst",
        "company": "Calix",
        "desc": "Calix provides the cloud, software platforms, systems and services required for communications service providers to simplify their businesses, excite their subscribers and grow their value. \n \n  We are seeking a motivated and experienced individual contributor to take on the role of Senior Business Analyst within Customer Engagement and Services. As a Senior Business Analyst, you will be responsible for independently driving and managing critical projects, ensuring their successful execution, and delivering measurable results. This role requires a self-starter with strong project management skills and the ability to work collaboratively across teams. \n \n \n Responsibilities: \n  Collaborate with senior leadership to identify, define, and prioritize special projects aligned with company goals. \n Ability to develop clear project objectives, scope, and success criteria. \n Consult with business stakeholders on requirements and system capabilities to meet business objectives. \n Collaborate with various subject matter experts and technical teams to formulate, document, present, and justify proposed solutions balancing scope, schedule, cost, and complexity. \n Create comprehensive project plans, including timelines, resource allocation, and budgets. Identify and secure necessary resources, including team members and external partners, as needed. \n Lead proof of concept projects to validate solutions. \n Lead cross-functional project teams and serve as the primary point of contact for project stakeholders. Drive project activities, ensuring milestones are met on time and within budget. Monitor and mitigate risks and resolve project-related issues as they arise. \n Provide regular project updates to senior leadership and stakeholders. Prepare and present reports, highlighting progress, challenges, and recommended actions. \n Conduct post-project evaluations to measure outcomes against project goals. Capture lessons learned and best practices for future projects. \n Ability to manage multiple engagements seamlessly. \n \n \n Qualifications: \n  Bachelor's degree in a relevant field; advanced degree or certifications (e.g., PMP) a plus. \n Proven experience (5+ years) successfully leading complex projects from initiation to completion. \n Able to translate business requirements efficiently and effectively into system solutions, articulating business impacts. \n Excellent business analysis abilities and experiences aligning business needs with IT capabilities. \n Excellent interpersonal, communication, and relationship management skills \n Strong project management skills, including the ability to create detailed project plans and manage resources effectively. \n Strong analytical and problem-solving abilities. \n Ability to work independently, take initiative, and drive projects to completion. \n Highly organized, with attention to detail and the ability to prioritize multiple tasks. \n Adaptability and the ability to thrive in a dynamic work environment. \n \n \n Location: \n  This is a remote-based position located in North America \n \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "f8e547c84b58fc3f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 82163.21,
        "salary_max": 104036.93,
        "title": "Business Analyst",
        "company": "Modus Create",
        "desc": "Hello! Are you ready to Work from Home and transform your career? If you have great consulting skills and know you can consistently delight our customers and help grow our accounts, Modus is the perfect fit for you. Our high performance team helps our clients to build awesome solutions to accomplish their goals and vision. Are you interested in working from home with some of the best talent on the planet? Then keep reading. \n \n  We're looking for a  Business Analyst  to join the engineering team at Modus. \n  About You \n  Experience level: Senior \n  [In reference to requisition 727] \n  You love helping and supporting teams to build great software. You have worked with teams before on large and demonstrable projects. You have 5+ years working in \"thinking roles\" in a development team in large, complex projects and technologies in large organizations. We need someone used to thinking their way through problems and methodically laying out solutions in a range of product development related domains. You have excellent knowledge of the software life cycle. You have Agile framework knowledge. You have work experience writing user stories and converting client needs into clear requirements that can be then written as epics, features and user stories. Experience with Jira and Confluence is a must. Also, you have experience with challenges of Agile and DevOps implementations in large organizations, and ideas about how to overcome them. \n  You are excellent at communicating client requirements to the different roles in your team, interacting with developers to ensure they understand these stories, or other stakeholders like designers and strategists. You could have the chance to work with other business analysts of the company internally to grow the practice. Being able to communicate with other departments related to your team and daily work is key. \n \n \n    You love learning and understand that software is an ever-evolving world. You enjoy playing with new tech and exploring areas that you might not have experience with yet. You are self-driven, self-learner willing to share knowledge and participate actively in your community.\n    \n  Having overlap with your team is critical when working in a global remote team. Modus requires all team members to overlap with EST hours daily. In addition, reliable high speed internet is a must.\n    \n \n Things You Might Do \n \n  Modus is a fast-growing, and remote-first company, so you'll likely get experience on many different projects across the organization. That said, here are some things you'll probably do:\n    \n \n \n Give back to the community via open source and blog posts \n Travel and meet great people- as part of our remote-first lifestyle, it's important that we come together as needed to work together, meet each other in person and have fun together. Please keep that in mind when you apply. \n Teach and be taught: Modus creates active teams that work in internal and external projects together, giving opportunities to stay relevant with the latest technologies and learning from experts worldwide \n Interact directly with internal and external clients to represent Modus and its values.  \n \n  Our Benefits may vary according to the Country you are located in, so please reach out to our recruiter in case you have any questions. \n    \n \n If you live in Costa Rica and you become a full-time employee we offer: \n \n \n \n Competitive compensation \n 100% Remote work (could vary according to the client's needs) \n Flexible working hours \n Travel according to client's needs \n Company paid private insurance \n The chance to work side-by-side with thought leaders in emerging tech \n Social Security (CCSS) by law \n \n \n  If you live in Romania and you become a full-time employee we offer: \n \n \n \n Competitive compensation \n Medical insurance  \n Meal vouchers \n Telework indemnity \n Bookster subscription \n Extra PTO Days with Tenure per year worked(up to max. 4 days) \n Possibility to obtain paid certification/courses if they align with company goals and are relevant for the employee's role \n Client Referral program \n 100 % remote work and the possibility to work from the office \n The chance to work side-by-side with thought leaders in emerging tech \n \n \n  If you live in the USA and you become a full-time employee we offer: \n \n \n \n Competitive compensation \n Health insurance (medical, vision, and dental) and other benefits (FSA and HSA) \n Virtual Care support \n 401(K) match to up to 3.5% of your annual salary \n Optional Voluntary Short or Long-term disability insurance. \n Remote work \n The chance to work side-by-side with thought leaders in emerging tech \n Flexible Time Off/PTO \n \n \n  If you live anywhere else you can become a contractor, and then we offer: \n \n \n \n Competitive compensation \n 100% Remote work (could vary according to the client's needs) \n Travel according to client's needs \n Employee Referral Program \n The chance to work side-by-side with thought leaders in emerging tech \n \n \n  About Modus \n \n  Modus Create is a digital product group that accelerates digital transformation. We use high performing small teams, emerging technology, and \"new school\" product development tools and methods to accelerate business outcomes. We support our clients across four core delivery areas: business and product strategy consulting, customer experience, cloud services, and Agile software delivery. \n     Driven by a team of world-class talent, we have been recognized by the Inc 5000 list of Fastest Growing Private Companies nine years in a row, the Washington Business Journal list of Fastest Growing Companies in the Washington, DC area three years in a row, and a top company for remote work by FlexJobs. We're also an official partner to Atlassian, AWS, Cloudflare, GitHub, InVision, Ionic Framework, and Vue.js! \n     Founded in 2011, with our HQ in Reston, Virginia and offices in Costa Rica, Romania and France, Modus has employees all over the world. Based on the model of an open source team, Modites work remotely and are located across the globe. This has allowed us to hire the best talent in the world, no matter where they live. Our highly collaborative, autonomous, and effective working environment is fueled by a team unified by a love of continuous learning. Our years of thought leadership including books, whitepapers, blog posts, conferences and MeetUp talks, demonstrate our commitment to sharing what we've learned. \n     We encourage every Modus employee to do the same. Our company is a platform for the growth of our employees. Through working with our distributed team of experts on challenging projects, every person that joins the Modus team can expect to continue growing and learning every day. This is your chance to be part of building something great. \n   \n \n Federal law requires Modus Create to confirm the identity and employment eligibility of all persons hired to work in the United States as full-time employees. \n The statement above does not apply to 1099 Contractors or International Contractors \n \n \n  Modus Create is committed to creating a diverse environment, and each of us contributes to inclusion. All qualified applicants will receive consideration for employment without regard to  \n race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class \n .",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "07958cea3962a6ca": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90000.0,
        "salary_max": 115000.0,
        "title": "Sr Business Intelligence Analyst",
        "company": "Aspirion Health Resources LLC",
        "desc": "What is Aspirion? \n  Aspirion is an industry-leading provider of complex claims and revenue cycle management services. We specialize in Motor Vehicle Accidents, Worker\u2019s Compensation, Veterans Administration and Tricare, Complex Denials, Out-of-State Medicaid, Aged AR, and Eligibility and Enrollment Services. Our employees work in an environment that is both challenging and rewarding. We ask a lot out of our team members and in return we offer flexibility, autonomy, and endless opportunities for advancement. As we are committed to growth within the complex claims industry, we offer the same growth to our employees. \n  What do we need?   \n Aspirion is seeking a Sr. BI Analyst who is looking for an opportunity to grow their skills and contribute to our continued success. The Sr. BI Analyst will design, develop, document, and support business intelligence solutions that enable data analytics, reporting, and decision-making. In this role, you engage stakeholders at all levels with curiosity, empathy, and a desire to help them solve problems. You are a systematic thinker who understands the importance of a well-designed and well-documented data environment. You have knowledge of industry best practices in self-service business intelligence, and data tools and analysis and can communicate well with the end-user community translating their needs into high performance designs. \n  What will you provide? \n \n This role is responsible for the aggregation of data from multiple data sources to create intelligence that helps design and / or transform the organization to maximize growth, efficiency, and customer retention. \n Build, maintain, automate, and enhance all self-service KPI reporting including but not limited to Incentive Compensation, Days to Hire, Employee Attrition, Whitespace, Total Addressable Market, Sales KPI\u2019s, Renewals, Terminations and more \n Leverage historical data and trends to predict future growth and / or risk. \n Partners with finance, product, sales, and client success leadership in the creation of annual sales budgets, renewals and client terminations. \n Responsible for QA and ensuring integrity of data. Provide a single source of truth that is dependable and accurate for all stakeholders \n Ability to document and translate cross functional business requirements into process/functional design/system solutions within Salesforce.com, HRIS systems, analytics platforms or other corporate applications. \n Project manage cross functional initiatives from start to finish \n Refine data models as needed and enhance metrics as the business evolves \n Assist in other ad-hoc analysis and presentations, board decks, etc. \n \n Requirements \n \n Five years or more in analytical work and data analytics experience \n Advanced knowledge of Microsoft tools. \u2013 specifically, Excel and Power Query. \n Advanced knowledge of Corporate applications such as SFDC, HRIS systems, Financial systems, Power BI \n \n Education and Experience Qualifications \n \n Bachelor's degree in Mathematics, Finance, or related fields \n Strong knowledge of Power BI \n Organizational skills with exceptional time management and planning skills \n Oral and written communication with VP/SVP level leaders \n Presentation skills \n \n Benefits \n  At Aspirion we invest in our employees by offering unlimited opportunities for advancement, a full benefits package, including health, dental, vision and life insurance upon hire, matching 401k, competitive salaries, and incentive programs. \n  AAP/EEO Statement   \n Equal Opportunity Employer/Drug-Free Workplace: Aspirion is an Equal Employment Opportunity employer. We adhere to a policy of making employment decisions without regard to race, color, age, sex, pregnancy, religion, national origin, ancestry, medical condition, marital status, gender identity citizenship status, veteran status, disability, or veteran status. Aspirion has a Drug-Free Workplace Policy in effect that is strictly adhered to.",
        "cleaned_desc": " Five years or more in analytical work and data analytics experience \n Advanced knowledge of Microsoft tools. \u2013 specifically, Excel and Power Query. \n Advanced knowledge of Corporate applications such as SFDC, HRIS systems, Financial systems, Power BI \n \n Education and Experience Qualifications \n   Bachelor's degree in Mathematics, Finance, or related fields \n Strong knowledge of Power BI \n Organizational skills with exceptional time management and planning skills \n Oral and written communication with VP/SVP level leaders \n Presentation skills \n ",
        "techs": [
            "excel",
            "power query",
            "sfdc",
            "hris systems",
            "power bi"
        ],
        "cleaned_techs": [
            "excel",
            "power query",
            "sfdc",
            "hris systems",
            "powerbi"
        ]
    },
    "f5a8f8b5bf3389eb": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 60.0,
        "salary_max": 60.0,
        "title": "IAM Business Analyst",
        "company": "Synchrony",
        "desc": "Job Description & Skill Requirement: \n \n Hands on experience writing technical requirements \n Able to create, report and manage IAM specific KPIs and program KRIs to measure operational efficiency and risks \n Perform detail review and documentation on IAM releases and key activities impacting end users \n Initiate and develop various communications (& plans) on IAM offerings, changes and enhancements, and update IAM related Job aid, User trainings \n Advanced Knowledge in Access Management, Ping Identity tools and standard technologies like Java, Scripting \n Excellent PowerPoint creation and presentation skills with strong experience in MS Word and Excel \n Experience and familiarity with project management tools and methodologies \n \n Job Type: Full-time \n Salary: $60.00 per hour \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n Weekends as needed \n \n Experience: \n \n IAM: 1 year (Preferred) \n Ping Identity: 1 year (Preferred) \n KPI: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Initiate and develop various communications (& plans) on IAM offerings, changes and enhancements, and update IAM related Job aid, User trainings \n Advanced Knowledge in Access Management, Ping Identity tools and standard technologies like Java, Scripting \n Excellent PowerPoint creation and presentation skills with strong experience in MS Word and Excel \n Experience and familiarity with project management tools and methodologies \n ",
        "techs": [
            "iam offerings",
            "changes and enhancements",
            "ping identity tools",
            "java",
            "scripting",
            "powerpoint",
            "ms word",
            "excel",
            "project management tools",
            "methodologies"
        ],
        "cleaned_techs": [
            "iam offerings",
            "changes and enhancements",
            "ping identity tools",
            "java",
            "scripting",
            "powerpoint",
            "microsoft",
            "excel",
            "project management tools",
            "methodologies"
        ]
    },
    "b2ae3a29565ea133": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 100000.0,
        "salary_max": 110000.0,
        "title": "Sr Business Analyst: 100% remote, Financial Tech, big data analytics SaaS",
        "company": "Relentless Talent",
        "desc": "One of my long term clients is growing again and looking to add a Business Analyst. They are a 16 person company, whom has been steadily growing and looking to add key players. \n For the Business Analyst role they are seeking someone: \n Degree in computer science, information management or related field. \n Experience with system integrations, ETL processes, network security and structure, cloud storage and processing fundamentals, file transmission methods, AWS and Azure environments. \n Strong analytical and problem-solving skills \n Bias towards action \n 5+ years experience, background in data operations systems in an agile environment is a plus \n Proven background participating in large scale initiatives and being self-motivated with little need for oversight \n Comfortable working in a 100% remote distributed team setting \n Please note, as a company they get together 2 times per year for 2 to 3 days. \n Core duties of the role \n \u00b7 Work with current data warehousing vendor and our new managed services provider to gain deep understanding of the current and planned technical infrastructures \n \u00b7 Coordinate with members of the Information Governance & Management team to assess operational system needs during the transformation period and after project completion \n \u00b7 Partner with the Operational Transformation team and new managed services provider to establish roles and responsibilities for support and maintenance of all new and existing systems that are part of the new operational model \n \u00b7 Collaborate with Analytics resources to determine new and expanded systems needs to enable organizational analytic function \n \u00b7 Serve as lead during implementation and integration phase for internal systems \n \u00b7 Support internal information systems and serve as point of contact for users \n \u00b7 Partner with internal resources and/or managed services provider to plan ongoing development efforts \n \u00b7 Coordinate with Senior Manager, Exchange Management on system enhancement and replacement projects \n \u00b7 Collaborate with Senior Manager, Information Quality to ensure systems continually support organizational information management needs \n \u00b7 Serve as the SME on structure and function of the Information Management environment \n Base salary with a 10%+ bonus which has been paid for a number of years, full benefits, 401k and PTO. You will support clients on east coast business hours. All candidate must have a online LinkedIn profile to be considered. \n Feel free to reach out directly if you are qualified: https://www.linkedin.com/in/lou-russo-2ba5006/ \n Job Type: Full-time \n Pay: $100,000.00 - $110,000.00 per year \n Benefits: \n \n 401(k) 3% Match \n Dental insurance \n Health insurance \n \n Compensation package: \n \n Bonus opportunities \n Yearly pay \n \n Experience level: \n \n 8 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": "One of my long term clients is growing again and looking to add a Business Analyst. They are a 16 person company, whom has been steadily growing and looking to add key players. \n For the Business Analyst role they are seeking someone: \n Degree in computer science, information management or related field. \n Experience with system integrations, ETL processes, network security and structure, cloud storage and processing fundamentals, file transmission methods, AWS and Azure environments. \n Strong analytical and problem-solving skills \n Bias towards action \n 5+ years experience, background in data operations systems in an agile environment is a plus \n Proven background participating in large scale initiatives and being self-motivated with little need for oversight ",
        "techs": [
            "system integrations",
            "etl processes",
            "network security and structure",
            "cloud storage and processing fundamentals",
            "file transmission methods",
            "aws",
            "azure environments"
        ],
        "cleaned_techs": [
            "system integrations",
            "etl processes",
            "cloud storage and processing fundamentals",
            "file transmission methods",
            "aws",
            "azure"
        ]
    },
    "8193a78db32052aa": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 114398.14,
        "salary_max": 144853.53,
        "title": "Functional Data Management (DM) / BODS Analyst - Senior",
        "company": "Acquaintek Inc",
        "desc": "At least 10 years of SAP experience \n \n \n Desired experience within ERP/SAP in at least two (2) or more of the following listed below: SAP T-Codes, Applications, and Tools; BI (including BW, BODS, BAPI); Data Archiving; Data Migration; Data Conversion and Data Loads; Data Distribution; Data Maintenance; Data Governance; Data Analysis; Data Extracts and Reporting; Data Mapping; Data Validation; Data Reconciliation; and Data Refreshes and Upgrades. \n \n \n Desired experience with Relational and Object-Oriented Databases, various Programming Languages (e.g. JAVA, SQL, C, C+, ...), various Data Management Tools (e.g. MDG, Attunity Gold Client Software, SAP Archiving, Oracle, Informatica, ...), various Data Modelling Tools (e.g. ERWIN, SAFYR, SADIE), various Data Reporting Tools (e.g. Cognos, Crystal Reports, SAS, ...), various SAP Tools, Configuration and Release Management Tools (e.g. Dimensions, HEAT, QC). \n \n Minimum Education: Bachelor\u2019s Degree in a recognized technical, engineering, scientific, managerial, business, or other discipline related to area of expertise. An additional four (4) years of relevant experience may be substituted for the Bachelor\u2019s Degree. An Associate\u2019s Degree together with two (2) years of documented relevant experience may be substituted for the Bachelor\u2019s Degree. \n \n Federal experience required \n \n \n Must be able to clear a DoD Secret clearance \n \n Job Type: Contract \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "6359b44e700e1aeb": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Data Analyst - Veeva Compass Solutions Consulting",
        "company": "Veeva Systems",
        "desc": "Veeva Systems is a mission-driven organization and pioneer in industry cloud, helping life sciences companies bring therapies to patients faster. As one of the fastest-growing SaaS companies in history, we surpassed $2B in revenue in our last fiscal year with extensive growth potential ahead.\n  \n \n \n  At the heart of Veeva are our values: Do the Right Thing, Customer Success, Employee Success, and Speed. We\u2019re not just any public company \u2013 we made history in 2021 by becoming a public benefit corporation (PBC), legally bound to balancing the interests of customers, employees, society, and investors.\n  \n \n \n  As a Work Anywhere company, we support your flexibility to work from home or in the office, so you can thrive in your ideal environment.\n  \n \n \n  Join us in transforming the life sciences industry, committed to making a positive impact on its customers, employees, and communities.\n  \n \n \n The Role \n \n \n \n  As a \n   Data Analyst focused on Veeva Compass Solutions Consulting and Pre-Sales Support , you will own analyses that demonstrate the quality, coverage, and strengths of our data network, as well as conduct data investigations prompted by inbound customer inquiries.\n  \n \n \n  You will be a member of a growing business unit at Veeva, working closely with Compass Strategy and Account Partners to position Compass data products (patient data and prescriber data) in-market and fuel product line growth.\n  \n \n \n  In your role, you will be responsible for performing and presenting pre-sales analysis to showcase Veeva Compass value to our customers. You\u2019ll perform qualitative and/or quantitative analyses to assist in the identification of data issues or anomalies that impact customers. You will curate observations of our data and customers\u2019 use of it, sharing feedback with Strategy and Product to enhance market positioning and inform the Compass roadmap.\n  \n \n \n  This is a great opportunity for someone who is passionate about health data and thrives in an entrepreneurial/start-up environment.\n  \n \n What You\u2019ll Do \n \n \n Research customer\u2019s therapeutic area  to understand diagnosis/treatment patterns, population characteristics, and market dynamics \n Build therapeutic area market definitions  to represent populations of interest for analysis \n Perform  data querying, cleansing, analysis, and QC  to support customer requests \n Manage projects and analyses to ensure timely  deliverables that meet client needs  and address key business questions \n Derive insights from prescription and medical claims data to  demonstrate the value and unique dimensions of our data network \n Understand data in the context of customer use cases, identify data gaps, and  develop recommendations as to how data may be used/interpreted \n Build overall  expertise on the data  in Veeva Compass, contributing to the development of normative databases, documentation, and standardized reporting to support customers \n Conduct exploratory analytics to  understand data anomalies  and  elevate meaningful observations  to the product for further analysis \n Collaborate closely with a cross-functional team  of Data Scientists, Product Managers, and Developers to ensure high-quality data delivery to our customers \n Gathering report requirements  from customers and  presenting results of analyses performed  to customers \n Lead and contribute to internal analytics initiatives supporting pre-sales  and highlighting recent market events, including data network profiling, therapeutic area analysis, and dashboarding \n \n Requirements \n \n 4+ years experience  working with big data for healthcare (claims data and prescriber data) \n Expert in  SQL \n Expert in  MS Office and/or Google Apps  (PowerPoint/Slides, Excel/Sheets, etc.) \n Proficient with visualization tools such as  Tableau, Power BI, Spotfire , etc. \n Understand how relational databases work, and experience designing  transformations, mappings,  and working with  reference tables \n Experience  investigating data issues  and working with a cross-functional team for problem resolution \n Excellent critical thinking, communication, and presentation skills \n \n Nice to Have \n \n Proficiency in Python \n Knowledge of Industry Standard billing codes such as ICD, CPT/HCPCS, NDC, etc. \n Therapeutic area knowledge \n Experience working with lab and genomics data \n Experience with ETL tools \n Experience working with a product and/or agile teams \n \n \n \n \n \n   #LI-Remote\n   \n \n   #BI-Remote\n   \n \n \n   Veeva\u2019s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.\n   \n \n \n   Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances. If you need assistance or accommodation due to a disability or special need when applying for a role or in our recruitment process, please contact us at talent_accommodations@veeva.com.",
        "cleaned_desc": " Requirements \n \n 4+ years experience  working with big data for healthcare (claims data and prescriber data) \n Expert in  SQL \n Expert in  MS Office and/or Google Apps  (PowerPoint/Slides, Excel/Sheets, etc.) \n Proficient with visualization tools such as  Tableau, Power BI, Spotfire , etc. \n Understand how relational databases work, and experience designing  transformations, mappings,  and working with  reference tables \n Experience  investigating data issues  and working with a cross-functional team for problem resolution \n Excellent critical thinking, communication, and presentation skills \n \n Nice to Have \n \n Proficiency in Python \n Knowledge of Industry Standard billing codes such as ICD, CPT/HCPCS, NDC, etc. \n Therapeutic area knowledge \n Experience working with lab and genomics data \n Experience with ETL tools ",
        "techs": [
            "sql",
            "ms office",
            "google apps",
            "powerpoint",
            "slides",
            "excel",
            "sheets",
            "tableau",
            "power bi",
            "spotfire",
            "relational databases",
            "transformations",
            "mappings",
            "reference tables",
            "python",
            "industry standard billing codes",
            "icd",
            "cpt/hcpcs",
            "ndc",
            "therapeutic area knowledge",
            "lab data",
            "genomics data",
            "etl tools"
        ],
        "cleaned_techs": [
            "sql",
            "microsoft",
            "google apps",
            "powerpoint",
            "slides",
            "excel",
            "sheets",
            "tableau",
            "powerbi",
            "spotfire",
            "relational databases",
            "transformations",
            "mappings",
            "reference tables",
            "python",
            "industry standard billing codes",
            "icd",
            "cpt/hcpcs",
            "ndc",
            "therapeutic area knowledge",
            "lab data",
            "genomics data",
            "etl tools"
        ]
    },
    "04a3d5f12660535e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55.0,
        "salary_max": 58.0,
        "title": "Business Analyst (OPF)",
        "company": "CONGLOMERATE IT LLC",
        "desc": "JOB ROLE: Business Analyst. \n Location: United States (Remote) \n Experience: 5-7 Years \n Job Type: Contract \n Work Authorization: USC, GC, GCEAD, H1 transfer \n Must have Skills: - OPF, ACH/Wire, and Omni Web Solutions. \n About Role: - \n We are seeking a skilled Business Analyst to join our team in the Retirement Business domain. As a Business Analyst, you will play a crucial role in understanding and optimizing our retirement products and services, contributing to the overall success of our organization. You will work closely with stakeholders, gather and analyze data, identify business needs, and provide actionable insights to drive strategic decisions. \n The Role \n Your responsibilities will include: \n \u25cf Requirement Gathering: Collaborate with stakeholders, including product managers, clients, and internal teams, to gather and document detailed business requirements related to retirement products and services. \n \u25cf Data Analysis: Analyze complex data sets, including financial data, customer information, and market trends, to identify patterns, trends, and opportunities in the retirement business domain. \n \u25cf Business Process Mapping: Document current and future business processes, identifying areas for improvement, efficiency gains, and automation opportunities. \n \u25cf Requirements Documentation: Create clear and concise business requirement documents, use cases, and user stories that outline functional and non-functional specifications for retirement business projects. \n \u25cf Data Modeling: Develop data models and collaborate with data engineers and architects to ensure data integrity and support reporting and analytics needs. \n \u25cf Risk Assessment: Assess potential risks and challenges associated with retirement products and services, and develop mitigation strategies to ensure business continuity. \n \u25cf Impact Analysis: Evaluate the impact of proposed changes or enhancements to existing retirement products and services and communicate these findings to relevant stakeholders. \n \u25cf Quality Assurance: Collaborate with quality assurance teams to define test cases, validate solutions against business requirements, and ensure the quality of retirement business systems. \n \u25cf Stakeholder Communication: Maintain open and effective communication with stakeholders throughout the project lifecycle, providing updates on progress, addressing concerns, and facilitating decision-making. \n \u25cf Market Research: Stay up-to-date with industry trends, regulatory changes, and competitors' offerings in the retirement business domain to inform strategic decisions. \n \u25cf Training and Documentation: Create training materials and documentation to ensure that stakeholders and end-users understand new processes and systems. \n \u25cf Continuous Improvement: Proactively identify opportunities for process improvement and efficiency gains in the retirement business domain. \n Ideal Profile \n \u25cf Bachelor's degree in business, finance, or a related field; a Master's degree is a plus. \n \u25cf Proven experience as a Business Analyst, preferably in the retirement business or financial services industry. \n \u25cf Strong analytical skills with the ability to translate data into actionable insights. \n \u25cf Proficiency in data analysis tools and techniques. \n \u25cf Excellent communication and interpersonal skills to work effectively with cross-functional teams. \n \u25cf Knowledge of retirement industry regulations and compliance requirements. \n \u25cf Familiarity with software development methodologies (Agile, Scrum, etc.). \n \u25cf Certification in business analysis (e.g., CBAP) is a plus. \n What's on Offer? \n \u25cf Join a team of world class IT professionals \n \u25cf Comprehensive salary package \n \u25cf Great opportunity for growth and development \n Job Type: Contract \n Salary: $55.00 - $58.00 per hour \n Experience level: \n \n 6 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Only W2 or 1099 can be considered \n \n Experience: \n \n Open Payment Framework: 3 years (Required) \n omni web solutions: 2 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " \u25cf Training and Documentation: Create training materials and documentation to ensure that stakeholders and end-users understand new processes and systems. \n \u25cf Continuous Improvement: Proactively identify opportunities for process improvement and efficiency gains in the retirement business domain. \n Ideal Profile \n \u25cf Bachelor's degree in business, finance, or a related field; a Master's degree is a plus. \n \u25cf Proven experience as a Business Analyst, preferably in the retirement business or financial services industry. \n \u25cf Strong analytical skills with the ability to translate data into actionable insights. \n \u25cf Proficiency in data analysis tools and techniques. \n \u25cf Excellent communication and interpersonal skills to work effectively with cross-functional teams. \n \u25cf Knowledge of retirement industry regulations and compliance requirements. \n \u25cf Familiarity with software development methodologies (Agile, Scrum, etc.). ",
        "techs": [
            "training and documentation",
            "continuous improvement",
            "bachelor's degree",
            "master's degree",
            "business analyst",
            "retirement business",
            "financial services industry",
            "analytical skills",
            "data analysis tools",
            "communication skills",
            "interpersonal skills",
            "cross-functional teams",
            "retirement industry regulations",
            "compliance requirements",
            "software development methodologies"
        ],
        "cleaned_techs": [
            "continuous improvement",
            "retirement business",
            "financial services industry",
            "data analysis tools",
            "cross-functional teams",
            "retirement industry regulations",
            "compliance requirements",
            "software development methodologies"
        ]
    },
    "b0d9c3fcd8734a7e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75000.0,
        "salary_max": 90000.0,
        "title": "Financial Systems Analyst (100% Remote)",
        "company": "Business Integra Inc",
        "desc": "Title:  \u201cFinancial Systems Analyst / \u201cOracle ERP Project/Program Management\u201d \n Work Mode:  100% Remote job \n Contract:  18 Months \n Job Description: \n Role Summary / Purpose: \n \n This role will support Accounting & Financial systems. \n Responsible for driving technical accounting compliance, financial and operational internal controls, process simplification, and operational excellence to deliver accurate financial reporting and analysis. \n This will include being the functional owner of 1-2 Oracle modules (AP, AR, Project, Inventory, etc.) in addition to any other systems/platforms outside of Nuclear\u2019s ERP that the Finance team uses in their standard work. \n The role will focus on implementing new Operating Units (OU) and will include project management for the implementations plus any additional support of the new OUs. \n The role is highly analytical and requires strong Accounting Information Systems knowledge or experience. \n \n Essential Responsibilities: \n \n Extract financial and attribute data from core accounting system to perform appropriate analyses. \n Analyze data and defines relevant information; interprets data for the purpose of determining root cause analysis or past performance. \n Liaison with other functional owners to understand requirements and recommend standardized solutions to meet reporting needs. \n Partner with Reporting team to define and oversee data quality standards to meet data requirements and expectations for Finance users. \n Recommends changes to processes to improve and achieve greater efficiencies by documenting business requirements and participating in testing efforts. \n Utilizes in-depth knowledge of a discipline and analytical thinking to execute policy/strategy. Basic knowledge of related job disciplines. \n Acts as a resource for colleagues with less experience. \n May lead small projects with low risks and resource requirements. Explains information; developing skills to bring team members to consensus around topics within field. \n Uses some judgment and can propose different solutions outside of set parameters to address more complicated, day-to-day problems. Has ability to prioritize information for data analysis. Uses technical experience and analytical thinking. Uses multiple internal and limited external sources outside of own team to arrive at decisions. \n \n Qualifications / Requirements: \n \n Bachelor's degree in accounting, finance, or related field \n 4+ years of related work experience as financial analyst \n Worked in a technical role within an Accounting, Finance, or FP&A department \n Strong oral and written communication skills. Demonstrated ability to analyze and resolve problems. \n Ability to document, plan, market, and execute programs. Established project management skills \n Intermediate to advanced Excel skills/knowledge \n \n Additional Desired Characteristics: \n \n Experience with Oracle ERP project/program management \n Experience with SQL, Query Writing \n Related work experience with ERP systems development and management from a financial perspective \n Account Reconciliation experience \n Supported internal/external audits \n Experience working with others on a global basis from a remote location \n \n Job Type: Contract \n Salary: $75,000.00 - $90,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n Monday to Friday \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Financial Systems: 5 years (Required) \n SQL: 5 years (Required) \n Query Writing: 5 years (Required) \n Data Analyst / Analysis: 5 years (Required) \n Oracle ERP project/program management: 5 years (Required) \n Oracle ERP: 5 years (Required) \n Government / Federal projects: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Analyze data and defines relevant information; interprets data for the purpose of determining root cause analysis or past performance. \n Liaison with other functional owners to understand requirements and recommend standardized solutions to meet reporting needs. \n Partner with Reporting team to define and oversee data quality standards to meet data requirements and expectations for Finance users. \n Recommends changes to processes to improve and achieve greater efficiencies by documenting business requirements and participating in testing efforts. \n Utilizes in-depth knowledge of a discipline and analytical thinking to execute policy/strategy. Basic knowledge of related job disciplines. \n Acts as a resource for colleagues with less experience. \n May lead small projects with low risks and resource requirements. Explains information; developing skills to bring team members to consensus around topics within field. \n Uses some judgment and can propose different solutions outside of set parameters to address more complicated, day-to-day problems. Has ability to prioritize information for data analysis. Uses technical experience and analytical thinking. Uses multiple internal and limited external sources outside of own team to arrive at decisions. \n \n Qualifications / Requirements: \n \n Bachelor's degree in accounting, finance, or related field \n 4+ years of related work experience as financial analyst \n Worked in a technical role within an Accounting, Finance, or FP&A department \n Strong oral and written communication skills. Demonstrated ability to analyze and resolve problems. ",
        "techs": [
            "analytical thinking",
            "data analysis",
            "data quality standards",
            "financial analyst",
            "oral and written communication skills"
        ],
        "cleaned_techs": [
            "analytical thinking",
            "data quality standards"
        ]
    },
    "feb06fa9a7bd05d7": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 80713.55,
        "salary_max": 102201.33,
        "title": "Senior Technical Business Analyst",
        "company": "Jack Henry and Associates, Inc.",
        "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n \n Under minimal supervision, contributes to the software development process by ensuring complete and accurate documentation of system requirements .   Serves as a liaison between customers and development departments during the product development phase. \n \n   What you\u2019ll be responsible for: \n \n Act as servant leader, to organize and lead scrum events. \n Coach team on adhering the scrum framework and adopting agile practices. \n Assist product owner in building and maintaining backlog. \n Gather business requirements, functional specifications, and cross team dependencies. \n Define acceptance criteria to satisfy the definition of done. \n Ensure that internal and external documentation is created. \n Ensure sprint and release metrics are followed to provide with deliverables. \n  Serves as a resource and/or participant in business process re-design activities. Assists the customer in determining if and how system enhancements may improve process flow and business function. \n \n \n Responsible for creating business requirements and system documentation, as well as contributing to end-user and project management documentation. \n  Works with quality assurance and programming teams to ensure changes are migrated into production correctly. \n  Interacts with technical teams to convey business requirements. \n \n \n Works with industry research groups to prepare for product trends. \n May perform application, systems, and regression tests.  \n May assist less experienced peers. \n May perform other job duties as assigned. \n \n What you\u2019ll need to have: \n \n Minimum of 6 years of experience serving as Technical Business Analyst. \n  Minimum of 4 years of Scrum Master experience. \n \n What would be nice for you to have: \n \n Bachelor\u2019s degree preferred. \n Has a wide range of experience and able to resolve complex issues. Works on complex and diverse projects. Analysis requires an in-depth evaluation of variable factors. Exercises good judgment in selecting methods, techniques, and evaluation criteria for obtaining solutions. \n Excellent knowledge of the financial industry. \n Excellent communication and customer interaction skills. \n Excellent project management skills. \n Excellent knowledge of Microsoft Office applications. \n Good grammar and writing skills. \n Able to define system and functional requirements.  \n Able to meet aggressive deadlines. \n Able to interact with and communicate well with other technical associates. \n \n \n \n \n  If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c5e260b916bce337": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 85000.0,
        "title": "Business Analyst II",
        "company": "GovEase",
        "desc": "Job Type:  Full-time \n Company Information: \n GovEase Auction a leading technology company specializing in providing innovative solutions for government agencies. Our cutting-edge platform enables efficient and transparent auctions, empowering our clients to optimize their procurement processes. We are seeking a highly skilled and motivated Business Analyst II to join our dynamic team and contribute to our mission of revolutionizing government auctions. \n Job Description: \n As a Business Analyst II at GovEase Auction, you will play a crucial role in driving business growth and maximizing operational efficiency. Working closely with cross-functional teams, you will be responsible for handling complex data sets, efficiently administering our platform, and assisting in further development of new and current products. Your ability to translate business requirements into technical solutions and to implement those solutions on a consistent basis will be essential for the success of our platform. \n Responsibilities: \n \n Conduct comprehensive analysis of auction data, identify patterns, and draw meaningful conclusions to support data-driven decision-making. \n Collaborate with stakeholders to define business requirements and translate them into functional specifications for software development. \n Participate in the design, development, and testing of new features and enhancements for our auction platform. \n Monitor and analyze platform performance metrics, providing recommendations for improvements and optimizations. \n Perform data validation and ensure data integrity throughout the system, identifying and resolving any data discrepancies. \n Proactively identify opportunities for process improvement and efficiency gains, working closely with cross-functional teams to implement solutions. \n Create and maintain detailed documentation, including business process flows, use cases, and user stories. \n Collaborate with product managers, developers, and QA teams to ensure the successful delivery of projects within established timelines. \n Support end-users by providing training and guidance on system functionalities and resolving any platform-related issues. \n Stay up to date with industry trends and best practices in business analysis and technology advancements, bringing innovative ideas to the team. \n \n Desired Skills & Experience: \n \n Bachelor's degree in Business Administration, Computer Science, Information Systems, or a related field. Advanced degree is a plus. \n Minimum of 3 years of experience as a Business Analyst or in a similar analytical role, preferably within the technology sector. \n Strong analytical and problem-solving skills, with the ability to work with complex data sets and draw meaningful insights. \n Proficiency in data analysis tools and techniques, such as SQL, Excel, and data visualization tools (e.g., Tableau, Power BI). \n Experience with requirements gathering, process modeling, and documenting functional specifications. \n Familiarity with agile development methodologies and the ability to work in an iterative and collaborative environment. \n Excellent communication skills, with the ability to effectively present complex concepts to both technical and non-technical stakeholders. \n Detail-oriented mindset with a focus on delivering high-quality work within established deadlines. \n Strong organizational skills, including the ability to prioritize tasks and manage multiple projects simultaneously. \n Knowledge of government procurement processes and regulations is a plus. \n \n Benefits: \n \n BCBS Health Insurance \n Vision Insurance \n Paid Vacation & Holiday Pay \n Training and Advancement opportunities \n \n GovEase is an Equal Employment Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law. GovEase will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. \n Job Type: Full-time \n Pay: $65,000.00 - $85,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Describe proficiency and skills with Microsoft Excel. \n Describe prior data analysis projects and tasks encountered. \n List tools previously used in business analyst roles. \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Business analysis: 3 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Collaborate with product managers, developers, and QA teams to ensure the successful delivery of projects within established timelines. \n Support end-users by providing training and guidance on system functionalities and resolving any platform-related issues. \n Stay up to date with industry trends and best practices in business analysis and technology advancements, bringing innovative ideas to the team. \n \n Desired Skills & Experience: \n \n Bachelor's degree in Business Administration, Computer Science, Information Systems, or a related field. Advanced degree is a plus. \n Minimum of 3 years of experience as a Business Analyst or in a similar analytical role, preferably within the technology sector. \n Strong analytical and problem-solving skills, with the ability to work with complex data sets and draw meaningful insights. \n Proficiency in data analysis tools and techniques, such as SQL, Excel, and data visualization tools (e.g., Tableau, Power BI). \n Experience with requirements gathering, process modeling, and documenting functional specifications. \n Familiarity with agile development methodologies and the ability to work in an iterative and collaborative environment. \n Excellent communication skills, with the ability to effectively present complex concepts to both technical and non-technical stakeholders. \n Detail-oriented mindset with a focus on delivering high-quality work within established deadlines. ",
        "techs": [
            "sql",
            "excel",
            "tableau",
            "power bi"
        ],
        "cleaned_techs": [
            "sql",
            "excel",
            "tableau",
            "powerbi"
        ]
    },
    "9da7f42938d4e027": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 113425.71,
        "salary_max": 143622.22,
        "title": "Lead Business Analyst",
        "company": "Global Alliant Inc",
        "desc": "Lead Business Analyst- Washington, DC - Remote - Candidates needs to be in USA to apply for this position. \n  We are open for C2C/1099/W2 for this position but cannot entertain H1B at this point of time. \n \n \n  Job Requirement- \n \n Extensive hands-on development in MS Dynamics CRM, particularly in Dynamics entities like Workflows, Business Entities, Business Logic, Data Access.  \n Excellent writing skills required, as is the ability to analyze, synthesize, and condense text that includes technical terminology. \n In-depth experience with the MS Office Suite (PowerPoint, Word, Visio, etc.) and In-depth experience researching, editing, and preparing documentation and familiarity. \n Must have a solid technical background and extensive experience working closely with technical staff (system Engineers, software developers, test engineers, etc.). \n Experience with .Net, Azure, MS Dynamics and case management. \n Experience with Azure cloud services such as Azure Functions, Service Bus, Logic Apps, and Blob Storage \n \n \n \n  If you are interested in applying for the position, please reach out to me at mayuri.s@globalalliantinc.com \n  Global Alliant, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a covered veteran in accordance with applicable federal, state, and local laws. We especially invite women, minorities, veterans, and individuals with disabilities to apply.",
        "cleaned_desc": " Extensive hands-on development in MS Dynamics CRM, particularly in Dynamics entities like Workflows, Business Entities, Business Logic, Data Access.  \n Excellent writing skills required, as is the ability to analyze, synthesize, and condense text that includes technical terminology. \n In-depth experience with the MS Office Suite (PowerPoint, Word, Visio, etc.) and In-depth experience researching, editing, and preparing documentation and familiarity.   Must have a solid technical background and extensive experience working closely with technical staff (system Engineers, software developers, test engineers, etc.). \n Experience with .Net, Azure, MS Dynamics and case management. \n Experience with Azure cloud services such as Azure Functions, Service Bus, Logic Apps, and Blob Storage ",
        "techs": [
            "ms dynamics crm",
            "workflows",
            "business entities",
            "business logic",
            "data access",
            "ms office suite",
            "powerpoint",
            "word",
            "visio",
            ".net",
            "azure",
            "case management",
            "azure functions",
            "service bus",
            "logic apps",
            "blob storage"
        ],
        "cleaned_techs": [
            "ms dynamics crm",
            "workflows",
            "business entities",
            "business logic",
            "data access",
            "microsoft",
            "powerpoint",
            "word",
            "visio",
            ".net",
            "azure",
            "case management",
            "service bus",
            "logic apps",
            "blob storage"
        ]
    },
    "0fec6bb79c0bbddc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 73100.0,
        "salary_max": 166000.0,
        "title": "Salesforce Business Analyst, Mid",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Melbourne,FL,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180022\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Salesforce Business Analyst, Mid\n          \n \n  The Opportunity: \n \n \n  Are you looking for an opportunity to establish processes and drive technology innovation? You know that true progress is made at the intersection of business and tech, and as an IT business analyst, you\u2019ll be highly skilled in both. Here, you\u2019ll have the chance to work with an Agile team as they develop digital products to support your clients\u2019 most pressing missions. We\u2019re looking for someone like you to propel business analytics and processes forward, including delve into technology trends to deliver user-friendly client experiences. \n \n \n \n  As an IT Business Analyst, you\u2019ll develop leading-edge Salesforce business solutions. Partnering with your team of architects, developers, testers, and leading junior analysts and other key stakeholders, you\u2019ll identify clients\u2019 business needs, gather user requirements, and develop user stories. You\u2019ll understand the overall direction and nuanced user needs clearly, and you\u2019ll lead your team as they fulfill these needs by creating deployable features. Together, you\u2019ll deliver high business value products for our veterans. Ready to make an impact by transforming and modernizing federal healthcare? Work with us as we build systems to change for the better. \n \n \n \n  Join us. The world can\u2019t wait. \n \n \n \n \n  You Have: \n \n \n \n  2+ years of experience as a Business Analyst \n  1+ years of experience with the Salesforce platform \n  Experience communicating with technical and non-technical audience \n  Experience translating business needs into effective and detailed user stories, requirements, and acceptance criteria \n  Knowledge of Agile methodology \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelor's degree or 4+ years of experience as Business Analyst in lieu of a degree \n \n \n \n \n \n     Nice If You Have: \n \n \n \n  Experience planning and leading business requirements gathering sessions \n  Experience with Scaled Agile Framework \n  Experience in government or Healthcare IT industries \n  Knowledge of Visio or Lucid Chart \n  Salesforce Certification \n \n \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "19c8c25392c0fc85": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 72167.34,
        "salary_max": 91379.94,
        "title": "Business Analyst II (Remote)",
        "company": "Steel Point Solutions",
        "desc": "Steel Point Solutions is an amazing SBA Certified (8a), HUBZone, Small Disadvantaged Business (SDB) and a Woman Owned Small Business (WOSB) company. Established in 2013 with a vision of offering world class, integrated business solutions for all levels of Government and commercial enterprises. We are represented by a team of talented and qualified professionals who know how essential efficient, cost-effective integrated solutions are to your organization's success. Leveraging these resources, we strive daily to lead the industry in digital transformation and service delivery. \n  Due to Growth Steel Point is looking for a Business Analyst II to perform the following: \n  Coordinate tasks and assist in identifying gaps in infrastructure, collaborating with key subject matter experts to develop business cases, and advocating for IT infrastructure changes to meet requirements (system IT, infrastructure, & business process analysis). \n  Collaborate with key functional stakeholders and subject matter experts to identify future infrastructure needs and document business cases and requirements documents. Collaborate with infrastructure organizations and technical stakeholders to ensure functional requirements are met. \n  Analyze business processes to support gap analysis; assess impacts of these gaps upon the functional community and recommend prioritization and approaches to address gaps. Will also support analysis of alternatives, business case analysis, material solution implementation plans, technology plans (such as cloud migration, application rationalization)   and guide the functional communities toward a future state capability. \n  Assist in supporting planning and prioritization activities, analyzing and recommending courses of action to improve operational efficiency, increase workforce productivity, reduce organizational risk, comply with mandates, meet strategic objectives and functional requirements. \n  This position requires that the candidates have a flexible work style, with the ability to adjust priorities, respond to short-turn requests, and yet maintain focus on project success. Preferred individual will be self-motivated, with a high energy level, and a proactive work ethic. \n  Participate in SCRUM development sprints and summaries, weekly SCRUMs and retrospectives. \n  Qualifications: \n \n Requires strong organizational skills and action-oriented personality; experience leading tasks, tracking actions across multiple organizations. \n Prior acquisition, program management, financial management, human resource management, logistics, or security processes a considerable plus. \n Familiar with business designs: business models, functions, processes, job roles and customer interactions as well as how they are impacted by digitization, AI/automation and emerging technologies/techniques \n Ability to communicate effectively with a diverse set of customers or partners across multiple disciplines \n Requires experience using continuous process improvement methodologies, tools, techniques \n Experience with developing data dashboards \n History of designing, developing and implementing technical solutions, conducting business, financial, workforce, and technology analysis \n Requires experience with IT systems and infrastructure management; facilitation, documenting requirements, drafting policy recommendations, and writing official minutes. \n Requires familiarity with IT fundamentals (software development life cycle, technical design, and requirements documentation); prior experience in system or technology analysis (e.g., cloud, application rationalization), compliance, or portfolio management a plus. \n Requires power user skills in MS Office products (Excel, PowerPoint, Project, Access) \n Candidates with recent and relevant acquisition, contracts, financial management, logistics, or security experience are ideal. \n \n Skills: \n \n BS in Computer Information Systems and Science or Computer Science preferred or a related field. \n Three (3) or more years of experience in eliciting, gathering, documenting, and tracking business requirements; performing and analyzing information system, technical approach, business needs and analytical analysis, defining detailed requirements, validating solutions to prepare and conduct briefing \n \n Steel Point Solutions, LLC is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status.",
        "cleaned_desc": " Experience with developing data dashboards \n History of designing, developing and implementing technical solutions, conducting business, financial, workforce, and technology analysis \n Requires experience with IT systems and infrastructure management; facilitation, documenting requirements, drafting policy recommendations, and writing official minutes. \n Requires familiarity with IT fundamentals (software development life cycle, technical design, and requirements documentation); prior experience in system or technology analysis (e.g., cloud, application rationalization), compliance, or portfolio management a plus. \n Requires power user skills in MS Office products (Excel, PowerPoint, Project, Access) ",
        "techs": [
            "developing data dashboards",
            "designing technical solutions",
            "implementing technical solutions",
            "conducting business analysis",
            "conducting financial analysis",
            "conducting workforce analysis",
            "conducting technology analysis",
            "it systems management",
            "infrastructure management",
            "facilitation",
            "documenting requirements",
            "drafting policy recommendations",
            "writing official minutes",
            "familiarity with it fundamentals",
            "software development life cycle",
            "technical design",
            "requirements documentation",
            "system analysis",
            "technology analysis",
            "compliance",
            "portfolio management",
            "power user skills in ms office products (excel",
            "powerpoint",
            "project",
            "access)"
        ],
        "cleaned_techs": [
            "developing data dashboards",
            "designing technical solutions",
            "implementing technical solutions",
            "conducting business analysis",
            "conducting financial analysis",
            "conducting workforce analysis",
            "conducting technology analysis",
            "it systems management",
            "infrastructure management",
            "facilitation",
            "documenting requirements",
            "drafting policy recommendations",
            "writing official minutes",
            "familiarity with it fundamentals",
            "software development life cycle",
            "technical design",
            "system analysis",
            "technology analysis",
            "compliance",
            "portfolio management",
            "powerpoint",
            "project",
            "access)"
        ]
    },
    "b72ad1c1f3b8831e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 74800.0,
        "salary_max": 125000.0,
        "title": "Senior Technical Business Analyst",
        "company": "Jack Henry and Associates, Inc.",
        "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n  The Senior Technical Business Analyst will be joining one of our back-end services teams that is responsible for Jack Henry's Enterprise API Gateway and Jack Henry's Consumer and Enterprise Identity Provider services. This is a dynamic, agile software delivery team that provides an enterprise-level authentication integration platform and contributes to a mission-critical set of applications. The Senior Technical Business Analyst lives at the intersection of product and engineering, helping translate business requirements into technical specifications for our enterprise integration platforms.\n  \n \n \n  You are infinitely curious and thrive in an environment where you are constantly learning and growing. You want to be somewhere that you are trusted and surrounded by great engineers who rely on your input into the products being developed. Although you work in a team you are self-motivated and able to work with independence. You care deeply about your work, your team, and the business.\n  \n \n \n  This position will be filled to work Remotely within the U.S.\n  \n \n \n  The target salary range for this position is $74,800 \u2013 $125,000, based on location and experience.\n  \n \n \n  If you are interested in this position, please apply on or before October 2, 2023.\n  \n \n \n \n  What you\u2019ll be responsible for: \n \n \n \n \n \n  Interacting with product teams and stakeholders to gather system requirements. \n  Creating requirements and system documentation as well as contributing to engineering and end-user documentation. \n  Interacting with engineering teams to accurately describe product requirements. \n  Learning and staying up to date on trends and best practices in areas relevant to your team. \n  Assisting in application, system, and user-acceptance tests. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 7 years of technical business analysis experience or software engineering experience. \n  Experience interacting with REST APIs. \n  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.",
        "cleaned_desc": "  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   ",
        "techs": [
            "api documentation reading and interpretation",
            "workflow and sequence diagrams documentation",
            "communication skills (written and verbal)",
            "experience in banking",
            "government",
            "or other high security or highly regulated systems",
            "experience with nodejs",
            "javascript",
            "and/or typescript software teams",
            "business analysis or technical business analysis experience with larger-scale or complex project work",
            "oauth and open id connect experience",
            "experience developing and integrating with identity and access management platform."
        ],
        "cleaned_techs": [
            "experience in banking",
            "government",
            "experience with nodejs",
            "javascript",
            "and/or typescript software teams",
            "business analysis or technical business analysis experience with larger-scale or complex project work",
            "oauth and open id connect experience",
            "experience developing and integrating with identity and access management platform."
        ]
    },
    "bdd32d1b433f8edf": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 68013.54,
        "salary_max": 86120.29,
        "title": "Claims EDI Analyst",
        "company": "Berkshire Hathaway Direct Insurance Company",
        "desc": "The Claims EDI Assistant is responsible for entering FROI and SROI reports in a timely and accurate manner while also maintaining that the EDI (Electronic Data Interchange) adheres to state-specific reporting requirements. Daily tasks include data entry, investigating errors, collaborating with adjusters and identifying error trends. This position is a resource for the WC Claims staff while supporting the department and will report to the Claims Operations Manager.\n  \n \n \n   Job Responsibilities\n  \n \n \n   Duties are not limited to the below and will expand over time.\n  \n \n  Submit EDI First Report of Injury and Subsequent Reports (Using our vendor\u2019s web-based portal) \n  Research Workers Compensation Claims in the claim system for information needed to complete EDI reports \n  Analyze any EDI errors and work the with claim adjuster to make necessary corrections as stipulated by the state requirements \n  Review state websites for filing information, potential penalties and fines \n  Communicate with claims adjusting staff or other necessary internal staff regarding missing data \n  Provide front line support for the Worker\u2019s Comp Claims Adjusting staff and leadership by answering low to highly complex EDI questions/issues \n  Gain knowledge concerning rules, statutes and required forms for each state jurisdiction \n \n \n \n   Preferred Knowledge\n  \n \n \n   Knowledge, Skills & Abilities:\n  \n \n  Ability to do critical thinking, analyzing data, problem solving and is detailed oriented \n  Ability to read and comprehend excel worksheets along with strong math skills \n  Exceptional organizational skills and ability to work independently \n  Punctual and consistent attendance is required in this position \n \n \n   EDUCATION:\n  \n \n  College degree or college level education preferred. \n \n \n \n   EXPERIENCE:\n  \n \n  Experience in Risk Management and/or Workers Comp with preferred prior experience/ knowledge of EDI business \n  Experience with PMS, CSS and HCS are a bonus \n \n \n \n   About Us\n  \n \n \n   biBERK is where commercial insurance buyers can obtain coverage for their businesses from insurers of the Berkshire Hathaway group of Insurance Companies, one of the best capitalized insurance groups in the world. Our ultimate parent, Berkshire Hathaway Inc. (berkshirehathaway.com) is a holding company with diversified interests in a host of industries, including insurance, energy, transportation and manufacturing. Most policies issued through \n   \n   biBERK.com\n    will be underwritten by Berkshire Hathaway Direct Insurance Company (\"BHDIC\"), which is an AM Best rated A++ insurer.\n  \n \n   BHDIC is domiciled in Omaha, Nebraska. BHDIC and the team at biBERK are focused on helping small business owners quickly and easily buy affordable insurance directly from a financially strong insurance company they can trust.\n  \n \n   Some Highlights of our Benefits are:\n  \n \n  Great work environment with growth opportunity \n  Subsidized downtown parking \n  Competitive compensation including bonus structure \n  Generous amounts of vacation and sick time \n  Closed on major holidays \n  401(k) with company match \n  A fantastic healthcare package \n  Tuition reimbursement after 6 months of employment",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "138efb2ff9c4ae55": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 74800.0,
        "salary_max": 125000.0,
        "title": "Senior Technical Business Analyst",
        "company": "Jack Henry and Associates, Inc.",
        "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n  The Senior Technical Business Analyst will be joining one of our back-end services teams that is responsible for Jack Henry's Enterprise API Gateway and Jack Henry's Consumer and Enterprise Identity Provider services. This is a dynamic, agile software delivery team that provides an enterprise-level authentication integration platform and contributes to a mission-critical set of applications. The Senior Technical Business Analyst lives at the intersection of product and engineering, helping translate business requirements into technical specifications for our enterprise integration platforms.\n  \n \n \n  You are infinitely curious and thrive in an environment where you are constantly learning and growing. You want to be somewhere that you are trusted and surrounded by great engineers who rely on your input into the products being developed. Although you work in a team you are self-motivated and able to work with independence. You care deeply about your work, your team, and the business.\n  \n \n \n  This position will be filled to work Remotely within the U.S.\n  \n \n \n  The target salary range for this position is $74,800 \u2013 $125,000, based on location and experience.\n  \n \n \n  If you are interested in this position, please apply on or before October 2, 2023.\n  \n \n \n \n  What you\u2019ll be responsible for: \n \n \n \n \n \n  Interacting with product teams and stakeholders to gather system requirements. \n  Creating requirements and system documentation as well as contributing to engineering and end-user documentation. \n  Interacting with engineering teams to accurately describe product requirements. \n  Learning and staying up to date on trends and best practices in areas relevant to your team. \n  Assisting in application, system, and user-acceptance tests. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 7 years of technical business analysis experience or software engineering experience. \n  Experience interacting with REST APIs. \n  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.",
        "cleaned_desc": "  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   ",
        "techs": [
            "api documentation",
            "workflow diagrams",
            "sequence diagrams",
            "nodejs",
            "javascript",
            "typescript",
            "oauth",
            "open id connect",
            "identity and access management platform"
        ],
        "cleaned_techs": [
            "workflow diagrams",
            "sequence diagrams",
            "nodejs",
            "javascript",
            "typescript",
            "oauth",
            "open id connect",
            "identity and access management platform"
        ]
    },
    "c6c9dcdc8a242545": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Data Analyst - Veeva Compass Solutions Consulting",
        "company": "Veeva Systems",
        "desc": "Veeva Systems is a mission-driven organization and pioneer in industry cloud, helping life sciences companies bring therapies to patients faster. As one of the fastest-growing SaaS companies in history, we surpassed $2B in revenue in our last fiscal year with extensive growth potential ahead.\n  \n \n \n  At the heart of Veeva are our values: Do the Right Thing, Customer Success, Employee Success, and Speed. We\u2019re not just any public company \u2013 we made history in 2021 by becoming a public benefit corporation (PBC), legally bound to balancing the interests of customers, employees, society, and investors.\n  \n \n \n  As a Work Anywhere company, we support your flexibility to work from home or in the office, so you can thrive in your ideal environment.\n  \n \n \n  Join us in transforming the life sciences industry, committed to making a positive impact on its customers, employees, and communities.\n  \n \n \n The Role \n \n \n \n  As a \n   Data Analyst focused on Veeva Compass Solutions Consulting and Pre-Sales Support , you will own analyses that demonstrate the quality, coverage, and strengths of our data network, as well as conduct data investigations prompted by inbound customer inquiries.\n  \n \n \n  You will be a member of a growing business unit at Veeva, working closely with Compass Strategy and Account Partners to position Compass data products (patient data and prescriber data) in-market and fuel product line growth.\n  \n \n \n  In your role, you will be responsible for performing and presenting pre-sales analysis to showcase Veeva Compass value to our customers. You\u2019ll perform qualitative and/or quantitative analyses to assist in the identification of data issues or anomalies that impact customers. You will curate observations of our data and customers\u2019 use of it, sharing feedback with Strategy and Product to enhance market positioning and inform the Compass roadmap.\n  \n \n \n  This is a great opportunity for someone who is passionate about health data and thrives in an entrepreneurial/start-up environment.\n  \n \n What You\u2019ll Do \n \n \n Research customer\u2019s therapeutic area  to understand diagnosis/treatment patterns, population characteristics, and market dynamics \n Build therapeutic area market definitions  to represent populations of interest for analysis \n Perform  data querying, cleansing, analysis, and QC  to support customer requests \n Manage projects and analyses to ensure timely  deliverables that meet client needs  and address key business questions \n Derive insights from prescription and medical claims data to  demonstrate the value and unique dimensions of our data network \n Understand data in the context of customer use cases, identify data gaps, and  develop recommendations as to how data may be used/interpreted \n Build overall  expertise on the data  in Veeva Compass, contributing to the development of normative databases, documentation, and standardized reporting to support customers \n Conduct exploratory analytics to  understand data anomalies  and  elevate meaningful observations  to the product for further analysis \n Collaborate closely with a cross-functional team  of Data Scientists, Product Managers, and Developers to ensure high-quality data delivery to our customers \n Gathering report requirements  from customers and  presenting results of analyses performed  to customers \n Lead and contribute to internal analytics initiatives supporting pre-sales  and highlighting recent market events, including data network profiling, therapeutic area analysis, and dashboarding \n \n Requirements \n \n 4+ years experience  working with big data for healthcare (claims data and prescriber data) \n Expert in  SQL \n Expert in  MS Office and/or Google Apps  (PowerPoint/Slides, Excel/Sheets, etc.) \n Proficient with visualization tools such as  Tableau, Power BI, Spotfire , etc. \n Understand how relational databases work, and experience designing  transformations, mappings,  and working with  reference tables \n Experience  investigating data issues  and working with a cross-functional team for problem resolution \n Excellent critical thinking, communication, and presentation skills \n \n Nice to Have \n \n Proficiency in Python \n Knowledge of Industry Standard billing codes such as ICD, CPT/HCPCS, NDC, etc. \n Therapeutic area knowledge \n Experience working with lab and genomics data \n Experience with ETL tools \n Experience working with a product and/or agile teams \n \n \n \n \n \n   #LI-Remote\n   \n \n   #BI-Remote\n   \n \n \n   Veeva\u2019s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.\n   \n \n \n   Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances. If you need assistance or accommodation due to a disability or special need when applying for a role or in our recruitment process, please contact us at talent_accommodations@veeva.com.",
        "cleaned_desc": " Requirements \n \n 4+ years experience  working with big data for healthcare (claims data and prescriber data) \n Expert in  SQL \n Expert in  MS Office and/or Google Apps  (PowerPoint/Slides, Excel/Sheets, etc.) \n Proficient with visualization tools such as  Tableau, Power BI, Spotfire , etc. \n Understand how relational databases work, and experience designing  transformations, mappings,  and working with  reference tables \n Experience  investigating data issues  and working with a cross-functional team for problem resolution \n Excellent critical thinking, communication, and presentation skills \n \n Nice to Have \n \n Proficiency in Python \n Knowledge of Industry Standard billing codes such as ICD, CPT/HCPCS, NDC, etc. \n Therapeutic area knowledge \n Experience working with lab and genomics data \n Experience with ETL tools ",
        "techs": [
            "sql",
            "ms office",
            "google apps",
            "powerpoint/slides",
            "excel/sheets",
            "tableau",
            "power bi",
            "spotfire",
            "relational databases",
            "transformations",
            "mappings",
            "reference tables",
            "python",
            "icd",
            "cpt/hcpcs",
            "ndc",
            "lab data",
            "genomics data",
            "etl tools"
        ],
        "cleaned_techs": [
            "sql",
            "microsoft",
            "google apps",
            "powerpoint/slides",
            "excel",
            "tableau",
            "powerbi",
            "spotfire",
            "relational databases",
            "transformations",
            "mappings",
            "reference tables",
            "python",
            "icd",
            "cpt/hcpcs",
            "ndc",
            "lab data",
            "genomics data",
            "etl tools"
        ]
    },
    "5b0aa55ff040e539": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 86961.086,
        "salary_max": 110112.12,
        "title": "Business Analyst - Remote",
        "company": "Optum",
        "desc": "Opportunities at Change Healthcare , part of the Optum family of businesses. We are transforming the health care system through innovative technology and analytics. Find opportunities to make a difference in a variety of career areas as we all play a role in accelerating health care transformation. Help us deliver cutting-edge solutions for patients, hospitals and insurance companies, resulting in healthier communities. Use your talents to improve the health outcomes of millions of people and discover the meaning behind:  Caring. Connecting. Growing together. \n \n \n \n The responsibility of the Business Analyst will successfully implement new customers in an effective and timely manner, ensuring that all detailed requirements are in place by the set deadline. Projects will involve leading cross-functional teams, comprised mainly of operations and IT resources, to execute enhancements and improvements based on strategic business initiatives. This role will require effective communication and coordination both internally, as well as externally. \n \n You\u2019ll enjoy the flexibility to work remotely * from anywhere within the U.S. as you take on some tough challenges. \n \n \n \n Primary Responsibilities: \n \n \n \n Creates project plans, task lists, detailed work plans to drive a new client start-up to completion that will involve client, operations, IT and hitting revenue goals with input and assistance from other leaders \n Takes projects from original concept through final implementation and manages existing projects \n Track tasks assigned to the project team and prepare regular status reports \n Regular and proactive meeting cadence established to drive deliverables of project \n Develop and assist in deliverable schedules \n Publish status for all projects in progress \n Frequently interacts with internal /external customers and/or functional peer group managers  \n Assesses project issues and develops resolutions to meet quality, processing, and client-satisfaction goals \n Work is reviewed and measured based on meeting objectives and schedules \n Other duties as assigned \n \n \n \n \n \n \n \n You\u2019ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in. \n \n \n Required Qualifications: \n \n \n \n BA or BS degree or equivalent experience \n 5+ years of experience in Business Analysis, with experience writing clear and concise requirement documents to clearly define expectations \n 2+ years of healthcare experience, specific to clearinghouse, with exposure to either provider and/or payer community \n ANSI/HIPAA knowledge \n Proven ability to create executive level communication \n Willing or ability to 25% travel is required with this position \n \n \n \n \n Preferred Qualifications: \n \n \n \n PMP certification  \n Process improvement or Lean Six Sigma background \n Solid understanding of proven project management methodologies \n Proven ability to work with large amounts of data, including checks for integrity, summation, and effective communication (written and verbal) to internal and external constituents \n Proven ability to manage multiple priorities \n Proven ability to manage through challenging conversations independently \n Proven excellent organizational, communication and interpersonal skills \n \n \n \n California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island, or Washington Residents Only:  The salary range for California, Colorado, Connecticut, Nevada, New Jersey, New York, Rhode Island or Washington residents is $85,000 to $167,300. Pay is based on several factors including but not limited to education, work experience, certifications, etc. In addition to your salary, UnitedHealth Group offers benefits such as, a comprehensive benefits package, incentive and recognition programs, equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). No matter where or when you begin a career with UnitedHealth Group, you\u2019ll find a far-reaching choice of benefits and incentives.\n   \n \n \n \n \n All employees working remotely will be required to adhere to UnitedHealth Group\u2019s Telecommuter Policy \n \n \n \n \n   \n \n \n At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone\u2013of every race, gender, sexuality, age,  location  and income\u2013deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized  groups  and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering  equitable  care that addresses health disparities and improves health outcomes \u2014 an enterprise priority reflected in our mission . \n \n \n \n \n \n \n \n Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action  employer  and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law . \n \n \n \n UnitedHealth Group is a  drug -  free workplace. Candidates  are required to  pass a drug test before beginning employment .",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4f7c1b9ee566c19e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 117000.0,
        "salary_max": 143000.0,
        "title": "Senior Business Intelligence Administrator - Business Objects",
        "company": "Cotiviti",
        "desc": "Overview: \n  \n   The Sr BI Administrator oversees the administration, operation, monitoring, tuning, and patching of the corporate Business Intelligence (BI) and Analytic Systems. This position requires expertise in the maintenance and operation of SAP BO BI applications and components and develops and oversees monitoring systems to measure usage and ensure operational stability. Works on multiple projects in a deadline driven environment while maintaining a high bar for customer success.\n   Responsibilities: \n  \n Install, upgrade, configure, deploy, automate, monitor, and optimize the performance of Business Objects application. \n  Submit and manage issues and enhancement cases with BI for administration/environment related items. \n  Expertise in Administration of Business Objects Business Intelligence Platform 3.1, 4.1/4.3. Expertise in Administration of Business Objects Data Services and Information Steward 4.1/4.2/4.3 BO Servers Upgrade from version BO BI 4.0 to latest version BO BI 4.1. BO Ds and IS Servers Upgrade from version 4.1 to latest version 4.2.  \n Develop mechanisms and automation for deploying BI projects and configuration changes across the various environments. \n  Windows and/or Linux Operating System Administration \n  Support BI integrations across Enterprise data environments like ETL Development, Hadoop, Oracle, MSSQL, Vertica, and Salesforce connectivity. \n  Support development teams via object/code migrations across environments \n  Develop mechanisms and automation for deploying or refreshing BI projects and configuration changes across the various environments, including User/Group Provisioning and DB Instances \n  Support BI and development teams with user/group security provisioning in BI \n  Facilitate customer user provisioning in Business Objects \n  Primary owner of test, build, release process in development and production infrastructures. Responsible to execute standard software source control, QA processes, build plan, deploy software to all development and production environments, continuous improvement of release processes including using automation, manual tools and methods. \n  Adopt and communicate new concepts, ideas, techniques, and best practices specific to BI \n  Deliver performance tuning of SAP BO architecture. \n  Qualifications: \n  \n Bachelor's degree in Computer Science, Information Technology, or equivalent \n  5+ years of BI and Data Warehousing experience; 4+ years as SAP BO Administrator \n  Knowledge of DevOps, particularly server management: Windows Server, VMware, Linux is a plus/beneficial. \n  Experience with Oracle and SQL Server databases \n  Knowledge of SAC (hybrid with BO)  \n Experience with cluster environment  \n Experience with WEBI and Crystal functionalities  \n Understanding security set up and environment refresh mechanism, system upgrade and vulnerability patches \n  Experience with SAP Business Objects BI4.2/XIR3.1, IDT/UDT, Dashboard/Design Studio,WEB I(Web Intelligence), Lumira, Crystal Reports, RDBMS knowledge(Netezza, DB2, Oracle atleast one),Strong Knowledge on BO Admin(User Security, Promotion/Migration), \n  Good experience in design & developing of IDT/UDT Universe. Should have strong experience in creating complex dashboard using Dashboard designer, Lumira and Design Studio tool. Experience in creating complex WEB I(Web Intelligence) reports.  \n Experience designing BI based architectures. Includes solid understanding of security, report and information distribution, and other related BI enterprise concerns and considerations. \n  Excellent interpersonal/communication skills with professional staff, senior level executives and the community at large \n  Ability to work efficiently in a team environment as well as independently. \n  Working knowledge of the BI integration with custom software applications using Java or .Net preferred \n \n \n  Working Conditions and Physical Requirements: \n \n \n  Remaining in a stationary position, often standing or sitting for prolonged periods. \n  Communicating with others to exchange information. \n  Repeating motions that may include the wrists, hands and/or fingers. \n  Assessing the accuracy, neatness and thoroughness of the work assigned. \n  No adverse environmental conditions expected. \n \n \n  Base compensation ranges from $117,000 to $143,000. Specific offers are determined by various factors, such as experience, education, skills, certifications, and other business needs. \n \n \n \n \n \n This role is eligible for discretionary bonus consideration \n \n \n \n  Cotiviti offers team members a competitive benefits package to address a wide range of personal and family needs, including medical, dental, vision, disability, and life insurance coverage, 401(k) savings plans, paid family leave, 9 paid holidays per year, and 17-27 days of Paid Time Off (PTO) per year, depending on specific level and length of service with Cotiviti. For information about our benefits package, please refer to our  \n Careers page. \n \n \n \n  #LI-REMOTE\n  \n \n   #LI-AK1\n  \n \n   #senior",
        "cleaned_desc": "Overview: \n  \n   The Sr BI Administrator oversees the administration, operation, monitoring, tuning, and patching of the corporate Business Intelligence (BI) and Analytic Systems. This position requires expertise in the maintenance and operation of SAP BO BI applications and components and develops and oversees monitoring systems to measure usage and ensure operational stability. Works on multiple projects in a deadline driven environment while maintaining a high bar for customer success.\n   Responsibilities: \n  \n Install, upgrade, configure, deploy, automate, monitor, and optimize the performance of Business Objects application. \n  Submit and manage issues and enhancement cases with BI for administration/environment related items. \n  Expertise in Administration of Business Objects Business Intelligence Platform 3.1, 4.1/4.3. Expertise in Administration of Business Objects Data Services and Information Steward 4.1/4.2/4.3 BO Servers Upgrade from version BO BI 4.0 to latest version BO BI 4.1. BO Ds and IS Servers Upgrade from version 4.1 to latest version 4.2.  \n Develop mechanisms and automation for deploying BI projects and configuration changes across the various environments. \n  Windows and/or Linux Operating System Administration \n  Support BI integrations across Enterprise data environments like ETL Development, Hadoop, Oracle, MSSQL, Vertica, and Salesforce connectivity. \n  Support development teams via object/code migrations across environments \n  Develop mechanisms and automation for deploying or refreshing BI projects and configuration changes across the various environments, including User/Group Provisioning and DB Instances    Support BI and development teams with user/group security provisioning in BI \n  Facilitate customer user provisioning in Business Objects \n  Primary owner of test, build, release process in development and production infrastructures. Responsible to execute standard software source control, QA processes, build plan, deploy software to all development and production environments, continuous improvement of release processes including using automation, manual tools and methods. \n  Adopt and communicate new concepts, ideas, techniques, and best practices specific to BI \n  Deliver performance tuning of SAP BO architecture. \n  Qualifications: \n  \n Bachelor's degree in Computer Science, Information Technology, or equivalent \n  5+ years of BI and Data Warehousing experience; 4+ years as SAP BO Administrator \n  Knowledge of DevOps, particularly server management: Windows Server, VMware, Linux is a plus/beneficial. \n  Experience with Oracle and SQL Server databases \n  Knowledge of SAC (hybrid with BO)  \n Experience with cluster environment    Experience with WEBI and Crystal functionalities  \n Understanding security set up and environment refresh mechanism, system upgrade and vulnerability patches \n  Experience with SAP Business Objects BI4.2/XIR3.1, IDT/UDT, Dashboard/Design Studio,WEB I(Web Intelligence), Lumira, Crystal Reports, RDBMS knowledge(Netezza, DB2, Oracle atleast one),Strong Knowledge on BO Admin(User Security, Promotion/Migration), \n  Good experience in design & developing of IDT/UDT Universe. Should have strong experience in creating complex dashboard using Dashboard designer, Lumira and Design Studio tool. Experience in creating complex WEB I(Web Intelligence) reports.  \n Experience designing BI based architectures. Includes solid understanding of security, report and information distribution, and other related BI enterprise concerns and considerations. \n  Excellent interpersonal/communication skills with professional staff, senior level executives and the community at large \n  Ability to work efficiently in a team environment as well as independently. \n  Working knowledge of the BI integration with custom software applications using Java or .Net preferred \n \n \n  Working Conditions and Physical Requirements: \n \n ",
        "techs": [
            "sap bo bi applications",
            "sap bo bi components",
            "business objects business intelligence platform 3.1",
            "business objects business intelligence platform 4.1/4.3",
            "business objects data services",
            "business objects information steward",
            "etl development",
            "hadoop",
            "oracle",
            "mssql",
            "vertica",
            "salesforce connectivity",
            "windows operating system administration",
            "linux operating system administration",
            "user/group provisioning in bi",
            "test/build/release process",
            "automation",
            "devops",
            "server management (windows server",
            "vmware",
            "linux)",
            "oracle databases",
            "sql server databases",
            "sac (hybrid with bo)",
            "cluster environment",
            "webi",
            "crystal functionalities",
            "security setup",
            "system upgrade",
            "vulnerability patches",
            "sap business objects bi4.2/xir3.1",
            "idt/udt",
            "dashboard/design studio",
            "web i (web intelligence)",
            "lumira",
            "crystal reports",
            "rdbms knowledge (netezza",
            "db2",
            "oracle)",
            "bo admin (user security",
            "promotion/migration)",
            "idt/udt universe design and development",
            "dashboard designer",
            "lumira",
            "design studio",
            "web i (web intelligence) report creation",
            "bi-based architectures",
            "java or .net integration with bi applications."
        ],
        "cleaned_techs": [
            "sap bo bi components",
            "business objects business intelligence platform 3.1",
            "business objects business intelligence platform 4.1/4.3",
            "business objects data services",
            "business objects information steward",
            "etl development",
            "hadoop",
            "oracle",
            "mssql",
            "vertica",
            "salesforce connectivity",
            "windows operating system administration",
            "linux operating system administration",
            "user/group provisioning in bi",
            "test/build/release process",
            "automation",
            "devops",
            "server management (windows server",
            "vmware",
            "linux)",
            "sql",
            "sac (hybrid with bo)",
            "cluster environment",
            "webi",
            "crystal functionalities",
            "system upgrade",
            "vulnerability patches",
            "sap business objects bi4.2/xir3.1",
            "idt/udt",
            "dashboard/design studio",
            "web i (web intelligence)",
            "lumira",
            "crystal reports",
            "rdbms knowledge (netezza",
            "db2",
            "promotion/migration)",
            "idt/udt universe design and development",
            "dashboard designer",
            "design studio",
            "web i (web intelligence) report creation",
            "bi-based architectures"
        ]
    },
    "2497be0f17610599": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81345.0,
        "salary_max": 105270.0,
        "title": "Senior Analyst - Business Intelligence Solutions",
        "company": "U.S. Bank National Association",
        "desc": "At U.S. Bank, we\u2019re on a journey to do our best. Helping the customers and businesses we serve to make better and smarter financial decisions and enabling the communities we support to grow and succeed. We believe it takes all of us to bring our shared ambition to life, and each person is unique in their potential. A career with U.S. Bank gives you a wide, ever-growing range of opportunities to discover what makes you thrive at every stage of your career. Try new things, learn new skills and discover what you excel at\u2014all from Day One. \n \n  Job Description \n  Responsible for very complex reporting projects that gather and integrate large volumes of data, performs in depth analysis, interprets results and develops actionable insights and recommendations for use across the company for customer and employee populations. Acquires data from multiple data sources in order to perform analysis and reporting. Identifies, analyzes and interprets trends or patterns in complex data in order to provide answers to business questions as well as provide recommendations for action. Presents data and analysis in a clear and concise manner allowing the audience to quickly understand the results and recommendations so they activate upon them and make data driven decisions. Collaborates with various partners to provide a holistic view of the analysis. Measures and monitors results of applied recommendations and present adjustments. Ensures all data acquisition, sharing and results of applied recommendations are compliant with company standards. \n \n  Basic Qualifications \n \n  Bachelor's degree, or equivalent work experience \n  Four to five years of data analysis experience \n \n  Preferred Skills/Experience \n \n  Experience in financial services, with thorough knowledge of HR systems or financial services products, customers, transactions and interaction data \n  Strong analytic skills with the ability to extract, collect, organize, analyze and interpret results for insights \n  Ability to data mine, analyze data, and present insights in a meaningful way \n  Ability to develop and maintain strategic partnership with Senior Business unit management, business partners and project sponsors, as well as communicate effectively with business, and development teams, end users, and product owners \n  Strong decision-making and problem-solving skills \n  Strong organization and project management skills \n  Effective interpersonal, verbal and written communication skills \n \n \n  The preferred working model for this role is hybrid from the locations listed but management will consider remote for the right candidate. Team members who are in a hybrid role typically spend three days a week at a U.S. Bank location, while having flexibility on their work location for the other working days. \n \n  If there\u2019s anything we can do to accommodate a disability during any portion of the application or hiring process, please refer to our disability accommodations for applicants. \n \n  Benefits: \n  Our approach to benefits and total rewards considers our team members\u2019 whole selves and what may be needed to thrive in and outside work. That's why our benefits are designed to help you and your family boost your health, protect your financial security and give you peace of mind. Our benefits include the following (some may vary based on role, location or hours): \n \n  Healthcare (medical, dental, vision) \n  Basic term and optional term life insurance \n  Short-term and long-term disability \n  Pregnancy disability and parental leave \n  401(k) and employer-funded retirement plan \n  Paid vacation (from two to five weeks depending on salary grade and tenure) \n  Up to 11 paid holiday opportunities \n  Adoption assistance \n  Sick and Safe Leave accruals of one hour for every 30 worked, up to 80 hours per calendar year unless otherwise provided by law \n \n \n  EEO is the Law \n  U.S. Bank is an equal opportunity employer committed to creating a diverse workforce. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors. \n \n  E-Verify \n  U.S. Bank participates in the U.S. Department of Homeland Security E-Verify program in all facilities located in the United States and certain U.S. territories. The E-Verify program is an Internet-based employment eligibility verification system operated by the U.S. Citizenship and Immigration Services. \n  The salary range reflects figures based on the primary location, which is listed first. The actual range for the role may differ based on the location of the role. In addition to salary, US Bank offers a comprehensive benefits package, including incentive and recognition programs, equity stock purchase 401k contribution and pension (all benefits are subject to eligibility requirements). Pay Range: $81,345.00 - $95,700.00 - $105,270.00\n   U.S. Bank will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.",
        "cleaned_desc": " \n  Preferred Skills/Experience \n \n  Experience in financial services, with thorough knowledge of HR systems or financial services products, customers, transactions and interaction data \n  Strong analytic skills with the ability to extract, collect, organize, analyze and interpret results for insights \n  Ability to data mine, analyze data, and present insights in a meaningful way \n  Ability to develop and maintain strategic partnership with Senior Business unit management, business partners and project sponsors, as well as communicate effectively with business, and development teams, end users, and product owners \n  Strong decision-making and problem-solving skills \n  Strong organization and project management skills ",
        "techs": [
            "hr systems",
            "financial services products",
            "data mining",
            "analytics",
            "data analysis",
            "strategic partnerships",
            "decision-making",
            "problem-solving",
            "organization",
            "project management"
        ],
        "cleaned_techs": [
            "hr systems",
            "financial services products",
            "data mining",
            "strategic partnerships",
            "decision-making",
            "problem-solving",
            "organization",
            "project management"
        ]
    },
    "6331c302fbed9fcf": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 96337.78,
        "salary_max": 121985.09,
        "title": "Business Analyst",
        "company": "CareMetx",
        "desc": "Job Description \n \n \n \n      CareMetx is seeking ambitious, motivated individuals with excellent communication, interpersonal and organizational skills who would like the opportunity to help people navigate the difficult healthcare landscape using their healthcare administration or information technology skills. When patients are prescribed high cost, specialty medications, organizations like CareMetx are hired by pharmaceutical companies to provide \"hub services.\" This niche industry has fast become an integral player in getting specialty products and devices to the patients who need them by managing the reimbursement for those products, identifying alternative funding when insurer's don't pay and providing clinical services when necessary. The hub maintains communication with physicians, specialty pharmacies, payers and others to assure patients get their medications in a timely fashion and continue to track progress while they are taking the medication.\n      \n \n \n Description \n \n \n POSITION SUMMARY: \n \n \n \n      The Business Analyst plays a critical role in supporting on-going product development through supporting intake of new business requests, assessing the impact of specific changes, prioritizing and sequencing the scrum team backlog, and partnering with the scrum team to prepare, execute, and deliver work across an on-going 2-week sprint cadence. This role is also expected to partner with Product Owners overseeing roadmap and release plan development within a particular product line to ensure that tactical delivery and sprint plans align to strategic planning. The Business Analyst is expected to gain knowledge of rapidly changing Product offerings, the technology we utilize to support them, and the broader pharmaceutical or healthcare industry. Demonstrable experience within a business analysis role within an Agile delivery environment is desired.\n      \n \n \n \n PRIMARY DUTIES AND RESPONSIBILITIES: \n \n \n \n Serves as a liaison between the business community and the IT organization in order to provide technical solutions to meet user needs \n Work directly with their product organization, representing the sales team\u2019s systems tools and processes \n Work in an agile methodology \u2013 ensure the team is focused on delivering value within a user and functionality driven context \n Analyzes business partner\u2019s operations to understand their strengths and weaknesses to determine opportunities to automate processes and functions \n Assists in the business process redesign and documentation as needed for new technology \n Translates high level business requirements into functional specifications for the IT organization and manages changes to such specifications \n Maintain a working-knowledge of business & technical functionalities within a given Product offering \n Provide consultative assistance to business users and stakeholders looking to streamline processes by analyzing and determining problem/opportunity/solution resolution \n Write user stories, maintain a healthy delivery team backlog, and collaborate within Agile team ceremonies \n Ensure that all stories are well documented, and the team has developed a common understanding for the task at hand \n Anticipate, quantify and resolve problems and issues with requirements. \n Communicate with clients and stakeholders using data process models to clarify and validate requirements \n Address issues and questions related to intended functionality of the system, as well as support the business in implementing the required changes to make effective use of the new system \n Serve as the conduit between the customer community (internal and external customers) and the software development team through which requirements flow \n Partner with Product & Solutions Leads to develop specifications, wireframes, diagrams and flowcharts for programmers to follow \n Perform all responsibilities within the guidelines and IT policies and directives at or above our client\u2019s performance and evaluation standards. \n Serve as the main point of contact for the Agile delivery team as it relates to business or functional questions, impediments, or dependencies \n Maintain user confidence and protect the business by keeping information confidential. \n \n \n \n Qualifications \n \n \n \n EXPERIENCE AND EDUCATIONAL REQUIREMENTS: \n \n \n \n Bachelor\u2019s degree in computer science, engineering or management information systems with a minimum of five (5) years of experience as a Business Analyst, Systems Engineer or equivalent. \n Ideally has experience within the Pharmaceutical, Medical Device or Healthcare industry. \n \n \n \n MINIMUM SKILLS, KNOWLEDGE AND ABILITY REQUIREMENTS: \n \n \n Demonstrated experience within a business analysis role within an Agile delivery environment \n Ability to turn abstract concepts or problems to be solved into tactical delivery approaches \n Ability to partner with Product and Technology to prioritize and sequence work \n Proven leadership skills and communication skills \n Critical thinker who can evaluate information gathered from multiple sources, reconcile conflicts, decompose high-level information into details, abstract up from low-level information to a general understanding, and distinguish user requests from the underlying business needs \n Experience working side by side with development and testing teams to facilitate accurate understanding throughout analysis and execution \n Management and maintenance of requirements traceability \n Well organized with the ability to manage multiple tasks at once in order to meet demanding deadlines. \n Team player who can effectively work in a fast paced environment. \n Proficient in Microsoft Office (Excel, Access, Powerpoint, Word) \n Proficient in Microsoft Visio, Project and Sharepoint \n \n \n \n \n \n \n \n Preferred Skills \n \n \n Strong understanding for Business Analysis & Agile Delivery \n Healthcare and/or Pharmaceutical Industry experience/knowledge \n Experience working within Jira to create work items and collaborate with Agile delivery teams to prioritize, plan, and execute work \n Experience developing and customizing requirements, process, and design documentation \n Experience leading demonstrations of working tested software to end-users to gather feedback \n Experience performing requirements, design, and testing activities \n Strong understanding of system architecture and a desire to participate in development strategy \n Experience with service oriented architecture and accompanying functional documentation",
        "cleaned_desc": " \n \n Bachelor\u2019s degree in computer science, engineering or management information systems with a minimum of five (5) years of experience as a Business Analyst, Systems Engineer or equivalent. \n Ideally has experience within the Pharmaceutical, Medical Device or Healthcare industry. \n \n \n \n MINIMUM SKILLS, KNOWLEDGE AND ABILITY REQUIREMENTS: \n \n \n Demonstrated experience within a business analysis role within an Agile delivery environment \n Ability to turn abstract concepts or problems to be solved into tactical delivery approaches \n Ability to partner with Product and Technology to prioritize and sequence work \n Proven leadership skills and communication skills \n Critical thinker who can evaluate information gathered from multiple sources, reconcile conflicts, decompose high-level information into details, abstract up from low-level information to a general understanding, and distinguish user requests from the underlying business needs \n Experience working side by side with development and testing teams to facilitate accurate understanding throughout analysis and execution \n Management and maintenance of requirements traceability   Well organized with the ability to manage multiple tasks at once in order to meet demanding deadlines. \n Team player who can effectively work in a fast paced environment. \n Proficient in Microsoft Office (Excel, Access, Powerpoint, Word) \n Proficient in Microsoft Visio, Project and Sharepoint \n \n \n \n \n \n \n \n Preferred Skills \n \n \n Strong understanding for Business Analysis & Agile Delivery \n Healthcare and/or Pharmaceutical Industry experience/knowledge \n Experience working within Jira to create work items and collaborate with Agile delivery teams to prioritize, plan, and execute work ",
        "techs": [
            "microsoft office (excel",
            "access",
            "powerpoint",
            "word)",
            "microsoft visio",
            "microsoft project",
            "microsoft sharepoint",
            "jira"
        ],
        "cleaned_techs": [
            "microsoft",
            "access",
            "powerpoint",
            "word)",
            "microsoft visio",
            "microsoft project",
            "microsoft sharepoint",
            "jira"
        ]
    },
    "d204708adf94b99e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 38.0,
        "salary_max": 40.0,
        "title": "Business Analyst 122504",
        "company": "Epathusa Inc",
        "desc": "Seeking Business Analyst for fully remote position. Will need ability to elicit and clearly document an update requirements, able to write test cases and scenarios, perform testing, and document results. Knowledge of creating and updating specification documentation, work with tickets and provide accurate updates in tickets being worked, and familiar with ADO (Azure DevOps). \n \n \n \n  5 Years Business Analyst experience working with requirements gathering and documenting. \n  Writing test cases, testing and documenting results \n  Ability to create and run SQL queries is nice to have",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "b9196de1b0f51a77": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 100000.0,
        "salary_max": 105000.0,
        "title": "Business Analyst",
        "company": "Ascendion",
        "desc": "Description \n About Ascendion \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n  Ascendion | Engineering to elevate life \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: \n \n Build the coolest tech for world\u2019s leading brands \n Solve complex problems \u2013 and learn new skill \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n \n Experience a community of change makers! \n  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n  About the Role: \n  Job Title:  Business Analyst \n  Day to Day: \n  Ascendion is looking for a business analyst to turn down a company owned device project. The role will be working on a ServiceNow analysis, focus. This person will develop short term processes for analysis on provisioning stages \n  Must Haves: \n \n \n 2 years of business process analysis or data analysis \n 2 - 4 years of experience in IT service management or ServiceNow toolset \n \n Should understand provisioning process with ServiceNow \n Experience with requesting tooling \n \n Strong experience with Micro soft suite \n \n SharePoint \n excel \n \n Must understand portals and inventory management \n Great communicator \n Great experience with process documentation \n Experience with business portal and inventory management \n \n \n Location:  Remote \n  Salary Range:  The salary for this position is between $100,000 \u2013 $105,000 annually. Factors which may affect pay within this range may include geography/market, skill, education, experience, and other qualifications of the successful candidate. \n  Benefits:  The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day accrued each calendar year. The \n  Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day of paid vacation time] [6 paid holiday and 1 floating holiday per calendar year] [Ascendion Learning Management System] \n  Want to change the world? Let us know. \n  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n Preferred Skills: \n \n business process analysis \n \n Job details \n \n \n Job ID \n \n \n   328550\n   \n \n \n \n Job Requirements \n \n \n   Business Analyst \n   \n \n \n \n \n Location \n \n \n   Tampa, Florida, US\n   \n \n \n \n \n Recruiter \n \n \n   Binal\n   \n \n \n \n Email \n \n \n   binal.patel@ascendion.com",
        "cleaned_desc": "  Must Haves: \n \n \n 2 years of business process analysis or data analysis \n 2 - 4 years of experience in IT service management or ServiceNow toolset \n \n Should understand provisioning process with ServiceNow \n Experience with requesting tooling \n \n Strong experience with Micro soft suite \n \n SharePoint \n excel \n \n Must understand portals and inventory management \n Great communicator \n Great experience with process documentation ",
        "techs": [
            "servicenow",
            "sharepoint",
            "excel"
        ],
        "cleaned_techs": [
            "servicenow",
            "sharepoint",
            "excel"
        ]
    },
    "7c1b99e9879697e2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "IT BA",
        "company": "Mitchell Martin",
        "desc": "Our client, a major American low cost airline, is seeking an IT BA\n  \n \n Location:  Remote\n  \n Position Type:  Contract\n  \n \n Position Summary: \n \n \n The Business Analyst, IT Enterprise Architecture (EA) provides direct support to the IT Enterprise Architecture team by supporting Enterprise Architects, Business Architects and Solution Architects in the development and maintenance of documentation for the planning and execution of IT projects. \n With guidance from the IT Business Architect and Enterprise Architecture Manager, the Business Analyst actively supports all aspects of projects from start to finish with a particular emphasis on documentation maintenance. \n The Business Analyst may occasionally serve as the project lead on documentation maintenance projects or provide support to Architects in new documentation efforts. \n \n \n Responsibilities: \n \n \n Update and maintain the Enterprise Product/System Inventory \n Actively support the creation and maintenance of Enterprise Architecture Blueprints which represent the current and future strategic state of the Enterprise, mapping and cross referencing Products with Capabilities, Data and Technologies. \n Actively support the creation and maintenance of Customer Journeys, which correlate User Interfaces and activity flows with Data and Technologies. \n Other duties as assigned \n \n \n Essential Skills and Experience: \n \n \n Ability to review, consolidate, communicate and reverse-engineer complex technical and systems documentation in collaboration with technical and/or subject matter experts \n Critically evaluate information gathered from multiple sources, reconcile conflicts, decompose high-level information into details, abstract up from low-level information to a general understanding, and distinguish user requests from the underlying true needs \n Collaborate with developers, architects, subject matter experts, and other IT crewmembers to help document the technical vision and any tradeoffs between usability and performance needs \n Proactively communicate and collaborate with external and internal customers to analyze information needs and functional requirements and deliver the following artifacts: Functional Requirements; Technical Requirements, include architecture, interfaces, security and business continuity \n Strong working knowledge of Microsoft Office Suite, including Outlook, Excel, Word, and Visio \n Good working knowledge of Confluence and Jira documentation methodologies \n Excellent verbal and written communication skills \n Ability to interact professionally with diverse stakeholders at all levels of the organization \n Strong interpersonal and demonstrated facilitation skills including the ability to motivate and influence others, and able to foster and contribute to a positive, upbeat team environment \n Strong customer service ethic and an understanding of how IT is ultimately delivered to the Customer \n High tolerance for working in a dynamic and shifting environment and able to readily embrace and participate in change initiatives \n Knowledge of technology fundamentals and concepts including Microsoft technologies \n Ability to work well with others and complete tasks with minimal supervision \n Effective time management and prioritization skills \n \n \n Preferred Experience and Qualifications: \n \n \n Experience in the commercial aviation industries with exposure to supporting IT systems and technologies \n Strong understanding of the Sabre reservations system and related technology \n Working knowledge of Business Architecture \n Working knowledge of industry standards in project management and development methodologies \n Working knowledge of risk management and quality assurance standards and methodologies \n \n \n \n M",
        "cleaned_desc": " Good working knowledge of Confluence and Jira documentation methodologies \n Excellent verbal and written communication skills \n Ability to interact professionally with diverse stakeholders at all levels of the organization \n Strong interpersonal and demonstrated facilitation skills including the ability to motivate and influence others, and able to foster and contribute to a positive, upbeat team environment \n Strong customer service ethic and an understanding of how IT is ultimately delivered to the Customer \n High tolerance for working in a dynamic and shifting environment and able to readily embrace and participate in change initiatives \n Knowledge of technology fundamentals and concepts including Microsoft technologies \n Ability to work well with others and complete tasks with minimal supervision \n Effective time management and prioritization skills \n \n   Preferred Experience and Qualifications: \n \n \n Experience in the commercial aviation industries with exposure to supporting IT systems and technologies \n Strong understanding of the Sabre reservations system and related technology \n Working knowledge of Business Architecture \n Working knowledge of industry standards in project management and development methodologies \n Working knowledge of risk management and quality assurance standards and methodologies \n \n \n ",
        "techs": [
            "confluence",
            "jira",
            "microsoft technologies",
            "sabre reservations system",
            "business architecture"
        ],
        "cleaned_techs": [
            "confluence",
            "jira",
            "microsoft technologies",
            "sabre reservations system",
            "business architecture"
        ]
    },
    "0633fec6ce3f0616": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 74800.0,
        "salary_max": 125000.0,
        "title": "Senior Technical Business Analyst",
        "company": "Jack Henry and Associates, Inc.",
        "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n  The Senior Technical Business Analyst will be joining one of our back-end services teams that is responsible for Jack Henry's Enterprise API Gateway and Jack Henry's Consumer and Enterprise Identity Provider services. This is a dynamic, agile software delivery team that provides an enterprise-level authentication integration platform and contributes to a mission-critical set of applications. The Senior Technical Business Analyst lives at the intersection of product and engineering, helping translate business requirements into technical specifications for our enterprise integration platforms.\n  \n \n \n  You are infinitely curious and thrive in an environment where you are constantly learning and growing. You want to be somewhere that you are trusted and surrounded by great engineers who rely on your input into the products being developed. Although you work in a team you are self-motivated and able to work with independence. You care deeply about your work, your team, and the business.\n  \n \n \n  This position will be filled to work Remotely within the U.S.\n  \n \n \n  The target salary range for this position is $74,800 \u2013 $125,000, based on location and experience.\n  \n \n \n  If you are interested in this position, please apply on or before October 2, 2023.\n  \n \n \n \n  What you\u2019ll be responsible for: \n \n \n \n \n \n  Interacting with product teams and stakeholders to gather system requirements. \n  Creating requirements and system documentation as well as contributing to engineering and end-user documentation. \n  Interacting with engineering teams to accurately describe product requirements. \n  Learning and staying up to date on trends and best practices in areas relevant to your team. \n  Assisting in application, system, and user-acceptance tests. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 7 years of technical business analysis experience or software engineering experience. \n  Experience interacting with REST APIs. \n  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.",
        "cleaned_desc": "  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   ",
        "techs": [
            "api documentation reading",
            "workflow diagrams",
            "sequence diagrams",
            "communication skills",
            "travel ability",
            "banking experience",
            "government experience",
            "high security system experience",
            "highly regulated system experience",
            "nodejs experience",
            "javascript experience",
            "typescript software team experience",
            "business analysis experience",
            "technical business analysis experience",
            "larger-scale project work experience",
            "oauth experience",
            "open id connect experience",
            "identity and access management platform integration experience."
        ],
        "cleaned_techs": [
            "workflow diagrams",
            "sequence diagrams",
            "travel ability",
            "banking experience",
            "government experience",
            "highly regulated system experience",
            "nodejs experience",
            "javascript experience",
            "typescript software team experience",
            "business analysis experience",
            "technical business analysis experience",
            "larger-scale project work experience",
            "oauth experience",
            "open id connect experience",
            "identity and access management platform integration experience."
        ]
    },
    "a9d4c6ae4de920b2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 55000.0,
        "salary_max": 140000.0,
        "title": "PLADS Business Systems Analyst (Salesforce)",
        "company": "Aflac, Incorporated",
        "desc": "Salary Range:  $55,000 - $140,000 \n \n  We\u2019ve Got You Under Our Wing \n  We are the duck. We develop and empower our people, cultivate relationships, give back to our community, and celebrate every success along the way. We do it all\u2026 The Aflac Way . \n \n  Aflac, a Fortune 500 company, is an industry leader in voluntary insurance products that pay cash directly to policyholders and one of America's best-known brands. Aflac has been recognized as Fortune\u2019s 50 Best Workplaces for Diversity and as one of World\u2019s Most Ethical Companies by Ethisphere.com. \n   \n Our business is about being there for people in need. So, ask yourself, are you the duck? If so, there\u2019s a home, and a flourishing career for you at Aflac. \n \n  Worker Designation  \u2013 This role is designated as a  remote  role. You will be expected to work from your home, within the continental US. Although this role is designated as remote, there may be occasions that you are requested to come to the office based on business need. Any requests to come to the office would be communicated with you in advance. \n \n  What does it take to be successful at Aflac? \n \n  Acting with Integrity \n  Communicating Effectively \n  Pursuing Self-Development \n  Serving Customers \n  Supporting Change \n  Supporting Organizational Goals \n  Working with Diverse Populations \n \n \n  What does it take to be successful in this role? \n \n Experience with requirements management tools and techniques, such as UML Class/Sequence Diagrams, Use Cases, Story-boarding, Scrum, Atlassian Tools Suite \u2013 Jira and Confluence \n \n   \n \n Experience using data query tools to perform data analysis, profiling and validation \n \n   \n \n Strong written and verbal communication skills \n \n   \n \n Experience in Life, Absence and Disability Insurance \n \n \n  Education & Experience Required \n \n  Bachelor's Degree Computer Science, Information Systems, Business Administration or related field \n  Five or more years of experience in the Business Analysis area \n  Demonstrated experience in developing projects across all phases of the project life cycle; demonstrated experience in developing functional specifications, , user interface designs/wireframes \n  Knowledge of how systems support business operations, collection of technical requirements, and modeling concepts \n  Experience in working simultaneously with technical IT resources and nontechnical business resources and users \n  Ability to apply statistical and other research methods into systems issues as required; review complex data and derive summary conclusions \n  Experience with Salesforce and ClaimVantage highly preferred \n \n  Or an equivalent combination of education and experience \n \n  Travel \n  Less than or equal to 10% \n \n  Principal Duties & Responsibilities \n \n With general management guidance and using independent discretion and decision making, assists with the identification and recording of detailed requirements from business users through interviews, documentation and facilitated working sessions for approved projects and enhancements while complying with the main principles relevant to legal and regulatory controls that govern standard work practices; assists with the coordination and lead of activities with business owners to gather requirements, monitor business decisions, and manage documentation and communication; adapts to apply different delivery methodologies including SCRUM, Waterfall, and Lean Six Sigma \n \n   \n \n Assists with the understanding of customers' objectives, processes, products and services in order to make educated recommendations that meet stakeholders' needs and expectations; creates process models based on business requirements in order to determine the completeness of the information and process components; assists in the evaluation of project impact through consultation with the business, regulatory, Information Technology management, development, quality assurance, validation and training teams \n \n   \n \n Assists with obtaining feedback and manages change processes while implementing the project plan(s); assists with production of requirement specifications and outlines solution design documents throughout the project life cycle, incorporating change requests and finalization of requirements documentation; prioritizes business change work, in line with project plans in order to deliver customer requirements \n \n   \n \n Assists with analysis and management of requirement risk, trace ability matrix and prioritizes requirements; performs quality review checks on project deliverables; supports development of test plan, testing, implementation and training activities; supports integration testing to ensure original requirements are met; assists quality assurance with the creation and execution of acceptance testing as needed \n \n   \n \n Develops, enhances, and maintains internal and external facing reporting solutions by gathering requirements in collaboration with business partners and technical resources; prepare reports for leadership, operations, and the account management team; analyzes data to identify opportunities for process improvement in areas such as client consultation and operations; provides user support through training on the use of reporting tools, ad hoc requests for data, and issue analysis \n \n   \n \n Supports post-implementation activities including problem solving and measurement of benefits achieved; identifies any potential issues and supports the analysis to determine root cause \n \n   \n \n Works with Business Systems Analysts and Architects to analyze and document impact of proposed technology to existing architecture and communicates any potential risks \n \n   \n \n Balances the competing constraints of business need, services, technology, and quality to produce the specified product, service or result with minimal change requests required \n \n   \n \n Monitors and reviews project financial information, updating where necessary in order to identify any anomalies or discrepancies against key project metrics and ensure management has access to up to date and accurate information; develops cost benefit analyses in accordance with standard processes to support the creation of realistic business cases for change initiatives \n \n   \n \n Monitors and reviews project work in order to ensure appropriate use of materials, tools, equipment or resources and adherence to schedules \n \n   \n \n Conducts due diligence on transactions and processes in order to determine the risk profile of a project in compliance with relevant regulations and recommends appropriate action \n \n   \n \n Independently collates and analyzes data using pre-determined tools, methods and formats and make recommendations in order to support business change's decision making process \n \n   \n \n Provides specialist advisory support to internal clients on a daily basis by being point of contact to ensure that there is no misalignment between policy and project practice; builds relationships with local team members to support delivery of projects \n \n   \n \n Performs other related duties as required \n \n \n  Total Rewards \n  This compensation range is specific to the job level and takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to: education, experience, licensure, certifications, geographic location, and internal equity. The range has been created in good faith based on information known to Aflac at the time of the posting. Compensation decisions are dependent on the circumstances of each case. This salary range does not include any potential incentive pay or benefits, however, such information will be provided separately when appropriate. The salary range for this position is $55,000 to $140,000. \n \n  In addition to the base salary, we offer an array of benefits to meet your needs including medical, dental, and vision coverage, prescription drug coverage, health care flexible spending, dependent care flexible spending, Aflac supplemental policies (Accident, Cancer, Critical Illness and Hospital Indemnity offered at no costs to employee), 401(k) plans, annual bonuses, and an opportunity to purchase company stock. On an annual basis, you\u2019ll also be offered 11 paid holidays, up to 20 days PTO to be used for any reason, and, if eligible, state mandated sick leave (Washington employees accrue 1 hour sick leave for every 40 hours worked) and other leaves of absence, if eligible, when needed to support your physical, financial, and emotional well-being. Aflac complies with all applicable leave laws, including, but not limited to sick and safe leave, and adoption and parental leave, in all states and localities.",
        "cleaned_desc": "  What does it take to be successful in this role? \n \n Experience with requirements management tools and techniques, such as UML Class/Sequence Diagrams, Use Cases, Story-boarding, Scrum, Atlassian Tools Suite \u2013 Jira and Confluence \n \n   \n \n Experience using data query tools to perform data analysis, profiling and validation \n \n   \n \n Strong written and verbal communication skills \n \n   \n \n Experience in Life, Absence and Disability Insurance \n \n \n  Education & Experience Required \n \n  Bachelor's Degree Computer Science, Information Systems, Business Administration or related field \n  Five or more years of experience in the Business Analysis area \n  Demonstrated experience in developing projects across all phases of the project life cycle; demonstrated experience in developing functional specifications, , user interface designs/wireframes    Knowledge of how systems support business operations, collection of technical requirements, and modeling concepts \n  Experience in working simultaneously with technical IT resources and nontechnical business resources and users \n  Ability to apply statistical and other research methods into systems issues as required; review complex data and derive summary conclusions \n  Experience with Salesforce and ClaimVantage highly preferred \n \n  Or an equivalent combination of education and experience \n \n  Travel \n  Less than or equal to 10% \n \n  Principal Duties & Responsibilities \n \n With general management guidance and using independent discretion and decision making, assists with the identification and recording of detailed requirements from business users through interviews, documentation and facilitated working sessions for approved projects and enhancements while complying with the main principles relevant to legal and regulatory controls that govern standard work practices; assists with the coordination and lead of activities with business owners to gather requirements, monitor business decisions, and manage documentation and communication; adapts to apply different delivery methodologies including SCRUM, Waterfall, and Lean Six Sigma \n \n   \n \n Assists with the understanding of customers' objectives, processes, products and services in order to make educated recommendations that meet stakeholders' needs and expectations; creates process models based on business requirements in order to determine the completeness of the information and process components; assists in the evaluation of project impact through consultation with the business, regulatory, Information Technology management, development, quality assurance, validation and training teams \n \n   \n \n Assists with obtaining feedback and manages change processes while implementing the project plan(s); assists with production of requirement specifications and outlines solution design documents throughout the project life cycle, incorporating change requests and finalization of requirements documentation; prioritizes business change work, in line with project plans in order to deliver customer requirements \n ",
        "techs": [
            "uml class/sequence diagrams",
            "use cases",
            "story-boarding",
            "scrum",
            "atlassian tools suite (jira and confluence)",
            "data query tools",
            "life",
            "absence and disability insurance",
            "salesforce",
            "claimvantage",
            "bachelor's degree computer science",
            "information systems",
            "business administration",
            "five or more years of experience in the business analysis area",
            "functional specifications",
            "user interface designs/wireframes",
            "systems support business operations",
            "technical requirements",
            "modeling concepts",
            "working simultaneously with technical it resources and nontechnical business resources and users",
            "statistical and other research methods",
            "review complex data",
            "salesforce",
            "claimvantage"
        ],
        "cleaned_techs": [
            "uml class/sequence diagrams",
            "use cases",
            "story-boarding",
            "scrum",
            "atlassian tools suite (jira and confluence)",
            "data query tools",
            "life",
            "absence and disability insurance",
            "salesforce",
            "claimvantage",
            "information systems",
            "business administration",
            "five or more years of experience in the business analysis area",
            "functional specifications",
            "user interface designs/wireframes",
            "systems support business operations",
            "technical requirements",
            "modeling concepts",
            "working simultaneously with technical it resources and nontechnical business resources and users",
            "statistical and other research methods",
            "review complex data"
        ]
    },
    "590907524474fa0c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 72731.76,
        "salary_max": 83642.82,
        "title": "Production Support Business Analyst",
        "company": "Moda Health",
        "desc": "Let\u2019s do great things, together    Founded in Oregon in 1955, Moda is proud to be a company of real people committed to quality. Today, like then, we\u2019re focused on building a better future for healthcare. That starts by offering outstanding coverage to our members, compassionate support to our community and comprehensive benefits to our employees. It keeps going by connecting with neighbors to create healthy spaces and places, together. \n  Moda values diversity and inclusion in our workplace. We aim to demonstrate our commitment to diversity through all our business practices and invite applications from candidates that share our commitment to this diversity. Our diverse experiences and perspectives help us become a stronger organization. Let\u2019s be better together. \n  Job Summary: \n  Moda Health is seeking a Production Support Business Systems Analyst who will act as a liaison between business and technical users to gather and document business requirements, business processes, system flows and functional system designs for break fixes, system upgrades, ongoing product implementations and small IT service requests. The Production Support BSA is responsible for providing IT support throughout the software development lifecycle, including testing and production implementation. To excel in this position, you should be self-motivated with strong analytical skills, in-depth knowledge of business systems analysis techniques and possess strong verbal and written communication skills. Experience with TriZetto Facets and/or Edifecs Enrollment Management system preferred.\n  \n \n This a full-time remote position. \n \n  Please fill out an application on our company page, linked below, to be considered for this position \n \n  https://j.brt.mv/jb.do?reqGK=27699478&refresh=true \n \n  Benefits: \n \n  Medical, Dental, Pharmacy and vision coverage \n  401K \n  FSA \n  PTO and paid holidays \n \n  Schedule: \n \n  Full time minimum 7.5 work days with 37.5 work weeks \n \n  Primary Functions: \n \n \n  Performs ongoing production support and bug fixes for assigned applications. \n  Performs best practice requirements engineering for all aspects of SDLC activities. To include eliciting, analysis, and prioritization of functional and non-functional requirements. \n  Collaborates with business and technical teams in defining and documenting detailed functional specification requirements, reviewing, analyzing and approving acceptance criteria for conversion, interface, and system enhancements. \n  Creates the functional specifications based on the finalized requirements for the designated functional systems, and at the correct time, converting systems to Moda Company Standard Software Systems. \n  Participates as a team member in short-term stabilization efforts involving existing systems and processes. \n  Participates in the development of business cases, contingency plans, business metrics and measurements, process models, training materials, new procedures, test scripts, ad-hoc reports, and smart solutioning for process improvements. \n  Participates in the review and approval of system designs, logical data designs, report design, interface designs, and conversion plans. Reviews and approves high-level data flows, functional specifications, and system for implementation. Suggests design alternatives. \n  Acts in review and approval capacity in the establishment and maintenance of unit and user acceptance testing and prioritization of requests for system enhancements, and system implementations. \n  Performs system testing of enhancements, conversions, and interface systems. \n  Develops and documents test plans and outcomes at a level of details that allows research and analysis. \n  Performs post implementation, quality assurance and troubleshooting. Develops both user and business unit technical documentation for system enhancements. \n  Performs other duties as assigned. \n \n  Requirements: \n \n \n  2+ years of experience in analysis, either technical or business related. \n  Knowledge of PC, Server Based and desktop applications including spreadsheets, word-processing and email. \n  Must be able to facilitate large and small group meetings or working sessions. \n  Proven skills in critical thinking, time management, and problem solving. \n  Demonstrated procedural and technical writing skills. \n  Must be able to work effectively within a production support team and in collaboration with peers. \n  Ability to work well under pressure, in a fast-paced environment, with frequent interruptions and shifting priorities. This includes working on multiple assignments simultaneously. \n  Ability to independently plan, organize, and prioritize task assignments to ensure quality standards and deadlines are met. \n  Ability to communicate effectively, both verbally and in writing, with business and technical personnel. \n  As applicable; a commitment to acquire the ability to read, write, and execute SQL statements. \n  Ability to maintain confidentiality and demonstrate a professional business image. \n  Resilient work ethics; demonstrating professionalism, punctuality, and reliability. \n \n  Preferred Requirements: \n \n  College Degree or equivalent work experience in related field. \n  Experience as a Business Systems or Program Analyst \n  Experience in the health insurance administration industry \n  Experience with Facets systems development \n  Subject matter expertise in Claims Processing, Claims Pricing, Clinical Editing, Benefit Config, Membership and/or Provider Processing. \n  Ability to read, write, and execute SQL statement. \n \n  Moda Health seeks to allow equal employment opportunities for all qualified persons without regard to race, religion, color, age, sex, sexual orientation, national origin, marital status, disability, veteran status or any other status protected by law.\n   \n  For more information regarding \n   accommodations  please direct your questions to HRAdmin@modahealth.com.",
        "cleaned_desc": "  Requirements: \n \n \n  2+ years of experience in analysis, either technical or business related. \n  Knowledge of PC, Server Based and desktop applications including spreadsheets, word-processing and email. \n  Must be able to facilitate large and small group meetings or working sessions. \n  Proven skills in critical thinking, time management, and problem solving. \n  Demonstrated procedural and technical writing skills. \n  Must be able to work effectively within a production support team and in collaboration with peers. \n  Ability to work well under pressure, in a fast-paced environment, with frequent interruptions and shifting priorities. This includes working on multiple assignments simultaneously. \n  Ability to independently plan, organize, and prioritize task assignments to ensure quality standards and deadlines are met. \n  Ability to communicate effectively, both verbally and in writing, with business and technical personnel. \n  As applicable; a commitment to acquire the ability to read, write, and execute SQL statements. ",
        "techs": [
            "pc",
            "server based and desktop applications",
            "spreadsheets",
            "word-processing",
            "email",
            "critical thinking",
            "time management",
            "problem solving",
            "procedural writing",
            "technical writing",
            "production support team",
            "collaboration",
            "fast-paced environment",
            "multiple assignments",
            "planning",
            "organizing",
            "prioritizing",
            "communication",
            "sql statements"
        ],
        "cleaned_techs": [
            "pc",
            "spreadsheets",
            "word-processing",
            "email",
            "critical thinking",
            "time management",
            "problem solving",
            "procedural writing",
            "technical writing",
            "production support team",
            "collaboration",
            "fast-paced environment",
            "multiple assignments",
            "planning",
            "organizing",
            "prioritizing",
            "communication",
            "sql"
        ]
    },
    "b7ba27df9428ea5b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 60000.0,
        "salary_max": -1.0,
        "title": "HCM Business Analyst",
        "company": "NDUS System Info Tech Services",
        "desc": "Position Description & Details \n \n \n \n \n \n Position #:   00105761 \n \n  # of positions:   1 \n \n  LOCATION: \n  Fargo, ND, Grand Forks, ND or Remote. \n \n  TYPE OF APPOINTMENT: \n  This is a full-time, 12-month, benefited position in the 3000 broadband, exempt from FLSA (not overtime eligible). \n \n  CLOSING DATE: \n  Applications received by 11:59 p.m. on October 2, 2023, will be given first consideration. \n \n  SALARY: \n  $60,000+ minimum annual salary (dependent on experience) plus full benefits package. \n \n  BENEFITS: \n  The North Dakota University System offers a competitive benefit package including a generous retirement plan and employer paid family health insurance, basic life insurance, sick leave, annual leave, employee tuition waiver, spouse/dependent tuition discount, and 10 paid holidays. \n \n  JOB SUMMARY: \n  The Human Resource Management (HCM) Business Analyst is responsible for working with personnel from the 11 NDUS institutions, System Office and Core Technology Services personnel in the maintenance, development, and enhancement of the PeopleSoft HR systems. The Human Resources Business Analyst provides functional expertise for the development, implementation, and support of the Human Resources software system to support NDUS business objectives. This is primarily a business, not a technical, position supporting all of the Human Resources modules. Training for this position is in Fargo, ND. \n  Minimum Qualifications: \n \n  Bachelor\u2019s Degree in Business Administration or related field, or equivalent combination of education and experience. \n  Advanced understanding of Recruiting, HR, and/or benefits, \n  Demonstrated ability to help an organization implement cost-effective technology solutions and resolve problems through troubleshooting, analysis and/or business process redesign. \n  Ability to provide and uphold excellent customer service standards. \n  Excellent oral and written communication skills coupled with an established track record for functioning as a strong team member. \n \n \n  Preferred Qualifications: \n \n  Experience analyzing systems issues from multiple perspectives. \n \n \n  Experience in Higher Education. \n  Experience with large HR ERP application software including but not limited to PeopleSoft, Oracle, or SAP. \n  Experience developing training materials and delivering training content. \n \n \n  APPLICATION INSTRUCTIONS: \n  Applicants should apply online at https://cts.ndus.edu/about/careers/ and upload a cover letter  specifically addressing the job qualifications,  and a current resume. Professional references may be requested. \n  To be considered for this position, and in order to move forward in the search process applicants  must  upload: \n \n  Cover letter \n  Resume \n \n \n  Applicants who are veterans and eligible to claim veteran\u2019s preference must include Form DD214 with the application for employment; claims for disabled veteran\u2019s preference must include Form DD214 and a letter less than one year old from the Department of Veterans\u2019 Affairs indicating disability; claims for preference as the eligible spouse of a disabled or deceased veteran must include Form DD214, a marriage certificate and a letter less than one year old from the Department of Veterans\u2019 Affairs indicating disability, or the veteran\u2019s death certificate. Due to access to restricted information, the successful candidate will be required to complete a satisfactory criminal background check. \n  Applicants must be eligible to work in the U.S. and I-9 employment certification is required at hire . There is no sponsorship available for this position. \n  Persons who may need additional job information or may require accommodation or assistance with the application or interview process should contact Jane Grinde at (701) 328.4217, or e-mail jane.grinde@ndus.edu. TTY Number 1-800-366-6888. \n \n  CONFIDENTIALITY OF APPLICATION MATERIALS:  Pursuant to NDCC 44-04-18.27, applications and any records related to the applications that identify an applicant are exempt, except records related to the finalists of the position, which are open to the public after the search committee has identified the top three finalists. \n \n  EEO/AA STATEMENT:  NDUS/Core Technology Services is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, or veteran status. \n \n  VETERAN\u2019S PREFERENCE NOTICE : Veterans claiming preference must submit all proof of eligibility by the closing date. Proof of eligibility includes a DD-214 and if claiming disabled status, a current letter of disability from the VA dated within the last 12 months. \n \n  NO SMOKING NOTICE:  As an employer, the State of North Dakota prohibits smoking in all places of state employment in accordance with N.D.C.C. \u00a7 23-12-10.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "1a3c9922881f9777": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 60.0,
        "salary_max": 70.0,
        "title": "Technical Business Analyst",
        "company": "v-solve",
        "desc": "Job Decribtion: Technical Business Analyst \n We are looking for Technical Business Analyst who are domain experts specifically in (Options/Clearing/Risk). We are looking at SME in this space who have  predominantly worked in capital markets domain. \n Location: Remote \n Experience:10+ \n Key Skills & Responsibilities : \n Requirements \n \n Trained in testing methodologies. \n Experience with SQL in various types of relational databases. \n Can participate in all Agile ceremonies including the daily SCRUM. \n Understanding of basic LINUX commands. \n Good verbal and written communication skills. \n Understanding of the Testing process. \n Advanced in using excel to compare data as part of testing. \n Good understanding of financial domain specifically options/Risk/clearing as part of testing.  \n Ability to work with employees within and from other departments. \n Ability to create and modify scripts for re-useable processes when necessary. \n Ability to create and update processes and procedures. \n Ability to make use of automation tools as necessary. \n \n Technical Skills  \n \n Knowledge of Jira, UC4, Python, pyspark, Hadoop, hive, and relational database concept. \n Knowledge of Microsoft Office Suite (Access, Word, Excel, and PowerPoint) \n Knowledge of SDLC, Agile-Scrum, UML, SOA, OOAD methodologies \n Hands on experience with Continuous Integration and Continuous Delivery (CI/CD) pipelines, tools, and technologies such as GitHub, Jenkins, Artifactory, Harness \n Hands on experience with SQL, Excel \n Good understanding of financial domain specifically Options/Risk/Clearing \n \n Job Type: Contract \n Pay: $60.00 - $70.00 per hour \n Experience level: \n \n 1 year \n \n Schedule: \n \n 8 hour shift \n \n Application Question(s): \n \n Predominately Worked in Finance domain like Options/Risk/Clearing ? \n \n Experience: \n \n Finance Domain: 7 years (Required) \n Information Technology: 10 years (Required) \n SQL: 7 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Ability to make use of automation tools as necessary. \n \n Technical Skills  \n \n Knowledge of Jira, UC4, Python, pyspark, Hadoop, hive, and relational database concept. \n Knowledge of Microsoft Office Suite (Access, Word, Excel, and PowerPoint) \n Knowledge of SDLC, Agile-Scrum, UML, SOA, OOAD methodologies \n Hands on experience with Continuous Integration and Continuous Delivery (CI/CD) pipelines, tools, and technologies such as GitHub, Jenkins, Artifactory, Harness \n Hands on experience with SQL, Excel ",
        "techs": [
            "jira",
            "uc4",
            "python",
            "pyspark",
            "hadoop",
            "hive",
            "relational database",
            "microsoft office suite",
            "access",
            "word",
            "excel",
            "powerpoint",
            "sdlc",
            "agile-scrum",
            "uml",
            "soa",
            "ooad",
            "continuous integration",
            "continuous delivery",
            "ci/cd",
            "github",
            "jenkins",
            "artifactory",
            "harness",
            "sql"
        ],
        "cleaned_techs": [
            "jira",
            "uc4",
            "python",
            "pyspark",
            "hadoop",
            "hive",
            "relational database",
            "microsoft",
            "access",
            "word",
            "excel",
            "powerpoint",
            "sdlc",
            "agile-scrum",
            "uml",
            "soa",
            "ooad",
            "continuous integration",
            "continuous delivery",
            "ci/cd",
            "github",
            "jenkins",
            "artifactory",
            "harness",
            "sql"
        ]
    },
    "b7380949a2f03ccc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 49800.0,
        "salary_max": 102000.0,
        "title": "Safety Analyst",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Stafford,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0180395\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Safety Analyst\n          \n  The Opportunity: \n  Are you looking for an opportunity to combine your technical skills with big picture thinking to make an impact in Environment, Safety, and Occupational Health (EOSH)? Our team supports senior-level DoD personnel with environment, system safety, and occupational health implementation and oversight for DoD system programs. You\u2019ll leverage your knowledge and will have an opportunity to grow your expertise in ESOH, including applying scientific and engineering principles, criteria, and techniques to identify and assess ESOH hazards and inform the implementation of mitigations to reduce warfighter risk. \n \n  As a research analyst on our team, you'll enjoy a dynamic team environment of client and contractor staff while executing comprehensive system safety programs or individual tasks on a variety of systems, including unmanned systems, ground-based missile systems, surface vessel threat and support systems, laser systems, and others. Under guidance and mentoring from senior staff, you\u2019ll assist with developing typical work products, including Safety Releases, National Environmental Policy Act (NEPA) documentation, Programmatic ESOH Evaluations (PESHEs), and System Safety Program Plans (SSPP) and a variety of analyses, including Preliminary Hazard Analysis (PHA), Subsystem and System Hazard Analysis (SHA and SSHA), Operating and Support Hazard Analysis (O&SHA), Explosive Ordnance Disposal (EOD) analysis, Safety Assessment Reports (SAR), and test report evaluations. You'll analyze data, develop written deliverables, assist with the presentation of results, and assist with the review of client system safety artifacts to verify compliance with requirements, policy, and guidance documents. You'll conduct these tasks with oversight and mentoring from Senior ESOH Engineers or Analysts, as needed, following established plans and quality standards and the freedom to improve processes and advance the EOSH discipline. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  1+ years of experience with ESOH tasking \n  Experience in performing ESOH tasks, including maintaining Hazard Tracking Systems for various programs and assist with other databases, including safety release tracker, configuration management databases, trouble report databases, requirements databases, Safety of Use Messages, and safety training databases \n  Experience with documentation development, including data packages, risk acceptance forms, technical information, and deliverables management \n  Knowledge of Military safety analyses and safety program implementation \n  Ability to assist with scheduling meetings and reserving appropriate conference facilities and meeting space \n  Secret clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  Experience with NAVSEAINST 8020.6, Weapon System Explosives Safety Review Board (WSESRB), or Software Systems Safety Technical Review Panel (SSSTRP) \n  Experience with performing risk assessments and analysis employing modeling and simulation techniques, including leveraging Model-Based Systems Engineering (MBSE) to perform ESOH assessments in digital models \n  Possession of excellent verbal and written communication skills \n  Bachelor\u2019s degree \n  Marine Corps Systems Command (MCSC) Principal for Environment, Safety, and Occupational Health (PESOH) with Level I MCSCO 5090 ESOH Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $49,800.00 to $102,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "90c071d45693ed04": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 82658.805,
        "salary_max": 104664.46,
        "title": "Senior Analyst, VBC Analytics",
        "company": "US Renal Care",
        "desc": "USRC's greatest strength in being a leader in the dialysis industry is our ability to recognize and celebrate the differences in our diverse workforce. We strongly believe in recruiting top talent and creating a diverse and inclusive work climate and culture at all levels of our organization.  \n SUMMARY \n  The  Senior Analyst of Value\u2010Based Care Analytics  supports healthcare data initiatives by providing accurate and timely data analysis and reports, quality assurance and ongoing process maintenance to help drive cost savings and quality improvement activities. The Senior Analyst position will work effectively with other analytics team members and other VBC key stakeholders and thrive in an ambiguous fast paced environment. \n \n Essential Duties and Responsibilities include the following. Other duties and tasks may be assigned. \n \n Obtain and analyze raw data from multiple sources, including claims, provider data, member eligibility and clinical data, to perform core job duties and to answer questions posed by internal /external customers. \n Conduct analysis to develop critical business insights and identify key drivers contributing to trends, medical cost reduction, clinical program effectiveness and quality improvement opportunities. \n Work with business units to gather and document data/report requirements and translate into technical build, data model design through the entire report/product cycle until completion. \n Generate and update standard reports on schedule to support Care management and market operation needs. \n Assist in data management work with analytics colleague to build scalable data structure to support production of reports.  \n Work collaboratively with key internal stakeholders, such as clinical operations, market operations, finance, product, and leadership teams of value-based care organization. \n Assist in developing presentations for external stakeholders such as providers, health plans, and other customers to explain total cost of care analyses, cost trends, and key cost of care levels. \n Participate in business process improvement efforts to collect and analyze metrics and continually improve processes. \n Be self-motivated, creative problem solver who can work independently and demonstrate strong project management skills to handle multiple complex projects in a fast-paced environment. \n Actively promote GUEST customer service standards; develop effective relationships at all levels of the organization. \n Be effective at translating complex or technical issues into common terms. Communicate in a compelling, simple manner. \n Train junior members of the team; participate in team concepts and promote a team effort; perform duties in accordance with company policies and procedures. \n Regular and reliable attendance is required for the job. \n \n Requirements: \n  Qualifications/Requirements: \n  To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. \n  Requirements include: \n \n Bachelor's degree in mathematics, statistics, actuarial science, public health or related quantitative field  \n Three (3) plus years of advanced analytics and programming skills working with claim data, electronic medical record data and other clinical data sources. \n Experience in the following areas preferred: health care claims analytics, managed healthcare analytics, cost of care, medical utilization, care management operational data, and health plan rate development. \n Advanced SQL skills required, with deep understanding of relational databases and data architecture is required. \n Use of the following tools preferred: Alteryx, SQL, Power BI, Python, Tableau, R, Excel.  \n Advanced data analyst skills required with a higher level of proficiency with Excel and analytical abstraction, analysis, and visualization tools. \n Excellent communication skills, both written and verbal.",
        "cleaned_desc": " \n Bachelor's degree in mathematics, statistics, actuarial science, public health or related quantitative field  \n Three (3) plus years of advanced analytics and programming skills working with claim data, electronic medical record data and other clinical data sources. \n Experience in the following areas preferred: health care claims analytics, managed healthcare analytics, cost of care, medical utilization, care management operational data, and health plan rate development. \n Advanced SQL skills required, with deep understanding of relational databases and data architecture is required. \n Use of the following tools preferred: Alteryx, SQL, Power BI, Python, Tableau, R, Excel.  ",
        "techs": [
            "alteryx",
            "sql",
            "power bi",
            "python",
            "tableau",
            "r",
            "excel"
        ],
        "cleaned_techs": [
            "alteryx",
            "sql",
            "powerbi",
            "python",
            "tableau",
            "r",
            "excel"
        ]
    },
    "3d1c4aad03bea0a1": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75000.0,
        "salary_max": 95000.0,
        "title": "Senior BI Reporting Analyst (Remote)",
        "company": "Aramark Uniform & Career Apparel LLC",
        "desc": "Overview: \n  The Senior BI Reporting Analyst\u2019s primary responsibility is to support, implement and maintain the visualization tools, techniques, standards, and methodologies to be used in enterprise development activities. This position is accountable and responsible for providing direction, guidance, and oversight to other developers on this team. This position is expected to show team and vendor leadership; work with little supervision; assist others in their area; and work with others to prepare accurate estimates of work. This position is expected to provide support in multiple projects of high scope and complexity. This role is highly cross-functional, and works closely with our internal Rental Operation, Direct Sales, IT, Marketing teams and external third-party vendors. The candidate must be able to work autonomously and have a solid understanding of process analysis, requirements gathering, systems design, Agile, DevOps and web-based solutions. \n  Responsibilities/Essential Functions: \n \n Analyze and understand end-user requirements to deliver data visualization solutions for managing enterprise data. \n    \n Design, build, test, implement, and support Data Visualization solutions that meet defined requirements. \n Manage Data Visualization solutions through the entire development lifecycle including requirements gathering, analysis, development, performance tuning, deployment, and automation. \n A willingness to learn and adapt to existing and future data visualization technologies. \n Lead in development of best practices to operationalize the products and continually improve practices and processes. \n Collaborate with client teams to communicate requirements, set deadlines, participate in testing, understand/resolve roadblocks and communicate effectively to impacted parties. \n \n Collaborate with data visualization team to develop architectural standards and rules for organizational needs and deliverables. \n Lead and champion the business power user program. \n Work with data engineering team to process and validate requirements for data transformation processes. \n Collaborate with IS team to develop an enterprise data visualization strategy. \n Track all hours worked and communicate status on a weekly basis. \n Create and update documentation. \n Perform special assignments and attend meetings as appointed to improve process efficiency and performance in job duties. \n Consistently seek improvement and excellence in job skills. \n Complete other duties and activities as assigned by manager. \n Supporting the goals of the company\u2019s technological alignment efforts \n Seeking out and implementing continuous process improvement opportunities \n Supporting internal communications related to business improvements and processes, system upgrades, and enhancements \n Build and sustain working relationships with all AUS functional areas \n Overseeing appropriate vendor relationships related to associated technologies, services, and solutions needed to operate enterprise functions \n Ensuring accurate and efficient governance policy development and adherence \n Report on statuses when requested \n Submit all time and expense reporting procedures accurately and timely \n Maintain good standing and completion on all compliance related matters (i.e., assigned mandatory trainings, actions required from audits, corporate policies, etc.) \n Perform all additional duties and responsibilities based on the direction and guidance of supervisor \n \n Knowledge/Skills/Abilities: \n \n Deep understanding of user experience (UX), design and customer service principles \n Excellent communicator \u2013 can articulate the pros and cons of various technologies, platforms and architectural options \n Takes the initiative to do the right thing \u2013 doesn\u2019t walk past a problem \n Motivator \u2013 willing to push themselves and the team towards success \n Agile learner \u2013 has passion and curiosity to learn new things and understand the \u201cwhy\u201d \n Skilled and proficient in MS Office O365 suite (i.e. Word, PowerPoint, Excel, SharePoint, Teams, Communications Tools, etc.) \n Ability to operate with a customer-centric service approach \n Ability to establish performance-based relationships with 3rd party vendors and technology providers and versed in setting standards and measurements for IT processes \n Ability to effectively define a business case, determine return on investment, and measure achievement of the case over time \n Ability to manage and work on multiple concurrent deliverables at various stages of development and completion \n Strong collaboration and team-building skills with the ability to create consensus around decisions and mitigate conflicts among teams \n Strong problem solving and analytical skills \n Professional level verbal and written communication skills \n Demonstrated attention to detail and quality of work products and communications \n Willingness to seek out and implement coaching, suggestions, and guidance from others \n \n Working Environment/Safety Requirements: \n \n Ensure necessary working environment and capabilities to effectively carry out responsibilities if working from a non-AUS location (remote work) \n Ability and willingness to handle work related issues during all hours of the day, every day of the week, understanding the responsibility of our organization\u2019s requirement for 24/7 production support \n Ability, willingness, and flexibility to travel as needed for approved work purposes in accordance with project and management schedules \n \n Experience/Qualifications: \n \n Bachelor\u2019s degree \n 5+ years of working experience with Power BI \n Experience working directly and consulting with business clients to design a solution \n Experience with tools and concepts related to data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data \n Experience with design and implementation of ETL/ELT/Streaming processes \n Database development experience using Oracle, SQL Server, Azure Synapse \n Ability to research, plan, organize, lead, and implement new processes or technology \n Experience creating dashboards using Power BI or other similar visualization tools (Looker, Tableau, Microstrategy, R Shiny, QlickSense, Business Objects, etc) \n Experience with the use of Project Management methodologies and tools \n Bachelor and/or Master\u2019s degree preferred but not required \n Be legally able to work in the United States: U.S. Citizen or Legal Resident \n \n License Requirements/Certifications: \n \n Valid U.S. driver\u2019s license (for rental cars when applicable) \n \n Benefits: Aramark offers a wide array of comprehensive benefit programs and services, including medical, dental, vision, short and long-term disability, basic life insurance, and paid parental leave. Employees are able to enroll in the company\u2019s 401k plan. Employees are eligible for 80 hours of vacation, 16 hours of floating holidays, and paid sick time every year. Employees will also receive 9 paid holidays throughout the calendar year. \n  Compensation: The salary rate for this position ranges from $75,000 to $95,000, depending on circumstances, including an applicant\u2019s skills and qualifications, certain degrees and certifications, prior job experience, market data, and other relevant factors. \n \n  Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities \n  The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor\u2019s legal duty to furnish information. 41 CFR 60-1.35(c)",
        "cleaned_desc": "Overview: \n  The Senior BI Reporting Analyst\u2019s primary responsibility is to support, implement and maintain the visualization tools, techniques, standards, and methodologies to be used in enterprise development activities. This position is accountable and responsible for providing direction, guidance, and oversight to other developers on this team. This position is expected to show team and vendor leadership; work with little supervision; assist others in their area; and work with others to prepare accurate estimates of work. This position is expected to provide support in multiple projects of high scope and complexity. This role is highly cross-functional, and works closely with our internal Rental Operation, Direct Sales, IT, Marketing teams and external third-party vendors. The candidate must be able to work autonomously and have a solid understanding of process analysis, requirements gathering, systems design, Agile, DevOps and web-based solutions. \n  Responsibilities/Essential Functions: \n \n Analyze and understand end-user requirements to deliver data visualization solutions for managing enterprise data. \n    \n Design, build, test, implement, and support Data Visualization solutions that meet defined requirements. \n Manage Data Visualization solutions through the entire development lifecycle including requirements gathering, analysis, development, performance tuning, deployment, and automation. \n A willingness to learn and adapt to existing and future data visualization technologies. \n Lead in development of best practices to operationalize the products and continually improve practices and processes. \n Collaborate with client teams to communicate requirements, set deadlines, participate in testing, understand/resolve roadblocks and communicate effectively to impacted parties. \n \n Collaborate with data visualization team to develop architectural standards and rules for organizational needs and deliverables. \n Lead and champion the business power user program. \n Work with data engineering team to process and validate requirements for data transformation processes.   Perform all additional duties and responsibilities based on the direction and guidance of supervisor \n \n Knowledge/Skills/Abilities: \n \n Deep understanding of user experience (UX), design and customer service principles \n Excellent communicator \u2013 can articulate the pros and cons of various technologies, platforms and architectural options \n Takes the initiative to do the right thing \u2013 doesn\u2019t walk past a problem \n Motivator \u2013 willing to push themselves and the team towards success \n Agile learner \u2013 has passion and curiosity to learn new things and understand the \u201cwhy\u201d \n Skilled and proficient in MS Office O365 suite (i.e. Word, PowerPoint, Excel, SharePoint, Teams, Communications Tools, etc.) \n Ability to operate with a customer-centric service approach \n Ability to establish performance-based relationships with 3rd party vendors and technology providers and versed in setting standards and measurements for IT processes \n Ability to effectively define a business case, determine return on investment, and measure achievement of the case over time \n Ability to manage and work on multiple concurrent deliverables at various stages of development and completion \n Strong collaboration and team-building skills with the ability to create consensus around decisions and mitigate conflicts among teams   Strong problem solving and analytical skills \n Professional level verbal and written communication skills \n Demonstrated attention to detail and quality of work products and communications \n Willingness to seek out and implement coaching, suggestions, and guidance from others \n \n Working Environment/Safety Requirements: \n \n Ensure necessary working environment and capabilities to effectively carry out responsibilities if working from a non-AUS location (remote work) \n Ability and willingness to handle work related issues during all hours of the day, every day of the week, understanding the responsibility of our organization\u2019s requirement for 24/7 production support \n Ability, willingness, and flexibility to travel as needed for approved work purposes in accordance with project and management schedules \n \n Experience/Qualifications: \n \n Bachelor\u2019s degree \n 5+ years of working experience with Power BI   Experience working directly and consulting with business clients to design a solution \n Experience with tools and concepts related to data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data \n Experience with design and implementation of ETL/ELT/Streaming processes \n Database development experience using Oracle, SQL Server, Azure Synapse \n Ability to research, plan, organize, lead, and implement new processes or technology \n Experience creating dashboards using Power BI or other similar visualization tools (Looker, Tableau, Microstrategy, R Shiny, QlickSense, Business Objects, etc) \n Experience with the use of Project Management methodologies and tools \n Bachelor and/or Master\u2019s degree preferred but not required \n Be legally able to work in the United States: U.S. Citizen or Legal Resident \n \n License Requirements/Certifications: \n \n Valid U.S. driver\u2019s license (for rental cars when applicable) \n \n Benefits: Aramark offers a wide array of comprehensive benefit programs and services, including medical, dental, vision, short and long-term disability, basic life insurance, and paid parental leave. Employees are able to enroll in the company\u2019s 401k plan. Employees are eligible for 80 hours of vacation, 16 hours of floating holidays, and paid sick time every year. Employees will also receive 9 paid holidays throughout the calendar year. ",
        "techs": [
            "power bi",
            "ms office o365 suite",
            "word",
            "powerpoint",
            "excel",
            "sharepoint",
            "teams",
            "communications tools",
            "dimensional modeling",
            "etl",
            "reporting tools",
            "data governance",
            "data warehousing",
            "oracle",
            "sql server",
            "azure synapse",
            "looker",
            "tableau",
            "microstrategy",
            "r shiny",
            "qlicksense",
            "business objects",
            "project management methodologies",
            "u.s. driver\u2019s license"
        ],
        "cleaned_techs": [
            "powerbi",
            "microsoft",
            "word",
            "powerpoint",
            "excel",
            "sharepoint",
            "teams",
            "communications tools",
            "dimensional modeling",
            "etl",
            "reporting tools",
            "data governance",
            "data warehousing",
            "oracle",
            "sql",
            "azure",
            "looker",
            "tableau",
            "microstrategy",
            "r shiny",
            "qlicksense",
            "business objects",
            "project management methodologies",
            "u.s. driver\u2019s license"
        ]
    },
    "3b1369c333547847": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 66000.0,
        "salary_max": 90000.0,
        "title": "Agile Business Project Analyst",
        "company": "Affiliated Technology Solutions",
        "desc": "Key Responsibilities: \n As an Agile Business Project Analyst, you will be an integral part of our project management and development process. Your day-to-day responsibilities will include: \n \n Crafting user stories and functional requirements using JIRA, and skillfully assigning points to user stories. \n Curating a well-organized product backlog in collaboration with developers and designers, ensuring that user stories are development-ready and appropriately grouped into epics. \n Collaborating closely with the Senior Product Manager to prioritize and map out your project's roadmap. \n Troubleshooting product support issues in conjunction with the operations team. \n Providing technical guidance and support throughout Agile sprint cycles. \n Assisting in validating system enhancements and coordinating with developers and testers. \n Leading and implementing the Scrum/Agile project lifecycle approach to software development. \n Conducting daily Scrum calls, estimation and grooming sessions, knowledge transfer sessions, and productive interactions with customers. \n Collaborating seamlessly with sprint teams to ensure the successful delivery of functionality. \n Participating in discussions and workshops to identify business challenges and propose software solutions. \n \n Qualifications: \n \n 1-3 years of experience in business analysis, digital marketing, or product management. \n Bachelor's degree or equivalent practical experience, with at least 5 years of related experience. \n Exceptional writing skills for creating release notes, user stories, and product documentation. \n Strong verbal communication skills to foster effective collaboration. \n Fundamental understanding of relational databases and website/app development. \n Outstanding analytical, problem-solving, and decision-making abilities. \n Telecommunications experience is a valuable asset. \n U.S. Citizenship is required. \n \n Job Type: Full-time \n Pay: $66,000.00 - $90,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n \n Experience level: \n \n 1 year \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Are you authorized to work in the United States as a W2 Employee? \n \n Experience: \n \n Business analysis: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Conducting daily Scrum calls, estimation and grooming sessions, knowledge transfer sessions, and productive interactions with customers. \n Collaborating seamlessly with sprint teams to ensure the successful delivery of functionality. \n Participating in discussions and workshops to identify business challenges and propose software solutions. \n \n Qualifications: \n \n 1-3 years of experience in business analysis, digital marketing, or product management. \n Bachelor's degree or equivalent practical experience, with at least 5 years of related experience. \n Exceptional writing skills for creating release notes, user stories, and product documentation. \n Strong verbal communication skills to foster effective collaboration. ",
        "techs": [
            "conducting daily scrum calls",
            "estimation and grooming sessions",
            "knowledge transfer sessions",
            "collaborating seamlessly with sprint teams",
            "participating in discussions and workshops \n\ntools and technologies: scrum",
            "estimation and grooming tools",
            "knowledge transfer tools",
            "collaboration tools",
            "discussion and workshop facilitation tools"
        ],
        "cleaned_techs": [
            "conducting daily scrum calls",
            "estimation and grooming sessions",
            "knowledge transfer sessions",
            "participating in discussions and workshops \n\ntools and technologies: scrum",
            "estimation and grooming tools",
            "knowledge transfer tools",
            "collaboration tools",
            "discussion and workshop facilitation tools"
        ]
    },
    "57ef076a0303cadc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 64682.906,
        "salary_max": 81902.97,
        "title": "Technical Business Analyst (Remote)",
        "company": "WebstaurantStore",
        "desc": "Looking for the start-up feel, but with a well-established and still rapidly growing company? Do you have a desire to work on a variety of projects in an Agile/Scrum environment? Do you enjoy solving puzzles? If you said yes to these questions, then you may be the right person to help us grow our team of Business Analysts. Take a look at our careers page and video: https://www.webstaurantstore.com/careers/ \n  100% remote opportunity for select states*. \n  WebstaurantStore , a Clark Associates Company and the internet\u2019s largest food service industry provider, is looking for a mid-level Technical Business Analyst candidate to join our growing company. This role focuses on IT related systems analysis and is a key part of growing our business and serving the purchasing needs of foodservice professionals worldwide. \n  As a mid-level  Technical Business Analyst , you will be: \n \n  Working effectively in a collaborative and innovative team-oriented environment \n  Perform analysis and gathering requirements for project initiatives \n  Create user stories to assist in the facilitation of software development and testing Assist stakeholders and product owners with analyzing and validating business needs and establishing development priorities \n  Act as a liaison between the Development department and the many Product Owners and business customers \n  Work closely with software engineers and quality assurance to enhance software solutions and ensure adherence to acceptance criteria \n  Facilitate meetings and assume Scrum Master duties \n  Coordinate development work across various development teams and business units \n \n  We are looking for driven, motivated candidates who have: \n \n  2+ years\u2019 experience as a Business Analyst \n  Experience in IT related to software development or support \n  Strong self-management skills and ability to adjust as needed to meet shifting priorities \n  Strong time management skills \n  Exceptional written and verbal communication skills \n  Desire to learn all business activities, processes and workflows \n  Ability to forge and maintain business relationships \n  Working knowledge of Software Development Life Cycle \n  Working knowledge of Agile and/or Scrum methodologies \n  Working knowledge of Kanban is a plus \n  Ambition and passion about technology and e-Commerce \n  Knowledge of relational databases and SQL is a plus \n  Experience with Azure DevOps or TFS a plus \n \n  WebstaurantStore  offers competitive compensation and a comprehensive benefits package including paid time off, medical/dental insurance, wellness programs, and a 401k with company match, profit sharing, and an annual bonus. \n  If you\u2019re ready for a challenge and have the ambition to succeed in a fast paced, growing industry, we\u2019d love to discuss the Technical Business Analyst position with you! Submit your resume and apply online today! \n  No relocation assistance provided. \n  Remote work qualifications \n \n  Access to a reliable and secure high-speed internet connection. Cable or fiber internet connections (at least 75mbps download/10mbps upload) are preferred, as satellite connections often cannot support the technologies used to perform day-to-day tasks. \n  Access to a home router and modem. \n  A dedicated home office space that is noise- and distraction-free. The space should have strong wireless connection or a wired Ethernet connection (wired connection is preferred, if possible). \n  A valid, physical address (apartment, suite, etc.). PO Boxes are not supported, as a physical address is required for you to receive your computer equipment. \n  The desire and ability to work and communicate with other team members via chat, webcam, etc. \n  Legal residents of one of the following states: (AK, AL, AR, AZ, DE, FL, GA, IA, ID, IN, KS, KY, MD, ME, MI, MN, MO, MS, NC, NH, NM, NV, OH, OK, PA, SC, SD, TN, TX, UT, VA, VT, WI, WV, and WY). H-1B Visa Sponsorship Not Available, W2 only.",
        "cleaned_desc": "  Ability to forge and maintain business relationships \n  Working knowledge of Software Development Life Cycle \n  Working knowledge of Agile and/or Scrum methodologies \n  Working knowledge of Kanban is a plus \n  Ambition and passion about technology and e-Commerce \n  Knowledge of relational databases and SQL is a plus \n  Experience with Azure DevOps or TFS a plus ",
        "techs": [
            "azure devops",
            "tfs",
            "sql"
        ],
        "cleaned_techs": [
            "azure",
            "tfs",
            "sql"
        ]
    },
    "843433cc684c05a6": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Finance Analyst",
        "company": "Smartwyre",
        "desc": "About Smartwyre \n \n \n   Smartwyre delivers commercial software (SaaS) to agricultural input businesses - the manufacturers and distributors of seeds, chemicals and fertilizer. These companies, which range from multinational enterprises to smaller, family-owned retailers, are based in the United States, Europe and Latin America. Our solutions help them manage pricing, incentives and transactional information in order to improve their business performance and better serve the world's farmers.\n  \n \n \n  Today, Smartwyre consists of a team of approximately 75 full-time professionals organized across our Product, Engineering, Customer Success, Data Operations, Marketing, Sales, and Corporate functions.\n  \n \n \n  We\u2019re a \"remote-first\" company with core teams in Denver, CO; Raleigh-Durham, NC; and London, United Kingdom. Come join us!\n  \n \n \n  About the role \n \n \n   Smartwyre is a fast-growing SaaS company and is looking for a technical Finance Analyst with a strong analytical mindset and ability to work to high standards whilst identifying opportunities for further improvements. You will have experience working in a fast-paced environment and have been involved in systems and process improvements and changes.\n  \n Your Responsibilities  \n \n Provide budgets and forecasts with detailed variances and be able to confidently navigate through financial spreadsheets and operating metrics. \n  Prepare analysis on variances against the plan considering financial and operational metrics providing insight to support action planning and decision making. \n  Analyze data around costs and revenues, understanding opportunities, risks and trends that impact the business. \n  Production of monthly management packs, investor reports and Board packs \n  Production of short term and long term cashflow forecasts \n  Key person in the system implementation projects. \n  Liaise with the external auditors to provide the necessary information for Year end audits. \n  Support the team with ad hoc analysis and reporting. \n  Drive improvements in the reporting framework \n \n \n  Our Ideal Candidate \n \n \n \n  Newly qualified in either ACCA, CIMA, ICAEW.\n   \n \n \n \n \n  Ideally, you will have experience in working for a similar business to Smartwyre; startup/scale up tech company and understand the challenges that come in a fast-paced work environment.\n  \n \n \n  We will be implementing a new finance system in the next 12months and experience in implementing/using NetSuite or other ERP systems is a beneficial.\n  \n \n \n  You can be based anywhere in the UK however you will be expected to come to the office in Farringdon once a week.\n  \n \n \n  What we offer \n \n \n   Competitive salary \n  \n \n  Healthcare \n  \n \n  401k contribution match\n  \n \n   Remote working culture\n   \n \n \n \n \n  We strongly encourage our employees to plan two consecutive weeks away every year. That\u2019s in addition to other time off. You\u2019ll come back more focused, with fresh perspective and new ideas.\n  \n \n \n  Please not we are currently not hiring candidates that reside in any of the following US states: CA, OR, WA, NV, AZ, NY, MA, IL, MI, NJ, CT, OH. However if you are open to relocation the please still apply and include that in your application.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "d69fe6bd9387843e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 74800.0,
        "salary_max": 125000.0,
        "title": "Senior Technical Business Analyst",
        "company": "Jack Henry and Associates, Inc.",
        "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n  The Senior Technical Business Analyst will be joining one of our back-end services teams that is responsible for Jack Henry's Enterprise API Gateway and Jack Henry's Consumer and Enterprise Identity Provider services. This is a dynamic, agile software delivery team that provides an enterprise-level authentication integration platform and contributes to a mission-critical set of applications. The Senior Technical Business Analyst lives at the intersection of product and engineering, helping translate business requirements into technical specifications for our enterprise integration platforms.\n  \n \n \n  You are infinitely curious and thrive in an environment where you are constantly learning and growing. You want to be somewhere that you are trusted and surrounded by great engineers who rely on your input into the products being developed. Although you work in a team you are self-motivated and able to work with independence. You care deeply about your work, your team, and the business.\n  \n \n \n  This position will be filled to work Remotely within the U.S.\n  \n \n \n  The target salary range for this position is $74,800 \u2013 $125,000, based on location and experience.\n  \n \n \n  If you are interested in this position, please apply on or before October 2, 2023.\n  \n \n \n \n  What you\u2019ll be responsible for: \n \n \n \n \n \n  Interacting with product teams and stakeholders to gather system requirements. \n  Creating requirements and system documentation as well as contributing to engineering and end-user documentation. \n  Interacting with engineering teams to accurately describe product requirements. \n  Learning and staying up to date on trends and best practices in areas relevant to your team. \n  Assisting in application, system, and user-acceptance tests. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 7 years of technical business analysis experience or software engineering experience. \n  Experience interacting with REST APIs. \n  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.",
        "cleaned_desc": "  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   ",
        "techs": [
            "api documentation",
            "workflow and sequence diagrams",
            "communication skills",
            "banking experience",
            "government experience",
            "high security systems experience",
            "regulated systems experience",
            "nodejs experience",
            "javascript experience",
            "typescript experience",
            "business analysis experience",
            "technical business analysis experience",
            "oauth experience",
            "open id connect experience",
            "identity and access management platform integration experience"
        ],
        "cleaned_techs": [
            "workflow and sequence diagrams",
            "banking experience",
            "government experience",
            "regulated systems experience",
            "nodejs experience",
            "javascript experience",
            "typescript experience",
            "business analysis experience",
            "technical business analysis experience",
            "oauth experience",
            "open id connect experience",
            "identity and access management platform integration experience"
        ]
    },
    "e2c1e50e4efbf348": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65700.0,
        "salary_max": 118300.0,
        "title": "Analyst, Business Systems Analysis (Remote)",
        "company": "Lincoln Financial",
        "desc": "Date:  Sep 8, 2023  \n Primary Location:  Radnor, PA, US  \n Company:  Lincoln Financial  \n \n \n Alternate Locations:  Work from Home\n   \n \n \n \n Work Arrangement: \n \n \n   Hybrid/Flexible : Work at home and use the office as appropriate for in-person collaboration.\n   \n \n \n \n Relocation assistance:  is not available for this opportunity.\n   \n \n \n \n Requisition #:  71902\n   \n \n \n \n \n \n \n  The Role at a Glance \n \n \n \n \n       We are excited to bring on an Analyst, Business Systems Analysis to the IT Annuity Organization.\n      \n \n      This Annuity IT position requires strong analytical, problem-solving, and organizational skills, along with proper prioritization of multiple assignments, while maintaining a sense of urgency to meet individual and team deadlines and goals.\n        Success in this role requires leadership ability among peers, excellent oral and written communication skills and effective collaboration with others, both internal and external to the team and company. The candidate should be self-motivated, show an inquisitive nature, seek improvements, ability to understand emerging technology trends and how they align to the strategic plan. Other abilities include accepting responsibility and accountability for own job and performance, demonstrate independent work behaviors, with strong accuracy and attention to detail and having decision-making skills to achieve desired results.\n      \n \n      This position will consult/analyze and deliver on more complex Business System Analysis assignments/projects for his/her assigned area(s) of responsibility. S/he will act as a resource to applicable internal/external stakeholders. S/he will also consult and collaborate with business stakeholders to define and validate more complex information as input for technology solutions that meet the needs, goals and objectives for his/her assigned area(s) of responsibility.\n       \n \n \n \n \n \n \n What you'll be doing \n \n \n \n \n Create, maintain, and coordinate updates to system data elements and configurable applications, including rules, values, tables and output with little or no development resource assistance. Create and run queries to generate, validate, and analyze data from various applications. \n Collaborates effectively with appropriate stakeholders on more complex issues and conflicts that impact time, cost, scope, quality and risk of assigned projects. \n Support Annuity release backlog grooming. \n Consults and acts as a resource to appropriate internal/external stakeholders to assess and deliver proposed more complex technical solutions that meet business requirements which may integrate process, business rules and business data with technology. \n Consults and collaborates with internal and/or external stakeholders to determine more complex technical specifications from business requirements. \n Determines and recommends the most appropriate technical response to identified complex problems, issues and/or defects by assessing impact and prioritization. \n Determines IT best practices and suggests how to improve current practices within a complex IT ecosystem. \n Develops complex technical solution requirements for assigned area(s) of responsibility. \n Escalates complex issues/conflicts to management as needed. \n May develop complex test plans and perform testing as needed. \n May update database tables as needed. \n Provides a more complex understanding of the business usage of information technology (IT) and helping technology add value to the business. \n Provides complex technical research and analysis to support business operations needs and presents findings to management or project leader. \n Using structured requirements process, clearly articulates, documents, and validates more complex technical requirements. \n \n \n \n \n \n \n \n  What we\u2019re looking for \n \n \n \n \n       Must-haves:\n       \n \n 3 - 5+ years\u2019 experience in business systems analysis that directly aligns with the specific responsibilities for this position (Required) \n 1-3 years of system analysis experience working in a large complex technical ecosystem \n 4 year/bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor\u2019s) in (Minimum Required) \n \n \n \n      Nice-to-haves:\n       \n \n Agile, Scrum, or Kanban experience highly preferred \n Experience supporting technology transformation as part of a Cloud first strategy is preferred \n Data analysis experience, analyzing data to ensure quality, looking for missing data, and following data patterns and relationships \n Competency working in many system analysis phases to consider/determine moderate business implications of applying technology to the current and future business environment \n Understanding of technology modernization concepts \u2013 ability to identify the need for more cost effective and technology appropriate solutions \n Strong requirements ability including facilitation, analysis, and business focus with stakeholder collaboration and partnership \n Strong knowledge of annuity business is preferred. Knowledge of Lincoln Annuity Products, especially product rules about Riders, Funds, M&E, etc. is a plus \n Demonstrated ability to identify and lead continuous improvement efficiencies within the team \n Advanced MS Excel skills \n Business Objects experience helpful \n \n \n \n \n \n \n \n \n What\u2019s it like to work here? \n \n \n   At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.\n   \n \n \n \n What\u2019s in it for YOU: \n \n \n \n \n     A clearly defined career framework to help you successfully manage your career\n       \n \n \n     Leadership development and virtual training opportunities\n       \n \n \n     PTO/parental leave\n       \n \n \n     Competitive 401K and employee benefits\n       \n \n \n     Free financial counseling, health coaching and employee assistance program\n       \n \n \n     Tuition assistance program\n       \n \n \n     A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations\n       \n \n \n     Effective productivity/technology tools and training\n       \n \n \n \n Pay Range:  $65,700 - $118,300\n   \n \n \n \n   Actual base pay could vary based on non-discriminatory factors including but not limited to work experience, education, location, licensure requirements, proficiency and qualifications required for the role. The base pay is just one component of Lincoln\u2019s total rewards package for employees. In addition, the role may be eligible for the Annual Incentive Program, which is discretionary and based on the performance of the company, business unit and individual. Other rewards may include long-term incentives, sales incentives and Lincoln\u2019s standard benefits package.\n   \n \n \n \n About The Company \n \n \n   Lincoln Financial Group provides advice and solutions that help people take charge of their financial lives with confidence and optimism. Today, approximately 16 million customers trust our retirement, insurance and wealth protection expertise to help address their lifestyle, savings and income goals, and guard against long-term care expenses.\n   \n \n \n  Headquartered in Radnor, Pennsylvania, Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE:LNC) and its affiliates. The company had $290 billion in end-of-period account balances net of reinsurance as of March 31, 2023.\n   \n \n \n \n   Lincoln Financial Group is a committed corporate citizen included on major sustainability indices including the Dow Jones Sustainability Index North America and ranks among Newsweek\u2019s Most Responsible Companies. Dedicated to diversity, equity and inclusion, we are included on transparency benchmarking tools such as the Corporate Equality Index, the Disability Equality Index and the Bloomberg Gender-Equality Index. Committed to providing our employees with flexible work arrangements, we were named to FlexJobs\u2019 list of the Top 100 Companies to Watch for Remote Jobs in 2022. With a long and rich legacy of acting ethically, telling the truth and speaking up for what is right, Lincoln was recognized as one of Ethisphere\u2019s 2022 World\u2019s Most Ethical Companies\u00ae. We create opportunities for early career talent through our intern development program, which ranks among WayUp and Yello\u2019s annual list of Top 100 Internship Programs.\n   \n \n \n \n   Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.\n   \n \n \n \n   Follow us on Facebook, Twitter, LinkedIn, and Instagram.\n   \n \n \n \n Be Aware of Fraudulent Recruiting Activities \n \n \n   If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.\n   \n \n   Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.\n   \n \n \n \n Additional Information \n \n \n   This position may be subject to Lincoln\u2019s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln\u2019s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.\n   \n \n \n \n   Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.\n   \n \n \n \n   Lincoln Financial Group (\u201cLFG\u201d) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ea9080872f0b22e7": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 90000.0,
        "salary_max": 130000.0,
        "title": "Sr. Business Analyst with Strong Healthcare & Quality Assurance Background",
        "company": "iCUBE Inc",
        "desc": "iCUBE, Inc. is seeking a Sr. Business Analyst/Quality Assurance Specialist - the position will be a fair mix (50/50) between business analysis and quality assurance responsibilities on different projects. \n \u2014 BUSINESS ANALYST WITH STRONG HEALTHCARE BACKGROUND \n Project Description \n This federal  healthcare project  is focused on providing a high level expertise in data integration, data exchange, and management services on large volume of data, establishing the data governance strategy, data management and modernization roadmap, performing an  analysis of the current state of the system, identifying current gaps and issues and making intelligent and effective recommendations involving AI/ML use case for automation of data pipelines,  suggesting required technology and skills needed to enable an established web-based system to more efficiently provide clinical data to make the healthcare system safer, higher quality, resulting in improved patient safety in hospitals. It also involves providing  subject matter expertise and advisory services on managing the data lifecycle in healthcare delivery, identifying opportunities for Advanced Analytics,  prototyping Advanced Analytics Opportunities, providing architecture recommendations based on ideal future state and tools/technologies currently available on a market vs. what is already in use in client\u2019s arsenal. \n Responsibilities 1.  Conduct an environmental scan - strong review of literature, regulatory environment, economic and health environment, and interested party needs and capabilities. It will involve many hours of reading, researching and conducting stakeholder interviews. \n 2.  Perform User Research ,  have a big vision ,  manage stakeholders, conduct Data Discovery  phase sessions with stakeholders,  build Data Flow diagrams  (a major starting point and input for further data analysis and data modeling.) \n 3. Interact with all the stakeholders and assist in  current state analysis and future state designs  of the system by reviewing and updating the existing usability study to identify the human interactions with the system. \n 4. Identify all  manual processes, understand the supporting processes,  review and update the use cases and requirements that cover the potential use of the system by individual hospitals and healthcare systems. \n 5. Demonstrate a comprehensive understanding of the  organization's service and the underlying resources and processes, easily discover weaknesses and opportunities for optimization,  providing strategic benefits for the business. \n 6.  Conduct deep research into facts and figures.  Find out the best possible recommendation to move the business forward. \n \u2014 QUALITY ASSURANCE ANALYST \n The Quality Analyst position on a federal government project involves a very robust validation of the web-based application involving web based forms for data collection and  complex financial calculations   to ensure that the forms, reporting, and process follow federal laws, regulations and codes, and applicable contracts as well as federal notices, instructions, policies, publications, and organizational standards. \n Responsibilities: \n 1. Development Validation Management Plan to include the tasks, activities, deliverables, milestones, and validation review periods. \n 2. Design and develop test plans, test cases, validation checklists, test datasets. \n 3. Work on epics, features, user stories, tasks for new portal modules to be developed. \n 4. Validate and test the portal modules for the following: Compliance with Rules and Policy, Data Review, Functionality and Eligibility Calculation, Data Reporting. \n 5. Develop detailed initial and final validation reports. \n 6. Coordinate User Acceptance Testing (UAT) and prepare UAT test plans, cases. \n 7. Ensure timely completion of all validation plan objectives and milestones. \n 8. Review and assess compliance with all the applicable rules and regulations. \n 9. Conduct interviews and surveys with stakeholders. \n 10. Develop and maintain user manuals. \n 11. Identify areas of non-compliance and recommend corrective actions to address those. \n 12. Identify areas of process improvement and recommend updates for the same. \n Qualifications: \n 1. Extensive experience (10+ years) in business analysis is a must! \n 2. Deep healthcare domain knowledge (5+ years) is a must! \n 3. Extensive experience (10+ years) in quality assurance is a must! \n 4. Ability to provide examples of your BA/QA work/artifacts during the interview process. \n 5. Excellent business and technical writing skills. \n 6. Deep passion and demonstrated success in finding solutions and understanding how things work. Desire to find out the best possible recommendation to move the business forward. \n 7. Desire to conduct deep research into facts and figures. \n 8. Keen to support the implementation of solutions that can help the project and the agency to flourish. \n 9. Ability to translate user needs and business goals into innovative and effective solution requirements. \n 10. Expertise in designing seamless, omnichannel customer experiences. \n 11. Proficiency in reading and writing business requirements, features, epics, user stores, functional and technical tasks, implementing process documentation, findings, reports. \n 12. Excellent communication skills, both written and verbal, and experience with communication at an executive level, small to midsize groups. \n 13. Senior skills in influencing and collaborating with diverse teams (e.g., data analysts, engineers, strategists) to ensure the user perspective is integrated throughout the project. \n 14. Extensive experience performing the Current State Assessment and Future State Analysis,  interacting with stakeholders and federal clients. \n 15. Data Management and Advanced Analytics skills. \n 16. Proficient in building workflow diagrams: MS Visio, Lucidchart, OmniGraffle, Miro, etc. \n 17. Experience in using and building appealing presentations such in PowerPoint, Google Slides, create graphics, infographics, etc. \n 18. Strong knowledge in using customer feedback survey tools: Google Forms, Microsoft Forms, Qualtrics for data analysis to inform design decisions. \n 19. Experience working with SharePoint for design collaboration and document management. \n 20. Knowledge of RESTful APIs for integrating design elements into web applications. \n 21. Highly detail-oriented - maintaining peak product quality, designing and implementing inspection activities, identifying and resolving problems, and consistently delivering exceptional outcomes. \n 22. Experience with automated testing, performance, load testing, compliance testing, performing QA on software/web tools validation and compliance testing. \n 23. Experience with Agile Release Trains, backlog grooming. \n 24. Extensive experience in Agile Development, Quality Assurance, Quality Control, Defect Management and Resolution processes. \n 25. Self-starter that takes ownership and an inventive problem solver with a high level of personal and team accountability. \n 26. Excellent communication skills and ability to effectively collaborate with cross-functional teams. \n 27. Detail-oriented with strong problem-solving skills. \n 28. Ability to prioritize tasks between multiple projects and meet deadlines in a fast-paced environment. \n 29. Must have a high level of work ethics, compliance, professionalism, and integrity. \n Additional Qualifications: \n \n Bachelor's degree in Business Analysis or related field \n Proven experience as a Business Analyst, Quality Analyst \n High degree of proficiency MS Office Suite (Excel, Word, PPT), Outlook & internet browser applications \n Experience working at the U.S. Department of Housing and Urban Development (HUD) is a big plus \n Experience working at the U.S. Department of Health and Human Services (HHS) or HHS Agencies is a big plus \n Familiarity of ISO 37301:2021 Standard (PDCA cycle) is a plus \n Familiarity with CMMI framework, ISO 9001 Standard is a plus \n Able to successfully pass background check prior to employment \n \n Job Type: Full-time \n Pay: $90,000.00 - $130,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Health insurance \n Life insurance \n Paid time off \n Vision insurance \n \n Compensation package: \n \n Performance bonus \n \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n \n Work Location: Remote",
        "cleaned_desc": "iCUBE, Inc. is seeking a Sr. Business Analyst/Quality Assurance Specialist - the position will be a fair mix (50/50) between business analysis and quality assurance responsibilities on different projects. \n \u2014 BUSINESS ANALYST WITH STRONG HEALTHCARE BACKGROUND \n Project Description \n This federal  healthcare project  is focused on providing a high level expertise in data integration, data exchange, and management services on large volume of data, establishing the data governance strategy, data management and modernization roadmap, performing an  analysis of the current state of the system, identifying current gaps and issues and making intelligent and effective recommendations involving AI/ML use case for automation of data pipelines,  suggesting required technology and skills needed to enable an established web-based system to more efficiently provide clinical data to make the healthcare system safer, higher quality, resulting in improved patient safety in hospitals. It also involves providing  subject matter expertise and advisory services on managing the data lifecycle in healthcare delivery, identifying opportunities for Advanced Analytics,  prototyping Advanced Analytics Opportunities, providing architecture recommendations based on ideal future state and tools/technologies currently available on a market vs. what is already in use in client\u2019s arsenal. \n Responsibilities 1.  Conduct an environmental scan - strong review of literature, regulatory environment, economic and health environment, and interested party needs and capabilities. It will involve many hours of reading, researching and conducting stakeholder interviews. \n 2.  Perform User Research ,  have a big vision ,  manage stakeholders, conduct Data Discovery  phase sessions with stakeholders,  build Data Flow diagrams  (a major starting point and input for further data analysis and data modeling.) \n 3. Interact with all the stakeholders and assist in  current state analysis and future state designs  of the system by reviewing and updating the existing usability study to identify the human interactions with the system. \n 4. Identify all  manual processes, understand the supporting processes,  review and update the use cases and requirements that cover the potential use of the system by individual hospitals and healthcare systems. \n 5. Demonstrate a comprehensive understanding of the  organization's service and the underlying resources and processes, easily discover weaknesses and opportunities for optimization,  providing strategic benefits for the business. \n 6.  Conduct deep research into facts and figures.  Find out the best possible recommendation to move the business forward. \n \u2014 QUALITY ASSURANCE ANALYST \n The Quality Analyst position on a federal government project involves a very robust validation of the web-based application involving web based forms for data collection and  complex financial calculations   to ensure that the forms, reporting, and process follow federal laws, regulations and codes, and applicable contracts as well as federal notices, instructions, policies, publications, and organizational standards. \n Responsibilities: \n 1. Development Validation Management Plan to include the tasks, activities, deliverables, milestones, and validation review periods. \n 2. Design and develop test plans, test cases, validation checklists, test datasets. \n 3. Work on epics, features, user stories, tasks for new portal modules to be developed. \n 4. Validate and test the portal modules for the following: Compliance with Rules and Policy, Data Review, Functionality and Eligibility Calculation, Data Reporting. \n 5. Develop detailed initial and final validation reports.   11. Proficiency in reading and writing business requirements, features, epics, user stores, functional and technical tasks, implementing process documentation, findings, reports. \n 12. Excellent communication skills, both written and verbal, and experience with communication at an executive level, small to midsize groups. \n 13. Senior skills in influencing and collaborating with diverse teams (e.g., data analysts, engineers, strategists) to ensure the user perspective is integrated throughout the project. \n 14. Extensive experience performing the Current State Assessment and Future State Analysis,  interacting with stakeholders and federal clients. \n 15. Data Management and Advanced Analytics skills. \n 16. Proficient in building workflow diagrams: MS Visio, Lucidchart, OmniGraffle, Miro, etc. \n 17. Experience in using and building appealing presentations such in PowerPoint, Google Slides, create graphics, infographics, etc. \n 18. Strong knowledge in using customer feedback survey tools: Google Forms, Microsoft Forms, Qualtrics for data analysis to inform design decisions. \n 19. Experience working with SharePoint for design collaboration and document management. \n 20. Knowledge of RESTful APIs for integrating design elements into web applications. \n 21. Highly detail-oriented - maintaining peak product quality, designing and implementing inspection activities, identifying and resolving problems, and consistently delivering exceptional outcomes. \n 22. Experience with automated testing, performance, load testing, compliance testing, performing QA on software/web tools validation and compliance testing. \n 23. Experience with Agile Release Trains, backlog grooming. \n 24. Extensive experience in Agile Development, Quality Assurance, Quality Control, Defect Management and Resolution processes. \n 25. Self-starter that takes ownership and an inventive problem solver with a high level of personal and team accountability. \n 26. Excellent communication skills and ability to effectively collaborate with cross-functional teams. \n 27. Detail-oriented with strong problem-solving skills. \n 28. Ability to prioritize tasks between multiple projects and meet deadlines in a fast-paced environment. ",
        "techs": [
            "icube",
            "ms visio",
            "lucidchart",
            "omnigraffle",
            "miro",
            "powerpoint",
            "google slides",
            "google forms",
            "microsoft forms",
            "qualtrics",
            "sharepoint",
            "restful apis."
        ],
        "cleaned_techs": [
            "icube",
            "ms visio",
            "lucidchart",
            "omnigraffle",
            "miro",
            "powerpoint",
            "google slides",
            "google forms",
            "microsoft forms",
            "qualtrics",
            "sharepoint",
            "restful apis."
        ]
    },
    "e89a79be2da67970": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 38.89,
        "salary_max": 38.89,
        "title": "Telecom Provisioning Data Analyst",
        "company": "APR Consulting Inc",
        "desc": "Our client is a worldwide telecommunications company that offers voice, data and video services and solutions on its award-winning networks and platforms, delivering on customers\u2019 demand for mobility, reliable network connectivity, security and control.    A telecommunications client is looking for a  Telecom Provisioning Data Analyst  to develop and maintain project schedules and calendars with the input and assistance of transition leads.     Location: Remote    Position: Telecom Provisioning Data Analyst   Pay: $38.89/hr. on W2   Duration: 12 months or longer    Targeted Years of Experience:  3-5 years     Responsibilities: \n \n Develop and maintain project schedules  and calendars with the input and  assistance of transition  leads \n Facilitate team meetings , providing meeting  minutes and action items  where needed \n Build strong communication channels with internal stakeholders in various departments: Sales, Professional Services, IT Operations, Development teams, Release Management, Networking \n Track tasks  assigned to the project team and prepare regular status reports \n Responsible for  tracking project changes  and producing updated schedules \n Gather and report performance measurement of on-going progress. \n Ensure smooth communication within the project team and other cross-functional teams \n Interface with internal/external stakeholders on a regular basis \n \n \n Qualifications: \n \n Experience in  reviewing telephony data .  \n Address validation and research skills.  \n Provisioning background  is helpful.  \n Experience in  Verizon systems is preferred . \n \n \n   This particular client may require all new hires show proof of vaccination. However, accommodations may be made for those with disabilities or religious reasons who cannot obtain a vaccine.     About APR:  Since 1980 APR Consulting, Inc. has provided professional recruiting and contingent workforce solutions to a diverse mix of clients, industries, and skill sets nationwide.  We are an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.     Don't miss out on this amazing opportunity! If you feel your experience is the match for this position please apply today and join our team. We look forward to working with you!    #SLA",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "65f12d74236a4b1f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 85000.0,
        "title": "Business Analyst II",
        "company": "GovEase",
        "desc": "Job Type:  Full-time \n Company Information: \n GovEase Auction a leading technology company specializing in providing innovative solutions for government agencies. Our cutting-edge platform enables efficient and transparent auctions, empowering our clients to optimize their procurement processes. We are seeking a highly skilled and motivated Business Analyst II to join our dynamic team and contribute to our mission of revolutionizing government auctions. \n Job Description: \n As a Business Analyst II at GovEase Auction, you will play a crucial role in driving business growth and maximizing operational efficiency. Working closely with cross-functional teams, you will be responsible for handling complex data sets, efficiently administering our platform, and assisting in further development of new and current products. Your ability to translate business requirements into technical solutions and to implement those solutions on a consistent basis will be essential for the success of our platform. \n Responsibilities: \n \n Conduct comprehensive analysis of auction data, identify patterns, and draw meaningful conclusions to support data-driven decision-making. \n Collaborate with stakeholders to define business requirements and translate them into functional specifications for software development. \n Participate in the design, development, and testing of new features and enhancements for our auction platform. \n Monitor and analyze platform performance metrics, providing recommendations for improvements and optimizations. \n Perform data validation and ensure data integrity throughout the system, identifying and resolving any data discrepancies. \n Proactively identify opportunities for process improvement and efficiency gains, working closely with cross-functional teams to implement solutions. \n Create and maintain detailed documentation, including business process flows, use cases, and user stories. \n Collaborate with product managers, developers, and QA teams to ensure the successful delivery of projects within established timelines. \n Support end-users by providing training and guidance on system functionalities and resolving any platform-related issues. \n Stay up to date with industry trends and best practices in business analysis and technology advancements, bringing innovative ideas to the team. \n \n Desired Skills & Experience: \n \n Bachelor's degree in Business Administration, Computer Science, Information Systems, or a related field. Advanced degree is a plus. \n Minimum of 3 years of experience as a Business Analyst or in a similar analytical role, preferably within the technology sector. \n Strong analytical and problem-solving skills, with the ability to work with complex data sets and draw meaningful insights. \n Proficiency in data analysis tools and techniques, such as SQL, Excel, and data visualization tools (e.g., Tableau, Power BI). \n Experience with requirements gathering, process modeling, and documenting functional specifications. \n Familiarity with agile development methodologies and the ability to work in an iterative and collaborative environment. \n Excellent communication skills, with the ability to effectively present complex concepts to both technical and non-technical stakeholders. \n Detail-oriented mindset with a focus on delivering high-quality work within established deadlines. \n Strong organizational skills, including the ability to prioritize tasks and manage multiple projects simultaneously. \n Knowledge of government procurement processes and regulations is a plus. \n \n Benefits: \n \n BCBS Health Insurance \n Vision Insurance \n Paid Vacation & Holiday Pay \n Training and Advancement opportunities \n \n GovEase is an Equal Employment Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law. GovEase will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. \n Job Type: Full-time \n Pay: $65,000.00 - $85,000.00 per year \n Benefits: \n \n 401(k) \n Dental insurance \n Health insurance \n Paid time off \n Vision insurance \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n Monday to Friday \n \n Application Question(s): \n \n Describe proficiency and skills with Microsoft Excel. \n Describe prior data analysis projects and tasks encountered. \n List tools previously used in business analyst roles. \n \n Education: \n \n Bachelor's (Required) \n \n Experience: \n \n Business analysis: 3 years (Preferred) \n \n Work Location: In person",
        "cleaned_desc": " Collaborate with product managers, developers, and QA teams to ensure the successful delivery of projects within established timelines. \n Support end-users by providing training and guidance on system functionalities and resolving any platform-related issues. \n Stay up to date with industry trends and best practices in business analysis and technology advancements, bringing innovative ideas to the team. \n \n Desired Skills & Experience: \n \n Bachelor's degree in Business Administration, Computer Science, Information Systems, or a related field. Advanced degree is a plus. \n Minimum of 3 years of experience as a Business Analyst or in a similar analytical role, preferably within the technology sector. \n Strong analytical and problem-solving skills, with the ability to work with complex data sets and draw meaningful insights. \n Proficiency in data analysis tools and techniques, such as SQL, Excel, and data visualization tools (e.g., Tableau, Power BI). \n Experience with requirements gathering, process modeling, and documenting functional specifications. \n Familiarity with agile development methodologies and the ability to work in an iterative and collaborative environment. \n Excellent communication skills, with the ability to effectively present complex concepts to both technical and non-technical stakeholders. \n Detail-oriented mindset with a focus on delivering high-quality work within established deadlines. ",
        "techs": [
            "sql",
            "excel",
            "tableau",
            "power bi"
        ],
        "cleaned_techs": [
            "sql",
            "excel",
            "tableau",
            "powerbi"
        ]
    },
    "1ceee08f28edecdc": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 45000.0,
        "salary_max": 60000.0,
        "title": "Digital Marketing Analyst",
        "company": "RXMG",
        "desc": "Company \n RXMG is a data-driven performance marketing company that delivers lifecycle campaign optimization and data monetization through email, social, search, SMS, and display media channels. RXMG connects advertisers to consumer audiences across multiple product verticals allowing advertisers to expand their online presence, drive engagement with their target markets, and monetize their unique insights into their consumers. RXMG also provides high-yield monetization environments to publishers with quality, targeted traffic channels. \n Job Summary \n The Digital Marketing Analyst (full-time) will provide important support, insights, and actions for our email marketing team. We are a multichannel digital marketer, primarily in the personal finance vertical. Our email marketing team handles all aspects of marketing campaigns ranging from copywriting and customer segmentation to deployment and analytics. \n We provide training and ongoing support, but also empower our staff to work creatively and independently. We have high standards and count on each other. This position reports to the Email Team's leadership. \n Responsibilities \n \n Monitor campaign performance to ensure success of active campaigns through reporting and analysis. \n  Analyze data from historical campaigns & measure the effectiveness of specific offer promotions. \n  Optimize campaigns and report revenue with related statistics to management. \n  Identify/solve problems in a fast-paced environment and communicate solutions to the rest of the team and management. \n  Interpret, analyze and make recommendations against campaign and database metrics. \n  Realize maximum revenue opportunities in accordance with goals and objectives of the company. \n  Report statistics and recommendations for company growth to management on a monthly basis. \n \n Qualifications \n \n Bachelor's Degree in Business, Economics, Finance, Marketing, Mathematics, Statistics or equivalent required. (Make sure you mention your GPA and major.) \n  Strong analytical skills, including ability to identify and quantify financial impact of opportunities with limited data. \n  Excellent written and oral communication skills (well-spoken, professional, friendly and courteous). \n  Ability to research new ideas and tools and bring insights back to the business \n  Self-motivated and driven. \n  Excellent interpersonal skills. \n  Ability to identify and solve problems quickly. \n  Meticulous and task-oriented. \n  Ability to work in a fast-paced environment and adapt to change. \n  Proficiency in Google Docs/Sheets, and Python required. \n  Knowledge of Tableau, Matlab, C,C++ or similar software/coding languages is a plus. \n \n \n Benefits of working with us: \n \n Unlimited PTO : Many organizations try this, but we do it successfully. \n  Paid Health Insurance, Dental, and Vision for you & your family : your family is our family. \n  Fully remote-work:  You don't have to come to an office! Our team works over Slack, Google Meet, and Zoom. \n  401K Plan : Matching 100% of the first 4% \n  Company-provided hardware : We don't want you to be held back by hardware - we provide the newest Apple hardware (MBP), extra monitors, and peripherals. \n  Employee education programs : Do you want to continue to learn and grow? We will pay for your training, courses, materials, and certifications. \n  Great Company Culture : Monthly Events (Poker, Guest Speakers, etc), Half Day Fridays (Summer time), and EOY \u201cQuiet Time\u201d (In December), 6 weeks paid parental leave.",
        "cleaned_desc": "  Self-motivated and driven. \n  Excellent interpersonal skills. \n  Ability to identify and solve problems quickly. \n  Meticulous and task-oriented. \n  Ability to work in a fast-paced environment and adapt to change. \n  Proficiency in Google Docs/Sheets, and Python required. \n  Knowledge of Tableau, Matlab, C,C++ or similar software/coding languages is a plus. ",
        "techs": [
            "google docs",
            "google sheets",
            "python",
            "tableau",
            "matlab",
            "c",
            "c++"
        ],
        "cleaned_techs": [
            "google",
            "google sheets",
            "python",
            "tableau",
            "matlab",
            "c",
            "c++"
        ]
    },
    "44317e013e1a07d9": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 75194.01,
        "salary_max": 95212.37,
        "title": "Sr Client Accounts Ops Analyst",
        "company": "DLA Piper",
        "desc": "DLA Piper is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. Job applicant poster  viewing center . \n  DLA Piper LLP (US) is a leading global business law firm. We are committed to attracting, developing, and retaining the best people across our practice and business service groups. We are looking for collaborative, results oriented people who enjoy working in a fast paced environment and have exceptional problem solving skills. \n  If you are a highly talented Sr Client Accounts Ops Analyst, we want to hear from you! \n \n \n  This position is remote. \n  Relocation is available in accordance with firm policy. \n \n \n \n Minimum Requirements: \n \n High School Diploma \n 5 years of business analysis or IT project management \n Excellent communication (verbal and written) and interpersonal skills are required to interact with various colleagues and business stakeholder \n Strong analytical skills \n Comfortable summarizing and communicating project scope and execution \n Strong attention to detail \n Proficient in Microsoft Office \n Advanced Microsoft Excel skills, including in use of Lookup and PivotTable functions \n Organized and a self-starter with the ability to handle a large number of projects at one time and meet multiple concurrent deadlines \n \n \n  Preferred Requirements: \n \n Bachelor\u2019s degree preferably in Business Administration, Accounting, Finance, or Business Process Management from an accredited institution \n Experience preferably in a law firm environment \n \n \n  What will your day look like?  In this role, you will interact with project stakeholders to understand business problems and define solution requirements. You will analyze business process and supporting systems and develop business cases, build metrics and perform reporting. You will document and communicate functional and system requirements and build process-flow diagrams. You will also support project management and reporting efforts and liaise with project participants and follow up routinely to ensure effective communication and completion of tasks. \n \n You will also interface with IT and various departments to support execution of cross-functional project requirements and perform system testing and requirements validation. You will develop training programs to ensure consistent billing processes across the team and provide training to attorneys and staff as needed. You will apply best practices for effective communication and problem solving, create standardized department reports, analyze data and document areas requiring improvement. You will continually review internal processes for opportunities to improve efficiencies. \n \n To learn more about DLA Piper, please visit our website. \n \n We offer exceptional career opportunities in an environment that is challenging, rewarding, and, we believe, truly different from our competitors. Our employees enjoy a competitive benefits package and a dynamic and diverse environment in which they can build a long and fruitful career and reap the rewards of their success. \n  Physical Demands, Work Environment, and Other Requirements  Sedentary work: Exerting up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Sedentary work involves sitting most of the time. Jobs are sedentary if walking and standing are required only occasionally, and all other sedentary criteria are met. \n  In accordance with New York City, California, and Washington's Pay Transparency Law, the pay range for this position, if hired to work in New York City, is $100,000 - $130,000. The compensation offered to a candidate selected for employment will be dependent upon various factors, including the candidate\u2019s geographic market, skills, educational and professional background, experience, and overall qualifications. Benefits information may be found on the DLA Piper LLP (US) career site. \n  Agency applications will not be considered.",
        "cleaned_desc": " Excellent communication (verbal and written) and interpersonal skills are required to interact with various colleagues and business stakeholder \n Strong analytical skills \n Comfortable summarizing and communicating project scope and execution \n Strong attention to detail \n Proficient in Microsoft Office \n Advanced Microsoft Excel skills, including in use of Lookup and PivotTable functions \n Organized and a self-starter with the ability to handle a large number of projects at one time and meet multiple concurrent deadlines ",
        "techs": [
            "microsoft office",
            "microsoft excel (including lookup and pivottable functions)"
        ],
        "cleaned_techs": [
            "microsoft",
            "excel"
        ]
    },
    "77b7fdf86752e9c2": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81916.66,
        "salary_max": 103724.734,
        "title": "ServiceNow Business Analyst",
        "company": "NetImpact Strategies",
        "desc": "Job Description: \n   We have an opportunity for a ServiceNow Business Analyst to support our ServiceNow Technical Services team for a federal client. This is a 100% remote position. The successful candidate will be responsible for analyzing and documenting business processes and systems. This position requires a full time commitment and will report directly to the ServiceNow Project Manager. \n \n  Typical responsibilities include: \n \n  Responsible for working with Process Owners to help identify technical requirements and guide them through SDLC until Production release \n  Analyze and document business processes and systems \n  Apply Agile methodology to elicit technical requirements and process flows for federal customers using interviews, document analysis, requirements workshops, surveys, business process reviews, and task and workflow analysis \n  Analyze and de-conflict requirements, data and information from multiple data sources and decompose into detailed requirements \n  Understand the needs of the client and successfully link needs with available technical solutions \n  Support creation of user stories and ensure that they meet the criteria required to deliver a successful product \n  Work with ServiceNow Architect and Developer in conducting testing to ensure quality of new software releases \n  Support User Acceptance Testing (UAT) including development of scripts and conducting UAT with end users \n  Create references and guides for end users as well as system administrators \n  Generate and update documentation to support requirements, design, and testing activities \n  Continually ensure client understands product updates \n  Support Change Management processes and play pivotal support role for tool adoption \n  Support report generation and materials for meetings \n  Provide quality control reviews \n  Qualifications: \n  \n A BA/BS degree in a related field (Computer Science, Software Engineering, or Business Management preferred) \n  A minimum of 2 years of experience \n  A minimum of 2 years of direct experience with ServiceNow products and platform implementation \n  Excellent presentation and communication skills in both written and oral form \n  Demonstrated experience with at least two ServiceNow products and platform implementation in a Business Analyst role \n  Demonstrated experience eliciting requirements using interviews, document analysis, requirements workshops, surveys, business process reviews, and task and workflow analysis. \n  Demonstrated experience critically evaluating information gathered from multiple sources, reconciling conflicts, decomposing high-level information into detailed requirements (e.g., Epics and User Stories) \n  Developed problem-solving and analytical abilities \n  About Us: \n  \n  Perks of working at NetImpact Strategies \n \n \n  Your health comes first \u2013 we offer comprehensive medical, dental, & vision insurance that starts the first of the month after you join the team \n  Invest in your future \u2013 401(k) Plan \u2013 Immediately vested employer contributions; no matching required \n  Work hard, play hard \u2013 we offer a generous Paid Time Off (PTO) policy and observe ALL ten (10) federal holidays \n  Pawsitively pawesome \u2013 Pet Insurance (because our little critters are part of our families, too!) \n  Invest in your education \u2013 Tuition reimbursement, internal training programs, & company-sponsored industry certifications \n  Be part of a dynamic and collaborative work environment recently ranked by The Washington Post as a Top Work Place in 2019 & 2020! \n  Have fun and celebrate and give back \u2013 Team building activities, community volunteering, quarterly HQ days, & an offsite annual awards banquet \n \n \n \n  ABOUT US \n \n \n   NetImpact Strategies Inc. (NetImpact) has been a Trusted Advisor driving impact through digital transformation for the Federal Government for over a decade. We solve complex problems with innovation and agility to create meaningful, transformative, and enduring change. As Trusted Advisors, NetImpact professionals partner with customer agencies to deliver solutions that empower them to not only meet their missions but also realize their strategic vision through agile, outcome-focused solutions addressing both strategic and tactical requirements. We design and implement comprehensive, tailored solutions that are both mindful of the client's culture and organizational dynamics. NetImpact\u2019s core values and commitment to a customer and results-oriented delivery approach has propelled our growth and enabled us to deliver impactful value across Strategic Consulting, Process Automation, Cloud, DevSecOps, Data and Analytics, and Cyber Security for the Federal Government.\n  \n \n \n  ACCESSIBILITY NOTE \n \n \n   NetImpact Strategies is committed to complying with all applicable provisions of the Americans with Disabilities Act, as amended (\u201cADA\u201d), and applicable state and local laws. It is NetImpact\u2019s policy not to discriminate against any qualified person or applicant with regard to any terms or conditions of employment on the basis of such individual\u2019s disability. Consistent with this policy of non-discrimination, NetImpact will provide reasonable accommodations to an individual with a disability, as defined in the ADA or applicable law, who has made NetImpact aware of his/her disability, unless doing so would cause undue hardship to NetImpact. If you are an applicant and need reasonable accommodation when applying for job opportunities within NetImpact, or request reasonable accommodation to utilize NetImpact\u2019s online employment application, please contact careers@netimpactstrategies.com.\n  \n \n \n  EQUAL OPPORTUNITY EMPLOYER \n \n \n   NetImpact is committed to the development of a creative, diverse, and inclusive work environment. In order to provide equal employment and advancement opportunities to all individuals, employment decisions at NetImpact will be based on merit, qualifications, and abilities. NetImpact does not discriminate against any person because of race, color, creed, religion, sex (including gender identity, sexual orientation, and pregnancy), marital status, national origin, disability, age, veteran status, genetic information or any other characteristic protected by federal, state, and local laws (referred to as \"protected status\").",
        "cleaned_desc": "  Support User Acceptance Testing (UAT) including development of scripts and conducting UAT with end users \n  Create references and guides for end users as well as system administrators \n  Generate and update documentation to support requirements, design, and testing activities \n  Continually ensure client understands product updates \n  Support Change Management processes and play pivotal support role for tool adoption \n  Support report generation and materials for meetings \n  Provide quality control reviews \n  Qualifications: \n  \n A BA/BS degree in a related field (Computer Science, Software Engineering, or Business Management preferred) \n  A minimum of 2 years of experience \n  A minimum of 2 years of direct experience with ServiceNow products and platform implementation ",
        "techs": [
            "support user acceptance testing (uat)",
            "development of scripts",
            "conducting uat",
            "create references and guides",
            "generate and update documentation",
            "support change management processes",
            "support role for tool adoption",
            "support report generation",
            "provide quality control reviews",
            "ba/bs degree in a related field",
            "2 years of experience",
            "direct experience with servicenow products and platform implementation"
        ],
        "cleaned_techs": [
            "support user acceptance testing (uat)",
            "development of scripts",
            "conducting uat",
            "create references and guides",
            "support change management processes",
            "support role for tool adoption",
            "support report generation",
            "provide quality control reviews",
            "2 years of experience",
            "direct experience with servicenow products and platform implementation"
        ]
    },
    "a8a99dba4237beba": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 65000.0,
        "salary_max": 85000.0,
        "title": "Financial Analyst",
        "company": "Havarti Risk Services, LLC",
        "desc": "About the Position \n Havarti is a start-up located in Indianapolis, IN, providing expert Health risk talent to a market in high demand for its services. We are an underwriting and risk services company led by recognized and former Health Insurer Chief Actuaries. Employer Stop Loss is the original entry into a $30B market annually and growing. This is an opportunity to gain valuable insight into a complex industry, high-cost healthcare patient patterns and the significant impact risk solutions can have. \n Havarti is committed to hiring employees eager to apply their knowledge innovatively while collaborating with our team's expertise to develop cutting-edge risk solutions. As a Financial Analyst, you have direct contact with, and thus learning opportunities, from many of Havarti\u2019s senior leaders and advisors. \n We are hiring a motivated and talented Financial Analyst to join our team at a very exciting time. This role requires both independent and shared responsibilities for various Finance and Accounting activities critical to Havarti\u2019s success. To do well in this role, you need to be strategic, an active problem solver, efficient, detail oriented, and resourceful. The ideal candidate is confident in their ability to develop and implement administrative systems and processes to support premium collection, commission payments and associated reports. Demonstrated leadership abilities in school, work, or community volunteering are also preferred. This role also has room for advancement. \n What you will do \n Havarti is a rapidly growing company, which will allow unique exposure to a wide range of work but is not limited to the following: \n \n Provide analytical, forecasting, reporting, and project support to senior management. \n Produce monthly reports, which include key metrics, financial results, and variance reporting. \n Identify opportunities for performance improvement across the organization. \n Maintain knowledge and inform the team of new insurance regulations or policies. \n Develop and implement admin systems for Premium collection, Commission payments, and bordereau reports function correctly and timely. \n Review the monthly premium and claims status, cycle completion, and compliance. \n Support audit exercises and contract commitments related to financial activities. \n Collaborate with team members and partners to identify and implement process improvements. \n Participate in continuous improvement activities, actively tracking cost reduction savings. \n Work with finance team and backup Underwriting and data analyst activities. \n Perform account reconciliations as needed. \n Support new product development with models that inform business decision-making. \n Ability to work in fast paced environment, handling multiple priorities to effective closure. \n Decisive, self-motivated/capable of working on own initiative. \n Good communication skills and the ability to work successfully in a team environment. \n Execute other tasks and projects as needed to support Finance and Accounting functions. \n \n Requirements \n \n Bachelor's degree (required) in Finance, Accounting, or related field; CPA or CMA (preferred). \n 3-5 years of relevant experience in corporate finance, financial planning & analysis, investment banking, or other related fields. \n Advanced working knowledge of Excel and financial modeling. \n Financial Planning: 3 years (Required) \n Microsoft Excel: 3 years advanced use (Required) \n Account reconciliation: 1 year (Preferred) \n Strong communication skills with proven ability to achieve results and be strategic. \n 1+ years of experience working at an early-stage start-up or small company (preferred). \n 1+ years of experience working in the health insurance industry (preferred). \n Excellent analytical, decision-making, and problem-solving skills. \n Continuous attention to quality and accuracy. \n \n Benefits \n \n Job Type: Full-time (Indianapolis or virtual) \n Salary: $65,000 - $85,000 annually \n Health Insurance \n 20 Days of Paid Time Off \n 401(k) (matching program) \n Professional development assistance \n Schedule: Monday-Friday, 40 hours per week (some evening and weekend hours required during enrollment season). \n \n Job Type: Full-time \n Pay: $65,000.00 - $85,000.00 per year \n Benefits: \n \n 401(k) \n 401(k) matching \n Health insurance \n Paid time off \n Professional development assistance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n Weekends as needed \n \n Experience: \n \n Finance: 1 year (Preferred) \n Microsoft Excel: 3 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ff96ff506a306ae4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 74800.0,
        "salary_max": 125000.0,
        "title": "Senior Technical Business Analyst",
        "company": "Jack Henry and Associates, Inc.",
        "desc": "At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you\u2019ll join us. We can\u2019t do it without you.\n  \n \n \n  The Senior Technical Business Analyst will be joining one of our back-end services teams that is responsible for Jack Henry's Enterprise API Gateway and Jack Henry's Consumer and Enterprise Identity Provider services. This is a dynamic, agile software delivery team that provides an enterprise-level authentication integration platform and contributes to a mission-critical set of applications. The Senior Technical Business Analyst lives at the intersection of product and engineering, helping translate business requirements into technical specifications for our enterprise integration platforms.\n  \n \n \n  You are infinitely curious and thrive in an environment where you are constantly learning and growing. You want to be somewhere that you are trusted and surrounded by great engineers who rely on your input into the products being developed. Although you work in a team you are self-motivated and able to work with independence. You care deeply about your work, your team, and the business.\n  \n \n \n  This position will be filled to work Remotely within the U.S.\n  \n \n \n  The target salary range for this position is $74,800 \u2013 $125,000, based on location and experience.\n  \n \n \n  If you are interested in this position, please apply on or before October 2, 2023.\n  \n \n \n \n  What you\u2019ll be responsible for: \n \n \n \n \n \n  Interacting with product teams and stakeholders to gather system requirements. \n  Creating requirements and system documentation as well as contributing to engineering and end-user documentation. \n  Interacting with engineering teams to accurately describe product requirements. \n  Learning and staying up to date on trends and best practices in areas relevant to your team. \n  Assisting in application, system, and user-acceptance tests. \n  May perform other job duties as assigned. \n \n \n \n  What you\u2019ll need to have: \n \n \n \n \n \n  A minimum of 7 years of technical business analysis experience or software engineering experience. \n  Experience interacting with REST APIs. \n  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   \n \n \n \n \n Why Jack Henry? \n \n \n \n  At Jack Henry, we pride ourselves through our motto of, \"Do the right thing, do whatever it takes, and have fun.\" We recognize the value of our associates and believe much of our company\u2019s strength and success depends on their well-being.\n   \n \n \n \n \n  We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.\n  \n \n \n \n \n  Culture of Commitment \n \n \n \n \n \n   Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.\n   \n \n \n \n \n Equal Employment Opportunity \n \n \n \n \n \n   At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business\u2014and our society\u2014stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.\n  \n \n \n \n \n   No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.\n  \n \n \n \n \n  Requests for full corporate job description may be requested through the interview process at any time.",
        "cleaned_desc": "  Experience reading and interpreting API documentation. \n  Strong Documentation Capabilities including workflow and sequence diagrams. \n  Excellent communication skills (written and verbal). \n  Ability to travel up to 10% to attend JH meetings, trainings, and/or professional conferences. \n \n \n \n  What would be nice for you to have: \n \n \n \n \n \n  Experience in banking, government, or other high security or highly regulated systems. \n  Experience with NodeJS. JavaScript, and/or TypeScript software teams. \n  Business analysis or technical business analysis experience with larger-scale or complex project work. \n  OAuth and Open ID Connect experience. \n  Experience developing and integrating with Identity and Access Management platform. \n \n \n \n \n   If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry\u2019s mission and can contribute to our company in a variety of ways.\n   ",
        "techs": [
            "api documentation reading and interpretation",
            "documentation capabilities (workflow and sequence diagrams)",
            "communication skills (written and verbal)",
            "travel ability (up to 10%)",
            "experience in banking",
            "government",
            "or other high security or highly regulated systems",
            "experience with nodejs",
            "javascript",
            "and/or typescript software teams",
            "business analysis or technical business analysis experience with larger-scale or complex project work",
            "oauth and open id connect experience",
            "experience developing and integrating with identity and access management platform."
        ],
        "cleaned_techs": [
            "travel ability (up to 10%)",
            "experience in banking",
            "government",
            "experience with nodejs",
            "javascript",
            "and/or typescript software teams",
            "business analysis or technical business analysis experience with larger-scale or complex project work",
            "oauth and open id connect experience",
            "experience developing and integrating with identity and access management platform."
        ]
    },
    "ba60ebc098b0e9dd": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 84508.195,
        "salary_max": 107006.21,
        "title": "Business Intelligence Specialist III \u2013 Medicaid",
        "company": "CORMAC",
        "desc": "Cormac is looking for a skilled  Business Intelligence Specialist  to join our growing company. This role will be responsible for managing data retrieval and analysis within an organization. This will include organizing data points, communicating between the Sr. BI Specialist and the IT department in analyzing data to determine the corporation\u2019s needs. \n Responsibilities \n \n Extract data from databases and data warehouses for reporting and facilitate sharing among multiple data systems. \n Meet with staff and hospital advisory groups to understand their unique data requests and explore solutions that inform their needs. \n Translate business requirements into data models for visualization deployment. \n Interpret complex data requests, visualize the data in a way that makes sense for each request, and help the stakeholders interpret and utilize the data. \n Assist in identifying and connecting additional data sources to new and existing Business Intelligence environments. \n Update website with refreshed data and test functionality after updates. \n Works with BI lead, business users and analysts to gather requirements, conduct design sessions and prepare specifications. \n Translates project requirements into functional and technical specifications for BI reports, dashboards and analytical applications. \n Develops, implements and maintains test strategies and plans. \n \n Minimum Qualifications \n \n Associate degree in Information Management, Information Systems, Healthcare Analytics, or equivalent field, Bachelor\u2019s Degree preferred. \n 4-6 years of experience as a Business Intelligence developer with expertise in Power BI within state Medicaid. \n A minimum of four (4) years of hands-on experience in a business analyst or a requirements specialist role supporting the design and development of federal or state-based marketplaces or complex health and human services systems. \n Hands-on experience translating business requirements into data models for visualization deployment. \n Knowledge of database programming and statistics. \n Knowledge of Microsoft Access, Excel, PowerPoint, and Word. \n \n Why CORMAC? \n At CORMAC, we leverage the power of data management and analytics to enable our customers to achieve their strategic goals. With over 20 years of experience in health information technology (HIT), human-centered design principles, and Agile development methodologies, CORMAC delivers complex digital solutions to solve some of the most challenging problems facing public healthcare programs today \n As a US Federal Government contractor in the public healthcare sector, our work is impactful and cutting-edge while being performed in a supportive, collaborative, and welcoming environment. We offer flexible work schedules with remote, hybrid, or fully in-person workplace options to empower our employees to decide the workplace most suitable for them. At CORMAC, we have a highly diverse workforce and believe a work environment is a place where creativity, collaboration, enthusiasm, and innovation happen, regardless of location. \n Position Requires Employment Eligibility Verification /E-Verify Participation/EEO \n As an Equal Employment Opportunity employer, CORMAC provides equal employment opportunity to all employees and applicants without regard to an individual's protected status, including race/ethnicity, color, national origin, ancestry, religion, creed, age, gender, gender identity/expression, sexual orientation, marital status, parental status, including pregnancy, childbirth, or related conditions, disability, military service, veteran status, genetic information, or any other protected status.",
        "cleaned_desc": "Cormac is looking for a skilled  Business Intelligence Specialist  to join our growing company. This role will be responsible for managing data retrieval and analysis within an organization. This will include organizing data points, communicating between the Sr. BI Specialist and the IT department in analyzing data to determine the corporation\u2019s needs. \n Responsibilities \n \n Extract data from databases and data warehouses for reporting and facilitate sharing among multiple data systems. \n Meet with staff and hospital advisory groups to understand their unique data requests and explore solutions that inform their needs.   Translate business requirements into data models for visualization deployment. \n Interpret complex data requests, visualize the data in a way that makes sense for each request, and help the stakeholders interpret and utilize the data. \n Assist in identifying and connecting additional data sources to new and existing Business Intelligence environments. \n Update website with refreshed data and test functionality after updates. \n Works with BI lead, business users and analysts to gather requirements, conduct design sessions and prepare specifications.   Associate degree in Information Management, Information Systems, Healthcare Analytics, or equivalent field, Bachelor\u2019s Degree preferred. \n 4-6 years of experience as a Business Intelligence developer with expertise in Power BI within state Medicaid. \n A minimum of four (4) years of hands-on experience in a business analyst or a requirements specialist role supporting the design and development of federal or state-based marketplaces or complex health and human services systems. \n Hands-on experience translating business requirements into data models for visualization deployment. \n Knowledge of database programming and statistics. ",
        "techs": [
            "business intelligence specialist",
            "data retrieval",
            "data analysis",
            "data points",
            "bi specialist",
            "it department",
            "data models",
            "visualization deployment",
            "data sources",
            "website updates",
            "power bi",
            "state medicaid",
            "business analyst",
            "requirements specialist",
            "database programming",
            "statistics"
        ],
        "cleaned_techs": [
            "business intelligence specialist",
            "data retrieval",
            "data points",
            "bi specialist",
            "it department",
            "data models",
            "visualization deployment",
            "data sources",
            "website updates",
            "powerbi",
            "state medicaid",
            "requirements specialist",
            "database programming",
            "statistics"
        ]
    },
    "f1d59e958c2360f5": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 4848.66,
        "salary_max": 7909.41,
        "title": "Information Technology BA II 100% remote in TX",
        "company": "Dept of Family & Protectve Svc",
        "desc": "The mission of DFPS is to protect children, the elderly, and people with disabilities from abuse, neglect, and exploitation by involving clients, families, and communities. We are looking to grow our teams with people who share our energy and enthusiasm to get behind our mission of protecting those among us who are most in need. \n     \n  The Texas Department of Family and Protective Services (DFPS) is currently seeking a Business Analyst for a full-time position within the Application Development team in the IT Department. This position is a Business Analyst II role and will report directly to the Business Analyst Manager. \n     \n  The BA II will perform complex (journey-level) business analysis work that includes coordination of the gathering, development, and documentation of user requirements, facilitation of work sessions with functional staff and project team members to capture and document requirements, and review and assessment of business processes to ensure requirements meet the customer needs. The BA II develops user acceptance testing scenarios, coordinates testing activities with customers, and validates testing results. Good written and verbal communication and presentation skills are necessary to succeed in this role. \n     \n  This position is classified as a full-time position (40 hours a week). Work outside of regular hours may be required. Travel to other Austin offices(s) may be required. Works under minimal supervision, with considerable latitude for the use of initiative and independent judgment. \n     \n  This position is a full-time position that includes other State of Texas benefits as described in this SAO site: http://www.sao.texas.gov/SAOReports/ReportNumber?id=18-704\n     \n \n \n \n \n \n \n \n Essential Job Functions: \n  Business Analysis & Process Improvement \n     \n Works with stakeholders to understand their technology needs and issues in performing their day-to-day work.  \n \n Conducts work sessions with users and project team members to document requirements, develop use cases, and/or technology solutions.  \n \n Works with stakeholders to define, elicit, and document requirements.  \n \n Participates in systems analysis as needed.  \n \n Analyzes program policies and business practices to provide recommendations and ideas for addressing technology requests, needs, and solutions.  \n \n Assists (and when needed coordinates) user acceptance testing activities.  \n \n Works with developers to interpret and provide clarification on requirements as needed.  \n \n Works with test team to interpret and provide clarification on requirements as needed.  \n \n Participates in release activities and application development implementation activities.  \n \n Is able to perform business analyst role in a waterfall or agile SDLC framework.  \n \n Is able to trouble shoot production defects and understand urgency based on severity level of defect reported.  \n \n Performs other duties as assigned. \n \n \n \n \n \n \n \n \n Knowledge Skills Abilities: \n \n Five (5) years\u2019 experience in a role demonstrating business systems analysis expertise.  \n \n Knowledge of the Business Analysis Body of Knowledge (BABOK).  \n \n Knowledge of Project Management Body of Knowledge (PMBOK) and Project Management Life Cycle (PMLC) methodologies.  \n \n Knowledge of Software Development Life Cycle (SDLC) and high-level system design methodologies and techniques (entity/relationship models, data/process flow diagrams); object-oriented programming and of programming client/server applications.  \n \n Exceptional interpersonal, presentation building, meeting facilitation, public-speaking, writing, editing, and proofreading skills.  \n \n Experience researching, understanding, and summarizing key and/or abstract ideas and when applicable, suggest recommendations from those findings.  \n \n Strong analytical and critical thinking skills.  \n \n Knowledge of productivity software including Microsoft Office Suite to include MS Word, Excel, PowerPoint, MS Project, SharePoint, Visio and/or SQL.  \n \n Demonstrates excellent organization skills, e.g., defines and organizes tasks, responsibilities, and priorities.  \n \n Able to work independently or as a member of a team. \n \n \n \n \n \n Registration or Licensure Requirements: \n \n Graduation from an accredited four-year college or university with a Bachelor\u2019s Degree in Business, MIS, CIS, Computer Science or similar. Work experience may be substituted for education on a year-for-year basis.  \n \n CBAP or similar Business Analyst certification is a plus but not required. \n \n \n \n \n \n \n \n \n Initial Selection Criteria: \n \n Graduation from an accredited four-year college or university; experience may be substituted for education on a year for year basis.  \n \n At least five (5) years\u2019 experience performing in the role of a Business Analyst.  \n \n  Note: You must meet the initial screening criteria to be considered. You should not apply if your submittal documents do not clearly reflect experience meeting the initial screening criteria.\n     \n \n \n \n \n \n \n \n Additional Information: \n  N/A \n    \n \n \n \n \n MOS Code: \n  Note: Military occupation(s) that relate to the initial selection criteria and registration or licensure requirements for this position may include 25B, 255A, IT, 182X, 682X, 26, C4|10, C4|11, ISM, 8848, 8846, 8858, 3D0X1 . All active duty military, reservists, guardsmen, and veterans are encouraged to apply if qualified to fill this position. For more information see the Texas State Auditor\u2019s Military Crosswalk at http://www.hr.sao.state.tx.us/Compensation/JobDescriptions.aspx.\n     \n \n \n \n \n \n As a state agency, DFPS is required Texas Administrative Code (TAC 206 and 213) to ensure all Electronic Information Resources (EIR) follow accessibility standards. The staff must be familiar with the WCAG 2.1 AA and Section 508 to create accessible content including but not limited to; Microsoft Office documents, Adobe PDFs, webpages, software, training guides, video, and audio files. \n \n \n \n \n \n \n HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work. \n \n \n In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.",
        "cleaned_desc": " \n Five (5) years\u2019 experience in a role demonstrating business systems analysis expertise.  \n \n Knowledge of the Business Analysis Body of Knowledge (BABOK).  \n \n Knowledge of Project Management Body of Knowledge (PMBOK) and Project Management Life Cycle (PMLC) methodologies.  \n \n Knowledge of Software Development Life Cycle (SDLC) and high-level system design methodologies and techniques (entity/relationship models, data/process flow diagrams); object-oriented programming and of programming client/server applications.  \n \n Exceptional interpersonal, presentation building, meeting facilitation, public-speaking, writing, editing, and proofreading skills.  \n \n Experience researching, understanding, and summarizing key and/or abstract ideas and when applicable, suggest recommendations from those findings.  \n \n Strong analytical and critical thinking skills.  \n \n Knowledge of productivity software including Microsoft Office Suite to include MS Word, Excel, PowerPoint, MS Project, SharePoint, Visio and/or SQL.  \n \n Demonstrates excellent organization skills, e.g., defines and organizes tasks, responsibilities, and priorities.  \n \n Able to work independently or as a member of a team. \n \n \n \n \n \n Registration or Licensure Requirements: ",
        "techs": [
            "babok",
            "pmbok",
            "pmlc",
            "sdlc",
            "entity/relationship models",
            "data/process flow diagrams",
            "object-oriented programming",
            "client/server applications",
            "microsoft office suite",
            "ms word",
            "excel",
            "powerpoint",
            "ms project",
            "sharepoint",
            "visio",
            "sql."
        ],
        "cleaned_techs": [
            "babok",
            "pmbok",
            "pmlc",
            "sdlc",
            "entity/relationship models",
            "data/process flow diagrams",
            "object-oriented programming",
            "microsoft",
            "excel",
            "powerpoint",
            "ms project",
            "sharepoint",
            "visio",
            "sql"
        ]
    },
    "a17306e75242d8ea": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 81397.5,
        "salary_max": 103067.375,
        "title": "Product BI Analyst- Remote",
        "company": "Proxibid",
        "desc": "ABOUT US \n  Auction Technology Group (ATG) is an award-winning business - won the title of Tech Business of the Year at the 2021 PLC awards! \n  ATG exists to revolutionize the secondary market. We believe in a world where millions of objects can be traded online at the best possible value through our channel of green commerce that gives new life to all things timeless, sustainable, or re-usable. \n  Our mission is to be the global marketplace connecting bidders, businesses, collectors, consigners, contractors, and consumers to an under-explored world curated by thousands of trusted auctioneer experts. ATG operates global digital marketplaces in three verticals for the auction industry: art and antiques, industrial & commercial and consumer surplus and returns. With 350 employees worldwide and teams in the US, Canada, Germany and the UK, our mission is to lead the digital transformation of these markets through tech innovation and digital expertise. \n  ATG will provide all necessary computing and communication equipment and will never ask a potential employee to purchase work equipment on their own account and seek reimbursement. \n  THE ROLE  \n The Data Analytics team plays a crucial role in our digital business. As a shared service function, our focus is on ensuring our stakeholders needs are being met, be that for sales, product, marketing, operations or finance. The current main outputs are enabling self-service reporting and analysis, creating new or ad hoc reports, retrospective analysis and automation of it, as well as forecasting. \n  We are looking for a Business Intelligence Analyst whose main focus will be empowering our Product teams with data and insight. You will be an expert BI report designer and data modeler, enhancing our suite of self-service reports in Power BI. You will have access to our Enterprise Data Warehouse to support this and you will have the chance to influence its continued development with your unique knowledge of the Product team's reporting requirements. \n  You will be an expert data analyst; comfortable working with large datasets of varying origin and cleanliness, using a variety of systems, and presenting findings back to the business teams. \n  You will need excellent communication skills as this is a highly visible role working across the global organization to partner closely with the Product Managers to understand their ongoing requirements. This role will be main contact for the Product data set. It will be the primary contact for manual data extraction/manipulation as well as reporting datasets to business units. \n  KEY TASKS & RESPONSIBILITIES \n \n  Remediating support requests related to data and data flows \n  Collecting, interpreting and disseminating complex data \n  Developing and maintaining reporting and dashboards to inform and empower stakeholders \n  Partner with the business to understand their requirements and uncover where the real data challenges & opportunities lie \n  Support and guide business users to access the data required for insight / analysis \n  Monitor analytics and metrics results \n  Work with the business to create detailed backlog items which can then be prioritized with the department leaders \n  Work closely with the BI Engineer and Platform engineering team to ensure that the new datasets are implemented and deployed appropriately into the data warehouse \n  Scrutiny of new dimensions/metrics/processes prior to release \n  Generate and maintain good quality documentation \n  Meet deadlines and complete projects within timeframes \n  Keep abreast of the latest developments in technology (particularly relating to Power BI) \n  Meet requirements for ad-hoc requests \n \n  KNOWLEDGE, SKILLS & EXPERIENCE REQUIRED  \n \n Solid experience in a business intelligence role(s) \n  Excellent SQL skills using a platform such as SQL Server, Oracle, MySQL, AWS, TSQL \n  Extensive experience of data visualization including proficiency in Microsoft Power BI or Looker (similar experience with Arcadia, Tableau etc will be considered) \n  Experience translating business requirements into deliverable user stories \n  Experience working within an Agile environment using Scrum or Kanban \n  Experience with Salesforce CRM an advantage \n  Experience with Google Analytics \n  Strong background turning data insights into strategy/solutions \n  Highly numerate and analytical with an excellent attention to detail \n  Excellent presentation, written and verbal communications skills to both technical and business stakeholders \n  Ability to multi-task and remain calm and focused in a high-pressure environment \n  Previous work experience with aggregator or marketplace websites, SaaS products would be an advantage \n  Strong written and verbal communication skills \n  Preferred experience utilizing Google Big Query \n \n  DIVERSITY, EQUALITY, AND INCLUSION \n  ATG strives to be a company where people of all races, religions and persuasions can work and thrive in a supportive environment. We are fully committed to the elimination of unlawful and unfair discrimination, and we value the differences that a diverse workforce brings to our organization. We will not discriminate because of any other irrelevant factor and proud to have built a culture that values meritocracy, openness, fairness, and transparency. \n  You will not be disadvantaged because of who you are or where you come from. What matters to us is that you are the best person for the job and are passionate and committed to our vision to deliver in your role. \n  We will do everything we can to support you during your application. If you need us to make any adjustments to our recruitment process, speak to our HR team who will be happy to support you. \n  EQUAL OPPORTUNITY EMPLOYER",
        "cleaned_desc": "  You will need excellent communication skills as this is a highly visible role working across the global organization to partner closely with the Product Managers to understand their ongoing requirements. This role will be main contact for the Product data set. It will be the primary contact for manual data extraction/manipulation as well as reporting datasets to business units. \n  KEY TASKS & RESPONSIBILITIES \n \n  Remediating support requests related to data and data flows \n  Collecting, interpreting and disseminating complex data \n  Developing and maintaining reporting and dashboards to inform and empower stakeholders \n  Partner with the business to understand their requirements and uncover where the real data challenges & opportunities lie \n  Support and guide business users to access the data required for insight / analysis \n  Monitor analytics and metrics results   \n Solid experience in a business intelligence role(s) \n  Excellent SQL skills using a platform such as SQL Server, Oracle, MySQL, AWS, TSQL \n  Extensive experience of data visualization including proficiency in Microsoft Power BI or Looker (similar experience with Arcadia, Tableau etc will be considered) \n  Experience translating business requirements into deliverable user stories \n  Experience working within an Agile environment using Scrum or Kanban \n  Experience with Salesforce CRM an advantage \n  Experience with Google Analytics \n  Strong background turning data insights into strategy/solutions    Highly numerate and analytical with an excellent attention to detail \n  Excellent presentation, written and verbal communications skills to both technical and business stakeholders \n  Ability to multi-task and remain calm and focused in a high-pressure environment \n  Previous work experience with aggregator or marketplace websites, SaaS products would be an advantage \n  Strong written and verbal communication skills \n  Preferred experience utilizing Google Big Query \n \n  DIVERSITY, EQUALITY, AND INCLUSION \n  ATG strives to be a company where people of all races, religions and persuasions can work and thrive in a supportive environment. We are fully committed to the elimination of unlawful and unfair discrimination, and we value the differences that a diverse workforce brings to our organization. We will not discriminate because of any other irrelevant factor and proud to have built a culture that values meritocracy, openness, fairness, and transparency. ",
        "techs": [
            "sql server",
            "oracle",
            "mysql",
            "aws",
            "tsql",
            "microsoft power bi",
            "looker",
            "arcadia",
            "tableau",
            "salesforce crm",
            "google analytics",
            "google big query"
        ],
        "cleaned_techs": [
            "sql",
            "oracle",
            "mysql",
            "aws",
            "tsql",
            "powerbi",
            "looker",
            "arcadia",
            "tableau",
            "salesforce crm",
            "google analytics",
            "google big query"
        ]
    },
    "bf5b11c3d00e510e": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40691.656,
        "salary_max": 51524.703,
        "title": "Functional Analyst I, Financial Aid & Registration (Telework Eligible)",
        "company": "Aims Community College",
        "desc": "Job Description:\n   This position is eligible for 100% remote work.\n  \n  The Functional Analyst position reports directly to the Student Technology Solutions Manager. This position will provide technical support to staff in the Financial Aid and Registration offices in meeting their daily functional responsibilities to collect, create and maintain Financial Aid & Registration processes in the students\u2019 systems \u2013 Workday & Banner. Responsible for providing system modifications and support for the assigned functional area(s) while ensuring the technology used aligns with industry best practices. In addition, participate in the testing and training for those systems. The position serves as a liaison between the departments and the college IT department with the Workday release review, testing and implementation of new processes and system updates.\n  \n  The Functional Analyst will also collaborate with the Executive Director of Financial Aid, Assistant Directors of Financial Aid, Registrar\u2019s office management team and Student Technology Solutions Manager, and other Workday functional area staff to identify business needs and to help troubleshoot system and process problems that may arise during the course of executing processes and daily office operations.\n  \n  The position keeps up-to-date with evolving practices and software that will assist the Financial Aid and Registration staff in their daily work and will assist, as needed, with report development and training staff on new system procedures and products.\n  \n \n   Student System Support\n  \n \n  Maintain processes related to Match and Merge and impact on Financial Aid and Registration functions \n  Reports (Support and Create) - Workday Reporting Developer - Writes, maintains, and interprets reports from Workday and Banner, using Workday reporting tools, Argos and SQL to support Financial Aid and Registration Workday processes; Update current functional reports and write new reports for daily operations as requested by staff in FA and Registration offices. \n  Business process/EIBs \u2013 assist the Financial Aid and Registration departments in the creation and execution of EIB\u2019s, as identified, to support all processes. \n  Review, respond and resolve Help Desk Ticket related to Financial Aid and Registration \n  Assist with integrations (Department of Education, COD, NSLDS, FSA Access, NextGen scholarship, Scholarnet alternative loans \n  Work with Financial Aid and Registration department staff to determine if and when it may be necessary to Reconfigurations \n  Prepare and execute processes for Financial Aid Year Roll \n  Provide input to Financial Aid and Registration teams on updates needed to Workday Job Aids, as needed \n \n \n     Evaluate and analyze Calculated Fields (Monitor and update reports, Configurations) as change is needed.\n    \n \n \n     Assist Enrollment Management team\u2019s functional analyst with review of student application to matriculation process issues and assist in troubleshooting residency classification and tuitions status issues and other related process issues that impact a student\u2019s financial aid and/or registration.\n    \n \n \n     Collaborate and coordinate with other STS functional analysts, as needed, to support processes that may/will impact students supported by other functional area offices.\n    \n \n \n     Cross-train on Enrollment Management, Records, Academic Affairs, Pathway Advising, and AVP & DOS areas (Aims2UNC; CDI; Transitions; TRiO; Testing Center; Counseling/CARE, DAS and Student Life).\n    \n \n \n     Assist Records (Academics) with Academic Requirements, Parchment (transcripts) and ongoing manual issues within the student registration area.\n    \n \n \n     Set up and schedule Financial Aid Engagements, dashboards, and BIRTs.\n    \n \n \n \n   Collaboration, Design & Support\n  \n \n  Collaborate with functional users and Information Technology Administrative Services (ITAS) to analyze the Workday student information system\u2019s functionality and other software systems that may be integrated with Workday, such as degree audit, CRM, etc. \n  Identify and implement software functionality, as it becomes available. \n  Elicit and understand the business requirements of stakeholders using interviews, document analysis, requirements workshops, business process modeling, task and workflow analysis, and other methodologies. \n  Perform user requirements analysis relative to software system capabilities to meet end-user requirements. \n  Collaborate in the design of technical solutions to resolve business problem. \n  Transfer the knowledge of business requirements to the ITAS department, as needed, to ensure they are accurately translated into system developments \n  Identify and develop student system changes and implement, standardize and/or enhance workflow. \n  Monitor daily Workday processes within Financial Aid and Registration to ensure they work properly and align with processes in other functional areas. \n  Research, design, develop and enhance documentation and materials needed to train staff in procedures, modifications, customizations and maintenance requirements. \n  Provide input for end-user training, as appropriate. \n \n \n \n   Testing, Documentation & Training\n  \n \n  Coordinate and collaborate with the STS Manager, STS Functional Analysts, and Workday functional users, to preview release information, create testing plans, read over enhancement documentation, fixes and changes and test Workday releases in collaboration with functional area staff. (2x per year. \n  Coordinate with the STS and IT teams to review, and create testing plans, as needed, for fixes and changes delivered through weekly patches from Workday. \n  Collaborate on integration testing of the Workday system, as new versions and functionality are made available. \n  Collaborate and coordinate with other departments to find a resolution when upgrades, patches, fixes or enhancements are needed. Work with the STS team to open and monitor requests with Workday, when necessary to resolve issues and perform corrective actions as necessary. \n  Remain up-to-date with all vendor-supplied documentation and provide more user - friendly system configuration and maintenance training manuals and other documentation, as needed. \n  Attend affinity group and vendor conferences and trainings, as assigned. (Professional Development). \n \n \n \n   Reporting & Data Analysis\n  \n \n  Reports needed by the Financial Aid and Registration offices or requested by other functional areas, create ad-hoc queries, and reports using Workday and other reporting tools, (Tableau, Prism, Argos, and PL/SQL etc.) to extract data. \n  Extract and analyze data to track/identify students for the Financial Aid and Registration offices, as needed. \n  Identify patterns, trends, and correlations to aid in effectiveness of these supported areas and in retention programs and student success. \n  Create dashboards and reports for Financial Aid and Registration directors, managers and/or staff, as needed. \n  Communicate findings in user-friendly and easily interpreted methods. \n  Create ad-hoc queries and reports as needed, using such appropriate reporting tools, such as Tableau, Argos, and PL/SQL. \n \n \n \n   Minimum Qualifications:\n  \n \n  Bachelor's Degree in Computer Information Systems or other related field; Plus, \n  Two (2) years of work experience with Workday, Banner or other Higher Ed ERP systems or an equivalent combination of education and/or work experience. \n  Excellent interpersonal and communication skills. \n  Attention to detail, problem-solving and conflict resolution capabilities. \n  Demonstrable computer proficiency with Microsoft Office programs. \n  Ability to organize tasks, set priorities and work on multiple projects simultaneously. \n  Ability to work independently with initiative and discretion. \n  Ability to work effectively with various populations in a diverse community setting.. \n  Excellent verbal and written communication skills. \n  Demonstrated ability to analyze data and organize workflow logically. \n  Experience presenting information or training in small groups. \n  Ability to maintain confidentiality. \n \n \n \n   Preferred Qualifications:\n  \n \n  Experience with project management and knowledge of best practices. \n  Experience writing SQL, and reports using current industry standard report writing tools, such as Argos, Tableau and Prism. \n  Knowledge of functional student services processes in higher education. \n  Knowledge of policies, procedures, and guidelines. \n  Understanding of SQL or transactional databases. \n  Experience testing patches, upgrade releases, documenting modifications and recovery procedures. \n  Experience using job scheduler software tools (Automic, UC4, Appworx), Argos or other software. \n \n \n \n   Required Documents:\n  \n \n  Cover Letter \n  Resume \n  Diversity Statement \n \n \n \n   All Applicants:\n  \n \n  Compare your previous work experience to the job duties listed on the job positing under job description. Enter the job duties you have preformed under the \"Work Experience\" section on your job application. We evaluate your experience based on this information. \n  Please make sure you state whether work experience (aka work history) is part time or full time employment by listing the average number of hours worked per week. This information is used to determine your new annual salary. \n  Be sure to upload all the required documents listed at the above in \"Additional Job Description\" section. This can be uploaded as part of your application materials in the \"My Experience\" section. If there are missing documents, your incomplete application will not be considered. \n \n \n \n   Diversity Statement Instructions\n  \n \n   Aims Community College recognizes and celebrates diversity within our students, faculty, and staff. We are committed to equity and inclusion to improve the learning experiences of all students and the working conditions of all employees.\n  \n \n \n \n     In your diversity statement, please provide your interpretation of what it means to serve a diverse community and work in an inclusive environment.\n    \n \n \n     Please include specific examples for how your background, education, and/or professional experience have prepared you to fulfill those responsibilities in this position.\n    \n \n \n     As you consider what to put in your statement, please note Aims Community College is committed to equal employment opportunity and does not discriminate on the basis of race, gender, age, or any other protected class.\n    \n \n \n \n   Aims Community College is an equal opportunity employer. Selection will be based solely on merit and will be without discrimination based on age, ancestry, color, creed, disability, ethnicity, familial status, gender, gender identity, genetic information, marital status, national origin, sex, sexual orientation, race, religion, or veteran's status. All application materials must be submitted by the closing date posted and become the property of Aims Community College. The screening committee will select finalists for interviews. The goal of Aims Community College is to enhance the diversity present in the district we serve. To comply with Immigration Reform and Control Act of 1986, if hired, you will be required to provide documents within 3 days of hire date to show your identity and your authorization to work. This law applies to all persons hired.\n  \n \n \n   Screening/Selection:\n  \n \n   In order to be considered please provide a thorough and complete application.\n    Initial screening will be conducted by a committee based on completed application materials.\n  \n \n \n   Employees in these positions may be asked to participate in temporary assignments lasting less than 6 months (such as curriculum development, short term projects, meetings and substitute duties) which could amount to additional temporary pay.\n  \n \n \n   Upon hire, all positions at Aims Community College require a criminal background check, and may require industry specific screenings such as an MVR, physical and/or drug screen. Keep in mind, a conviction does not automatically preclude candidates from being employed. The nature of a conviction will be considered relative to the duties of the position.\n  \n \n \n   If you need assistance with this process please contact Human Resources at 970-378-3720.",
        "cleaned_desc": "  Collaborate and coordinate with other departments to find a resolution when upgrades, patches, fixes or enhancements are needed. Work with the STS team to open and monitor requests with Workday, when necessary to resolve issues and perform corrective actions as necessary. \n  Remain up-to-date with all vendor-supplied documentation and provide more user - friendly system configuration and maintenance training manuals and other documentation, as needed. \n  Attend affinity group and vendor conferences and trainings, as assigned. (Professional Development). \n \n \n \n   Reporting & Data Analysis\n  \n \n  Reports needed by the Financial Aid and Registration offices or requested by other functional areas, create ad-hoc queries, and reports using Workday and other reporting tools, (Tableau, Prism, Argos, and PL/SQL etc.) to extract data. \n  Extract and analyze data to track/identify students for the Financial Aid and Registration offices, as needed. \n  Identify patterns, trends, and correlations to aid in effectiveness of these supported areas and in retention programs and student success. \n  Create dashboards and reports for Financial Aid and Registration directors, managers and/or staff, as needed. \n  Communicate findings in user-friendly and easily interpreted methods. \n  Create ad-hoc queries and reports as needed, using such appropriate reporting tools, such as Tableau, Argos, and PL/SQL. \n \n \n \n   Minimum Qualifications:\n  \n \n  Bachelor's Degree in Computer Information Systems or other related field; Plus, \n  Two (2) years of work experience with Workday, Banner or other Higher Ed ERP systems or an equivalent combination of education and/or work experience. \n  Excellent interpersonal and communication skills. \n  Attention to detail, problem-solving and conflict resolution capabilities. \n  Demonstrable computer proficiency with Microsoft Office programs. \n  Ability to organize tasks, set priorities and work on multiple projects simultaneously. \n  Ability to work independently with initiative and discretion. \n  Ability to work effectively with various populations in a diverse community setting.. \n  Excellent verbal and written communication skills. \n  Demonstrated ability to analyze data and organize workflow logically. \n  Experience presenting information or training in small groups. \n  Ability to maintain confidentiality. \n \n ",
        "techs": [
            "workday",
            "tableau",
            "prism",
            "argos",
            "pl/sql"
        ],
        "cleaned_techs": [
            "workday",
            "tableau",
            "prism",
            "argos",
            "pl/sql"
        ]
    },
    "72ef101e09978a8a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 37.0,
        "salary_max": 42.0,
        "title": "IT Business Analyst 3 (VA16)",
        "company": "Resource Management Associates, LLC",
        "desc": "The client is looking for a candidate who will work closely with multiple stakeholders, Subject Matter Experts (SMEs), and development teams to document business requirements & business flow diagrams. \n The ideal candidate will be responsible for enterprise-wide business analysis of web applications for the Office of Information Management (OIM) and its customers. \n The ideal candidate will work closely with multiple stakeholders, Subject Matter Experts (SMEs), and development teams to document business requirements. \n The ideal candidate will report to the Project Manager to ensure business requirements, enhancements, modifications, and newly identified business initiatives are thoroughly documented for successful implementation of Information Technology solutions. \n Specific Tasks such as: \n -Working with customers and project management team to develop business requirements in response to requests for systems enhancements, modifications, and newly identified business initiatives \n -Working with technical team and vendor to ensure requirements are incorporated into systems design and testing \n -Evaluating alternative strategies and making recommendations for viable solutions that are compatible with current technologies and systems \n -Developing requirements documentation and business flow diagrams \n -Actively participating in functional and systems integration unit testing; creating test plans, scenarios, and testing results \n -Assisting customers with testing \n -Developing and presenting training to customers \n -Providing implementation and maintenance support \n -Meeting regularly with customers \n -Proactively making suggestions for systems and process improvement and performing competitive, problem, and opportunity analysis, emphasizing integration, experimentation, creative brainstorming, early complexity assessment, and capturing results in the form of a business case to propose a new change initiative \n -Keep Project Manager informed of key issues that may impact project implementation \n -Facilitate project conference calls, status meetings, planning sessions, and provide for meeting notes \n -Utilizing system based project management applications, collaboration applications, and MS Office applications; Visio, SharePoint, Google Meets, Teams, etc \n Job Types: Full-time, Part-time, Contract, Temporary \n Pay: $37.00 - $42.00 per hour \n Schedule: \n \n 8 hour shift \n Monday to Friday \n \n Application Question(s): \n \n What is your desired contract hourly rate? \n Can you work off a W2 or 1099? \n \n Experience: \n \n Relational databases (SQL): 7 years (Preferred) \n System development lifecycle (SDLC) methodologies: 7 years (Preferred) \n Quality assurance techniques: 7 years (Preferred) \n Skill in project planning and requirements gathering: 7 years (Preferred) \n problem-solving, active listening, and egotiation: 7 years (Preferred) \n business analysis and business process mapping: 7 years (Preferred) \n Procedural writing, and process engineering: 7 years (Preferred) \n Conflict resolution and group visitation: 7 years (Preferred) \n Organization and time management,: 7 years (Preferred) \n Manage, coordinate, and prioritize multiple activities: 7 years (Preferred) \n Business process engineering methods: 7 years (Preferred) \n Multiple project management methodologies: 6 years (Preferred) \n \n Work Location: Hybrid remote in Richmond, VA 23219",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "709a7a6a3ef5b71a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 107153.18,
        "salary_max": 135679.8,
        "title": "Senior Business Process Transformation / Automation ROI Analyst- Department of Veterans Affairs (VBA Central Office)",
        "company": "Sprezzatura Management Consulting",
        "desc": "Position Description:  \n Sprezzatura is seeking a skilled and experienced Senior Business Process Transformation / Automation ROI Analyst to help improve efficiency, effectiveness, and customer service within the VBA Central Office. As a Senior Business Process Transformation / Automation ROI Analyst, you must demonstrate the ability to build ROI business cases for supporting and advancing automation initiatives, preferably in Fed benefits environment. The candidate will demonstrate an understanding of the automation transformation decision making process by understanding, analyzing, and diagramming the nuts and bolts of the existing processes and apply this learning to create proposed redesign solutions. Then candidate must then be able to effectively articulate (written and verbal) these proposed redesign solutions, to both internal and external senior level stakeholders. It\u2019s key that the candidate have experience documenting, mapping, and redesigning business processes and procedures utilizing BPMN and be able to articulate recommendations expressed in terms of benefit to the Veteran and Return on Investment. Candidate will contribute to the VA's mission of providing exceptional services to our nation's veterans by consistently demonstrating knowledge of process improvement methodologies and change management strategies throughout the period of performance. \n \n \n  Responsibilities: \n \n Process Analysis and Assessment: Conduct comprehensive analysis of existing business processes within the VBA Central Office. Identify areas for improvement, inefficiencies, and opportunities to enhance effectiveness and customer satisfaction. \n Process Redesign and Optimization: Collaborate with stakeholders to redesign processes, incorporating industry best practices and innovative solutions. Streamline workflows, eliminate bottlenecks, and implement process improvements to drive efficiency and productivity. \n Change Management: Develop and implement change management strategies to support process reengineering initiatives. Engage stakeholders, communicate changes effectively, and address concerns to ensure smooth implementation and adoption of new processes. \n Data Collection and Analysis: Collect and analyze data related to process performance, productivity, and customer feedback. Identify key performance indicators (KPIs) to measure process effectiveness and track progress towards improvement goals. \n Process Documentation and Standardization: Document redesigned processes, including workflows, standard operating procedures (SOPs), and process maps. Ensure clear and comprehensive documentation to guide process implementation and facilitate knowledge transfer. \n Stakeholder Engagement: Collaborate with cross-functional teams, including subject matter experts, end-users, and leadership, to gather requirements, validate process designs, and obtain buy-in for proposed changes. Foster a collaborative and inclusive approach to process reengineering. \n Training and Education: Develop training materials and conduct training sessions to educate stakeholders on new processes and associated tools. Provide ongoing support and guidance to ensure successful process implementation and adherence. \n Continuous Improvement: Establish mechanisms for ongoing monitoring, evaluation, and refinement of reengineered processes. Collect feedback, measure performance against KPIs, and identify opportunities for further optimization and innovation. \n \n \n \n  Qualifications: \n \n Must have a minimum of 5 years\u2019 proven experience in business process reengineering, process improvement, or related roles. \n Must have experience supporting Veterans Affairs, Veterans Benefits Administration (VBA). Preferably to have background in Claims, Compensation, Pension, VBMS or VBA Backend systems.  \n Understanding of Process Improvement Methodologies; Lean Six Sigma, Business Process Reengineering, Business Process Notation, Root Cause Analysis \n Bachelor\u2019s or Master\u2019s degree in one of the following disciplines is desired; Business Administration, Industrial Engineering, Operations Management, Applied Mathematics, Statistics, Supply Chain Management, Information Systems or Information Technology  \n Experience in analyzing and redesigning complex business processes in large organizations. \n Familiarity with process mapping techniques and process modeling tools. \n Solid understanding of change management principles and experience in driving organizational change. \n Strong analytical and problem-solving skills, with the ability to identify root causes and develop practical solutions. \n Excellent communication and interpersonal skills to effectively engage stakeholders at all levels of the organization. \n Understanding of government operations and experience in the healthcare industry is a plus. \n \n Transitioning military and/or Veterans with relevant experience are invited to apply. Sprezzatura is an equal opportunity employer. Sprezzatura offers benefits including healthcare, 401K, vacation, and paid sick leave. \n \n  Company Description \n  Sprezzatura Management Consulting, LLC (www.sprezzmc.com) is a Washington, DC-area Service-Disabled Veteran-Owned Small Business (SDVOSB) that enables government transformation by supplying insight and leadership at the intersection of people, processes, and technology. We apply knowledge, project, and life-cycle management best practices to catalyze change.",
        "cleaned_desc": " Familiarity with process mapping techniques and process modeling tools. \n Solid understanding of change management principles and experience in driving organizational change. \n Strong analytical and problem-solving skills, with the ability to identify root causes and develop practical solutions. \n Excellent communication and interpersonal skills to effectively engage stakeholders at all levels of the organization. \n Understanding of government operations and experience in the healthcare industry is a plus. \n ",
        "techs": [
            "process mapping techniques",
            "process modeling tools",
            "change management principles",
            "analytical skills",
            "problem-solving skills",
            "communication skills",
            "interpersonal skills",
            "government operations knowledge",
            "healthcare industry experience"
        ],
        "cleaned_techs": [
            "process mapping techniques",
            "process modeling tools",
            "change management principles",
            "government operations knowledge",
            "healthcare industry experience"
        ]
    },
    "7d5066cd6a234224": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 77578.914,
        "salary_max": 98232.195,
        "title": "Business Process Transformation / Automation ROI Analyst - Department of Veterans Affairs (VBA Central Office)",
        "company": "Sprezzatura Management Consulting",
        "desc": "Position Description: \n \n \n  Sprezzatura is seeking a skilled and experienced Business Process Transformation / Automation ROI Analyst to help improve efficiency, effectiveness, and customer service within the VBA Central Office. In this role you must demonstrate the ability to design recommendations for advancing automation initiatives, preferably in a Fed benefits environment. The candidate will demonstrate an understanding of the automation transformation decision making process by understanding, analyzing, and diagramming the nuts and bolts of the existing processes and apply this learning to create proposed redesign solutions. Then candidate must then be able to effectively articulate (written and verbal) these proposed redesign solutions, to both internal and external senior level stakeholders. It\u2019s key that the candidate have experience documenting, mapping, and redesigning business processes and procedures utilizing BPMN and be able to articulate recommendations expressed in terms of benefit to the Veteran. Candidate will contribute to the VA's mission of providing exceptional services to our nation's veterans by consistently demonstrating knowledge of process improvement methodologies and change management strategies throughout the period of performance. \n \n \n  Responsibilities: \n \n Process Analysis and Assessment: Conduct comprehensive analysis of existing business processes within the VBA Central Office. Identify areas for improvement, inefficiencies, and opportunities to enhance effectiveness and customer satisfaction. \n Process Redesign and Optimization: Collaborate with stakeholders to redesign processes, incorporating industry best practices and innovative solutions. Streamline workflows, eliminate bottlenecks, and implement process improvements to drive efficiency and productivity. \n Change Management: Develop and implement change management strategies to support process reengineering initiatives. Engage stakeholders, communicate changes effectively, and address concerns to ensure smooth implementation and adoption of new processes. \n Data Collection and Analysis: Collect and analyze data related to process performance, productivity, and customer feedback. Identify key performance indicators (KPIs) to measure process effectiveness and track progress towards improvement goals. \n Process Documentation and Standardization: Document redesigned processes, including workflows, standard operating procedures (SOPs), and process maps. Ensure clear and comprehensive documentation to guide process implementation and facilitate knowledge transfer. \n Stakeholder Engagement: Collaborate with cross-functional teams, including subject matter experts, end-users, and leadership, to gather requirements, validate process designs, and obtain buy-in for proposed changes. Foster a collaborative and inclusive approach to process reengineering. \n Training and Education: Develop training materials and conduct training sessions to educate stakeholders on new processes and associated tools. Provide ongoing support and guidance to ensure successful process implementation and adherence. \n Continuous Improvement: Establish mechanisms for ongoing monitoring, evaluation, and refinement of reengineered processes. Collect feedback, measure performance against KPIs, and identify opportunities for further optimization and innovation. \n \n \n \n  Qualifications: \n \n Must have a minimum of 2 years\u2019 proven experience in business process reengineering, process improvement, or related roles. \n Must have experience supporting Veterans Affairs, Veterans Benefits Administration (VBA). Preferably to have background in Medical Disability, Claims, Compensation, Pension, VA Digital Services, VBMS or VBA Backend systems. . \n Understanding of Process Improvement Methodologies; Lean Six Sigma, Business Process Reengineering, Business Process Notation, Root Cause Analysis \n Bachelor\u2019s or Master\u2019s degree in one of the following disciplines is desired; Business Administration, Industrial Engineering, Operations Management, Applied Mathematics, Statistics, Supply Chain Management, Information Systems or Information Technology  \n Experience in analyzing and redesigning complex business processes in large organizations. \n Familiarity with process mapping techniques and process modeling tools. \n Solid understanding of change management principles and experience in driving organizational change. \n Strong analytical and problem-solving skills, with the ability to identify root causes and develop practical solutions. \n Excellent communication and interpersonal skills to effectively engage stakeholders at all levels of the organization. \n Understanding of government operations and experience in the healthcare industry is a plus. \n \n Transitioning military and/or Veterans with relevant experience are invited to apply. Sprezzatura is an equal opportunity employer. Sprezzatura offers benefits including healthcare, 401K, vacation, and paid sick leave. \n \n  Company Description \n  Sprezzatura Management Consulting, LLC (www.sprezzmc.com) is a Washington, DC-area Service-Disabled Veteran-Owned Small Business (SDVOSB) that enables government transformation by supplying insight and leadership at the intersection of people, processes, and technology. We apply knowledge, project, and life-cycle management best practices to catalyze",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "a8a1ee45764131a4": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 69300.0,
        "salary_max": 103950.0,
        "title": "Program Analyst, Population Health",
        "company": "Gold Coast Health Plan",
        "desc": "CA salary range posted. Please note: Salary range will vary for out of state remote work. \n \n  POSITION SUMMARY \n  The Program Analyst for Population Health will be critical to the success of key clinical initiatives that support Gold Coast Health Plan\u2019s strategic vision. In this role, the Program Analyst for Population Health will work independently and be responsible for monitoring the California Department of Health Care Services (DHCS) Population Health Management (PHM) Policy Guide and ensuring compliance with PHM program requirements. Working collaboratively with the Manager of Wellness and Prevention under the direction of the Senior Manager of Population Health, this position supports the operations and evaluation of an array of PHM programs by supporting the advancement of the Model of Care and GCHP\u2019s Quality Strategy. \n  This role will work within a context of a multidisciplinary team of both internal and external stakeholders, identify opportunities to enhance Member outcomes through collaborative initiatives that address gaps in care, and strengthen Plan relations with external stakeholders at both the public health and community levels to advance health equity initiatives for the organization. These partnerships with external stakeholders include federal, state, and local levels, and are necessary to advance the organization\u2019s interests, and ongoing contracted, provider and vendor delivered programs with a focus on quality, accessibility, sustainability, and integration within GCHP. \n  ESSENTIAL FUNCTIONS \n  Reasonable Accommodations Statement \n  To accomplish this job successfully, an individual must be able to perform, with or without reasonable accommodation, each essential function satisfactorily. Reasonable accommodations may be made to help enable qualified individuals with disabilities to perform the essential functions. \n  Essential Functions Statement(s) \n  The following critical functions will be supported through this position: \n \n  Strategize, implement, and maintain program initiatives that align with the California Department of Health Care Services (DHCS) PHM Strategy, PHM Policy Guide, the DHCS Comprehensive Quality Strategy, and GCHP\u2019s Quality Strategy. \n  Responsible for working with the Quality Improvement team to ensure successful implementation of PHM National Committee for Quality Assurance (NCQA) requirements, including the clinical population needs assessment. \n  Recommend strategies to maximize effectiveness and efficiency of operational systems that support quality and population health functions. \n  Oversee participation with cross functional and external PHM related Program collaboratives, including the DHCS PHM Service Pilot. \n  Engage in efforts to obtain data on GCHP Members to support risk stratification, segmentation, and tiering for use in program planning and evaluation. \n  Work with external stakeholders to leverage provider screening/assessment data and admit, discharge, transfer data from facilities to better understand Member needs. \n  Integrate risk stratification, segmentation and tiering into establishing business priorities for programs (i.e. leverage ACG risk scores to identify members that could benefit from care management or target outreach). \n  Deploy a health risk assessment process in line with NCQA requirements to learn more about our Members with unknown risk. \n  Works closely with the Senior Manager of Population Health to: \n \n  o Implement a comprehensive PHM Monitoring plan for GCHP in line with DHCS requirements, including dashboards for monitoring KPIs and impact of wellness and prevention. \n  o Enter into MOUs with various programs and services to facilitate care coordination and information exchange. \n  o Ensure the Ventura County Community Information Exchange is being designed to facilitate referral support and data sharing between GCHP and Enhanced Care Management and Community Support providers \n  o Represent the PHM program business needs in organizational projects, such as operational readiness for the 2024 DHCS contract. \n  o Align Health Equity program goals with departmental and enterprise-wide goals. \n  o Strategize on program development and expansion. \n \n  POSITION QUALIFICATIONS \n \n  SKILLS & QUALIFICATIONS \n  The following represents the typical qualifications, skills, and knowledge necessary to be eligible for this position. \n  Education: \n \n  Bachelor's Degree (four-year college or technical school) Required, Field of Study: Nursing, Public Health, Public Administration, Health Care Administration or Related Field \n  Master's Degree Preferred, Field of Study: Nursing, Public Health, Public Administration, Health Care Administration or Related Field \n \n  Experience: \n \n  5+ plus years of experience in managed care, public health, or other clinical/medical background in healthcare that is relevant to the Medicaid population. \n  Experience in coordination, development, implementation and evaluation of data driven programs. \n  Project Management Experience \n \n  Computer Skills: \n \n  Strong knowledge of Microsoft Office software including advanced skills in Word, Excel, and Access. \n  Strong experience with Business Visualization Tools, (i.e. BI tools, PowerPoint, Visio, etc.) is preferred. \n  Experience with tele-webinar programs (i.e. Zooms or Teams) \n \n  Other Requirements: \n \n  Demonstrated relationship management skills with internal and external partners; strong client and consultant facing skills. \n  Demonstrated solution design experience: developing innovative clinical approaches to address the needs of a population. \n  Strong orientation to teamwork. \n \n  Certifications & Licenses: \n \n All licenses and certificates must be maintained as a condition of employment. \n Valid California Driver License, transportation and automobile liability insurance in limits acceptable to the Gold Coast Health Plan. Must maintain a satisfactory driving record. \n \n  Other Requirements: \n \n  Ability to utilize evidence-based practice guidelines in the evaluation and management of vendor performance for utilization management, care management and transitional care activities. \n  Ability to develop and implement projects, systems, programs, policies, and procedures. \n  Ability to act as a technical resource and explain regulations, processes, and programs related to area of assignment. \n  Ability to provide leadership and facilitate meetings. \n  Ability to analyze and interpret legal and contractual language. \n  Knowledge of the tools and techniques related to program and project management. \n  Ability to foster effective and collaborative working relationships, influence others, and build consensus with individuals at all levels in the organization \n  Ability to professionally direct and manage difficult callers or other types of challenging interactions through the utilization of interpersonal intervention skills. \n  Ability to utilize good judgment and tact when interacting with health care providers, members, and other stakeholders. \n  Ability to work independently, manage assigned workload, make decisions related to areas of functional responsibility, and recognize issues requiring escalation. \n  Ability to identify issues, conduct research, gather, and analyze information, reach logical and sound conclusions, and make recommendations for action. \n  Ability to effectively, clearly, and independently document, summarize and resolve complex issues. \n  Ability to analyze data and prepare written and oral reports.",
        "cleaned_desc": " \n  Computer Skills: \n \n  Strong knowledge of Microsoft Office software including advanced skills in Word, Excel, and Access. \n  Strong experience with Business Visualization Tools, (i.e. BI tools, PowerPoint, Visio, etc.) is preferred. \n  Experience with tele-webinar programs (i.e. Zooms or Teams) \n \n  Other Requirements: \n \n  Demonstrated relationship management skills with internal and external partners; strong client and consultant facing skills. \n  Demonstrated solution design experience: developing innovative clinical approaches to address the needs of a population. \n  Strong orientation to teamwork. \n \n  Certifications & Licenses: ",
        "techs": [
            "microsoft office software",
            "word",
            "excel",
            "access",
            "business visualization tools",
            "bi tools",
            "powerpoint",
            "visio",
            "tele-webinar programs",
            "zooms",
            "teams"
        ],
        "cleaned_techs": [
            "microsoft",
            "word",
            "excel",
            "access",
            "business visualization tools",
            "bi tools",
            "powerpoint",
            "visio",
            "tele-webinar programs",
            "zooms",
            "teams"
        ]
    },
    "8a900cde592d0c82": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Functional Analyst I, AVP & DOS (Telework Eligible)",
        "company": "Aims Community College",
        "desc": "Job Description:\n   This position is eligible for 100% remote work.\n  \n  The Functional Analyst position reports directly to the Student Technology Solutions Manager and will provide technical support for staff in the Aims2UNC; CDI; Transitions; TRiO; Testing Center; Counseling/CARE, DAS, Pathway Advising and Student Life offices in assisting in the daily functional needs to collect, develop and maintain applicable processing in the Workday and Banner student systems.\n  \n  The Functional Analyst also provides system support for the assigned functional area(s) while ensuring the technology aligns with industry, internal Aims and operational best practices. The Functional Analyst collaborates with the department directors/managers, Student Technology Solutions Manager, other analysts, and Workday functional area staff to identify business needs; help troubleshoot system and process problems that may arise while executing processes and supporting daily office operations. The Functional Analyst keeps up-to-date with evolving practices and software that will assist them in supporting these offices, providing specific support to students. And the will also assist with report development and training staff on new system processes, procedures, and products.\n  \n \n   Student Information Systems Design & Support\n  \n \n  Assist in maintaining and resolving Match and Merge processes \n  Create and upload EIBs, as needed, to support all processes \n  Review, respond, and resolve systems-related Help Desk and work with the Workday support team on issues identified as \"bugs.\" \n  Cross-train on the business processes with the Enrollment Management, Records, Pathway Advising (PA), Academic Affairs, Financial Aid, and Registration functional analysts. \n  Assess additional software needs of multiple departments and recommend software purchases and implementation. The Functional Analyst will liaise with the users and Aims IT integration team during the implementation to gather the requirements. \n  Assist AVP and DOS offices/departments with ongoing processes (manual) performed outside of the Workday student system, as needed. \n  Set up and schedule needed Engagements and dashboards in the Workday student system for any AVP and DOS areas. \n  Identify and implement software functionality as it becomes available.  Monitor daily Workday processes to ensure they align with processes in all functional areas. \n \n \n \n   Collaboration\n  \n \n  Collaborate with functional users and Information Technology Administrative Services (ITAS) to analyze the Workday student information system's functionality and other software systems that may be integrated with Workday, i.e. degree audit, CRM, etc. Identify and collaborate to develop and recommend student system changes and implement, standardize and/or enhance workflow. \n  As needed, collaborate and coordinate with other STS functional analysts to support processes that may/will impact students and supported areas. \n  Collaborate on integration testing of the Workday system as new versions and functionality are available. \n  Collaborate and coordinate with other departments to find a resolution when upgrades, patches, fixes or enhancements are needed. Work with the STS team to open and monitor requests with Workday when necessary to resolve issues and perform corrective actions as necessary. \n \n \n \n   Testing, Documentation & Training\n  \n \n  Coordinate and collaborate with the STS Manager, STS functional analysts, and Workday functional users to preview Workday release information, create testing plans, read over enhancement documentation, fixes, and changes, and test Workday releases in collaboration with functional area staff. (2x per year) \n  Remain up-to-date with all vendor-supplied documentation and provide more user-friendly system configuration, maintenance training manuals, and other documentation, as needed. \n  Attend affinity group and vendor conferences and training as assigned. (Professional Development) \n  Creation and maintenance of software training materials/job aids for other software used by Transitions Center, Pathway Advising, and Testing Center staff (examples: Calendly, Handshake, etc.). \n  Research, design, develop and enhance documentation and materials to train staff in procedures, modifications, customizations, and maintenance requirements. \n  Provide input for end-user training, as appropriate. \n \n \n \n   Reporting & Data Analysis\n  \n \n  Writes, maintains, and creates daily reports and reports as needed by offices and supported areas or requested by other functional areas, creates ad-hoc queries and reports using reporting tools (Tableau, Prism, and PL/SQL, WQL) to extract data. \n  Extract and analyze data to track students in Aims2UNC, CDI, TRIO, Transitions, Testing Center, Counseling/CARE, DAS, Pathways Advising and Student Life offices, as needed. \n  Identify patterns, trends, and correlations to aid in the ineffectiveness of these supported areas, retention programs, and student success. \n  As needed, Create dashboards and reports for offices and supported areas. \n  Communicate findings in user-friendly and easily interpreted methods. \n  Provide data collection support to the Assistant Director and Director for multiple departments, including but not limited to software impact on staff job performance, service statistics, student satisfaction, student learning, and student retention efforts. \n \n \n \n   Other Duties as Assigned\n  \n \n \n   Minimum Qualifications:\n  \n \n  Bachelor's Degree in Computer Information Systems or other related field; Plus, \n  Two (2) years of work experience with Workday, Banner or other Higher Ed ERP systems or an equivalent combination of education and/or work experience. \n  Attention to detail, problem-solving and conflict resolution capabilities. \n  Demonstrable computer proficiency with Microsoft Office programs . \n  Ability to organize tasks, set priorities and work on multiple projects simultaneously. \n  Ability to work independently with initiative and discretion. \n  Ability to work effectively with various populations in a diverse community setting. \n  Excellent verbal and written communication skills. \n  Demonstrated ability to analyze data and organize workflow logically. \n  Experience presenting information or training in small groups. \n  Ability to maintain confidentiality. \n \n \n \n   Preferred Qualifications:\n  \n \n  Experience writing SQL and reports using current industry standard report writing tools like Tableau, and Prism. \n  Knowledge of functional student services processes in higher education. \n  Knowledge of policies, procedures, and guidelines. \n  Experience testing patches, upgrade releases, documenting modifications, and recovery procedures. \n  Experience using job scheduler software tools (Automic, UC4, Appworx), or other software. \n \n \n \n   Required Documents:\n  \n \n  Cover Letter \n  Resume \n  Diversity Statement \n \n \n \n   All Applicants:\n  \n \n  Compare your previous work experience to the job duties listed on the job positing under job description. Enter the job duties you have preformed under the \"Work Experience\" section on your job application. We evaluate your experience based on this information. \n  Please make sure you state whether work experience (aka work history) is part time or full time employment by listing the average number of hours worked per week. This information is used to determine your new annual salary. \n  Be sure to upload all the required documents listed at the above in \"Additional Job Description\" section. This can be uploaded as part of your application materials in the \"My Experience\" section. If there are missing documents, your incomplete application will not be considered. \n \n \n \n   Diversity Statement Instructions\n  \n \n   Aims Community College recognizes and celebrates diversity within our students, faculty, and staff. We are committed to equity and inclusion to improve the learning experiences of all students and the working conditions of all employees.\n  \n \n \n \n     In your diversity statement, please provide your interpretation of what it means to serve a diverse community and work in an inclusive environment.\n    \n \n \n     Please include specific examples for how your background, education, and/or professional experience have prepared you to fulfill those responsibilities in this position.\n    \n \n \n     As you consider what to put in your statement, please note Aims Community College is committed to equal employment opportunity and does not discriminate on the basis of race, gender, age, or any other protected class.\n    \n \n \n \n   Aims Community College is an equal opportunity employer. Selection will be based solely on merit and will be without discrimination based on age, ancestry, color, creed, disability, ethnicity, familial status, gender, gender identity, genetic information, marital status, national origin, sex, sexual orientation, race, religion, or veteran's status. All application materials must be submitted by the closing date posted and become the property of Aims Community College. The screening committee will select finalists for interviews. The goal of Aims Community College is to enhance the diversity present in the district we serve. To comply with Immigration Reform and Control Act of 1986, if hired, you will be required to provide documents within 3 days of hire date to show your identity and your authorization to work. This law applies to all persons hired.\n  \n \n \n   Screening/Selection:\n  \n \n   In order to be considered please provide a thorough and complete application.\n    Initial screening will be conducted by a committee based on completed application materials.\n  \n \n \n   Employees in these positions may be asked to participate in temporary assignments lasting less than 6 months (such as curriculum development, short term projects, meetings and substitute duties) which could amount to additional temporary pay.\n  \n \n \n   Upon hire, all positions at Aims Community College require a criminal background check, and may require industry specific screenings such as an MVR, physical and/or drug screen. Keep in mind, a conviction does not automatically preclude candidates from being employed. The nature of a conviction will be considered relative to the duties of the position.\n  \n \n \n   If you need assistance with this process please contact Human Resources at 970-378-3720.",
        "cleaned_desc": " \n \n   Minimum Qualifications:\n  \n \n  Bachelor's Degree in Computer Information Systems or other related field; Plus, \n  Two (2) years of work experience with Workday, Banner or other Higher Ed ERP systems or an equivalent combination of education and/or work experience. \n  Attention to detail, problem-solving and conflict resolution capabilities. \n  Demonstrable computer proficiency with Microsoft Office programs . \n  Ability to organize tasks, set priorities and work on multiple projects simultaneously. \n  Ability to work independently with initiative and discretion. \n  Ability to work effectively with various populations in a diverse community setting. \n  Excellent verbal and written communication skills. \n  Demonstrated ability to analyze data and organize workflow logically. \n  Experience presenting information or training in small groups. \n  Ability to maintain confidentiality. \n \n \n \n   Preferred Qualifications:\n  \n \n  Experience writing SQL and reports using current industry standard report writing tools like Tableau, and Prism. \n  Knowledge of functional student services processes in higher education. \n  Knowledge of policies, procedures, and guidelines. \n  Experience testing patches, upgrade releases, documenting modifications, and recovery procedures. \n  Experience using job scheduler software tools (Automic, UC4, Appworx), or other software. \n \n ",
        "techs": [
            "workday",
            "banner",
            "tableau",
            "prism",
            "sql",
            "automic",
            "uc4",
            "appworx"
        ],
        "cleaned_techs": [
            "workday",
            "banner",
            "tableau",
            "prism",
            "sql",
            "automic",
            "uc4",
            "appworx"
        ]
    },
    "7fe3a78275de767a": {
        "terms": [
            "data analyst"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Business Analyst",
        "company": "Envision, LLC",
        "desc": "Envision is seeking a Business Analyst for our 4\u20136-month remote role in Jefferson City, MO. \n \n  NO C2C OR THIRD PARTIES ALLOWED \n \n  Project Summary \n \n  The project can be summarized as collections of reports and public information for statewide district grading on performance and accreditation recommendations to the State Board of Education. \n \n  Top Skills \n \n \n \n Ability to elicit and clearly document and update requirements, minimum of five years of experience. \n Experience writing test cases and scenarios, performing testing, and documenting results. \n Knowledge of creating and updating specification documentation. \n Familiar with ADO (Azure DevOps) and working with tickets. \n Provide accurate updates in the tickets being worked. \n \n Nice to Have: \n \n \n Ability to create and run simple SQL queries. \n \n Additional details: \n \n \n Must have the ability to research data concerns and work effectively in a team environment between technical and non-technical resources.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "e13283e14347bc2b": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 40.0,
        "salary_max": 50.0,
        "title": "Data Analyst",
        "company": "Kforce",
        "desc": "RESPONSIBILITIES: \n  Kforce has a client looking for a fully remote technical Data Analyst to recognize trends and ultimate improve delivery times. This person will be responsible for writing complex SQL queries from scratch and will be visualizing and presenting the data via Tableau. \n \n \n REQUIREMENTS: \n \n \n Ability to write complex SQL queries from scratch \n Ability to build datasets/models \n Proficient with Tableau \n Time Management \n Strong communication \n Ability to work well with other teams \n  The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. \n \n  We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. \n \n \n Note:  Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. \n \n  This job is not eligible for bonuses, incentives or commissions. \n \n  Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "0f6006341834d61c": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 27.0,
        "salary_max": 27.0,
        "title": "Billing Analyst (Remote)",
        "company": "ALTA IT Services",
        "desc": "ALTA IT Services is staffing a 12+month contract opportunity for a Billing Analyst to support a leading health insurance customer. The individual is responsible for maintaining admin rates, preparing and delivering invoices to bring in revenue for the organization. This includes establishing and managing the accuracy and efficiency of the established process as well as identifying and resolving data and setup issues as it relates to internal billing systems. The incumbent is also responsible for remitting payment to client vendors within proper timeframes to ensure late fees are not charged. Pay: $27/HR 12-month Contract 100% Remote Vaccination Required ESSENTIAL FUNCTIONS: Compiles, validates, and supports financial data. Maintains comprehensive Excel spreadsheets for cash application and reconciliation to daily bank statements to ensure the bank and internal financial systems are in sync. Analyzes data to ensure that the rates are accurate, mapping of fields correspond to internal financial systems. Establishes and maintains relationships with Points of Contact (POC) at account and vendor levels. Supports external audit requests when required. \n \n \n ALTA IT Services is staffing a 12+month contract opportunity for a Billing Analyst to support a leading health insurance customer. The individual is responsible for maintaining admin rates, preparing and delivering invoices to bring in revenue for the organization. This includes establishing and managing the accuracy and efficiency of the established process as well as identifying and resolving data and setup issues as it relates to internal billing systems. The incumbent is also responsible for remitting payment to client vendors within proper timeframes to ensure late fees are not charged. \n  \n \n Pay: $27/HR \n \n 12-month Contract  \n \n 100% Remote  \n \n Vaccination Required  \n \n  ESSENTIAL FUNCTIONS: \n  \n \n Compiles, validates, and supports financial data.  \n Maintains comprehensive Excel spreadsheets for cash application and reconciliation to daily bank statements to ensure the bank and internal financial systems are in sync.  \n Analyzes data to ensure that the rates are accurate, mapping of fields correspond to internal financial systems.  \n Establishes and maintains relationships with Points of Contact (POC) at account and vendor levels.  \n Supports external audit requests when required.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "28f60426c996287f": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 51000.0,
        "salary_max": 91000.0,
        "title": "Business Analyst",
        "company": "Ascendion",
        "desc": "Description \n About Ascendion \n  Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. \n  Ascendion | Engineering to elevate life \n  We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us: \n \n Build the coolest tech for world\u2019s leading brands \n Solve complex problems \u2013 and learn new skill \n Experience the power of transforming digital engineering for Fortune 500 clients \n Master your craft with leading training programs and hands-on experience \n \n Experience a community of change makers! \n  Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion. \n  About the Role: \n  Job Title:  Business Process Analyst/IT Service Management/ServiceNow Admin \n  Key Responsibilities: \n \n Ascendion is looking for a business analyst to turn down a company-owned device project. \n The role will be working on a ServiceNow analysis and mobi-lity focus. This person will develop short-term processes for the analysis of mobi-lity provisioning stages \n \n \n \n  Must Haves: \n \n 2 years of business process analysis or data analysis \n 2 - 4 years of experience in IT service management or ServiceNow toolset \n \n Should understand the provisioning process with ServiceNow \n Experience with requesting tooling \n \n Strong experience with MS-suite \n \n SharePoint \n Excel \n \n Must understand client portals and inventory management \n Great communicator \n Great experience with process documentation \n Experience with business mobi-lity portal and inventory management \n \n \n \n  Location:  Remote \n \n \n  Salary Range:  The salary for this position is between $51,000 \u2013 $91,000 annually. Factors which may affect pay within this range may include geography/market, skill, education, experience, and other qualifications of the successful candidate. \n  Benefits:  The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day of paid vacation time] [6 paid holiday and 1 floating holiday per calendar year] [Ascendion Learning Management System] \n \n \n  Want to change the world? Let us know. \n  Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let\u2019s talk! \n \n \n Preferred Skills: \n \n ServiceNow \n  Service Management \n  Process Documentation \n  IT Service Management \n  Sharepoint \n  Excel \n  Mobil-ity Provisioning \n \n Job details \n \n \n Job ID \n \n \n   328572\n   \n \n \n \n Job Requirements \n \n \n   Business Analyst\n   \n \n \n \n \n Location \n \n \n   Tampa, Florida, US\n   \n \n \n \n \n Recruiter \n \n \n   Adarsh\n   \n \n \n \n Email \n \n \n   adarsh.singh@ascendion.com",
        "cleaned_desc": " \n \n  Must Haves: \n \n 2 years of business process analysis or data analysis \n 2 - 4 years of experience in IT service management or ServiceNow toolset \n \n Should understand the provisioning process with ServiceNow \n Experience with requesting tooling \n \n Strong experience with MS-suite \n \n SharePoint \n Excel \n \n Must understand client portals and inventory management \n Great communicator \n Great experience with process documentation \n Experience with business mobi-lity portal and inventory management \n ",
        "techs": [
            "servicenow",
            "sharepoint",
            "excel"
        ],
        "cleaned_techs": [
            "servicenow",
            "sharepoint",
            "excel"
        ]
    },
    "5458549b3e2b48af": {
        "terms": [
            "data analyst"
        ],
        "salary_min": 27.0,
        "salary_max": 27.0,
        "title": "Data Analyst",
        "company": "TotalMed Medfi",
        "desc": "Pay:  $27 per hour \n Hours:  Monday - Friday 8:00 am - 5:00 pm \n Position Details: \n \n Create/utilize reporting to analyze key data elements to identify trends, \u201cbad data\u201d or missing data points that will drive overall data quality and accuracy \n Utilize existing AzCH applications to remediate data errors and drive consistency and the quality of the data \n Ensure data accuracy for lines of business to drive an excellent member experience for our health plan and to facilitate the accurate on-time payments on claims \n Position utilizes large data sets in excel spreadsheets that require the ability to utilize strong excel skills for creating pivot tables, VLOOKUPs, and excel formulas. Attention to detail and solid analytical skills are essential. \n Position requires outstanding communication skills (verbal and written) in collaboration and correspondences to internal and external customers and departments. \n Position requires flexing to changing deadlines and business needs \n Position requires attention to detail for reporting deliverable to the state and to regulators \n \n Position Requirements: \n \n Intermediate Excel skills (pivot tables, sort, filter, VLOOKUP at a minimum) \n 2+ years Data analysis (review and analyze especially large data sets/large spreadsheets) \n Healthcare Background \n \n #INDAS \n Job Type: Full-time \n Pay: $27.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Vlookup: 1 year (Required) \n \n Work Location: Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "7682ff45abc857ca": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 50.0,
        "salary_max": 55.0,
        "title": "Data Engineer II",
        "company": "ITgen systems",
        "desc": "Position:  Data Engineer II (Mid-Senior Level) \n Location:  Remote \n Duration:  4-6 months CTH \n Job Description : \n \n Expert at Python and SQL experience is a must \n Must haves in the cloud space ( preferred azure, snowflake) \n Hive/spark. \n Data modeling and architecture. (no architect people) hands on engineer. \n \n Job Type: Contract \n Salary: $50.00 - $55.00 per hour \n Experience: \n \n Data Engineer: 7 years (Required) \n Data modeling: 5 years (Required) \n Data warehouse: 3 years (Required) \n Azure: 4 years (Required) \n Snowflake: 4 years (Required) \n Python: 5 years (Required) \n SQL: 4 years (Required) \n Hive/spark: 5 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " \n Expert at Python and SQL experience is a must \n Must haves in the cloud space ( preferred azure, snowflake) \n Hive/spark. ",
        "techs": [
            "python",
            "sql",
            "azure",
            "snowflake",
            "hive",
            "spark"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "azure",
            "snowflake",
            "hive",
            "spark"
        ]
    },
    "e6cfa3bc47e047b6": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 113068.48,
        "salary_max": 143169.89,
        "title": "Data Engineer",
        "company": "Arva Intelligence",
        "desc": "Software Data Engineer \n  We are looking for a Software Data Engineer to join our green tech startup team to help us find big-data-sets and develop the ETL technology used to clean, transform, and load data-sets to train machine learning models. As a Software Data Engineer, you will be responsible for designing and implementing ETL processes and tools and ensuring the quality and governance of the data. You will work with various stakeholders, including data scientists, sales, customer support, and other developers, to optimize large data-set pipelines and develop solutions for Agronomic data-set ingestion for Farm, Ranch and Forest. \n  Key Responsibilities \n \n Develop a strong understanding of ETL processes and tools, including Extract, Transform, and Load processes and the tools used for ETL. \n Develop and use big data indexing solutions, including data storage and retrieval solutions, such as AWS Glue, AWS Data Pipeline, Apache Spark, Apache Kafka, Amazon S3, Amazon Redshift, Amazon EMR, and Amazon Athena. \n Utilize programming skills in languages such as Python, Django, JavaScript, NodeJS, Scripting, and SQL, including experience in geospatial databases solutions and tools for DB development in PostgreSQL and PostGIS. \n Ensure data quality and governance by implementing data cleaning, error correction, validation, unit tests, and verification processes. \n Develop and optimize large data-set pipelines, including cache memory, storage systems, and large data-set processing solutions. \n Develop solutions for Agronomic data-set ingestion for Farm, Ranch and Forest such as boundary files, soil, planting, yield, fertilizer, and other soil strata applications. \n Collaborate and communicate effectively with various stakeholders, data scientists, sales, customer support, and other developers. \n Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. \n Minimum of 3-5 years of experience in software development, with a focus on ETL processes and big data technologies. \n Strong programming skills in languages such as Python, Django, JavaScript, NodeJS, Scripting, and SQL. \n Experience in geospatial databases solutions and tools for DB development in PostgreSQL and PostGIS. \n Familiarity with big data indexing solutions, including data storage and retrieval solutions such as AWS Glue, AWS Data Pipeline, Apache Spark, Apache Kafka, Amazon S3, Amazon Redshift, Amazon EMR, and Amazon Athena. \n Experience in developing solutions for Agronomic data-set ingestion for Farm, Ranch and Forest such as boundary files, soil, planting, yield, fertilizer, and other soil strata applications. \n Strong understanding of ETL processes and tools, including Extract, Transform, and Load processes and the tools used for ETL. \n Excellent communication and collaboration skills to work with various stakeholders, data scientists, sales, customer support, and other developers. \n \n Benefits \n  At Arva Intelligence, we are committed to providing our employees a comprehensive benefits package designed to support your well-being, both personally and professionally. Our benefits include company paid medical insurance for you and your family, as well as dental, vision and disability insurance options, 401k retirement plan with matching contributions, flexible paid time off, and an employee assistance program (EAP). \n \n  Employment Eligibility \n  Only applicants currently eligible to work in the United States will be considered for this position. \n \n  About Arva Intelligence \n  Arva is a machine learning software-based SaaS company with offices located in Houston, TX and Park City, UT. Arva's application platform was built to apply our novel ML technology to the agricultural industry, optimizing and measuring regenerative practices, improving crop yields, and reducing operational costs for farms, ranches, and forestry. Our models predict precisely what types and amounts of nutrients, including hybrid/genetic seeds and other biological/microbial products, should be applied to improve crop land sustainability and soil health. In addition, our platform helps our customers and partners capitalize on \"natural regenerative practices\" by providing recommendations that improve environmental and ecological ecosystems. Platform features include practice verification and registration, as well as the sale of inset and offset credits to our corporate buyers. Thus, Arva is helping to keep the planet green by providing a \"green-tech\" platform that informs, measures, validates, predicts, and registers carbon exchange opportunities, allowing growers and ranchers to produce and sell credits that are bought by our corporate partners, who endorse sustainable food supply and carbon neutrality. \n  If you are a self-motivated individual with a passion for building and supporting cloud-based applications, and are excited to work in a dynamic startup environment, we would love to hear from you.",
        "cleaned_desc": "Software Data Engineer \n  We are looking for a Software Data Engineer to join our green tech startup team to help us find big-data-sets and develop the ETL technology used to clean, transform, and load data-sets to train machine learning models. As a Software Data Engineer, you will be responsible for designing and implementing ETL processes and tools and ensuring the quality and governance of the data. You will work with various stakeholders, including data scientists, sales, customer support, and other developers, to optimize large data-set pipelines and develop solutions for Agronomic data-set ingestion for Farm, Ranch and Forest. \n  Key Responsibilities \n \n Develop a strong understanding of ETL processes and tools, including Extract, Transform, and Load processes and the tools used for ETL.   Develop and use big data indexing solutions, including data storage and retrieval solutions, such as AWS Glue, AWS Data Pipeline, Apache Spark, Apache Kafka, Amazon S3, Amazon Redshift, Amazon EMR, and Amazon Athena. \n Utilize programming skills in languages such as Python, Django, JavaScript, NodeJS, Scripting, and SQL, including experience in geospatial databases solutions and tools for DB development in PostgreSQL and PostGIS. \n Ensure data quality and governance by implementing data cleaning, error correction, validation, unit tests, and verification processes. \n Develop and optimize large data-set pipelines, including cache memory, storage systems, and large data-set processing solutions. \n Develop solutions for Agronomic data-set ingestion for Farm, Ranch and Forest such as boundary files, soil, planting, yield, fertilizer, and other soil strata applications.   Collaborate and communicate effectively with various stakeholders, data scientists, sales, customer support, and other developers. \n Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field. \n Minimum of 3-5 years of experience in software development, with a focus on ETL processes and big data technologies. \n Strong programming skills in languages such as Python, Django, JavaScript, NodeJS, Scripting, and SQL. \n Experience in geospatial databases solutions and tools for DB development in PostgreSQL and PostGIS.   Familiarity with big data indexing solutions, including data storage and retrieval solutions such as AWS Glue, AWS Data Pipeline, Apache Spark, Apache Kafka, Amazon S3, Amazon Redshift, Amazon EMR, and Amazon Athena. \n Experience in developing solutions for Agronomic data-set ingestion for Farm, Ranch and Forest such as boundary files, soil, planting, yield, fertilizer, and other soil strata applications. \n Strong understanding of ETL processes and tools, including Extract, Transform, and Load processes and the tools used for ETL. \n Excellent communication and collaboration skills to work with various stakeholders, data scientists, sales, customer support, and other developers. \n ",
        "techs": [
            "aws glue",
            "aws data pipeline",
            "apache spark",
            "apache kafka",
            "amazon s3",
            "amazon redshift",
            "amazon emr",
            "amazon athena",
            "python",
            "django",
            "javascript",
            "nodejs",
            "scripting",
            "sql",
            "postgresql",
            "postgis"
        ],
        "cleaned_techs": [
            "aws",
            "apache spark",
            "apache kafka",
            "python",
            "django",
            "javascript",
            "nodejs",
            "scripting",
            "sql",
            "postgresql",
            "postgis"
        ]
    },
    "9dc43cbbaf62cfaa": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 123347.0,
        "salary_max": 156184.78,
        "title": "Data Engineer 4724",
        "company": "MetroStar",
        "desc": "Data Engineer \n  Remote \n  As  Data Engineer , you'll take a leadership role in architecting, building, and optimizing our data pipelines, data warehouses, and data lakes. Your deep technical expertise and extensive experience will drive the development of scalable, efficient, and reliable data solutions that empower our analytics and business intelligence initiatives. You will collaborate closely with cross-functional teams including data scientists, analysts, and software engineers to ensure our data ecosystem meets both current and future requirements. \n  We know that you can't have great technology services without amazing people. At MetroStar, we are  obsessed  with   our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers. \n  If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below! \n  What you'll do: \n \n Lead the design and implementation of complex, end-to-end data pipelines to collect, process, and transform data from various sources into usable formats. \n Develop and maintain ETL/ELT processes to ensure data integrity, accuracy, and availability for downstream applications. \n Collaborate with data scientists and analysts to understand data requirements and assist in the creation of data models, dashboards, and visualizations. \n Optimize data infrastructure for performance, scalability, and cost-effectiveness, making use of both traditional relational databases and modern big data technologies. \n Ensure data security and compliance with relevant data protection regulations throughout the data lifecycle. \n Identify and resolve data-related issues, troubleshoot performance bottlenecks, and provide timely support to maintain data operations. \n Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous learning. \n \n What you'll need to succeed: \n \n Bachelor's or Master's degree in Computer Science, Information Technology, or a related field. \n Minimum of 8 years of professional experience in data engineering, with a proven track record of designing and implementing robust data solutions. \n Expertise in building and maintaining data pipelines using tools such as Talend. \n Experience implementing data integration within tools such as Pentaho. \n Strong programming skills in languages such as Python, Java, Scala, or SQL for data processing and manipulation. \n Proficiency in working with CI/CD (e.g. Jenkins) and containerization technologies (e.g., Docker, Kubernetes) to deploy data platforms such as Talend and Pentaho. \n Experience with data warehousing solutions and data modeling concepts. \n Familiarity with version control systems (e.g., Git) and collaborative development practices. \n Excellent problem-solving skills and the ability to tackle complex technical challenges. \n Strong communication skills to collaborate effectively with cross-functional teams and present technical concepts to non-technical stakeholders. \n \n Like we said,  we are  big fans of our people. That's why  we offer  a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades. \n  Don't meet every single requirement?  \n Studies have shown that women, people of color and the LGBTQ+ community are less likely to apply to jobs unless they meet every single qualification. At MetroStar we are dedicated to building a diverse, inclusive, and authentic culture, so, if you're excited about this role, but your previous experience doesn't align perfectly with every qualification in the job description, we encourage you to go ahead and apply. We pride ourselves on making great matches, and you may be the perfect match for this role or another one we have. Best of luck! \u2013 The MetroStar People & Culture Team \n  What we want you to know: \n  In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. \n  MetroStar Systems is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of MetroStar Systems. \n  Not ready to apply now? \n  Sign up to join our newsletter here.",
        "cleaned_desc": " Lead the design and implementation of complex, end-to-end data pipelines to collect, process, and transform data from various sources into usable formats. \n Develop and maintain ETL/ELT processes to ensure data integrity, accuracy, and availability for downstream applications. \n Collaborate with data scientists and analysts to understand data requirements and assist in the creation of data models, dashboards, and visualizations. \n Optimize data infrastructure for performance, scalability, and cost-effectiveness, making use of both traditional relational databases and modern big data technologies. \n Ensure data security and compliance with relevant data protection regulations throughout the data lifecycle. \n Identify and resolve data-related issues, troubleshoot performance bottlenecks, and provide timely support to maintain data operations. \n Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous learning.   \n What you'll need to succeed: \n \n Bachelor's or Master's degree in Computer Science, Information Technology, or a related field. \n Minimum of 8 years of professional experience in data engineering, with a proven track record of designing and implementing robust data solutions. \n Expertise in building and maintaining data pipelines using tools such as Talend. \n Experience implementing data integration within tools such as Pentaho.   Strong programming skills in languages such as Python, Java, Scala, or SQL for data processing and manipulation. \n Proficiency in working with CI/CD (e.g. Jenkins) and containerization technologies (e.g., Docker, Kubernetes) to deploy data platforms such as Talend and Pentaho. \n Experience with data warehousing solutions and data modeling concepts. \n Familiarity with version control systems (e.g., Git) and collaborative development practices. \n Excellent problem-solving skills and the ability to tackle complex technical challenges. \n Strong communication skills to collaborate effectively with cross-functional teams and present technical concepts to non-technical stakeholders. \n ",
        "techs": [
            "talend",
            "pentaho",
            "python",
            "java",
            "scala",
            "sql",
            "jenkins",
            "docker",
            "kubernetes",
            "git"
        ],
        "cleaned_techs": [
            "talend",
            "pentaho",
            "python",
            "java",
            "scala",
            "sql",
            "jenkins",
            "docker",
            "kubernetes",
            "git"
        ]
    },
    "96da202e654fb30f": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 100000.0,
        "salary_max": 154000.0,
        "title": "Data Operations Engineer",
        "company": "Moen",
        "desc": "Company Description \n \n \n At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work.  \n Learn more about our culture here. \n \n \n Job Description \n \n  We are seeking a talented Data Integration Engineer to join our newly established Data and Analytics organization within the Data Engineering team under Data Platforms. As a key member of our dynamic team, you will play a crucial role in advancing our data transformation and integration initiatives across a variety of ERPs, including SAP, Oracle E-Business Suite (EBS), Oracle JD Edwards (JDE), SQL Server, and others. If you're passionate about solving complex technical challenges, collaborating with cross-functional teams, and contributing to cutting-edge data solutions, this role is perfect for you.\n  \n  Enjoy \n  remote work  with the option to engage at our North Olmsted office. This role offers career growth and leadership opportunities.\n  \n \n RESPONSIBLIITIES: \n \n \n What you will be doing \n \n \n  Drive Innovative Data Integration:  Collaborate within a small yet diverse team to lead the migration of data from multiple ERPs and SQL Server, utilizing Extract and Load tools. Leverage your technical expertise to ensure seamless data movement and integration. \n  Maintain and Enhance Legacy Systems:  Utilize your expertise to work with existing legacy systems and reports. Engage in reverse engineering to understand and improve these systems incrementally, applying your technical acumen to patch, optimize functionality, and migrate data pipelines to the Modern Data Platform (MDP). \n  Clean Programming, Self-Documenting Code, Version Control, and CI/CD:  Adhere to clean programming skills and self-documenting code practices, while utilizing GIT version control for codebase management and contributing to automation through CI/CD pipelines for streamlined deployments. \n  Cross-functional Collaboration, Problem-Solving, and Teamwork:  Collaborate closely with both on-shore and offshore team members, stakeholders across the country and world, fostering teamwork, a 'we got this' mentality, and effective technical problem-solving. \n  Orchestrate and Enhance Processes:  Contribute to the continuous improvement of data integration processes, orchestrating workflows optimal efficiency and reliability.   \n \n \n  Hiring Pay Range: $100,000 - $154,000\n  \n \n \n Actual pay will vary based on qualifications and other factors \n \n \n  Qualifications \n \n \n QUALIFICATIONS:  \n \n \n BASIC QUALIFICATIONS:   \n \n \n \n Experience:  5+ years of experience working with data integration and transformation, including a strong understanding of SQL for data querying and manipulation. \n  Technical Proficiency and Problem-Solving:  Deep understanding of data integration tools and methods, coupled with a proven ability to troubleshoot complex technical challenges. \n  Communication and Agile Experience:  Excellent communication skills for translating technical concepts to non-technical stakeholders, with comfort in Agile methodologies and project management tools. \n \n \n  PREFERRED QUALIFICATIONS: \n \n \n  Education:  Bachelor's degree in Computer Information Systems, Computer Science, or related field. \n  Cloud Data Warehousing Exposure:  Experience with Snowflake or comparable cloud based data systems and tools. \n  Source Systems:  Exposure to multiple ERPs, especially SAP, Oracle EBS, Oracle JDE, and others. \n  SQL Expertise:  Proficiency in SQL, especially in managing data systems. \n  Clean Programming Skills:  Strong adherence to clean programming practices, producing self-documenting code using coding best practices. \n \n \n  Very Nice to Have: \n \n \n  Experience in SAP BW, ABAP programming, SAP BPC (Business Planning and Consolidation), and/or Oracle BI (Business Intelligence) for data visualization and reporting. \n  Proficiency in GIT version control for codebase management, coupled with experience in automation through CI/CD pipelines. \n  Proficiency in Python, especially in implementing and orchestrating data integrations. \n \n  Join us in this exciting role to shape the future of our data integration initiatives, improve processes, and drive impactful results. Your expertise will contribute to the success of our growing Data and Analytics organization.\n  \n \n Additional Information \n \n \n Company Description: \n \n  At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here\n  \n \n At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates\u2019 unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates\u2019 feeling of belonging at work. \n \n  Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more\n  \n \n Equal Employment Opportunity \n \n  FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.\n  \n \n Reasonable Accommodations \n \n  FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.",
        "cleaned_desc": " What you will be doing \n \n \n  Drive Innovative Data Integration:  Collaborate within a small yet diverse team to lead the migration of data from multiple ERPs and SQL Server, utilizing Extract and Load tools. Leverage your technical expertise to ensure seamless data movement and integration. \n  Maintain and Enhance Legacy Systems:  Utilize your expertise to work with existing legacy systems and reports. Engage in reverse engineering to understand and improve these systems incrementally, applying your technical acumen to patch, optimize functionality, and migrate data pipelines to the Modern Data Platform (MDP). \n  Clean Programming, Self-Documenting Code, Version Control, and CI/CD:  Adhere to clean programming skills and self-documenting code practices, while utilizing GIT version control for codebase management and contributing to automation through CI/CD pipelines for streamlined deployments. \n  Cross-functional Collaboration, Problem-Solving, and Teamwork:  Collaborate closely with both on-shore and offshore team members, stakeholders across the country and world, fostering teamwork, a 'we got this' mentality, and effective technical problem-solving. \n  Orchestrate and Enhance Processes:  Contribute to the continuous improvement of data integration processes, orchestrating workflows optimal efficiency and reliability.   \n \n \n  Hiring Pay Range: $100,000 - $154,000\n  \n \n \n Actual pay will vary based on qualifications and other factors \n \n \n  Qualifications   \n \n QUALIFICATIONS:  \n \n \n BASIC QUALIFICATIONS:   \n \n \n \n Experience:  5+ years of experience working with data integration and transformation, including a strong understanding of SQL for data querying and manipulation. \n  Technical Proficiency and Problem-Solving:  Deep understanding of data integration tools and methods, coupled with a proven ability to troubleshoot complex technical challenges. \n  Communication and Agile Experience:  Excellent communication skills for translating technical concepts to non-technical stakeholders, with comfort in Agile methodologies and project management tools. \n \n \n  PREFERRED QUALIFICATIONS: \n \n \n  Education:  Bachelor's degree in Computer Information Systems, Computer Science, or related field.    Cloud Data Warehousing Exposure:  Experience with Snowflake or comparable cloud based data systems and tools. \n  Source Systems:  Exposure to multiple ERPs, especially SAP, Oracle EBS, Oracle JDE, and others. \n  SQL Expertise:  Proficiency in SQL, especially in managing data systems. \n  Clean Programming Skills:  Strong adherence to clean programming practices, producing self-documenting code using coding best practices. \n \n \n  Very Nice to Have: \n \n \n  Experience in SAP BW, ABAP programming, SAP BPC (Business Planning and Consolidation), and/or Oracle BI (Business Intelligence) for data visualization and reporting. \n  Proficiency in GIT version control for codebase management, coupled with experience in automation through CI/CD pipelines. \n  Proficiency in Python, especially in implementing and orchestrating data integrations. \n \n  Join us in this exciting role to shape the future of our data integration initiatives, improve processes, and drive impactful results. Your expertise will contribute to the success of our growing Data and Analytics organization.\n  \n \n Additional Information \n ",
        "techs": [
            "extract and load tools",
            "modern data platform (mdp)",
            "git version control",
            "ci/cd pipelines",
            "sql",
            "snowflake",
            "sap",
            "oracle ebs",
            "oracle jde",
            "sap bw",
            "abap programming",
            "sap bpc",
            "oracle bi",
            "python"
        ],
        "cleaned_techs": [
            "extract and load tools",
            "modern data platform (mdp)",
            "git version control",
            "ci/cd pipelines",
            "sql",
            "snowflake",
            "sap",
            "oracle",
            "sap bw",
            "abap programming",
            "sap bpc",
            "python"
        ]
    },
    "759982dce0af3528": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 132378.11,
        "salary_max": 159423.1,
        "title": "Senior Data Engineer",
        "company": "Wallero",
        "desc": "Job Title:  Senior Data Engineer \n Location:  Seattle Area \n Job Description: \n We are seeking a highly skilled and motivated Senior Data Engineer to join our dynamic team in the Seattle area. As a Senior Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure. If you have a passion for data engineering and possess expertise in Azure, Snowflake, and ADF (Azure Data Factory), we encourage you to apply. \n Key Responsibilities: \n Data Pipeline Development:  Design, develop, and maintain efficient data pipelines using Azure Data Factory (ADF) to move, transform, and load data. \n Data Warehouse Management:  Collaborate with the team to manage data warehousing solutions, including Snowflake, ensuring data accuracy, availability, and performance. \n ETL Processes:  Create and optimize ETL (Extract, Transform, Load) processes to support data integration from various sources into our data platform. \n Data Modeling:  Implement data models that align with business requirements and optimize query performance. \n Data Quality:  Ensure data quality and consistency through data cleansing, validation, and data profiling. \n Monitoring and Optimization:  Monitor system performance, identify bottlenecks, and optimize data pipelines and workflows for efficiency. \n Documentation:  Maintain comprehensive documentation of data engineering processes, data flows, and transformations. \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field (Master's preferred). \n Proven experience as a Data Engineer, with a focus on Azure, Snowflake, and ADF. \n Strong expertise in data pipeline development, ETL processes, and data warehousing. \n Proficiency in SQL, data modeling, and database design. \n Familiarity with data integration, data governance, and data security best practices. \n Excellent problem-solving skills and attention to detail. \n Strong communication and collaboration abilities. \n \n Job Type: Contract \n Salary: $132,378.11 - $159,423.09 per year \n Experience level: \n \n 10 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Data engineer: 10 years (Required) \n Spark: 8 years (Required) \n Azure Data Lake: 8 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": " ETL Processes:  Create and optimize ETL (Extract, Transform, Load) processes to support data integration from various sources into our data platform. \n Data Modeling:  Implement data models that align with business requirements and optimize query performance. \n Data Quality:  Ensure data quality and consistency through data cleansing, validation, and data profiling. \n Monitoring and Optimization:  Monitor system performance, identify bottlenecks, and optimize data pipelines and workflows for efficiency. \n Documentation:  Maintain comprehensive documentation of data engineering processes, data flows, and transformations. \n Qualifications: \n   Bachelor's degree in Computer Science, Information Technology, or a related field (Master's preferred). \n Proven experience as a Data Engineer, with a focus on Azure, Snowflake, and ADF. \n Strong expertise in data pipeline development, ETL processes, and data warehousing. \n Proficiency in SQL, data modeling, and database design. \n Familiarity with data integration, data governance, and data security best practices. \n Excellent problem-solving skills and attention to detail. \n Strong communication and collaboration abilities. ",
        "techs": [
            "etl processes",
            "data modeling",
            "data quality",
            "monitoring and optimization",
            "documentation",
            "azure",
            "snowflake",
            "adf",
            "sql",
            "data warehousing",
            "data integration",
            "data governance",
            "data security"
        ],
        "cleaned_techs": [
            "etl processes",
            "data quality",
            "monitoring and optimization",
            "azure",
            "snowflake",
            "adf",
            "sql",
            "data warehousing",
            "data integration",
            "data governance"
        ]
    },
    "f15de85d03a1aa41": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 52.0,
        "salary_max": 52.0,
        "title": "Quantitative Data Engineer",
        "company": "Ora Apps",
        "desc": "Job Title: Quantitative Data Engineer \n Location: Remote \n Duration: Long Term \n Rate: $52/hr. on W2 All Inclusive \n What We\u2019re Looking For: \n \n Bachelor/Master\u2019s degree in Computer Science, Information Systems, or related field \n Strong analytical, data and programming skills (Python/SQL/NoSQL/JavaScript) \n 3+years of experience with large data sets ETL and techniques to architect them for performance, experience using alternative unstructured data is a plus \n 1+ year of experience with cloud computing services, AWS preferred \n Aptitude for designing infrastructure, and data products for Quant/Data Scientists is a plus \n Ability to work effectively in an agile environment with numerous stakeholders on complex research and new development projects \n A genuine interest in investment strategies, equities, and fixed income. Asset management industry experience is a plus. \n Strong verbal and written communication skill, must be a team player \n \n Job Type: Full-time \n Salary: $52.00 per hour \n Compensation package: \n \n 1099 contract \n \n Experience level: \n \n 5 years \n 6 years \n \n Schedule: \n \n 8 hour shift \n \n Experience: \n \n Quantitative Data Engineer: 5 years (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Bachelor/Master\u2019s degree in Computer Science, Information Systems, or related field \n Strong analytical, data and programming skills (Python/SQL/NoSQL/JavaScript) \n 3+years of experience with large data sets ETL and techniques to architect them for performance, experience using alternative unstructured data is a plus \n 1+ year of experience with cloud computing services, AWS preferred \n Aptitude for designing infrastructure, and data products for Quant/Data Scientists is a plus \n Ability to work effectively in an agile environment with numerous stakeholders on complex research and new development projects ",
        "techs": [
            "python",
            "sql",
            "nosql",
            "javascript",
            "aws"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "nosql",
            "javascript",
            "aws"
        ]
    },
    "cb9841d0eead198d": {
        "terms": [
            "data engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Sr. Data Engineer",
        "company": "Pomeroy",
        "desc": "Pomeroy is seeking a Senior Data Engineer to work for one of our clients on a contract basis for a 6 month project with the possibility of extension. This is a fully remote role however you must be in the eastern standard time zone. \n Note: W2 employment only. No C2C options available. Must be legally authorized to work in the United States without sponsorship now or in the future. \n Key Responsibilities: \n \n Design, develop, and deploy robust and scalable data solutions using AWS data analytics services, with a focus on Redshift. \n Collaborate with data scientists, analysts, and stakeholders to understand data requirements and translate them into effective ETL processes and reporting solutions. \n Create and maintain data pipelines, ensuring data quality, reliability, and performance. \n Develop and maintain Python routines/scripts to support ETL processes, data transformation, and reporting needs. \n Optimize and fine-tune existing data infrastructure to ensure efficient query performance and cost-effectiveness. \n Perform database design and optimization, including schema design and indexing, to support evolving business needs. \n Mentor and provide guidance to junior data engineers in best practices for data engineering, AWS, and Python development. \n Stay up-to-date with industry trends, emerging technologies, and best practices in data engineering and analytics. \n \n Qualifications: \n \n Senior Engineer with 7+ yrs of Exp in AWS , Redshift and Database design, dev, deploy in reporting & ETL space \n Design, Build and operationalize the enterprise data solutions and applications using AWS data analytics with Redshift and Python. \n Experience in design and also hands on development of Python routines/scrip \n \n Job Types: Full-time, Contract \n Pay: $38.00 - $40.00 per hour \n Experience level: \n \n 7 years \n \n Application Question(s): \n \n Are you a vendor or looking for a C2C role? If yes, please leave employer information. If no please write No. Any other answer will result in auto rejection. \n \n Experience: \n \n AWS: 7 years (Required) \n Redshift: 7 years (Required) \n Database design: 7 years (Required) \n Database development: 7 years (Required) \n ETL: 7 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Pomeroy is seeking a Senior Data Engineer to work for one of our clients on a contract basis for a 6 month project with the possibility of extension. This is a fully remote role however you must be in the eastern standard time zone. \n Note: W2 employment only. No C2C options available. Must be legally authorized to work in the United States without sponsorship now or in the future. \n Key Responsibilities: \n \n Design, develop, and deploy robust and scalable data solutions using AWS data analytics services, with a focus on Redshift. \n Collaborate with data scientists, analysts, and stakeholders to understand data requirements and translate them into effective ETL processes and reporting solutions. \n Create and maintain data pipelines, ensuring data quality, reliability, and performance.   Develop and maintain Python routines/scripts to support ETL processes, data transformation, and reporting needs. \n Optimize and fine-tune existing data infrastructure to ensure efficient query performance and cost-effectiveness. \n Perform database design and optimization, including schema design and indexing, to support evolving business needs. \n Mentor and provide guidance to junior data engineers in best practices for data engineering, AWS, and Python development. \n Stay up-to-date with industry trends, emerging technologies, and best practices in data engineering and analytics. \n \n Qualifications: ",
        "techs": [
            "aws data analytics services",
            "redshift",
            "python"
        ],
        "cleaned_techs": [
            "aws",
            "redshift",
            "python"
        ]
    },
    "67bc08b92ba130bf": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 130456.03,
        "salary_max": 165186.4,
        "title": "STAFF SOFTWARE ENGINEER, DATA",
        "company": "UniGroup",
        "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com",
        "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ",
        "techs": [
            "python",
            "javascript/typescript",
            "postgres",
            "mongodb",
            "microservices",
            "aws",
            "docker",
            "kubernetes",
            "git",
            "gitlab",
            "github",
            "sql",
            "kafka"
        ],
        "cleaned_techs": [
            "python",
            "javascript/typescript",
            "postgres",
            "mongodb",
            "microservices",
            "aws",
            "docker",
            "kubernetes",
            "git",
            "gitlab",
            "github",
            "sql",
            "kafka"
        ]
    },
    "a0256c947b3ff6e5": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 110000.0,
        "salary_max": 140000.0,
        "title": "Senior/Lead GCP Data Engineer",
        "company": "Publicis Sapient",
        "desc": "Senior/Lead GCP Data Engineer \n \n  Full-time \n \n \n \n \n \n \n  Company Description \n \n \n  Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across truly value \n \n \n \n \n \n  Job Description \n \n \n  Senior/Lead Data Engineering Google Cloud Platform (GCP) is responsible to develop and deliver effective cloud solutions for clients. This position requires in-depth knowledge and expertise in GCP services, architecture, and best practices. They will collaborate with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions. He will also be responsible for driving innovation and staying up-to-date with the latest GCP technologies and trends to provide industry-leading solutions. \n  Your Impact: \n \n  Collaborate with clients to understand their business requirements and design GCP architecture to meet their needs. \n  Develop and implement cloud strategies, best practices, and standards to ensure efficient and effective cloud utilization. \n  Work with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions on GCP. \n  Provide technical guidance and mentorship to the team to develop their skills and expertise in GCP. \n  Stay up-to-date with the latest GCP technologies, trends, and best practices and assess their applicability to client solutions. \n \n \n \n \n \n \n  Qualifications \n \n \n \n  Must have good implementation   experience on   various   GCP\u2019s Data Storage and Processing services such as BigQuery, Dataflow, Bigtable, Dataform, Data fusion, cloud spanner, Cloud SQL \n  Must have programmatic experience with tools like Javascript, Python, Apache Spark. \n  What sets you apart: \n  Experience in complex migrations from legacy data warehousing solutions or on-prem datalakes to GCP \n  Experience in building real-time ingestion and processing frameworks on GCP. \n  Adaptability to learn new technologies and products as the job demands. \n  Multi-cloud & hybrid cloud experience \n  Any cloud certification \n \n \n \n \n \n \n  Additional Information \n \n \n \n  Gender-Neutral Policy \n  Access to Medical Plan \n  Employee engagement activities and events \n  Remote work \n  Additional Information  Base Salary Range for the Role: 110000- 140000 (varies depending on experience)  The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. Actual range for this position may differ, depending on location and specific skillset required for the work itself.  Learn more about us at www.publicissapient.com or explore other career opportunities careers.publicissapient.com.  As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at h[email protected] or you may call us at +1-617-621-0200.",
        "cleaned_desc": "  Collaborate with clients to understand their business requirements and design GCP architecture to meet their needs. \n  Develop and implement cloud strategies, best practices, and standards to ensure efficient and effective cloud utilization. \n  Work with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions on GCP. \n  Provide technical guidance and mentorship to the team to develop their skills and expertise in GCP. \n  Stay up-to-date with the latest GCP technologies, trends, and best practices and assess their applicability to client solutions. \n \n \n \n \n \n \n  Qualifications   \n \n \n  Must have good implementation   experience on   various   GCP\u2019s Data Storage and Processing services such as BigQuery, Dataflow, Bigtable, Dataform, Data fusion, cloud spanner, Cloud SQL \n  Must have programmatic experience with tools like Javascript, Python, Apache Spark. \n  What sets you apart: \n  Experience in complex migrations from legacy data warehousing solutions or on-prem datalakes to GCP \n  Experience in building real-time ingestion and processing frameworks on GCP. \n  Adaptability to learn new technologies and products as the job demands. \n  Multi-cloud & hybrid cloud experience \n  Any cloud certification \n ",
        "techs": [
            "bigquery",
            "dataflow",
            "bigtable",
            "dataform",
            "data fusion",
            "cloud spanner",
            "cloud sql",
            "javascript",
            "python",
            "apache spark"
        ],
        "cleaned_techs": [
            "bigquery",
            "dataflow",
            "bigtable",
            "dataform",
            "data fusion",
            "cloud spanner",
            "cloud sql",
            "javascript",
            "python",
            "apache spark"
        ]
    },
    "d7222feef577e785": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 65.0,
        "salary_max": 70.0,
        "title": "Sr. Data Engineer",
        "company": "The Judge Group",
        "desc": "Our client is currently seeking a \n  Sr. Data Engineer \n \n \n Job Description: \n \n Supply Chain Data Strategy and Cloud Operation are core. \n With sales of over $100 B, the capability of delivering critical data and building cloud first solutions our teams offer is one of the most critical capabilities of the company.  \n We?re looking for individuals who can bring their core set of knowledge as well as learn new tools to provide new data and capabilities to support clients ever growing Supply Chain. \n  Accountable for developing and delivering technological responses to targeted business outcomes.  \n Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for Supply Chain and the overall enterprise.  \n Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration where needed.  \n Demonstrate the company?s core values of respect, honesty, integrity, diversity, inclusion and safety. \n \n Top 3 Skills:   \n Data Manipulation(DBX, Spark, Sql). \n Key Responsibilities \n \n Create and leverage Databricks notebooks to source, shape and store data using SQL, Python, Pyspark. \n Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses. \n Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration. \n Define high-level migration plans to address the gaps between the current and future state. \n Analyze technology environments to detect critical deficiencies and recommend solutions for improvement. \n Promote the reuse of data assets, including the management of the data catalog for reference.",
        "cleaned_desc": " Key Responsibilities \n \n Create and leverage Databricks notebooks to source, shape and store data using SQL, Python, Pyspark. \n Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses. ",
        "techs": [
            "databricks notebooks",
            "sql",
            "python",
            "pyspark"
        ],
        "cleaned_techs": [
            "databricks notebooks",
            "sql",
            "python",
            "pyspark"
        ]
    },
    "8fa914eba0589801": {
        "terms": [
            "data engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Lead Data Warehouse Engineer (work from home)",
        "company": "American Red Cross",
        "desc": "Please use Google Chrome or Mozilla Firefox when accessing Candidate Home. \n \n By joining the American Red Cross you will touch millions of lives every year and experience the greatness of the human spirit at its best. Are you ready to be part of the world's largest humanitarian network? \n \n \n Join us-Where your Career is a Force for Good! \n \n \n Job Description: \n \n \n WHY CHOOSE US?  \n  As one of the nation's premier humanitarian organizations, the American Red Cross is dedicated to helping people in need throughout the United States and, in association with other Red Cross networks, throughout the world. When you join our team, you have a direct impact on a meaningful mission, and you can help save lives every day. If you share our passion for helping people, join us in this excellent career opportunity. \n  Work where your career is a force for good. \n \n  We are committed to the diversity of our workforce and to delivering our programs and services in a culturally competent manner reflecting the communities we serve. Our work environment is collaborative, respectful, and inclusive with a focus on building allyship and a culture of belonging that empowers all team members. Come to learn, grow, and succeed while sharing your passion for making a difference. \n  \n  The Red Cross supports a variety of cultural and community resource groups for employees and volunteers. From the Ability Network, our Asian American & Pacific Islander Resource Group, the Latino Resource Group, and Red Cross PRIDE, to the Umoja African American Resource Group, our Veterans+ Resource Group, and the Women's Resource Group, these networks provide connections, mentoring and help give voice to important concerns and opinions. \n  \n  At the American Red Cross, your uniqueness can shin e! \n  \n \n WHAT YOU NEED TO KNOW ABOUT THE JOB: \n  The Enterprise Data & Analytics Team is building out a team of Data Warehouse Engineers to support mission-transforming work through data at the American Red Cross. As a result, we are hiring for a Lead Data Warehouse Engineers to help do this exciting work!\n  \n  As a Lead Data Warehouse Engineer for the American Red Cross, you will be part of a Data Management team that is modernizing and transforming our data and reporting capabilities across multiple verticals by implementing a new modernized data architecture.\n  \n  The Lead Data Warehouse Engineer will help develop, maintain and support an enterprise data warehouse system and corresponding data and will be responsible for database design and implementation of agreed upon standards. This position requires an innovative engineer who is passionate about data & data quality. The ideal candidate will possess strong data warehousing experience and the ability to develop scalable data pipelines that make data management and analytics/reporting faster, more insightful, and more efficient. \n  \n \n The work location is 100% virtual from a home office with occasional in-person meetings as necessary. Preference for candidate to be in the Mid-Atlantic states (NC, SC, VA) &/or to start the workday at 8am East coast to work with off-shore resources. \n \n \n WHERE YOUR CAREER IS A FORCE FOR GOOD (Key Responsibilities): \n \n \n Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. \n Build and implement scalable solutions that align to our data governance standards and architectural roadmap for data integrations, data storage, reporting, and analytic solutions.  \n Design and develop data integrations and a data quality framework. Write unit/integration/functional tests and document work. \n Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues. \n Serve as tech lead by mentoring less experienced members of the team through code reviews, pair programming and similar hands-on interactions.  \n \n  PAY INFORMATION: The annual salary range for this position is $135K - $140K. We do not offer an annual bonus for this role. Note that American Red Cross salaries are aligned to the specific geographic location in which the work is primarily performed. Other factors that may be used to determine your actual salary may include your specific skills, how many years of experience you have and comparison to other employees already in this role. **We will review specific salary information at the time of phone screening based upon your location & experience.**\n  \n  Scope: Individual contributor that works under limited supervision. Apply subject matter knowledge. Capacity to understand specific needs or requirements to apply skills/knowledge. \n  \n  Qualified candidates must be authorized to work in the United States. The American Red Cross does not sponsor employment visas. \n  \n \n WHAT YOU NEED TO SUCCEED (required/minimum qualifications): \n \n \n Education*: 4-year college degree or equivalent combination of education and experience. Prefer academic backgrounds in Computer Science, Mathematics, Statistics, or related technical field. \n 7+ years of relevant work experience in data engineering, business intelligence or related field. \n Experience with a variety of database technologies and data warehouse schema design patterns (snowflake and star in particular). \n Experience with cloud-based databases, specifically AWS technologies (e.g., Redshift, RDS, S3, EMR, EC2, Kinesis)  \n \n \n \n Proficient in Informatica (Power Center, IDMC, IDQ, MFT) required \n Experience using SQL queries as well as writing and optimizing SQL queries in a business environment with large-scale, complex datasets. \n Experience creating ETL and/or ELT jobs. \n Experience with Agile software development methodologies. \n Excellent problem solving and troubleshooting skills. \n Process oriented with great documentation skills. \n Proficient in object-oriented programming (Python in particular). \n Experience with DevOps methodologies and tools (e.g., Git, Artifactory, etc.). \n Experience developing in a Linux environment.  \n Experience developing integrations across multiple systems and APIs is a plus. \n Experience with Big Data tools like Spark, Hadoop, Kafka, etc. is a plus. \n \n \n \n Combination of candidate's education and general experience satisfies requirements so long as the total years equate to description's minimum education and general experience years combined (Management experience cannot be substituted). \n \n \n  BENEFITS FOR YOU: \n \n We take care of you, while you take care of others. As a mission-based organization, we believe our team needs great support to do great work. Our comprehensive benefits help you in balancing home and work, retirement, getting healthy and more. With our resources and perks, you have amazing possibilities at the American Red Cross to advance and learn.  \n \n \n Medical, Dental, & Vision Plans  \n Health Spending Accounts & Flexible Spending Accounts \n PTO + Holidays  \n 401K with up to 5% Match  \n Paid Family Leave \n Employee Assistance Programs  \n Disability and Insurance: Short + Long Term  \n Service Awards and Recognition \n \n \n \n LI-EH1 \n \n  IND123\n  \n \n \n LI-EH1 \n \n  IND123 \n \n \n Apply now! Joining our team will provide you with the opportunity to make a difference every day. \n \n  The American Red Cross is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. \n  \n  Interested in Volunteering?\n  \n  Life's emergencies don't stop, and neither do American Red Cross volunteers, who represent more than 90 percent of our workforce to help prevent and alleviate human suffering. You can make a difference by volunteering in a position that appeals to you and allows you to use your unique skills and talents. The Red Cross relies on generous volunteers who give their time and talent to help fulfill our lifesaving mission.\n  \n  Visit redcross.org/volunteertoday to learn more, including our most-needed volunteer positions.\n  \n  To view the EEOC Summary of Rights, click here: Summary of Rights",
        "cleaned_desc": " WHAT YOU NEED TO KNOW ABOUT THE JOB: \n  The Enterprise Data & Analytics Team is building out a team of Data Warehouse Engineers to support mission-transforming work through data at the American Red Cross. As a result, we are hiring for a Lead Data Warehouse Engineers to help do this exciting work!\n  \n  As a Lead Data Warehouse Engineer for the American Red Cross, you will be part of a Data Management team that is modernizing and transforming our data and reporting capabilities across multiple verticals by implementing a new modernized data architecture.\n  \n  The Lead Data Warehouse Engineer will help develop, maintain and support an enterprise data warehouse system and corresponding data and will be responsible for database design and implementation of agreed upon standards. This position requires an innovative engineer who is passionate about data & data quality. The ideal candidate will possess strong data warehousing experience and the ability to develop scalable data pipelines that make data management and analytics/reporting faster, more insightful, and more efficient. \n  \n \n The work location is 100% virtual from a home office with occasional in-person meetings as necessary. Preference for candidate to be in the Mid-Atlantic states (NC, SC, VA) &/or to start the workday at 8am East coast to work with off-shore resources. \n \n \n WHERE YOUR CAREER IS A FORCE FOR GOOD (Key Responsibilities): \n \n \n Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. \n Build and implement scalable solutions that align to our data governance standards and architectural roadmap for data integrations, data storage, reporting, and analytic solutions.  \n Design and develop data integrations and a data quality framework. Write unit/integration/functional tests and document work. \n Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues. \n Serve as tech lead by mentoring less experienced members of the team through code reviews, pair programming and similar hands-on interactions.  \n \n  PAY INFORMATION: The annual salary range for this position is $135K - $140K. We do not offer an annual bonus for this role. Note that American Red Cross salaries are aligned to the specific geographic location in which the work is primarily performed. Other factors that may be used to determine your actual salary may include your specific skills, how many years of experience you have and comparison to other employees already in this role. **We will review specific salary information at the time of phone screening based upon your location & experience.**\n     Scope: Individual contributor that works under limited supervision. Apply subject matter knowledge. Capacity to understand specific needs or requirements to apply skills/knowledge. \n  \n  Qualified candidates must be authorized to work in the United States. The American Red Cross does not sponsor employment visas. \n  \n \n WHAT YOU NEED TO SUCCEED (required/minimum qualifications): \n \n \n Education*: 4-year college degree or equivalent combination of education and experience. Prefer academic backgrounds in Computer Science, Mathematics, Statistics, or related technical field. \n 7+ years of relevant work experience in data engineering, business intelligence or related field. \n Experience with a variety of database technologies and data warehouse schema design patterns (snowflake and star in particular). \n Experience with cloud-based databases, specifically AWS technologies (e.g., Redshift, RDS, S3, EMR, EC2, Kinesis)  \n \n \n \n Proficient in Informatica (Power Center, IDMC, IDQ, MFT) required \n Experience using SQL queries as well as writing and optimizing SQL queries in a business environment with large-scale, complex datasets. \n Experience creating ETL and/or ELT jobs. \n Experience with Agile software development methodologies. \n Excellent problem solving and troubleshooting skills. \n Process oriented with great documentation skills. \n Proficient in object-oriented programming (Python in particular). ",
        "techs": [
            "informatica (power center",
            "idmc",
            "idq",
            "mft)",
            "sql queries",
            "etl",
            "elt",
            "agile software development methodologies",
            "python"
        ],
        "cleaned_techs": [
            "informatica (power center",
            "idmc",
            "idq",
            "mft)",
            "etl",
            "elt",
            "agile software development methodologies",
            "python"
        ]
    },
    "d0e41796b3c4de97": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 129731.945,
        "salary_max": 164269.55,
        "title": "STAFF SOFTWARE ENGINEER, DATA",
        "company": "UniGroup",
        "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com",
        "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ",
        "techs": [
            "data modelling",
            "data mining techniques",
            "programming languages (python",
            "javascript/typescript)",
            "relational sql databases (postgres)",
            "nosql databases (mongodb)",
            "cloud environments (microservices",
            "aws",
            "docker",
            "kubernetes)",
            "git",
            "gitlab",
            "github",
            "sql database design",
            "big data tools (kafka)",
            "data pipeline and workflow management tools"
        ],
        "cleaned_techs": [
            "data modelling",
            "data mining techniques",
            "programming languages (python",
            "javascript/typescript)",
            "relational sql databases (postgres)",
            "nosql",
            "cloud environments (microservices",
            "aws",
            "docker",
            "kubernetes)",
            "git",
            "gitlab",
            "github",
            "sql",
            "big data tools (kafka)",
            "data pipeline and workflow management tools"
        ]
    },
    "0906b399336e2bf4": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 66000.0,
        "salary_max": 115000.0,
        "title": "Data Operations Engineer",
        "company": "Lighthouse Document Technologies Inc",
        "desc": "What is special about Lighthouse? \n  Lighthouse is built on a foundation of unique, compassionate, highly driven individuals. We elevate the strengths and talents of those around us while leveraging opportunities for growth. We offer the experience of solving complex problems while continuing to grow multiple facets of your career. Lighthouse is where innovation meets support and where collaboration is the key ingredient to success. We grow together and are stronger together. \n \n  What\u2019s unique about this role? \n  The Data Operations Engineer role is part of the eDiscovery Custom Engineering team and focuses on creating quick-turn solutions that solve complex eDiscovery data problems utilizing modern software technologies. The team\u2019s software solutions typically include interpreted language programs, complex scripts, SQL database queries, and light application development. This is an execution role responsible for planning, grooming, and developing the most efficient technology solution to meet internal and external client needs. The team functions as the next-level technical escalation to support the eDiscovery service delivery organization and involves quick-turn response and resolution. Solutions typically include automating and optimizing the execution of manual tasks, data manipulation tools (extract, normalize, transform, organize, query), integrating 3rd party technologies, and just-in-time custom eDiscovery client requirements. Timeframes are typically quick-turn and measured in hours, days, and weeks. \n \n  As a Data Operations Engineer, you must be a self-starter and have a talent for collecting information from many sources across the business and clients and pulling that information together to execute an efficient solution that meets the business needs. \n \n  What will this person do? \n \n  Create quick-turn eDiscovery solutions that solve client and operational needs with a primary focus on automating and optimizing complex manual tasks, data handling tools (extract, normalize, transform, organize, query), integrating 3rd party technologies, and just-in-time custom eDiscovery client requirements. \n  Responsible for the creation or modification of production-ready software applications and workflows from conception to completion in the most efficient and timely manner. \n  Solution creation includes designing, coding, debugging, and unit testing that meets internal and external client requirements. \n  Specify software and related workflow requirements to determine design feasibility within time and cost constraints. \n  Contribute to the planning and estimating software development timelines and accountable to deliver on the timelines by actively managing risks and changing requirements. \n  Provide execution escalation support for complex client requirements, software issues, root cause analysis, and investigation/remediation of complex technology problems. \n  Effective use of modern software development tools and techniques to create efficient and reliable algorithms with appropriate exception handling/fault tolerance. \n  Communicate and train on how to use newly developed solutions as needed. \n \n  Perform other related duties as assigned. \n \n  Bring your passion and together we will shine. It would also be great if you have the following: \n \n  Bachelor\u2019s Degree in Computer Science or equivalent experience/certification preferred. \n  2+ years professional development including strong competencies or expertise in Python, SQL, C#, .NET Core, Ruby, Agile, data analysis & transformation, and other modern programming techniques preferred. \n  2+ years of technical eDiscovery software solution experience including techniques for complex data extraction, transformation, mapping, and large dataset query development preferred. \n  Experience with Relativity, Nuix, and other proprietary eDiscovery software solutions is preferred.Strong analytical, troubleshooting, problem solving, and root cause analysis skills. \n  Effective written and oral communication skills \n  Understanding of e-discovery principles and best practices. \n  Exceptional attention to detail and strong organizational skills. \n  Willingness to adapt to a rapidly changing environment and changing requirements. \n  Ability to work in a fast-paced environment and manage competing priorities. \n  Ability to work flexible hours as needed. \n  Adherence to processes and procedures while remaining results-oriented and \u201cthinking outside the box\u201d. \n \n  Work Environment and Physical Demands \n \n  Duties are performed in a typical office environment while at a desk or computer table. \n  Duties require the ability to use a computer, communicate over the telephone, and read printed material, in a quiet and professional setting. \n  Duties may require being on call periodically and working outside normal working hours (evenings and weekends). \n \n \n  Lighthouse celebrates and thrives on diversity and is an Equal Opportunity Employer. We hire, train, and promote regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law. We welcome any talents and contributions you can bring to the team and are deeply committed to growing an environment where everyone can feel safe, is respected, and can show up as themselves. Come as you are! \n \n  As required by applicable pay transparency laws, Lighthouse complies with compensation disclosure requirements for roles that may be hired in locations under these requirements. Factors that may be used to determine your actual salary may include a wide array of factors, including: your specific skills and experience, geographic location, or other relevant factors. The salary range for this position may be tailored to be lower or higher in different talent markets. \n \n  The expected pay for this role will range from $66,000 to $115,000 per year. This role will be eligible to participate in an annual bonus or incentive program. \n \n  Lighthouse offers a quality comprehensive benefits package including, medical, dental, vision, and a 401k with company match. Company paid benefits also include Life & AD&D, short and long-term disability, telemedicine through 98point6, and other wellness plans. We offer a generous Flexible PTO program and paid volunteer days. Employees may also participate in voluntary insurance plans including accident, hospitalization, and critical illness plans as well as pet insurance. \n \n  As a trailblazer and catalyst for change, Lighthouse rises to each opportunity to help our clients and our people do what they do best\u2014shine.",
        "cleaned_desc": " \n  Bring your passion and together we will shine. It would also be great if you have the following: \n \n  Bachelor\u2019s Degree in Computer Science or equivalent experience/certification preferred. \n  2+ years professional development including strong competencies or expertise in Python, SQL, C#, .NET Core, Ruby, Agile, data analysis & transformation, and other modern programming techniques preferred. \n  2+ years of technical eDiscovery software solution experience including techniques for complex data extraction, transformation, mapping, and large dataset query development preferred. \n  Experience with Relativity, Nuix, and other proprietary eDiscovery software solutions is preferred.Strong analytical, troubleshooting, problem solving, and root cause analysis skills. \n  Effective written and oral communication skills \n  Understanding of e-discovery principles and best practices. \n  Exceptional attention to detail and strong organizational skills. ",
        "techs": [
            "python",
            "sql",
            "c#",
            ".net core",
            "ruby",
            "agile",
            "data analysis & transformation",
            "relativity",
            "nuix"
        ],
        "cleaned_techs": [
            "python",
            "sql",
            "c#",
            ".net core",
            "ruby",
            "agile",
            "data analysis & transformation",
            "relativity",
            "nuix"
        ]
    },
    "96bbdec555f6d48f": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 127986.02,
        "salary_max": 162058.83,
        "title": "STAFF SOFTWARE ENGINEER, DATA",
        "company": "UniGroup",
        "desc": "Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology. \n \n  The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE. \n \n \n Essential Duties and Responsibilities: \n \n \n Technical Skills: \n Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code. \n Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy. \n Proficient at using systematic debugging to diagnose all issues within a set of related domains. \n Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains. \n Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems. \n Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes. \n Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example. \n Delivery: \n Reviews cross-team work critically and ensures it\u2019s appropriately broken down and prioritized, and well understood by all involved teams. \n Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy. \n Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations. \n Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved. \n When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions. \n Feedback, Communication, Collaboration: \n Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors. \n Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors. \n Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication. \n Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors. \n Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due. \n Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams. \n Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans. \n Leadership: \n Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves. \n Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals. \n Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes. \n Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in. \n Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors. \n Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills \n \n Education, License or Certification: \n \n \n Bachelor\u2019s degree in Information Systems or equivalent experience. \n \n Experience: \n \n \n 6-8 years of experience in IS Development \n  We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law. \n \n  We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country\u2019s heroes. We hope you consider joining the UniGroup family. \n \n  UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com",
        "cleaned_desc": " Strategic Impact: \n Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals. \n Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints. \n Technical expertise with data modelling and data mining techniques: \n Experience with programming languages (e.g. Python and JavaScript/Typescript) \n Experience with relational SQL and NoSQL databases, including Postgres and MongoDB. \n Experience with cloud environments (Microservices / AWS / Docker / Kubernetes) \n Experience of using Git / GitLab /GitHub \n Hands-on experience with SQL database design \n Experience with big data tools such as Kafka, etc. \n Experience with data pipeline and workflow management tools \n Great numerical and analytical skills ",
        "techs": [
            "data modelling",
            "data mining",
            "python",
            "javascript",
            "typescript",
            "relational sql",
            "nosql databases",
            "postgres",
            "mongodb",
            "cloud environments",
            "microservices",
            "aws",
            "docker",
            "kubernetes",
            "git",
            "gitlab",
            "github",
            "sql database design",
            "big data tools",
            "kafka",
            "data pipeline",
            "workflow management"
        ],
        "cleaned_techs": [
            "data modelling",
            "data mining",
            "python",
            "javascript",
            "typescript",
            "relational sql",
            "nosql",
            "postgres",
            "mongodb",
            "cloud environments",
            "microservices",
            "aws",
            "docker",
            "kubernetes",
            "git",
            "gitlab",
            "github",
            "sql",
            "big data tools",
            "kafka",
            "data pipeline",
            "workflow management"
        ]
    },
    "130125edf01e8f42": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105783.266,
        "salary_max": 133945.19,
        "title": "Data Protection Engineer [JOB ID 20230918]",
        "company": "Phoenix Cyber",
        "desc": "Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States. \n  Requirements: \n \n  5+ years\u2019 experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise. \n  5+ years\u2019 experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise. \n  Experience with Regex \n \n  Description: \n \n  Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options. \n  Assess different DLP endpoint protection tool options and help the customer choose the best option. \n  Develop DLP design, design DLP integrations and assess enterprise reporting capability. \n  Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode. \n  Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options. \n  Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP\u2019s), and assess enterprise reporting capability. \n  Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode. \n  Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n  Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n \n  Requirements: \n \n  Secret Clearance \n  Active: CySA, CEH, SSCP, or GICSP Certification \n \n  Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team. \n  Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status. \n  Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify. \n   \n 61QqVicRqa",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "c57f6a06d74a9490": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 110000.0,
        "salary_max": 165000.0,
        "title": "CAT Modeling/Senior Data Engineer (US Remote)",
        "company": "Swyfft",
        "desc": "Swyfft Holdings, LLC, consists of Swyfft, LLC and Core Programs, LLC. Both are fast-growing, tech-enabled MGA\u2019s that are disrupting the traditional insurance industry by re-imagining how you price and bind home insurance and commercial package products. From lightning-fast quotes to hassle-free claims servicing, Swyfft Holdings, LLC leverages big data to provide the very best customer service experience in the industry. We're growing, we\u2019re expanding and we're looking for \u201ctech-savvy\u201d folks like you to join our team! \n \n \n  About the Position: \n \n  As a Senior Data Engineer, you will be instrumental in supporting the development and use of our data systems. Your goal is to ensure that information flows timely and accurately to and from the organization and within. As a successful Senior Data Engineer, you will bring forth a strong understanding of databases and data analysis procedures. You are a highly technical SQL expert with strong problem-solving skills and excellent troubleshooting capabilities. In a perfect world, you might even have some previous experience working for a broker, insurance company or an insurtech. \n \n \n   This position is a 100% remote U.S. based opportunity. Some travel for day-to-day work, team meetings, and training will be required. \n \n \n \n  Key Responsibilities: (What you'll be asked to do) \n \n \n \n  Build efficient ways to organize, store and analyze data while maintaining availability and consistency. \n Create processes and enforce policies for effective data management. \n Formulate techniques for quality data collection to ensure adequacy, accuracy and legitimacy of data. \n Devise and implement efficient and secure procedures for data handling and analysis with attention to all technical aspects. \n Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n \n \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n \n \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n \n \n \n  Reliable high-speed internet connectivity required. \n Designated quiet work from home space. \n \n \n \n  We Have a Great Benefits Package! \n \n \n \n  20 days of PTO annually \n Medical, Dental, Vision \n Short- and Long-Term Disability (Company Paid) \n Life & AD&D (Company Paid) \n Healthcare, Dependent Care and Transit FSA \n 401K with a generous matching contribution and no vesting schedule \n \n \n \n  Salary \n \n $110,000 - $165,000 \n \n \n \n  The salary range reflected above is a good faith estimate of base pay for the primary location of the position. The salary for this position ultimately will be determined based on the education, experience, knowledge, and abilities of the successful candidate. \n \n \n  It is the policy of Swyfft to provide equal employment opportunities to all employees and applicants for employment without regard to race, religion, color, ethnic origin, gender, gender identity, age, marital status, veteran status, sexual orientation, disability, or any other basis prohibited by applicable federal, state, or local law. EOE/AA/M/D/V/F. \n \n \n  Please Note: Swyfft is not accepting 3rd party agency resumes for this position, please do not forward resumes to our careers email address or Swyfft employees. Swyfft will not be responsible for any fees related to unsolicited resumes.",
        "cleaned_desc": "Swyfft Holdings, LLC, consists of Swyfft, LLC and Core Programs, LLC. Both are fast-growing, tech-enabled MGA\u2019s that are disrupting the traditional insurance industry by re-imagining how you price and bind home insurance and commercial package products. From lightning-fast quotes to hassle-free claims servicing, Swyfft Holdings, LLC leverages big data to provide the very best customer service experience in the industry. We're growing, we\u2019re expanding and we're looking for \u201ctech-savvy\u201d folks like you to join our team! \n \n \n  About the Position: \n \n  As a Senior Data Engineer, you will be instrumental in supporting the development and use of our data systems. Your goal is to ensure that information flows timely and accurately to and from the organization and within. As a successful Senior Data Engineer, you will bring forth a strong understanding of databases and data analysis procedures. You are a highly technical SQL expert with strong problem-solving skills and excellent troubleshooting capabilities. In a perfect world, you might even have some previous experience working for a broker, insurance company or an insurtech. \n \n \n   This position is a 100% remote U.S. based opportunity. Some travel for day-to-day work, team meetings, and training will be required. \n \n \n \n  Key Responsibilities: (What you'll be asked to do) \n \n \n \n  Build efficient ways to organize, store and analyze data while maintaining availability and consistency. \n Create processes and enforce policies for effective data management. \n Formulate techniques for quality data collection to ensure adequacy, accuracy and legitimacy of data. \n Devise and implement efficient and secure procedures for data handling and analysis with attention to all technical aspects. \n Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards.   Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n \n \n  Some Requirements: \n \n   \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n \n \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n ",
        "techs": [
            "swyfft holdings",
            "llc",
            "swyfft",
            "llc",
            "core programs",
            "llc",
            "big data",
            "sql",
            "cat modeling (air & rms)",
            "sql server",
            "postgresql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "data warehousing",
            "star schemas",
            "predictive analysis",
            "data visualization",
            "microsoft excel",
            "spatial database functionality."
        ],
        "cleaned_techs": [
            "swyfft holdings",
            "llc",
            "swyfft",
            "core programs",
            "big data",
            "sql",
            "cat modeling (air & rms)",
            "postgresql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "data warehousing",
            "star schemas",
            "predictive analysis",
            "data visualization",
            "excel",
            "spatial database functionality."
        ]
    },
    "a43fc95db50fd697": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105783.266,
        "salary_max": 133945.19,
        "title": "Data Protection Engineer [JOB ID 20230918]",
        "company": "Phoenix Cyber",
        "desc": "Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States. \n  Requirements: \n \n  5+ years\u2019 experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise. \n  5+ years\u2019 experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise. \n  Experience with Regex \n \n  Description: \n \n  Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options. \n  Assess different DLP endpoint protection tool options and help the customer choose the best option. \n  Develop DLP design, design DLP integrations and assess enterprise reporting capability. \n  Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode. \n  Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options. \n  Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP\u2019s), and assess enterprise reporting capability. \n  Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode. \n  Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n  Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n \n  Requirements: \n \n  Secret Clearance \n  Active: CySA, CEH, SSCP, or GICSP Certification \n \n  Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team. \n  Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status. \n  Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify. \n   \n MADJezY2P0",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "e35d423ea9001808": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105783.266,
        "salary_max": 133945.19,
        "title": "Data Protection Engineer [JOB ID 20230918]",
        "company": "Phoenix Cyber",
        "desc": "Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States. \n  Requirements: \n \n  5+ years\u2019 experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise. \n  5+ years\u2019 experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise. \n  Experience with Regex \n \n  Description: \n \n  Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options. \n  Assess different DLP endpoint protection tool options and help the customer choose the best option. \n  Develop DLP design, design DLP integrations and assess enterprise reporting capability. \n  Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode. \n  Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options. \n  Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP\u2019s), and assess enterprise reporting capability. \n  Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode. \n  Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n  Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n \n  Requirements: \n \n  Secret Clearance \n  Active: CySA, CEH, SSCP, or GICSP Certification \n \n  Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team. \n  Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status. \n  Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify. \n   \n 4OWQ5dG6V8",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "ca96023e5fe72347": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 114384.83,
        "salary_max": 144836.67,
        "title": "CAT Modeling/Senior Data Engineer (US Remote)",
        "company": "Swyfft",
        "desc": "Swyfft Holdings, LLC, consists of Swyfft, LLC and Core Programs, LLC. Both are fast-growing, tech-enabled MGA\u2019s that are disrupting the traditional insurance industry by re-imagining how you price and bind home insurance and commercial package products. From lightning-fast quotes to hassle-free claims servicing, Swyfft Holdings, LLC leverages big data to provide the very best customer service experience in the industry. We're growing, we\u2019re expanding and we're looking for \u201ctech-savvy\u201d folks like you to join our team! \n \n \n  About the Position: \n \n  As a Senior Data Engineer, you will be instrumental in supporting the development and use of our data systems. Your goal is to ensure that information flows timely and accurately to and from the organization and within. As a successful Senior Data Engineer, you will bring forth a strong understanding of databases and data analysis procedures. You are a highly technical SQL expert with strong problem-solving skills and excellent troubleshooting capabilities. In a perfect world, you might even have some previous experience working for a broker, insurance company or an insurtech. \n \n \n   This position is a 100% remote U.S. based opportunity. Some travel for day-to-day work, team meetings, and training will be required. \n \n \n \n  Key Responsibilities: (What you'll be asked to do) \n \n \n \n  Build efficient ways to organize, store and analyze data while maintaining availability and consistency. \n Create processes and enforce policies for effective data management. \n Formulate techniques for quality data collection to ensure adequacy, accuracy and legitimacy of data. \n Devise and implement efficient and secure procedures for data handling and analysis with attention to all technical aspects. \n Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n \n \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n \n \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n \n \n \n  Reliable high-speed internet connectivity required. \n Designated quiet work from home space. \n \n \n \n  We Have a Great Benefits Package! \n \n \n \n  20 days of PTO annually \n Medical, Dental, Vision \n Short- and Long-Term Disability (Company Paid) \n Life & AD&D (Company Paid) \n Healthcare, Dependent Care and Transit FSA \n 401K with a generous matching contribution and no vesting schedule \n \n \n \n  It is the policy of Swyfft to provide equal employment opportunities to all employees and applicants for employment without regard to race, religion, color, ethnic origin, gender, gender identity, age, marital status, veteran status, sexual orientation, disability, or any other basis prohibited by applicable federal, state, or local law. EOE/AA/M/D/V/F. \n \n \n  Please Note: Swyfft is not accepting 3rd party agency resumes for this position, please do not forward resumes to our careers email address or Swyfft employees. Swyfft will not be responsible for any fees related to unsolicited resumes.",
        "cleaned_desc": " Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n   \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n   \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n ",
        "techs": [
            "cat modeling (air & rms)",
            "sql server (ms and postgresql)",
            "tableau",
            "r",
            "python",
            "dataiku",
            "microsoft excel",
            "spatial database functionality."
        ],
        "cleaned_techs": [
            "cat modeling (air & rms)",
            "sql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "excel",
            "spatial database functionality."
        ]
    },
    "6633ad98e617bee0": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105783.266,
        "salary_max": 133945.19,
        "title": "Data Protection Engineer [JOB ID 20230918]",
        "company": "Phoenix Cyber",
        "desc": "Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States. \n  Requirements: \n \n  5+ years\u2019 experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise. \n  5+ years\u2019 experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise. \n  Experience with Regex \n \n  Description: \n \n  Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options. \n  Assess different DLP endpoint protection tool options and help the customer choose the best option. \n  Develop DLP design, design DLP integrations and assess enterprise reporting capability. \n  Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode. \n  Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options. \n  Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP\u2019s), and assess enterprise reporting capability. \n  Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode. \n  Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n  Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n \n  Requirements: \n \n  Secret Clearance \n  Active: CySA, CEH, SSCP, or GICSP Certification \n \n  Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team. \n  Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status. \n  Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify. \n   \n nnfOFCM9Qq",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4c1125b3b8d0cf9e": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 116621.625,
        "salary_max": 147668.97,
        "title": "CAT Modeling/Senior Data Engineer (US Remote)",
        "company": "Swyfft",
        "desc": "Swyfft Holdings, LLC, consists of Swyfft, LLC and Core Programs, LLC. Both are fast-growing, tech-enabled MGA\u2019s that are disrupting the traditional insurance industry by re-imagining how you price and bind home insurance and commercial package products. From lightning-fast quotes to hassle-free claims servicing, Swyfft Holdings, LLC leverages big data to provide the very best customer service experience in the industry. We're growing, we\u2019re expanding and we're looking for \u201ctech-savvy\u201d folks like you to join our team! \n \n \n  About the Position: \n \n  As a Senior Data Engineer, you will be instrumental in supporting the development and use of our data systems. Your goal is to ensure that information flows timely and accurately to and from the organization and within. As a successful Senior Data Engineer, you will bring forth a strong understanding of databases and data analysis procedures. You are a highly technical SQL expert with strong problem-solving skills and excellent troubleshooting capabilities. In a perfect world, you might even have some previous experience working for a broker, insurance company or an insurtech. \n \n \n   This position is a 100% remote U.S. based opportunity. Some travel for day-to-day work, team meetings, and training will be required. \n \n \n \n  Key Responsibilities: (What you'll be asked to do) \n \n \n \n  Build efficient ways to organize, store and analyze data while maintaining availability and consistency. \n Create processes and enforce policies for effective data management. \n Formulate techniques for quality data collection to ensure adequacy, accuracy and legitimacy of data. \n Devise and implement efficient and secure procedures for data handling and analysis with attention to all technical aspects. \n Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n \n \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n \n \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n \n \n \n  Reliable high-speed internet connectivity required. \n Designated quiet work from home space. \n \n \n \n  We Have a Great Benefits Package! \n \n \n \n  20 days of PTO annually \n Medical, Dental, Vision \n Short- and Long-Term Disability (Company Paid) \n Life & AD&D (Company Paid) \n Healthcare, Dependent Care and Transit FSA \n 401K with a generous matching contribution and no vesting schedule \n \n \n \n  It is the policy of Swyfft to provide equal employment opportunities to all employees and applicants for employment without regard to race, religion, color, ethnic origin, gender, gender identity, age, marital status, veteran status, sexual orientation, disability, or any other basis prohibited by applicable federal, state, or local law. EOE/AA/M/D/V/F. \n \n \n  Please Note: Swyfft is not accepting 3rd party agency resumes for this position, please do not forward resumes to our careers email address or Swyfft employees. Swyfft will not be responsible for any fees related to unsolicited resumes.",
        "cleaned_desc": " Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n   \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n   \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n ",
        "techs": [
            "cat modeling",
            "air",
            "rms",
            "sql server",
            "postgresql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "microsoft excel",
            "slack",
            "ms teams"
        ],
        "cleaned_techs": [
            "cat modeling",
            "air",
            "rms",
            "sql",
            "postgresql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "excel",
            "slack",
            "ms teams"
        ]
    },
    "2aed69d35806a514": {
        "terms": [
            "data engineer",
            "machine learning engineer"
        ],
        "salary_min": 60000.0,
        "salary_max": 90000.0,
        "title": "Data Engineer - AI/ML (Virtual)",
        "company": "S&P Global",
        "desc": "Job Description \n This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills. \n \n  Duties and Responsibilities \n Implement machine learning algorithms \n Collect and clean data \n Evaluate the performance of AI/ML models \n Work closely with the stakeholders to understand the business needs and develop solutions around these needs \n Develop and deploy the AI models \n Daily scrum update \n Work closely with QA team to fix bugs \n Basic understanding of automation \n \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n \n  S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location. \n \n  This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ . \n \n  Flexible Working \n We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can. \n \n  Return to Work \n Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace. \n \n \n Grade/Level ( relevant for internal applicants only ):  9 \n \n \n About Company Statement:  S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape. \n \n \n EEO Statement: \n  S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n  ----------------------------------------------------------- \n \n  Equal Opportunity Employer \n S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment. \n \n  If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person. \n \n \n US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law. \n \n  ----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group) \n \n \n Job ID:  289943 \n \n Posted On:  2023-09-18 \n \n Location:  Virtual, New Jersey, United States",
        "cleaned_desc": " \n \n The ideal candidate possesses: \n  Bachelor\u2019s degree from an accredited college or university, with major course work in computer science, information technology, or related field. \n Master\u2019s or advanced education is preferred. \n 3-5 years of experience in software development and testing \n Experience with programming languages such as Python or Java is a plus. \n Strong problem-solving skills. \n Ability to work independently and as part of a team. \n Basic understanding of machine learning \n Passionate about learning emerging technologies \n ",
        "techs": [
            "python",
            "java",
            "machine learning"
        ],
        "cleaned_techs": [
            "python",
            "java"
        ]
    },
    "3892934e7acf8390": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 118758.54,
        "salary_max": 150374.77,
        "title": "CAT Modeling/Senior Data Engineer (US Remote)",
        "company": "Swyfft",
        "desc": "Swyfft Holdings, LLC, consists of Swyfft, LLC and Core Programs, LLC. Both are fast-growing, tech-enabled MGA\u2019s that are disrupting the traditional insurance industry by re-imagining how you price and bind home insurance and commercial package products. From lightning-fast quotes to hassle-free claims servicing, Swyfft Holdings, LLC leverages big data to provide the very best customer service experience in the industry. We're growing, we\u2019re expanding and we're looking for \u201ctech-savvy\u201d folks like you to join our team! \n \n \n  About the Position: \n \n  As a Senior Data Engineer, you will be instrumental in supporting the development and use of our data systems. Your goal is to ensure that information flows timely and accurately to and from the organization and within. As a successful Senior Data Engineer, you will bring forth a strong understanding of databases and data analysis procedures. You are a highly technical SQL expert with strong problem-solving skills and excellent troubleshooting capabilities. In a perfect world, you might even have some previous experience working for a broker, insurance company or an insurtech. \n \n \n   This position is a 100% remote U.S. based opportunity. Some travel for day-to-day work, team meetings, and training will be required. \n \n \n \n  Key Responsibilities: (What you'll be asked to do) \n \n \n \n  Build efficient ways to organize, store and analyze data while maintaining availability and consistency. \n Create processes and enforce policies for effective data management. \n Formulate techniques for quality data collection to ensure adequacy, accuracy and legitimacy of data. \n Devise and implement efficient and secure procedures for data handling and analysis with attention to all technical aspects. \n Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n \n \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n \n \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n \n \n \n  Reliable high-speed internet connectivity required. \n Designated quiet work from home space. \n \n \n \n  We Have a Great Benefits Package! \n \n \n \n  20 days of PTO annually \n Medical, Dental, Vision \n Short- and Long-Term Disability (Company Paid) \n Life & AD&D (Company Paid) \n Healthcare, Dependent Care and Transit FSA \n 401K with a generous matching contribution and no vesting schedule \n \n \n \n  It is the policy of Swyfft to provide equal employment opportunities to all employees and applicants for employment without regard to race, religion, color, ethnic origin, gender, gender identity, age, marital status, veteran status, sexual orientation, disability, or any other basis prohibited by applicable federal, state, or local law. EOE/AA/M/D/V/F. \n \n \n  Please Note: Swyfft is not accepting 3rd party agency resumes for this position, please do not forward resumes to our careers email address or Swyfft employees. Swyfft will not be responsible for any fees related to unsolicited resumes.",
        "cleaned_desc": " Establish rules and procedures for data sharing with upper management and external stakeholders. \n Support others in the daily use of data systems and ensure compliance to legal and company standards. \n Provide assistance with reports and data extraction when needed. \n Monitor and analyze information and data systems and evaluate their performance to discover ways of enhancing them (such as new technologies and upgrades).  \n Ensure digital databases and archives are protected from security breaches and data losses. \n Troubleshoot data-related problems and authorize maintenance or modifications \n \n \n \n  The Successful Candidate: (what we're looking for) \n \n \n \n  You have experience with CAT Modeling using software such as AIR & RMS. \n You have a strong understanding of databases and data analysis procedures. \n You have an analytical mindset and strong problem-solving skills. \n You have excellent communication and collaboration skills. \n You have intense attention to detail and quality assurance. \n \n   \n  Some Requirements: \n \n \n \n  Expertise in SQL Server (MS and PostgreSQL) Tableau, R & Python. \n Experience using platforms such as Dataiku. \n 7+ years of experience as a data manager. \n Excellent understanding of data administration and management functions such as collection, analysis, and distribution. \n Understanding of data warehousing and star schemas. \n Basic familiarity with predictive analysis and data visualization techniques. \n Solid understanding of R and Python environment configuration and basic programming. \n Expert level in Microsoft Excel. \n \n \n Understanding of spatial database functionality is a plus. \n \n \n Education: \n   \n \n  Bachelors\u2019 degree or equivalent experience required in a related field. \n Advanced degrees or Certifications are a plus. \n \n \n Computer Skills: \n \n \n \n  You are familiar with predictive analysis and data visualization techniques using relevant tools such as: Tableau, Dataiku, R, Python. \n Must be proficient with MS Office and other internal insurance related programs, systems or applications.  \n \n \n Ability to communicate effectively using programs such as Slack & MS Teams. You are comfortable sharing screens and video chatting. \n \n \n \n  Other: \n ",
        "techs": [
            "cat modeling software",
            "air",
            "rms",
            "sql server",
            "ms",
            "postgresql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "microsoft excel",
            "slack",
            "ms teams."
        ],
        "cleaned_techs": [
            "cat modeling software",
            "air",
            "rms",
            "sql",
            "ms",
            "postgresql",
            "tableau",
            "r",
            "python",
            "dataiku",
            "excel",
            "slack",
            "ms teams."
        ]
    },
    "13e69d3455c26f9f": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105783.266,
        "salary_max": 133945.19,
        "title": "Data Protection Engineer [JOB ID 20230918]",
        "company": "Phoenix Cyber",
        "desc": "Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States. \n  Requirements: \n \n  5+ years\u2019 experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise. \n  5+ years\u2019 experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise. \n  Experience with Regex \n \n  Description: \n \n  Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options. \n  Assess different DLP endpoint protection tool options and help the customer choose the best option. \n  Develop DLP design, design DLP integrations and assess enterprise reporting capability. \n  Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode. \n  Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options.  \n Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP\u2019s), and assess enterprise reporting capability. \n  Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode.  \n Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n  Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT). \n \n  Requirements: \n \n  Secret Clearance \n  Active: CySA, CEH, SSCP, or GICSP Certification \n \n  Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team. \n  Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status. \n  Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify.gov/ \n   \n   \n nUffbkCeGN",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "471d8accc1a1b89d": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 60409.0,
        "salary_max": 95359.0,
        "title": "IT Applications/Report Developer (Data Engineer)",
        "company": "TRILLIUM HEALTH RESOURCES",
        "desc": "Pay Plan Title:  IT Applications/Report Developer\n      \n \n  Working Title  Data Engineer\n      \n \n  FLSA Status:  Exempt\n      \n \n  Posting Salary Range:  $60,409 - $95,359\n      \n \n  Office Location:  Remote with offices available in Greenville and Wilmington NC\n      \n \n  POSTING DETAILS: \n  Make an Impact \n  Trillium Health Resources is a local governmental agency (LME/MCO) in North Carolina that manages serious mental health, substance use, and intellectual/developmental disability services. Serving in 28 counties, we help individuals and their families strengthen well-being and build foundations for a healthy life. \n  Join our team as we empower others to live their best lives by providing access to quality healthcare. We offer a challenging, engaging work environment where staff take home more than a paycheck. Every day, we see the results of our dedication \u2013 in the smiles of children on our accessible playgrounds and in the pride on the face of an adult cooking a meal for the first time. Working at Trillium Health Resources is more than just a job; it is an opportunity to make a direct impact on the communities we serve. \n  At Trillium, we know that empowering others begins with supporting and developing our team. That\u2019s why we offer competitive benefits and work-from-home flexibility so that our employees thrive outside of the office. We\u2019re also committed to building a diverse, inclusive culture where all employees have the potential to grow professionally and personally. \n  What We\u2019re Looking For \n  Trillium Health Resources is transforming public health in North Carolina by managing the health needs of many of the state\u2019s most vulnerable populations. After successfully implementing managed care for mental health, substance use, and intellectual/developmental disabilities in the early 2010s, we\u2019re currently implementing a groundbreaking new type of Medicaid health plan that focuses on people\u2019s physical health needs, as well as factors like housing and food insecurity that can affect health. \n  We\u2019re seeking a Data Engineer who wants to grow their IT career by helping us implement this new model. You\u2019ll work directly with team members from all parts of our organization, on everything from Medicaid claims processing, to finance and accounting, to quality improvement and population health management. \n  On a typical day, you might: \n \n  Use SQL to: \n \n  Create a report that helps assess the health of our provider network \n  Create a report that identifies pregnant members and directs them to targeted prenatal services \n \n  Use R/R-Studio, Python, or Power BI  to design an interactive COVID-19 dashboard \n  Help onboard a new 3rd-party reporting tool by conducting end-user testing and creating a maintenance plan \n  Use Azure DevOps, TFS, or other software development/project management tools to: \n \n  Respond to requests from internal partners, \n  Document and track your progress on outstanding work \n  Maintain version control for reports and other code \n \n  Develop a data dictionary for a new line of business, such as physical or pharmacy claims data \n  Customize a data set(commercial or open) to fit Trillium\u2019s requirements \n  Plan, coordinate, and implement a new set of security measures to safeguard HIPAA-protected member data \n \n  Employee Benefits: \n  Trillium knows that work/life balance is important. That\u2019s why we offer our employees competitive benefits and flexibility that is second to none. Take a look at what we have to offer: \n \n  Flexible Work Schedules. Remote work was a strong part of our culture prior to COVID-19, and currently, employees may work remotely 100% of the time, with an in-office option available for those who prefer that. \n  Paid Time Off (PTO) of 23 days per year, plus 10 paid holidays both in first year of employment \n  Health Insurance - no premium for employee coverage \n  NC Local Government retirement pension. This is a defined-benefit retirement plan that will pay you a monthly amount upon retirement, for the rest of your life, with as little as five years of service. For more information, go to: \n \n  https://files.nc.gov/retire/documents/files/Actives/LGERSHandbook.pdf \n \n  401k with 5% employer match & immediate vesting \n  Public Service Loan Forgiveness Qualifying Employer \n  Flexible Spending Accounts \n \n  Qualifications: \n  Education:  High School (required certification) / Associate\u2019s degree Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, or Human Service field. Requires Certification \n \n  Experience:  High School diploma and three (3) years\u2019 experience in any of the following areas: Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, Human Service field, healthcare claims environment, reporting development, n-tier and web-based system development or support with strong technical knowledge in the specialized areas of application system programming, including software tools such as: SQL Server 2008 R2 or above, SQL, Oracle, NoSQL, MySQL, TFS (Team Foundation Server), Microsoft IIS and Microsoft .NET framework2.0 or above , Source Control, SSRS, SSIS, SSAS, SSMS, Visual Studio BIDS, Visual Studio 2008 or above, C#. Requires certification. Applicable certification(s) may be substituted to equivalent degree and experience requirements.\n      \n \n  OR \n \n \n       Associate\u2019s degree and a minimum one (1) year experience in any of the following areas: Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, Human Service field, healthcare claims environment, reporting development, n-tier and web-based system development or support with strong technical knowledge in the specialized areas of application system programming, including software tools such as: SQL Server 2008 R2 or above, SQL, Oracle, NoSQL, MySQL, TFS (Team Foundation Server), Microsoft IIS and Microsoft .NET framework2.0 or above , Source Control, SSRS, SSIS, SSAS, SSMS, Visual Studio BIDS, Visual Studio 2008 or above, C#. Requires certification. Applicable certification(s) may be substituted to equivalent degree and experience requirements.\n      \n \n  OR \n  Equivalent combination of education/experience \n  Preferred Experience: (If Applicable):  Recent experience with SQL database management or report development (Power BI, Analytical, R, Python, Visual Studio and /or SSRS) preferred \n  License/Certification: Certification required for High School and Associates degree. \n  Preferred Experience: (If Applicable):  Applicable certification(s) including Microsoft data systems certifications CSTP, ISTQB, ASTQB, MTA, MCSA, MCSD, MCSE, ITIL v3, Power BI, as well as INFORMS, IIBA, AWS, Azure, or equivalent certifications will be accepted \n  Must have a valid driver\u2019s license \n  Location: Remote with offices available in Greenville or Wilmington, NC \n  Deadline for application: Friday, September 22, 2023 at 11:59 p.m. \n  To be considered for employment, all candidates are required to submit an application through ADP and upload a current resume.  Your resume must provide your level of education and detailed work experience, including: \n \n  Employer Name\n        \n  Dates of service (month & year) \n  Average number of hours worked per week \n  Essential duties of the job as related to the position you\u2019re applying for \n \n  Education\n        \n  Degree type \n  Date degree was awarded \n  Institution \n \n  Licensure/certification, if applicable \n \n  After submitting your application through our career center in ADP, your resume will be reviewed to ensure that your skills and experience meet the essential criteria for the role you have applied for. \n  The diversity of the communities we serve is reflected in our employees. Trillium Health Resources is an Equal Employment Opportunity (EEO) employer. \n  Trillium Health Resources is a drug-free workplace. Candidates are required to pass a drug test as a condition of employment. \n  #Innovation #Technology #Careers #NorthCarolina #BehavioralHealth",
        "cleaned_desc": "  Education:  High School (required certification) / Associate\u2019s degree Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, or Human Service field. Requires Certification \n \n  Experience:  High School diploma and three (3) years\u2019 experience in any of the following areas: Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, Human Service field, healthcare claims environment, reporting development, n-tier and web-based system development or support with strong technical knowledge in the specialized areas of application system programming, including software tools such as: SQL Server 2008 R2 or above, SQL, Oracle, NoSQL, MySQL, TFS (Team Foundation Server), Microsoft IIS and Microsoft .NET framework2.0 or above , Source Control, SSRS, SSIS, SSAS, SSMS, Visual Studio BIDS, Visual Studio 2008 or above, C#. Requires certification. Applicable certification(s) may be substituted to equivalent degree and experience requirements.\n      \n \n  OR \n \n \n       Associate\u2019s degree and a minimum one (1) year experience in any of the following areas: Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, Human Service field, healthcare claims environment, reporting development, n-tier and web-based system development or support with strong technical knowledge in the specialized areas of application system programming, including software tools such as: SQL Server 2008 R2 or above, SQL, Oracle, NoSQL, MySQL, TFS (Team Foundation Server), Microsoft IIS and Microsoft .NET framework2.0 or above , Source Control, SSRS, SSIS, SSAS, SSMS, Visual Studio BIDS, Visual Studio 2008 or above, C#. Requires certification. Applicable certification(s) may be substituted to equivalent degree and experience requirements.\n      \n \n  OR \n  Equivalent combination of education/experience \n  Preferred Experience: (If Applicable):  Recent experience with SQL database management or report development (Power BI, Analytical, R, Python, Visual Studio and /or SSRS) preferred \n  License/Certification: Certification required for High School and Associates degree. \n  Preferred Experience: (If Applicable):  Applicable certification(s) including Microsoft data systems certifications CSTP, ISTQB, ASTQB, MTA, MCSA, MCSD, MCSE, ITIL v3, Power BI, as well as INFORMS, IIBA, AWS, Azure, or equivalent certifications will be accepted \n  Must have a valid driver\u2019s license \n  Location: Remote with offices available in Greenville or Wilmington, NC \n  Deadline for application: Friday, September 22, 2023 at 11:59 p.m. ",
        "techs": [
            "sql server 2008 r2",
            "sql",
            "oracle",
            "nosql",
            "mysql",
            "tfs (team foundation server)",
            "microsoft iis",
            "microsoft .net framework2.0",
            "source control",
            "ssrs",
            "ssis",
            "ssas",
            "ssms",
            "visual studio bids",
            "visual studio 2008",
            "c#",
            "power bi",
            "analytical",
            "r",
            "python",
            "cstp",
            "istqb",
            "astqb",
            "mta",
            "mcsa",
            "mcsd",
            "mcse",
            "itil v3",
            "informs",
            "iiba",
            "aws",
            "azure"
        ],
        "cleaned_techs": [
            "sql",
            "oracle",
            "nosql",
            "mysql",
            "tfs (team foundation server)",
            "microsoft iis",
            "microsoft .net framework2.0",
            "source control",
            "ssrs",
            "ssis",
            "ssas",
            "ssms",
            "visual studio bids",
            "visual studio 2008",
            "c#",
            "powerbi",
            "analytical",
            "r",
            "python",
            "cstp",
            "istqb",
            "astqb",
            "mta",
            "mcsa",
            "mcsd",
            "mcse",
            "itil v3",
            "informs",
            "iiba",
            "aws",
            "azure"
        ]
    },
    "8fd25c8c117e6177": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 89000.0,
        "salary_max": 135000.0,
        "title": "Data Engineer (Remote a Possibility)",
        "company": "Tri Counties Bank",
        "desc": "The hiring range for this opportunity is $89,000 - $135,000 annually along with incentive opportunities, creating a competitive total compensation package based on our pay scale, and may be modified by location and is commensurate with qualifications and experience. \n  POSITION SUMMARY \n  The Data Engineer manages the entire back-end development life cycle for the Bank\u2019s data warehouse. The implementation of Extract, Transform, Load (ETL) procedures, cube building for database and performance management, and dimensional design of the table structure are all tasks that fall under the purview of the Data Engineer. The position collaborates closely with the Product Management, other Data Engineers, and Analyst teams to achieve insights, provide the organization with valuable data solutions, and enable reliably informed strategic decisions. Data Engineers must be able to work independently on projects with little oversight from senior leadership. They also need strong communication skills and effectively convey their ideas to senior leadership and other members of the team. \n  MAJOR RESPONSIBILITIES \n \n Create data models used to extract information from various sources and store it in a usable format. \n \n \n Maintain data integrity by designing backup and recovery procedures. \n \n \n Identify opportunities to enhance performance by improving database structure or indexing methods. \n \n \n Conduct research to identify new technologies that can be applied to current projects. \n \n \n Deliver reports, dashboards, and custom solutions for various business lines\u2019 critical requirements. \n \n \n Lead all aspects of data engineering from delivery planning, estimating and analysis, all the way through to data architecture and pipeline design, delivery, and production implementation. \n \n \n Analyze data to find patterns or insights that can be used to develop strategies or make business decisions. \n \n \n Develop new dashboards using existing data sets to create new products or improve existing services. \n \n \n Maintain existing applications by updating existing code or adding new features to meet new requirements. \n \n \n Design and implement security measures to protect data from unauthorized access or misuse. \n \n \n Recommend infrastructure changes to improve storage capacity or performance. \n \n \n Analyze and organize raw data, build data systems and pipelines. \n \n \n Evaluate business needs, objectives, interpret trends and patterns. \n \n \n Conduct complex data analysis and report on results. \n \n \n Prepare data for prescriptive and predictive modeling. \n \n \n Build algorithms and prototypes. \n \n \n Combine raw information from different sources. \n \n \n Explore ways to enhance data quality and reliability. \n \n \n Identify opportunities for data acquisition. \n \n \n Collaborate with data analysts and architects on several projects. \n \n \n Contribute and maintain a data dictionary. \n \n  SECONDARY RESPONSIBILITIES \n \n Maintain a current understanding of stated procedures and policies, including regulatory compliance issues as it relates to all pertinent FDIC, DFPI, and other Federal security regulations related to Data Governance and Data Security. \n \n \n Maintain a current understanding of Bank policies and procedures in compliance with all federal and state laws, including but not limited to Bank Secrecy Act (SARs, CIP, OFAC), Information Security (GLBA), Privacy Laws (CCPA), Identity Theft Red Flags, Financial Elder Abuse Reporting, and any other applicable regulations that may be specific to your job duties. \n \n \n Understand data privacy and data security concepts and experience with delivering data-related projects. \n \n \n Ability to communicate across disciplines (ex. security, privacy, legal, risk). \n \n  OTHER RESPONSIBILITIES \n \n Firm understanding of Data Governance, specifically in the banking and financial sector. \n \n \n Review, comprehend and maintain a current knowledge of all applicable laws, rules and regulations governing assigned area of responsibility. \n \n \n Extensive experience managing corporate data warehouse programs within medium to large organizations. \n \n \n Knowledge of evolving and current threats including Cyber terrorism. \n \n \n Maintain confidentiality regarding all customer and employee information. \n \n \n Perform other duties as assigned. \n \n  EDUCATION, EXPERIENCE AND OTHER SKILLS REQUIRED \n \n Bachelor\u2019s degree in Information Security, Information Technology or related field, strongly preferred. \n \n \n 5+ years of proven data and performance engineering experience. \n \n \n Expert in SQL. \n \n \n Python experience \n \n \n Snowflake experience (developing ETL pipelines) \n \n \n Data Bricks experience \n \n \n Writing Workflows and Notebooks in python/scala/sql \n \n \n Knowledge of AWS \n \n \n A proven track record of developing custom-built data/analytics solutions and experience in supporting large scale programs. \n \n \n Experience with system analysis, data analysis or programming, using a variety of computer languages and procedures. \n \n \n Experience working in Agile environments. \n \n \n Banking experience strongly preferred. \n \n \n Experience leading complex regulatory projects. \n \n \n Experience across multiple bank departments desired. \n \n \n Knowledge of laws and regulations impacting data protection and confidentiality, integrity, and availability of systems and data in the financial industry such as Sarbanes-Oxley, and state regulations. \n \n \n Effective interpersonal skills with the ability to work effectively with individuals and groups at all organizational levels. \n \n \n Leadership ability to provide guidance, coaching and training to staff and to other Bank employees. \n \n \n Ability to take initiative and prioritize tasks, good time-management, problem prevention and problem-solving skills. \n \n \n Proven track record of success demonstrating leadership and management skills. \n \n \n Effective verbal and written communication skills, including presentation skills. \n \n  COMPANY PROFILE \n  Established in 1975, Tri Counties Bank is a wholly-owned subsidiary of TriCo Bancshares (NASDAQ: TCBK) headquartered in Chico, California, with assets of nearly $10 billion and more than 45 years of financial stability. Tri Counties Bank provides a unique brand of Service With Solutions\u00ae for communities throughout California with a breadth of personal, small business and commercial banking services, plus an extensive branch network, more than 37,000 surcharge-free ATMs nationwide, and advanced online and mobile banking. \n  Tri Counties Bank remains strong and profitable through our top-down commitment to our core values, sound business principles and responsible lending practices. \n  Our success is also based on our community engagement. We still believe in the vision of the helpful and caring community banker. As we grow and serve more communities, we become more involved, providing substantial financial and volunteer support to local economies and community organizations. We applaud our employees who roll up their sleeves to work and volunteer for a greater good in our communities. \n  Tri Counties Bank hires individuals who are qualified for the role and who represent the communities in which we serve. We look to place people in positions where they can best utilize their abilities and strengths, and where they are able to grow with the Bank. \n  Tri Counties Bank is an Affirmative Action and Equal Opportunity Employer, Race/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability/Veteran.",
        "cleaned_desc": "The hiring range for this opportunity is $89,000 - $135,000 annually along with incentive opportunities, creating a competitive total compensation package based on our pay scale, and may be modified by location and is commensurate with qualifications and experience. \n  POSITION SUMMARY \n  The Data Engineer manages the entire back-end development life cycle for the Bank\u2019s data warehouse. The implementation of Extract, Transform, Load (ETL) procedures, cube building for database and performance management, and dimensional design of the table structure are all tasks that fall under the purview of the Data Engineer. The position collaborates closely with the Product Management, other Data Engineers, and Analyst teams to achieve insights, provide the organization with valuable data solutions, and enable reliably informed strategic decisions. Data Engineers must be able to work independently on projects with little oversight from senior leadership. They also need strong communication skills and effectively convey their ideas to senior leadership and other members of the team. \n  MAJOR RESPONSIBILITIES \n \n Create data models used to extract information from various sources and store it in a usable format. \n \n \n Maintain data integrity by designing backup and recovery procedures. \n \n \n Identify opportunities to enhance performance by improving database structure or indexing methods. \n \n \n Conduct research to identify new technologies that can be applied to current projects. \n \n \n Deliver reports, dashboards, and custom solutions for various business lines\u2019 critical requirements. \n \n \n Lead all aspects of data engineering from delivery planning, estimating and analysis, all the way through to data architecture and pipeline design, delivery, and production implementation. \n \n \n Analyze data to find patterns or insights that can be used to develop strategies or make business decisions. \n \n \n Develop new dashboards using existing data sets to create new products or improve existing services. \n \n \n Maintain existing applications by updating existing code or adding new features to meet new requirements. \n \n \n Design and implement security measures to protect data from unauthorized access or misuse.   \n \n Recommend infrastructure changes to improve storage capacity or performance. \n \n \n Analyze and organize raw data, build data systems and pipelines. \n \n \n Evaluate business needs, objectives, interpret trends and patterns. \n \n \n Conduct complex data analysis and report on results. \n \n \n Prepare data for prescriptive and predictive modeling. \n \n \n Build algorithms and prototypes. \n \n \n Combine raw information from different sources. \n \n \n Explore ways to enhance data quality and reliability. \n \n \n Identify opportunities for data acquisition. \n \n \n Collaborate with data analysts and architects on several projects. \n \n \n Contribute and maintain a data dictionary.    EDUCATION, EXPERIENCE AND OTHER SKILLS REQUIRED \n \n Bachelor\u2019s degree in Information Security, Information Technology or related field, strongly preferred. \n \n \n 5+ years of proven data and performance engineering experience. \n \n \n Expert in SQL. \n \n \n Python experience \n \n \n Snowflake experience (developing ETL pipelines) \n \n \n Data Bricks experience \n \n \n Writing Workflows and Notebooks in python/scala/sql \n \n \n Knowledge of AWS \n \n \n A proven track record of developing custom-built data/analytics solutions and experience in supporting large scale programs. \n \n \n Experience with system analysis, data analysis or programming, using a variety of computer languages and procedures. \n \n \n Experience working in Agile environments. ",
        "techs": [
            "the hiring range for this opportunity is $89,000 - $135,000 annually along with incentive opportunities",
            "creating a competitive total compensation package based on our pay scale",
            "and may be modified by location and is commensurate with qualifications and experience.\nposition summary\nthe data engineer manages the entire back-end development life cycle for the bank\u2019s data warehouse. the implementation of extract",
            "transform",
            "load (etl) procedures",
            "cube building for database and performance management",
            "and dimensional design of the table structure are all tasks that fall under the purview of the data engineer. the position collaborates closely with the product management",
            "other data engineers",
            "and analyst teams to achieve insights",
            "provide the organization with valuable data solutions",
            "and enable reliably informed strategic decisions. data engineers must be able to work independently on projects with little oversight from senior leadership. they also need strong communication skills and effectively convey their ideas to senior leadership and other members of the team.\nmajor responsibilities\ncreate data models used to extract information from various sources and store it in a usable format.\nmaintain data integrity by designing backup and recovery procedures.\nidentify opportunities to enhance performance by improving database structure or indexing methods.\nconduct research to identify new technologies that can be applied to current projects.\ndeliver reports",
            "dashboards",
            "and custom solutions for various business lines\u2019 critical requirements.\nlead all aspects of data engineering from delivery planning",
            "estimating and analysis",
            "all the way through to data architecture and pipeline design",
            "delivery",
            "and production implementation.\nanalyze data to find patterns or insights that can be used to develop strategies or make business decisions.\ndevelop new dashboards using existing data sets to create new products or improve existing services.\nmaintain existing applications by updating existing code or adding new features to meet new requirements.\ndesign and implement security measures to protect data from unauthorized access or misuse.\nrecommend infrastructure changes to improve storage capacity or performance.\nanalyze and organize raw data",
            "build data systems and pipelines.\nevaluate business needs",
            "objectives",
            "interpret trends and patterns.\nconduct complex data analysis and report on results.\nprepare data for prescriptive and predictive modeling.\nbuild algorithms and prototypes.\ncombine raw information from different sources.\nexplore ways to enhance data quality and reliability.\nidentify opportunities for data acquisition.\ncollaborate with data analysts and architects on several projects.\ncontribute and maintain a data dictionary. education",
            "experience and other skills required\nbachelor\u2019s degree in information security",
            "information technology or related field",
            "strongly preferred.\n5+ years of proven data and performance engineering experience.\nexpert in sql.\npython experience\nsnowflake experience (developing etl pipelines)\ndata bricks experience\nwriting workflows and notebooks in python/scala/sql\nknowledge of aws\na proven track record of developing custom-built data/analytics solutions and experience in supporting large scale programs.\nexperience with system analysis",
            "data analysis or programming",
            "using a variety of computer languages and procedures.\nexperience working in agile environments.\n\nspecific tools and technologies:\n- sql\n- python\n- snowflake\n- data bricks\n- aws"
        ],
        "cleaned_techs": [
            "the hiring range for this opportunity is $89,000 - $135,000 annually along with incentive opportunities",
            "creating a competitive total compensation package based on our pay scale",
            "and may be modified by location and is commensurate with qualifications and experience.\nposition summary\nthe data engineer manages the entire back-end development life cycle for the bank\u2019s data warehouse. the implementation of extract",
            "transform",
            "load (etl) procedures",
            "cube building for database and performance management",
            "and dimensional design of the table structure are all tasks that fall under the purview of the data engineer. the position collaborates closely with the product management",
            "other data engineers",
            "provide the organization with valuable data solutions",
            "dashboards",
            "and custom solutions for various business lines\u2019 critical requirements.\nlead all aspects of data engineering from delivery planning",
            "estimating and analysis",
            "all the way through to data architecture and pipeline design",
            "delivery",
            "build data systems and pipelines.\nevaluate business needs",
            "objectives",
            "information technology or related field",
            "strongly preferred.\n5+ years of proven data and performance engineering experience.\nexpert in sql.\npython experience\nsnowflake experience (developing etl pipelines)\ndata bricks experience\nwriting workflows and notebooks in python/scala/sql\nknowledge of aws\na proven track record of developing custom-built data/analytics solutions and experience in supporting large scale programs.\nexperience with system analysis",
            "data analysis or programming",
            "using a variety of computer languages and procedures.\nexperience working in agile environments.\n\nspecific tools and technologies:\n- sql\n- python\n- snowflake\n- data bricks\n- aws"
        ]
    },
    "e835776adc86650b": {
        "terms": [
            "data engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Software Engineer Manager, Data Analytics (Remote)",
        "company": "Home Depot / THD",
        "desc": "Position Purpose: \n  As a Software Engineer Manager, you will be given a chance to contribute to the products we create and help grow the next generation of engineering talent.  In addition, you will be given the chance to work with our most strategic vendors to ensure that 3rd party tools and applications are readily available to all product teams that are interested in using them. \n \n Key Responsibilities: \n \n   \n  30% Delivery & Execution:\n   \n \n  Collaborates and pairs with product team members (UX, engineering, and product management) to create secure, reliable, scalable software solutions \n  Documents, reviews and ensures that all quality and change control standards are met \n  Writes custom code or scripts to automate infrastructure, monitoring services, and test cases \n  Works with vendors and partners for the successful implementation of critical tooling and platforms \n  Creates meaningful dashboards, logging, alerting, and responses to ensure that issues are captured and addressed proactively \n  Contributes to enterprise-wide tools to drive destructive testing, automation, and engineering empowerment \n  Evaluates new technologies for adoption across the enterprise \n  Participates in and leads review board sessions to drive consistency across the enterprise \n  Fills in on product teams for engineers who are out of the office \n  10% Support & Enablement:\n   \n \n  Fields questions from engineers, product teams, or support teams \n  Monitors tools and participates in conversations to encourage collaboration across product teams \n  Provides application support for software running in production \n  Acts as a technical escalation point for the engineers on the team \n  50% People:\n   \n \n  Provides leadership, mentoring, and coaching to Software Engineers \n  Attracts, retains, and develops top talent to build a world class Software Engineering Team \n  Conducts annual and mid-year reviews by reviewing individual development plans and team feedback \n  Fosters collaboration with team members to drive consistency across product teams, and finds opportunities to expose engineers to career interests \n  Acts as a proponent of modern software development practices \n  Guides team members in strategy, alignment, analysis, and execution tasks within and across product teams \n  Participates in and contributes to learning activities around modern software design and development core practices (communities of practice) \n  10% Learning:\n   \n \n  Learns, through reading, tutorials, and videos, new technologies and best practices being used within other technology organizations \n  Builds relationships with technology leaders at other companies to learn best practices and elegant solutions to common problems \n \n \n Direct Manager/Direct Reports: \n \n  Typically reports to the Software Engineer Sr. Manager, Technology Director or Sr. Director. \n \n \n Travel Requirements: \n \n  Typically requires overnight travel 5% to 20% of the time. \n \n \n Physical Requirements: \n \n  Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles. \n \n \n Working Conditions: \n \n  Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable. \n \n \n \n \n Minimum Qualifications: \n \n  Must be eighteen years of age or older. \n  Must be legally permitted to work in the United States. \n  Mastery of an object oriented programming language (preferably Java) \n  Must be legally permitted to work in the United States \n \n \n Preferred Qualifications: \n \n  5-7 years of relevant work experience \n  Experience with Cloud technologies such as GCP. \n  Mastery of a modern scripting language (preferably Python) \n  Mastery of a modern web application framework such as Ruby on Rails, Spring MVC, and Node.js \n  Mastery of writing SQL queries against a relational database \n  Mastery of modern product development processes and pipelines \n  Proficient in effective troubleshooting and issue resolution techniques \n  Proficient in effective system monitoring and log analysis techniques \n  Capable of understanding complicated systems quickly \n  Experience in guiding more junior team members through Software Engineering fundamentals in a professional setting \n  Experience managing and growing team members in a professional setting \n  Experience balancing workloads across teams \n  Experience managing vendor relationships \n  Experience with translating high level strategy to tactical execution \n \n \n Minimum Education: \n \n  The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job. \n \n \n Preferred Education: \n \n  No additional education \n \n \n Minimum Years of Work Experience: \n \n  5 \n \n \n Preferred Years of Work Experience: \n \n  No additional years of experience \n \n \n Minimum Leadership Experience: \n \n  None \n \n \n Preferred Leadership Experience: \n \n  None \n \n \n Certifications: \n \n  None \n \n \n Competencies: \n \n  Attracts Top Talent: Attracting and selecting the best talent to meet current and future business needs \n  Balances Stakeholders: Anticipating and balancing the needs of multiple stakeholders \n  Builds Effective Teams: Building strong-identity teams that apply their diverse skills and perspectives to achieve common goals \n  Business Insight: Applying knowledge of business and the marketplace to advance the organization's goals \n  Collaborates: Building partnerships and working collaboratively with others to meet shared objectives \n  Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences \n  Develops Talent: Developing people to meet both their career goals and the organization's goals \n  Drives Engagement: Creating a climate where people are motivated to do their best to help the organization achieve its objectives \n  Drives Vision and Purpose: Painting a compelling picture of the vision and strategy that motivates others to action \n  Manages Ambiguity: Operating effectively, even when things are not certain or the way forward is not clear \n  Organizational Savvy: Maneuvering comfortably through complex policy, process, and people-related organizational dynamics \n  Situational Adaptability: Adapting approach and demeanor in real time to match the shifting demands of different situations",
        "cleaned_desc": "  Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles. \n \n \n Working Conditions: \n \n  Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable. \n \n \n \n \n Minimum Qualifications: \n \n  Must be eighteen years of age or older. \n  Must be legally permitted to work in the United States. \n  Mastery of an object oriented programming language (preferably Java) \n  Must be legally permitted to work in the United States \n \n \n Preferred Qualifications: \n \n  5-7 years of relevant work experience \n  Experience with Cloud technologies such as GCP. \n  Mastery of a modern scripting language (preferably Python) \n  Mastery of a modern web application framework such as Ruby on Rails, Spring MVC, and Node.js \n  Mastery of writing SQL queries against a relational database \n  Mastery of modern product development processes and pipelines \n  Proficient in effective troubleshooting and issue resolution techniques ",
        "techs": [
            "java",
            "gcp",
            "python",
            "ruby on rails",
            "spring mvc",
            "node.js",
            "sql"
        ],
        "cleaned_techs": [
            "java",
            "gcp",
            "python",
            "ruby on rails",
            "spring mvc",
            "node.js",
            "sql"
        ]
    },
    "7f7feb940f422621": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105300.0,
        "salary_max": 190350.0,
        "title": "Data Center Facilities Engineer",
        "company": "Leidos",
        "desc": "Description   \n \n Leidos is hiring a  Data Center Facilities Engineer  at Ft. Meade, MD. \n \n  POSITION SUMMARY:  The selected candidate will be part of the Defense Enclave Services (DES) team to lead data collection, design, and implementation of tasks associated with the management of: cable plant, floor space, heating and cooling, and physical data center security. This engineer will establish the key data points that are inputs to migration planning efforts, and collect the predefined information through documents, site surveys, and customer interviews. Using the data collected the engineer will create migration plans that include technical designs and a schedule of migration tasks. \n \n \n  CLEARANCE REQUIREMENT :\n   \n \n Must hold an active Secret clearance prior to start. (US Citizenship required) \n \n \n \n  PRIMARY RESPONSIBILITIES: \n \n  Evaluate, design, and deploy the central components of data center facilities, including: power, cooling, physical security, floor space management, and cable management. \n  Define monitoring and management requirements. \n  Providing professional engineering advice to facility technicians, including design, planning, specifications, and operation of electrical and mechanical equipment, HVAC systems design and operation, as well as structural and architectural considerations in field locations. \n  Providing guidance and recommendations to government management regarding engineering and facilities issues. \n  Working in close collaboration with Network Engineers, Server Engineers, Cyber Engineers, Storage Engineers, Data Experts, and other key technical resources. \n  Identify procurement and tracking of maintenance materials, safety supplies, and spare components. \n  Ensuring compliance with all applicable building codes and standards. \n  Maintaining the inventory of buildings and installed systems, and establishing maintenance and replacement cycles. \n  Performing facility condition assessments. \n  Developing and proposing facility upgrade and replacement projects. \n  Possess strong soft skills in the form of documentation and client communications. \n  Able to perform physical activities including heavy lifting, climbing in and out of equipment, crawling, and working outdoors in cold, dry, high elevation environments. \n \n \n  BASIC QUALIFICATIONS: \n \n  Bachelor\u2019s Degree and 12+ years of prior relevant experience; additional years of experience may be substituted in lieu of a degree. \n  Possess professional knowledge of Architectural, structural, mechanical, electrical, and fire protection engineering concepts and principles. \n  Experience in asset reliability centered maintenance strategies that target preventive/predictive maintenance. \n  Communicate effectively, both orally and in writing, with management and staff to present, defend, negotiate, and clarify programs, decisions and recommendations. \n  Field construction experience including managing changes, quality control, deliverables, redlining drawings, and other activities supporting work completion. \n  Experience with procurement and material tracking. \n  Current United States Passport, and valid Driver\u2019s License issued in the United States. \n  Proactively identify any unsafe conditions or hazards and communicate them effectively. \n  Complies with applicable safety, environment, health, and waste management policies and procedure. \n \n \n \n  PREFERRED QUALIFICATIONS: \n \n \n Experience with resource loaded scheduling. \n Experience with fire safety systems including fire alarm systems and suppression. \n Experience with Data Center Infrastructure Management solutions. \n \n \n \n  DISADES \n  External Referral Eligible \n \n  Pay Range:  Pay Range $105,300.00 - $190,350.00\n  \n  The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law. \n  #Remote",
        "cleaned_desc": "  PREFERRED QUALIFICATIONS: \n \n \n Experience with resource loaded scheduling. \n Experience with fire safety systems including fire alarm systems and suppression. \n Experience with Data Center Infrastructure Management solutions. \n \n \n \n  DISADES \n  External Referral Eligible ",
        "techs": [
            "resource loaded scheduling",
            "fire alarm systems",
            "suppression",
            "data center infrastructure management solutions"
        ],
        "cleaned_techs": [
            "resource loaded scheduling",
            "fire alarm systems",
            "suppression",
            "data center infrastructure management solutions"
        ]
    },
    "095cee836bb3bb14": {
        "terms": [
            "data engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Senior Software Engineer in Data, Game Creation",
        "company": "Electronic Arts",
        "desc": "Electronic Arts Inc. is a global leader in interactive entertainment. We develop and deliver games, content and online services across platforms. We have a broad portfolio of brands that span the most popular genres. \n We exist to Inspire the World to Play. We create extraordinary new game experiences for our millions of players everywhere by bringing together accomplished people that combine creativity, innovation, and passion. We immerse our employees into an inclusive culture and provide opportunities for learning and leading that allow our employees to do the most impactful and rewarding work of their careers. Join us in driving the next revolution in games.. \n The Challenge Ahead \n This technical role in the Game Creation team reports to an Engineering Manager, and you can be fully remote in the US. It involves envisioning, designing, and building enterprise-level solutions for EA's video games and central services teams. You'll create architectures integrating custom, COTS, and packaged applications, and work with products like JIRA, Perforce, and GitLab. Our cloud-first approach uses Azure and AWS, and you'll lead agile teams supporting thousands of users across game teams like FIFA, Madden, Battlefield, and central teams like Frostbite and Origin \n Key Responsibilities \n \n You will address complex challenges and create solutions using the latest Game Creation products to empower game creators \n You will be a Game Creation product SME, comprehending business intricacies, collaborating with teams, and enriching the game development experience using our Azure data platform. \n You will lead data insights by identifying patterns, correlations, and trends for impactful reports and visualizations. \n \n Job qualifications and requirements \n \n 5+ years of experience managing and serving as an SDLC/ALM tools SME for products such as JIRA, Gitlab, Perforce, Artifactory, Azure DevOps, Jenkins; more tools = stronger candidate. \n 5+ years of experience using the mentioned SDLC/ALM tools for data analysis, monitoring, and reporting. \n 5+ years of experience working with .NET, including .NET Core, C#, ASP.NET, JavaScript, REST. \n 5+ years of experience in database development, queries, and ETL processes. \n 3+ years of experience with Azure, including VMs, Networks, Azure Data Factory, Azure Data Lake, Azure Data Explorer, Bicep, and Logic Apps \n 3+ years of experience identifying data patterns, correlations, and trends, constructing reports, dashboards, analytics and visualizations \n 3+ years of experience with PowerBI constructing reports, dashboards, analytics and visualizations \n \n Bonus Requirements \n \n Azure Synapse, Fabric \n Terraform \n Docker and Kubernetes \n AWS \n Tableau \n Python \n \n US COMPENSATION AND BENEFITS \n The base salary ranges listed below are for the defined geographic market pay zones in these states. If you reside outside of these locations, a recruiter will advise on the base salary range and benefits for your specific location. EA has listed the base salary ranges it in good faith expects to pay applicants for this role in the locations listed, as of the time of this posting. Salary offered will be determined based on numerous relevant business and candidate factors including, for example, education, qualifications, certifications, experience, skills, geographic location, and business or organizational needs. \n BASE SALARY RANGES \n \n California (depending on location e.g. Los Angeles vs. Sacramento): $149,150 - $233,500 \n New York (depending on location e.g. Manhattan vs. Buffalo): $136,000 - $233,500 \n Jersey City, NJ: $171,100 - $233,500 \n Colorado (depending on location e.g. Denver vs. Colorado Springs):$136,000 - $190,850 \n Washington (depending on location e.g. Seattle vs. Spokane): $136,000 - $218,900 \n \n Base salary is just one part of the overall compensation at EA. We also offer a package of benefits including paid time off (3 weeks per year to start), 80 hours per year of sick time, 16 paid company holidays per year, 10 weeks paid time off to bond with baby, medical/dental/vision insurance, life insurance, disability insurance, and 401(k) to regular full-time employees. Certain roles may also be eligible for bonus and equity. \n #LI-Remote, #LI-Hybrid, #LI-Onsite #FlexibleWork \n \n  We are a global team of creators, storytellers, technologists, experience originators, innovators and so much more. We believe amazing games and experiences start with teams as diverse as the players and communities we serve. At Electronic Arts, the only limit is your imagination.",
        "cleaned_desc": " You will lead data insights by identifying patterns, correlations, and trends for impactful reports and visualizations. \n \n Job qualifications and requirements \n \n 5+ years of experience managing and serving as an SDLC/ALM tools SME for products such as JIRA, Gitlab, Perforce, Artifactory, Azure DevOps, Jenkins; more tools = stronger candidate. \n 5+ years of experience using the mentioned SDLC/ALM tools for data analysis, monitoring, and reporting. \n 5+ years of experience working with .NET, including .NET Core, C#, ASP.NET, JavaScript, REST. \n 5+ years of experience in database development, queries, and ETL processes.   3+ years of experience with Azure, including VMs, Networks, Azure Data Factory, Azure Data Lake, Azure Data Explorer, Bicep, and Logic Apps \n 3+ years of experience identifying data patterns, correlations, and trends, constructing reports, dashboards, analytics and visualizations \n 3+ years of experience with PowerBI constructing reports, dashboards, analytics and visualizations \n \n Bonus Requirements \n \n Azure Synapse, Fabric \n Terraform ",
        "techs": [
            "jira",
            "gitlab",
            "perforce",
            "artifactory",
            "azure devops",
            "jenkins",
            ".net",
            ".net core",
            "c#",
            "asp.net",
            "javascript",
            "rest",
            "azure",
            "vms",
            "networks",
            "azure data factory",
            "azure data lake",
            "azure data explorer",
            "bicep",
            "logic apps",
            "powerbi",
            "azure synapse",
            "fabric",
            "terraform"
        ],
        "cleaned_techs": [
            "jira",
            "gitlab",
            "perforce",
            "artifactory",
            "azure",
            "jenkins",
            ".net",
            ".net core",
            "c#",
            "asp.net",
            "javascript",
            "rest",
            "vms",
            "networks",
            "bicep",
            "logic apps",
            "powerbi",
            "fabric",
            "terraform"
        ]
    },
    "9cbc14853500de1b": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105336.664,
        "salary_max": 133379.69,
        "title": "Experienced Civil Engineer - Data Center (Remote)",
        "company": "Olsson",
        "desc": "Company Description\n   We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible. \n  Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u2014 and will continue to allow us \u2014 to grow. The result? Inspired people, amazing designs, and projects with purpose. \n \n \n \n Job Description\n   Olsson provides multidisciplinary design services for some of the largest and most forward-thinking and desirable companies in the world to work for. The large hyperscale data center campuses we design throughout the U.S. will give you the opportunity to work on some of the largest and most complex engineering-driven projects being built today. Our clients are relationship based and truly value the work we do for them, affording us the opportunity to contribute to society\u2019s technological and connected community through the design of the critical infrastructure that is the foundation of these projects. \n  As an engineer on our Data Center Civil Team, you will be a part of the firm\u2019s largest and most complex projects. You will serve as a project manager on some projects and lead design engineer on others. Prepare planning and design documents, process design calculations, and develop and maintain team and client standards. You may lead quality assurance/quality control and act as an advisor on complex projects. You will also coordinate with other Olsson teams, professional staff, technical staff, clients, and other consultants. \n  You may travel to job sites for observation and attend client meetings. \n \n Olsson currently has  one opportunity  for an Experienced Engineer. This role offers flexible work options, including remote and hybrid opportunities, to accommodate diverse working preferences and promote work-life balance. Candidates can live in Lincoln, Omaha, Phoenix, Chandler, or Dallas-Fort Worth area and work remotely, or work out of any Olsson office location in these regions/areas. \n \n \n \n \n Qualifications\n   You are passionate about: \n \n  Working collaboratively with others \n  Having ownership in the work you do \n  Using your talents to positively affect communities \n  Solving problems \n  Providing excellence in client service \n \n  You bring to the team: \n \n  Strong communication skills \n  Ability to contribute and work well on a team \n  Bachelor's Degree in civil engineering \n  At least 6 years of related civil engineering experience \n  Proficient in Civil 3D software \n  Must be a registered professional engineer \n \n  Additional Information\n   Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u2019re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it. \n  As an Olsson employee, you\u2019ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u2019ll: \n \n  Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP) \n  Engage in work that has a positive impact in communities \n  Receive an excellent 401(k) match \n  Participate in a wellness program promoting balanced lifestyles \n  Benefit from a bonus system that rewards performance \n  Have the possibility for flexible work arrangements \n \n  Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status. \n  #LI-LA1 \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "9d24ab0c1846eccf": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 111447.02,
        "salary_max": 141116.77,
        "title": "Senior Civil Engineer - Data Center (Remote)",
        "company": "Olsson",
        "desc": "Company Description\n   We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible. \n  Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u2014 and will continue to allow us \u2014 to grow. The result? Inspired people, amazing designs, and projects with purpose. \n \n \n \n Job Description\n   Olsson provides multidisciplinary design services for some of the largest and most forward-thinking and desirable companies in the world to work for. The large hyperscale data center campuses we design throughout the U.S. will give you the opportunity to work on some of the largest and most complex engineering-driven projects being built today. Our clients are relationship based and truly value the work we do for them, affording us the opportunity to contribute to society\u2019s technological and connected community through the design of the critical infrastructure that is the foundation of these projects. \n  As an experienced engineer on our Data Center Civil Team, you will be a part of the firm\u2019s largest and most complex projects. You will serve as a project manager on some projects and lead design engineer on others. Prepare planning and design documents, process design calculations, and develop and maintain team and client standards. You may lead quality assurance/quality control and act as an advisor on complex projects. You will also coordinate with other Olsson teams, professional staff, technical staff, clients, and other consultants. \n  You may travel to job sites for observation and attend client meetings. \n \n Olsson currently has one opportunity for a Senior Civil Engineer. This role offers flexible work options, including remote and hybrid opportunities, to accommodate diverse working preferences and promote work-life balance. Candidates can live in Lincoln, Omaha, Overland Park or Dallas-Fort Worth area and work remotely or work out of any Olsson office location in these regions/areas. \n \n \n \n \n Qualifications\n   You are passionate about: \n \n  Working collaboratively with others \n  Having ownership in the work you do \n  Using your talents to positively affect communities \n  Solving problems \n  Providing excellence in client service \n \n  You bring to the team: \n \n  Strong communication skills \n  Ability to contribute and work well on a team \n  Bachelor's Degree in civil engineering \n  At least 6 years of related civil engineering experience \n  Proficient in Civil 3D software \n  Must be a registered professional engineer \n \n  Additional Information\n   Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u2019re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it. \n  As an Olsson employee, you\u2019ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u2019ll: \n \n  Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP) \n  Engage in work that has a positive impact in communities \n  Receive an excellent 401(k) match \n  Participate in a wellness program promoting balanced lifestyles \n  Benefit from a bonus system that rewards performance \n  Have the possibility for flexible work arrangements \n \n  Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status. \n  #LI-LA1 \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "dad8623d3e0ba005": {
        "terms": [
            "data engineer"
        ],
        "salary_min": 105336.664,
        "salary_max": 133379.69,
        "title": "Licensed Civil Engineer - Data Center (Remote)",
        "company": "Olsson",
        "desc": "Company Description\n   We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible. \n  Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us \u2014 and will continue to allow us \u2014 to grow. The result? Inspired people, amazing designs, and projects with purpose. \n \n \n \n Job Description\n   Olsson provides multidisciplinary design services for some of the largest and most forward-thinking and desirable companies in the world to work for. The large hyperscale data center campuses we design throughout the U.S. will give you the opportunity to work on some of the largest and most complex engineering-driven projects being built today. Our clients are relationship based and truly value the work we do for them, affording us the opportunity to contribute to society\u2019s technological and connected community through the design of the critical infrastructure that is the foundation of these projects. \n  As a Licensed Civil Engineer on our Data Center Civil Team, you will be a part of the firm\u2019s largest and most complex projects. You will serve as a project manager on some projects and lead design engineer on others. Prepare planning and design documents, process design calculations, and develop and maintain team and client standards. You may lead quality assurance/quality control and act as an advisor on complex projects. You will also coordinate with other Olsson teams, professional staff, technical staff, clients, and other consultants. \n  You may travel to job sites for observation and attend client meetings. \n \n Olsson currently has one opportunity for a Licensed Civil Engineer. This role offers flexible work options, including remote and hybrid opportunities, to accommodate diverse working preferences and promote work-life balance. Candidates can live in Lincoln, Omaha, Overland Park, Denver or Dallas-Fort Worth area and work remotely or work out of any Olsson office location in these regions/areas. \n \n \n \n \n Qualifications\n   You are passionate about: \n \n  Working collaboratively with others \n  Having ownership in the work you do \n  Using your talents to positively affect communities \n  Solving problems \n  Providing excellence in client service \n \n  You bring to the team: \n \n  Strong communication skills \n  Ability to contribute and work well on a team \n  Bachelor's Degree in civil engineering \n  At least 6 years of related civil engineering experience \n  Proficient in Civil 3D software \n  Must be a registered professional engineer \n \n  Additional Information\n   Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we\u2019re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it. \n  As an Olsson employee, you\u2019ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you\u2019ll: \n \n  Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP) \n  Engage in work that has a positive impact in communities \n  Receive an excellent 401(k) match \n  Participate in a wellness program promoting balanced lifestyles \n  Benefit from a bonus system that rewards performance \n  Have the possibility for flexible work arrangements \n \n  Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status. \n  #LI-LA1 \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "180d14d250d2c238": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 130000.0,
        "salary_max": 160000.0,
        "title": "Senior Software Engineer",
        "company": "Audigent",
        "desc": "About Audigent \n  Audigent is the leading data activation, curation and identity platform. Audigent's pioneering data platform unlocks the power of privacy-safe, first party data to maximize addressability and monetization of media at scale without using cookies. As one of the industry's first data curation platforms powered by its unique identity suite (Hadron ID\u2122), Audigent is transforming the programmatic landscape with its innovative SmartPMP\u2122, ContextualPMP\u2122 and CognitivePMP\u2122 products, which use artificial intelligence and machine learning to package and optimize consumer-safe data with premium inventory supply at scale. Providing value and performance for the world's largest brands and global media agencies across 100,000+ campaigns each month, Audigent's verified, opt-in data drives monetization for premium publisher and data partners that include: Cond\u00e9 Nast, TransUnion, Warner Music Group, Penske Media, a360 Media, Fandom and many others. For more information, visit www.audigent.com. \n  What is the role? \n  The Senior Engineer will work closely with our engineering and product teams to design, develop, and deploy high-performance applications that power our ad delivery, analytics, and optimization systems. This position is ideal for someone who is passionate about building scalable, efficient, and robust systems in a fast-paced environment. \n  What will you do? \n \n Design and implement low-latency, high-throughput applications to support our real time infrastructure \n Conduct code reviews, architectural discussions, and contribute to team best practices \n Work collaboratively with cross-functional teams to define system specifications and requirements \n Optimize existing systems for scalability, performance, and reliability \n Lead and mentor junior engineers \n Collaborate with the DevOps team for seamless deployment and orchestration of services \n Troubleshoot and resolve system-related issues in a timely manner \n Maintain documentation for system design, algorithms, and APIs \n \n Ideal Requirements \n \n 5+ years of professional experience in back-end development, preferably in an AdTech environment \n Strong proficiency in Golang and/or Rust; expertise in other languages is a plus \n Experience in building distributed, low-latency, and high-throughput systems \n Solid understanding of data structures, algorithms, and software design \n Familiarity with cloud computing platforms (AWS, GCP, or Azure) \n Experience with Infrastructure as Code (IaC) tools like Terraform, Ansible, or similar \n Experience with databases (SQL, NoSQL) and caching solutions \n Excellent communication and teamwork skills \n Strong problem-solving skills and attention to detail \n Experience with version control systems like Git \n \n Nice to Have \n \n Experience in real-time bidding (RTB) and programmatic advertising \n Familiarity with containerization and orchestration tools like Docker and Kubernetes \n Knowledge of CI/CD pipelines and automated testing frameworks \n \n Benefits \n \n Flexible work schedule \n Health, dental, and vision insurance \n 401(k) with company match \n Generous PTO policy \n Professional development opportunities \n \n Total Compensation:  $130,000-$160,000 based on your skills and experience",
        "cleaned_desc": "About Audigent \n  Audigent is the leading data activation, curation and identity platform. Audigent's pioneering data platform unlocks the power of privacy-safe, first party data to maximize addressability and monetization of media at scale without using cookies. As one of the industry's first data curation platforms powered by its unique identity suite (Hadron ID\u2122), Audigent is transforming the programmatic landscape with its innovative SmartPMP\u2122, ContextualPMP\u2122 and CognitivePMP\u2122 products, which use artificial intelligence and machine learning to package and optimize consumer-safe data with premium inventory supply at scale. Providing value and performance for the world's largest brands and global media agencies across 100,000+ campaigns each month, Audigent's verified, opt-in data drives monetization for premium publisher and data partners that include: Cond\u00e9 Nast, TransUnion, Warner Music Group, Penske Media, a360 Media, Fandom and many others. For more information, visit www.audigent.com. \n  What is the role? \n  The Senior Engineer will work closely with our engineering and product teams to design, develop, and deploy high-performance applications that power our ad delivery, analytics, and optimization systems. This position is ideal for someone who is passionate about building scalable, efficient, and robust systems in a fast-paced environment. \n  What will you do? \n \n Design and implement low-latency, high-throughput applications to support our real time infrastructure \n Conduct code reviews, architectural discussions, and contribute to team best practices   \n 5+ years of professional experience in back-end development, preferably in an AdTech environment \n Strong proficiency in Golang and/or Rust; expertise in other languages is a plus \n Experience in building distributed, low-latency, and high-throughput systems \n Solid understanding of data structures, algorithms, and software design \n Familiarity with cloud computing platforms (AWS, GCP, or Azure) \n Experience with Infrastructure as Code (IaC) tools like Terraform, Ansible, or similar \n Experience with databases (SQL, NoSQL) and caching solutions   Excellent communication and teamwork skills \n Strong problem-solving skills and attention to detail \n Experience with version control systems like Git \n \n Nice to Have \n \n Experience in real-time bidding (RTB) and programmatic advertising \n Familiarity with containerization and orchestration tools like Docker and Kubernetes ",
        "techs": [
            "audigent",
            "hadron id\u2122",
            "smartpmp\u2122",
            "contextualpmp\u2122",
            "cognitivepmp\u2122",
            "artificial intelligence",
            "machine learning",
            "cond\u00e9 nast",
            "transunion",
            "warner music group",
            "penske media",
            "a360 media",
            "fandom",
            "golang",
            "rust",
            "aws",
            "gcp",
            "azure",
            "terraform",
            "ansible",
            "sql",
            "nosql",
            "git",
            "docker",
            "kubernetes"
        ],
        "cleaned_techs": [
            "audigent",
            "hadron id\u2122",
            "smartpmp\u2122",
            "contextualpmp\u2122",
            "cognitivepmp\u2122",
            "ai",
            "cond\u00e9 nast",
            "transunion",
            "warner music group",
            "penske media",
            "a360 media",
            "fandom",
            "golang",
            "rust",
            "aws",
            "gcp",
            "azure",
            "terraform",
            "ansible",
            "sql",
            "nosql",
            "git",
            "docker",
            "kubernetes"
        ]
    },
    "c3bd2a7b802ef11e": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 143000.0,
        "salary_max": 204000.0,
        "title": "Software Engineer, OS Frameworks - Reality Labs",
        "company": "Meta",
        "desc": "Reality Labs at Meta is building products that make it easier for people to connect with the ones they love most, enjoy top-notch, wire-free VR, and push the future of computing platforms. We are a team of world-class experts developing and shipping products at the intersection of hardware, software and content.As an OS Frameworks Engineer on the Reality Labs team at Meta, you can help build new, innovative hardware and software that radically redefine the way people work, play and connect. What we build today could one day be the norm. So to be here today is to truly be at the heart of change and the frontier of what's to come. We're the people helping to define the metaverse. We may not have all the answers. But together, we're getting closer.\n  \n \n \n Software Engineer, OS Frameworks - Reality Labs Responsibilities:    \n \n Lead and set direction in how Meta Reality Labs develops its future capabilities to deliver best-in-class VR devices. \n  Develop APIs in the system-level framework layer that allow other layers of the stack to implement compelling and performant use cases. \n  Collaborate with cross-functional teams of partners, product managers and engineers to build an end-to-end solution. \n  Work with Application and Platform teams to debug functional, performance and stability issues across the stack. \n  Build on OS internals. Set technical direction for significant improvements. \n  Uplift coding and design skills on the team through reviews and introduction of best practices. Model behaviors through clean readable code, upfront debug-ability and testability when implementing complex components. \n  Work closely with product management, application software engineers and partners to understand requirements, specify interfaces for new software frameworks, and enhance existing frameworks. \n  Participate in design reviews and code reviews for the team. \n \n \n \n \n Minimum Qualifications:   \n \n  Bachelor degree or equivalent experience in the field of Computer Science, Computer Engineering or a similar field \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n  5+ years of Software development experience \n  3+ years of experience in developing any of the following: Operating Systems, AOSP, Identity, Device management on iOS/Android, Device Security, Android Enterprise \n  Experience with Android, macOS, or Windows internals or frameworks services \n  Experience coding in either C++ or Java \n \n \n \n \n Preferred Qualifications:   \n \n  3+ years experience with any of the following: Android internals, AOSP, Android SDK, Android NDK, Android JNI, Android IPC mechanisms, Linux OS development \n  1+ years of experience developing software for Mobile platforms (Android/iOS) \n  Experience with Android performance tools and security models \n  Experience with Android UI frameworks and services \n \n \n \n \n \n \n \n  Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment. \n   \n  Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",
        "cleaned_desc": "  Work with Application and Platform teams to debug functional, performance and stability issues across the stack. \n  Build on OS internals. Set technical direction for significant improvements. \n  Uplift coding and design skills on the team through reviews and introduction of best practices. Model behaviors through clean readable code, upfront debug-ability and testability when implementing complex components. \n  Work closely with product management, application software engineers and partners to understand requirements, specify interfaces for new software frameworks, and enhance existing frameworks. \n  Participate in design reviews and code reviews for the team. \n \n \n \n   Minimum Qualifications:   \n \n  Bachelor degree or equivalent experience in the field of Computer Science, Computer Engineering or a similar field \n  Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. \n  5+ years of Software development experience \n  3+ years of experience in developing any of the following: Operating Systems, AOSP, Identity, Device management on iOS/Android, Device Security, Android Enterprise \n  Experience with Android, macOS, or Windows internals or frameworks services \n  Experience coding in either C++ or Java \n   \n \n \n Preferred Qualifications:   \n \n  3+ years experience with any of the following: Android internals, AOSP, Android SDK, Android NDK, Android JNI, Android IPC mechanisms, Linux OS development \n  1+ years of experience developing software for Mobile platforms (Android/iOS) \n  Experience with Android performance tools and security models \n  Experience with Android UI frameworks and services ",
        "techs": [
            "os internals",
            "c++",
            "java",
            "android internals",
            "aosp",
            "android sdk",
            "android ndk",
            "android jni",
            "android ipc mechanisms",
            "linux os development"
        ],
        "cleaned_techs": [
            "os internals",
            "c++",
            "java",
            "android internals",
            "aosp",
            "android sdk",
            "android ndk",
            "android jni",
            "android ipc mechanisms",
            "linux os development"
        ]
    },
    "e0fc5ede4dd28400": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 142697.8,
        "salary_max": 180687.2,
        "title": "Senior Software Engineer",
        "company": "Karius",
        "desc": "About Karius \n \n \n     Karius is a venture-backed life science startup focused on transforming the way infectious diseases are diagnosed. Combining Next-Generation Sequencing and proprietary data analysis, we can identify over 1,000 pathogens from a single blood sample with typical turnaround time in one business day. By unlocking the information present in microbial cell-free DNA, we're helping doctors quickly solve their most challenging cases, with a future vision of accelerating clinical trials, discovering new microbes, and reducing patient suffering worldwide.\n    \n \n \n  Position Summary \n \n \n     We are building and operating a unique software stack of cloud infrastructure, software services, APIs, web and mobile interactive interfaces, and AI-driven data analytics pipelines to deliver life-saving results in the highly complex infectious disease landscape. We believe the success of Karius\u2019 products is driven by both our unique technology and the elegance of the software solution. We seek talented and passionate individuals who want to be part of this impactful journey of reaching the team\u2019s ambitious goals, far beyond what any single individual could accomplish.\n    \n \n \n  As a Sr. Software Engineer in this space, your primary focus will be designing, developing and maintaining the backend and LIMS software and infrastructure to execute Karius Lab Diagnostics software in commercial and research setup.\n    \n \n \n  Why Should You Join Us? \n \n \n     Karius core mission is to conquer infectious diseases through innovations around genomic sequencing and machine learning. The company\u2019s platform is already delivering unprecedented insight into the microbial landscape, providing clinicians with a comprehensive test capable of identifying more than a thousand pathogens directly from blood. Through this journey, we realized that the microbial cell-free DNA platform may hold value that goes well beyond the direct diagnosis of infections. You, as part of the Karius team, will be able to see the immense opportunity to expand the human knowledge around this emerging topic and apply it directly to critical problems in human health and disease.\n    \n \n \n  Reports to:  Sr. Director of Software Engineering\n    \n \n \n  Location:  Redwood City, CA (Hybrid) or Remote (US)\n    \n \n \n  Primary Responsibilities \n \n \n Design and development of backend software services that interact with the LIMS software and that drive the Karius genomics lab workflows and related business processes to generate life-saving diagnostic reports. \n Follow Domain Driven Design to clearly document the service design and the interfaces. \n Ensure the software services meet expected quality gates by developing unit and functional tests. \n Collaborate with cross-functional teams such as Lab Operations, Customer Success, Product Management and Quality Engineering, and follow the defined Engineering SDLC to deliver value to the customers and users. \n Contribute to the engineering organization\u2019s technical efforts such as design and code review, technology evaluations and development of proof of concepts. \n Provide production support of diagnostics software services. \n Contribute to advancing a culture of a high-performing team by having close collaboration and engagement with the rest of the engineering team in solving challenges as they arise. \n \n \n \n  What\u2019s Fun About the Job? \n \n \n     Karius is operating at the edge of what is now known to be possible in infectious disease diagnostics. With that, comes a wave of new and incredible challenges and opportunities. To deliver on that value, you will be tapping into some of the most advanced technologies, architecting and innovating where the current solutions simply don't suffice. You will get to see how much your work really matters.\n    \n \n \n  Travel:  No travel required.\n    \n \n \n  Physical Requirements \n \n \n     Subject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office environment.\n    \n \n \n  Position Requirements \n \n \n     First and foremost, you are energized and motivated by the opportunity to build an elegant software. You enjoy seeing your creation work like a clock positively impacting thousands of people every year. You crave tough challenges in a super technical and collaborative environment that requires creativity and vision to navigate complex and ambiguous problems.\n    \n \n \n  In addition, you will be able to present:\n    \n \n \n  BS or MS degree in Computer Science, Software Engineering or related technical fields involving algorithms and coding. \n 5+ years of software engineering experience, including designing, developing and maintaining backend solutions in a production environment, including 2+ experience in LIMS software such as Illumina Clarity. \n A deep understanding of various system architectural patterns, such as event driven microservices, and a strong hands on experience with related technologies such as Kafka. \n Expert level experience with Typescript/javaScript stack using frameworks such as Express, Nest.js, Node.js. \n Practical examples of complex system data modeling and servicing using REST, GraphQL, no-SQL/SQL databases & ORMs. \n Experience with DevOps culture using cloud computing in AWS, Azure or GCP . \n A deep understanding of and hands-on experience with the software deployment and operation using containerization technologies like Docker and container management like Kubernetes. \n Experience with development lifecycle management tools like Jira, Confluence, git \n \n \n     As a big plus, experience in healthcare, life sciences or other regulated industries.\n    \n \n \n  Personal Qualifications \n \n \n Passionate, purpose-driven, and excited about Karius\u2019 mission. \n Mastered your craft yet eager to learn and grow. \n Demonstrated ability to tackle complex problems. \n Ability to work independently but also be an excellent team player. \n Ability to work effectively and efficiently in a fast paced (startup) environment. \n \n \n \n  At Karius, we value a diverse and inclusive workplace and provide equal employment opportunity for all applicants and employees and are committed to honor and invest in the full diversity of people, in our hiring, recruiting and development of employees across the Company. All qualified applicants for employment are encouraged to apply and will be considered without regard to an individual\u2019s race, color, sex, gender identity and gender expression (including transgender individuals who are transitioning, have transitioned, or are perceived to be transitioning to the gender with which they identify), religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws. If you are unable to submit your application due to a disability, please contact us at recruiting@kariusdx.com and we will accommodate qualified individuals with disabilities.",
        "cleaned_desc": "     Subject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office environment.\n    \n \n \n  Position Requirements \n \n \n     First and foremost, you are energized and motivated by the opportunity to build an elegant software. You enjoy seeing your creation work like a clock positively impacting thousands of people every year. You crave tough challenges in a super technical and collaborative environment that requires creativity and vision to navigate complex and ambiguous problems.\n    \n \n \n  In addition, you will be able to present:\n    \n \n \n  BS or MS degree in Computer Science, Software Engineering or related technical fields involving algorithms and coding. \n 5+ years of software engineering experience, including designing, developing and maintaining backend solutions in a production environment, including 2+ experience in LIMS software such as Illumina Clarity. \n A deep understanding of various system architectural patterns, such as event driven microservices, and a strong hands on experience with related technologies such as Kafka. \n Expert level experience with Typescript/javaScript stack using frameworks such as Express, Nest.js, Node.js. \n Practical examples of complex system data modeling and servicing using REST, GraphQL, no-SQL/SQL databases & ORMs.   Experience with DevOps culture using cloud computing in AWS, Azure or GCP . \n A deep understanding of and hands-on experience with the software deployment and operation using containerization technologies like Docker and container management like Kubernetes. \n Experience with development lifecycle management tools like Jira, Confluence, git \n \n \n     As a big plus, experience in healthcare, life sciences or other regulated industries.\n    \n \n \n  Personal Qualifications \n \n \n Passionate, purpose-driven, and excited about Karius\u2019 mission. \n Mastered your craft yet eager to learn and grow. \n Demonstrated ability to tackle complex problems. \n Ability to work independently but also be an excellent team player. \n Ability to work effectively and efficiently in a fast paced (startup) environment. \n \n \n ",
        "techs": [
            "software engineering",
            "lims software",
            "illumina clarity",
            "system architectural patterns",
            "event driven microservices",
            "kafka",
            "typescript",
            "javascript",
            "express",
            "nest.js",
            "node.js",
            "rest",
            "graphql",
            "no-sql",
            "sql databases",
            "orms",
            "devops",
            "cloud computing",
            "aws",
            "azure",
            "gcp",
            "docker",
            "kubernetes",
            "jira",
            "confluence",
            "git"
        ],
        "cleaned_techs": [
            "software engineering",
            "lims software",
            "illumina clarity",
            "system architectural patterns",
            "event driven microservices",
            "kafka",
            "typescript",
            "javascript",
            "express",
            "nest.js",
            "node.js",
            "rest",
            "graphql",
            "no-sql",
            "sql",
            "orms",
            "devops",
            "cloud computing",
            "aws",
            "azure",
            "gcp",
            "docker",
            "kubernetes",
            "jira",
            "confluence",
            "git"
        ]
    },
    "4d3d30a1b28478a8": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 84100.0,
        "salary_max": 111300.0,
        "title": "Support Engineer 5",
        "company": "Blueprint Technologies",
        "desc": "Who is Blueprint? \n  We are a technology solutions firm headquartered in Bellevue, Washington, with a strong presence across the United States. Unified by a shared passion for solving complicated problems, our people are our greatest asset. We use technology as a tool to bridge the gap between strategy and execution, powered by the knowledge, skills, and expertise of our teams, who all have unique perspectives and years of experience across multiple industries. We're bold, smart, agile, and fun. \n  What does Blueprint do? \n  Blueprint helps organizations unlock value from existing assets by leveraging cutting-edge technology to create additional revenue streams and new lines of business. We connect strategy, business solutions, products, and services to transform and grow companies. \n  Why Blueprint? \n  At Blueprint, we believe in the power of possibility and are passionate about bringing it to life. Whether you join our bustling product division, our multifaceted services team or you want to grow your career in human resources, your ability to make an impact is amplified when you join one of our teams. You'll focus on solving unique business problems while gaining hands-on experience with the world's best technology. We believe in unique perspectives and build teams of people with diverse skillsets and backgrounds. At Blueprint, you'll have the opportunity to work with multiple clients and teams, such as data science and product development, all while learning, growing, and developing new solutions. We guarantee you won't find a better place to work and thrive than at Blueprint. \n  We are looking for a  Support Engineer 5  to join us as we build cutting-edge technology solutions! This is your opportunity to be part of a team that is committed to delivering best-in-class service to our customers. \n  Key Responsibilities: \n \n Serve as the final point of escalation and resolution for advanced technical support, handling highly complex products, escalated issues, and confidential security matters. \n Provide advanced technical support to diverse audiences, including IT professionals, developers, architects, and executive management. \n Take ownership of customer support experience by collaborating with teams, implementing troubleshooting best practices, and ensuring transparency. \n Drive customer success and instill confidence in the Azure platform. \n Offer best practice recommendations across the entire range of Azure resources based on customer solutions. \n Clearly articulate recommendations in both written and spoken form to technical and leadership audiences. \n Navigate complex and strategic customer events, understanding their requirements and needs. \n \n Qualifications: \n \n Fluent in English language (reading, writing, and speaking). \n Minimum of 3 years' experience in a customer-facing or customer support role, with a strong ability to troubleshoot and solve complex technical issues involving multiple technologies in a team environment. \n At least 2 years' experience with SQL Server or a similar database product. \n Solid knowledge of performance tuning, database design, and T-SQL language. \n Experience in capacity planning, sizing SQL Server environments, and configuring high availability solutions. \n Ability to meet customer, and/or government security screening requirements for the role. \n Industry experience with Microsoft Server products, network connectivity, UNIX or other operating systems, and database migration to the cloud or SQL Server version upgrades. \n Experience in creating technical documentation and sharing knowledge through training and mentoring. \n Additional experience in the following areas is beneficial: \n \n Containers: Docker, Kubernetes (k8), OpenShift, cloud storage, flannel. \n Big Data: Apache Spark, YARN, Livy, ZooKeeper, Ranger, Knox, Polybase. \n Machine Learning: SparkSQL, Java, Scala, Python, Jupyter. \n Data Sources: MongoDB, Cloudera, Teradata, Oracle, DB2. \n Monitoring: Collectd, Grafana, Fluentd, InfluxDB, Elasticsearch. \n Familiarity with Linux script-based development environments and tools (Perl, Python, Ruby, PHP, etc.). \n \n \n Salary Range \n  Pay ranges vary based on multiple factors including, without limitation, skill sets, education, responsibilities, experience, and geographical market. The pay range for this position reflects geographic based ranges for Washington state: $84,100 to $111,300 USD/annually. The salary/wage and job title for this opening will be based on the selected candidate's qualifications and experience and may be outside this range. \n  Equal Opportunity Employer \n  Blueprint Technologies, LLC is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, age, disability, sex, gender identity or expression, orientation, veteran/military status, religion, national origin, ancestry, marital, or familial status, genetic information, citizenship, or any other status protected by law. \n  If you need assistance or a reasonable accommodation to complete the application process, please reach out to: recruiting@bpcs.com \n  Blueprint believe in the importance of a healthy and happy team, which is why our comprehensive benefits package includes: \n \n Medical, dental, and vision coverage \n Flexible Spending Account \n 401k program \n Competitive PTO offerings \n Parental Leave \n Opportunities for professional growth and development \n \n If you have a passion for exploring new ideas and delivering real-world product impact, this job is for you! Join our team and help us advance the state-of-the-art in object detection and tracking using ML techniques.",
        "cleaned_desc": " Minimum of 3 years' experience in a customer-facing or customer support role, with a strong ability to troubleshoot and solve complex technical issues involving multiple technologies in a team environment. \n At least 2 years' experience with SQL Server or a similar database product. \n Solid knowledge of performance tuning, database design, and T-SQL language. \n Experience in capacity planning, sizing SQL Server environments, and configuring high availability solutions. \n Ability to meet customer, and/or government security screening requirements for the role. \n Industry experience with Microsoft Server products, network connectivity, UNIX or other operating systems, and database migration to the cloud or SQL Server version upgrades. \n Experience in creating technical documentation and sharing knowledge through training and mentoring. \n Additional experience in the following areas is beneficial: \n \n Containers: Docker, Kubernetes (k8), OpenShift, cloud storage, flannel. ",
        "techs": [
            "sql server",
            "t-sql",
            "capacity planning",
            "high availability solutions",
            "microsoft server products",
            "network connectivity",
            "unix",
            "database migration",
            "sql server version upgrades",
            "docker",
            "kubernetes",
            "openshift",
            "cloud storage",
            "flannel"
        ],
        "cleaned_techs": [
            "sql",
            "t-sql",
            "capacity planning",
            "high availability solutions",
            "microsoft server products",
            "network connectivity",
            "unix",
            "database migration",
            "docker",
            "kubernetes",
            "openshift",
            "cloud storage",
            "flannel"
        ]
    },
    "79d487b021649b75": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 140000.0,
        "salary_max": 140000.0,
        "title": "Full-Stack Software Engineer",
        "company": "AidKit, Inc.",
        "desc": "Hi! I\u2019m Justin, AidKit\u2019s Engineering Manager. We are looking for a software engineer to join our team who is passionate about building high-leverage solutions to drive impact at scale. At AidKit, we are driven by our company values - being accountable to the people we serve. \n  AidKit is a social impact startup born from the pandemic that aims to 100x the leverage of organizations helping people in need. Today, we run the largest guaranteed income programs in the country. Looking forward, we aim to be  the platform  for delivering assistance to anyone, anywhere, efficiently, at scale, and with dignity. \n  We believe that the best technology shouldn\u2019t be limited to big tech and, to that end, we\u2019re committed to  responsibly  adapting the latest advances in abstraction and machine learning to enhance the leverage of those around us. \n  We got our start as volunteers delivering relief to undocumented workers left behind amidst the early days of COVID and have since grown into a fully bootstrapped platform that has disbursed over $170 million directly into hard to reach communities. \n  We are a team of 24 and we\u2019re profitable \u2014 we\u2019ve raised $0 from investors so that we can chase building the future we want to exist rather than chase a return for outside investors. \n  About the Role \n  As a salaried software engineer, your role will consist of building our no/low-code platform that allows organizations doing good to build a bespoke experience without bespoke software. \n  Our stack looks roughly as follows: \n \n Typescript, React & Tailwind on the front-end \n Typescript, Postgres and DynamoDB on the backend (with some Python we\u2019re slowly deprecating). \n Pulumi for Infrastructure as Code deployments on AWS. \n \n Your responsibilities would include: \n \n Going from vague problems to fully fleshed out solutions across multiple layers of the stack that addresses real business needs. \n Writing code to expand our platform that is clean, easy to extend, secure, and documented. \n Write and review design documents for upcoming product and technical components and features. \n Participate in code reviews. \n Work with the engineering team to help plan our technical and product roadmaps. \n Handle prioritization and sizing for upcoming technical work. \n \n About You \n \n Experience in building full-stack web applications (Typescript preferred, but not a requirement) \n Willing to jump in and do right by those we serve, whatever it takes. \n Eager to tackle complex problems and comfortable working with ambiguity. \n Not required but bonus points if have done any of the following:\n    \n  Experience  managing large scale web infrastructure  serving hundreds of thousands of users (or more!). Why? We run the largest guaranteed income pilots in the country, scaling from 1 to 1000 requests per second over the course of minutes.   \n \n \n Experience  designing infrastructure that is robust to failure  and minimizes mean time to recovery.  Why? We serve populations that are in dire need and often low on tech-literacy. If they have issues, they\u2019re unlikely to come back and try again   \n \n \n Experience  designing green-field projects from the ground up  and owning major architectural decisions.  Why? We believe that we can broaden our impact by building newer, better solutions to old problems and that requires thinking from first principles.   \n \n \n \n You care deeply about the mission of direct aid and supporting anyone who needs help, no matter where they come from. \n \n About the Hiring Manager \n  As in any job, your happiness and fulfillment will be a function of your manager. Isn\u2019t it wild that in most jobs you have no idea who you\u2019d actually work for? \n  The hiring manager for this role is Justin Cajayon. Quick bio for him: before joining AidKit, he led multiple teams at a fintech startup and oversaw key initiatives for their series B funding round. Previously, he joined a full-stack consulting shop as the 3rd full-time employee and led their expansion to 10 employees. Today, he is very grateful to have the opportunity to serve the social sector and find ways for technology to drive positive impact at scale. \n  Interview Process \n  Interview Screen \n  30 Minutes \n  You will speak with Justin and discuss your background, what\u2019s important to you in your next role and any questions you might have about the role. \n  Code Interview \n  60 Minutes \n  We\u2019ll send you a small full-stack Typescript app to check out locally and get familiar with (if you haven\u2019t done full-stack work recently). We\u2019ll then jump on a zoom call and incrementally add features until we exhaust 60 minutes. You\u2019re welcome to use Google / StackOverflow / ChatGPT as you would normally while working. \n  Deep Dive \n  60 Minutes \n  You\u2019ll pick a project that you\u2019ve had some-level of responsibility for in the past and walk us through the \u201cstory\u201d behind that project. What motivated it? What were the major engineering decisions and how were they decided? What was the resulting architecture? What would you do the same or differently, knowing what you know now? We recommend either preparing or being ready to draw an architecture diagram on the call. \n  Reference Check \n  As part of our hiring policies we ask you to provide a reference who we can contact who can speak towards your work. Ideally, this is a past manager who we can speak to to understand how to best set you up for success at AidKit. \n  Compensation and Location \n  For this full-time position, you can work from anywhere in the United States. We currently have team members in Colorado, Connecticut, California, Washington State, Washington DC and New York. The salary for this role is $140,000. We also provide equity which varies by position and experience and a comprehensive benefits package including 401K matching, health benefits, flexible schedule, and unlimited paid time off.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "67999d2172544f2e": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Software Engineer - Community (P2P) - Cash App",
        "company": "Afterpay",
        "desc": "Company Description \n \n \n \n     It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic ecosystem, developing unique financial products, including Afterpay/Clearpay, to provide a better way to send, spend, invest, borrow and save to our 47 million monthly active customers. We want to redefine the world\u2019s relationship with money to make it more relatable, instantly available, and universally accessible.\n     \n  Today, Cash App has thousands of employees working globally across office and remote locations, with a culture geared toward innovation, collaboration and impact. We\u2019ve been a distributed team since day one, and many of our roles can be done remotely from the countries where Cash App operates. No matter the location, we tailor our experience to ensure our employees are creative, productive, and happy.\n     \n  Check out our locations, benefits, and more at cash.app/careers.\n    \n \n \n \n \n  Job Description \n \n \n  The Team: \n  The Cash Peer-to-peer (P2P) team is in charge of re-imagining and building powerful new product experiences for person to person payments. This team owns and operates the core product experience of millions of Cash App customers. The contributions you make on this team will be used by millions of people in a wide variety of scenarios. We are seeking an experienced and motivated individual to contribute to the development and enhancement of our cutting-edge payment solutions. \n  The Job: \n  As a Software Engineer on this team, you will play a pivotal role in designing, implementing, and maintaining robust, scalable, and secure peer-to-peer payment systems. \n  You will: \n \n  Scope, build, and scale products, systems, and services that have an immediate impact on our customers. \n  Lead and participate in critical technical, design, and product discussions. \n  Test, maintain and deploy high-quality software solutions ensuring adherence to coding best practices and industry standards. \n  Participate in all parts of product development, working with non-Engineering related disciplines (Product and Design) and adjacent Engineering teams (Mobile, Platform, Machine Learning, and Data Science). \n \n \n \n \n \n  Qualifications \n \n \n  You have: \n \n  2+ year of professional experience in software development \n  Solid understanding of distributed systems, network protocols, and data structures. \n  Strong problem-solving skills and ability to work in a fast-paced, collaborative environment. \n  Boundless curiosity, persistence and a desire to get things done \n  Experience building backend systems and working with FE/mobile teams \n  Bachelor's Degree or Diploma in Computer Science, or equivalent experience. \n \n  Technologies we use and teach: \n \n  Java, Kotlin \n  MySQL, Dynamo, ElasticSearch, Snowflake, Aurora DB \n  gRPC and Protocol Buffers \n  Amazon Web Services (AWS) \n  DataDog, Prometheus, SignalFx \n \n \n \n \n \n  Additional Information \n \n \n  This role can support remote employment across North America.Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.    Zone A: USD $152,100 - USD $185,900  Zone B: USD $144,500 - USD $176,700  Zone C: USD $136,900 - USD $167,300  Zone D: USD $129,300 - USD $158,100 \n \n  To find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \n  Full-time employee benefits include the following: \n \n  Healthcare coverage (Medical, Vision and Dental insurance) \n  Health Savings Account and Flexible Spending Account \n  Retirement Plans including company match \n  Employee Stock Purchase Program \n  Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \n  Paid parental and caregiving leave \n  Paid time off (including 12 paid holidays) \n  Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees) \n  Learning and Development resources \n  Paid Life insurance, AD&D, and disability benefits \n  Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \n \n  These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. \n  US and Canada EEOC Statement \n  We\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \n  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Want to learn more about what we\u2019re doing to build a workplace that is fair and square? \n  Additionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis. \n \n \n  Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.",
        "cleaned_desc": "  Qualifications \n \n \n  You have: \n \n  2+ year of professional experience in software development \n  Solid understanding of distributed systems, network protocols, and data structures. \n  Strong problem-solving skills and ability to work in a fast-paced, collaborative environment. \n  Boundless curiosity, persistence and a desire to get things done \n  Experience building backend systems and working with FE/mobile teams \n  Bachelor's Degree or Diploma in Computer Science, or equivalent experience. \n \n  Technologies we use and teach: \n \n  Java, Kotlin \n  MySQL, Dynamo, ElasticSearch, Snowflake, Aurora DB ",
        "techs": [
            "java",
            "kotlin",
            "mysql",
            "dynamo",
            "elasticsearch",
            "snowflake",
            "aurora db"
        ],
        "cleaned_techs": [
            "java",
            "kotlin",
            "mysql",
            "dynamo",
            "elasticsearch",
            "snowflake",
            "aurora db"
        ]
    },
    "9587d8631126939c": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 181656.92,
        "salary_max": 230018.14,
        "title": "Staff Platform Engineer",
        "company": "Afresh",
        "desc": "Afresh is on a mission to eliminate food waste and make fresh food accessible to all. Our first A.I.-powered solution optimizes ordering, forecasting, and store operations for fresh food departments in brick-and-mortar grocers. With our Fresh Operating System, regional and national grocery retailers have placed $1.6 billion in produce orders across the US and we've helped our partners prevent 34 million pounds of food from going to waste. Working at Afresh represents a one-of-a-kind opportunity to have massive social impact at scale by leveraging uncommonly impactful software \u2013 we hope you'll join us! \n \n  About the role \n \n Directly impact our mission of reducing fresh food waste by working on our backend data and machine learning platform that uses massive amounts of grocery store data to make ordering recommendations \n Build out our backend data platform as well as supporting tooling to process tens of billions of historical data points collected from tens of thousands of retail stores and beyond \n Support developer experience for our wider engineering organization across functions and teams \n Leverage modern data analysis and processing frameworks, programming languages, and tooling\u2014such as Apache Spark, Pandas, Python, and SQL\u2014to provide powerful compute capabilities to our data platform \n Scale our data backends that leverage a combination of traditional databases, data warehouses, and data lakes to support varying access patterns \n Scale up your impact by leading technical projects, participating in technical and design decisions, mentoring engineers, and participating in recruiting functions \n Act as an exemplar for our culture of excellence, curiosity, collaboration, proactivity, candor, humility, and kindness \n \n Skills and experience \n \n 5+ years of professional software engineering experience \n Bachelor's degree in a STEM field, ideally in computer science or related field \n Outstanding programming skills with deep knowledge of databases, distributed systems, and backend concepts \n Demonstrated ability to design, build, deploy, and manage large production compute or data backend platforms at scale \n Experience using modern big data frameworks, scaling computation to hundreds of machines, and/or working with machine learning systems preferred \n Demonstrated ability to triage and solve open-ended, ambiguous systems-level problems \n \n The above represent attributes our ideal candidate possesses. We encourage all highly-qualified candidates to apply, even if they do not fulfill all the listed criteria. \n  #LI-REMOTE \n \n  About Afresh    Founded in 2017, Afresh is working on the #1 solution to curb climate change: reducing food waste. By combining human insight and transformative technology, we're helping grocers provide fresher food to customers at more affordable prices.     Afresh sits at an incredible intersection of positive social impact, rocket ship financial growth, and cutting-edge technology. Our best-in-class AI research has been published in top journals including ICML, and we've raised over $148 million in funding from investors including former co-CEO of Whole Foods Market Walter Robb and Eric Schmidt's Innovation Endeavors. \n  Fresh is the past, present, and future of our food system \u2013 the waste we create today will impact our planet for years to come. Join us as we continue to build a vibrant, diverse, and inclusive team that embodies our company's values of proactivity, kindness, candor, and humility.     Afresh provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity/expression, marital status, pregnancy or related condition, or any other basis protected by law. \n  Here at Afresh, many of our employees work remotely provided that they reside in one of the following states: AR, CA, CO, FL, GA, IL, KY, MA, MI, MT, MO, NV, NJ, NY, NC, OR, PA, TX, WA, WI. However, there may be key roles that will require a candidate/employee to be local to our San Francisco, CA office. In which case this requirement will be included in the job posting details under \"Skills and experience\" for reference.",
        "cleaned_desc": " Build out our backend data platform as well as supporting tooling to process tens of billions of historical data points collected from tens of thousands of retail stores and beyond \n Support developer experience for our wider engineering organization across functions and teams \n Leverage modern data analysis and processing frameworks, programming languages, and tooling\u2014such as Apache Spark, Pandas, Python, and SQL\u2014to provide powerful compute capabilities to our data platform \n Scale our data backends that leverage a combination of traditional databases, data warehouses, and data lakes to support varying access patterns \n Scale up your impact by leading technical projects, participating in technical and design decisions, mentoring engineers, and participating in recruiting functions   Bachelor's degree in a STEM field, ideally in computer science or related field \n Outstanding programming skills with deep knowledge of databases, distributed systems, and backend concepts \n Demonstrated ability to design, build, deploy, and manage large production compute or data backend platforms at scale \n Experience using modern big data frameworks, scaling computation to hundreds of machines, and/or working with machine learning systems preferred \n Demonstrated ability to triage and solve open-ended, ambiguous systems-level problems ",
        "techs": [
            "apache spark",
            "pandas",
            "python",
            "sql"
        ],
        "cleaned_techs": [
            "apache spark",
            "pandas",
            "python",
            "sql"
        ]
    },
    "fd3e0f4ce0d20e42": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 152500.0,
        "salary_max": 243500.0,
        "title": "Senior Software Development Engineer, Android",
        "company": "Zillow",
        "desc": "About the team  Are you passionate about building new, immersive experiences to change how people shop for homes and rentals? Every month 180 million users turn to Zillow for help. The Zillow RMX Team is re-imagining the home tour experience, giving people the feeling of being there from the convenience of their phones or computers. Using groundbreaking technologies, our team works across product, research, engineering, and business to enable people to walk through a home virtually. We believe this will become the future of home shopping!\n  \n  About the role \n  The RMX Consumer Media Experiences team is looking for an experienced Android developer to help us build our Interactive Media Experiences for Android! As an Android developer, you will be responsible for delivering on key architectural problems, crafting amazing user experiences, driving features forward across multiple teams, and blazing trails. You\u2019ll work side-by-side with outstanding computer vision and machine learning teams to push the limits of what devices can do while building our new Consumer Media Experiences and viewing experiences. \n  This role has been categorized as a Remote position. \u201cRemote\u201d employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.\n   In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $152,500.00 - $243,500.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.\n   In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.\n  \n  Who you are \n  5+ years of software application and systems development experience. \n  Experience in developing mobile consumer software applications, with a strong understanding of the mobile ecosystem, and a customer-focused attitude. \n  A proven track record of high efficiency and quality in software design, coding, testing, and debugging. \n  Strong analytical and quantitative skills - use data and metrics to back up assumptions and recommendations. \n  The ability to work in a fast, agile, and nimble environment with frequent change. \n  Excellent problem-solving and critical-thinking skills. Friendly collaborator with others. \n \n  Ideally three or more of the following: \n  You hold a Bachelor's degree in Computer Science or Computer Engineering \n \n  5+ years of software development experience \n  You have a solid understanding of Kotlin, Java, and building Android applications \n  You thrive in a fast, agile, and multi-functional team environment \n  You published one or more apps to the Google Play store \n  You have a desire to write clean, well-tested code \n  You demonstrate excellent problem-solving and critical thinking skills and are passionate about mobile app development. \n  Experience working with OpenGL and or Vulkan \n  General graphics programming experience \n \n \n  Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know. \n \n  Get to know us \n  Zillow is reimagining real estate to make home a reality for more and more people. \n \n  As the most-visited real estate website in the United States, Zillow\u00ae and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people. \n \n  Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We\u2019re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don\u2019t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees\u2019 Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list. \n \n  Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com. \n \n  Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.",
        "cleaned_desc": "  Who you are \n  5+ years of software application and systems development experience. \n  Experience in developing mobile consumer software applications, with a strong understanding of the mobile ecosystem, and a customer-focused attitude. \n  A proven track record of high efficiency and quality in software design, coding, testing, and debugging. \n  Strong analytical and quantitative skills - use data and metrics to back up assumptions and recommendations. \n  The ability to work in a fast, agile, and nimble environment with frequent change. \n  Excellent problem-solving and critical-thinking skills. Friendly collaborator with others. \n ",
        "techs": [
            "none"
        ],
        "cleaned_techs": []
    },
    "c98d1aaeb96f6379": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 99711.75,
        "salary_max": 126257.3,
        "title": "Software Engineer (II) \u2013 AI Applications",
        "company": "HP",
        "desc": "Locations include Spring, Texas (preferred location), and US remote. \n \n  The Team \n  We are a growing centralized team helping HP take advantage of new AI/ML technology, especially around Generative AI and large language models. We engage with business units to advise and prototype solutions, and we develop and run software applications for internal use. \n \n  The Role \n  As a Software Engineer you will work to rapidly develop AI-powered software applications, especially internal business applications powered by large language models. You will work closely with data scientists, machine learning engineers, and other software engineers, using the latest tools and technologies. \n \n  Skills and Profile \n \n Prior software engineering experience with business applications in a cloud environment. \n Full-stack ability and interest is a plus. We are hiring a dedicated Lead UI Software Engineer, but it is a plus if you can assist with front-end contributions when needed. \n In this team we value a start-up mindset and a sense of urgency to deliver to our internal customers. The ideal candidate will have experience from a fast-moving SaaS start-up in addition to experience from a large complex organization. \n Technologies you may use include Azure services, python, langchain, micro services, docker, CI/CD, React, Elastic Search, SQL and NoSQL. \n Plus for: Azure DevOps and platform, user & account administration, document search technologies, vector databases, and LLM-prompt engineering. \n The recent AI progress is disruptive, and our team is in the midst of it! As a consequence, day-to-day priorities, tasks, and team structure may change rapidly. We are looking for somebody who thrives in such an environment. The role is not a fit if you value \"business as usual\". \n Experience working in a distributed team with diverse backgrounds. Ability to engage in discussions in a respectful manner. \n Mastery in English is required. \n \n \n  Education and Length of Experience  Bachelor's degree in Computer Science or similar, or demonstrated competence, plus typically a minimum of 2-4 years of relevant experience or 1-3 years with a Master's degree. \n \n  About HP \n \n \n \n \n \n  You\u2019re out to reimagine and reinvent what\u2019s possible\u2014in your career as well as the world around you.\n  \n \n   So are we. We love taking on tough challenges, disrupting the status quo, and creating what\u2019s next. We\u2019re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\n  \n \n \n \n   HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\n  \n \n \n \n   Our history: HP\u2019s commitment to diversity, equity and inclusion \u2013 it's just who we are.\n  \n \n   From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you\u2019re more innovative and that helps grow our bottom line. Come to HP and thrive!",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "5cb5dd8275e411d8": {
        "terms": [
            "machine learning engineer",
            "mlops"
        ],
        "salary_min": 58300.0,
        "salary_max": 133000.0,
        "title": "DevOps Engineer, Mid",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         San Diego,CA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180073\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer, Mid\n           The Opportunity: \n  As a DevOps engineer, you know how to set up cloud environments and provision computer networking, storage, and virtual networks\u2014ultimately, how to \u201charness the cloud.\u201d We\u2019re looking for an experienced DevOps infrastructure engineer like you to support our clients as they modernize their IT infrastructures and meet their most challenging missions. \n \n  As a DevOps infrastructure engineer at Booz Allen, you\u2019ll work closely with cloud architects and engineers to manage server configuration for modern cloud solutions. You\u2019ll apply your skills within a DevOps framework to establish or provision virtual machines or networks and use cloud service providers to further your clients\u2019 meaningful missions. \n \n  With access to our internal innovative labs, there\u2019s no better place to further your skills and explore different ways of solving our clients\u2019 challenges. Whether helping to develop, deploy, or manage IT infrastructures for crucial server and network components, here, you\u2019ll have the latest tech and brightest teammates at your fingertips. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  3+ years of experience as a DevOps Engineer \n  Experience with continuous integration and continuous deployment (CI/CD) platforms, including GitLab, GitHub, Jenkins, Azure DevOps, ArgoCD, or AWS CodeSuite \n  Experience with packaging or deploying software via Linux containers \n  Experience with software development life cycle \n  Experience with the use of version control systems for code management and artifact tracking, including GitHub, GitLab, or Jira \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelors degree \n \n \n  Nice If You Have: \n \n  Experience with infrastructure as code (IaC) and configuration management tools, including Terraform or Ansible \n  Experience with cloud service providers, including AWS, Azure, or GCP \n  Experience with software system architecture or microservices architecture design and implementation \n  Experience with network and server infrastructure monitoring and management \n  Experience with programming languages, including Python \n  Knowledge of orchestration tools, including Kubernetes or OpenShift \n  Knowledge of machine learning approaches, techniques, and their advantages and disadvantages \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. \n \n  Create Your Career: \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  Experience with continuous integration and continuous deployment (CI/CD) platforms, including GitLab, GitHub, Jenkins, Azure DevOps, ArgoCD, or AWS CodeSuite \n  Experience with packaging or deploying software via Linux containers \n  Experience with software development life cycle \n  Experience with the use of version control systems for code management and artifact tracking, including GitHub, GitLab, or Jira \n  Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements \n  Bachelors degree \n \n \n  Nice If You Have: \n \n  Experience with infrastructure as code (IaC) and configuration management tools, including Terraform or Ansible \n  Experience with cloud service providers, including AWS, Azure, or GCP \n  Experience with software system architecture or microservices architecture design and implementation \n  Experience with network and server infrastructure monitoring and management \n  Experience with programming languages, including Python \n  Knowledge of orchestration tools, including Kubernetes or OpenShift \n  Knowledge of machine learning approaches, techniques, and their advantages and disadvantages \n \n \n  Vetting: \n  Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. ",
        "techs": [
            "gitlab",
            "github",
            "jenkins",
            "azure devops",
            "argocd",
            "aws codesuite",
            "linux containers",
            "version control systems",
            "github",
            "gitlab",
            "jira",
            "public trust",
            "suitability/fitness determination",
            "infrastructure as code",
            "terraform",
            "ansible",
            "cloud service providers",
            "aws",
            "azure",
            "gcp",
            "software system architecture",
            "microservices architecture",
            "network monitoring",
            "server infrastructure monitoring",
            "programming languages",
            "python",
            "orchestration tools",
            "kubernetes",
            "openshift",
            "machine learning."
        ],
        "cleaned_techs": [
            "gitlab",
            "github",
            "jenkins",
            "azure",
            "argocd",
            "aws",
            "linux containers",
            "version control systems",
            "jira",
            "public trust",
            "suitability/fitness determination",
            "infrastructure as code",
            "terraform",
            "ansible",
            "cloud service providers",
            "gcp",
            "software system architecture",
            "microservices architecture",
            "network monitoring",
            "server infrastructure monitoring",
            "programming languages",
            "python",
            "orchestration tools",
            "kubernetes",
            "openshift",
            "machine learning."
        ]
    },
    "574619bbf675796a": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 81800.0,
        "salary_max": 186000.0,
        "title": "Safety Engineer",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Stafford,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0180391\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Safety Engineer\n           The Opportunity: \n  Are you looking for an opportunity to combine your technical skills with big picture thinking to make an impact in Environment, Safety, and Occupational Health (EOSH)? Our team supports senior-level DoD personnel with environment, system safety, and occupational health implementation and oversight for DoD system programs. You\u2019ll leverage your specialized knowledge and expertise in ESOH, including applying scientific and engineering principles, criteria, and techniques to identify and assess ESOH hazards and inform the implementation of mitigations to reduce warfighter risk. \n \n  As a systems engineer on our team, you'll enjoy a dynamic team environment of client and contractor staff while executing comprehensive system safety programs or individual tasks on a variety of systems, including unmanned systems, ground-based missile systems, surface vessel threat and support systems, laser systems, and others. Typical work products include Safety Releases, National Environmental Policy Act (NEPA) documentation, Programmatic ESOH Evaluations (PESHEs), System Safety Program Plans (SSPP), a variety of analyses, such as Preliminary Hazard Analysis (PHA), Subsystem and System Hazard Analysis (SHA and SSHA), Operating and Support Hazard Analysis (O&SHA), Explosive Ordnance Disposal (EOD) analysis, Safety Assessment Reports (SAR), and test report evaluations. You'll analyze data, develop written deliverables, assist with the presentation of results, and assist with the review of client system safety artifacts to verify compliance with requirements, policy, and guidance documents. You'll conduct these tasks with oversight and mentoring from Senior ESOH Engineers, as needed, following established plans and quality standards and the freedom to improve processes and advance the EOSH discipline. \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  5+ years of experience with ESOH tasking \n  Experience in performing medium-level complexity ESOH tasks with minimal oversight \n  Experience with conducting Military safety analyses and safety program implementation \n  Ability to analyze, research, assess, and organize technical data into cohesive and clear technical reports and presentations \n  Ability to organize, schedule, and facilitate technical meetings and working groups \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with NAVSEAINST 8020.6, Weapon System Explosives Safety Review Board (WSESRB), or Software Systems Safety Technical Review Panel (SSSTRP) \n  Experience with performing risk assessments and analysis employing modeling and simulation techniques, including leveraging Model-Based Systems Engineering (MBSE) to perform ESOH assessments in digital models \n  Experience with Digital Engineering, Machine Learning and Artificial Intelligence, Software Development, Solid-state Electrical Circuit Design, Unmanned Systems Design, Human Factors Engineering, or Fault Tree Analysis \n  Possession of excellent verbal and written communication skills \n  Navy WISE Principal for Safety (PFS) and Marine Corps Systems Command (MCSC) Principal for Environment, Safety, and Occupational Health (PESOH) with Level I MCSCO 5090 ESOH Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  Experience in performing medium-level complexity ESOH tasks with minimal oversight \n  Experience with conducting Military safety analyses and safety program implementation \n  Ability to analyze, research, assess, and organize technical data into cohesive and clear technical reports and presentations \n  Ability to organize, schedule, and facilitate technical meetings and working groups \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with NAVSEAINST 8020.6, Weapon System Explosives Safety Review Board (WSESRB), or Software Systems Safety Technical Review Panel (SSSTRP) \n  Experience with performing risk assessments and analysis employing modeling and simulation techniques, including leveraging Model-Based Systems Engineering (MBSE) to perform ESOH assessments in digital models \n  Experience with Digital Engineering, Machine Learning and Artificial Intelligence, Software Development, Solid-state Electrical Circuit Design, Unmanned Systems Design, Human Factors Engineering, or Fault Tree Analysis \n  Possession of excellent verbal and written communication skills \n  Navy WISE Principal for Safety (PFS) and Marine Corps Systems Command (MCSC) Principal for Environment, Safety, and Occupational Health (PESOH) with Level I MCSCO 5090 ESOH Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n ",
        "techs": [
            "navseainst 8020.6",
            "wsesrb",
            "ssstrp",
            "model-based systems engineering (mbse)",
            "digital engineering",
            "machine learning",
            "artificial intelligence",
            "software development",
            "solid-state electrical circuit design",
            "unmanned systems design",
            "human factors engineering",
            "fault tree analysis",
            "navy wise principal for safety (pfs)",
            "marine corps systems command (mcsc) principal for environment",
            "safety",
            "and occupational health (pesoh)",
            "level i mcsco 5090 esoh certification"
        ],
        "cleaned_techs": [
            "navseainst 8020.6",
            "wsesrb",
            "ssstrp",
            "model-based systems engineering (mbse)",
            "digital engineering",
            "ai",
            "software development",
            "solid-state electrical circuit design",
            "unmanned systems design",
            "human factors engineering",
            "fault tree analysis",
            "navy wise principal for safety (pfs)",
            "marine corps systems command (mcsc) principal for environment",
            "safety",
            "and occupational health (pesoh)",
            "level i mcsco 5090 esoh certification"
        ]
    },
    "0af5fc61a12f5cf8": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 60102.94,
        "salary_max": 76103.72,
        "title": "IT Junior Infrastructure Engineer",
        "company": "GES",
        "desc": "Overview: \n   THIS IS A REMOTE OPPORTUNITY IN THE US. \n  Job Profile \n  Introduction \n  Individuals within the IT Infrastructure Engineer role are responsible for the operations of secure and highly available computing platforms, servers, and networks. They install, maintain, upgrade, and continuously improve the company's operating environment. They also maintain the ongoing reliability, performance, and support of the infrastructure. This includes monitoring the operating environments, responding to incidents, problems and planning for growth. Individuals in this class are also responsible for the overall operation and maintenance of the data center. \n  Infrastructure Engineers deploy the release of new technologies as well as design, install, configure, maintain, and perform testing of PC/server operating systems, networks, and related utilities and hardware. Other responsibilities include troubleshooting problems as reported by users, supporting Web access and electronic messaging services, and maintaining a secure systems environment. They also provide infrastructure solutions based on application needs and anticipated growth, install new servers, networks, and solutions, and maintain the infrastructure. \n  Infrastructure Engineers require good communication skills and must be able to work collaboratively with clients and other technical colleagues. Individuals work across all functional areas of the company utilizing a strong customer service orientation to ensure that all service requests and incidents are resolved in a professional manner. They share their expertise and provide individual training and support.  Responsibilities: \n  Duties and Responsibilities \n  Assisting in Deployment and Configuration: Under the guidance of senior team members, assist in deploying and configuring IT infrastructure systems, including servers, applications, and cloud systems. \n  Basic System Management and Maintenance: Help in managing and maintaining IT infrastructure systems, focusing on basic system checks, and flagging issues to senior engineers for resolution. \n  Aiding in System Upgrades and Migrations: Assist senior engineers in performing system upgrades and migrations, including helping to install patches, updating software, and assisting in data transfers. \n  Monitoring System Performance: Work with monitoring tools to collect performance statistics under the supervision of senior staff. Report any potential issues and collaborate with senior team members on possible solutions. \n  Basic Network and Server Troubleshooting: Assist in diagnosing basic network connectivity, server hardware, and software issues. Escalate complex problems to senior engineers. \n  Document Maintenance: Help in maintaining system documentation, including updating existing technical specifications, system configurations, and basic troubleshooting guides. \n  Compliance Support: Assist in ensuring IT infrastructure complies with the company\u2019s IT policies and procedures, including security policies and regulatory requirements. \n  Collaboration with IT Teams: Collaborate with other IT teams like software development and security under the guidance of senior team members to meet the organization\u2019s goals. \n  Learning and Development: Regularly read about new technologies and trends in the IT industry to assist in identifying new opportunities for infrastructure improvement. \n  Tier I-II Support: Provide Tier I-II support, escalating issues to senior engineers when necessary. Be part of the junior on-call rotation. \n  Documentation: Assist in writing or updating technical documentation for various IT infrastructure components.  Qualifications: \n  Technical Skills \n  Windows Server Management: Basic knowledge of Windows Server versions, including features like Active Directory, Group Policy, and Windows Server Update Services (WSUS). \n  Azure Cloud Services: Familiarity with Azure services, like Azure Active Directory, Azure Virtual Machines, and Azure Blob Storage. \n  PowerShell Scripting: An understanding of basic PowerShell commands and perhaps some scripting for automating tasks. \n  Microsoft 365: Experience with or understanding of Microsoft 365 services like Outlook, SharePoint, and Teams. \n  Virtualization: Understanding of VMWare for creating and managing virtual machines. \n  Networking: Basic understanding of networking concepts and how they apply to Microsoft products. Familiarity with network protocols, DNS, and DHCP. \n  Security Practices: Awareness of Microsoft-specific security best practices, like role-based access control in Azure and Windows Defender configurations. \n  Configuration Management: Understanding of configuration management tools like Kaseya and Intune. \n  Monitoring Tools: Familiarity with Monitoring tools. \n \n  Soft Skills \n  Communication: Ability to communicate technical concepts clearly and effectively to both technical and non-technical team members. \n  Problem-solving: Capability to diagnose issues and find appropriate solutions in a Microsoft environment. \n  Teamwork: Comfortable working in a team, especially in a DevOps culture that may include cross-functional roles and responsibilities. \n  Adaptability: The tech world changes quickly, especially with Microsoft's frequent updates and changes to their platforms. Being adaptable is key. \n  Attention to Detail: Being meticulous in documentation and tasks to ensure the integrity and security of the infrastructure. \n  Customer Service: Capable of providing quality internal support in line with company expectations and service levels. \n  Learning Orientation: Eagerness to take on the challenge of learning new Microsoft technologies as they emerge. \n \n  Education and Experience \n  Typically requires an associate degree in a relevant field of study or equivalent work experience. \n  Typically requires 2-3 years of relevant information technology experience. \n  Requires basic knowledge of various infrastructure solutions.  Work Environment: \n  Company Profile \n  GES, Global Experience Specialists, is a global exhibition services company with a legacy spanning over 90 years and teams throughout North America, Europe, and the Middle East. We create some of the most influential exhibitions in the world \u2013 think international medical symposiums, industry leading exhibitions for technology, manufacturing that help communities meet, educate, and move their mission forward. From initial strategy to show-stopping audio visual, accommodations to award winning creative \u2013 and every detail in between \u2013 we create shows that propel commerce, education, and community! \n  Our mission is to deliver extraordinary exhibition experiences through simple, user-friendly services and best-in-class execution. \n  Global IT Team Profile \n  Members of the Global IT Team effect real change across the Viad global network, and have a direct, positive impact to the overall user experience. In a fast moving, dynamic company, you have first-hand experience on multiple technology areas and services. \n  The Global IT Team supports the broader, segmented IT divisions across Viad, including GES, Pursuit across all our operating geographies. \n  We strive to develop a healthy work-life balance with a strong emphasis on team building, team spirit, and open communication.",
        "cleaned_desc": "  Documentation: Assist in writing or updating technical documentation for various IT infrastructure components.  Qualifications: \n  Technical Skills \n  Windows Server Management: Basic knowledge of Windows Server versions, including features like Active Directory, Group Policy, and Windows Server Update Services (WSUS). \n  Azure Cloud Services: Familiarity with Azure services, like Azure Active Directory, Azure Virtual Machines, and Azure Blob Storage. \n  PowerShell Scripting: An understanding of basic PowerShell commands and perhaps some scripting for automating tasks. \n  Microsoft 365: Experience with or understanding of Microsoft 365 services like Outlook, SharePoint, and Teams. \n  Virtualization: Understanding of VMWare for creating and managing virtual machines. \n  Networking: Basic understanding of networking concepts and how they apply to Microsoft products. Familiarity with network protocols, DNS, and DHCP. \n  Security Practices: Awareness of Microsoft-specific security best practices, like role-based access control in Azure and Windows Defender configurations.    Configuration Management: Understanding of configuration management tools like Kaseya and Intune. \n  Monitoring Tools: Familiarity with Monitoring tools. \n \n  Soft Skills \n  Communication: Ability to communicate technical concepts clearly and effectively to both technical and non-technical team members. \n  Problem-solving: Capability to diagnose issues and find appropriate solutions in a Microsoft environment. \n  Teamwork: Comfortable working in a team, especially in a DevOps culture that may include cross-functional roles and responsibilities. \n  Adaptability: The tech world changes quickly, especially with Microsoft's frequent updates and changes to their platforms. Being adaptable is key. \n  Attention to Detail: Being meticulous in documentation and tasks to ensure the integrity and security of the infrastructure. ",
        "techs": [
            "windows server management",
            "azure cloud services",
            "powershell scripting",
            "microsoft 365",
            "virtualization",
            "networking",
            "security practices",
            "configuration management",
            "monitoring tools",
            "communication",
            "problem-solving",
            "teamwork",
            "adaptability",
            "attention to detail"
        ],
        "cleaned_techs": [
            "windows server management",
            "azure",
            "powershell scripting",
            "microsoft 365",
            "virtualization",
            "networking",
            "configuration management",
            "monitoring tools",
            "communication",
            "problem-solving",
            "teamwork",
            "adaptability",
            "attention to detail"
        ]
    },
    "fc0897c6322a975a": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 150000.0,
        "salary_max": 200000.0,
        "title": "Senior Backend Engineer - Mobile",
        "company": "Zeta Global",
        "desc": "WHO WE ARE \n  Zeta Global (NYSE: ZETA) is the Data-Powered Marketing Cloud that leverages advanced artificial intelligence (AI) and trillions of consumer signals to make it easier for marketers to acquire, grow, and retain customers more efficiently. Through the Zeta Marketing Platform (ZMP), our vision is to make sophisticated marketing simple by unifying identity, intelligence, and omnichannel activation into a single platform \u2013 powered by one of the industry's largest proprietary databases and AI. Our enterprise customers across multiple verticals are empowered to personalize experiences with consumers at an individual level across every channel, delivering better results for marketing programs. Zeta was founded in 2007 by David A. Steinberg and John Sculley and is headquartered in New York City with offices around the world. \n \n \n  THE ROLE \n  Zeta Marketing Platform (ZMP) is a machine learning/AI powered customer acquisition and CRM multi-tenant platform. The backend developer will work on server-side APIs and services that enable a highly distributed event pipeline and a stack that gets tens of thousands of messages per second. \n  As a senior member of the Software Engineering team, you will join the group responsible for designing, developing, and owning the distributed systems CRM platform for Zeta. You will collaborate with your fellow Engineers and Product Managers to develop a roadmap and subsequent projects to build the next generation comprehensive, multichannel marketing solution that unifies and unlocks data across digital touch points, driving return on marketing investment. \n  You should have a deep knowledge of distributed systems and cloud architecture. You will need extensive design and development experience and be passionate about working with high-throughput systems where the issues of throughput, performance, redundancy, and concurrency are paramount. \n  Key Responsibilities:  \n As a Senior Software Developer, you will be: \n \n Responsible for independently and cooperatively understanding business requirements, designing, and implementing core components for real-world marketing automation platform. \n Designing, implementing application code to satisfy product requirements \n Ensuring high product quality through rigorous code reviews and unit tests \n Fixing bugs and implementing enhancements \n Taking ownership of a significant product component in design and implementation \n \n Requirements: \n \n We are looking for exceptional talent with superior academic credentials and a solid foundation in computer sciences and distributed systems design and development. \n The candidate will have had at least 6 years of experience developing scalable, robust software platforms using Java/Ruby/Python or an equivalent language. \n An undergraduate degree in Computer Science (or a related field) from a university where the primary language of instruction is English is strongly desired. \n Strong communication skills in a large-distributed development team environment are essential. \n \n Qualification: \n \n BS or MS in Computer Science or related field \n 8 -12 years of working experience with Python, Ruby and/or J2EE technology or equivalent OO paradigm \n Strong knowledge and experience with Kafka, Elastic Search, NoSQL databases such as Aerospike, Thrift, CI, and AWS. \n Experience working with container-based solutions is a plus. \n Experience working in a fast-paced technology environment. \n Strong object-oriented programming and design skills. \n Excellent problem solving, critical thinking, and communication skills. \n Ability and desire to learn new skills and take on new tasks. \n \n \n \n  BENEFITS & PERKS \n \n Unlimited PTO \n Excellent medical, dental, and vision coverage \n Employee Equity and Stock Purchase Plan \n Employee Discounts, Virtual Wellness Classes, and Pet Insurance And more!! \n \n SALARY RANGE \n  The compensation range for this role is $150,000.00 - $200,000.00, depending on location and experience. \n  PEOPLE & CULTURE AT ZETA \n  Zeta considers applicants for employment without regard to, and does not discriminate on the basis of an individual's sex, race, color, religion, age, disability, status as a veteran, or national or ethnic origin; nor does Zeta discriminate on the basis of sexual orientation, gender identity or expression. \n  We're committed to building a workplace culture of trust and belonging, so everyone feels invited to bring their whole selves to work. We provide a forum for employees to celebrate, support and advocate for one another. Learn more about our commitment to diversity, equity and inclusion here: https://zetaglobal.com/blog/a-look-into-zetas-ergs/ \n  ZETA IN THE NEWS! \n  https://zetaglobal.com/press/?cat=press-releases \n  #LI-MC1 \n \n \n  #LI-Remote",
        "cleaned_desc": "WHO WE ARE \n  Zeta Global (NYSE: ZETA) is the Data-Powered Marketing Cloud that leverages advanced artificial intelligence (AI) and trillions of consumer signals to make it easier for marketers to acquire, grow, and retain customers more efficiently. Through the Zeta Marketing Platform (ZMP), our vision is to make sophisticated marketing simple by unifying identity, intelligence, and omnichannel activation into a single platform \u2013 powered by one of the industry's largest proprietary databases and AI. Our enterprise customers across multiple verticals are empowered to personalize experiences with consumers at an individual level across every channel, delivering better results for marketing programs. Zeta was founded in 2007 by David A. Steinberg and John Sculley and is headquartered in New York City with offices around the world. \n \n \n  THE ROLE \n  Zeta Marketing Platform (ZMP) is a machine learning/AI powered customer acquisition and CRM multi-tenant platform. The backend developer will work on server-side APIs and services that enable a highly distributed event pipeline and a stack that gets tens of thousands of messages per second. \n  As a senior member of the Software Engineering team, you will join the group responsible for designing, developing, and owning the distributed systems CRM platform for Zeta. You will collaborate with your fellow Engineers and Product Managers to develop a roadmap and subsequent projects to build the next generation comprehensive, multichannel marketing solution that unifies and unlocks data across digital touch points, driving return on marketing investment. \n  You should have a deep knowledge of distributed systems and cloud architecture. You will need extensive design and development experience and be passionate about working with high-throughput systems where the issues of throughput, performance, redundancy, and concurrency are paramount. \n  Key Responsibilities:  \n As a Senior Software Developer, you will be:   The candidate will have had at least 6 years of experience developing scalable, robust software platforms using Java/Ruby/Python or an equivalent language. \n An undergraduate degree in Computer Science (or a related field) from a university where the primary language of instruction is English is strongly desired. \n Strong communication skills in a large-distributed development team environment are essential. \n \n Qualification: \n \n BS or MS in Computer Science or related field \n 8 -12 years of working experience with Python, Ruby and/or J2EE technology or equivalent OO paradigm \n Strong knowledge and experience with Kafka, Elastic Search, NoSQL databases such as Aerospike, Thrift, CI, and AWS. \n Experience working with container-based solutions is a plus. ",
        "techs": [
            "kafka",
            "elastic search",
            "nosql databases",
            "aerospike",
            "thrift",
            "ci",
            "aws"
        ],
        "cleaned_techs": [
            "kafka",
            "elastic search",
            "nosql",
            "aerospike",
            "thrift",
            "ci",
            "aws"
        ]
    },
    "a73d73124fa3ba54": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Computer Vision Engineer / Scientist - Stryker",
        "company": "OpenTeams",
        "desc": "Who We Are \n  OpenTeams is the services marketplace where open source software users can find, vet, and contract with service providers. At OpenTeams we believe in a culture of do-ers, learners, and collaborators. We are looking for people who are motivated, humble, curious, and respectful of others. In order to meet the demands of our high growth business, we are looking for talented individuals to provide insights, solutions, and strategy to our internal leadership team and client partners. \n \n  As a  Senior CV Engineer/Scientist , you will play a crucial role in driving business impacts and delving deep into the complexities of computer vision and deep learning problem-solving. This high-visibility opportunity is a perfect match for technical leaders who are passionate about making a tangible difference in the AI healthcare landscape. \n  Technical Responsibilities: \n \n Work and collaborate with the CV/ML team to design, prototype, evaluate, optimize, implement and deploy CV/DL algorithms as an integral part of AI-powered medical technologies for the operating room. \n Participate in cutting edge research in computer vision that can be applied to AR/xR product development. \n Design and develop novel computer vision and/or machine learning algorithms in areas such as: real-time scene and object tracking, reconstruction and understanding as well as, segmentation, face tracking, body tracking, key point estimation, depth sensing, generative approaches such as GANs, 3D stereo and volumetric reconstruction, 2D / 3D medical imaging segmentation and rendering. \n Research and prototype state-of-the-art computer vision and deep learning methods to develop solutions that meets product requirements. \n Design algorithm evaluation frameworks, schedule and report algorithm performance on a regular basis. \n Formulate processes for choosing appropriate sensors based on requirements like cameras and developing image processing algorithms, with an emphasis on classical computer vision, 3D geometry, and deep learning. \n Document and present progress in algorithm design, development, and evaluation (requirements/design/architecture/bugs/tests). \n Lead code reviews for projects/systems as an independent reviewer applying design principles, coding standards and best practices. \n \n Qualifications \n \n \n Bachelor's degree in software engineering/ Computer Science or related discipline with 2+ years of work experience OR Master's in relevant disciplines with 0+ years of experience \n Industry experience working on projects such as: real-time SLAM and 3D reconstruction, sensor fusion and active depth sensing, object and body tracking and pose estimation, and/or image processing. Image and/or semantic segmentation, 2D and 3D key point estimation and surface reconstruction, depth estimation, generative methods such as GANs, or photorealistic rendering. \n Practical Experience with Python or C/C++. \n Experience with camera calibration, stereo vision, tracking, 3D points clouds, registration and associated algorithm development. \n Experience with deep learning framework such as PyTorch, Tensorflow, Keras, Caffe, etc for deep learning model training and deployment. \n Strong background in at least three of these specialties: (i) 3D Vision and projective geometry, (ii) Computer Graphics, (iii) Deep learning/machine learning for computer vision, (iv) Practical applications of classical computer vision and machine learning techniques. \n Practical experience with computer vision frameworks like OpenCV, Open3D, PCL, etc. \n Experience in designing and training and deploying production-grade deep learning architectures for computer vision application with a broad under\u2010standing of latest CV / DL methods and literature. \n Experience in writing reusable, scalable, test-driven and well documented codebase. \n Excellent writing and verbal communication skills. \n Bonus for: (i) Previous experience with any head-mounted (ego-centric device) or xR platform, (ii) Academic publication in CV/AI conferences / journals such as CVPR, ICCP, ICCV, NeurIPS, etc. is a plus. \n \n \n Why You Should Join \n  You'll become an important part of a collaborative, remote-first team. We are a passionate and ambitious team, with a proven record of success building multiple companies. We strive to provide a working environment that gives you room to learn and grow. OpenTeams is committed to creating a diverse and inclusive work environment and is proud to be an equal opportunity employer. \n  All qualified applicants will receive equal consideration for recruitment, interviews, employment, training, compensation, promotion, and related activities without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status or any and all other protected classes and in accordance with all applicable laws.",
        "cleaned_desc": " Bachelor's degree in software engineering/ Computer Science or related discipline with 2+ years of work experience OR Master's in relevant disciplines with 0+ years of experience \n Industry experience working on projects such as: real-time SLAM and 3D reconstruction, sensor fusion and active depth sensing, object and body tracking and pose estimation, and/or image processing. Image and/or semantic segmentation, 2D and 3D key point estimation and surface reconstruction, depth estimation, generative methods such as GANs, or photorealistic rendering. \n Practical Experience with Python or C/C++. \n Experience with camera calibration, stereo vision, tracking, 3D points clouds, registration and associated algorithm development. \n Experience with deep learning framework such as PyTorch, Tensorflow, Keras, Caffe, etc for deep learning model training and deployment. \n Strong background in at least three of these specialties: (i) 3D Vision and projective geometry, (ii) Computer Graphics, (iii) Deep learning/machine learning for computer vision, (iv) Practical applications of classical computer vision and machine learning techniques.   Practical experience with computer vision frameworks like OpenCV, Open3D, PCL, etc. \n Experience in designing and training and deploying production-grade deep learning architectures for computer vision application with a broad under\u2010standing of latest CV / DL methods and literature. \n Experience in writing reusable, scalable, test-driven and well documented codebase. \n Excellent writing and verbal communication skills. \n Bonus for: (i) Previous experience with any head-mounted (ego-centric device) or xR platform, (ii) Academic publication in CV/AI conferences / journals such as CVPR, ICCP, ICCV, NeurIPS, etc. is a plus. \n ",
        "techs": [
            "python",
            "c/c++",
            "pytorch",
            "tensorflow",
            "keras",
            "caffe",
            "opencv",
            "open3d",
            "pcl"
        ],
        "cleaned_techs": [
            "python",
            "c/c++",
            "pytorch",
            "tensorflow",
            "keras",
            "caffe",
            "opencv",
            "open3d",
            "pcl"
        ]
    },
    "de789511392895d7": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 116621.01,
        "salary_max": 147668.19,
        "title": "Advanced Software Engineer (Sr Site Reliability Engineer)",
        "company": "Honeywell",
        "desc": "Advanced Software Engineer (Sr Site Reliability Engineer) \n \n Advanced Software Engineer (Sr Site Reliability Engineer) for Honeywell International, Inc. (Atlanta, GA) \n \n \n RESPONSIBILITIES:  \n \n \n Focus on the products \u201cProduction Insights\u201d and \u201cEmission,\u201d which aim to optimize energy and protect the environment by identifying energy leakage based on streaming telemetry data and providing close insights for connected industrial plants. \n Maintain and improve the legacy product \u201cForge Insights.\u201d \n Forge Insights product is data-driven insights of business, which collect the data from all the lines of business runs in Honeywell and provide insights visualization to help the business owner make the right decision to extract better outcome. \n Build, design, improve reliability, and add features to the products. \n Build a global Grafana dashboard to monitor Microsoft Azure services, OpenShift, Microservices, Databases, and all the essential components which help us maintain Service Level Agreements, Service Level Objectives, and Service Level Indicators. \n Configure proactive Alerts of the services, which help us to improve the error budget and fill toll gaps. \n Work closely with Architect and Cybersecurity team to enhance product overall workflow design and reduce cyber-attacks by following a zero-trust policy. \n Identify security gaps and close those gaps by patching systems by using automation tools, redesigning the approval process, and migrating the workbook to new workspaces to disable the publicly accessible endpoint\u2014cost optimization of resources. \n \n \n \n \n  ADDITIONAL INFORMATION: \n \n \n Job Site: Atlanta, GA \n 40 hours/week \n Eligible for Employee Referral Program: $1500 \n If offered employment must have legal right to work in U.S. EOE. \n \n \n  YOU MUST HAVE: \n  Qualified applicants must have a Master\u2019s degree or foreign equivalent in Computer Science, Computer Engineering, or a related field and four (4) years of experience with system administration, application development, software engineering, infrastructure development, or related areas.  \n Alternatively, the employer will accept a Ph.D. in the stated fields and two (2) years of experience listed.  \n Must possess one (1) year of experience in the following: programming in languages, including JavaScript, Python, Java, or Ruby; Data Analysis for Data Science / Data warehouse / ETL projects, Big Data, Machine Learning, and Application Architect; with expertise in the following areas: Azure Cloud Service, JIRA, AD Server, Docker, Teradata, Ranger, Kafka, Hive, Sqoop, Autosys, Ansible, DTS, NDM, JFrog, Zookeeper, Sentry, Spark, Networking, and Cloud Security. \n  Telecommuting is permitted two (2) times per week. \n  Additional Information \n \n  JOB ID:  req416347 \n  Category:  Engineering \n  Location:  715 Peachtree Street, N.E.,Atlanta,Georgia,30308,United States \n  Exempt \n \n \n  Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.",
        "cleaned_desc": " Must possess one (1) year of experience in the following: programming in languages, including JavaScript, Python, Java, or Ruby; Data Analysis for Data Science / Data warehouse / ETL projects, Big Data, Machine Learning, and Application Architect; with expertise in the following areas: Azure Cloud Service, JIRA, AD Server, Docker, Teradata, Ranger, Kafka, Hive, Sqoop, Autosys, Ansible, DTS, NDM, JFrog, Zookeeper, Sentry, Spark, Networking, and Cloud Security. \n  Telecommuting is permitted two (2) times per week. \n  Additional Information \n \n  JOB ID:  req416347 \n  Category:  Engineering \n  Location:  715 Peachtree Street, N.E.,Atlanta,Georgia,30308,United States \n  Exempt ",
        "techs": [
            "javascript",
            "python",
            "java",
            "ruby",
            "azure cloud service",
            "jira",
            "ad server",
            "docker",
            "teradata",
            "ranger",
            "kafka",
            "hive",
            "sqoop",
            "autosys",
            "ansible",
            "dts",
            "ndm",
            "jfrog",
            "zookeeper",
            "sentry",
            "spark",
            "networking",
            "cloud security"
        ],
        "cleaned_techs": [
            "javascript",
            "python",
            "java",
            "ruby",
            "azure",
            "jira",
            "ad server",
            "docker",
            "teradata",
            "ranger",
            "kafka",
            "hive",
            "sqoop",
            "autosys",
            "ansible",
            "dts",
            "ndm",
            "jfrog",
            "zookeeper",
            "sentry",
            "spark",
            "networking"
        ]
    },
    "920637f8545a16ec": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 170593.08,
        "salary_max": 216008.86,
        "title": "Staff Platform Engineer",
        "company": "Afresh",
        "desc": "Afresh is on a mission to eliminate food waste and make fresh food accessible to all. Our first A.I.-powered solution optimizes ordering, forecasting, and store operations for fresh food departments in brick-and-mortar grocers. With our Fresh Operating System, regional and national grocery retailers have placed $1.6 billion in produce orders across the US and we've helped our partners prevent 34 million pounds of food from going to waste. Working at Afresh represents a one-of-a-kind opportunity to have massive social impact at scale by leveraging uncommonly impactful software \u2013 we hope you'll join us! \n \n About the role \n \n Directly impact our mission of reducing fresh food waste by working on our backend data and machine learning platform that uses massive amounts of grocery store data to make ordering recommendations \n Build out our backend data platform as well as supporting tooling to process tens of billions of historical data points collected from tens of thousands of retail stores and beyond \n Support developer experience for our wider engineering organization across functions and teams \n Leverage modern data analysis and processing frameworks, programming languages, and tooling\u2014such as Apache Spark, Pandas, Python, and SQL\u2014to provide powerful compute capabilities to our data platform \n Scale our data backends that leverage a combination of traditional databases, data warehouses, and data lakes to support varying access patterns \n Scale up your impact by leading technical projects, participating in technical and design decisions, mentoring engineers, and participating in recruiting functions \n Act as an exemplar for our culture of excellence, curiosity, collaboration, proactivity, candor, humility, and kindness \n \n Skills and experience \n \n 5+ years of professional software engineering experience \n Bachelor's degree in a STEM field, ideally in computer science or related field \n Outstanding programming skills with deep knowledge of databases, distributed systems, and backend concepts \n Demonstrated ability to design, build, deploy, and manage large production compute or data backend platforms at scale \n Experience using modern big data frameworks, scaling computation to hundreds of machines, and/or working with machine learning systems preferred \n Demonstrated ability to triage and solve open-ended, ambiguous systems-level problems \n \n The above represent attributes our ideal candidate possesses. We encourage all highly-qualified candidates to apply, even if they do not fulfill all the listed criteria. \n  #LI-REMOTE \n \n About Afresh    Founded in 2017, Afresh is working on the #1 solution to curb climate change: reducing food waste. By combining human insight and transformative technology, we're helping grocers provide fresher food to customers at more affordable prices.     Afresh sits at an incredible intersection of positive social impact, rocket ship financial growth, and cutting-edge technology. Our best-in-class AI research has been published in top journals including ICML, and we've raised over $148 million in funding from investors including former co-CEO of Whole Foods Market Walter Robb and Eric Schmidt's Innovation Endeavors. \n  Fresh is the past, present, and future of our food system \u2013 the waste we create today will impact our planet for years to come. Join us as we continue to build a vibrant, diverse, and inclusive team that embodies our company\u2019s values of proactivity, kindness, candor, and humility.     Afresh provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity/expression, marital status, pregnancy or related condition, or any other basis protected by law. \n  Here at Afresh, many of our employees work remotely provided that they reside in one of the following states: AR, CA, CO, FL, GA, IL, KY, MA, MI, MT, MO, NV, NJ, NY, NC, OR, PA, TX, WA, WI. However, there may be key roles that will require a candidate/employee to be local to our San Francisco, CA office. In which case this requirement will be included in the job posting details under \"Skills and experience\" for reference.",
        "cleaned_desc": " Build out our backend data platform as well as supporting tooling to process tens of billions of historical data points collected from tens of thousands of retail stores and beyond \n Support developer experience for our wider engineering organization across functions and teams \n Leverage modern data analysis and processing frameworks, programming languages, and tooling\u2014such as Apache Spark, Pandas, Python, and SQL\u2014to provide powerful compute capabilities to our data platform \n Scale our data backends that leverage a combination of traditional databases, data warehouses, and data lakes to support varying access patterns \n Scale up your impact by leading technical projects, participating in technical and design decisions, mentoring engineers, and participating in recruiting functions   Bachelor's degree in a STEM field, ideally in computer science or related field \n Outstanding programming skills with deep knowledge of databases, distributed systems, and backend concepts \n Demonstrated ability to design, build, deploy, and manage large production compute or data backend platforms at scale \n Experience using modern big data frameworks, scaling computation to hundreds of machines, and/or working with machine learning systems preferred \n Demonstrated ability to triage and solve open-ended, ambiguous systems-level problems ",
        "techs": [
            "apache spark",
            "pandas",
            "python",
            "sql"
        ],
        "cleaned_techs": [
            "apache spark",
            "pandas",
            "python",
            "sql"
        ]
    },
    "543a87736d607245": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Safety Engineer, Senior",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Stafford,VA,US \n         \n \n \n \n         Remote Work: \n         \n \n         Hybrid \n         \n \n \n \n         Job Number: \n         \n \n         R0180392\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         Safety Engineer, Senior\n           The Opportunity: \n  Are you looking for an opportunity to combine your technical expertise with big picture thinking to make an impact in Environment, Safety, and Occupational Health (EOSH)? Our team supports senior-level DoD personnel with environment, system safety, and occupational health implementation and oversight for DoD system programs. You\u2019ll leverage your specialized knowledge and expertise in ESOH, including applying scientific and engineering principles, criteria, and techniques to identify and assess ESOH hazards and inform the implementation of mitigations to reduce warfighter risk. \n \n  As a systems engineer on our team, you'll enjoy a dynamic team environment of client and contractor staff while executing comprehensive system safety programs or individual tasks on a variety of systems, including unmanned systems, ground-based missile systems, surface vessel threat and support systems, and laser systems. Typical work products, including Safety Releases, National Environmental Policy Act (NEPA) documentation, Programmatic ESOH Evaluations, System Safety Program Plans (SSPP), a variety of analyses, such as Preliminary Hazard Analysis (PHA), Subsystem and System Hazard Analysis (SHA and SSHA), Operating and Support Hazard Analysis (O&SHA), Explosive Ordnance Disposal (EOD) analysis, Safety Assessment Reports (SAR), and test report evaluations. You'll analyze data, develop written deliverables, assist with the presentation of results, and assist with the review of client system safety artifacts to verify compliance with requirements, policy, and guidance documents. You'll conduct these tasks following established plans and quality standards and the freedom to improve processes and advance the EOSH discipline. \n \n  Join us. The world can\u2019t wait. \n \n  You Have: \n \n  12+ years of experience with ESOH tasking \n  Experience with overseeing and mentoring junior- and mid-level ESOH engineers \n  Experience with applying Military safety analyses and safety program implementation \n  Ability to analyze, research, assess, and organize technical data into cohesive and clear technical reports and presentations \n  Ability to organize, schedule, and facilitate technical meetings and working groups \n  Secret clearance \n  Bachelor's degree \n \n \n  Nice If You Have: \n \n  Experience with NAVSEAINST 8020.6, Weapon System Explosives Safety Review Board (WSESRB), or Software Systems Safety Technical Review Panel (SSSTRP) \n  Experience with performing risk assessments and analysis employing modeling and simulation techniques, including leveraging Model-Based Systems Engineering (MBSE) to perform ESOH assessments in digital models \n  Experience with Digital Engineering, Machine Learning and Artificial Intelligence, Software Development, Solid-state Electrical Circuit Design, Unmanned Systems Design, Human Factors Engineering, or Fault Tree Analysis \n  Possession of excellent verbal and written communication skills \n  Associate Safety and Health Manager (ASHM), Certified Industrial Hygienist (CIH), Certified Hazardous Materials Manager (CHMM), Certified Safety Professional (CSP), Certified Fire Protection Specialist (CFPS), Safety Management Specialist (SMS), Navy WISE Principal for Safety (PFS), and Marine Corps Systems Command (MCSC) Principal for Environment, Safety, Occupational Health (PESOH) with Level II MCSCO 5090 ESOH Certification \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. \n \n  Create Your Career: \n \n  Grow With Us \n  Your growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. \n \n  A Place Where You Belong \n  Diverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll build your community in no time. \n \n  Support Your Well-Being \n  Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home. \n \n  Your Candidate Journey \n  At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "61471b631bded2b4": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 70.0,
        "salary_max": 100.0,
        "title": "Sr. Storage Engineer (NetApp)",
        "company": "BigR.io",
        "desc": "Sr. System Engineer/ Storage Engineer with NetApp Experience Boston/ Cambridge, MA - Remote (Occasional travel) 99% Remote Opportunity \n About BigR.io:  BigR.io is a remote-based, technology consulting firm with headquarters in Boston, MA. We deliver software solutions ranging from custom development, software implementation, data analytics, and machine learning/AI integrations. We are a one-stop shop that attracts clients from a variety of industries because of our proven ability to deliver cutting-edge and cost-conscious software solutions. \n Our thought-forward, Big Data team is working on a number of data architecture and software-solution projects. You will join this high-caliber team as a Technical Consultant who will work with our clients to implement software-based solutions to fit their needs. \n Job Description:  BigR.io is seeking a highly skilled Senior System Engineer/ Storage Engineer with extensive experience in NetApp storage systems to join our team. The ideal candidate will have a proven track record of designing, implementing, and managing complex NetApp storage environments in enterprise-level organizations. \n Responsibilities: \u25cf Design, implement, and manage complex NetApp storage environments. \u25cf Work closely with cross-functional teams to ensure the availability and performance of the storage infrastructure. \u25cf Develop and implement storage strategies and procedures to ensure optimal performance and availability. \u25cf Provide technical expertise in the development of solutions and proposals for customers. \u25cf Lead the resolution of complex storage issues, working with vendors and other technical teams as required. \u25cf Develop and maintain documentation of storage systems, configurations, and procedures. \u25cf Participate in capacity planning and performance analysis activities. \u25cf Develop and maintain disaster recovery plans and procedures. \u25cf Provide training and mentoring to junior members of the team. \n Qualifications: \u25cf Bachelor's degree in Computer Science or a related field, or equivalent experience. \u25cf 8+ years of experience in designing, implementing, and managing complex NetApp storage environments. \u25cf Strong knowledge of NetApp storage technologies including ONTAP, FAS, AFF, and Clustered Data ONTAP. \u25cf Experience with storage protocols including NFS, CIFS, iSCSI, and FCP. \u25cf Strong understanding of virtualization technologies such as VMware and Hyper-V. \u25cf Experience with backup and recovery solutions, including NetBackup and Commvault. \u25cf Strong understanding of networking technologies and protocols. \u25cf Excellent problem-solving skills and the ability to troubleshoot complex issues. \u25cf Strong communication and interpersonal skills. \u25cf Ability to work independently as well as in a team environment. \u25cf NetApp certification such as NCDA or NCIE is highly desirable. \u25cf Knowledge of cloud computing technologies, such as AWS and Azure \u25cf Familiarity with storage virtualization and data management \u25cf Experience with containerization technologies, such as Docker and Kubernetes \n This is an excellent opportunity for an experienced engineer to work on cutting-edge technology solutions and collaborate with a team of highly skilled professionals. If you have a passion for engineering and NetApp, we encourage you to apply for this position. \n Job Types: Full-time, Contract \n Salary: $70.00 - $100.00 per hour \n Benefits: \n \n Dental insurance \n Health insurance \n Vision insurance \n \n Schedule: \n \n 8 hour shift \n Monday to Friday \n No weekends \n \n Experience: \n \n System/ Storage Engineer: 8 years (Required) \n NetApp: 5 years (Required) \n Cloud: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Sr. System Engineer/ Storage Engineer with NetApp Experience Boston/ Cambridge, MA - Remote (Occasional travel) 99% Remote Opportunity \n About BigR.io:  BigR.io is a remote-based, technology consulting firm with headquarters in Boston, MA. We deliver software solutions ranging from custom development, software implementation, data analytics, and machine learning/AI integrations. We are a one-stop shop that attracts clients from a variety of industries because of our proven ability to deliver cutting-edge and cost-conscious software solutions. \n Our thought-forward, Big Data team is working on a number of data architecture and software-solution projects. You will join this high-caliber team as a Technical Consultant who will work with our clients to implement software-based solutions to fit their needs. \n Job Description:  BigR.io is seeking a highly skilled Senior System Engineer/ Storage Engineer with extensive experience in NetApp storage systems to join our team. The ideal candidate will have a proven track record of designing, implementing, and managing complex NetApp storage environments in enterprise-level organizations. \n Responsibilities: \u25cf Design, implement, and manage complex NetApp storage environments. \u25cf Work closely with cross-functional teams to ensure the availability and performance of the storage infrastructure. \u25cf Develop and implement storage strategies and procedures to ensure optimal performance and availability. \u25cf Provide technical expertise in the development of solutions and proposals for customers. \u25cf Lead the resolution of complex storage issues, working with vendors and other technical teams as required. \u25cf Develop and maintain documentation of storage systems, configurations, and procedures. \u25cf Participate in capacity planning and performance analysis activities. \u25cf Develop and maintain disaster recovery plans and procedures. \u25cf Provide training and mentoring to junior members of the team.   Qualifications: \u25cf Bachelor's degree in Computer Science or a related field, or equivalent experience. \u25cf 8+ years of experience in designing, implementing, and managing complex NetApp storage environments. \u25cf Strong knowledge of NetApp storage technologies including ONTAP, FAS, AFF, and Clustered Data ONTAP. \u25cf Experience with storage protocols including NFS, CIFS, iSCSI, and FCP. \u25cf Strong understanding of virtualization technologies such as VMware and Hyper-V. \u25cf Experience with backup and recovery solutions, including NetBackup and Commvault. \u25cf Strong understanding of networking technologies and protocols. \u25cf Excellent problem-solving skills and the ability to troubleshoot complex issues. \u25cf Strong communication and interpersonal skills. \u25cf Ability to work independently as well as in a team environment. \u25cf NetApp certification such as NCDA or NCIE is highly desirable. \u25cf Knowledge of cloud computing technologies, such as AWS and Azure \u25cf Familiarity with storage virtualization and data management \u25cf Experience with containerization technologies, such as Docker and Kubernetes \n This is an excellent opportunity for an experienced engineer to work on cutting-edge technology solutions and collaborate with a team of highly skilled professionals. If you have a passion for engineering and NetApp, we encourage you to apply for this position. \n Job Types: Full-time, Contract \n Salary: $70.00 - $100.00 per hour \n Benefits: ",
        "techs": [
            "netapp storage systems",
            "ontap",
            "fas",
            "aff",
            "clustered data ontap",
            "nfs",
            "cifs",
            "iscsi",
            "fcp",
            "vmware",
            "hyper-v",
            "netbackup",
            "commvault",
            "networking technologies",
            "ncda",
            "ncie",
            "aws",
            "azure",
            "docker",
            "kubernetes."
        ],
        "cleaned_techs": [
            "netapp storage systems",
            "ontap",
            "fas",
            "aff",
            "clustered data ontap",
            "nfs",
            "cifs",
            "iscsi",
            "fcp",
            "vmware",
            "hyper-v",
            "netbackup",
            "commvault",
            "networking technologies",
            "ncda",
            "ncie",
            "aws",
            "azure",
            "docker",
            "kubernetes."
        ]
    },
    "afd5f74b3c58da57": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 117904.35,
        "salary_max": 149293.19,
        "title": "SENIOR SYSTEMS ENGINEER",
        "company": "Applied Digital",
        "desc": "Company Overview: Applied Digital is a pioneering next-generation datacenter company that specializes in providing high-performance computing cloud solutions to clients in the artificial intelligence and machine learning industries. We are committed to delivering cutting-edge technology and innovative solutions to empower our clients' AI projects. As part of our evolution towards a remote-friendly team, we are seeking a dynamic and experienced Senior Systems Engineer to join us remotely and play a pivotal role in shaping our technology stack and toolset. \n \n  Job Title : Senior Systems Engineer \n  Department: Information Technology \n  Location : Remote (US) \n \n  Job Summary : As a Senior Systems Engineer at Applied Digital, you will have the unique opportunity to help shape our toolset and technology stack while working remotely from anywhere. You will be a key member of our highly motivated team, contributing to modern and pragmatic approaches in infrastructure management and operations. Your expertise will drive the development and implementation of cutting-edge solutions in areas such as infrastructure automation, OS deployments, monitoring and alerting, security frameworks, compute platforms, and core services. \n \n  Responsibilities: \n  Technology Stack Evolution: \n \n  Collaborate with the team to modernize and evolve our technology stack, contributing to the adoption of innovative tools and best practices. \n \n  Infrastructure Automation and Management: \n \n  Utilize HashiCorp Terraform and Ansible to automate infrastructure provisioning, configuration, and management. \n  Contribute to the development of Infrastructure as Code (IAC) practices to ensure scalable and efficient systems. \n \n  Standardized OS Deployments: \n \n  Design and implement standardized OS deployments using tools like HashiCorp Packer, Metal-as-a-Service, Debian, and Ubuntu. \n \n  Monitoring and Alerting Solutions: \n \n  Build out monitoring and alerting solutions using Zabbix, Grafana, and Prometheus to ensure optimal system health and performance. \n \n  Security Frameworks Implementation: \n \n  Implement security frameworks including RBAC, LDAP, PAM, HashiCorp Vault, SSL Certificates, PKI, and Certificate Authority. \n  Enhance security posture by integrating robust security measures across the infrastructure. \n \n  Compute Platforms and Virtualization: \n \n  Work with Kubernetes, Virtualization using KVM and vSphere to optimize compute platforms for efficient and scalable services. \n \n  Core Services Enhancement: \n \n  Build and optimize core services such as DNS, DHCP, and IPAM using tools like BIND, ISC, Kea, Infoblox, and Netbox. \n \n  Continuous Improvement: \n \n  Drive continuous improvement initiatives across infrastructure components, focusing on reliability, performance, and scalability. \n \n  Cross-Functional Collaboration: \n \n  Collaborate with cross-functional teams including DevOps, Security, and Networking to ensure seamless integration of technologies. \n \n \n  Bachelor's degree in Computer Science, Information Technology, or a related field. Advanced degree is a plus. \n  5+ years of experience as a Systems Engineer, with a focus on designing and managing complex infrastructure. \n  Expertise in infrastructure automation using HashiCorp Terraform and Ansible for provisioning and configuration management. \n  Strong familiarity with tools like HashiCorp Packer, Metal-as-a-Service, Debian, and Ubuntu for standardized OS deployments. \n  Experience in implementing monitoring and alerting solutions using Zabbix, Grafana, and Prometheus. \n  Proficiency in implementing security frameworks including RBAC, LDAP, PAM, HashiCorp Vault, SSL Certificates, PKI, and Certificate Authority. \n  In-depth knowledge of compute platforms such as Kubernetes, Virtualization with KVM and vSphere. \n  Experience building and optimizing core services including DNS, DHCP, and IPAM using tools like BIND, ISC, Kea, Infoblox, and Netbox. \n  Strong analytical and problem-solving skills, with the ability to architect and optimize complex systems. \n  Excellent communication and collaboration skills for effective remote teamwork. \n  Proven ability to drive process improvement and contribute to modern, forward-looking technology strategies. \n \n \n  Application Process: \n  If you are interested in this position and meet the qualifications mentioned above, we encourage you to apply by submitting your resume and a cover letter outlining your relevant experience. We thank all applicants for their interest; however, only those selected for an interview will be contacted.",
        "cleaned_desc": "  Bachelor's degree in Computer Science, Information Technology, or a related field. Advanced degree is a plus. \n  5+ years of experience as a Systems Engineer, with a focus on designing and managing complex infrastructure. \n  Expertise in infrastructure automation using HashiCorp Terraform and Ansible for provisioning and configuration management. \n  Strong familiarity with tools like HashiCorp Packer, Metal-as-a-Service, Debian, and Ubuntu for standardized OS deployments. \n  Experience in implementing monitoring and alerting solutions using Zabbix, Grafana, and Prometheus. \n  Proficiency in implementing security frameworks including RBAC, LDAP, PAM, HashiCorp Vault, SSL Certificates, PKI, and Certificate Authority. \n  In-depth knowledge of compute platforms such as Kubernetes, Virtualization with KVM and vSphere. \n  Experience building and optimizing core services including DNS, DHCP, and IPAM using tools like BIND, ISC, Kea, Infoblox, and Netbox. \n  Strong analytical and problem-solving skills, with the ability to architect and optimize complex systems. \n  Excellent communication and collaboration skills for effective remote teamwork. \n  Proven ability to drive process improvement and contribute to modern, forward-looking technology strategies. \n ",
        "techs": [
            "bachelor's degree in computer science",
            "information technology",
            "or a related field",
            "hashicorp terraform",
            "ansible",
            "hashicorp packer",
            "metal-as-a-service",
            "debian",
            "ubuntu",
            "zabbix",
            "grafana",
            "prometheus",
            "rbac",
            "ldap",
            "pam",
            "hashicorp vault",
            "ssl certificates",
            "pki",
            "certificate authority",
            "kubernetes",
            "kvm",
            "vsphere",
            "bind",
            "isc",
            "kea",
            "infoblox",
            "netbox"
        ],
        "cleaned_techs": [
            "information technology",
            "or a related field",
            "hashicorp terraform",
            "ansible",
            "hashicorp packer",
            "metal-as-a-service",
            "debian",
            "ubuntu",
            "zabbix",
            "grafana",
            "prometheus",
            "rbac",
            "ldap",
            "pam",
            "hashicorp vault",
            "ssl certificates",
            "pki",
            "certificate authority",
            "kubernetes",
            "kvm",
            "vsphere",
            "bind",
            "isc",
            "kea",
            "infoblox",
            "netbox"
        ]
    },
    "6f1304ff67dedca2": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 124251.91,
        "salary_max": 157330.6,
        "title": "Software Engineer - Community (P2P) - Cash App",
        "company": "Cash App",
        "desc": "Company Description\n   It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic ecosystem, developing unique financial products, including Afterpay/Clearpay, to provide a better way to send, spend, invest, borrow and save to our 47 million monthly active customers. We want to redefine the world\u2019s relationship with money to make it more relatable, instantly available, and universally accessible.    Today, Cash App has thousands of employees working globally across office and remote locations, with a culture geared toward innovation, collaboration and impact. We\u2019ve been a distributed team since day one, and many of our roles can be done remotely from the countries where Cash App operates. No matter the location, we tailor our experience to ensure our employees are creative, productive, and happy.    Check out our locations, benefits, and more at cash.app/careers. \n \n \n \n Job Description\n   The Team: \n  The Cash Peer-to-peer (P2P) team is in charge of re-imagining and building powerful new product experiences for person to person payments. This team owns and operates the core product experience of millions of Cash App customers. The contributions you make on this team will be used by millions of people in a wide variety of scenarios. We are seeking an experienced and motivated individual to contribute to the development and enhancement of our cutting-edge payment solutions. \n  The Job: \n  As a Software Engineer on this team, you will play a pivotal role in designing, implementing, and maintaining robust, scalable, and secure peer-to-peer payment systems. \n  You will: \n \n  Scope, build, and scale products, systems, and services that have an immediate impact on our customers. \n  Lead and participate in critical technical, design, and product discussions. \n  Test, maintain and deploy high-quality software solutions ensuring adherence to coding best practices and industry standards. \n  Participate in all parts of product development, working with non-Engineering related disciplines (Product and Design) and adjacent Engineering teams (Mobile, Platform, Machine Learning, and Data Science). \n \n \n \n \n Qualifications\n   You have: \n \n  2+ year of professional experience in software development \n  Solid understanding of distributed systems, network protocols, and data structures. \n  Strong problem-solving skills and ability to work in a fast-paced, collaborative environment. \n  Boundless curiosity, persistence and a desire to get things done \n  Experience building backend systems and working with FE/mobile teams \n  Bachelor's Degree or Diploma in Computer Science, or equivalent experience. \n \n  Technologies we use and teach: \n \n  Java, Kotlin \n  MySQL, Dynamo, ElasticSearch, Snowflake, Aurora DB \n  gRPC and Protocol Buffers \n  Amazon Web Services (AWS) \n  DataDog, Prometheus, SignalFx \n \n  Additional Information\n   This role can support remote employment across North America.Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.    Zone A: USD $152,100 - USD $185,900  Zone B: USD $144,500 - USD $176,700  Zone C: USD $136,900 - USD $167,300  Zone D: USD $129,300 - USD $158,100 \n \n  To find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \n  Full-time employee benefits include the following: \n \n  Healthcare coverage (Medical, Vision and Dental insurance) \n  Health Savings Account and Flexible Spending Account \n  Retirement Plans including company match \n  Employee Stock Purchase Program \n  Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \n  Paid parental and caregiving leave \n  Paid time off (including 12 paid holidays) \n  Paid sick leave (1 hour per 26 hours worked (max 80 hours per calendar year to the extent legally permissible) for non-exempt employees and covered by our Flexible Time Off policy for exempt employees) \n  Learning and Development resources \n  Paid Life insurance, AD&D, and disability benefits \n  Additional Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \n \n  These benefits are further detailed in Block's policies. This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. \n  US and Canada EEOC Statement \n  We\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \n  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Want to learn more about what we\u2019re doing to build a workplace that is fair and square? Check out our  I+D page . \n  Additionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis. \n \n \n  Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.",
        "cleaned_desc": "  Scope, build, and scale products, systems, and services that have an immediate impact on our customers. \n  Lead and participate in critical technical, design, and product discussions. \n  Test, maintain and deploy high-quality software solutions ensuring adherence to coding best practices and industry standards. \n  Participate in all parts of product development, working with non-Engineering related disciplines (Product and Design) and adjacent Engineering teams (Mobile, Platform, Machine Learning, and Data Science). \n \n \n \n \n Qualifications\n   You have: \n \n  2+ year of professional experience in software development    Solid understanding of distributed systems, network protocols, and data structures. \n  Strong problem-solving skills and ability to work in a fast-paced, collaborative environment. \n  Boundless curiosity, persistence and a desire to get things done \n  Experience building backend systems and working with FE/mobile teams \n  Bachelor's Degree or Diploma in Computer Science, or equivalent experience. \n \n  Technologies we use and teach: \n \n  Java, Kotlin \n  MySQL, Dynamo, ElasticSearch, Snowflake, Aurora DB \n  gRPC and Protocol Buffers \n  Amazon Web Services (AWS) ",
        "techs": [
            "scope",
            "build",
            "scale",
            "lead",
            "participate",
            "test",
            "maintain",
            "deploy",
            "software development",
            "distributed systems",
            "network protocols",
            "data structures",
            "problem-solving",
            "fast-paced",
            "collaborative environment",
            "java",
            "kotlin",
            "mysql",
            "dynamo",
            "elasticsearch",
            "snowflake",
            "aurora db",
            "grpc",
            "protocol buffers",
            "amazon web services (aws)"
        ],
        "cleaned_techs": [
            "scope",
            "build",
            "scale",
            "lead",
            "participate",
            "test",
            "maintain",
            "deploy",
            "software development",
            "distributed systems",
            "network protocols",
            "data structures",
            "problem-solving",
            "fast-paced",
            "collaborative environment",
            "java",
            "kotlin",
            "mysql",
            "dynamo",
            "elasticsearch",
            "snowflake",
            "aurora db",
            "grpc",
            "protocol buffers",
            "aws"
        ]
    },
    "ae4311a1be49de1a": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 82000.0,
        "salary_max": 185000.0,
        "title": "Senior Software Engineer- DataOps Cloud (REMOTE)",
        "company": "GEICO",
        "desc": "Position Summary\n  \n \n   GEICO is seeking an experienced Senior Engineer with a passion for building high performance, low-latency platforms, and applications. You will help drive our insurance business transformation as we redefine experiences for our customers.\n  \n \n \n   Position Description\n  \n \n   Our Senior Engineer is a key member of the engineering staff working across the organization to provide a friction-less experience to our customers and maintain the highest standards of protection and availability. Our team thrives and succeeds in delivering high quality technology products and services in a hyper-growth environment where priorities shift quickly. The ideal candidate has broad and deep technical knowledge, typically ranging from front-end UIs through back-end systems and all points in between.\n  \n \n \n   Position Responsibilities\n  \n \n   As a Senior Engineer, you will:\n  \n \n Develop general infrastructure technology in a public/private cloud \n Design, configure, optimize, manage, monitor, document and support platform services and components, as well as supporting enterprise data ingestion \n Work with a wide range of stakeholders and functional teams and establish a high trust partnership with internal business partners, and other IT groups to support company initiatives \n Provide advanced system administration, operational support, and problem resolution for a large complex cloud computing environment in and develop scripts to automate the deployment of resource stacks and associated configurations \n Extend standard systems management processes into the cloud including change, incident, and problem management \n Develop and maintain a library of deployable, tested, and documented automation design scripts, processes, and procedures \n Enable DevOps development activities and complex development tasks that will involve working with a wide variety of tools and container management systems \n Coordinate and bring application experts and other infrastructure teams together for finding optimal solutions to issues related to capacity, security, performance \n Implement and maintain CI/CD solutions and create code deployment models to support self-service automation \n \n \n \n   Qualifications\n   \n \n A technical background and knowledge of big data foundational concepts such as relational database, data warehouse, and data lakes is required to help build and maintain robust, scalable data and machine learning platforms \n Be well versed on general infrastructure technology and understand public and private cloud concepts such as Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS) \n Experience configuring and managing technologies used in big data and machine learning such as Snowflake, Spark, virtual networking in cloud environments \n Experience with container orchestration tools such as Docker and Kubernetes \n Experience with infrastructure-as-code technologies such as Terraform \n Extensive experience and strong understanding of cloud and infrastructure components. Preferred technologies include Azure, event streaming, data transformation, data warehouse, Azure Data Factory, and Azure data lake and services \n Strong working knowledge of networking concepts such as DNS, DHCP, Firewalls, Sub netting with a preference in Azure \n Automation experience and strong coding & scripting skills (shell, NodeJS, Python etc.) \n Experience in backend programming languages like PL/SQL, T-SQL, NZ SQL etc. \n Awareness of DB Optimization techniques pertinent to cloud data warehouses. Snowflake preferred \n Understanding of data ingress & egress patterns between cloud components. Big data Snowflake and different cloud service providers preferred \n Proficiency in Spark and Snowflake platform Architecture, function/feature is a plus \n Experience architecting and designing current systems \n Advanced understanding of DevOps concepts including Azure DevOps framework and tools \n Advanced understanding of monitoring concepts and tooling \n Experience with continuous delivery and infrastructure as code \n Strong problem-solving ability \n Ability to excel in a fast-paced environment \n Knowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) \n Experience and good understanding of big data eco systems like Hadoop, Spark, and Snowflake \n \n \n \n \n   Experience\n  \n \n 4+ years of professional software development and/or infrastructure experience \n 3+ years of experience with AWS, GCP, Azure, or another cloud service \n 3+ years of experience with architecture and design \n 2+ years of experience in open-source frameworks \n \n \n   Education\n  \n \n Bachelor\u2019s degree in Computer Science, Information Systems, or equivalent education or work experience \n \n \n \n  Annual Salary\n   $82,000.00 - $185,000.00\n  \n   The above annual salary range is a general guideline. Multiple factors are taken into consideration to arrive at the final hourly rate/ annual salary to be offered to the selected candidate. Factors include, but are not limited to, the scope and responsibilities of the role, the selected candidate\u2019s work experience, education and training, the work location as well as market and business considerations.\n  \n \n  At this time, GEICO will not sponsor a new applicant for employment authorization for this position.\n  \n \n  Benefits:\n  \n \n   As an Associate, you\u2019ll enjoy our \n   \n   Total Rewards Program\n   \n \n to help secure your financial future and preserve your health and well-being, including: \n \n \n \n  Premier Medical, Dental and Vision Insurance with no waiting period** \n  Paid Vacation, Sick and Parental Leave \n  401(k) Plan \n  Tuition Reimbursement \n  Paid Training and Licensures \n \n \n \n Benefits may be different by location. Benefit eligibility requirements vary and may include length of service. \n \n \n   **Coverage begins on the date of hire. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.\n  \n \n \n   The equal employment opportunity policy of the GEICO Companies provides for a fair and equal employment opportunity for all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO hires and promotes individuals solely on the basis of their qualifications for the job to be filled.\n  \n \n \n   GEICO reasonably accommodates qualified individuals with disabilities to enable them to receive equal employment opportunity and/or perform the essential functions of the job, unless the accommodation would impose an undue hardship to the Company. This applies to all applicants and associates. GEICO also provides a work environment in which each associate is able to be productive and work to the best of their ability. We do not condone or tolerate an atmosphere of intimidation or harassment. We expect and require the cooperation of all associates in maintaining an atmosphere free from discrimination and harassment with mutual respect by and for all associates and applicants.",
        "cleaned_desc": " Provide advanced system administration, operational support, and problem resolution for a large complex cloud computing environment in and develop scripts to automate the deployment of resource stacks and associated configurations \n Extend standard systems management processes into the cloud including change, incident, and problem management \n Develop and maintain a library of deployable, tested, and documented automation design scripts, processes, and procedures \n Enable DevOps development activities and complex development tasks that will involve working with a wide variety of tools and container management systems \n Coordinate and bring application experts and other infrastructure teams together for finding optimal solutions to issues related to capacity, security, performance \n Implement and maintain CI/CD solutions and create code deployment models to support self-service automation \n \n \n \n   Qualifications\n   \n \n A technical background and knowledge of big data foundational concepts such as relational database, data warehouse, and data lakes is required to help build and maintain robust, scalable data and machine learning platforms \n Be well versed on general infrastructure technology and understand public and private cloud concepts such as Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS) \n Experience configuring and managing technologies used in big data and machine learning such as Snowflake, Spark, virtual networking in cloud environments \n Experience with container orchestration tools such as Docker and Kubernetes \n Experience with infrastructure-as-code technologies such as Terraform \n Extensive experience and strong understanding of cloud and infrastructure components. Preferred technologies include Azure, event streaming, data transformation, data warehouse, Azure Data Factory, and Azure data lake and services \n Strong working knowledge of networking concepts such as DNS, DHCP, Firewalls, Sub netting with a preference in Azure \n Automation experience and strong coding & scripting skills (shell, NodeJS, Python etc.) \n Experience in backend programming languages like PL/SQL, T-SQL, NZ SQL etc. \n Awareness of DB Optimization techniques pertinent to cloud data warehouses. Snowflake preferred \n Understanding of data ingress & egress patterns between cloud components. Big data Snowflake and different cloud service providers preferred   Proficiency in Spark and Snowflake platform Architecture, function/feature is a plus \n Experience architecting and designing current systems \n Advanced understanding of DevOps concepts including Azure DevOps framework and tools \n Advanced understanding of monitoring concepts and tooling \n Experience with continuous delivery and infrastructure as code \n Strong problem-solving ability \n Ability to excel in a fast-paced environment \n Knowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication) \n Experience and good understanding of big data eco systems like Hadoop, Spark, and Snowflake \n \n \n \n \n   Experience\n  \n \n 4+ years of professional software development and/or infrastructure experience \n 3+ years of experience with AWS, GCP, Azure, or another cloud service \n 3+ years of experience with architecture and design \n 2+ years of experience in open-source frameworks \n \n \n   Education",
        "techs": [
            "advanced system administration",
            "operational support",
            "problem resolution",
            "scripts",
            "automation",
            "resource stacks",
            "standard systems management processes",
            "change management",
            "incident management",
            "problem management",
            "library of deployable scripts",
            "processes",
            "procedures",
            "devops development",
            "container management systems",
            "ci/cd solutions",
            "code deployment models",
            "technical background",
            "big data concepts",
            "relational database",
            "data warehouse",
            "data lakes",
            "infrastructure technology",
            "public cloud",
            "private cloud",
            "software as a service (saas)",
            "platform as a service (paas)",
            "infrastructure as a service (iaas)",
            "big data technologies",
            "snowflake",
            "spark",
            "virtual networking",
            "cloud environments",
            "container orchestration tools",
            "docker",
            "kubernetes",
            "infrastructure-as-code technologies",
            "terraform",
            "cloud components",
            "azure",
            "event streaming",
            "data transformation",
            "data warehouse",
            "azure data factory",
            "azure data lake",
            "networking concepts",
            "dns",
            "dhcp",
            "firewalls",
            "sub netting",
            "automation",
            "coding",
            "scripting",
            "backend programming languages",
            "pl/sql",
            "t-sql",
            "nz sql",
            "db optimization techniques",
            "data ingress",
            "egress patterns",
            "spark platform",
            "snowflake platform architecture",
            "devops concepts",
            "azure devops framework",
            "monitoring concepts",
            "continuous delivery",
            "infrastructure as code",
            "problem-solving ability",
            "developer tooling",
            "software development life cycle",
            "hadoop"
        ],
        "cleaned_techs": [
            "advanced system administration",
            "operational support",
            "problem resolution",
            "scripts",
            "automation",
            "resource stacks",
            "standard systems management processes",
            "change management",
            "incident management",
            "problem management",
            "library of deployable scripts",
            "processes",
            "procedures",
            "devops development",
            "container management systems",
            "ci/cd solutions",
            "code deployment models",
            "technical background",
            "big data concepts",
            "relational database",
            "data warehouse",
            "data lakes",
            "infrastructure technology",
            "public cloud",
            "private cloud",
            "software as a service (saas)",
            "platform as a service (paas)",
            "infrastructure as a service (iaas)",
            "big data technologies",
            "snowflake",
            "spark",
            "virtual networking",
            "cloud environments",
            "container orchestration tools",
            "docker",
            "kubernetes",
            "infrastructure-as-code technologies",
            "terraform",
            "cloud components",
            "azure",
            "event streaming",
            "data transformation",
            "networking concepts",
            "dns",
            "dhcp",
            "firewalls",
            "sub netting",
            "coding",
            "scripting",
            "backend programming languages",
            "pl/sql",
            "t-sql",
            "nz sql",
            "db optimization techniques",
            "data ingress",
            "egress patterns",
            "spark platform",
            "snowflake platform architecture",
            "devops concepts",
            "monitoring concepts",
            "continuous delivery",
            "infrastructure as code",
            "problem-solving ability",
            "developer tooling",
            "software development life cycle",
            "hadoop"
        ]
    },
    "1df6ff88aea75b5c": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Engineer, Power Plant Control (PPC) (Remote)",
        "company": "Power Factors",
        "desc": "ABOUT POWER FACTORS \n \n \n  Power Factors develops software that accelerates the global energy transition by empowering all renewable energy stakeholders to collaborate, automate critical workflows, and make the best decisions. Power Factors fights climate change with code. \n \n \n  Power Factors has incorporated its four flagship solutions Drive, Greenbyte, Unity and BluePoint to build an integrated suite of open and smart apps. These apps are purpose built for asset management, field service optimization, and performance optimization. Leveraging the domain expertise and machine learning-based advanced analytics within these apps, customers can maximize the value of their renewable assets to stay competitive. \n \n \n  Power Factors\u2019 renewable energy software platform is one of the most extensive and widely deployed solutions in the market with over 200 GW of wind, solar, hydro, and energy storage assets managed worldwide. \n \n \n  Learn more at powerfactors.com. \n \n \n  ABOUT THE ROLE \n \n \n  We are now looking for a Power Plant Control Engineer to complete our dynamic global team. As a part of the Controls & Grid Integration team, your mission is to deliver grid integration and power plant control related engineering tasks for solar, storage and hybrid sites during the projects execution phase. We are responsible for implementing new renewable assets, such as solar, storage, wind or hybrid sites, onto our Platform. \n \n \n  We are made up of hard-working, fun-loving people who are passionate about making the world better. We are a very international team spread across multiple locations, with a team spirit that is truly hard to beat! We work with agile methodologies such as Kanban and Scrum. \n \n \n  As a Power Plant Control Engineer, you will face a variety of tasks related to the grid integration and power plant control implementation of renewable energy assets. Typical implementation-activities involve interacting with our customers and possibly with the grid operators to gather all information needed, perform the requirements analysis, provide the design study and finally complete the grid integration/compliance tests and submit the respective report. \n \n \n  It goes without saying that in this role you\u2019ll get to know the renewable energy industry and are able to develop your skills further through internal and external learning events. \n \n \n  WHAT YOU WILL BE DOING \n \n \n \n Analyze requirements for Grid integration, including the applicable Grid Code, of solar, storage, wind and hybrid power plants \n Escalate new requirements to internal product teams for implementation. \n Design the flow for new control applications. \n Contribute to the mathematical modelling of the Power Plant Control Algorithms \n Prepare the project specific control narrative. \n Commission the projects power plant controller. \n Conduct Grid Code Compliance tests (usually remote), including data analysis and reporting. \n Develop application studies for new grid integration and power plant control installations. \n Be the main technical interface to Grid Operators and client specialists \n Provide remote troubleshooting help to on-site engineers \n \n \n \n  WHAT YOU WILL NEED TO BE SUCCESSFUL \n \n \n  We are looking for a team member that is proactive and communicative and enjoys being a part of a tight-knit team. You feel comfortable assisting customers in understanding technical integration and networking details and thrive in an environment where you need to find creative solutions to challenging problems in a fast-changing context. This means that you are efficient at managing multiple projects and portfolios of varying complexities and a driven by continuous learning and growth. \n \n \n  Specifically, we are looking for someone with the following toolbox: \n \n \n  SKILLS & REQUIREMENTS \n \n \n \n MS/BS in Electrical or Automations Engineering with technical background in power system engineering \n 3 plus years experience as SCADA Engineer \n Knowledge of principle of operation of RES (Solar, Wind, Storage or Hybrid sites) \n Good knowledge of digital and analog signals \n Experience with Industrial protocols (MODBUS, DNP3, OPC, etc) \n Experience with PLCs \n Basic knowledge of Local Networks \n Experience with Linux OS, use of terminal and shell \n Experience in modelling of power control systems in Digsilent, PSSE or PSCAD. \n Excellent written and verbal communication skills \n \n \n \n  Overall, we need fierce but humble people to help us achieve our ambitious plan. Join us to fight climate change with code! \n \n \n  LIFE @ POWER FACTORS \n \n \n  We are an agile software development company \u2013 big enough to make an impact, but small enough to move quickly and execute in a growing industry, taking advantage of rapidly evolving technologies. We are a collective of bold and ingenious talents driven by results. Our team is made up of hard-working, fun-loving people who are passionate about making the world a better place. We seek fierce and humble people to help us achieve our ambitious plan. \n \n \n  WHY JOIN US \n \n \n \n A humble cause with a clear purpose \u2013 you will help us fight climate change with every day at work. We aim to be environmentally conscious in all aspects of our operations. \n Work with passionate experts and top-talents in your field \u2013 we are proud of our highly skilled crowd and the savviness each of us brings to the team. \n Friendly and uplifting atmosphere \u2013 we believe kindness and respectfulness is core for our culture. A friendly smile or a helping hand is always near you. \n Flexible hours and workplace \u2013 it is the result that counts, not when or where. Our hybrid/remote work setup allows everyone to set themselves up for success and create a more sustainable work-life balance. \n All the benefits you expect (and more) \u2013 besides the basic benefits (adopted to local needs and norms), you will enjoy perks such as 8h of paid volunteering per year and participation in our Corporate Bonus Program (to name a few). \n \n \n \n  WE ARE AN EQUAL OPPORTUNITY EMPLOYER \n \n \n  Power Factors is an Equal Opportunity Employer committed to engaging a diverse workforce and sustaining an inclusive culture. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",
        "cleaned_desc": " \n \n \n MS/BS in Electrical or Automations Engineering with technical background in power system engineering \n 3 plus years experience as SCADA Engineer \n Knowledge of principle of operation of RES (Solar, Wind, Storage or Hybrid sites) \n Good knowledge of digital and analog signals \n Experience with Industrial protocols (MODBUS, DNP3, OPC, etc) \n Experience with PLCs \n Basic knowledge of Local Networks \n Experience with Linux OS, use of terminal and shell \n Experience in modelling of power control systems in Digsilent, PSSE or PSCAD. \n Excellent written and verbal communication skills \n \n \n \n  Overall, we need fierce but humble people to help us achieve our ambitious plan. Join us to fight climate change with code! \n \n ",
        "techs": [
            "ms/bs in electrical or automations engineering",
            "scada engineer",
            "res (solar",
            "wind",
            "storage or hybrid sites)",
            "digital signals",
            "analog signals",
            "industrial protocols (modbus",
            "dnp3",
            "opc)",
            "plcs",
            "local networks",
            "linux os",
            "terminal and shell",
            "modelling of power control systems in digsilent",
            "psse or pscad"
        ],
        "cleaned_techs": [
            "ms/bs in electrical or automations engineering",
            "scada engineer",
            "res (solar",
            "wind",
            "storage or hybrid sites)",
            "digital signals",
            "analog signals",
            "industrial protocols (modbus",
            "dnp3",
            "opc)",
            "plcs",
            "local networks",
            "linux os",
            "terminal and shell",
            "modelling of power control systems in digsilent",
            "psse or pscad"
        ]
    },
    "e8ce0ea32885742d": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 119447.875,
        "salary_max": 151247.62,
        "title": "Cloud IT System Architect III-Medicaid",
        "company": "CORMAC",
        "desc": "Cormac is seeking an experienced  Cloud IT Systems Architect  who has expertise in the strategy, design, development, and implementation of large-scale projects in the cloud. The ideal candidate will have a firm grasp of emerging technologies, platforms, and applications and an ability to customize them to help our business become more secure and efficient. Extensive knowledge of cloud maintenance, experience in managing staff, and advanced industry knowledge are essential to keep us on the cutting edge. The cloud engineer will have an immediate impact on the day-to-day efficiency of IT operations and an ongoing impact on growth. \n Responsibilities \n \n Work in tandem with our engineering team to identify and implement the most optimal cloud-based solutions for the company. \n Define and document best practices and strategies regarding application deployment and infrastructure maintenance. \n Provide guidance, thought leadership, and mentorship to developer teams to build their cloud competencies. \n Ensure application performance, uptime, and scale, maintaining high standards for code quality and thoughtful design. \n Manage cloud environments in accordance with company security guidelines. \n At the direction of lead architects, develop and implement technical efforts to design, build, and deploy AWS applications, including large-scale data processing, computationally intensive statistical modeling, and advanced analytics. \n Participate in all aspects of the software development lifecycle for AWS solutions, including planning, requirements, development, testing, and quality assurance. \n Troubleshoot incidents, identify root causes, fix and document problems, and implement preventive measures. \n Educate teams on the implementation of new cloud-based initiatives, providing associated training when necessary. \n Demonstrate exceptional problem-solving skills, with an ability to see and solve issues before they affect business productivity. \n \n Minimum Qualification \n \n Bachelor\u2019s Degree in an IT or business-related field such as Information Technology or Computer Science. \n At least 5 years of experience in architecting, designing, developing, and implementing cloud solutions on AWS platforms. \n Understanding of and experience with the five pillars of a well-architected framework. \n Experience in several of the following areas: database architecture, ETL, business intelligence, big data, machine learning, advanced analytics. \n Proven ability to collaborate with multidisciplinary teams of business analysts, developers, data scientists, and subject-matter experts. \n Hands on experience within state Medicaid. \n Must possess a thorough knowledge of Medicaid and regulations as set by the federal and state government. \n Knowledge of web services, API, REST, and RPC. \n AWS certification, preferred. \n \n Position Requires Employment Eligibility Verification  /E-Verify Participation/EEO \n As an Equal Employment Opportunity employer, CORMAC provides equal employment opportunity to all employees and applicants without regard to an individual's protected status, including race/ethnicity, color, national origin, ancestry, religion, creed, age, gender, gender identity/expression, sexual orientation, marital status, parental status, including pregnancy, childbirth, or related conditions, disability, military service, veteran status, genetic information, or any other protected status.",
        "cleaned_desc": " Provide guidance, thought leadership, and mentorship to developer teams to build their cloud competencies. \n Ensure application performance, uptime, and scale, maintaining high standards for code quality and thoughtful design. \n Manage cloud environments in accordance with company security guidelines. \n At the direction of lead architects, develop and implement technical efforts to design, build, and deploy AWS applications, including large-scale data processing, computationally intensive statistical modeling, and advanced analytics. \n Participate in all aspects of the software development lifecycle for AWS solutions, including planning, requirements, development, testing, and quality assurance.   \n Bachelor\u2019s Degree in an IT or business-related field such as Information Technology or Computer Science. \n At least 5 years of experience in architecting, designing, developing, and implementing cloud solutions on AWS platforms. \n Understanding of and experience with the five pillars of a well-architected framework. \n Experience in several of the following areas: database architecture, ETL, business intelligence, big data, machine learning, advanced analytics. ",
        "techs": [
            "aws platforms",
            "large-scale data processing",
            "computationally intensive statistical modeling",
            "advanced analytics",
            "software development lifecycle",
            "planning",
            "requirements",
            "development",
            "testing",
            "quality assurance",
            "bachelor's degree",
            "it",
            "business-related field",
            "information technology",
            "computer science",
            "architecting",
            "designing",
            "implementing cloud solutions",
            "well-architected framework",
            "database architecture",
            "etl",
            "business intelligence",
            "big data",
            "machine learning"
        ],
        "cleaned_techs": [
            "aws",
            "large-scale data processing",
            "computationally intensive statistical modeling",
            "advanced analytics",
            "planning",
            "requirements",
            "development",
            "testing",
            "quality assurance",
            "it",
            "business-related field",
            "information technology",
            "computer science",
            "architecting",
            "designing",
            "implementing cloud solutions",
            "well-architected framework",
            "database architecture",
            "etl",
            "business intelligence",
            "big data"
        ]
    },
    "f347066330bcdcc9": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 113000.0,
        "salary_max": 162000.0,
        "title": "Senior Product Manager, Equipment",
        "company": "ServiceTitan",
        "desc": "Ready to be a Titan?\n  \n \n   At ServiceTitan we solve real world problems in the specialty trade services and construction industry and we are seeking an experienced and visionary product leader to lead growth efforts expanding our addressable market. We are passionate about bringing innovative and delightful solutions to traditional problems and workflows. Our ambitious team of product managers, designers, data analysts, technical project managers, developers, quality assurance engineers, technical writers, and product marketers works closely with our internal stakeholders, strategic business partners, hundreds of thousands of users, and broader community to help make the lives of hard working women and men in the trades easier through technology. We embrace agile development and design thinking to rapidly ship solutions with real impact and high value. We measure our success based on our customers\u2019 success and our ability to meaningfully improve their lives.\n  \n \n \n   As Sr. Product Manager of Equipment, you will own the vision and execution for expansion of ServiceTitan\u2019s capabilities as they relate to managing equipment installed and serviced by our customers (e.g., air conditioners, heaters, boilers, chillers, pumps, air handling units, water heaters, water softeners, electrical panels, roll up doors, automatic gates, fire suppression systems, security systems). You will lead and coordinate a highly talented and fast-paced team that is responsible for successfully launching new products to market that improve product-market fit, capture market share, and increase addressable market size. You will own all aspects of the product development lifecycle. You will be accountable for setting and achieving KPIs that measure customer impact and business results. This is a high visibility, high stakes, position that aligns with a top company goal for ServiceTitan.\n  \n \n \n   Our approach is customer-focused and data-driven. You will dive in to deeply understand our customers and their needs, collect and analyze data, and guide the team to move at high velocity and ship impactful solutions. This position will also be key in forming strong partnerships with original equipment manufacturers (OEM) and suppliers as well as creating a comprehensive ecosystem of integrated solutions leveraging ServiceTitan\u2019s platform capabilities and application programming interface (API). There are many opportunities for the application of machine learning (ML), artificial intelligence (AI), and internet of things (IoT) powered by climate data, utility data, and building automation system (BAS) data. You will leverage new and emerging technologies to deliver innovative solutions for our customers.\n  \n \n \n   What you'll do:\n  \n \n \n \n     Create, articulate, evangelize, champion, and execute the vision for Equipment\n    \n \n \n     Own the product roadmap for your domain and make defensible and data-driven strategic prioritization decisions to optimize customer impact and business results\n    \n \n \n     Drive the product development lifecycle from market research through discovery, design, validation, requirements, grooming, planning, development, delivery, and go-to-market\n    \n \n \n     Enable pre-sale and post-sale stakeholders to understand market needs, use cases, and recommended best practices, including partnering with Documentation, Enablement, and Marketing on content creation\n    \n \n \n     Influence multiple product areas in collaboration with R&D leaders across CRM, Pricebook, Estimates, Purchasing, Inventory, Jobs & Project Management, Forms & Media, Accounting, and Reporting\n    \n \n \n     Achieve goals by establishing and attaining KPIs for revenue, retention, usability, adoption, engagement, and satisfaction\n    \n \n \n     Identify and take action on opportunities for continuous improvement\n    \n \n \n     Communicate and mitigate risks in order to successfully achieve objectives\n    \n \n \n     Own customer and prospect escalations to ensure proper resolution while managing impact to roadmap commitments\n    \n \n \n     Nurture strategic partnership relationships, resulting in creation and adoption of new integrations\n    \n \n \n \n   What you'll need:\n  \n \n \n \n     4-7 years of relevant work experience in product management, SaaS products strongly preferred\n    \n \n \n     Ability to build consensus and work collaboratively cross-functionally within and beyond research and development teams\n    \n \n \n     Data-driven approach to measuring success and quantifying customer outcomes and business impacts\n    \n \n \n     Self-starter that thrives in an entrepreneurial, fast-paced environment with the demonstrated initiative to lead, motivate, and collaborate effectively with others\n    \n \n \n     Demonstrated track record of delivering industry-transforming solutions across web and mobile platforms\n    \n \n \n     Proven ability to deliver against ambitious schedule milestones while paying strict attention to detail and quality\n    \n \n \n     Capacity to operate autonomously and bring clarity in uncertain environments\n    \n \n \n     Strong EQ to empathize with stakeholders and balance several perspectives, ultimately creating support and alignment around your decisions\n    \n \n \n     Sound judgment and credibility to make difficult trade-off decisions that deliver optimal outcomes with finite resources\n    \n \n \n     Excellent communication skills that allow you to translate complex and detailed information into simple and readily understandable executive summaries\n    \n \n \n     Enthusiasm for your vision and mission that inspires your team members and customers, creating evangelists and champions for your cause\n    \n \n \n     Bias toward action allowing you to move quickly while establishing the foundation for long term success\n    \n \n \n     Resourcefulness to leverage available tools, customers, data, and subject matter experts to extract key insights\n    \n \n \n     Previous experience with machine learning (ML), artificial intelligence (AI), and internet of things (IoT) a plus\n    \n \n \n     A General Manager mindset; MBA a plus\n    \n \n \n \n   Be Human With Us:\n  \n \n   Being human isn\u2019t about checking every box on a list. It\u2019s about the experiences we have, people we meet, and the perspectives we share. So, if you have the skills but are hesitant to apply because of your background, apply anyway. We need amazing people like you to help us challenge the conventional and think differently about the problems that we\u2019re solving. We\u2019re in this together. Come be human, with us.\n  \n \n \n   What We Offer:\n  \n \n   When you join our team, you\u2019re not just accepting a job. You\u2019re making a career move. Here\u2019s how we\u2019ll support you in doing some of the most impactful work of your career:\n  \n \n \n \n     Flextime, recognition, and support for autonomous work: Flexible time off with ample learning and development opportunities to continue growing your career. We offer a comprehensive onboarding program, leadership training for Titans at all levels, and other programs and events. Great work is rewarded through Bonusly, peer-nominated awards, and more.\n    \n \n \n     Holistic health and wellness benefits: Company-paid medical, dental, and vision (with 100% employer paid options and 90% coverage for dependents), FSA and HSA, 401k match, and telehealth options including memberships to Headspace, Galileo, One Medical, Ginger and more.\n    \n \n \n     Support for Titans at all stages of life: Parental leave and support, up to $20k in adoption reimbursement, on demand maternity support through Maven Maternity, free breast milk shipping through Maven Milk, pet insurance, legal advisory services, financial planning tools, and more.\n    \n \n \n \n   At ServiceTitan, we celebrate individuality and uniqueness. We believe that the convergence of fresh perspectives and experiences from all walks of life is what makes our product and culture so great. We strongly encourage people from underrepresented groups to apply. We do not discriminate against employees based on race, color, religion, sex, national origin, gender identity or expression, age, disability, pregnancy (including childbirth, breastfeeding, or related medical condition), genetic information, protected military or veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws.\n  \n  ServiceTitan is committed to fair and equitable compensation for all of our employees. We thoughtfully consider a wide range of factors when determining individual compensation. The expected salary range for this role is between $113,000 - $162,000. Actual compensation for an individual may vary depending on skills, performance over time, qualifications, experience, and location. In addition to the base salary, the total compensation package also includes an annual bonus, equity and a holistic suite of benefits.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "2b7315b7c71326c1": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": 100050.86,
        "salary_max": 126686.69,
        "title": "Senior Detection Engineer",
        "company": "Computer World Services",
        "desc": "The mission of the OFR is to support the Financial Stability Oversight Council (FSOC) in promoting financial stability by: collecting data on behalf of FSOC; providing such data to FSOC and member agencies; standardizing the types and formats of data reported and collected; performing applied research and essential long-term research; developing tools for risk measurement and monitoring; performing other related services; making the results of the activities of the OFR available to financial regulatory agencies; and assisting such member agencies in determining the types of formats of data authorized to be collected by such member agencies.  \n The Senior Detection Engineer provides services required to integrate existing security and network tools, platforms, and threat intel feeds in a modern hybrid (cloud/on-premises) environment to implement zero-trust security policies. This includes the ability to detect and respond to vulnerabilities and security incidents, alert on incidents and vulnerabilities for action, and enable active threat hunting capabilities. Identify gaps in security operations capabilities and/or visibility and provide recommendations to improve existing tools or new technology. Develop and automate highly complex detection playbooks that fully integrate and utilize the security and network tools. This role is highly technical and requires a solid understanding of offensive network security principles and how to translate these to protect and defend enterprise environments. This engineer will support the deployment of new network security technologies that will enhance the overall network security capabilities of the organization. This includes, but is not limited to tuning detection systems to minimize false positives, enhancing detection policies such as using adversarial models / TTPs (Tools, Techniques & Procedures) and threat intelligence to build the latest/greatest detections. Implement User Behavior Monitoring that leverages machine learning and artificial intelligence techniques to detect anomalous user actions and help combat advanced threats. The engineer is expected to perform mild penetration testing to test defenses, and work closely with the different technology teams to harden all systems, building deception ecosystems (breadcrumbs to trap servers), as well as identifying required data sources, and architect/engineer pipelines to get the data needed to make any/all detections. The engineer should be proficient in collecting multiple sources of network/security data under a single visibility platform with the ability to correlate events, preferably using machine learning / artificial intelligence, to identify indicators of compromise. Develop relevant dashboards, stoplight charts, monitors, metrics, and diagrams to assist operators in assessing the current security state of the enterprise. \n Key Tasks and Responsibilities \n \n Configure, set policy and tune platforms to increase detection capabilities and scope, and eliminate noise and false positives: \n \n \n EDR/IDS/IPS \n \n \n NDR/Network \n \n \n Identity Provider (IdP) authentication policies \n \n \n Email defense platforms \n \n \n Integration of threat intelligence feeds with security policy enforcement points \n \n \n SIEM and XDR detections \n \n \n Security orchestration, automation, and response (SOAR) playbook development \n \n \n Apply knowledge of monitoring, analyzing, detecting and responding to cyber events to develop clever, efficient methods and technology to detect all types of threat and to weaponize our threat hunting capabilities \n \n \n Develop strategies for network security operations, which includes detecting new threats as they emerge, including those from the most sophisticated threat actors; enhancing our detection and investigation capabilities with threat correlations and intelligence; integrating situational awareness of system intrusions; enhancing ticket data, and automate mitigation of threats \n \n \n Develop and implement strategies to secure and monitor new technologies, platforms, or services \n \n \n Develop and deploy deception technology (e.g., honeypots, honey hashes) across both enterprise and cloud environments. This includes planting breadcrumbs on endpoints/services, and then laying trap servers/services to detect their use \n \n \n Work with Technology teams to develop architecture that utilizes integrations between network, host, and security tools and intelligence feeds that fuses defenses and detections together to increase the effectiveness of policy enforcement. This includes not only endpoints and email; but networks, Identity Providers, cloud (e.g., IAM), Access/Authentication/Authorization, Zero Trust, jumphosts/bastion, firewalls, etc. \n \n \n Identify data sources required, and then architect/engineer pipelines to get the data needed to make any/all detections, preferably on a cloud-based, single platform / single pane of glass \n \n \n Perform security testing to identify security strengths and weaknesses, to assess the effectiveness of existing controls, and to recommend remedial action \n \n \n Evaluate modern, state of the art network security technologies, work with proof-of-concepts and evaluate them for adoption.  \n \n \n Train and educate engineers about new detection/response tactics and technologies \n \n \n Document specifications, playbooks and detections - not as an afterthought, but through the whole process and polished to share externally \n \n \n Work with developers to build security automation workflows, enrichments, and mitigations \n \n \n Gather, analyze, and assess the current and future threat landscape, and assist in providing leadership with a realistic overview of risks and threats in the enterprise environment \n \n \n Evaluate policies and procedures and recommend updates to management as appropriate \n \n  Job Requirements: \n \n Education & Experience \n \n Wide, deep and practical knowledge of TTPs (Tools, Techniques & Procedures) used by attackers across all varieties of attack surfaces - Authentication, Authorization, Networks, AD, Zero Trust, Firewalls, Applications, etc.) \n \n \n Solid experience with offensive TTPs, penetration testing and working with/on purple teams to harden detection capabilities \n \n \n Note we are not looking for individuals who only have experience with OWASP/application testing and network perimeter assessments; but the whole gambit of technologies and vectors, such as OS Escalations, Active Directory, Appliances, SaaS, Networks, Zero Trust, ATO, etc.) \n \n \n Mastery of security tools such as endpoint protection/EDR, SIEM, IPS/IDS, HIDS/NIDS, Networking, firewalls, WAFs, edge/endpoint security, DNS security, cryptography, layered security, defense in depth practices, vulnerability scanning, malware analysis tools, networking tool for full packet analysis, data encryption, data loss prevention, DDoS prevention, etc. \n \n \n Experience building detections for enterprise environments, which must include systems outside of a SIEM \n \n \n Deep understanding of Active Directory architecture and features; as well as the attacks and defenses (e.g., NTLM/Kerberos, escalation paths, multiple kinds of Kerberoasting, ADCS vectors, etc.) \n \n \n Experience securing and monitoring cloud-based IdPs such as Okta/Azure AD \n \n \n Scripting capabilities (e.g., bash, powershell, python) \n \n \n SOAR and playbook automation experience \n \n \n Linux/Unix OS and Windows administration knowledge \n \n \n Collaborative mindset that thrives in fast paced environments \n \n \n Excellent verbal and written communication skills including the ability to author and present materials ranging from detailed technical specifications to high-level concepts for senior audiences \n \n \n Preferred College Degree in Computer Science or related \n \n \n Must have 10+ years of related experience \n \n Certifications \n \n Preference given for CEH, CISM, GIAC, GCIH, GSLC, GICSP, GSEC, CEH, GWAP, CompTIA Net+, CompTIA A+, CompTIA Security+, CASP CE, SEC+, CISSP, CISSLP, Splunk Core, OSCP, etc. \n \n Security Clearance \n \n Public Trust \n \n \n Must be US Citizen \n \n Other (Travel, Work Environment, DoD 8570 Requirements, Administrative Notes, etc.) \n \n This is a remote/work from home role \n \n \n \n \n \n \n \n  Get job alerts by email. \n   Sign up now!  Join Our Talent Network! \n  \n \n Job Snapshot \n \n Employee Type  Full-Time \n   \n \n Location  United States of America (Remote) \n   \n \n Job Type  Engineering, Government, Information Technology \n   \n \n Experience  Not Specified \n   \n \n Date Posted  08/21/2023 \n   \n \n Job ID  4018/2854/18341",
        "cleaned_desc": " \n Develop strategies for network security operations, which includes detecting new threats as they emerge, including those from the most sophisticated threat actors; enhancing our detection and investigation capabilities with threat correlations and intelligence; integrating situational awareness of system intrusions; enhancing ticket data, and automate mitigation of threats \n \n \n Develop and implement strategies to secure and monitor new technologies, platforms, or services \n \n \n Develop and deploy deception technology (e.g., honeypots, honey hashes) across both enterprise and cloud environments. This includes planting breadcrumbs on endpoints/services, and then laying trap servers/services to detect their use \n \n \n Work with Technology teams to develop architecture that utilizes integrations between network, host, and security tools and intelligence feeds that fuses defenses and detections together to increase the effectiveness of policy enforcement. This includes not only endpoints and email; but networks, Identity Providers, cloud (e.g., IAM), Access/Authentication/Authorization, Zero Trust, jumphosts/bastion, firewalls, etc. \n \n \n Identify data sources required, and then architect/engineer pipelines to get the data needed to make any/all detections, preferably on a cloud-based, single platform / single pane of glass \n \n \n Perform security testing to identify security strengths and weaknesses, to assess the effectiveness of existing controls, and to recommend remedial action \n \n \n Evaluate modern, state of the art network security technologies, work with proof-of-concepts and evaluate them for adoption.  \n \n \n Train and educate engineers about new detection/response tactics and technologies \n \n \n Document specifications, playbooks and detections - not as an afterthought, but through the whole process and polished to share externally \n \n \n Work with developers to build security automation workflows, enrichments, and mitigations \n   \n Gather, analyze, and assess the current and future threat landscape, and assist in providing leadership with a realistic overview of risks and threats in the enterprise environment \n \n \n Evaluate policies and procedures and recommend updates to management as appropriate \n \n  Job Requirements: \n \n Education & Experience \n \n Wide, deep and practical knowledge of TTPs (Tools, Techniques & Procedures) used by attackers across all varieties of attack surfaces - Authentication, Authorization, Networks, AD, Zero Trust, Firewalls, Applications, etc.) \n \n \n Solid experience with offensive TTPs, penetration testing and working with/on purple teams to harden detection capabilities \n \n \n Note we are not looking for individuals who only have experience with OWASP/application testing and network perimeter assessments; but the whole gambit of technologies and vectors, such as OS Escalations, Active Directory, Appliances, SaaS, Networks, Zero Trust, ATO, etc.) \n \n \n Mastery of security tools such as endpoint protection/EDR, SIEM, IPS/IDS, HIDS/NIDS, Networking, firewalls, WAFs, edge/endpoint security, DNS security, cryptography, layered security, defense in depth practices, vulnerability scanning, malware analysis tools, networking tool for full packet analysis, data encryption, data loss prevention, DDoS prevention, etc. \n \n \n Experience building detections for enterprise environments, which must include systems outside of a SIEM \n \n \n Deep understanding of Active Directory architecture and features; as well as the attacks and defenses (e.g., NTLM/Kerberos, escalation paths, multiple kinds of Kerberoasting, ADCS vectors, etc.) \n \n \n Experience securing and monitoring cloud-based IdPs such as Okta/Azure AD \n   \n Scripting capabilities (e.g., bash, powershell, python) \n \n \n SOAR and playbook automation experience \n \n \n Linux/Unix OS and Windows administration knowledge \n \n \n Collaborative mindset that thrives in fast paced environments \n \n \n Excellent verbal and written communication skills including the ability to author and present materials ranging from detailed technical specifications to high-level concepts for senior audiences \n \n \n Preferred College Degree in Computer Science or related \n \n \n Must have 10+ years of related experience \n \n Certifications \n \n Preference given for CEH, CISM, GIAC, GCIH, GSLC, GICSP, GSEC, CEH, GWAP, CompTIA Net+, CompTIA A+, CompTIA Security+, CASP CE, SEC+, CISSP, CISSLP, Splunk Core, OSCP, etc. \n \n Security Clearance \n \n Public Trust \n \n ",
        "techs": [
            "network security operations",
            "threat correlations",
            "threat intelligence",
            "situational awareness",
            "deception technology",
            "honeypots",
            "honey hashes",
            "architecture",
            "integrations",
            "intelligence feeds",
            "policy enforcement",
            "data pipelines",
            "security testing",
            "proof-of-concepts",
            "security automation workflows",
            "threat landscape analysis",
            "policy evaluation",
            "ttps",
            "offensive ttps",
            "penetration testing",
            "purple teams",
            "endpoint protection/edr",
            "siem",
            "ips/ids",
            "hids/nids",
            "firewalls",
            "wafs",
            "dns security",
            "cryptography",
            "vulnerability scanning",
            "malware analysis",
            "data encryption",
            "data loss prevention",
            "ddos prevention",
            "active directory architecture",
            "okta/azure ad",
            "scripting",
            "soar",
            "playbook automation",
            "linux/unix administration",
            "windows administration",
            "verbal and written communication",
            "computer science",
            "ceh",
            "cism",
            "giac",
            "gcih",
            "gslc",
            "gicsp",
            "gsec",
            "gwap",
            "comptia net+",
            "comptia a+",
            "comptia security+",
            "casp ce",
            "sec+",
            "cissp",
            "cisslp",
            "splunk core",
            "oscp"
        ],
        "cleaned_techs": [
            "threat correlations",
            "threat intelligence",
            "situational awareness",
            "deception technology",
            "honeypots",
            "honey hashes",
            "architecture",
            "integrations",
            "intelligence feeds",
            "policy enforcement",
            "data pipelines",
            "proof-of-concepts",
            "threat landscape analysis",
            "policy evaluation",
            "ttps",
            "offensive ttps",
            "penetration testing",
            "purple teams",
            "endpoint protection/edr",
            "siem",
            "ips/ids",
            "hids/nids",
            "firewalls",
            "wafs",
            "cryptography",
            "vulnerability scanning",
            "malware analysis",
            "data encryption",
            "data loss prevention",
            "ddos prevention",
            "active directory architecture",
            "okta/azure ad",
            "scripting",
            "soar",
            "playbook automation",
            "linux/unix administration",
            "windows administration",
            "verbal and written communication",
            "computer science",
            "ceh",
            "cism",
            "giac",
            "gcih",
            "gslc",
            "gicsp",
            "gsec",
            "gwap",
            "comptia net+",
            "comptia a+",
            "casp ce",
            "sec+",
            "cissp",
            "cisslp",
            "splunk core",
            "oscp"
        ]
    },
    "6d30c31ce36c3a6c": {
        "terms": [
            "machine learning engineer"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Product Manager",
        "company": "Phaidra",
        "desc": "About Phaidra \n  Phaidra is building the future of industrial automation. \n  The world today is filled with static, monolithic infrastructure. Factories, power plants, buildings, etc. operate the same they've operated for decades \u2014 because the controls programming is hard-coded. Thousands of lines of rules and heuristics that define how the machines interact with each other. The result of all this hard-coding is that facilities are frozen in time, unable to adapt to their environment while their performance slowly degrades. \n  Phaidra creates AI-powered control systems for the industrial sector, enabling industrial facilities to automatically learn and improve over time. Specifically: \n \n We use reinforcement learning algorithms to provide this intelligence, converting raw sensor data into high-value actions and decisions. \n We focus on industrial applications, which tend to be well-sensorized with measurable KPIs \u2014 perfect for reinforcement learning. \n We enable domain experts (our users) to configure the AI control systems (i.e. agents) without writing code. They define what they want their AI agents to do, and we do it for them. \n \n Our team has a track record of applying AI to some of the toughest problems. From achieving superhuman performance with DeepMind's AlphaGo, to reducing the energy required to cool Google's Data Centers by 40%, we deeply understand AI and how to apply it in production for massive impact. \n  Phaidra is based in the USA but 100% remote; we do not have a physical office. We hire employees internationally with the help of our partner, OysterHR. Our team is currently located throughout the USA, Canada, UK, Norway, Italy, Portugal, and India. \n  **Please only apply to one opening. If you are a better fit for another opening, our team will move your application. Candidates who apply to multiple openings will not be considered.** \n \n  Who You Are \n  You're a self starter and you're comfortable with the unknown and understand that startup life means that you're going to be wearing multiple hats. You're accountable, curious, and obsessed with improvement, both in yourself and in others. You like a challenge, aren't afraid to fail and learn from your missteps and are excited to help build a world-class company from the ground up. \n  As a Product Manager at Phaidra, you are helping envision, develop, and deliver state-of-the-art enterprise machine learning tools and services to the market. \n  You will own the product roadmap and technical development cycles. You will develop a thorough understanding of the full suite of interfaces, identify gaps, and work collaboratively with engineering, solution architects, design, and marketing teams to bring products to life. \n  **We are seeking a team member located within one of the following areas: USA/Canada/UK/EU \n  Responsibilities \n \n Define functional requirements, develop detailed product specifications and associated project work plans for features and key enhancement requests. \n Own the roadmap, functional requirements, and develop timeline for multiple staged releases of your product. \n Provide technical guidance to customer teams using Phaidra products \n Be deeply empathetic to customer needs - working to identify, define, and represent their goals and problems - and rally partners to tackle them. \n Think analytically and make decisions and forecast impact through data. Test and learn via analytics, user research, prototyping, surveys, user testing, customer interviews, and rapid experimentation. \n Gathering direct feedback from customers and expertly communicating that to the Product and Engineering Teams. \n \n Key Qualifications \n \n 3+ years of technical product management experience \n Industrial/HVAC controls experience \n Have shipped refined complex, technical products \n Experience pulling insights from quantitative and qualitative data to articulate customer challenges \n Strong technical understanding, ability to establish credibility with engineers \n Bias-to-action and hands-on experience delivering business results. You're not afraid to get your hands dirty. \n Ability to drive teams of diverse backgrounds to ship features on aggressive timeline \n Excellent communicator, written and verbal, and enjoys a fast paced work environment. \n 3+ years experience with Agile and scrum workflows and processes. \n \n Onboarding \n  In your first 30 days... \n \n Familiarize yourself with the Phaidra Handbook. \n Review Product roadmaps, requirements, designs, and implementations. \n Participate in recurring meetings with relevant teams. \n Introduce yourself to the Product customers. \n \n By your first 60 days... \n \n Build an understanding of our work processes and tools. \n Interview customers and identify gaps in our Product. \n Start writing and communicating requirements. \n Start refining the Product roadmap. \n \n By your first 90 days... \n \n Create formal launch plans for Product releases. \n Organize and refine Product documentation and team APIs. \n Prioritize Product features and bugs. \n Assist with constructing high-level test plans. \n Create presentations to share progress with stakeholders. \n \n Bonus \n \n Hands-on experience with modern machine learning libraries, frameworks and technologies \n AI/ML product management experience \n Working in a start-up environment \n Experience working with a global, remote team \n Familiarity with B2B sales \n \n Base Salary \n \n US Residents: $130,000-$160,000 \n UK Residents: \u00a394,000-\u00a3116,000 \n \n This position will also include equity. \n  These are best faith estimates of the base salary range for this position. Multiple factors such as experience, education, level, and location are taken into account when determining compensation. \n \n  Benefits & Perks \n \n Fast-paced and team-oriented environment where you will be instrumental in the direction of the company. \n Phaidra is a 100% remote company with a digital nomad policy. \n Competitive compensation & equity with an early exercise option. \n Outsized responsibilities & professional development. \n Training is foundational; functional, customer immersion, and development training. \n Medical, dental, and vision insurance (exact benefits vary by region). \n Unlimited paid time off, with a minimum of 20 days off per year requirement. \n Paid parental leave (exact benefits vary by region). \n Home office setup stipend and company MacBook. \n Monthly internet reimbursement. \n \n On being Remote \n  We are thoughtful about remote collaboration. We look to the pioneers - like Gitlab - for inspiration and best practices to create a stellar remote work environment. We have a documentation-first culture and actively practice asynchronous communication in everything we do. Our team stays connected through tools like Slack and video chat. Most teams meet daily, and we have dedicated all-hands meetings bi-weekly to build strong relationships. We hold virtual team building events once per month - and even hold virtual socials to watch rocket launches! We have a yearly in-person, all-company summit in locations like Seattle, Athens, Goa, and Barcelona. \n  Equal Opportunity Employment \n  Phaidra is an Equal Opportunity Employer; employment with Phaidra is governed on the basis of merit, competence, and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability, or any other legally protected status. We welcome diversity and strive to maintain an inclusive environment for all employees. If you need assistance with completing the application process, please contact us at hiring@phaidra.ai. \n  E-Verify Notice \n  Phaidra participates in E-Verify, an employment authorization database provided through the U.S. Department of Homeland Security (DHS) and Social Security Administration (SSA). As required by law, we will provide the SSA and, if necessary, the DHS, with information from each new employee's Form I-9 to confirm work authorization for those residing in the United States. \n  Additional information about E-Verify can be found here. \n  #LI-Remote \n  WE DO NOT ACCEPT APPLICATIONS FROM RECRUITERS.",
        "cleaned_desc": " \n Define functional requirements, develop detailed product specifications and associated project work plans for features and key enhancement requests. \n Own the roadmap, functional requirements, and develop timeline for multiple staged releases of your product. \n Provide technical guidance to customer teams using Phaidra products \n Be deeply empathetic to customer needs - working to identify, define, and represent their goals and problems - and rally partners to tackle them. \n Think analytically and make decisions and forecast impact through data. Test and learn via analytics, user research, prototyping, surveys, user testing, customer interviews, and rapid experimentation. \n Gathering direct feedback from customers and expertly communicating that to the Product and Engineering Teams. \n \n Key Qualifications \n \n 3+ years of technical product management experience \n Industrial/HVAC controls experience \n Have shipped refined complex, technical products \n Experience pulling insights from quantitative and qualitative data to articulate customer challenges \n Strong technical understanding, ability to establish credibility with engineers \n Bias-to-action and hands-on experience delivering business results. You're not afraid to get your hands dirty. \n Ability to drive teams of diverse backgrounds to ship features on aggressive timeline \n Excellent communicator, written and verbal, and enjoys a fast paced work environment. \n 3+ years experience with Agile and scrum workflows and processes. ",
        "techs": [
            "phaidra products",
            "agile",
            "scrum"
        ],
        "cleaned_techs": [
            "phaidra products",
            "agile",
            "scrum"
        ]
    },
    "a95d97d840a7f54e": {
        "terms": [
            "mlops"
        ],
        "salary_min": 70.0,
        "salary_max": -1.0,
        "title": "AWS DevOps Engineer/W2",
        "company": "Stark Dev, LLC",
        "desc": "This position is open for  United States Citizens/ GC/GC EAD/H4 EAD/TN VISA HOLDERS. \n Workplace Type \n 100% Remote \n Experience Level \n Expert Level \n External Communities Job Description \n An exciting DevOps Opportunity for someone with a Linux/ AWS background that is interested in joining a Leading Medical Device Companies Connected Device Team. This individual will bring outside expertise to advise and guide on best practices to continue to grow their DevOps presence through industry best practice. \n Enterprise Req Skills \n DevOps, Automation,Aws,Python,Linux,Cloud \n Job Title \n AWS DevOps Engineer \n Top Skills Details \n 1) 3-5 Years of Experience working in AWS DevOps Environment -Native AWS Tooling: AWS Formation / Cloud Watch 2) Python Scripting Experience 3) Hands on experience with build and release pipelines and Microservices using GitLab 4) Linux Experience 5) Strong Communication \n Job Type: Contract \n Pay: From $70.00 per hour \n Experience level: \n \n 5 years \n \n Schedule: \n \n Monday to Friday \n \n Experience: \n \n AWS DevOps Environment: 3 years (Required) \n Native AWS Tooling: AWS Formation / Cloud Watch: 3 years (Required) \n Python Scripting: 3 years (Required) \n building pipelines and Microservices using GitLab: 2 years (Required) \n NodeJS: 1 year (Preferred) \n Linux: 2 years (Required) \n Typescript: 2 years (Required) \n AWS CloudFormation: 2 years (Required) \n Agile development framework: 2 years (Required) \n Terraform: 1 year (Preferred) \n \n Work Location: Remote",
        "cleaned_desc": " Enterprise Req Skills \n DevOps, Automation,Aws,Python,Linux,Cloud \n Job Title \n AWS DevOps Engineer \n Top Skills Details \n 1) 3-5 Years of Experience working in AWS DevOps Environment -Native AWS Tooling: AWS Formation / Cloud Watch 2) Python Scripting Experience 3) Hands on experience with build and release pipelines and Microservices using GitLab 4) Linux Experience 5) Strong Communication \n Job Type: Contract ",
        "techs": [
            "devops",
            "automation",
            "aws",
            "python",
            "linux",
            "cloud",
            "aws formation",
            "cloud watch",
            "gitlab"
        ],
        "cleaned_techs": [
            "devops",
            "automation",
            "aws",
            "python",
            "linux",
            "cloud",
            "cloud watch",
            "gitlab"
        ]
    },
    "89636414dcf9dc8d": {
        "terms": [
            "mlops"
        ],
        "salary_min": 104300.14,
        "salary_max": 132067.22,
        "title": "DevOps Engineer",
        "company": "Optimal Growth Technologies",
        "desc": "Client:  Canadian \n \n Location:  Remote (India/Mexico), work within Canadian time zone (EST) \n \n Period:  12 Months \n \n Type:  Contract \n \n \n Role Overview: \n  We are seeking a highly skilled and experienced DevOps Engineer to join our dynamic team. As a DevOps Engineer, you will play a crucial role in enhancing our systems and processes to ensure seamless development, deployment, and operation of our applications and services. The ideal candidate is an intermediate to advanced Systems Engineer with expertise in Terraform, Azure DevOps, PowerShell, and Azure technologies. Additionally, proficiency in English and excellent communication skills are essential for success in this role. \n \n \n Key Responsibilities: \n  Collaborate with development and operations teams to design, implement, and maintain automated CI/CD pipelines. Utilize Terraform for infrastructure as code (IaC) to efficiently provision and manage resources on cloud platforms. Work closely with Azure DevOps to automate and streamline the release process, ensuring faster and more reliable deployments. Develop and maintain PowerShell scripts for tasks related to automation, configuration management, and system administration. Configure and manage Azure resources, including virtual machines, databases, and networking components. Monitor and optimize system performance, security, and availability, identifying and resolving issues as they arise. Collaborate with cross-functional teams to troubleshoot and resolve technical problems. Stay up-to-date with industry best practices and emerging technologies to drive continuous improvement in DevOps processes. \n \n \n Skills and Qualifications: \n  Intermediate to advanced proficiency in Systems Engineering. Extensive experience with Terraform for infrastructure provisioning and management. Strong expertise in Azure DevOps for CI/CD pipeline automation. Proficient in PowerShell scripting for automation and configuration management. In-depth knowledge of Azure cloud services and resources. Excellent command of the English language, both written and spoken. Outstanding communication skills, with the ability to convey complex technical concepts to diverse stakeholders. \n \n \n Preferred Qualifications: \n  Bachelors degree in Computer Science, Engineering, or a related field. Relevant certifications in DevOps, Azure, or related technologies. Experience with containerization technologies (e.g., Docker, Kubernetes).Familiarity with configuration management tools (e.g., Ansible, Puppet).Knowledge of source code management systems (e.g., Git).Understanding of networking principles and protocols.",
        "cleaned_desc": " \n Key Responsibilities: \n  Collaborate with development and operations teams to design, implement, and maintain automated CI/CD pipelines. Utilize Terraform for infrastructure as code (IaC) to efficiently provision and manage resources on cloud platforms. Work closely with Azure DevOps to automate and streamline the release process, ensuring faster and more reliable deployments. Develop and maintain PowerShell scripts for tasks related to automation, configuration management, and system administration. Configure and manage Azure resources, including virtual machines, databases, and networking components. Monitor and optimize system performance, security, and availability, identifying and resolving issues as they arise. Collaborate with cross-functional teams to troubleshoot and resolve technical problems. Stay up-to-date with industry best practices and emerging technologies to drive continuous improvement in DevOps processes. \n   \n Skills and Qualifications: \n  Intermediate to advanced proficiency in Systems Engineering. Extensive experience with Terraform for infrastructure provisioning and management. Strong expertise in Azure DevOps for CI/CD pipeline automation. Proficient in PowerShell scripting for automation and configuration management. In-depth knowledge of Azure cloud services and resources. Excellent command of the English language, both written and spoken. Outstanding communication skills, with the ability to convey complex technical concepts to diverse stakeholders. \n ",
        "techs": [
            "terraform",
            "azure devops",
            "powershell",
            "azure cloud services"
        ],
        "cleaned_techs": [
            "terraform",
            "azure",
            "powershell"
        ]
    },
    "a2a4115d6d823ee0": {
        "terms": [
            "mlops"
        ],
        "salary_min": 58300.0,
        "salary_max": 133000.0,
        "title": "DevOps Engineer",
        "company": "Booz Allen Hamilton",
        "desc": "Job Description \n \n \n \n \n \n \n \n \n \n \n         Location: \n         \n \n         Charleston,SC,US \n         \n \n \n \n         Remote Work: \n         \n \n         Yes \n         \n \n \n \n         Job Number: \n         \n \n         R0180033\n         \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n         DevOps Engineer\n           The Challenge : \n  Are you looking for an opportunity to make a difference in the healthcare market? What if you could find a position that is tailor-made for your mix of development, engineering, and communication skills? Efficient software development teams make the most of their time by limiting the activities that take developers away from writing their code. That\u2019s why we need you, a DevOps engineer, to help us shorten the time it takes to get critical tools developed and into the hands of our Agile developers creating products supporting our warfighters around the world. \n \n  As a DevOps engineer on our team, you\u2019ll help streamline our software development life cycle from requirements to monitoring in production. You\u2019ll incorporate open-source tools, automation, and Cloud resources to cut down on tedious, boring tasks, and free up the team\u2019s developers to do what they do best \u2013 innovate. You\u2019ll work with the team to implement continuous integration and delivery to limit manual testing and troubleshooting. \n \n  This is an opportunity to build your experience in Cloud-native technologies, Infrastructure-as-Code, pipelines, and Kubernetes while developing products that will support our Agile teams to move faster and deliver more to those on the front lines providing care for our warfighters. Build your experience with the software development life cycle on a team that works together to make the best software solutions. Join our team as we build tools to transform the future. \n \n  Empower change with us. \n \n  You Have: \n \n  Experience with Cloud engineering \n  Experience with automation technologies, including Ansible and Terraform \n  Ability to obtain a security clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  Experience with Amazon Web Services \n  Experience with Docker and containerization \n  Experience with Jenkins and pipeline technologies \n  Experience with open-source frameworks for logging and monitoring, including ELK, Prometheus, and Grafana \n  Bachelor's degree \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n \n  Build Your Career: \n  A challenging and dynamic work environment isn\u2019t all we have to offer. When you join Booz Allen, you\u2019ll have access to: \n \n  experts in virtually every field \n  a culture that focuses on supporting our employees \n  opportunities that provide stability while offering variety \n \n \n  You\u2019ll also be exposed to a wealth of training resources through our Digital University, an online learning portal featuring more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We\u2019ll help you develop the career you want as you chart your own course for success. \n \n  Compensation \n  At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. \n  Salary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n          \n  Work Model  Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. \n \n  If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility. \n  If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role. \n \n \n  EEO Commitment \n  We\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
        "cleaned_desc": "  You Have: \n \n  Experience with Cloud engineering \n  Experience with automation technologies, including Ansible and Terraform \n  Ability to obtain a security clearance \n  HS diploma or GED \n \n \n  Nice If You Have: \n \n  Experience with Amazon Web Services \n  Experience with Docker and containerization \n  Experience with Jenkins and pipeline technologies \n  Experience with open-source frameworks for logging and monitoring, including ELK, Prometheus, and Grafana \n  Bachelor's degree \n \n \n  Clearance: \n  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. \n ",
        "techs": [
            "cloud engineering",
            "ansible",
            "terraform",
            "amazon web services (aws)",
            "docker",
            "jenkins",
            "elk (elasticsearch",
            "logstash",
            "and kibana)",
            "prometheus",
            "grafana"
        ],
        "cleaned_techs": [
            "cloud engineering",
            "ansible",
            "terraform",
            "aws",
            "docker",
            "jenkins",
            "elk (elasticsearch",
            "logstash",
            "and kibana)",
            "prometheus",
            "grafana"
        ]
    },
    "024dc461f7e55047": {
        "terms": [
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 204500.0,
        "title": "Principal DevOps Engineer - Claims Technology (REMOTE)",
        "company": "GEICO",
        "desc": "GEICO\u2019s Technology Solutions organization has a great opportunity for a Principal DevOps Engineer to join our Claims Administration and Management Office (AMO) team. This position is fully Remote and offers the opportunity to be highly engaged with internal and external teams while working independently.\n  \n \n \n   The right candidate for this position will work on a small team that collaborates with groups across the organization, have confident communication skills, strong multi-tasking abilities and excellent troubleshooting experience involving complex technical issues.\n  \n \n \n   Position Responsibilities\n  \n \n   As a Principal DevOps Engineer, you will:\n  \n \n \n \n     Lead the design, implementation and administration of middleware infrastructure including WebServers, Application Servers, Messaging on Apache Tomcat, JBoss, IBM MQ, AMQ, Dot-Net, API gateways, other complex engineering technologies on Linux, Windows OS. Knowledge of MuleSoft 4.x Platform Administration\n    \n \n \n     Drive the implementation of DevOps practices, tools and automation to streamline the SDLC, deployment process and infrastructure management\n    \n \n \n     Identify and resolve performance bottlenecks, conduct capacity planning and implement performance testing, optimization strategies\n    \n \n \n     Drive initiatives to improve system stability, reliability by implementing SRE principles, incident response, post-mortem, disaster recovery, chaos engineering\n    \n \n \n     Ensure security compliance of middleware systems by implementing best practices, accessing vulnerability as recommended by Cybersecurity team with an understanding of security protocols\n    \n \n \n     Collaborate with IT teams including but not limited to: Developers, System & Network administrators, Database Architects, Infrastructure, Technical Operations and Security teams for continuous support and improvement\n    \n \n \n     Provide 24/7 operations support for production, other critical environments and DevOps multi-tasking with clear communication skills\n    \n \n \n     Establish and employ continuous integration practices and tools\n    \n \n \n \n   Qualifications\n  \n \n \n \n     Fluency in DevOps, Middleware concepts, Operational Framework and Cloud Architecture\n    \n \n \n     Ensure high availability and scalability of applications and infrastructure by implementing monitoring and alerting solutions with monitoring tools like: Dynatrace, Splunk, Grafana or similar tools to detect and resolve issues\n    \n \n \n     Strong expertise with DevOps KPIs, configurable monitoring dashboards to monitor trends, metrics, progress and workflow\n    \n \n \n     Experience with management of configurations, provisioning of infrastructure resources using infrastructure-as-code tools, techniques with Ansible Automation Platform (AAP) or similar\n    \n \n \n     Experience in project management working across IT teams on project requirements, setting goals and ensuring their successful executions\n    \n \n \n     Experience using strong problem solving and analytical skills to triage complex technical issues\n    \n \n \n     Working experience with agile teams following Scrum and/or Kanban methodology\n    \n \n \n     Provide technical leadership, mentorship, coaching to the IT teams promoting professional knowledge sharing\n    \n \n \n     Experience with software tools: Microsoft ADO, SharePoint, PowerBI, Helix, Confluence or similar\n    \n \n \n \n   Experience\n  \n \n \n \n     6+ years of professional software development experience\n    \n \n \n     3+ years of experience with architecture and design3+ years of experience with AWS, GCP, Azure, or another cloud service\n    \n \n \n     4+ years of experience in open source frameworks\n    \n \n \n     1+ years of people management experience\n    \n \n \n \n   Education\n  \n \n \n \n     Bachelor\u2019s degree in Computer Science, Information Systems, or equivalent education or work experience\n    \n \n \n \n   #LI-MK1\n  \n \n \n  Annual Salary\n   $100,000.00 - $204,500.00\n  \n   The above annual salary range is a general guideline. Multiple factors are taken into consideration to arrive at the final hourly rate/ annual salary to be offered to the selected candidate. Factors include, but are not limited to, the scope and responsibilities of the role, the selected candidate\u2019s work experience, education and training, the work location as well as market and business considerations.\n  \n \n  GEICO will consider sponsoring a new qualified applicant for employment authorization for this position.\n  \n \n  Benefits:\n  \n \n   As an Associate, you\u2019ll enjoy our \n   \n   Total Rewards Program\n   \n \n to help secure your financial future and preserve your health and well-being, including: \n \n \n \n  Premier Medical, Dental and Vision Insurance with no waiting period** \n  Paid Vacation, Sick and Parental Leave \n  401(k) Plan \n  Tuition Reimbursement \n  Paid Training and Licensures \n \n \n \n Benefits may be different by location. Benefit eligibility requirements vary and may include length of service. \n \n \n   **Coverage begins on the date of hire. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.\n  \n \n \n   The equal employment opportunity policy of the GEICO Companies provides for a fair and equal employment opportunity for all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO hires and promotes individuals solely on the basis of their qualifications for the job to be filled.\n  \n \n \n   GEICO reasonably accommodates qualified individuals with disabilities to enable them to receive equal employment opportunity and/or perform the essential functions of the job, unless the accommodation would impose an undue hardship to the Company. This applies to all applicants and associates. GEICO also provides a work environment in which each associate is able to be productive and work to the best of their ability. We do not condone or tolerate an atmosphere of intimidation or harassment. We expect and require the cooperation of all associates in maintaining an atmosphere free from discrimination and harassment with mutual respect by and for all associates and applicants.",
        "cleaned_desc": "    \n \n \n     Collaborate with IT teams including but not limited to: Developers, System & Network administrators, Database Architects, Infrastructure, Technical Operations and Security teams for continuous support and improvement\n    \n \n \n     Provide 24/7 operations support for production, other critical environments and DevOps multi-tasking with clear communication skills\n    \n \n \n     Establish and employ continuous integration practices and tools\n    \n \n \n \n   Qualifications\n  \n \n \n \n     Fluency in DevOps, Middleware concepts, Operational Framework and Cloud Architecture\n    \n \n \n     Ensure high availability and scalability of applications and infrastructure by implementing monitoring and alerting solutions with monitoring tools like: Dynatrace, Splunk, Grafana or similar tools to detect and resolve issues\n    \n \n \n     Strong expertise with DevOps KPIs, configurable monitoring dashboards to monitor trends, metrics, progress and workflow\n    \n \n       Experience with management of configurations, provisioning of infrastructure resources using infrastructure-as-code tools, techniques with Ansible Automation Platform (AAP) or similar\n    \n \n \n     Experience in project management working across IT teams on project requirements, setting goals and ensuring their successful executions\n    \n \n \n     Experience using strong problem solving and analytical skills to triage complex technical issues\n    \n \n \n     Working experience with agile teams following Scrum and/or Kanban methodology\n    \n \n \n     Provide technical leadership, mentorship, coaching to the IT teams promoting professional knowledge sharing\n    \n \n \n     Experience with software tools: Microsoft ADO, SharePoint, PowerBI, Helix, Confluence or similar\n    \n \n \n \n   Experience\n  \n \n \n \n     6+ years of professional software development experience\n    \n ",
        "techs": [
            "developers",
            "system & network administrators",
            "database architects",
            "infrastructure",
            "technical operations",
            "security teams",
            "dynatrace",
            "splunk",
            "grafana",
            "ansible automation platform (aap)",
            "microsoft ado",
            "sharepoint",
            "powerbi",
            "helix",
            "confluence"
        ],
        "cleaned_techs": [
            "developers",
            "system & network administrators",
            "database architects",
            "infrastructure",
            "technical operations",
            "dynatrace",
            "splunk",
            "grafana",
            "ansible automation platform (aap)",
            "microsoft ado",
            "sharepoint",
            "powerbi",
            "helix",
            "confluence"
        ]
    },
    "b1c915da08491ca5": {
        "terms": [
            "mlops"
        ],
        "salary_min": 95159.59,
        "salary_max": 120493.25,
        "title": "DevOps Manager",
        "company": "Green Thumb",
        "desc": "The Role \n  GTI is looking for a people-first DevOps Manager to support the development and operation of cutting-edge web and mobile eCommerce applications across our many lines of business: retail delivery/click-and-collect (B2C), wholesale B2B, and CPG brands both via retailer (B2B2C) and D2C where allowed. The role is a foundational piece of a highly visible, business facing team focused on aligning strategic objectives with tactical demands in the cannabis industry, one of the fastest growing and most innovative industries in the US. The customer experiences you enable will generate over half a billion dollars in your first year. \n  Responsibilities \n \n Manage and mentor a diverse team of DevOps, QA and Support Engineers in the US and India \n Champion our SDLC and CI/CD pipeline to improve the developer experience and productivity \n Enable the development of modern cloud-native software, producing decoupled and highly-performant services to power revenue-generating web, mobile and in-store applications \n Codify, maintain and improve testing processes to ensure high quality and maintainable code \n Optimize architecture for security, scalability, reliability, and resiliency \n Leverage serverless technologies such as AWS Lambda to drive innovation and minimize timelines \n Collaborate across business and technical partners to define requirements, dependencies and challenges, mitigating risks and removing blockers \n \n Qualifications \n \n 5+ years of progressive software engineering, including 2 years as a team lead and/or people manager \n Ability to motivate, mentor, empower, organize and communicate across distributed teams \n AWS Certified DevOps Engineer or equivalent professional experience \n Track record deploying and supporting complex technical solutions across multiple applications, balancing build and run considerations \n Deep technical competency and thought leadership; flexibility to leverage existing proficiencies or adopt new frameworks \n Principles of site reliability engineering; monitoring, alerting and on-call program execution \n Unit, functional and integration testing via frameworks such as Jest or Selenium \n Relational and non-relational databases; functions and containers; REST and GraphQL APIs \n Delivery, security/compliance and automation via edge cloud platforms (Cloudflare, Netlify) \n \n Stack \n \n Frontend:  React, Next.js, Composable / Atomic Design \n Backend:  Node.js, TypeScript, Serverless \n Architecture:  Microservices based, API first, Cloud-native SaaS, Headless \n \n Additional Requirements \n \n Must pass any and all required background checks \n Must be and remain compliant with all legal or company regulations for working in the industry \n Must possess valid driver's license \n Must be a minimum of 21 years of age \n \n \n \n  #LI-Remote",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "4098169b2d5bd6b1": {
        "terms": [
            "mlops"
        ],
        "salary_min": 119302.945,
        "salary_max": 151064.11,
        "title": "Sr. DevOps Manager (Remote)",
        "company": "Patterson Companies, Inc.",
        "desc": "The Senior DevOps Manager is accountable for leading the DevOps and DevOps team within the Cloud Engineering - Technical Operations Group. Technical Operations is responsible for DevOps, DevSecOps and SRE. The Manager will report to the Director of Cloud Engineering \u2013 Technical Operations. The group will focus on practices and tools with a collaborative cultural philosophy to manage software development process. The team will work on automation and integrating processes between software development and supporting teams. In addition, the team will focus on the security of the entire software development process including integration of security best-practices early-on and throughout the entire software development life cycle. The Sr. DevOps/DevSecOps Manager works closely with internal and external customers and product teams to identify and maximize opportunities to promote the strategic use of technology solutions. Participates in the development of technical and development standards for product and system domain and enterprise. \n \n  Essential Functions \n  To perform this job successfully, an employee must be able to perform each essential function satisfactorily, with or without reasonable accommodation. To request a reasonable accommodation, notify Human Resources or the manager who oversees the position. \n \n  Leads team members to complete DevOps and DevSecOps related activities for products and systems; creates a high-performance culture driven by strategic objectives and goals of Patterson. \n  Hires, leads, and develops a diverse set of individuals operating as a collective team. \n  Develops team and individual goals and holds direct reports accountable for meeting performance standards and goals; measures staff performance and completes regular performance reviews and ranking \n  Partners with other leaders in software engineering to ensure quality and timely planning and delivery of products and systems across domains \n  Defines DevOps & DevSecOps strategy and objectives and establishes short-term and long-term metrics for department goals ensuring product quality throughout the software development life cycle \n  Introduces and adopts contemporary approaches to DevOps & DevSecOps practices, including automation for products and plans \n  Participates in annual budget development and financial management for the functional areas \n  Works closely with stakeholders and business leadership to ensure understanding of DevOps & DevSecOps practices, objectives, and metrics and to discover product priorities and requirements within and across domains \n  Maintains and builds knowledge of trends and technologies and their application within domain; partners with technical leaders to influence adoption of new technical techniques, processes and tools \n  Drives highest level support for incoming incidents from end users to resolve application and software issues. \n  For products under scope of regulatory quality management, ensures completion of quality related tasks within functional areas \n \n \n  A dditional Functions \n  In addition to the essential functions listed above, the incumbent may perform the following additional functions.  \n \n Provides input for annual budget development and financial management for the functional areas \n  Facilitates completion of product software development lifecycle documentation and controls \n  Provides regulatory approvals for quality management records for software medical device products \n  Serves as liaison with indirect sourcing to ensure timely purchases, renewals and contract SoW management \n \n \n  Required Qualifications \n \n  Bachelor's in Computer Science, Information Systems, a related field or equivalent work experience \n  7+ years\u2019 of Cloud, DevOps and production system security related experiences \n  At least 5 years\u2019 experience in team management \n  Experience in building and maintaining mainstream security systems on cloud platforms. \n  Solid experience and mindset on cloud-based security solution and architecture design and implementation \n  Define and govern DevOps and DevSecOps standards, processes and strategy that will be used across the Dental Software organization \n  Knowledge of DevOps thought leadership with mindset to lead new ways to use data \n  Familiarity with Terraform and Cloud Formation Templates \n  Knowledge of current DevOps, automation and test coverage strategic concepts and understanding of how multiple development technologies, languages and platforms are used to build software products \n  Experience in strategic planning, development, implementation, change management and maintenance of large-scale, integrated systems \n  Ability to interpret customer and business needs to help build technical plans for capability and value delivery \n  Proven ability to establish and drive strategic and tactical initiatives while providing conflict resolution when necessary \n  Ability to solve problems independently and collaborate as a team to solve complex problems \n  Demonstrated ability to lead, communicate and work in a collaborative and cross-functional team environment  \n Experience Building and maintaining GCP, AWS, or Azure infrastructure and services \n  Experience working in an Agile/Scrum environment and different automation and DevOps tools required to develop digital pipelines \n \n \n  Preferred Qualifications \n  Experience with corporate governance and developing business cases and return on investment analyses  \n Experience working with on regulated software products \n  Knowledge of Azure Cloud Platform \n \n  Office environment \u2013 either in Patterson facility or at home/remote location \n  Travel to corporate sites is periodically required (Quarterly or so) \n \n  Periodic on call rotations and available outside of normal business hours on evenings and weekends during critical production release or issue escalation periods \n \n  The duties of this role may be performed remotely in the following states: AK,AZ,CA,CO,CT,DC,HI,ID,IL,KS,KY,ME,MA,MI,MN,MO,NE,NV,NH,NM,NY,OR,RI,SD,TN,TX,UT,VT,WA,WV,WI \n \n  The potential compensation range for this role is below. The final offer amount would be based on various factors such as candidate location (geographical labor market), experience, and skills. \n  $180,000 - $200,000",
        "cleaned_desc": "  Serves as liaison with indirect sourcing to ensure timely purchases, renewals and contract SoW management \n \n \n  Required Qualifications \n \n  Bachelor's in Computer Science, Information Systems, a related field or equivalent work experience \n  7+ years\u2019 of Cloud, DevOps and production system security related experiences \n  At least 5 years\u2019 experience in team management \n  Experience in building and maintaining mainstream security systems on cloud platforms. \n  Solid experience and mindset on cloud-based security solution and architecture design and implementation \n  Define and govern DevOps and DevSecOps standards, processes and strategy that will be used across the Dental Software organization \n  Knowledge of DevOps thought leadership with mindset to lead new ways to use data    Familiarity with Terraform and Cloud Formation Templates \n  Knowledge of current DevOps, automation and test coverage strategic concepts and understanding of how multiple development technologies, languages and platforms are used to build software products \n  Experience in strategic planning, development, implementation, change management and maintenance of large-scale, integrated systems \n  Ability to interpret customer and business needs to help build technical plans for capability and value delivery \n  Proven ability to establish and drive strategic and tactical initiatives while providing conflict resolution when necessary \n  Ability to solve problems independently and collaborate as a team to solve complex problems \n  Demonstrated ability to lead, communicate and work in a collaborative and cross-functional team environment  \n Experience Building and maintaining GCP, AWS, or Azure infrastructure and services \n  Experience working in an Agile/Scrum environment and different automation and DevOps tools required to develop digital pipelines \n \n \n  Preferred Qualifications ",
        "techs": [
            "terraform",
            "cloud formation templates",
            "gcp",
            "aws",
            "azure"
        ],
        "cleaned_techs": [
            "terraform",
            "cloud formation templates",
            "gcp",
            "aws",
            "azure"
        ]
    },
    "fec8f9e9c69ae17e": {
        "terms": [
            "mlops"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Instructor, DevOps (SDA Program, Live Online)",
        "company": "Fullstack Academy",
        "desc": "Fullstack Academy is a top-ranked immersive school for technology skills training. Fullstack prepares students with the in-demand skills they need to launch fulfilling tech careers. \n  ABOUT THE ROLE \n  Fullstack Academy Instructors scale their impact as a DevOps professional by training the next generation of DevOps Engineers. In this role, you\u2019ll create dynamic learning experiences through deployment of instructional best practices that are student-centered and designed to meet the needs of adult learners. You\u2019ll co-facilitate lessons from the curriculum and will serve as subject matter expert to students and staff. You will support students through exercises designed to build knowledge and skills and promote grit, problem-solving and a collaborative learning community. Ultimately, you will prepare students for the next chapter in their lives as they seek employment in the DevOps field. \n  Fullstack Academy is excited to extend our mission internationally through a partnership with a local education provider in Saudi Arabia. The partnership in Saudi Arabia, part of Saudi Vision 2030, aims to develop human capital and the digital capabilities of Saudi university graduates. In response to Saudi tech employers calling for more practically prepared talent, Fullstack Academy is going to provide the much needed training via our bootcamp model.  \n LOGISTICS \n  This is a contract role for approximately 15 weeks and requires an ability to lead classes from 9:00 a.m. - 5:00 p.m. Riyadh Time Sunday through Thursday in a face-to-face synchronous online class experience. The exact dates noted below are subject to change. \n  The contract spans 15 weeks: \n \n Instructor on-boarding to Fullstack Academy for two weeks in the middle of December. This training requires work from 9am - 5pm on Central Standard Time. \n Additional training and lesson planning January 10-13  \n 3 days cohort preparation and student orientation January 14-16 \n 12 weeks of bootcamp instruction on location from January 17- April 9, 2024 \n Classes meet from Sunday-Thursday 9:00am - 5:00 pm Riyadh Time \n Classes will be taught in English - knowledge of Arabic is not required \n The teaching team will consist of instructors and mentors (teaching assistants) \n US holidays that fall during the bootcamp will not be recognized \n Saudi Arabia holidays that fall during the bootcamp will be recognized \n \n This role reports to a Program Manager and is supported by a collaborative academics team at Fullstack Academy and a team with the local Saudi partner to ensure an exceptional experience for each student in the cohort.  \n INSTRUCTOR RESPONSIBILITIES \n  In this role, you will: \n \n Create a positive, professional and inclusive learning environment, by:\n    \n Teaching lessons in accordance with learning objectives and fidelity to session plans provided by Fullstack \n Employing strategies known to meet the needs of adult learners, including leveraging tech tools, instructional best practices and connecting content to the real world by sharing industry insights and professional experiences \n Managing regular communication with students and support teams to align on progress, expectations, celebrate milestones and address concern areas \n Providing individualized student support during synchronous class sessions and outside class synchronously during office hours and asynchronously through timely communication \n \n Evaluate student performance and progression toward competencies based on course deliverables and course rubrics, by:\n    \n Providing constructive and timely feedback to students in the cohort, escalating concerns in a timely manner to the support teams \n Assisting in the management of Academic Plans for Success for individual students who need additional support \n \n Serve as role model for students and as an ambassador for our brands, by:\n    \n Exhibiting professionalism and an ethical and empathetic approach when engaging with Fullstack staff, students, and the public \n Promoting student retention and amplify student satisfaction by creating a positive classroom culture, communicating timely with students and leveraging effective interventions and sharing of resources \n Encouraging teamwork and seeking feedback for continuous improvement \n \n \n QUALIFICATIONS \n  Eligibility requires the following: \n \n Minimum one or more of the following\n    \n Bachelor\u2019s Degree in Computer Science, Information Technology, or related field such as DevOps or Cloud Computing  \n OR minimum three years of experience as a DevOps engineer \n Have prior experience teaching or mentoring in an informal capacity \n AND have one or more AWS certifications, especially:\n      \n AWS Certified Cloud Foundations \n AWS Certified Solutions Architect - Associate \n AWS Certified Developer - Associate \n AWS Certified SysOps Administrator - Associate \n \n \n Preferential consideration will be given to candidates with the following experience:\n    \n A minimum of five years of professional experience in a DevOps role  \n AND prior experience teaching or mentoring in a formal capacity \n AND are an AWS Academy Accredited Educator for at least one AWS Academy course, especially:\n      \n AWS Academy Cloud Architecting \n AWS Academy Cloud Developing \n AWS Academy Cloud Operations \n \n \n \n COMPENSATION PACKAGE \n  Contract includes compensation for: onboarding and online instruction and a generous bonus.",
        "cleaned_desc": "",
        "techs": "",
        "cleaned_techs": []
    },
    "7cacea803827d03b": {
        "terms": [
            "mlops"
        ],
        "salary_min": 108796.45,
        "salary_max": 137760.55,
        "title": "DevOps / Infrastructure Automation Engineer - remote in D.C. area",
        "company": "Paradyme Management",
        "desc": "Paradyme Management is a rapidly growing government technology leader that puts service first, for its customers, its team and the communities it supports. Paradyme harnesses DevSecOps and Agile development processes to deliver exceptional results for digital transformations. With headquarters office in Tysons Corner, VA, Paradyme\u2019s award-winning culture sets it apart through its team\u2019s deep commitment to service and collaboration with its customers, each other and the community. Learn more at www.paradymemanagement.com. \n The IT Infrastructure Automation Specialist will play a crucial role in streamlining and enhancing our IT operations by designing, implementing, and managing automation solutions. This role demands a deep understanding of infrastructure technologies, scripting, and orchestration tools to improve efficiency, reduce manual intervention, and enhance overall system reliability. The successful candidate will collaborate with cross-functional teams to ensure that IT infrastructure supports the company's growth and business objectives. \n Key Responsibilities: \n Infrastructure Automation:  Design, develop, and maintain automation scripts and workflows to automate routine infrastructure tasks such as provisioning, configuration management, and scaling. \n Orchestration:  Implement orchestration frameworks to streamline complex workflows and ensure efficient resource allocation across servers, storage, and networking. \n Scripting and Coding:  Utilize scripting languages (e.g., Python, PowerShell) and Infrastructure as Code (IaC) tools (e.g., Terraform, Terragrunt, Ansible) to automate infrastructure deployment and management. \n Monitoring and Optimization:  Continuously monitor infrastructure performance, identify bottlenecks, and optimize systems for improved efficiency, scalability, and cost-effectiveness. \n Security and Compliance:  Implement security best practices and compliance standards through automation to ensure a secure IT environment. \n Collaboration:  Collaborate with IT teams to gather requirements, assess automation needs, and provide technical expertise to support various projects and initiatives. Work closely with the team in a Kanban and SAFe environment to deliver on project goals. \n Documentation:  Maintain detailed documentation of automation scripts, configurations, and procedures for knowledge sharing and future reference. \n Troubleshooting:  Diagnose and resolve automation-related issues promptly to minimize downtime and ensure system stability. \n Stay Current:  Stay abreast of emerging automation and infrastructure technologies, and recommend innovative solutions to enhance operations. \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). \n 5+ years experience in IT infrastructure automation, scripting, and orchestration. \n Proficiency in scripting languages (e.g., Python, PowerShell) and automation tools (e.g., Ansible, Terraform, Terragrunt). \n Strong knowledge of cloud platforms (e.g., AWS, Azure, GCP) and virtualization technologies. \n Active Public Trust clearance or the ability to obtain and maintain one. \n Familiarity with containerization and container orchestration (e.g., Docker, Kubernetes, Morpheus). \n Excellent problem-solving and troubleshooting skills. \n Strong communication and collaboration skills. \n Ability to work independently and as part of a team. \n \n Preferred Skills: \n \n Certifications such as AWS Certified DevOps Engineer, Microsoft Certified: Azure DevOps Engineer, or relevant industry certifications are a plus. \n Understanding of Kanban and SAFe methodologies. \n Experience in software development, including proficiency in programming languages such as Java, Python, C++, or others is a plus. \n Familiarity with software development methodologies, version control systems (e.g., Git) is a plus. \n \n REMOTE WORK \n While this position is currently remote, we prefer candidates reside in the local MD, DC, VA areas in the event that our federal customer requires hybrid work in the future. \n Physical Requirements:  These are the essential physical requirements needed to successfully perform the job. \n \n Sedentary work.Requires sitting up to 8 hours per day. \n \n May require lifting up to 5 pounds unassisted. Fine repetitive motor skills with hands, wrists, and fingers in coordination with eyes. \n \n Hearing, speaking, and vision: Adequate to perform job duties and communicate in person, via video, and telephone. Includes reading information from printed sources and computer screens. \n Other: Work may be performed in an office environment, which may involve frequent contact with staff and the public. Work may be stressful at times. \n \n Paradyme Management, Inc. is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Paradyme will take the steps to ensure that people with disabilities are provided reasonable accommodations. Accordingly, if a reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please contact Rose Luczak, Director of People Operations at rose.luczak@paradyme.usor at (571) 289-0548 \n Paradyme is a federal contractor and an EEO and an Affirmative Action Employer. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, pregnancy-related disability, physical or mental disability, genetic information, sexual orientation, marital status, familial status, personal appearance, occupation, citizenship, veteran or military status, gender identity or expression, or any other characteristic protected by federal, state or local law. \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Employee assistance program \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Vision insurance \n \n Experience level: \n \n 5 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n \n Work Location: Remote",
        "cleaned_desc": "Paradyme Management is a rapidly growing government technology leader that puts service first, for its customers, its team and the communities it supports. Paradyme harnesses DevSecOps and Agile development processes to deliver exceptional results for digital transformations. With headquarters office in Tysons Corner, VA, Paradyme\u2019s award-winning culture sets it apart through its team\u2019s deep commitment to service and collaboration with its customers, each other and the community. Learn more at www.paradymemanagement.com. \n The IT Infrastructure Automation Specialist will play a crucial role in streamlining and enhancing our IT operations by designing, implementing, and managing automation solutions. This role demands a deep understanding of infrastructure technologies, scripting, and orchestration tools to improve efficiency, reduce manual intervention, and enhance overall system reliability. The successful candidate will collaborate with cross-functional teams to ensure that IT infrastructure supports the company's growth and business objectives. \n Key Responsibilities: \n Infrastructure Automation:  Design, develop, and maintain automation scripts and workflows to automate routine infrastructure tasks such as provisioning, configuration management, and scaling. \n Orchestration:  Implement orchestration frameworks to streamline complex workflows and ensure efficient resource allocation across servers, storage, and networking. \n Scripting and Coding:  Utilize scripting languages (e.g., Python, PowerShell) and Infrastructure as Code (IaC) tools (e.g., Terraform, Terragrunt, Ansible) to automate infrastructure deployment and management. \n Monitoring and Optimization:  Continuously monitor infrastructure performance, identify bottlenecks, and optimize systems for improved efficiency, scalability, and cost-effectiveness. \n Security and Compliance:  Implement security best practices and compliance standards through automation to ensure a secure IT environment. \n Collaboration:  Collaborate with IT teams to gather requirements, assess automation needs, and provide technical expertise to support various projects and initiatives. Work closely with the team in a Kanban and SAFe environment to deliver on project goals. \n Documentation:  Maintain detailed documentation of automation scripts, configurations, and procedures for knowledge sharing and future reference. \n Troubleshooting:  Diagnose and resolve automation-related issues promptly to minimize downtime and ensure system stability. \n Stay Current:  Stay abreast of emerging automation and infrastructure technologies, and recommend innovative solutions to enhance operations. \n Qualifications:   \n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). \n 5+ years experience in IT infrastructure automation, scripting, and orchestration. \n Proficiency in scripting languages (e.g., Python, PowerShell) and automation tools (e.g., Ansible, Terraform, Terragrunt). \n Strong knowledge of cloud platforms (e.g., AWS, Azure, GCP) and virtualization technologies. \n Active Public Trust clearance or the ability to obtain and maintain one. \n Familiarity with containerization and container orchestration (e.g., Docker, Kubernetes, Morpheus). \n Excellent problem-solving and troubleshooting skills. \n Strong communication and collaboration skills. \n Ability to work independently and as part of a team. \n \n Preferred Skills: \n ",
        "techs": [
            "devsecops",
            "agile development",
            "scripting",
            "orchestration tools",
            "infrastructure technologies",
            "automation solutions",
            "provisioning",
            "configuration management",
            "scaling",
            "scripting languages",
            "infrastructure as code (iac) tools",
            "monitoring",
            "optimization",
            "security best practices",
            "compliance standards",
            "collaboration",
            "kanban",
            "safe",
            "documentation",
            "troubleshooting",
            "emerging automation and infrastructure technologies",
            "cloud platforms",
            "virtualization technologies",
            "containerization",
            "container orchestration"
        ],
        "cleaned_techs": [
            "devsecops",
            "agile development",
            "scripting",
            "orchestration tools",
            "infrastructure technologies",
            "automation solutions",
            "provisioning",
            "configuration management",
            "scaling",
            "scripting languages",
            "infrastructure as code (iac) tools",
            "monitoring",
            "optimization",
            "compliance standards",
            "collaboration",
            "kanban",
            "safe",
            "troubleshooting",
            "emerging automation and infrastructure technologies",
            "cloud platforms",
            "virtualization technologies",
            "containerization",
            "container orchestration"
        ]
    },
    "8754ee8888a60412": {
        "terms": [
            "mlops"
        ],
        "salary_min": 150000.0,
        "salary_max": 170000.0,
        "title": "Sr. DevOps Engineer",
        "company": "Brahma consulting group",
        "desc": "Title: Senior DevOps Engineer \n Location: Redwood City, CA (Remote) \n Type: Direct Hire \n Senior DevOps Engineer We are seeking a DevOps Engineer to accelerate production team engineering infrastructure build and stability through test automation and cloud-based DevOps practices. This key resource will help ZaiNar shift to a high volume, production support model while maintaining innovation in the R&D environment. Experience creating and sustaining multi-cloud and hybrid cloud production systems is required. We expect a proactive individual to propose and implementing industry best practices that enhance ZaiNar\u2019s competitive edge. This role works closely with SW and HW development teams. The successful candidate will be self-motivated and have the ability to proactively communicate and implement technical changes to support engineering strategy. \n JOB RESPONSIBILITIES \n \n Infrastructure as Code with AWS and Terraform. \n CI/CD pipeline design and implementation (GitHub/Actions, GitLab, and/or Jenkins). \n Design and manage quality gates and test automation. \n Identify and record bugs. \n Manage, monitor, troubleshoot, identify bottlenecks and system constraints in AWS production and development environments. \n Provide Engineering and Executive management with real time information on operational performance and necessary documentation. \n \n MUST HAVE ATTRIBUTES/SKILLS \n \n Strong understanding of cloud-based computing, application design, and concepts including serverless, monitoring, auto-scaling, centralized logging with significant AWS experience. \n Experience in Infrastructure as Code via Terraform. \n Experience supporting production SaaS in a multi-account/multi-region AWS environment. \n Strong knowledge of Python or other scripting languages. Experience in other programming languages will be considered as a plus, for job automation and environment understanding. \n Strong experience managing Linux environments. \n Experience in a rapidly growing engineering startup environment. \n Experience with SonarCloud implementation or like best practices. \n Fluency in English. \n \n SHOULD HAVE ATTRIBUTES/SKILLS \n \n BSc degree in Computer Science, Engineering, or a related subject. MSc a plus. \n Hands-on experience with Docker containers, and Kubernetes is a plus. \n Experience with supporting and scaling the majority of the following AWS Services: Lambda, DynamoDB, IAM, IoT Core, EKS, MSK, API Gateway, and Kinesis. \n Pip packaging, deployment automation, configuration management, and Debian packaging. \n Serverless and microservice architecture (and REST). \n Experience with Lambda diagnostic frameworks like Sentry.io or Datadog. \n Experience with test frameworks like Robot and JMeter. \n Experience in Azure, GCP, or hybrid cloud environments. \n \n Job Type: Full-time \n Pay: $150,000.00 - $170,000.00 per year \n Benefits: \n \n Dental insurance \n Health insurance \n Vision insurance \n \n Experience level: \n \n 10 years \n 11+ years \n 5 years \n 6 years \n 7 years \n 8 years \n 9 years \n \n Experience: \n \n Terraform: 3 years (Required) \n AWS: 3 years (Required) \n Python: 2 years (Required) \n \n Work Location: Remote",
        "cleaned_desc": "Title: Senior DevOps Engineer \n Location: Redwood City, CA (Remote) \n Type: Direct Hire \n Senior DevOps Engineer We are seeking a DevOps Engineer to accelerate production team engineering infrastructure build and stability through test automation and cloud-based DevOps practices. This key resource will help ZaiNar shift to a high volume, production support model while maintaining innovation in the R&D environment. Experience creating and sustaining multi-cloud and hybrid cloud production systems is required. We expect a proactive individual to propose and implementing industry best practices that enhance ZaiNar\u2019s competitive edge. This role works closely with SW and HW development teams. The successful candidate will be self-motivated and have the ability to proactively communicate and implement technical changes to support engineering strategy. \n JOB RESPONSIBILITIES \n \n Infrastructure as Code with AWS and Terraform. \n CI/CD pipeline design and implementation (GitHub/Actions, GitLab, and/or Jenkins). \n Design and manage quality gates and test automation. \n Identify and record bugs. \n Manage, monitor, troubleshoot, identify bottlenecks and system constraints in AWS production and development environments.   Provide Engineering and Executive management with real time information on operational performance and necessary documentation. \n \n MUST HAVE ATTRIBUTES/SKILLS \n \n Strong understanding of cloud-based computing, application design, and concepts including serverless, monitoring, auto-scaling, centralized logging with significant AWS experience. \n Experience in Infrastructure as Code via Terraform. \n Experience supporting production SaaS in a multi-account/multi-region AWS environment. \n Strong knowledge of Python or other scripting languages. Experience in other programming languages will be considered as a plus, for job automation and environment understanding. \n Strong experience managing Linux environments. \n Experience in a rapidly growing engineering startup environment. \n Experience with SonarCloud implementation or like best practices.   Fluency in English. \n \n SHOULD HAVE ATTRIBUTES/SKILLS \n \n BSc degree in Computer Science, Engineering, or a related subject. MSc a plus. \n Hands-on experience with Docker containers, and Kubernetes is a plus. \n Experience with supporting and scaling the majority of the following AWS Services: Lambda, DynamoDB, IAM, IoT Core, EKS, MSK, API Gateway, and Kinesis. \n Pip packaging, deployment automation, configuration management, and Debian packaging. \n Serverless and microservice architecture (and REST). \n Experience with Lambda diagnostic frameworks like Sentry.io or Datadog. \n Experience with test frameworks like Robot and JMeter. ",
        "techs": [
            "aws",
            "terraform",
            "github/actions",
            "gitlab",
            "jenkins",
            "python",
            "linux",
            "sonarcloud",
            "english",
            "docker",
            "kubernetes",
            "lambda",
            "dynamodb",
            "iam",
            "iot core",
            "eks",
            "msk",
            "api gateway",
            "kinesis",
            "pip",
            "debian",
            "serverless",
            "rest",
            "sentry.io",
            "datadog",
            "robot",
            "jmeter."
        ],
        "cleaned_techs": [
            "aws",
            "terraform",
            "github/actions",
            "gitlab",
            "jenkins",
            "python",
            "linux",
            "sonarcloud",
            "english",
            "docker",
            "kubernetes",
            "lambda",
            "dynamodb",
            "iam",
            "iot core",
            "eks",
            "msk",
            "api gateway",
            "kinesis",
            "pip",
            "debian",
            "serverless",
            "rest",
            "sentry.io",
            "datadog",
            "robot",
            "jmeter."
        ]
    },
    "9d7f8f5cc3975128": {
        "terms": [
            "mlops"
        ],
        "salary_min": 119302.945,
        "salary_max": 151064.11,
        "title": "Sr. DevOps Manager (Remote)",
        "company": "Patterson Dental Holdings, Inc.",
        "desc": "The Senior DevOps Manager is accountable for leading the DevOps and DevOps team within the Cloud Engineering - Technical Operations Group. Technical Operations is responsible for DevOps, DevSecOps and SRE. The Manager will report to the Director of Cloud Engineering \u2013 Technical Operations. The group will focus on practices and tools with a collaborative cultural philosophy to manage software development process. The team will work on automation and integrating processes between software development and supporting teams. In addition, the team will focus on the security of the entire software development process including integration of security best-practices early-on and throughout the entire software development life cycle. The Sr. DevOps/DevSecOps Manager works closely with internal and external customers and product teams to identify and maximize opportunities to promote the strategic use of technology solutions. Participates in the development of technical and development standards for product and system domain and enterprise. \n \n  Essential Functions \n  To perform this job successfully, an employee must be able to perform each essential function satisfactorily, with or without reasonable accommodation. To request a reasonable accommodation, notify Human Resources or the manager who oversees the position. \n \n  Leads team members to complete DevOps and DevSecOps related activities for products and systems; creates a high-performance culture driven by strategic objectives and goals of Patterson. \n  Hires, leads, and develops a diverse set of individuals operating as a collective team. \n  Develops team and individual goals and holds direct reports accountable for meeting performance standards and goals; measures staff performance and completes regular performance reviews and ranking \n  Partners with other leaders in software engineering to ensure quality and timely planning and delivery of products and systems across domains \n  Defines DevOps & DevSecOps strategy and objectives and establishes short-term and long-term metrics for department goals ensuring product quality throughout the software development life cycle \n  Introduces and adopts contemporary approaches to DevOps & DevSecOps practices, including automation for products and plans \n  Participates in annual budget development and financial management for the functional areas \n  Works closely with stakeholders and business leadership to ensure understanding of DevOps & DevSecOps practices, objectives, and metrics and to discover product priorities and requirements within and across domains \n  Maintains and builds knowledge of trends and technologies and their application within domain; partners with technical leaders to influence adoption of new technical techniques, processes and tools \n  Drives highest level support for incoming incidents from end users to resolve application and software issues. \n  For products under scope of regulatory quality management, ensures completion of quality related tasks within functional areas \n \n \n  A dditional Functions \n  In addition to the essential functions listed above, the incumbent may perform the following additional functions.  \n \n Provides input for annual budget development and financial management for the functional areas \n  Facilitates completion of product software development lifecycle documentation and controls \n  Provides regulatory approvals for quality management records for software medical device products \n  Serves as liaison with indirect sourcing to ensure timely purchases, renewals and contract SoW management \n \n \n  Required Qualifications \n \n  Bachelor's in Computer Science, Information Systems, a related field or equivalent work experience \n  7+ years\u2019 of Cloud, DevOps and production system security related experiences \n  At least 5 years\u2019 experience in team management \n  Experience in building and maintaining mainstream security systems on cloud platforms. \n  Solid experience and mindset on cloud-based security solution and architecture design and implementation \n  Define and govern DevOps and DevSecOps standards, processes and strategy that will be used across the Dental Software organization \n  Knowledge of DevOps thought leadership with mindset to lead new ways to use data \n  Familiarity with Terraform and Cloud Formation Templates \n  Knowledge of current DevOps, automation and test coverage strategic concepts and understanding of how multiple development technologies, languages and platforms are used to build software products \n  Experience in strategic planning, development, implementation, change management and maintenance of large-scale, integrated systems \n  Ability to interpret customer and business needs to help build technical plans for capability and value delivery \n  Proven ability to establish and drive strategic and tactical initiatives while providing conflict resolution when necessary \n  Ability to solve problems independently and collaborate as a team to solve complex problems \n  Demonstrated ability to lead, communicate and work in a collaborative and cross-functional team environment  \n Experience Building and maintaining GCP, AWS, or Azure infrastructure and services \n  Experience working in an Agile/Scrum environment and different automation and DevOps tools required to develop digital pipelines \n \n \n  Preferred Qualifications \n  Experience with corporate governance and developing business cases and return on investment analyses  \n Experience working with on regulated software products \n  Knowledge of Azure Cloud Platform \n \n  Office environment \u2013 either in Patterson facility or at home/remote location \n  Travel to corporate sites is periodically required (Quarterly or so) \n \n  Periodic on call rotations and available outside of normal business hours on evenings and weekends during critical production release or issue escalation periods \n \n  The duties of this role may be performed remotely in the following states: AK,AZ,CA,CO,CT,DC,HI,ID,IL,KS,KY,ME,MA,MI,MN,MO,NE,NV,NH,NM,NY,OR,RI,SD,TN,TX,UT,VT,WA,WV,WI \n \n  The potential compensation range for this role is below. The final offer amount would be based on various factors such as candidate location (geographical labor market), experience, and skills. \n  $180,000 - $200,000",
        "cleaned_desc": "  Serves as liaison with indirect sourcing to ensure timely purchases, renewals and contract SoW management \n \n \n  Required Qualifications \n \n  Bachelor's in Computer Science, Information Systems, a related field or equivalent work experience \n  7+ years\u2019 of Cloud, DevOps and production system security related experiences \n  At least 5 years\u2019 experience in team management \n  Experience in building and maintaining mainstream security systems on cloud platforms. \n  Solid experience and mindset on cloud-based security solution and architecture design and implementation \n  Define and govern DevOps and DevSecOps standards, processes and strategy that will be used across the Dental Software organization \n  Knowledge of DevOps thought leadership with mindset to lead new ways to use data    Familiarity with Terraform and Cloud Formation Templates \n  Knowledge of current DevOps, automation and test coverage strategic concepts and understanding of how multiple development technologies, languages and platforms are used to build software products \n  Experience in strategic planning, development, implementation, change management and maintenance of large-scale, integrated systems \n  Ability to interpret customer and business needs to help build technical plans for capability and value delivery \n  Proven ability to establish and drive strategic and tactical initiatives while providing conflict resolution when necessary \n  Ability to solve problems independently and collaborate as a team to solve complex problems \n  Demonstrated ability to lead, communicate and work in a collaborative and cross-functional team environment  \n Experience Building and maintaining GCP, AWS, or Azure infrastructure and services \n  Experience working in an Agile/Scrum environment and different automation and DevOps tools required to develop digital pipelines \n \n \n  Preferred Qualifications ",
        "techs": [
            "terraform",
            "cloud formation templates",
            "gcp",
            "aws",
            "azure",
            "agile/scrum",
            "automation",
            "devops"
        ],
        "cleaned_techs": [
            "terraform",
            "cloud formation templates",
            "gcp",
            "aws",
            "azure",
            "agile/scrum",
            "automation",
            "devops"
        ]
    },
    "c205187ecbbcbd88": {
        "terms": [
            "mlops"
        ],
        "salary_min": 111645.19,
        "salary_max": 141367.69,
        "title": "DevOps Engineer - Remote",
        "company": "SAP",
        "desc": "We help the world run better \n  Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. Apply now! \n \n  We are seeking an experienced DevOps Engineer to join our rapidly growing technology team. The successful candidate should have a minimum of 3-5 years of experience in a similar role and be proficient in managing cloud infrastructure and services, particularly in environments that use Git, Terraform, and Kubernetes. Knowledge in deploying SAP Ariba and familiarity with Kafka, Hadoop, and Cassandra are considered significant pluses. The candidate should be passionate about automation and have an understanding of software development and system administration. The individual in this role will work closely with our software engineering teams to design, automate, and optimize scalable systems, and will help solve complex system issues. \n \n  **Responsibilities:** \n \n  1. Develop, maintain, and improve our continuous integration/continuous delivery (CI/CD) pipeline using cloud services and automation tools. \n  2. Use Terraform for cloud resource provisioning and management. \n  3. Implement automated infrastructure capabilities like backups, security tools, monitoring. \n  4. Design and implement scalable cloud-based services to support our development teams. \n  5. Collaborate with developers to optimize the application development workflow. \n  6. Troubleshoot complex system issues and provide technical support to the team. \n  7. Implement industry best practices for system hardening and configuration management. \n  8. Deploy and manage containerized applications using Kubernetes. \n  9. If necessary, deploy and maintain SAP Ariba in cloud environments. \n  10. Stay current with industry trends, making recommendations as needed to help the company excel. \n \n  **Requirements:** \n \n  1. Bachelor's degree in Computer Science, Information Technology, or a related field or equivalent work experience. \n  2. 3-5 years of experience as a DevOps Engineer or similar software engineering role. \n  3. Proficiency with Git, Terraform, Kubernetes, and other infrastructure automation toolsets. \n  4. Experience with cloud services (e.g., AWS, Google Cloud, Azure) and understanding of their offerings. \n  5. Experience in network, server, and application-status monitoring. \n  6. Strong command of software-automation production systems. \n  7. Excellent problem-solving and troubleshooting skills. \n  8. Understanding of scalable computing systems. \n  9. Strong communication skills and ability to explain protocol and processes with team and management. \n \n  **Nice to Have:** \n \n  1. Experience with deploying and maintaining SAP Ariba. \n  2. Knowledge of distributed data processing systems such as Kafka, Hadoop, Cassandra. \n  3. Certification in AWS, Google Cloud, or Azure. \n  4. Knowledge of scripting languages such as Python, Bash. \n \n  At our company, we value diversity and always treat all employees and job applicants based on merit, qualifications, competence, and talent. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. \n \n  We build breakthroughs together \n \n  SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together. \n  We win with inclusion \n  SAP\u2019s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone \u2013 regardless of background \u2013 feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.  SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com.  For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training. \n  EOE AA M/F/Vet/Disability \n  Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability. \n  Compensation Range Transparency : SAP believes the value of pay transparency contributes towards an honest and supportive culture and is a significant step toward demonstrating SAP\u2019s commitment to pay equity. SAP provides the annualized compensation range inclusive of base salary and variable incentive target for the career level applicable to the posted role. The targeted combined range for this position is $81,700 - $174,800 USD. The actual amount to be offered to the successful candidate will be within that range, dependent upon the key aspects of each case which may include education, skills, experience, scope of the role, location, etc. as determined through the selection process. Any SAP variable incentive includes a targeted dollar amount and any actual payout amount is dependent on company and personal performance. Please reference this link for a summary of SAP benefits and eligibility requirements: SAP North America Benefits. \n  Requisition ID: 374581 | Work Area: Software-Development Operations | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: Virtual - USA #LI-Hybrid",
        "cleaned_desc": "  3. Implement automated infrastructure capabilities like backups, security tools, monitoring. \n  4. Design and implement scalable cloud-based services to support our development teams. \n  5. Collaborate with developers to optimize the application development workflow. \n  6. Troubleshoot complex system issues and provide technical support to the team. \n  7. Implement industry best practices for system hardening and configuration management. \n  8. Deploy and manage containerized applications using Kubernetes. \n  9. If necessary, deploy and maintain SAP Ariba in cloud environments. \n  10. Stay current with industry trends, making recommendations as needed to help the company excel. \n    **Requirements:** \n \n  1. Bachelor's degree in Computer Science, Information Technology, or a related field or equivalent work experience. \n  2. 3-5 years of experience as a DevOps Engineer or similar software engineering role. \n  3. Proficiency with Git, Terraform, Kubernetes, and other infrastructure automation toolsets. \n  4. Experience with cloud services (e.g., AWS, Google Cloud, Azure) and understanding of their offerings. \n  5. Experience in network, server, and application-status monitoring. \n  6. Strong command of software-automation production systems. \n  7. Excellent problem-solving and troubleshooting skills.    8. Understanding of scalable computing systems. \n  9. Strong communication skills and ability to explain protocol and processes with team and management. \n \n  **Nice to Have:** \n \n  1. Experience with deploying and maintaining SAP Ariba. \n  2. Knowledge of distributed data processing systems such as Kafka, Hadoop, Cassandra. \n  3. Certification in AWS, Google Cloud, or Azure. \n  4. Knowledge of scripting languages such as Python, Bash. ",
        "techs": [
            "backups",
            "security tools",
            "monitoring",
            "cloud-based services",
            "development teams",
            "application development workflow",
            "system issues",
            "technical support",
            "system hardening",
            "configuration management",
            "containerized applications",
            "kubernetes",
            "sap ariba",
            "git",
            "terraform",
            "cloud services (e.g.",
            "aws",
            "google cloud",
            "azure)",
            "network monitoring",
            "server monitoring",
            "application-status monitoring",
            "software-automation production systems",
            "scalable computing systems",
            "communication skills",
            "protocol",
            "deploying and maintaining sap ariba",
            "distributed data processing systems (kafka",
            "hadoop",
            "cassandra)",
            "aws certification",
            "google cloud certification",
            "azure certification",
            "scripting languages (python",
            "bash)"
        ],
        "cleaned_techs": [
            "backups",
            "monitoring",
            "cloud-based services",
            "development teams",
            "application development workflow",
            "system issues",
            "technical support",
            "system hardening",
            "configuration management",
            "kubernetes",
            "sap ariba",
            "git",
            "terraform",
            "cloud services (e.g.",
            "aws",
            "gcp",
            "azure",
            "network monitoring",
            "server monitoring",
            "application-status monitoring",
            "software-automation production systems",
            "scalable computing systems",
            "protocol",
            "deploying and maintaining sap ariba",
            "distributed data processing systems (kafka",
            "hadoop",
            "cassandra)",
            "scripting languages (python",
            "bash)"
        ]
    },
    "fc12a15739a310af": {
        "terms": [
            "mlops"
        ],
        "salary_min": 111987.64,
        "salary_max": 141801.31,
        "title": "Sr DevOps Engineer System Admin",
        "company": "Lucid Technologies Inc",
        "desc": "Job Title: Sr DevOps Engineer/System Admin \n  \n \n  Location: Remote\n  \n \n \n  Summary:\n  \n \n   Under general direction, responsible for effectively tracking, logging, categorizing, and maintaining changes made against the accepted Clients baseline(s) standards. Develops, distributes, and tracks all change packages resulting from approved Configuration Control Board action. Trains personnel by conducting workshops and seminars on the proper methodology to maintain a proactive CM program. Provides daily support and direction to staff as to change status requirements, deadlines, and problems. Responsible for the effective development and implementation of programs to ensure that all information systems products and services meet minimum Clients standards and end-user requirements. Administers the change control process for zero defects software development. Responsible for configuration management of requirements, design, and code. Evaluates and selects configuration management tools and standards. Prepares configuration management plans and procedures. Administers problem management process including monitoring and reporting on problem resolution. Ensures adequate product testing prior to implementation. Coordinates with users and systems development personnel on releases of software. Verifies the completeness and accuracy of release libraries before implementation and ensures that correct versions of programs are included in specified releases. Makes recommendations to superiors regarding the acquisition and/or implementation of software to increase information systems efficiency, configuration management activities including product identification, change control, status accounting, operation of the program support library, and development and monitoring of equipment/system acceptance plans. Operates and manages program support library. Monitors library structure and procedures to assure system integrity, including procedures for collection, release, production, test, and emergency libraries and the movement/migration of components between libraries. Monitors end-item acceptance plans. Typically performs all functional duties independently.\n  \n \n \n  Job Responsibilities:\n  \n \n   Experience in DevOps Engineering, team management, and collaboration\n  \n \n   Experience in DevOps using test automation and CI/CD tools, containers, cloud infrastructure, and other modern technologies, CI/CD pipeline set up from scratch as DevOps lead\n  \n \n   Experience with service-oriented architectures and microservices; deploying resilient, scalable, high-throughput systems.\n  \n \n   Experience in developing and maintaining CI/CD processes for enterprise SaaS and on-prem applications using tools like GitHub, Jenkins, Maven, Gradle, GitLabs etc.\n  \n \n   Knowledge of IT infrastructure security protocols\n  \n \n   Experience with configuration management tools like Ansible\n  \n \n   Advanced knowledge of programming languages such as Python and Java and writing code and scripts.\n  \n \n   Hands-on experience in building and administering VMs and Containers using tools such as Docker / Kubernetes.\n  \n \n   Familiarity with logging and monitoring technologies\n  \n \n   Ability to install and configure software, gather test-stage data, and perform de-bugging.\n  \n \n   Proficiency in documenting processes and monitoring performance metrics.\n  \n \n   Advanced knowledge of best practices related to data encryption and cybersecurity.\n  \n \n   Strong hardware/software troubleshooting skills\n  \n \n   Strong networking knowledge and experience is highly desired.\n  \n \n   Develop / Maintain Documentation on operational, configuration, or other procedures.\n  \n \n   Ability to oversee and mentor junior software developers, as well as report to management\n  \n \n   Must be able to work independently and self-directed, as well as, within a team.\n  \n \n   Experience working in a separation of duties environment and providing instructions/guidance to separate Systems Admins\n  \n \n \n  Education/Experience:\n  \n \n   A minimum of ten (10) yearsand#39; experience in software development, configuration/data management, and/or related field;\n  \n \n   A degree from an accredited College/University in Software Engineering, Computer Science, or related discipline is preferred;\n  \n \n   Able to perform all functional duties independently on high-visibility programs, or mission critical aspects of a given program;\n  \n \n   Able to oversee the efforts of direct reporting resources and/or be responsible for the efforts of all staff assigned to a specific job;\n  \n \n   Experience training/mentoring less experienced personnel;\n  \n \n   Extensive experience in configuration management, specifically in the areas of configuration identification, configuration status accounting, change management (including change verification/testing) and version control of documentation and software code;\n  \n \n   Able to define/document configuration management standards and prepare configuration management plans and procedures;\n  \n \n   Able to train personnel about proper CM disciplines/procedures by conducting workshops and seminars;\n  \n \n   Extensive experience with more than one configuration management tool (e.g. Rational Jazz, Star Team, PVCS, Subversion) and with configuration management standards;\n  \n \n   Able to evaluate competing configuration management tools/standards and select the best for a given problem domain;\n  \n \n   Extensive experience with release management, including coordination with users and development personnel and verification of release content;\n  \n \n   Able to recommend acquisition and/or implementation of system software to increase system efficiency;\n  \n \n   Extensive experience with program support library operation/management, and development and monitoring of equipment/system acceptance plans;\n  \n \n   Able to obtain Postal clearance;\n  \n \n   Excellent communication skills.\n  \n \n \n  Additional Provisions:\n  \n \n   Must be able to obtain a Position of Public Trust Clearance Pass both a client mandated clearance process to include drug screening, criminal history check and credit check.\n  \n \n   Once candidates resume is approved and interview passed, the agency is responsible for providing drug screening. Failure to submit the drug screening results will delay the security clearance process.\n  \n \n   If a candidate is given an interim clearance, continuation of employment is then based on the candidate receiving a sensitive clearance.\n  \n \n   All candidates must be a US Citizen, or have permanent residence status (Green Card).\n  \n \n   Candidate must have lived in the United States for the past 5 years.\n  \n \n   Cannot have more than 6 months travel outside the United States within the last five years. Military Service excluded. (Exception does not include military family members.) All overtime must be pre-approved in writing by the client manager or his/her designated representative.\n  \n \n   Agency will not be reimbursed for overtime charges without previous written authorization. Authorized overtime will be reimbursed at straight time.\n  \n \n \n  Thanks and Regards, \n Chandrasekhar Kandi \n Lead Recruiter   Lucid Technologies Inc \n O:214-385-4144 EXT:204 \n F: 214-889-5857 \n W: www.LucidTechINC.com \n Supplier Registration: https://lucidtechinc.com/supplierregistration",
        "cleaned_desc": "  \n \n   Experience with configuration management tools like Ansible\n  \n \n   Advanced knowledge of programming languages such as Python and Java and writing code and scripts.\n  \n \n   Hands-on experience in building and administering VMs and Containers using tools such as Docker / Kubernetes.\n  \n \n   Familiarity with logging and monitoring technologies\n  \n \n   Ability to install and configure software, gather test-stage data, and perform de-bugging.\n  \n \n   Proficiency in documenting processes and monitoring performance metrics.\n  \n \n   Advanced knowledge of best practices related to data encryption and cybersecurity.\n  \n \n   Strong hardware/software troubleshooting skills\n  \n \n   Strong networking knowledge and experience is highly desired.\n  \n \n   Develop / Maintain Documentation on operational, configuration, or other procedures.   \n \n   Ability to oversee and mentor junior software developers, as well as report to management\n  \n \n   Must be able to work independently and self-directed, as well as, within a team.\n  \n \n   Experience working in a separation of duties environment and providing instructions/guidance to separate Systems Admins\n  \n \n \n  Education/Experience:\n  \n \n   A minimum of ten (10) yearsand#39; experience in software development, configuration/data management, and/or related field;\n  \n \n   A degree from an accredited College/University in Software Engineering, Computer Science, or related discipline is preferred;\n  \n \n   Able to perform all functional duties independently on high-visibility programs, or mission critical aspects of a given program;\n  \n \n   Able to oversee the efforts of direct reporting resources and/or be responsible for the efforts of all staff assigned to a specific job;\n  \n \n   Experience training/mentoring less experienced personnel;\n  \n ",
        "techs": [
            "ansible",
            "python",
            "java",
            "docker",
            "kubernetes",
            "logging and monitoring technologies",
            "data encryption",
            "cybersecurity",
            "hardware/software troubleshooting",
            "networking knowledge",
            "documentation",
            "mentoring",
            "separation of duties",
            "software development",
            "configuration/data management",
            "software engineering",
            "computer science",
            "training/mentoring"
        ],
        "cleaned_techs": [
            "ansible",
            "python",
            "java",
            "docker",
            "kubernetes",
            "logging and monitoring technologies",
            "data encryption",
            "cybersecurity",
            "hardware/software troubleshooting",
            "networking knowledge",
            "mentoring",
            "separation of duties",
            "software development",
            "configuration/data management",
            "software engineering",
            "computer science",
            "training/mentoring"
        ]
    },
    "48bbea01ed484d9c": {
        "terms": [
            "mlops"
        ],
        "salary_min": null,
        "salary_max": null,
        "title": "Mentor, DevOps (SDA Program, Live Online)",
        "company": "Fullstack Academy",
        "desc": "Fullstack Academy is a top-ranked immersive school for technology skills training. Fullstack prepares students with the in-demand skills they need to launch fulfilling tech careers. \n  ABOUT THE ROLE \n  Fullstack Academy Mentors scale their impact as a DevOps professionals by training the next generation of DevOps Engineers. In this role, you will support students through exercises designed to build knowledge and skills and promote grit, problem-solving and a collaborative learning community. Ultimately, you will prepare students for the next chapter in their lives as they seek employment in the DevOps field. \n  Fullstack Academy is excited to extend our mission internationally through a partnership with a local education provider in Saudi Arabia. The partnership in Saudi Arabia, part of Saudi Vision 2030, aims to develop human capital and the digital capabilities of Saudi university graduates. In response to Saudi tech employers calling for more practically prepared talent, Fullstack Academy is going to provide the much needed training via our bootcamp model.  \n LOGISTICS \n  This is a contract role for approximately 15 weeks and requires an ability to support students and instructors in live classes from 9:00 a.m. - 5:00 p.m. Riyadh Time Sunday through Thursday in a synchronous online class experience. The exact dates noted below are subject to change. \n  The contract spans 15 weeks: \n \n Mentor on-boarding to Fullstack Academy for two weeks in the middle of December. This training requires work from 9am - 5pm on Central Standard Time. \n Additional training and preparation January 10-13  \n 3 days cohort preparation and student orientation January 14-16 \n 12 weeks of bootcamp instruction on location from January 17- April 9, 2024 \n Classes meet from Sunday-Thursday 9:00am - 5:00 pm Riyadh Time \n Classes will be taught in English - knowledge of Arabic is not required \n The teaching team will consist of instructors and mentors (teaching assistants) \n US holidays that fall during the bootcamp will not be recognized \n Saudi Arabia holidays that fall during the bootcamp will be recognized \n \n This role reports to a Program Manager and is supported by a collaborative academics team at Fullstack Academy and a team with the local Saudi partner to ensure an exceptional experience for each student in the cohort.  \n MENTOR RESPONSIBILITIES \n  In this role, you will create a positive class experience by: \n \n Promoting student progress during class worktime by supporting development of both competence and confidence \n Leveraging tech tools and connecting content to the real world by sharing industry insights and professional experiences \n Providing constructive and timely feedback to students in the cohort, escalating concerns in a timely manner to the support teams \n Providing individualized student support during synchronous class sessions and outside class synchronously during office hours and asynchronously through timely communication \n Exhibiting professionalism and an ethical and empathetic approach when engaging with Fullstack staff, students, and the public \n \n QUALIFICATIONS \n  Eligibility requires the following: \n \n Minimum one or more of the following\n    \n A minimum one year of experience as a DevOps engineer \n Have prior experience teaching or mentoring in an informal capacity \n AND have one or more AWS certifications, especially:\n      \n AWS Certified Cloud Foundations \n AWS Certified Solutions Architect - Associate \n AWS Certified Developer - Associate \n AWS Certified SysOps Administrator - Associate \n \n \n Preferential consideration will be given to candidates with the following experience:\n    \n Bachelor\u2019s Degree in Computer Science, Information Technology, or related field such as DevOps or Cloud Computing  \n A minimum of three years of professional experience in a DevOps role  \n AND prior experience teaching or mentoring in a formal capacity \n \n \n COMPENSATION PACKAGE \n  Contract includes compensation for: onboarding and on-site instruction and a generous bonus.",
        "cleaned_desc": " AWS Certified SysOps Administrator - Associate \n \n \n Preferential consideration will be given to candidates with the following experience:\n    \n Bachelor\u2019s Degree in Computer Science, Information Technology, or related field such as DevOps or Cloud Computing  \n A minimum of three years of professional experience in a DevOps role  \n AND prior experience teaching or mentoring in a formal capacity \n \n ",
        "techs": [
            "aws certified sysops administrator - associate"
        ],
        "cleaned_techs": [
            "aws"
        ]
    },
    "42d5fdcb0726ec90": {
        "terms": [
            "mlops"
        ],
        "salary_min": 80000.0,
        "salary_max": 140000.0,
        "title": "Senior DevOps Engineer",
        "company": "Madwire",
        "desc": "This is a US-based position, our offices are located in Fort Collins, CO. This position can be in-office, remote* (in approved US states), or a hybrid of the two. \n  Who you are \n \n You are an expert troubleshooter and powerful builder. \n You are an infrastructure aficionado. \n You are motivated to get the job done and done excellently. Execution Excellence is our standard and our standard is non negotiable. \n You are a passionate human: passionate about making a difference in the world, passionate about helping teammates succeed. \n You are thorough in your work. \n You are curious and ready to learn. Like the clients we represent, our teammates are entrepreneurs. The most successful people at Madwire are those willing to put in the time it takes to become an expert for small business digital marketing. \n You comfortably navigate between tasks, willing to learn, and teach others. \n \n Position Summary \n \n  DevOps engineers are vital to Madwire\u2019s mission because they are responsible for the stability and reliability of our software products. \n \n  Primary Responsibilities \n \n Help maintain the infrastructure for Marketing 360, the #1 marketing platform \n Improve the developer experience through automation, tooling, and support \n Assist in developing and deploying a GitOps-based continuous delivery system \n Work with the team to deploy performant, scalable and secure software services \n Debug and monitor existing services and help resolve problems. \n \n Supervisory Responsibility \n \n  No supervisory responsibilities \n \n  Travel \n \n  Occasional travel may be required, but is not a significant part of the job. \n \n  Requirements \n \n 4+ yrs professional experience as a DevOps engineer (or similar) managing Kubernetes, on Google Cloud Platform and/or AWS \n Working knowledge of Git, continuous integration, and continuous deployment, preferably with ArgoCD \n Ability to work in a team environment within a fast-paced product team \n \n Preferred Education/Experience \n \n Experience with delivery of a SaaS product \n Understanding of micro-services and related architectures \n Working understanding of firewalls, security groups, and networking \n Development experience, ideally with Go \n Working knowledge of relational and / NoSQL databases \n \n Benefits \n  This position offers a competitive salary, great health benefits, 401(k), and a great work environment. \n  Salary Range \n  $80,000 - $140,000 annual \n  Employee Health Benefits \n \n  Employees are eligible to enroll in benefit plans effective day one. \n \n  401(k) \n \n \n Eligibility to enter the plan is the first of the month following 60 days of employment. \n Madwire matches 50% up to 6% of employee contributions effective after one year of employment. \n \n Paid Time Off \n \n \n 10 paid holidays per year \n Unlimited vacation that starts on day 1 \n 5 sick days annually \n \n Approved States* \n  We are currently hiring in the following states: AK, AZ, AR, CO, FL, GA, HI, IN, IA, KS, KY, LA, MD, MI, MN, MS, MO, MT, NE, NJ, NM, NC, ND, OH, OK, OR, PA, RI, SC, SD, TN, TX, UT, VT, VA, WV, WI, WY. Please note that it may take up to 2 months to authorize work in some states. Please let the hiring manager know what state you live in so we can plan accordingly. \n  About  Madwire \n  We specialize in \u201cMarketing and Design,\u201d we call it \u201cMad.\u201d It\u2019s in our blood. Our manifesto. Our calling. We love Mad\u2122. We are a world-class digital marketing company, growing small- and medium-sized businesses through a single, powerful platform. We provide technology and talent, with Marketing 360 as our powerful software backed by the professional marketing services that the team at Madwire has to offer. We are a collaborative group, and everyone has some kind of talent that fits into our greater puzzle. \n \n We are an Inc 5000 Fastest Growing Company in America for six years straight. \n We are rated the #1 Best Place to Work by Glassdoor (2016). \n Joe Kellogg and JB Kellogg have been rated the top CEOs by Glassdoor for three years straight. \n We\u2019re ranked in the Top 50 Family-Owned Colorado Companies for six years straight. \n We are a Top 10 Marketing Company by Inc 500 (2014). \n We ranked #2 on Entrepreneur 360 (2017). \n \n Company Culture \n  At Madwire, we believe in attracting the absolute best individuals in their field. For the past ten years we have offered a dynamic working environment full of compassion, energy, and a whole lot of fun. Our current employees enjoy a collaborative, supportive, and dynamic working environment. We go hard because our customers demand that we put out the best possible products. On the other hand, we definitely know how to have fun. Hard work, an amazing culture, engaging technology, helping small business succeed, what could be better? \n  We Don\u2019t Discriminate \n  Madwire is an equal opportunity employer and complies with all applicable federal, state and local fair employment practice laws. Madwire strictly prohibits and does not tolerate discrimination against employees, applicants or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex, gender (including gender nonconformity and status as a transgender or transsexual individual), age, physical or mental disability, citizenship, past, current or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state or local law. All Madwire employees, other workers and representatives are prohibited from engaging in unlawful discrimination. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, training, promotion, discipline, compensation, benefits and termination of employment. \n  Madwire complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Madwire will reasonably accommodate qualified individuals with a disability, if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. \n  Other Duties \n  Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.",
        "cleaned_desc": " \n 4+ yrs professional experience as a DevOps engineer (or similar) managing Kubernetes, on Google Cloud Platform and/or AWS \n Working knowledge of Git, continuous integration, and continuous deployment, preferably with ArgoCD \n Ability to work in a team environment within a fast-paced product team \n \n Preferred Education/Experience \n \n Experience with delivery of a SaaS product \n Understanding of micro-services and related architectures \n Working understanding of firewalls, security groups, and networking \n Development experience, ideally with Go \n Working knowledge of relational and / NoSQL databases \n \n Benefits \n  This position offers a competitive salary, great health benefits, 401(k), and a great work environment. \n  Salary Range ",
        "techs": [
            "kubernetes",
            "google cloud platform",
            "aws",
            "git",
            "continuous integration",
            "continuous deployment",
            "argocd",
            "saas product delivery",
            "micro-services",
            "firewalls",
            "security groups",
            "networking",
            "go development",
            "relational databases",
            "nosql databases"
        ],
        "cleaned_techs": [
            "kubernetes",
            "gcp",
            "aws",
            "git",
            "continuous integration",
            "continuous deployment",
            "argocd",
            "saas product delivery",
            "micro-services",
            "firewalls",
            "networking",
            "go development",
            "relational databases",
            "nosql"
        ]
    },
    "6ae4f32fc6446655": {
        "terms": [
            "mlops"
        ],
        "salary_min": 118935.03,
        "salary_max": 150598.25,
        "title": "Senior Salesforce DevOps Engineer",
        "company": "Octo",
        "desc": "Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes. \n  Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region\u2019s best places to work multiple times, Octo is an employer of choice! \n \n You... \n  As a  Senior Salesforce DevOps Engineer  at Octo, you will be responsible for supporting multiple delivery projects for the Department of Veterans Affairs. This role will be responsible for supporting and providing continuous delivery with high software quality. \n  Us... \n  We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client\u2019s missions. \n  Program Mission... \n  The Digital Transformation Center (DTC) supports Veterans Affairs (VA) with onboarding and maintaining enterprise SaaS and PaaS solutions used to support the mission of serving our Veterans and their associated stakeholders. We are digitizing information and processes for improved implementation, leveraging modern tools and low code/no code for reusability and faster delivery. \n \n   \n \n \n Octo is an Equal Opportunity/Affirmative Action employer. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation. \n  Octo is an IBM subsidiary which has been acquired by IBM and will be integrated into the IBM organization. Octo will be the hiring entity. By proceeding with this application, you understand that Octo will share your personal information with other IBM affiliates involved in your recruitment process, wherever these are located. More Information on how IBM protects your personal information, including the safeguards in case of cross-border data transfer, are available here:   https://www.ibm.com/careers/us-en/privacy-policy/ \u201d. \n \n \n \n Requirements... \n \n Support the refinement of processes related to continuous delivery of Salesforce products by defining and developing automation of Salesforce releases \n Create, extend, and maintain both code and configuration of Salesforce continuous integration solutions and functionality. \n Partner with development teams to ensure agile software delivery and DevOps practices are applied \n Deploy code changes in different environments for testing and production environments through Github and/or Copado \n Collaboration in code reviews, agile ceremonies like retrospectives, daily standups, and sprint planning, pair programming, and MVP strategy and operations \n Coordinate with program and project leaders to analyze technologies being utilized on the projects. \n Maintain the integrity of services integrated with our cloud environments, including proprietary in-house systems and external integrations. \n Bachelor\u2019s Degree in Computer Science, Engineering or other technical discipline required, OR a minimum of 8 years equivalent work experience. \n 5+ years working with Salesforce development and/or DevOps/release management with an understanding of CI/CD processes, integration concepts \n Troubleshooting errors associated with package deployments, scratch org creation, and Salesforce DX CLI \n Experience in Salesforce APIs, Metadata, SOQL, and SOSL \n Fluency with scripting and tooling with one of the following: Python, Bash Scripting, Salesforce DX, Linux Command Line, Salesforce CLI, Kubernetes, Docker, AWS, Salesforce Apex \n Must be able to use a computer. \n Must be able to communicate both verbally and in written form. \n Must be able to obtain a government security clearance. \n Must be eligible to work in the United States. \n Must have reliable internet service that allows for effective telecommuting. \n \n \n Desired Skills: \n \n Experience with Github Actions \n Pester testing and mocking framework \n Experience in Quality Assurance Automation \n Salesforce packaging 2.0 \n \n Years of Experience:  5+ years of relevant experience. \n  Education:  Bachelor\u2019s Degree in Computer Science, Engineering or other technical discipline required, OR a minimum of 8 years equivalent work experience. \n  Location:  Remote within the United States. \n  Clearance:  Ability to obtain government clearance.",
        "cleaned_desc": " Requirements... \n \n Support the refinement of processes related to continuous delivery of Salesforce products by defining and developing automation of Salesforce releases \n Create, extend, and maintain both code and configuration of Salesforce continuous integration solutions and functionality. \n Partner with development teams to ensure agile software delivery and DevOps practices are applied \n Deploy code changes in different environments for testing and production environments through Github and/or Copado \n Collaboration in code reviews, agile ceremonies like retrospectives, daily standups, and sprint planning, pair programming, and MVP strategy and operations \n Coordinate with program and project leaders to analyze technologies being utilized on the projects. \n Maintain the integrity of services integrated with our cloud environments, including proprietary in-house systems and external integrations.   Bachelor\u2019s Degree in Computer Science, Engineering or other technical discipline required, OR a minimum of 8 years equivalent work experience. \n 5+ years working with Salesforce development and/or DevOps/release management with an understanding of CI/CD processes, integration concepts \n Troubleshooting errors associated with package deployments, scratch org creation, and Salesforce DX CLI \n Experience in Salesforce APIs, Metadata, SOQL, and SOSL \n Fluency with scripting and tooling with one of the following: Python, Bash Scripting, Salesforce DX, Linux Command Line, Salesforce CLI, Kubernetes, Docker, AWS, Salesforce Apex \n Must be able to use a computer. \n Must be able to communicate both verbally and in written form. \n Must be able to obtain a government security clearance. \n Must be eligible to work in the United States. ",
        "techs": [
            "github",
            "copado",
            "salesforce dx cli",
            "salesforce apis",
            "metadata",
            "soql",
            "sosl",
            "python",
            "bash scripting",
            "linux command line",
            "salesforce cli",
            "kubernetes",
            "docker",
            "aws",
            "salesforce apex"
        ],
        "cleaned_techs": [
            "github",
            "copado",
            "salesforce dx cli",
            "salesforce apis",
            "metadata",
            "soql",
            "sosl",
            "python",
            "bash scripting",
            "linux command line",
            "salesforce cli",
            "kubernetes",
            "docker",
            "aws",
            "salesforce apex"
        ]
    },
    "5c36b2f7e6d82ff0": {
        "terms": [
            "mlops"
        ],
        "salary_min": 80000.0,
        "salary_max": 120000.0,
        "title": "DevOps Engineer 2",
        "company": "Madwire",
        "desc": "This is a US-based position, our offices are located in Fort Collins, CO. This position can be in-office, remote* (in approved US states), or a hybrid of the two. \n  Who you are \n \n You are an expert troubleshooter and powerful builder. \n You are an infrastructure aficionado. \n You are motivated to get the job done and done excellently. Execution Excellence is our standard and our standard is non negotiable. \n You are a passionate human: passionate about making a difference in the world, passionate about helping teammates succeed. \n You are thorough in your work. \n You are curious and ready to learn. Like the clients we represent, our teammates are entrepreneurs. The most successful people at Madwire are those willing to put in the time it takes to become an expert for small business digital marketing. \n You comfortably navigate between tasks, willing to learn, and teach others. \n \n Position Summary \n \n  DevOps engineers are vital to Madwire\u2019s mission because they are responsible for the stability and reliability of our software products. \n \n  Primary Responsibilities \n \n Help maintain the infrastructure for Marketing 360, the #1 marketing platform \n Improve the developer experience through automation, tooling, and support \n Assist in developing and deploying a GitOps-based continuous delivery system \n Work with the team to deploy performant, scalable and secure software services \n Debug and monitor existing services and help resolve problems. \n \n Supervisory Responsibility \n \n  No supervisory responsibilities \n \n  Travel \n \n  Occasional travel may be required, but is not a significant part of the job. \n \n  Requirements \n \n 2+ yrs professional experience as a DevOps engineer (or similar) managing Kubernetes, on Google Cloud Platform and/or AWS \n Working knowledge of Git, continuous integration, and continuous deployment, preferably with ArgoCD \n Ability to work in a team environment within a fast-paced product team \n \n Preferred Education/Experience \n \n Experience with delivery of a SaaS product \n Understanding of micro-services and related architectures \n Working understanding of firewalls, security groups, and networking \n Development experience, ideally with Go \n Working knowledge of relational and / NoSQL databases \n \n Benefits \n  This position offers a competitive salary, great health benefits, 401(k), and a great work environment. \n  Salary Range \n  $80,000 - $140,000 annual \n  Employee Health Benefits \n \n  Employees are eligible to enroll in benefit plans effective day one. \n \n  401(k) \n \n \n Eligibility to enter the plan is the first of the month following 60 days of employment. \n Madwire matches 50% up to 6% of employee contributions effective after one year of employment. \n \n Paid Time Off \n \n \n 10 paid holidays per year \n Unlimited vacation that starts on day 1 \n 5 sick days annually \n \n Approved States* \n  We are currently hiring in the following states: AK, AZ, AR, CO, FL, GA, HI, IN, IA, KS, KY, LA, MD, MI, MN, MS, MO, MT, NE, NJ, NM, NC, ND, OH, OK, OR, PA, RI, SC, SD, TN, TX, UT, VT, VA, WV, WI, WY. Please note that it may take up to 2 months to authorize work in some states. Please let the hiring manager know what state you live in so we can plan accordingly. \n  About  Madwire \n  We specialize in \u201cMarketing and Design,\u201d we call it \u201cMad.\u201d It\u2019s in our blood. Our manifesto. Our calling. We love Mad\u2122. We are a world-class digital marketing company, growing small- and medium-sized businesses through a single, powerful platform. We provide technology and talent, with Marketing 360 as our powerful software backed by the professional marketing services that the team at Madwire has to offer. We are a collaborative group, and everyone has some kind of talent that fits into our greater puzzle. \n \n We are an Inc 5000 Fastest Growing Company in America for six years straight. \n We are rated the #1 Best Place to Work by Glassdoor (2016). \n Joe Kellogg and JB Kellogg have been rated the top CEOs by Glassdoor for three years straight. \n We\u2019re ranked in the Top 50 Family-Owned Colorado Companies for six years straight. \n We are a Top 10 Marketing Company by Inc 500 (2014). \n We ranked #2 on Entrepreneur 360 (2017). \n \n Company Culture \n  At Madwire, we believe in attracting the absolute best individuals in their field. For the past ten years we have offered a dynamic working environment full of compassion, energy, and a whole lot of fun. Our current employees enjoy a collaborative, supportive, and dynamic working environment. We go hard because our customers demand that we put out the best possible products. On the other hand, we definitely know how to have fun. Hard work, an amazing culture, engaging technology, helping small business succeed, what could be better? \n  We Don\u2019t Discriminate \n  Madwire is an equal opportunity employer and complies with all applicable federal, state and local fair employment practice laws. Madwire strictly prohibits and does not tolerate discrimination against employees, applicants or any other covered persons because of race, color, religion, creed, national origin or ancestry, ethnicity, sex, gender (including gender nonconformity and status as a transgender or transsexual individual), age, physical or mental disability, citizenship, past, current or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state or local law. All Madwire employees, other workers and representatives are prohibited from engaging in unlawful discrimination. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, training, promotion, discipline, compensation, benefits and termination of employment. \n  Madwire complies with the Americans with Disabilities Act (ADA), as amended by the ADA Amendments Act, and all applicable state or local law. Consistent with those requirements, Madwire will reasonably accommodate qualified individuals with a disability, if such accommodation would allow the individual to perform the essential functions of the job, unless doing so would create an undue hardship. \n  Other Duties \n  Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.",
        "cleaned_desc": " \n 2+ yrs professional experience as a DevOps engineer (or similar) managing Kubernetes, on Google Cloud Platform and/or AWS \n Working knowledge of Git, continuous integration, and continuous deployment, preferably with ArgoCD \n Ability to work in a team environment within a fast-paced product team \n \n Preferred Education/Experience \n \n Experience with delivery of a SaaS product \n Understanding of micro-services and related architectures \n Working understanding of firewalls, security groups, and networking \n Development experience, ideally with Go \n Working knowledge of relational and / NoSQL databases \n \n Benefits \n  This position offers a competitive salary, great health benefits, 401(k), and a great work environment. \n  Salary Range ",
        "techs": [
            "kubernetes",
            "google cloud platform",
            "aws",
            "git",
            "continuous integration",
            "continuous deployment",
            "argocd",
            "saas",
            "micro-services",
            "firewalls",
            "security groups",
            "networking",
            "go",
            "relational databases",
            "nosql databases"
        ],
        "cleaned_techs": [
            "kubernetes",
            "gcp",
            "aws",
            "git",
            "continuous integration",
            "continuous deployment",
            "argocd",
            "saas",
            "micro-services",
            "firewalls",
            "networking",
            "go",
            "relational databases",
            "nosql"
        ]
    },
    "da77eb019ceafe2c": {
        "terms": [
            "mlops"
        ],
        "salary_min": 100000.0,
        "salary_max": 135000.0,
        "title": "REMOTE- Mid-Level DevOps Engineer (BP)",
        "company": "Sigma Defense [SOLUTE]",
        "desc": "Sigma Defense Systems  is a leading technology company serving the Department of Defense (DoD), providing tactical communications systems and services for digital modernization since 2006. Through our acquisitions of SOLUTE in January 2022 and Sub U Systems in May 2022, we have expanded our software and communications hardware solutions to better support JADC2, C5ISR, SATCOM, and DEVSECOPS for customers in the Army, Navy, Air Force, Marine Corps, and Space Force. Through a combination of hardware, software, and industry expertise, we provide a complete portfolio of solutions and services that accelerates information collection and sharing for faster decision making and better mission outcomes. \n  We are a company of innovative professionals thriving in a highly motivating work environment that fosters creativity and independent thinking. If you are a motivated individual with a desire to support our service men and women, now is a great time to join Sigma Defense! \n  Why would you work for us? Quite simply, the work we do is meaningful and stimulating. We promote initiative and independent thought; we encourage direct client engagement to ensure we are delivering what the customer wants; and our engineers and scientists are working on cutting-edge projects that move the state-of-the-art closer to the people who need them. If you're looking for technical challenges and an opportunity to take a leadership role in an environment that encourages you to excel, then WE are your destination. \n  Want to know what it's like to work at Sigma?  Find out what our employees are saying. \n  Discover Your Next Mission with Sigma Defense  - Find and follow us at Sigma Defense Systems LLC: Overview | LinkedIn and visit Sigma Defense | A Leading Technology Company for more information.  \n Equal Opportunity Employer/Veterans/Disabled:  Sigma Defense Systems is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. \n \n \n \n Sigma Defense is seeking a platform engineer who is enthusiastic about learning and contributing ideas to multiple teams. As a member of the team, the  Mid-Level DevSecOps Engineer  will help accelerate software modernization efforts through platform engineering in unique environments and help instill good DevSecOps practices across the industry. An ideal candidate will bring flexible and humble mindset to the team, and willingness to take on new and unique challenges. As this is a fully remote position, embracing the remote-first culture with the understanding of responsibility for intentional communication as part of daily activity is critical for success. \n  Requirements \n \n Must be a citizen of the United States. \n At minimum 2+ years of experience in DevOps role.  \n Candidate must have experience in a customer service capacity as they will be working directly with customers.  \n Excellent interpersonal and communication skills are needed as providing follow-ups and reports to the customer is required.  \n Candidate must have a customer-first attitude. \n \n Personnel Clearance Level: \n \n Candidate must possess or have the ability to obtain an active, DoD issued Secret security clearance.  A clearance will be sponsored for the right candidate, but employment is contingent upon their ability to successfully obtain a clearance.   \n Candidates with an active DoD issued Secret security clearance, or higher, are preferred. \n \n Education Requirements: \n \n  High School Diploma or GED \n \n  Software/Programs Experience: \n \n Kubernetes experience is critical (operational and developmental.) \n GitOps \n Terraform > VMWare, Azure, AWS \n Helm or Kustomize \n Agile \n Docker \n Linux \n \n Candidate Differentiators: \n \n \n Familiarity with code security and static analysis tools. \n Experience with Git-based infrastructure as code development processes. \n Familiarity with Agile Manifesto. \n Experience documenting processes and workflows with attention to detail. \n Experience with:\n    \n Gitlab CI/CD, Terraform, ArgoCD, Sonarqube, Anchore, Fortify, or, \n a generalized background in CI/CD, static code analysis, and Git infrastructure. \n \n \n Essential Job Duties (Not All-Inclusive): \n \n Contribute to daily Standup meetings. \n Development and maintenance of Infrastructure as Code. \n Development and maintenance of Helm and Kustomize deployments. \n Contribute to individual and team growth, skills, and culture. \n Contribute ideas for continuous improvement. \n \n Salary Range:  $100,000 - $135,000 annually.  \n Benefits \n \n Dental and Vision Insurance \n Medical Insurance to Include an HSA Plan and HRA Plan Which Features a $6,000 Health Reimbursement \n Life and A&D coverage \n Employee Assistance Program (EAP) \n 401(k) Plan with Company Matching Contributions \n 160 Hours of Paid Time Off (PTO) with Carry-Over up to 240 hours \n 12 (Floating) Holidays \n Educational Assistance \n Highly Competitive Salary \n Flexible Schedule",
        "cleaned_desc": " \n Kubernetes experience is critical (operational and developmental.) \n GitOps \n Terraform > VMWare, Azure, AWS \n Helm or Kustomize \n Agile \n Docker \n Linux \n \n Candidate Differentiators: \n \n \n Familiarity with code security and static analysis tools. \n Experience with Git-based infrastructure as code development processes. ",
        "techs": [
            "kubernetes",
            "gitops",
            "terraform",
            "vmware",
            "azure",
            "aws",
            "helm",
            "kustomize",
            "agile",
            "docker",
            "linux"
        ],
        "cleaned_techs": [
            "kubernetes",
            "gitops",
            "terraform",
            "vmware",
            "azure",
            "aws",
            "helm",
            "kustomize",
            "agile",
            "docker",
            "linux"
        ]
    },
    "40826a8d11b958e7": {
        "terms": [
            "mlops"
        ],
        "salary_min": 91514.64,
        "salary_max": 115877.92,
        "title": "DevOps / CI/CD Engineer - Remote in D.C. area",
        "company": "Paradyme Management",
        "desc": "Paradyme Management is a rapidly growing government technology leader that puts service first, for its customers, its team and the communities it supports. Paradyme harnesses DevSecOps and Agile development processes to deliver exceptional results for digital transformations. With headquarters office in Tysons Corner, VA, Paradyme\u2019s award-winning culture sets it apart through its team\u2019s deep commitment to service and collaboration with its customers, each other and the community. Learn more at www.paradymemanagement.com. \n As a CI/CD DevOps Engineer at Paradyme, you will be responsible for designing, implementing, and managing the CI/CD pipelines that enable our development teams to deliver high-quality software efficiently. Operating within a Kanban and SAFe environment, you will ensure that our software development processes align with industry best practices and security standards while maintaining a Public Trust clearance. \n CI/CD Pipeline Development: Design, build, and maintain CI/CD pipelines using tools such as Jenkins, GitHub Actions, and GitLab, ensuring automation and efficiency in software delivery. Collaborate with development teams to integrate CI/CD processes into the software development lifecycle. Infrastructure as Code (IaC): Implement Infrastructure as Code (IaC) practices using Terraform, CloudFormation, or similar tools to automate infrastructure provisioning. Manage and version control IaC templates to ensure consistency and repeatability. Security and Compliance: Implement security best practices and compliance standards in CI/CD pipelines, guaranteeing the secure delivery of software. Maintain the security of development and production environments in accordance with Public Trust clearance requirements. Automation and Orchestration: Develop automation scripts and orchestration processes using scripting languages (e.g., Python, Bash) to streamline operational tasks. Integrate automated testing, code analysis, and quality assurance processes into the CI/CD pipeline. Kanban and SAFe Environment: Collaborate effectively within a Kanban and SAFe Agile environment, working closely with cross-functional teams to facilitate efficient software development and deployment. Participate in Agile ceremonies and contribute to process improvement initiatives. Documentation and Reporting: Maintain comprehensive documentation of CI/CD pipeline configurations, processes, and procedures. Generate reports and metrics to monitor the effectiveness of CI/CD processes. \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). \n Proven experience as a DevOps Engineer with a focus on CI/CD pipelines (3+ years). \n Strong expertise in Jenkins, GitHub Actions, GitLab, or similar CI/CD tools. \n Proficiency in scripting and automation using languages such as Python, Bash, or similar. \n Experience working in a Kanban and SAFe Agile environment. \n Active or the ability to obtain and maintain a Public Trust clearance. \n Strong problem-solving and troubleshooting skills. \n Excellent communication and collaboration skills. \n \n Preferred Skills: \n \n Certifications related to DevOps, CI/CD, or cloud platforms (e.g., AWS, Azure, GCP) are a plus. \n Familiarity with containerization and orchestration technologies like Docker and Kubernetes. \n Knowledge of security best practices and compliance standards (e.g., NIST, FISMA). \n \n REMOTE WORK \n While this position is currently remote, we prefer candidates reside in the local MD, DC, VA areas in the event that our federal customer requires hybrid work in the future. \n Physical Requirements:  These are the essential physical requirements needed to successfully perform the job. \n \n Sedentary work.Requires sitting up to 8 hours per day. \n \n May require lifting up to 5 pounds unassisted. Fine repetitive motor skills with hands, wrists, and fingers in coordination with eyes. \n \n Hearing, speaking, and vision: Adequate to perform job duties and communicate in person, via video, and telephone. Includes reading information from printed sources and computer screens. \n Other: Work may be performed in an office environment, which may involve frequent contact with staff and the public. Work may be stressful at times. \n \n Paradyme Management, Inc. is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Paradyme will take the steps to ensure that people with disabilities are provided reasonable accommodations. Accordingly, if a reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please contact Rose Luczak, Director of People Operations at rose.luczak@paradyme.usor at (571) 289-0548 \n Paradyme is a federal contractor and an EEO and an Affirmative Action Employer. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, pregnancy-related disability, physical or mental disability, genetic information, sexual orientation, marital status, familial status, personal appearance, occupation, citizenship, veteran or military status, gender identity or expression, or any other characteristic protected by federal, state or local law. \n Job Type: Full-time \n Benefits: \n \n 401(k) \n 401(k) matching \n Dental insurance \n Flexible spending account \n Health insurance \n Health savings account \n Life insurance \n Paid time off \n Parental leave \n Professional development assistance \n Vision insurance \n \n Experience level: \n \n 3 years \n \n Schedule: \n \n 8 hour shift \n Day shift \n \n Work Location: Remote",
        "cleaned_desc": "Paradyme Management is a rapidly growing government technology leader that puts service first, for its customers, its team and the communities it supports. Paradyme harnesses DevSecOps and Agile development processes to deliver exceptional results for digital transformations. With headquarters office in Tysons Corner, VA, Paradyme\u2019s award-winning culture sets it apart through its team\u2019s deep commitment to service and collaboration with its customers, each other and the community. Learn more at www.paradymemanagement.com. \n As a CI/CD DevOps Engineer at Paradyme, you will be responsible for designing, implementing, and managing the CI/CD pipelines that enable our development teams to deliver high-quality software efficiently. Operating within a Kanban and SAFe environment, you will ensure that our software development processes align with industry best practices and security standards while maintaining a Public Trust clearance. \n CI/CD Pipeline Development: Design, build, and maintain CI/CD pipelines using tools such as Jenkins, GitHub Actions, and GitLab, ensuring automation and efficiency in software delivery. Collaborate with development teams to integrate CI/CD processes into the software development lifecycle. Infrastructure as Code (IaC): Implement Infrastructure as Code (IaC) practices using Terraform, CloudFormation, or similar tools to automate infrastructure provisioning. Manage and version control IaC templates to ensure consistency and repeatability. Security and Compliance: Implement security best practices and compliance standards in CI/CD pipelines, guaranteeing the secure delivery of software. Maintain the security of development and production environments in accordance with Public Trust clearance requirements. Automation and Orchestration: Develop automation scripts and orchestration processes using scripting languages (e.g., Python, Bash) to streamline operational tasks. Integrate automated testing, code analysis, and quality assurance processes into the CI/CD pipeline. Kanban and SAFe Environment: Collaborate effectively within a Kanban and SAFe Agile environment, working closely with cross-functional teams to facilitate efficient software development and deployment. Participate in Agile ceremonies and contribute to process improvement initiatives. Documentation and Reporting: Maintain comprehensive documentation of CI/CD pipeline configurations, processes, and procedures. Generate reports and metrics to monitor the effectiveness of CI/CD processes. \n Qualifications: \n \n Bachelor's degree in Computer Science, Information Technology, or a related field (or equivalent work experience). \n Proven experience as a DevOps Engineer with a focus on CI/CD pipelines (3+ years). \n Strong expertise in Jenkins, GitHub Actions, GitLab, or similar CI/CD tools. \n Proficiency in scripting and automation using languages such as Python, Bash, or similar. \n Experience working in a Kanban and SAFe Agile environment. \n Active or the ability to obtain and maintain a Public Trust clearance.   Strong problem-solving and troubleshooting skills. \n Excellent communication and collaboration skills. \n \n Preferred Skills: \n \n Certifications related to DevOps, CI/CD, or cloud platforms (e.g., AWS, Azure, GCP) are a plus. \n Familiarity with containerization and orchestration technologies like Docker and Kubernetes. \n Knowledge of security best practices and compliance standards (e.g., NIST, FISMA). \n \n REMOTE WORK \n While this position is currently remote, we prefer candidates reside in the local MD, DC, VA areas in the event that our federal customer requires hybrid work in the future. ",
        "techs": [
            "jenkins",
            "github actions",
            "gitlab",
            "terraform",
            "cloudformation",
            "python",
            "bash",
            "kanban",
            "safe agile",
            "aws",
            "azure",
            "gcp",
            "docker",
            "kubernetes",
            "nist",
            "fisma."
        ],
        "cleaned_techs": [
            "jenkins",
            "github actions",
            "gitlab",
            "terraform",
            "cloudformation",
            "python",
            "bash",
            "kanban",
            "safe agile",
            "aws",
            "azure",
            "gcp",
            "docker",
            "kubernetes",
            "nist",
            "fisma."
        ]
    },
    "93d900098ae8959a": {
        "terms": [
            "mlops"
        ],
        "salary_min": 140000.0,
        "salary_max": 160000.0,
        "title": "Senior AWS DevOps Engineer",
        "company": "Kforce",
        "desc": "RESPONSIBILITIES: \n  Kforce has a client that is seeking a fully remote Senior AWS DevOps Engineer. The successful candidate will demonstrate extensive engineering experience in executing work within the CloudOps/DevOps space. \n \n \n Responsibilities: \n \n \n Senior AWS DevOps Engineer will collaborate closely with the delivery team to ensure seamless integration of development and deployment processes \n Participate in on-call rotation, providing operational support and incident management 24/7 for one week per month \n Collaborate with software engineers to implement best practices for application deployment and configuration management with Amazon ECS \n As a Senior AWS DevOps Engineer, you will leverage your skills to automate repetitive tasks and streamline deployment workflows using GitHub Actions \n Participate in the creation and maintenance of Terraform modules for infrastructure deployments in AWS \n \n REQUIREMENTS: \n \n \n Proven experience working as a DevOps Engineer with 5+ years in AWS \n Hands-on experience with Terraform for infrastructure as code \n Experience with container orchestration (ECS, EKS, Kubernetes) \n Experience configuring & managing CI/CD tools (Jenkins, GitHub, Spinnaker) \n Experience with Kubernetes manifests, deployments, and ingress \n Experience automating builds, releases, and other activities \n Experience operating and configuring observability tools such as Datadog \n Strong familiarity with version control systems, particularly GitHub \n Mastery of one or more scripting languages such as Python and Bash \n Effective communication skills, both verbal and written \n  The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future. \n \n  We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability & ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave. \n \n \n Note:  Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law. \n \n  This job is not eligible for bonuses, incentives or commissions. \n \n  Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",
        "cleaned_desc": " \n \n Proven experience working as a DevOps Engineer with 5+ years in AWS \n Hands-on experience with Terraform for infrastructure as code \n Experience with container orchestration (ECS, EKS, Kubernetes) \n Experience configuring & managing CI/CD tools (Jenkins, GitHub, Spinnaker) \n Experience with Kubernetes manifests, deployments, and ingress ",
        "techs": [
            "aws",
            "terraform",
            "ecs",
            "eks",
            "kubernetes",
            "jenkins",
            "github",
            "spinnaker"
        ],
        "cleaned_techs": [
            "aws",
            "terraform",
            "ecs",
            "eks",
            "kubernetes",
            "jenkins",
            "github",
            "spinnaker"
        ]
    },
    "metadata": {
        "keywords": [
            "data science",
            "data analyst",
            "data engineer",
            "machine learning engineer",
            "mlops"
        ],
        "locations": [
            "remote"
        ],
        "time_ran": "11:51:07-19-09-23",
        "num_jobs": 7441,
        "timings": {
            "start_drivers": 46.01746892929077,
            "find_job_ids": 522.530196428299,
            "get_job_descs": 133.5970060825348
        },
        "models": {
            "classifier": {
                "clf": "data/classifier_models/job_desc_classifier_v1.0.pkl",
                "tfidf": "data/classifier_models/job_desc_tfidf_vectorizerv1.0.pkl"
            },
            "NER": "gpt-3.5-turbo"
        }
    }
}